{"ae83164544567281": {"terms": ["data science", "data engineer"], "salary_min": 79602.0, "salary_max": 114700.0, "title": "Associate Data Engineer", "company": "Liberty Mutual", "desc": "Pay Philosophy \n  The typical starting salary range for this role is determined by a number of factors including skills, experience, education, certifications and location. The full salary range for this role reflects the competitive labor market value for all employees in these positions across the national market and provides an opportunity to progress as employees grow and develop within the role. Some roles at Liberty Mutual have a corresponding compensation plan which may include commission and/or bonus earnings at rates that vary based on multiple factors set forth in the compensation plan for the role. \n  Description  \n \n Under direct supervision, responsible for the analysis, development, and execution of data solutions of low to moderate complexity that assists with the information lifecycle needs of an organization \n  Assists with collecting, integrating, and analyzing organizational data with the purpose of drawing conclusions from that information \n  Develops, constructs, tests, and maintains data architectures for data platform, database, analytical, reporting, or data science systems \n  Recognizes opportunities to improve data reliability, quality, and efficiency and may make recommendations where appropriate  \n Designs and develops low complexity programs and tools to support ingestion, curation and provisioning of enterprise data to achieve analytics or reporting \n  Builds and designs data models and data architecture that improve accessibility, efficiency, governance and quality of data \n  Recognizes opportunities to improve data quality \n  Assists with aspects of deployment of data solutions \n  Helps identify possible process improvements that address technology gaps within a single business process of low to moderate complexity \n  Analyzes and prepare low to moderately complex technology enabled recommendations to address gaps within a single business process \n  Performs other projects and duties as assigned \n  Telecommuting permitted up to 100% \n \n  Qualifications \n  The position requires a Bachelor\u2019s degree, or foreign equivalent, in Electrical Engineering, or a related technical or business field plus two (2) years of experience in the job offered or a Associate Data Engineer-related occupation. Position also requires demonstrable experience with each of the following: \n \n  New and emerging technologies including AWS SDK, and Docker/Kubernetes \n  IT concepts, strategies and methodologies \n  IT architectures and technical standards \n  Business function and business operations \n  Design and development tools \n  Layered systems architectures and shared data engineering concepts \n  Agile data engineering concepts and processes \n  Applying customer requirements, including drawing out unforeseen implications and making recommendations for design, the ability to define design reasoning, understanding potential impacts of design requirements \n  Telecommuting permitted up to 100% \n \n  To apply, please visit https://jobs.libertymutualgroup.com/, select \u201cSearch Jobs,\u201d enter job requisition #2023-61263 in the \u201cJob ID or Keywords\u201d field, and submit resume. Alternatively, you may apply by submitting a resume via e-mail to RecruitLM@LibertyMutual.com. Reference requisition number in subject of e-mail. \n  About Us \n  **This position may have in-office requirements depending on candidate location.** \n \n  At Liberty Mutual, our purpose is to help people embrace today and confidently pursue tomorrow. That\u2019s why we provide an environment focused on openness, inclusion, trust and respect. Here, you\u2019ll discover our expansive range of roles, and a workplace where we aim to help turn your passion into a rewarding profession. \n \n  Liberty Mutual has proudly been recognized as a \u201cGreat Place to Work\u201d by Great Place to Work\u00ae US for the past several years. We were also selected as one of the \u201c100 Best Places to Work in IT\u201d on IDG\u2019s Insider Pro and Computerworld\u2019s 2020 list. For many years running, we have been named by Forbes as one of America\u2019s Best Employers for Women and one of America\u2019s Best Employers for New Graduates\u2014as well as one of America\u2019s Best Employers for Diversity. To learn more about our commitment to diversity and inclusion please visit: https://jobs.libertymutualgroup.com/diversity-equity-inclusion/ \n \n  We value your hard work, integrity and commitment to make things better, and we put people first by offering you benefits that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/Benefits \n \n  Liberty Mutual is an equal opportunity employer. We will not tolerate discrimination on the basis of race, color, national origin, sex, sexual orientation, gender identity, religion, age, disability, veteran\u2019s status, pregnancy, genetic information or on any basis prohibited by federal, state or local law.", "cleaned_desc": "", "techs": ""}, "4dc3b0e83239236b": {"terms": ["data science"], "salary_min": 97981.15, "salary_max": 124065.96, "title": "Data Scientist", "company": "Wizeline", "desc": "The Company \n  Wizeline is a global digital services company helping mid-size to Fortune 500 companies build, scale, and deliver high-quality digital products and services. \n  We thrive in solving our customer\u2019s challenges through human-centered experiences, digital core modernization, and intelligence everywhere (AI/ML and data). We help them succeed in building digital capabilities that bring technology to the core of their business. \n \n \n  Our People \n  At Wizeline, we are a team of near 2,000 people spread across 25+ countries. We understand that great technology begins with outstanding talent and diversity of thought. Our business was built on doing well and doing good, and our values of Ownership, Innovation, Community, and Diversity & Inclusion are embedded within our company\u2019s DNA. We are committed to offering our Wizeliners the opportunity to create their career path and develop the skills needed to achieve their personal goals. \n \n \n  Community Impact \n  We are proud to contribute to local economies by developing technology ecosystems in places like Mexico, Colombia, and Vietnam. We also created Wizeline Academy, a free, community-based education program that teaches high-value skills to workers looking to advance their tech industry careers. As of 2022, Academy has served more than 28,000 students across 675 courses. Wizeliners have the opportunity to upskill by taking Wizeline Academy courses and can also share their expertise by delivering classes to students. \n \n \n  What will you bring to the team? \n  The Intelligence Unit of the Business Operations team seeks a Data Scientist with strong analytical and communication skills to join our team. We develop algorithms that involve learning from core systems, such as HCM, ERP, ATS, CRM, internal products, and Staffing Systems, in order to generate and improve existing data models. \n  Your Day-to-Day \n  On a typical day, you will work closely with talented data analysts, data engineers, software engineers, and business groups. As a successful data scientist in our team, you are an analytical problem solver who enjoys diving into data, is excited about investigations and algorithms, can multi-task, and can credibly interface between technical teams and business stakeholders. Your analytical abilities, business understanding, and technical savvy will be used to identify specific and actionable opportunities to solve existing business problems, through collaboration with engineering and business teams. Your expertise in synthesizing and communicating insights and recommendations to audiences of varying levels of technical sophistication will enable you to answer specific business questions and innovate for the future. \n  Major responsibilities include: \n \n Analyzing and translating business needs into long-term solution data models, utilizing code for analyzing data, and building statistical and machine learning models and algorithms. \n \n \n Evaluating implemented data systems for variances, discrepancies, and efficiency. \n \n \n Supporting decision-making by providing requirements to develop analytic capabilities, platforms, pipelines, and metrics then using them to analyze trends and find root causes of model inaccuracy. \n \n  Are You a Fit? \n Minimum qualifications: \n  Optimization Solvers (CPLEX, Gurobi, Pulp, Pyomo, etc)  Mixed Integer Programming  Machine Learning Techniques \n    Nice to Have Skills \n  AdTech  Greedy Heuristics  Timeseries Modeling  AWS SageMaker \n \n \n  Why You Should Apply \n  Still not convinced you should apply? Here are some of the things that make Wizeline different from other technology services companies: \n  Our Values \n  At Wizeline, we value innovation, community, and ownership. Our commitment to diversity, inclusion, and respect fosters an environment where everyone does well and does good. We're proud to be recognized by the Human Rights Campaign Foundation in response to our inclusive corporate policies and best practices for LGBTQ+ employees. \n  Our Culture \n  We offer exceptional career growth and learning opportunities to our employees with skill development workshops, mentoring programs, and support for side projects or entrepreneurial work. We ranked 7th on Expansi\u00f3n\u2019s Super Companies 2021 list. \n \n \n  Our Benefits and Perks \n  We offer competitive compensation and employee-centric benefits, including industry-leading maternity and paternity leave, wellness programs, and remote work opportunities. All Wizeliners have access to continuous learning opportunities through Wizeline Academy, including cloud certifications, mentorship, LinkedIn Learning, Udemy, and in-house technical bootcamps developed by our experts in the field. \n \n \n  In recognition of our superb employee benefits, we debuted on Quartz\u2019s list of the Best Companies for Remote Workers and ranked 5th on Expansi\u00f3n\u2019s Super Workspaces 2021 list. \n \n \n  Our Global Family \n  To support the global nature of our business and help our employees grow beyond their technical skills, we offer free virtual English and Spanish language classes as well as provide immigration support when applicable. Prior to COVID-19, we had a robust Work Abroad program in place, which we plan to continue once it\u2019s safe to do so. \n \n \n  #AllAreWelcomeHere \n  Wizeline creates and fosters a diverse, inclusive, and harassment-free workplace where everyone can achieve their potential. All applicants will be considered for employment regardless of race, color, religion, sex, sexual orientation, gender identity, national origin, veteran, or disability status. \n \n \n  Please note that by submitting your application, you agree with the terms and conditions of our Privacy Policy. \n \n  Please note that by submitting your application, you agree with the terms and conditions of our Privacy Policy.  \n \n \n \n Data Scientist  \n LOCATION \n Latam based Remote \n DEPARTMENT \n Data Science", "cleaned_desc": "  What will you bring to the team? \n  The Intelligence Unit of the Business Operations team seeks a Data Scientist with strong analytical and communication skills to join our team. We develop algorithms that involve learning from core systems, such as HCM, ERP, ATS, CRM, internal products, and Staffing Systems, in order to generate and improve existing data models. \n  Your Day-to-Day \n  On a typical day, you will work closely with talented data analysts, data engineers, software engineers, and business groups. As a successful data scientist in our team, you are an analytical problem solver who enjoys diving into data, is excited about investigations and algorithms, can multi-task, and can credibly interface between technical teams and business stakeholders. Your analytical abilities, business understanding, and technical savvy will be used to identify specific and actionable opportunities to solve existing business problems, through collaboration with engineering and business teams. Your expertise in synthesizing and communicating insights and recommendations to audiences of varying levels of technical sophistication will enable you to answer specific business questions and innovate for the future. \n  Major responsibilities include: \n \n Analyzing and translating business needs into long-term solution data models, utilizing code for analyzing data, and building statistical and machine learning models and algorithms. \n \n \n Evaluating implemented data systems for variances, discrepancies, and efficiency. \n \n \n Supporting decision-making by providing requirements to develop analytic capabilities, platforms, pipelines, and metrics then using them to analyze trends and find root causes of model inaccuracy. ", "techs": ["hcm", "erp", "ats", "crm"]}, "37c37cec6a51cba7": {"terms": ["data science", "data analyst"], "salary_min": 55.0, "salary_max": 55.0, "title": "Senior Data Analyst", "company": "TAJ Technologies Inc", "desc": "Job Title: Senior Analyst \n Work location: REMOTE \n Duration: One Year and 40 hours/week (5*8 DAY SHIFT) \n Schedule Shift: Flexible \n Schedule Notes:  Required minimum 7+ year of Data Analyst experience. The candidate will have a broad technical background including SQL, data warehousing, dashboard development with SPLUNK and experience programming in high-level languages such as Java and Python. The successful candidate must also have strong organizational skills, system support experience, and a strong customer focus. Regularly reviews applications performance and availability metrics to ensure the applications are within established set standards. Maintains and supports multiple systems of complex software applications and their associated hardware at multiple Client sites. Demonstrates initiative and works independently as needed to accomplish responsibilities. May interface with vendor support service groups or other external support teams to ensure proper escalation during outages or periods of degraded system performance. Interfaces routinely with colleagues who may be located at any of the Mayo Group practices to perform job responsibilities requiring virtual collaboration and partnership. \n Job Type: Contract \n Pay: $55.00 per hour \n Expected hours: 40 per week \n Benefits: \n \n Health insurance \n \n Compensation package: \n \n Signing bonus \n \n Experience level: \n \n 7 years \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n No weekends \n \n Application Question(s): \n \n Could you please specify the most suitable time for us to connect, ideally between 9:30 AM and 4:30 PM? We can have a comprehensive discussion about the job opportunity during that time. \n \n Experience: \n \n Senior Data Analyst: 7 years (Required) \n SQL: 7 years (Required) \n Data warehouse: 7 years (Required) \n Splunk: 7 years (Required) \n Python: 3 years (Required) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "f6025098ab97e827": {"terms": ["data science", "data engineer", "machine learning engineer", "mlops"], "salary_min": 123552.03, "salary_max": 156444.4, "title": "Data Science Engineer", "company": "PrizePicks", "desc": "At PrizePicks, we are the fastest growing sports company in North America, as recognized by Inc. 5000. As the leading platform for Daily Fantasy Sports, we cover a diverse range of sports leagues, including the NFL, NBA, and Esports titles like League of Legends and CS:GO. Our team of over 350 employees thrives in an inclusive culture that values individuals from diverse backgrounds, regardless of their level of sports fandom. Ready to reimagine the DFS industry together? \n \n  The Analytics Team is responsible for building and maintaining analytics tools and workflows to support the PrizePicks business across all departments \u2014 at the core of these operations is data. As a Data Science Engineer, you will be developing, maintaining, and testing streaming data and MLOps infrastructures to enable PrizePicks to offer real-time priced markets within the product. \n  What you'll do: \n \n Create and maintain optimal sport data stream architecture, ensuring data reliability in both speed and quality for both raw and transformed data pipelines. \n Partner with Data Science to determine the best paths for operationalization of DS/ML assets, ensuring model output quality, stability, and scalability. \n Lead the design and implementation of the data and MLOps stack required for real-time pricing models and contribute to architecture evaluations and decisions for our growing data product roadmap. \n Work cross-functionally with Engineering, QA, and Product teams to enable the creation and distribution of highly-visible, real-time, in-game micromarket offerings to the PrizePicks platform. \n Build and own rigorous monitoring, alerting, and documentation processes, and work with Engineering teams to ensure complete feature uptime. \n \n What you have: \n \n 3+ years of experience in a data science, machine learning engineer, or data-oriented software engineering role creating and pushing end-to-end data science pipelines and MLOps assets to production. \n Experience building and optimizing cloud-based data streaming pipelines and infrastructure. \n Experience exposing real-time predictive model outputs to production-grade systems leveraging large-scale distributed data processing and model training. \n Experience with the following: \n Strong organizational, communication, presentation, and collaboration experience with organizational technical and non-technical teams \n Graduate degree in Computer Science, Statistics, Mathematics, Informatics, Information Systems or other quantitative field \n Preferred: experience building real-time production data science pipelines in a daily fantasy sports or oddsmaking business \n \n Where you'll live: \n \n Anywhere in the US is fine but Atlanta would be preferred. \n \n Benefits you'll receive: \n  In addition to your great compensation package, company subsidized medical/dental/vision coverage plans and matching 401(k), we'll shower you with perks including: \n \n Break room with ping pong, endless snacks and in-office lunch once a week \n Unlimited PTO to encourage a healthy work/life balance (2 week min required!) \n Modern work schedule focused on getting the job done, not hours clocked \n Workplace flexibility  \n Company and team outings, we encourage a tight-knit workplace \n Generous Maternity AND Paternity leave (16 weeks!) \n Annual bonus & stock options  \n Wellness program \n Company equipment provided (Windows & Mac options) \n Annual performance reviews with opportunity for growth and career development \n \n \n \n  You must be authorized to work for any employer in the U.S. We are unable to sponsor or take over sponsorship of an employment Visa at this time. \n  PrizePicks is an Equal Opportunity Employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.", "cleaned_desc": " Work cross-functionally with Engineering, QA, and Product teams to enable the creation and distribution of highly-visible, real-time, in-game micromarket offerings to the PrizePicks platform. \n Build and own rigorous monitoring, alerting, and documentation processes, and work with Engineering teams to ensure complete feature uptime. \n \n What you have: \n \n 3+ years of experience in a data science, machine learning engineer, or data-oriented software engineering role creating and pushing end-to-end data science pipelines and MLOps assets to production. \n Experience building and optimizing cloud-based data streaming pipelines and infrastructure. \n Experience exposing real-time predictive model outputs to production-grade systems leveraging large-scale distributed data processing and model training. ", "techs": ["work cross-functionally with engineering", "qa", "and product teams", "data science", "machine learning engineer", "data-oriented software engineering", "data science pipelines", "mlops assets", "cloud-based data streaming pipelines", "infrastructure", "real-time predictive model outputs", "large-scale distributed data processing", "model training."]}, "da6e2fa007f28d70": {"terms": ["data science", "mlops"], "salary_min": 108147.22, "salary_max": 136938.47, "title": "Data Scientist", "company": "Novisync", "desc": "Location:  Remote Remote USA\n     \n \n \n \n \n  Big data engineering in spark(databricks recommended not a must have) \n  Python flask/Gunicorn API dev \n  API Integration with Azure cognitive services or similar search enginers \n  Experience with Azure computer vision API\u2019s \n  Understanding of OpenAI (good to have, not a must have) \n  Data App development experience ( preferably in Dash App) \n  API monitoring/scaling experience in Kubernetes \n  Mlflow/Mlops/Datascience background", "cleaned_desc": "", "techs": ""}, "6b5aa328fc739cdb": {"terms": ["data science", "data analyst"], "salary_min": null, "salary_max": null, "title": "People Data Analyst - Survey and Research", "company": "Atlassian", "desc": "Overview: \n   Working at Atlassian \n  Atlassians can choose where they work \u2013 whether in an office, from home, or a combination of the two. That way, Atlassians have more control over supporting their family, personal goals, and other priorities. We can hire people in any country where we have a legal entity. Interviews and onboarding are conducted virtually, a part of being a distributed-first company. \n \n  Our People Data team is comprised of people with backgrounds in analytics, data management, data governance, and data insights. We implement solid data management practices to deliver reliable and trusted data. \n \n  The Research Data Analyst is responsible for developing and managing data-driven research projects. This includes collecting and analyzing data, creating visualizations, and communicating findings to stakeholders. The ideal candidate will have a strong understanding of Qualtrics, SQL, and BI tools.  Responsibilities: \n  \n  Conduct in-depth analysis of employee survey data to identify trends, patterns, and insights related to employee engagement, satisfaction, and well-being. \n  Develop and execute data-driven research projects. \n  Create interactive and informative data visualizations and dashboards to communicate key findings to stakeholders. \n  Collaborate with HR, leadership, and other teams to understand their data needs and provide data-driven insights to inform decision-making. \n  Work with cross-functional teams to ensure that research findings are incorporated into decision-making processes. \n  Create data driven reports and dashboards for insights and decision making. \n  Develop and maintain data pipelines and reporting systems to ensure accurate delivery of survey results. \n  Support the design and administration of employee surveys, ensuring they are well-structured and provide actionable data. \n  Assist in the development of employee engagement strategies and initiatives based on survey findings. \n \n  Qualifications: \n  \n  Bachelor's degree in Data Science, Business Analytics, Human Resources, or a related field. \n  5-7 years of experience in data management and data quality assurance, with a focus on HR and People data. \n  Proficiency in data integration, transformation, and ETL (Extract, Transform, Load) processes. \n  Proficiency in data visualization tools such as Tableau, Power BI, or similar. \n  Strong statistical analysis skills and familiarity with statistical software (e.g., R, Python). \n  Familiarity with HRIS (Human Resources Information Systems) and HR processes. \n  Strong project management skills \n  Experience with data analysis in the context of employee survey data. \n  Excellent communication skills, with the ability to translate complex data into actionable insights. \n  Detail-oriented, with a passion for accuracy and data integrity. \n  Collaborative mindset and ability to work effectively in cross-functional teams. \n  You have amazing project management skills. \n \n \n  Compensation \n  At Atlassian, we strive to design equitable and explainable compensation programs. To support this goal, the baseline of our range is higher than that of the typical market range, but in turn we expect to hire most candidates near this baseline. Base pay within the range is ultimately determined by a candidate's skills, expertise, or experience. \n  In the United States, we have three geographic pay zones. For this role, our current base pay ranges for new hires in each zone are: \n  Zone A: $163,300 - $217,700 \n  Zone B: $147,000 - $196,000 \n  Zone C: $135,600 - $180,700 \n  This role may also be eligible for benefits, bonuses, commissions, and equity. \n  Please visit go.atlassian.com/payzones for more information on which locations are included in each of our geographic pay zones. However, please confirm the zone for your specific location with your recruiter. \n  #LI-Remote \n \n  Our perks & benefits \n  Atlassian offers a variety of perks and benefits to support you, your family and to help you engage with your local community. Our offerings include health coverage, paid volunteer days, wellness resources, and so much more. Visit  go.atlassian.com/perksandbenefits   to learn more. \n  About Atlassian \n  At Atlassian, we're motivated by a common goal: to unleash the potential of every team. Our software products help teams all over the planet and our solutions are designed for all types of work. Team collaboration through our tools makes what may be impossible alone, possible together. \n  We believe that the unique contributions of all Atlassians create our success. To ensure that our products and culture continue to incorporate everyone's perspectives and experience, we never discriminate based on race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status. All your information will be kept confidential according to EEO guidelines. \n  To provide you the best experience, we can support with accommodations or adjustments at any stage of the recruitment process. Simply inform our Recruitment team during your conversation with them. \n  Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. \n  To learn more about our culture and hiring process, visit  go.atlassian.com/crh .", "cleaned_desc": "  Bachelor's degree in Data Science, Business Analytics, Human Resources, or a related field. \n  5-7 years of experience in data management and data quality assurance, with a focus on HR and People data. \n  Proficiency in data integration, transformation, and ETL (Extract, Transform, Load) processes. \n  Proficiency in data visualization tools such as Tableau, Power BI, or similar. \n  Strong statistical analysis skills and familiarity with statistical software (e.g., R, Python). \n  Familiarity with HRIS (Human Resources Information Systems) and HR processes. \n  Strong project management skills \n  Experience with data analysis in the context of employee survey data. \n  Excellent communication skills, with the ability to translate complex data into actionable insights. \n  Detail-oriented, with a passion for accuracy and data integrity. ", "techs": ["bachelor's degree in data science", "business analytics", "human resources", "or a related field", "\n5-7 years of experience in data management and data quality assurance", "with a focus on hr and people data", "\nproficiency in data integration", "transformation", "and etl (extract", "transform", "load) processes", "\nproficiency in data visualization tools such as tableau", "power bi", "or similar", "\nstrong statistical analysis skills and familiarity with statistical software (e.g.", "r", "python)", "\nfamiliarity with hris (human resources information systems) and hr processes", "\nstrong project management skills", "\nexperience with data analysis in the context of employee survey data", "\nexcellent communication skills", "\ndetail-oriented", "with a passion for accuracy and data integrity."]}, "650e20f642a35ee4": {"terms": ["data science", "data analyst"], "salary_min": 68688.0, "salary_max": 136422.0, "title": "Data Analyst (Remote)", "company": "CareFirst BlueCross BlueShield", "desc": "Resp & Qualifications   \n PURPOSE:   The main purpose of a data analyst is to find meaning in data so that the derived knowledge can be used to make informed decisions and assist the organization in making better business decisions.      ESSENTIAL FUNCTIONS: \n \n  Engages in data exploration using various programming languages (reading and writing code), requiring knowledge of multiple database structures.  \n Supports stakeholder in gathering business and technical requirements to deliver data driven solutions. \n  Produces technical documentation that is consistent with professional standards. \n  Research and analyze data flow across data ecosystem including operational and analytical data platforms. \n  Serve as a knowledgeable resource supporting data questions and issues from stakeholders. \n  Collect, analyze, and interpret data to glean insights, and suggest business appropriate recommendations. \n  Participate in the design, development, validation and delivery of data to provide insight into business decisions.  \n \n QUALIFICATIONS:     Education Level:  Bachelor's Degree in Data Science, Mathematics, Computer Science, Statistics, Business or related field OR in lieu of a Bachelor's degree, an additional 4 years of relevant work experience is required in addition to the required work experience.     Experience:  3 years of data analysis or relevant work experience.     Preferred Qualifications: \n \n  Hands on experience with Big Data/NoSQL Platforms with experience delivering production projects at scale.  \n Experience in health care industry. \n \n  Knowledge, Skills and Abilities (KSAs) \n \n  Quantitative, analytical and problem solving skills.  \n Knowledge and understanding of analytical tools, languages, applications, platforms. \n  Excellent communication skills both written and verbal. \n  Ability to learn quickly and take direction. \n  Must be able to meet established deadlines and handle multiple customer service demands from internal and external customers, within set expectations for service excellence. Must be able to effectively communicate and provide positive customer service to every internal and external customer, including customers who may be demanding or otherwise challenging. \n \n  Salary Range:  $68,688 - $136,422   \n Salary Range Disclaimer   \n The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the work is being performed. This compensation range is specific and considers factors such as (but not limited to) the scope and responsibilites of the position, the candidate's work experience, education/training, internal peer equity, and market and business consideration. It is not typical for an individual to be hired at the top of the range, as compensation decisions depend on each case's facts and circumstances, including but not limited to experience, internal equity, and location. In addition to your compensation, CareFirst offers a comprehensive benefits package, various incentive programs/plans, and 401k contribution programs/plans (all benefits/incentives are subject to eligibility requirements). \n  Department   \n HealthCare Analytics \n  Equal Employment Opportunity   \n CareFirst BlueCross BlueShield is an Equal Opportunity (EEO) employer. It is the policy of the Company to provide equal employment opportunities to all qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, protected veteran or disabled status, or genetic information. \n  Where To Apply   \n Please visit our website to apply: www.carefirst.com/careers \n  Federal Disc/Physical Demand   \n Note: The incumbent is required to immediately disclose any debarment, exclusion, or other event that makes him/her ineligible to perform work directly or indirectly on Federal health care programs. \n  PHYSICAL DEMANDS: \n  The associate is primarily seated while performing the duties of the position. Occasional walking or standing is required. The hands are regularly used to write, type, key and handle or feel small controls and objects. The associate must frequently talk and hear. Weights up to 25 pounds are occasionally lifted. \n  Sponsorship in US   \n Must be eligible to work in the U.S. without Sponsorship \n  #LI-LD1", "cleaned_desc": "Resp & Qualifications   \n PURPOSE:   The main purpose of a data analyst is to find meaning in data so that the derived knowledge can be used to make informed decisions and assist the organization in making better business decisions.      ESSENTIAL FUNCTIONS: \n \n  Engages in data exploration using various programming languages (reading and writing code), requiring knowledge of multiple database structures.  \n Supports stakeholder in gathering business and technical requirements to deliver data driven solutions. \n  Produces technical documentation that is consistent with professional standards. \n  Research and analyze data flow across data ecosystem including operational and analytical data platforms.    Serve as a knowledgeable resource supporting data questions and issues from stakeholders. \n  Collect, analyze, and interpret data to glean insights, and suggest business appropriate recommendations. \n  Participate in the design, development, validation and delivery of data to provide insight into business decisions.  \n \n QUALIFICATIONS:     Education Level:  Bachelor's Degree in Data Science, Mathematics, Computer Science, Statistics, Business or related field OR in lieu of a Bachelor's degree, an additional 4 years of relevant work experience is required in addition to the required work experience.     Experience:  3 years of data analysis or relevant work experience.     Preferred Qualifications: \n \n  Hands on experience with Big Data/NoSQL Platforms with experience delivering production projects at scale.    Experience in health care industry. \n \n  Knowledge, Skills and Abilities (KSAs) \n \n  Quantitative, analytical and problem solving skills.  \n Knowledge and understanding of analytical tools, languages, applications, platforms. \n  Excellent communication skills both written and verbal. ", "techs": ["programming languages", "database structures", "technical documentation", "data flow analysis", "data analysis", "data interpretation", "data design and development", "validation of data", "big data/nosql platforms", "health care industry", "quantitative skills", "analytical skills", "problem solving skills", "analytical tools", "communication skills"]}, "703f3910a0ec488e": {"terms": ["data science"], "salary_min": 125000.0, "salary_max": 175000.0, "title": "Data Scientist", "company": "Ascendion", "desc": "Description \n About Ascendion : \n  Ascendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next. \n  Ascendion | Engineering to elevate life \n  We have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us \n \n Build the coolest tech for the world\u2019s leading brands \n Solve complex problems - and learn new skills \n Experience the power of transforming digital engineering for Fortune 500 clients \n Master your craft with leading training programs and hands-on experience \n Experience a community of change-makers! \n \n \n \n  Join a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion. \n  About the Role: \n  Job Title: Data Scientist \n  Job Responsibilities: \n \n Work with senior management, technical and client teams in order to determine data requirements, business data implementation approaches, best practices for advanced data manipulation, storage, and analysis strategies \n Write and code logical and physical database descriptions and specify identifiers of the database to the management system or direct others in coding descriptions \n Design, implement, automate, and maintain large-scale enterprise data ETL processes \n Modify existing databases and database management systems and/or direct programmers and analysts to make changes \n Test programs or databases, correct errors and make necessary modifications \n \n Qualifications: \n \n 10+ years of applicable experience required \n Experience with database technologies \n Knowledge of the ETL process \n Knowledge of at least one scripting language \n Strong written and oral communication skills \n Strong troubleshooting and problem-solving skills \n Desire to be working with data and helping businesses make better data-driven decisions \n \n Must have Requirements: \n \n Statistics \n Python \n SQL \n E-commerce \n \n Location:  Remote \n  Salary Range:  The salary for this position is between  $125K- 175K Annually . Factors that may affect pay within this range may include geography/market, skills, education, experience, and other qualifications of the successful candidate. \n  Benefits : The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [09-10 days/hours of paid time off] \n  Want to change the world? Let us know. \n  Tell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let\u2019s talk! \n Preferred Skills: \n \n Statistics \n  Python \n  SQL \n  E-commerce \n \n Job details \n \n \n Job ID \n \n \n   328906\n   \n \n \n \n Job Requirements \n \n \n   Data Scientist\n   \n \n \n \n \n Location \n \n \n   Redmond, Washington, US\n   \n \n \n \n \n Recruiter \n \n \n   Namrata\n   \n \n \n \n Email \n \n \n   namrata.rani@ascendion.com", "cleaned_desc": " \n Work with senior management, technical and client teams in order to determine data requirements, business data implementation approaches, best practices for advanced data manipulation, storage, and analysis strategies \n Write and code logical and physical database descriptions and specify identifiers of the database to the management system or direct others in coding descriptions \n Design, implement, automate, and maintain large-scale enterprise data ETL processes \n Modify existing databases and database management systems and/or direct programmers and analysts to make changes \n Test programs or databases, correct errors and make necessary modifications \n \n Qualifications: \n \n 10+ years of applicable experience required \n Experience with database technologies \n Knowledge of the ETL process \n Knowledge of at least one scripting language \n Strong written and oral communication skills \n Strong troubleshooting and problem-solving skills \n Desire to be working with data and helping businesses make better data-driven decisions \n \n Must have Requirements: ", "techs": ["database technologies", "etl process", "scripting language"]}, "1fd98fea0ceb9bb7": {"terms": ["data science"], "salary_min": 45616.586, "salary_max": 57760.766, "title": "Virtual Concierge Representative", "company": "Ashfield Nordic AB", "desc": "We are seeking a Virtual Concierge Representative in support of the Inogen Portable Oxygen Concentrator Franchise.\n  \n \n \n   The Virtual Concierge Representative is responsible for educating HCP offices around the process for the benefit and coverage validation process required for Inogen device delivery. You will interact with HCPs, including nurses and insurance specialists, managed care organizations (Medicare).\n  \n \n \n   This is your opportunity to join Inizio Engage and represent a top biotechnology company!\n  \n \n \n   What\u2019s in it for you?\n  \n \n \n  Competitive compensation \n  Excellent Benefits \u2013 accrued time off, medical, dental, vision, 401k, disability & life insurance, paid maternity and bonding time benefits, employee discounts/promotions \n  Generous performance-driven Incentive Compensation package \n  Competitive environment with company wide recognition, contests, and coveted awards \n  Exceptional company culture \n  Recognized as a Top Workplace USA 2021 \n  Awarded a \u201cGreat Place to Work\u201d award in 2022 and 2023 \n  Fortune Best Workplaces in Biopharma 2022 \n \n \n \n   What will you be doing?\n  \n \n \n  Educating HCP offices around the process for coverage eligibility for POC therapy \n  Ensuring that the HCP office understands all required documentation i.e. EOBs, certificates of medical necessity \n  Communicating with HCP offices with a regular, deliberate cadence \n  Acting with a sense of urgency \n  Responding to questions from HCPs in a timely manner \n  Following up on key action items to ensure HCP is reminded on what is needed for validation to be completed \n  Partnering with RDMs to ensure timely deliver \n \n \n \n   What do you need for this position?\n  \n \n \n  1+ years of total sales/service experience \n  Customer service experience preferred \n  Bachelor\u2019s Degree Preferred \n  Competitive and sales driven with soft skills to work within a team structure \n  Strong clinical, scientific and business acumen and ability to educate prescribers and key influencers \n  Documented track record of positive sales results required \n  Ability to independently manage territory sales plan and adjust as required to meet/exceed objectives \n  Proficient using technology (Zoom, WebEx) platform to connect with customers \n  Ability to join frequent meetings and calls without disruption or disconnecting \n \n \n \n   About Inizio Engage\n  \n \n \n  Inizio Engage is a strategic, commercial, and creative engagement partner that specializes in healthcare. Our passionate, global workforce augments local expertise and diverse mix of skills with data, science, and technology to deliver bespoke engagement solutions that help clients reimagine how they engage with their patients, payers, people and providers to improve treatment outcomes. Our mission is to partner with our clients, improving lives by helping healthcare professionals and patients get the medicines, knowledge and support they need.\n  \n \n \n   To learn more about Inizio Engage, visit us at: \n   \n   https://inizio.health/\n   \n \n \n \n   We believe in our values: We empower everyone/We rise to the challenge/We work as one/We ask what if/We do the right thing, and we will ask you how your personal values align to them.\n  \n \n \n   Inizio Engage is proud to be an equal opportunity employer. Individuals seeking employment at Inizio are considered without regards to age, ancestry, color, gender, gender identity or expression, genetic information, marital status, medical condition (including pregnancy, childbirth, or related medical conditions), mental or physical disability, national origin, protected family care or medical leave status, race, religion (including beliefs and practices or the absence thereof), sexual orientation, military or veteran status, or any other characteristic protected by federal, state, or local laws. Further, pursuant to applicable local ordinances, Inizio will consider for employment qualified applicants with arrest and conviction records.\n  \n \n \n   Inizio Engage is an equal opportunity employer M/F/V/D. We appreciate your interest in our company, however, only qualified candidates will be considered.", "cleaned_desc": "", "techs": ""}, "712f3e9852eace29": {"terms": ["data science"], "salary_min": 114477.43, "salary_max": 144953.94, "title": "Data Scientist", "company": "eCapital", "desc": "About Us:  At eCapital, we are on a mission to ignite growth and empower businesses across North America and the U.K. by accelerating their access to capital. Our expertise and forward-thinking technology create customized, cutting-edge solutions for clients in over 80 industries. We are proud to have been named to the prestigious Inc. 5000 Fastest Growing Company list in 2023, recognized as a \u2018Great Place to Work\u2019 by the Secured Finance Network, and celebrated as a \u2018Most Innovative Company\u2019 by ABF Journal; all thanks to our dynamic team who are the cornerstone of our success. \n  To continue to innovate and find better solutions for our company and clients, we need bright minds, enthusiastic advocates, and savvy industry professionals. By joining our team, you will have the opportunity to unleash your potential, challenge yourself, and experience a rewarding culture with competitive salaries and unique employee benefits. \n  Are you ready to make an impact and help us shape the future of finance? \n  The Role:  eCapital is looking for a  Data Scientist  to join a growing Business Intelligence team. In this role, you will take the lead on developing and maintaining the end to end Machine Learning workflow. From building data pipelines using the latest cloud technologies to deploying models for consumption, you will collaborate with the infrastructure team to implement production ready solutions. You will have the opportunity to work on a variety of projects including OCR, credit risk modeling, client retention, sales forecasting, fraud detection, marketing recommendation systems. You will have the opportunity to directly influence the course of the business from day one as eCapital continues to leverage it\u2019s volumes of data. \n  Responsibilities: \n \n  Independently design, test, deploy and maintain production Machine Learning models using established frameworks and CI/CD practices \n  Work on multiple concurrent projects, anticipate obstacles, and make high quality deliveries on an aggressive schedule \n \n \n  Work with data source teams, domain experts and data analysts to define data cleansing and data enrichment requirements \n  Stay up to date with industry standards and technological advancements that will improve the quality, productivity and performance of your work. \n  Provide support in a DevOps environment to monitor jobs and overall system performance. \n \n  Qualifications: \n \n  Bachelor's degree in computer science, engineering, mathematics, or a related technical discipline \n \n \n  Advanced degree (PhD) in Machine Learning, Data Science, AI, Computer Science, Computer Engineering, Electrical Engineering, Physics, Statistics, Applied Math or other quantitative fields \n  3-5 years working experience in data science/predictive analytics roles \n  Proven track record in modifying and applying advanced algorithms to address practical problems \n  Strong, hands-on technical familiarity with AWS ML technologies and tools \n  Significant experience in agile software development & continuous integration + continuous deployment methodologies along with supporting tools such as Git, Jira \n \n \n  Strong skill in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy \n \n  Nice to have: \n \n  Experience with Terraform, AWS CloudFormation or other infrastructure as code tools \n \n  What you will get:  We are a growing organization that thrives on delivering trusted financial services to help our clients succeed. Joining us will allow you to: \n \n  Work in a dynamic, collaborative, progressive, and high-performing team \n  Opportunities to do challenging work and grow \n  Make a difference and lasting impact \n \n   \n   \n 4cufd9T4No", "cleaned_desc": "  Bachelor's degree in computer science, engineering, mathematics, or a related technical discipline \n \n \n  Advanced degree (PhD) in Machine Learning, Data Science, AI, Computer Science, Computer Engineering, Electrical Engineering, Physics, Statistics, Applied Math or other quantitative fields \n  3-5 years working experience in data science/predictive analytics roles \n  Proven track record in modifying and applying advanced algorithms to address practical problems \n  Strong, hands-on technical familiarity with AWS ML technologies and tools \n  Significant experience in agile software development & continuous integration + continuous deployment methodologies along with supporting tools such as Git, Jira   \n \n  Strong skill in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy \n \n  Nice to have: \n \n  Experience with Terraform, AWS CloudFormation or other infrastructure as code tools \n ", "techs": ["bachelor's degree in computer science", "engineering", "mathematics", "or a related technical discipline", "advanced degree (phd) in machine learning", "data science", "ai", "computer science", "computer engineering", "electrical engineering", "physics", "statistics", "applied math or other quantitative fields", "aws ml technologies and tools", "git", "jira", "terraform", "aws cloudformation"]}, "24cea3c6b722df47": {"terms": ["data science"], "salary_min": 70.0, "salary_max": 75.0, "title": "Data Scientist - III", "company": "eTeam Inc.", "desc": "Title:  Data Scientist \n \n Location:  100% Remote \n \n Duration:  6 Months \n \n \n Responsibilities: \n  \" Support the various AI/Client models that need to be deployed to production \n \" Troubleshoot various activities and rectify any problems that arise in the end-to-end model pipeline \n \" Test and validate AI Models. Deploy and manage models throughout the end to end lifecycle. \n \" Industrialize the model pipeline which includes Testing & validation of the model pipeline \n \" Be part of the requirements for new enhancements in model/solution \n \" Propose new ideas/solutions that can be helpful for the project overall \n \" Analyze and understand problems and issues to convert these insights into system requirements \n \" Build scalable and high performance Machine Learning and Data Mining algorithms \n \n \n MUST HAVE SKILLS (Most Important):  Python, PySpark, SQL, GCP \n \n \n DESIRED SKILLS: \n  Deep Learning, Neural Networks \n \n \n EDUCATION/CERTIFICATIONS: \n  BS", "cleaned_desc": " \" Build scalable and high performance Machine Learning and Data Mining algorithms \n \n \n MUST HAVE SKILLS (Most Important):  Python, PySpark, SQL, GCP \n ", "techs": ["python", "pyspark", "sql", "gcp"]}, "63267dabd9331b8c": {"terms": ["data science"], "salary_min": 52100.0, "salary_max": 119000.0, "title": "Clinical Research Data Scientist and Curator", "company": "Booz Allen Hamilton", "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Bethesda,MD,US \n         \n \n \n \n         Remote Work: \n         \n \n         Yes \n         \n \n \n \n         Job Number: \n         \n \n         R0182778\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Clinical Research Data Scientist and Curator\n           Key Role:  Apply analytics and data scientist knowledge and consulting expertise, coupled with an original approach to work. Help clients and stakeholders make sense of their data and encourage actionable results. Work on health projects using tools such as R, SAS, Python, and Excel, to curate and analyze the data. \n \n  Basic Qualifications: \n \n  2+ years of experience as a data researcher, data engineer, or curator with health research data \n  Experience with data management, data cleaning, or data entry \n  Knowledge of informed consent process and forms, data use limitations, data use agreements, and data collection procedures and case report forms \n  Ability to quickly connect disparate information and be highly detail-oriented \n  Bachelor's degree \n \n \n  Additional Qualifications: \n \n  Experience with R, SAS, Python, Excel, JupyterLab, Jupyter Notebook, and GitHub \n  Experience generating metadata and annotations \n  Experience with de-identification methods and techniques for PII and PHI, and data sharing best practices \n  Experience with data quality and data standards such as FHIR \n  Experience with data repositories such as dbGaP and Sequence Read Archive (SRA) \n  Experience analyzing data governance policies and procedures \n  Knowledge of Common Data Elements (CDEs) and data harmonization techniques \n \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $52,100.00 to $119,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.", "cleaned_desc": " \n \n         Clinical Research Data Scientist and Curator\n           Key Role:  Apply analytics and data scientist knowledge and consulting expertise, coupled with an original approach to work. Help clients and stakeholders make sense of their data and encourage actionable results. Work on health projects using tools such as R, SAS, Python, and Excel, to curate and analyze the data. \n \n  Basic Qualifications: \n \n  2+ years of experience as a data researcher, data engineer, or curator with health research data \n  Experience with data management, data cleaning, or data entry \n  Knowledge of informed consent process and forms, data use limitations, data use agreements, and data collection procedures and case report forms \n  Ability to quickly connect disparate information and be highly detail-oriented \n  Bachelor's degree \n \n \n  Additional Qualifications: \n ", "techs": ["r", "sas", "python", "excel"]}, "b654303e92485149": {"terms": ["data science"], "salary_min": 103956.51, "salary_max": 131632.11, "title": "Data Scientist", "company": "Zilliant", "desc": "Zilliant powers intelligent B2B commerce with our industry-leading price optimization and sales guidance software. Our data science, cloud-native software, and passion for customer success deliver the highest ROI, fastest time to value, and highest customer satisfaction. If you\u2019re ready to make an impact at a growing company that values the time, input, and effort of each of its employees, we\u2019re eager to connect with you! Zilliant is looking for a Data Scientist to join our team. \n  As a Data Scientist, you will be responsible for creating and maintaining advanced scientific models that fuel our core products, as well as acting as a Pricing Science expert to advise Zilliant customers. You will be part of the Services department and you will report to the Director of Science. \n  What You\u2019ll Do: \n \n  Examine and interpret data to extract information and insights to design, build, and tune Zilliant advanced scientific models. \n  Participate in exploratory data analysis, statistical analysis, data quality analysis, data density analysis, and reporting. \n  Identify, analyze and propose solutions to both simple and complex customers science problems. \n  Perform all types of data manipulations such as data cleansing, data preparation, data transformations to serve downstream models. \n  Produce both functional and technical documentation for implementations of Zilliant scientific models, with a special focus on customization. \n  Report data insights and model results to senior stakeholders and provide business recommendations. \n \n  Who You Are: \n \n  A self-starter: you can align, adapt, and manage changing requirements. \n  Analytically minded: you like breaking down problems and looking through data to find patterns, trends, and outliers. \n  An avid, ongoing learning: you keep up to date with the latest trends in your field and are always on the lookout for new and exciting ways to improve your efficiency. \n  A clear communicator: you understand business needs, break them up into technical requirements; and you can explain technical and complex science in simple terms to senior stakeholders \n \n  What You\u2019ll Need: \n \n  Bachelor\u2019s or Master\u2019s Degree in Computer Science, Mathematics, Statistics, or related STEM field (or equivalent working experience) \n  3+ years' experience with SQL (T-SQL) and Python or other common analytical programming languages \n  3+ years' experience with Business Intelligence tools such as Tableau, PowerBI, or equivalent \n  Experience with predictive modelling such as classification and regression machine learning \n  Experience with pricing strategies such as cost-plus pricing, value-based pricing, penetrating pricing, dynamic pricing, bundling pricing nice to have \n  Experience in distribution, manufacturing, commodity, or B2B SaaS nice to have \n \n  What You\u2019ll Enjoy: \n \n  Full benefits package including medical, dental, and 401k plans with a company match \n  Generous Paid Time Off (PTO) policy to ensure a solid work/life balance \n  Comprehensive parental leave to provide time to bond with new family members \n  Remote or Hybrid work schedule, depending on team and personal preferences \n  The financial and strategic backing of Madison Dearborn Partners (MDP) \n \n  Zilliant is a proud Equal Opportunity Employer (EOE) and provides an environment of diversity, equality, and inclusion (DEI) to all employees and applicants, regardless of a person\u2019s age, race, color, physical or mental disability, genetic information, gender, gender identity or expression, marital status, medical condition, ancestry, military or veteran status, national origin, religion, religious creed, sex, sexual orientation, or any other protected status under federal, state, or local law. \n   \n aVA75JX2oE", "cleaned_desc": "  3+ years' experience with SQL (T-SQL) and Python or other common analytical programming languages \n  3+ years' experience with Business Intelligence tools such as Tableau, PowerBI, or equivalent \n  Experience with predictive modelling such as classification and regression machine learning \n  Experience with pricing strategies such as cost-plus pricing, value-based pricing, penetrating pricing, dynamic pricing, bundling pricing nice to have \n  Experience in distribution, manufacturing, commodity, or B2B SaaS nice to have \n \n  What You\u2019ll Enjoy: ", "techs": ["sql (t-sql)", "python", "tableau", "powerbi"]}, "4ea47e2ab8ce0245": {"terms": ["data science"], "salary_min": 103956.51, "salary_max": 131632.11, "title": "Data Scientist", "company": "Zilliant", "desc": "Remote \n   \n \n   Full Time \n   \n \n   Science & Applications \n   \n \n   Mid Level\n   \n \n \n \n \n \n Zilliant powers intelligent B2B commerce with our industry-leading price optimization and sales guidance software. Our data science, cloud-native software, and passion for customer success deliver the highest ROI, fastest time to value, and highest customer satisfaction. If you\u2019re ready to make an impact at a growing company that values the time, input, and effort of each of its employees, we\u2019re eager to connect with you! Zilliant is looking for a Data Scientist to join our team. \n  As a Data Scientist, you will be responsible for creating and maintaining advanced scientific models that fuel our core products, as well as acting as a Pricing Science expert to advise Zilliant customers. You will be part of the Services department and you will report to the Director of Science. \n  What You\u2019ll Do: \n \n  Examine and interpret data to extract information and insights to design, build, and tune Zilliant advanced scientific models. \n  Participate in exploratory data analysis, statistical analysis, data quality analysis, data density analysis, and reporting. \n  Identify, analyze and propose solutions to both simple and complex customers science problems. \n  Perform all types of data manipulations such as data cleansing, data preparation, data transformations to serve downstream models. \n  Produce both functional and technical documentation for implementations of Zilliant scientific models, with a special focus on customization. \n  Report data insights and model results to senior stakeholders and provide business recommendations. \n \n  Who You Are: \n \n  A self-starter: you can align, adapt, and manage changing requirements. \n  Analytically minded: you like breaking down problems and looking through data to find patterns, trends, and outliers. \n  An avid, ongoing learning: you keep up to date with the latest trends in your field and are always on the lookout for new and exciting ways to improve your efficiency. \n  A clear communicator: you understand business needs, break them up into technical requirements; and you can explain technical and complex science in simple terms to senior stakeholders \n \n  What You\u2019ll Need: \n \n  Bachelor\u2019s or Master\u2019s Degree in Computer Science, Mathematics, Statistics, or related STEM field (or equivalent working experience) \n  3+ years' experience with SQL (T-SQL) and Python or other common analytical programming languages \n  3+ years' experience with Business Intelligence tools such as Tableau, PowerBI, or equivalent \n  Experience with predictive modelling such as classification and regression machine learning \n  Experience with pricing strategies such as cost-plus pricing, value-based pricing, penetrating pricing, dynamic pricing, bundling pricing nice to have \n  Experience in distribution, manufacturing, commodity, or B2B SaaS nice to have \n \n  What You\u2019ll Enjoy: \n \n  Full benefits package including medical, dental, and 401k plans with a company match \n  Generous Paid Time Off (PTO) policy to ensure a solid work/life balance \n  Comprehensive parental leave to provide time to bond with new family members \n  Remote or Hybrid work schedule, depending on team and personal preferences \n  The financial and strategic backing of Madison Dearborn Partners (MDP) \n \n  Zilliant is a proud Equal Opportunity Employer (EOE) and provides an environment of diversity, equality, and inclusion (DEI) to all employees and applicants, regardless of a person\u2019s age, race, color, physical or mental disability, genetic information, gender, gender identity or expression, marital status, medical condition, ancestry, military or veteran status, national origin, religion, religious creed, sex, sexual orientation, or any other protected status under federal, state, or local law.", "cleaned_desc": "  Examine and interpret data to extract information and insights to design, build, and tune Zilliant advanced scientific models. \n  Participate in exploratory data analysis, statistical analysis, data quality analysis, data density analysis, and reporting. \n  Identify, analyze and propose solutions to both simple and complex customers science problems. \n  Perform all types of data manipulations such as data cleansing, data preparation, data transformations to serve downstream models. \n  Produce both functional and technical documentation for implementations of Zilliant scientific models, with a special focus on customization. \n  Report data insights and model results to senior stakeholders and provide business recommendations. \n \n  Who You Are: \n \n  A self-starter: you can align, adapt, and manage changing requirements.    Analytically minded: you like breaking down problems and looking through data to find patterns, trends, and outliers. \n  An avid, ongoing learning: you keep up to date with the latest trends in your field and are always on the lookout for new and exciting ways to improve your efficiency. \n  A clear communicator: you understand business needs, break them up into technical requirements; and you can explain technical and complex science in simple terms to senior stakeholders \n \n  What You\u2019ll Need: \n \n  Bachelor\u2019s or Master\u2019s Degree in Computer Science, Mathematics, Statistics, or related STEM field (or equivalent working experience) \n  3+ years' experience with SQL (T-SQL) and Python or other common analytical programming languages \n  3+ years' experience with Business Intelligence tools such as Tableau, PowerBI, or equivalent \n  Experience with predictive modelling such as classification and regression machine learning ", "techs": ["zilliant advanced scientific models", "exploratory data analysis", "statistical analysis", "data quality analysis", "data density analysis", "data cleansing", "data preparation", "data transformations", "functional documentation", "technical documentation", "customization", "business recommendations", "sql", "t-sql", "python", "business intelligence tools", "tableau", "powerbi", "predictive modeling", "classification machine learning", "regression machine learning."]}, "da77046826dd1ee6": {"terms": ["data science"], "salary_min": 60000.0, "salary_max": 75000.0, "title": "Data Scientist", "company": "EXL Services", "desc": "Company Overview and Culture \n \n EXL (NASDAQ:  EXLS) is a global analytics and digital solutions company that partners with clients to improve business outcomes and unlock growth. Bringing together deep domain expertise with robust data, powerful analytics, cloud, and AI, we create agile, scalable solutions and execute complex operations for the world\u2019s leading corporations in industries including insurance, healthcare, banking and financial services, media, and retail, among others. Focused on creating value from data for driving faster decision-making and transforming operating models, EXL was founded on the core values of innovation, collaboration, excellence, integrity and respect. Headquartered in New York, our team is over 40,000 strong, with more than 50 offices spanning six continents. For information, visit www.exlservice.com. \n \n  For the past 20 years, EXL has worked as a strategic partner and won awards in its approach to helping its clients solve business challenges such as digital transformation, improving customer experience, streamlining business operations, taking products to market faster, improving corporate finance, building models to become compliant more quickly with new regulations, turning volumes of data into business opportunities, creating new channels for growth and better adapting to change. The business operates within four business units: Insurance, Health, Analytics, and Emerging businesses. \n \n  About EXL Health \n We leverage Human Ingenuity and domain expertise to help clients improve outcomes, optimize revenue and maximize profitability across the healthcare ecosystem. Technology, data and analytics are at the heart of our solutions. We collaborate closely with clients to transform how care is delivered, managed and paid. \n \n  EXL Health combines deep domain expertise with analytic insights and technology-enabled services to transform how care is delivered, managed, and paid. Leveraging Human Ingenuity, we collaborate with our clients to solve complex problems and enhance their performance with nimble, scalable solutions. With data on more than 260 million lives, we work with hundreds of organizations across the healthcare ecosystem. \n \n  We help payers improve member care quality and network performance, manage population risk, and optimize revenue while decreasing administrative waste and reducing health claim expenditures. We help Pharmacy Benefit Managers (PBMs) manage member drug benefits and reduce drug spending while maintaining quality. We help provider organizations proactively manage risk, improve outcomes, and optimize network performance. We provide Life Sciences companies with enriched data, insights through advanced analytics and data visualization tools to get the right treatment to the right patient at the right time. \n \n  Data Scientist \n \n \n At least 5 years of experience as a data scientist with expertise in Deep Learning, Hadoop, Hive and SQL, who can drive adoption and not pick up skill on the job. \n Strong proficiency in programming language Python. \n Hands-on experience in automating data science models and job scheduling. \n Hands-on for building the models and solid knowledge on Statistics. \n In-depth knowledge in Deep Learning, Time Series forecasting, Regression Techniques, Clustering and data filtering techniques. \n Ability to build relevant impactful visuals for the business stakeholders. \n Improving data governance and quality, increasing the reliability of data. \n Proven skills in translating analytics output to actionable recommendations. \n Strong verbal and written communication skills. \n Self-starter and independent worker. \n Capable of applying judgment to plan and execute your tasks. \n  Minimum bachelor\u2019s degree from a recognized university in Computer Science, Engineering or equivalent. \n \n  EEO/Minorities/Females/Vets/Disabilities \n \n \n Base Salary Range Disclaimer:  The base salary range represents the low and high end of the EXL base salary range for this position. Actual salaries will vary depending on factors including but not limited to: location and experience. The base salary range listed is just one component of EXL's total compensation package for employees. Other rewards may include bonuses, as well as a Paid Time Off policy, and many region specific benefits. \n \n  Please also note that the data shared through the job application will be stored and processed by EXL in accordance with the EXL Privacy Policy. \n \n  Application & Interview Impersonation Warning \u2013 Purposely impersonating another individual when applying and / or participating in an interview in order to obtain employment with EXL Service Holdings, Inc. (the \u201cCompany\u201d) for yourself or for the other individual is a crime. We have implemented measures to deter and to uncover such unlawful conduct. If the Company identifies such fraudulent conduct, it will result in, as applicable, the application being rejected, an offer (if made) being rescinded, or termination of employment as well as possible legal action against the impersonator(s). \n \n  EXL may use artificial intelligence to create insights on how your candidate information matches the requirements of the job for which you applied. While AI may be used in the recruiting process, all final decisions in the recruiting and hiring process will be taken by the recruiting and hiring teams after considering a candidate\u2019s full profile. As a candidate, you can choose to opt out of this artificial intelligence screening process. Your decision to opt out will not negatively impact your opportunity for employment with EXL.", "cleaned_desc": " \n \n At least 5 years of experience as a data scientist with expertise in Deep Learning, Hadoop, Hive and SQL, who can drive adoption and not pick up skill on the job. \n Strong proficiency in programming language Python. \n Hands-on experience in automating data science models and job scheduling. \n Hands-on for building the models and solid knowledge on Statistics. \n In-depth knowledge in Deep Learning, Time Series forecasting, Regression Techniques, Clustering and data filtering techniques. ", "techs": ["deep learning", "hadoop", "hive", "sql", "python"]}, "314e79551a1c2cc0": {"terms": ["data science", "machine learning engineer"], "salary_min": 100000.0, "salary_max": 130000.0, "title": "Biomedical Data Scientist", "company": "Cognoa", "desc": "Are you interested in shaping the future of digital behavioral health? \n Cognoa is a pediatric behavioral health company developing digital diagnostic and therapeutic products with the goals of enabling earlier and more equitable access to care and improving the lives and outcomes of children and families living with behavioral health conditions, starting with autism. \n Digital medicine is a relatively new healthcare and business paradigm. Our team brings together experts in the fields of AI, technology, clinical drug development and commercialization. This new configuration of skills and experiences has led to exciting opportunities and has also generated unique and interesting challenges. \n Our headquarters are located in Palo Alto, CA. All positions are hybrid with regional offices located throughout the United States. \n \n We are seeking a Data Scientist with expertise in machine learning, Python programming, and relational databases to contribute to our mission of creating exceptional products for pediatric health. As a member of our data science team, you will work closely with cross-functional teams to analyze complex healthcare data, develop machine learning models, and drive data-driven decision-making. \n \n Responsibilities \n \n Data Analysis: Collect, clean, and preprocess healthcare data, ensuring data quality and consistency for analysis. Extract insights and actionable recommendations from data to improve pediatric healthcare. \n  Machine Learning: Develop and implement machine learning models to solve critical problems in pediatric health, such as disease prediction, treatment optimization, and outcome analysis. \n  Data Modeling: Utilize advanced statistical and machine learning techniques to build predictive models, clustering algorithms, and classification systems. Optimize models for scalability, accuracy, and interpretability. \n  Python Development: Write clean, efficient, and maintainable Python code to implement data analysis and machine learning solutions. Leverage Python libraries and frameworks for data manipulation, analysis, and model deployment. \n  Relational Databases: Work with relational databases (e.g., SQL) to extract and transform data for analysis. Create, modify, and optimize database queries for specific data science tasks. \n  Collaboration: Collaborate with cross-functional teams, including clinicians, engineers, and product managers, to understand business objectives and translate them into data-driven strategies and actionable insights. \n  Model Evaluation: Develop and execute thorough model evaluation procedures, including validation, performance metrics, and interpretability assessments. \n  Data Visualization: Present results and insights through data visualization tools and reports, making complex data accessible and understandable to non-technical stakeholders. \n \n Qualifications \n \n Bachelor's or higher degree in Data Science, Computer Science, Statistics, or a related field. \n  Advanced degree (Master's or Ph.D.) in a relevant field preferred. \n  2 \u2013 4 year's experience in biomedical data science required. \n  Proven experience in machine learning and data analysis, especially in a healthcare or medical setting. \n  Proficiency in Python and experience with machine learning libraries such as TensorFlow, Keras, scikit-learn, and pandas. \n  Strong understanding of relational databases and SQL for data retrieval and manipulation. \n  Excellent problem-solving and analytical skills. \n  Effective communication and teamwork abilities. \n  A strong desire to make a positive impact on pediatric health through data-driven approaches. \n  Must be able to exercise judgment and independently determine and take appropriate action where precedent may not exist. \n  Must be able to develop solutions to a wide range of highly complex problems, which require an in-depth degree of ingenuity, creativity, and innovation. \n  Maturity of temperament and emotional intelligence; able to render a calm stabilizing presence without compromising influence and authority. \n  A strategic thinker, inspiring leader, effective manager, and team player. \n  Collaborative and with the ability to create opportunities that facilitate buy-in and teamwork. \n  Preferred Qualifications: \n \n  Experience working with electronic health records (EHR) or clinical data. \n  Knowledge of healthcare regulations and compliance (e.g., HIPAA). \n  Experience with cloud platforms (e.g., AWS, GCP, Azure). \n \n \n Cognoa is an equal opportunity employer and does not discriminate in employment on the basis of race, color, religion, sex (including pregnancy and gender identity), national origin, political affiliation, sexual orientation, marital status, disability, genetic information, age, membership in an employee  organization, retaliation, parental status, military service, or other non-merit factor.", "cleaned_desc": " \n Data Analysis: Collect, clean, and preprocess healthcare data, ensuring data quality and consistency for analysis. Extract insights and actionable recommendations from data to improve pediatric healthcare. \n  Machine Learning: Develop and implement machine learning models to solve critical problems in pediatric health, such as disease prediction, treatment optimization, and outcome analysis. \n  Data Modeling: Utilize advanced statistical and machine learning techniques to build predictive models, clustering algorithms, and classification systems. Optimize models for scalability, accuracy, and interpretability. \n  Python Development: Write clean, efficient, and maintainable Python code to implement data analysis and machine learning solutions. Leverage Python libraries and frameworks for data manipulation, analysis, and model deployment. \n  Relational Databases: Work with relational databases (e.g., SQL) to extract and transform data for analysis. Create, modify, and optimize database queries for specific data science tasks. \n  Collaboration: Collaborate with cross-functional teams, including clinicians, engineers, and product managers, to understand business objectives and translate them into data-driven strategies and actionable insights. \n  Model Evaluation: Develop and execute thorough model evaluation procedures, including validation, performance metrics, and interpretability assessments.    Data Visualization: Present results and insights through data visualization tools and reports, making complex data accessible and understandable to non-technical stakeholders. \n \n Qualifications \n \n Bachelor's or higher degree in Data Science, Computer Science, Statistics, or a related field. \n  Advanced degree (Master's or Ph.D.) in a relevant field preferred. \n  2 \u2013 4 year's experience in biomedical data science required. \n  Proven experience in machine learning and data analysis, especially in a healthcare or medical setting.    Proficiency in Python and experience with machine learning libraries such as TensorFlow, Keras, scikit-learn, and pandas. \n  Strong understanding of relational databases and SQL for data retrieval and manipulation. \n  Excellent problem-solving and analytical skills. \n  Effective communication and teamwork abilities. \n  A strong desire to make a positive impact on pediatric health through data-driven approaches. \n  Must be able to exercise judgment and independently determine and take appropriate action where precedent may not exist. \n  Must be able to develop solutions to a wide range of highly complex problems, which require an in-depth degree of ingenuity, creativity, and innovation. \n  Maturity of temperament and emotional intelligence; able to render a calm stabilizing presence without compromising influence and authority.    A strategic thinker, inspiring leader, effective manager, and team player. \n  Collaborative and with the ability to create opportunities that facilitate buy-in and teamwork. \n  Preferred Qualifications: \n \n  Experience working with electronic health records (EHR) or clinical data. \n  Knowledge of healthcare regulations and compliance (e.g., HIPAA). \n  Experience with cloud platforms (e.g., AWS, GCP, Azure). \n ", "techs": ["collect", "clean", "and preprocess healthcare data", "machine learning", "data modeling", "python development", "relational databases", "collaboration", "model evaluation", "data visualization", "data science", "computer science", "statistics", "python", "tensorflow", "keras", "scikit-learn", "pandas", "sql", "biomedical data science", "healthcare", "medical setting", "electronic health records (ehr)", "clinical data", "healthcare regulations", "hipaa", "cloud platforms", "aws", "gcp", "azure."]}, "5e2a917500c2b7d4": {"terms": ["data science", "data analyst"], "salary_min": 104369.516, "salary_max": 132155.06, "title": "Senior Data Analyst, Data Science - Verity Tracking", "company": "Gevo, Inc.", "desc": "About the Role \n \n  We are looking for a team member with excellent programming, data engineering, and analytical skills for the position of Senior Data Analyst, Data Science. To be successful in this role you will:  \n \n Design scalable data science programs to help capture, organize, and analyze data  \n Write clean, testable, and modularized code  \n Build automatic data science workflows and analysis of data science life cycle (including model deployment and monitoring)  \n Aggregate, clean, and study data while identifying trends and insights to solve significant near- and long-term business problems  \n Clean data and automate basic data characterization processes and anomaly detection algorithms  \n Identify opportunities to enhance the flow and analysis of multiple different data sets into and across the company  \n Transparently communicate priorities, obstacles, and progress on a regular basis to the Product Analytics Lead  Comfortably lead technical data science operations while following agile principles \n  \n \n Who you are:   \n \n Degree in a quantitative field such as data science, data analytics, or statistics; with applied experience in technical data science implementation (programming)  \n Comfortable in data validation and quality assurance methods, including validating and verifying GIS-type data  \n Logic-driven critical thinker hungry for precision and increasing understanding and confidence in data  \n Proficient in common data science programming languages such as Python or R and proficient with data management systems  \n Passionate about environmental sustainability with domain knowledge in agricultural practices and industrial processes  \n Experienced in building trusted business relationships  \n Strong written and verbal communicator  \n \n Education:  \n \n Bachelor's (Required) in a quantitative field such as data science, computer science, physics, engineering, applied mathematics, or statistics.  \n MS Analytics or similar degree (Preferred)  \n \n Experience:  \n \n Data Engineering Knowledge (SQL or similar): 3+ years (Required)  \n Data analytics/science: 3+ years (Required)  \n Programming Knowledge (R or Python): 3+ years (Required)  \n Data science program design: 2+ years (Preferred)  \n \n Who We Are \n \n We are People First  \n We are Mission-Focused  \n We are Agile  \n We are Innovators \n \n Gevo  is a next generation, \u201clow-carbon\u201d fuel company focused on the development and commercialization of renewable alternatives to petroleum-based products. Low-carbon fuels reduce the carbon intensity, or the level of greenhouse gas emissions, compared to standard fossil-based fuels across their lifecycle. The most common low-carbon fuels are renewable fuels. Gevo is focused on the development and production of mainstream fuels like gasoline and jet fuel using renewable feedstocks that have the potential to lower greenhouse gas emissions at a meaningful scale and enhance agricultural production, including food and other related products. \n  What Gevo Offers You   \n \n Free health, dental, vision, life and disability insurance for employee and family  \n 21 days of vacation and sick leave plus 11 paid holidays  \n 401k contribution plan with match in Gevo stock \n Annual incentive plan, based on Company performance  \n Paid community service time  \n \n \n Be part of a smart, high performing, passionate team  \n Work-from-home stipend, if remote \n \n \n  Commitment to Diversity and Inclusion   \n Gevo, Inc. is an equal opportunity employer that is committed to diversity and inclusion in the workplace. We prohibit discrimination and harassment of any kind based on race, color, sex, religion, sexual orientation, national origin, disability, genetic information, pregnancy, or any other protected characteristic as outlined by federal, state, or local laws. \n  Physical Requirements \n \n Light work that includes moving objects up to 20 pounds \n Remaining in a stationary position, often standing or sitting for prolonged periods \n Communicating with others to exchange information", "cleaned_desc": "About the Role \n \n  We are looking for a team member with excellent programming, data engineering, and analytical skills for the position of Senior Data Analyst, Data Science. To be successful in this role you will:  \n \n Design scalable data science programs to help capture, organize, and analyze data  \n Write clean, testable, and modularized code  \n Build automatic data science workflows and analysis of data science life cycle (including model deployment and monitoring)  \n Aggregate, clean, and study data while identifying trends and insights to solve significant near- and long-term business problems  \n Clean data and automate basic data characterization processes and anomaly detection algorithms  \n Identify opportunities to enhance the flow and analysis of multiple different data sets into and across the company  \n Transparently communicate priorities, obstacles, and progress on a regular basis to the Product Analytics Lead  Comfortably lead technical data science operations while following agile principles \n    \n Who you are:   \n \n Degree in a quantitative field such as data science, data analytics, or statistics; with applied experience in technical data science implementation (programming)  \n Comfortable in data validation and quality assurance methods, including validating and verifying GIS-type data  \n Logic-driven critical thinker hungry for precision and increasing understanding and confidence in data  \n Proficient in common data science programming languages such as Python or R and proficient with data management systems  \n Passionate about environmental sustainability with domain knowledge in agricultural practices and industrial processes  \n Experienced in building trusted business relationships  \n Strong written and verbal communicator  \n \n Education:  ", "techs": ["none"]}, "cfedf6ee02e29518": {"terms": ["data science", "machine learning engineer"], "salary_min": 100000.0, "salary_max": 145000.0, "title": "Data Scientist", "company": "Trane Technologies", "desc": "At Trane TechnologiesTM and through our businesses including Trane\u00ae and Thermo King\u00ae, we create innovative climate solutions for buildings, homes, and transportation that challenge what\u2019s possible for a sustainable world. We're a team that dares to look at the world's challenges and see impactful possibilities. We believe in a better future when we uplift others and enable our people to thrive at work and at home. We boldly go. \n  The Market & Customer Insights team is growing our capability to provide data-driven insights to the business through a combination of ad-hoc analyses, broad and sustainable data and analytics solutions, and cross-functional collaboration. To meet these ambitious goals, we are looking for a  Data Scientist  to join the team. \n  You will be responsible for working with the team to develop advanced analytics models to help the business leverage data to identify prospects, forecast the future of the market and run multivariate analysis. The main focus will be to help the team with an understanding of Trane\u2019s business, our customers, our competition, and our place in the market through data. This person will take the lead on ensuring the team is leveraging advanced analytics / modeling wherever possible. In addition, you will work with cross-functional partners to share knowledge, drive analytics standards and best practices, and accelerate capabilities across Trane Commercial. This is a Remote position. \n  Key Competencies \n \n Technical Excellence\u2014comfortable around very large data sets and utilizing machine learning tools/languages appropriately. \n Machine Learning Expertise \u2013 strong communication skills to fully understand the business question to be answered. Excellent data exploration techniques to determine if the data available is sufficient to answer the business question. Superior technical capability to identify and develop the right Machine Learning model for the problem at hand. \n Cross Functional Collaboration \u2013 within analytics teams, the business and IT. \n Innate Curiosity \u2013 constant drive to learn more, ask questions, seek better outcomes. \n \n Responsibilities: \n \n Engage with business to strategically identify and scope out new machine learning opportunities.  \n Evaluate data and business problems to determine the suitability of data science approach.  \n Research and devise innovative statistical models. \n Deliver Machine Learning projects from end-to-end: \n    \n Identify the required data sets and appropriate modeling approaches to address business problems. \n Partner with data engineers to access the data pipeline.  \n Own feature engineering that may span multiple, complex data sources. \n Responsible for developing multiple models using random forest, XG Boost, K-Means clustering and other state-of-the art methods.  \n Test and compare model results using statistical tools to select the best model. \n Lead discussions around model outcomes with business SMEs to validate predictions and explain results.  \n Recommend model refresh schedule. Initially manage model monitoring once in production.  \n \n Advise and adhere to security protocol for different data sets.  \n Research and experiment with new technologies to keep the team on the cutting edge and leveraging the latest thinking in the machine learning space.  \n Operate in an agile fashion to deliver regular \u201cdemos\u201d to the customer. \n \n Qualifications: \n \n BS/BA degree in computer science, statistics, mathematics, MIS, engineering or similar.  \n 5+ years of experience in a hands-on data science role, additional years of experience in related analytics field a plus.  \n 3+ years of hands-on experience in developing analytical solutions using techniques such as machine learning, propensity matching, hypothesis testing and descriptive statistics. \n Proficiency with data mining, mathematics, and statistical analysis. \n Advanced pattern recognition and predictive modeling experience. \n Knowledge of machine learning platforms, and experience working with IT organizations.  \n Able to recognize and help guide the business to identify appropriate uses of ML. \n Experience with multiple models, and knowledge of when to apply each \u2013 clustering, classification, random forest, regression. \n Proficiency in programming languages such as SQL, Python (preferred) or R \n Experience with one or more: Jupyter Notebooks, PyCharm, Spark, GitHub, Sagemaker, and AWS, GCP, or other cloud-based environments. \n Experience with data visualization tools preferable \u2013 Tableau, Matplotlib, etc.  \n Excellent communication skills \u2013able to convey complex concepts to technical and business teams in a simple and understandable way. \n Agile experience a plus. \n \n What\u2019s in it for you: \n \n Benefits kick in day one! \n 6% 401K match, additional 2% core contribution = 8% overall match \n 3 weeks of vacation, plus site paid holidays \n Benefits*: Trane-Technologies-Benefits-Offered.pdf \n \n Base Pay Range: $100,000 - $145,000 \n  Disclaimer: This \"range\" could be a result of seniority, merit, geographic location where the work is performed, education, experience, travel requirements for the job, or because of a system the employer uses to measure earnings by quantity or quality of production (so, for example, positions that may not have traditional salary ranges). \n \n Benefits vary by region, business alignment, union involvement and employee status. \n \n  We offer competitive compensation and comprehensive benefits and programs. We are an equal opportunity employer; all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, pregnancy, age, marital status, disability, status as a protected veteran, or any legally protected status. \n   #LI-Remote", "cleaned_desc": " \n Engage with business to strategically identify and scope out new machine learning opportunities.  \n Evaluate data and business problems to determine the suitability of data science approach.  \n Research and devise innovative statistical models. \n Deliver Machine Learning projects from end-to-end: \n    \n Identify the required data sets and appropriate modeling approaches to address business problems. \n Partner with data engineers to access the data pipeline.  \n Own feature engineering that may span multiple, complex data sources. \n Responsible for developing multiple models using random forest, XG Boost, K-Means clustering and other state-of-the art methods.  \n Test and compare model results using statistical tools to select the best model.   Lead discussions around model outcomes with business SMEs to validate predictions and explain results.  \n Recommend model refresh schedule. Initially manage model monitoring once in production.  \n \n Advise and adhere to security protocol for different data sets.  \n Research and experiment with new technologies to keep the team on the cutting edge and leveraging the latest thinking in the machine learning space.  \n Operate in an agile fashion to deliver regular \u201cdemos\u201d to the customer. \n \n Qualifications: \n \n BS/BA degree in computer science, statistics, mathematics, MIS, engineering or similar.  \n 5+ years of experience in a hands-on data science role, additional years of experience in related analytics field a plus.    3+ years of hands-on experience in developing analytical solutions using techniques such as machine learning, propensity matching, hypothesis testing and descriptive statistics. \n Proficiency with data mining, mathematics, and statistical analysis. \n Advanced pattern recognition and predictive modeling experience. \n Knowledge of machine learning platforms, and experience working with IT organizations.  \n Able to recognize and help guide the business to identify appropriate uses of ML. \n Experience with multiple models, and knowledge of when to apply each \u2013 clustering, classification, random forest, regression. \n Proficiency in programming languages such as SQL, Python (preferred) or R \n Experience with one or more: Jupyter Notebooks, PyCharm, Spark, GitHub, Sagemaker, and AWS, GCP, or other cloud-based environments. \n Experience with data visualization tools preferable \u2013 Tableau, Matplotlib, etc.  \n Excellent communication skills \u2013able to convey complex concepts to technical and business teams in a simple and understandable way. \n Agile experience a plus. ", "techs": ["machine learning", "random forest", "xg boost", "k-means clustering", "statistical tools", "security protocol", "data mining", "mathematics", "statistical analysis", "pattern recognition", "predictive modeling", "machine learning platforms", "it organizations", "clustering", "classification", "regression", "sql", "python", "r", "jupyter notebooks", "pycharm", "spark", "github", "sagemaker", "aws", "gcp", "tableau", "matplotlib", "communication skills", "agile experience"]}, "9fca7ba2feba7459": {"terms": ["data science", "machine learning engineer"], "salary_min": 190000.0, "salary_max": 220000.0, "title": "Director of Data Science (Remote)", "company": "Huckleberry Labs", "desc": "About Huckleberry \n \n \n \n  Huckleberry\u2019s purpose is to create life-changing products and experiences through fresh, beautiful, human-centered technology that brings health, well-being, and a bit of magic to every family.\n  \n \n \n  We combine Data, AI, and Behavioural Science to build products that are at the cutting edge of tech today.\n  \n \n \n  The app has 4.9 stars, garnering rave reviews from people who call it \u201clife-changing\u201d and their \u201c#1 recommendation to parents\u201d.\n  \n \n \n  We are rapidly growing and building new products to enable every family to thrive.\n  \n \n \n  About the Role \n \n \n \n  As the Director of Data Science, you will collaborate across departments (including Product, Engineering, Marketing, Analytics, and domain experts) to create amazing features and products that leverage data, machine learning, and AI to impact the lives of families. The Director of Data Science is responsible for bringing technical solutions to challenges discovered through user research and unlocking new product opportunities made possible by recent advances in ML and AI.\n  \n \n \n  This role requires strong technical skills, an eye for detail, experience delivering high-quality digital products to millions of users, and an ability to drive projects forward. Join Huckleberry to be a key player in improving the day-to-day lives of families around the world.\n  \n \n \n  This role reports to the CTO and leads a small team of data scientists.\n  \n \n \n  Areas of Responsibility \n \n  Manage and lead the data science team covering machine learning, artificial intelligence, and predictive analytics \n  Collaborate with product managers, domain experts, and parents to translate complex problems into simple, magical, user focussed solutions \n  Work with business leaders and the team to define and execute our roadmap \n  Experiment and build new predictive and recommendation models that further personalize recommendations and improve efficacy \n  Leverage our unique dataset of families from more than 100 countries and diverse demographics to create solutions accessible to everyone for every situation \n  Translate high-level product requirements into detailed specifications for frontend, backend, and database and cloud engineers \n \n \n  Requirements \n \n  5+ years of experience using Python for machine learning in a commercial setting \n  3+ years of experience building AI-driven recommendation systems \n  2+ years of people management experience \n  M.S. or Ph. D. in a quantitative field such as Computer Science, Statistics, Physics, or a related field \n  Experience using AWS or GCP to create data pipelines, build new models, and deploying to mission-critical applications \n  Strong communication skills with an ability to communicate complex concepts to a variety of audiences at all levels of the organization \n  Proven track record using AI/ML to create new and unique products \n  Proactive, willing to try new things, and gets things done in a startup environment \n \n \n  Nice to have \n \n  Experience working on a consumer-facing product making advanced algorithms accessible to everyone \n  A passion for children and family wellness, with the understanding that every family is different, and one size does not fit all \n \n \n  Compensation and Benefits \n \n  Salary range $190,000 - $220,000 dependent on experience \n  Equity \n  Unlimited PTO \n  Health \n  Vision \n  Dental \n  FSA/DCFSA \n  Paid parental leave \n  401k match \n \n \n \n  Huckleberry Labs is an equal-opportunity employer that is committed to diversity and inclusion in the workplace. We prohibit discrimination and harassment of any kind based on race, color, sex, religion, sexual orientation, national origin, disability, genetic information, pregnancy, or any other protected characteristic as outlined by federal, state, or local laws.\n  \n \n \n  Huckleberry Labs makes hiring decisions based solely on qualifications, merit, and business needs at the time.", "cleaned_desc": "  5+ years of experience using Python for machine learning in a commercial setting \n  3+ years of experience building AI-driven recommendation systems \n  2+ years of people management experience \n  M.S. or Ph. D. in a quantitative field such as Computer Science, Statistics, Physics, or a related field \n  Experience using AWS or GCP to create data pipelines, build new models, and deploying to mission-critical applications \n  Strong communication skills with an ability to communicate complex concepts to a variety of audiences at all levels of the organization \n  Proven track record using AI/ML to create new and unique products \n  Proactive, willing to try new things, and gets things done in a startup environment \n \n \n  Nice to have \n \n  Experience working on a consumer-facing product making advanced algorithms accessible to everyone \n  A passion for children and family wellness, with the understanding that every family is different, and one size does not fit all \n \n ", "techs": ["python", "machine learning", "ai-driven recommendation systems", "people management", "aws", "gcp", "data pipelines", "complex concepts communication", "ai/ml", "consumer-facing product", "advanced algorithms", "children and family wellness"]}, "0944d4963e017b42": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Director Data Analytics", "company": "Sodexo", "desc": "Unit Description: \n   Sodexo is in search of a  Director, Data Analytics  to lead the execution of Segment Business Analytics roadmap and build support structures to achieve our objectives. This position will play a critical role in optimizing the operational and financial performance of our North America Healthcare business. They will assist in creating and operationalizing models that support organizational strategic objectives, as well as the development of effective tracking and analytics of key indicators to attain proactive and predictive insights, helping to improve both business and sales executive performance indicators. They will work closely with our leadership teams to identify opportunities, develop, and manage strategic initiatives and drive transformation. \n  *This is a virtual position & the person can reside anywhere in the US* \n \n  Key activities: \n \n  Spearhead the Data and Analytics function and align it with the segment strategic direction, setting ambitious goals and ensuring that the function's roadmap is broadly informed by key stakeholders, clearly communicated, and thoughtfully executed. \n  Create, manage, and improve the segment databases. \n  Lead the design, development, maintenance, growth, quality, analysis, and presentation of our datasets. \n  Evaluate and manage customer data, customer research, market conditions and competitor data. \n  Develop strategic data initiatives; this includes resourcing and prioritizing key initiatives as well as showcasing relevant data via data presentation and self-service platforms; some examples include go-to-market strategy, market share and sizing analysis, territory mapping, organization design planning, monitoring Customer Experience etc.  \n Work with stakeholders and business leaders to provide insights and analysis support to help them make critical decisions and identify areas of opportunity. \n  Based on analysis of data, create & manage forecast model tracking key indicator trends \n  Manage fielding, prioritizing, and delivering analytics requests, and fostering a data-driven culture by supporting other teams in the consumption and use of our data.  \n Support all NorAm segment specific commercial organization data and analytics needs.  \n \n Responsibilities: \n \n  Data Collection and Management \n \n  Gather and integrate data from multiple sources, including internal databases, CRM systems, and external sources. \n  Maintain and update databases, ensuring data accuracy, completeness, and reliability. \n \n  Data Analysis \n \n  Analyze data to identify trends, patterns, and anomalies. \n  Provide insights on sales performance metrics like quote achievement, conversion rates, average deal sizes, etc. \n  Use statistical methods to analyze data and produce actionable insights. \n \n  Reporting \n \n  Develop regular sales performance reports for leadership and sales teams. \n  Design and create data reports using visualization tools, making complex data more accessible, understandable, and usable through visuals and dashboards. \n  Transform raw data into meaningful and actionable business information. \n  Present findings to stakeholders through standard and ad hoc reports \n \n  Forecasting and Predictive Analysis \n \n  Utilize statistical methods to forecast future sales trends. \n  Help in setting realistic sales targets based on historical data and market analysis. \n  Develop models to predict future trends based on historical data. \n \n  Collaboration \n \n  Work closely with the sales team to understand their needs and provide data for sales pitches, strategies, and campaigns. \n  Liaise with the IT department to improve data collection and reporting systems. \n \n  Continuous Improvement \n \n  Recommend improvements in sales strategies based on the data-driven insights. \n  Stay updated with the latest trends, data analysis tools, techniques, and best practices. \n \n \n \n  Qualifications: \n \n  Bachelor\u2019s degree in data science, Statistics, Business, Finance, Operations, or comparable proven experience in related field \n  Previous experience in data analysis, strategic thinking, commercial mindset, and strong execution \n  Proficiency in data analysis tools like Excel, SQL, and data visualization tools like Tableau or PowerBI \n  Naturally curious and logical with strong analytical and problem-solving skills \n  Detail-oriented with a knack for spotting data anomalies and discrepancies \n  Able to work in a fast-paced environment and manage multiple tasks. \n \n \n  Agile with the ability to speak and relate to each business function. Can quickly come up to speed and understand support services sales, operations, HR, and all other areas. \n  Excellent communication skills, both verbal and written \n  Able to communicate complex data findings clearly to non-technical audiences. \n  Willing to be coached and mentored. \n \n \n  What We Offer: \n  \n   Sodexo offers fair and equitable compensation, partially determined by a candidate's education level or years of relevant experience. While the budgeted range for the position is posted, Sodexo salary offers are based on a candidate's specific criteria, like experience, skills, education and training.\n   Position Summary: \n  \n   Sodexo\u2019s is in search of a Director, Data Analytics to lead the execution of Segment Business Analytics roadmap and build support structures to achieve sustainable operations. The Director, Data Analytics will assist in creating and operationalizing models that support organizational strategic objectives, as well as the development of effective tracking and analytics of key indicators to attain proactive and predictive insights, helping to articulate offer value, client & patient experience and to improve performance indicators.\n  \n \n   Key activities:\n   \n \n Manage and improve the Segment strategic databases. \n Evaluate and manage customer data, customer research, market conditions and competitor data. \n Work with stakeholders to define business and systems requirements for new information technologies, particularly in the areas of BI, analytics, and data warehousing. \n Based on analysis of data, create & manage forecast model tracking key indicator trends. \n Oversee and facilitate management of unit segmentation. \n Facilitate strategic initiatives supporting market share/sizing analysis, territory mapping, organization design planning. \n Facilitate operational design for analytical models driving both operational and enabler metrics. \n Work as a lead architect to facilitate tracking, monitoring of key strategic initiatives such as Patient experience using Service Depot, EIC using Trakkar tools and formulate models to measure effectiveness. \n \n  Qualifications & Requirements: \n  \n   Basic Education Requirement - Bachelor\u2019s Degree or equivalent experience\n  \n \n   Basic Management Experience - 7 years\n  \n \n   Basic Functional Experience - 7 years of experience in compensation\n  \n \n \n  Sodexo is an EEO/AA/Minority/Female/Disability/Veteran employer.", "cleaned_desc": "  Gather and integrate data from multiple sources, including internal databases, CRM systems, and external sources. \n  Maintain and update databases, ensuring data accuracy, completeness, and reliability. \n \n  Data Analysis \n \n  Analyze data to identify trends, patterns, and anomalies. \n  Provide insights on sales performance metrics like quote achievement, conversion rates, average deal sizes, etc. \n  Use statistical methods to analyze data and produce actionable insights. \n \n  Reporting \n \n  Develop regular sales performance reports for leadership and sales teams. \n  Design and create data reports using visualization tools, making complex data more accessible, understandable, and usable through visuals and dashboards. \n  Transform raw data into meaningful and actionable business information. \n  Present findings to stakeholders through standard and ad hoc reports \n \n  Forecasting and Predictive Analysis \n \n  Utilize statistical methods to forecast future sales trends. \n  Help in setting realistic sales targets based on historical data and market analysis.    Develop models to predict future trends based on historical data. \n \n  Collaboration \n \n  Work closely with the sales team to understand their needs and provide data for sales pitches, strategies, and campaigns. \n  Liaise with the IT department to improve data collection and reporting systems. \n \n  Continuous Improvement \n \n  Recommend improvements in sales strategies based on the data-driven insights. \n  Stay updated with the latest trends, data analysis tools, techniques, and best practices. \n \n \n \n  Qualifications: \n \n  Bachelor\u2019s degree in data science, Statistics, Business, Finance, Operations, or comparable proven experience in related field \n  Previous experience in data analysis, strategic thinking, commercial mindset, and strong execution \n  Proficiency in data analysis tools like Excel, SQL, and data visualization tools like Tableau or PowerBI \n  Naturally curious and logical with strong analytical and problem-solving skills   \n Manage and improve the Segment strategic databases. \n Evaluate and manage customer data, customer research, market conditions and competitor data. \n Work with stakeholders to define business and systems requirements for new information technologies, particularly in the areas of BI, analytics, and data warehousing. \n Based on analysis of data, create & manage forecast model tracking key indicator trends. \n Oversee and facilitate management of unit segmentation. \n Facilitate strategic initiatives supporting market share/sizing analysis, territory mapping, organization design planning. \n Facilitate operational design for analytical models driving both operational and enabler metrics. \n Work as a lead architect to facilitate tracking, monitoring of key strategic initiatives such as Patient experience using Service Depot, EIC using Trakkar tools and formulate models to measure effectiveness. \n \n  Qualifications & Requirements: \n  \n   Basic Education Requirement - Bachelor\u2019s Degree or equivalent experience\n  \n \n   Basic Management Experience - 7 years\n  \n \n   Basic Functional Experience - 7 years of experience in compensation\n  ", "techs": ["excel", "sql", "tableau", "powerbi"]}, "43d07e3ab54dd648": {"terms": ["data science"], "salary_min": 115000.0, "salary_max": 160000.0, "title": "Assistant Vice President, Risk Analytics", "company": "Wedbush Securities", "desc": "Job Description: \n  Wedbush Securities is one of the largest securities firms and investment banks in the nation. We provide innovative financial solutions through our Wealth Management, Capital Markets, Futures and Advanced Clearing & Prime Services divisions. Headquartered in Los Angeles, California with over 100 offices and more than 80 correspondent offices, our commitment to providing relentless, customized service is the foundation of our consistent growth.  \n  Our Chicago office is hiring for an experienced Assistant Vice President, Risk Analytics to join our Risk and Credit Group for a 100% remote opportunity. The primary function of this role is to act as a Data Scientist for the Risk Management Department, and a Project Manager/Liaison for all related Risk systems and IT functions. You will need to design SQL queries and relational databases to carry out daily tasks and automate reports for the risk management department.  \n  Responsibilities will include, but are not limited to:  \n \n  Build, monitor, distribute risk reports and margin calculations \n  Design SQL query and relational databases to carry out daily tasks and automate reports \n  Create and Manage risk dashboards \n  Perform complex data analysis on account balances and positions across the firm \n  Manage ad hoc projects as requested by leadership \n  Be the system administrator and point of contact for various risk systems and tools \n  Present and explain analysis in a non-technical and accessible manner alongside data visualization \n  Perform other tasks and duties as required and assigned \n \n \n  Experience and Skills: \n \n  Bachelor\u2019s Degree from an accredited University, preferably in Computer Science, Data Science, or related field \n  Advanced proficiency in SQL and understanding of data access tools \n  5+ years\u2019 experience in Information Technology, preferably for a financial services firm \n  5+ years\u2019 experience in Data Analytics, Risk Analysis, or related role \n  Understanding of Equities, Options, and Margin is a plus \n  Must be detail oriented and maintain data integrity \n  Creative, solution-oriented mindset with the ability to handle pressure to meet deadlines \n  Able to work with minimal supervision, taking ownership of work and completing tasks in timely manner, while adapting rapidly to changing work environments, priorities and organizational needs \n  Ability to identify gaps in existing processes and gain efficiency through automation. \n  Experience working with multiple teams across different time zones \n \n \n  Job Benefits: \n  Wedbush Securities offers robust benefits to our colleagues.  \n \n Comprehensive medical, dental, and vision coverage with multiple health plan options for you and your family \n  Health Savings Account with company-sponsored contributions \n  Flexible Spending Accounts (FSA) traditional and dependent care \n  Pre-Tax Commuter Benefits \n  401(k) plan with discretionary, competitive company matching and profit-sharing contributions \n  Tuition reimbursement up to $5,250/year \n  3 weeks of Paid Time Off \n  2 weeks of Paid Sick Time (may vary by location) \n  10 Paid Holidays \n  Charitable Donation Matching Contributions \n  Paid Leave (Military, Jury Duty, Volunteer Time Off, Disability, etc.) \n  FINRA License Sponsorship \n  Travel & Employee Assistance and Employee Discount Programs \n \n  The reasonable estimate of the compensation range for this role has not been adjusted for the applicable geographic location. A reasonable estimate of the current hiring range is $115,000-$160,000. Colleagues may be eligible for additional, discretionary incentive compensation based on the individual and the firm's performance. At Wedbush, it is not typical for an individual to be hired at, or near, the top of the range for their role. Decisions regarding compensation are determined on a case-by-case basis and are dependent on a variety of factors including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs.  \n Wedbush Securities (WS) is proud to be an Equal Employment Opportunity employer. WS does not discriminate based on race, religion, color, creed, sex, sexual orientation, gender, gender identity or expression, national origin, ancestry, citizenship status, registered domestic partner status, uniform service member status, marital status, pregnancy, age, medical condition, disability, genetic information, family care or medical leave status, or any other consideration made unlawful by applicable federal, state, or local laws, or on the basis that an applicant or Colleague is perceived to have these characteristics or is associated with someone who is perceived to have these characteristics. WS aims to foster a culture of inclusion where all Colleagues are valued for their unique contributions to the firm as well as provided equal opportunities to succeed.  \n Wedbush uses E-Verify, an Internet-based system, to confirm the eligibility of all newly hired employees to work in the United States. Learn more about E-Verify, including your rights and responsibilities here https://www.e-verify.gov/employees/e-verify-overview    From: Wedbush Securities", "cleaned_desc": "  Advanced proficiency in SQL and understanding of data access tools \n  5+ years\u2019 experience in Information Technology, preferably for a financial services firm \n  5+ years\u2019 experience in Data Analytics, Risk Analysis, or related role \n  Understanding of Equities, Options, and Margin is a plus \n  Must be detail oriented and maintain data integrity \n  Creative, solution-oriented mindset with the ability to handle pressure to meet deadlines \n  Able to work with minimal supervision, taking ownership of work and completing tasks in timely manner, while adapting rapidly to changing work environments, priorities and organizational needs \n  Ability to identify gaps in existing processes and gain efficiency through automation. \n  Experience working with multiple teams across different time zones ", "techs": ["sql", "data access tools", "equities", "options", "margin", "automation"]}, "d8f8a3fb7d73af1a": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Technical Program Manager (L6) - Game Discovery", "company": "Netflix", "desc": "Remote, United States\n      \n \n \n \n \n \n \n         Netflix Games Studio\n        \n \n \n \n \n \n \n \n     Netflix is one of the world's leading entertainment services with over 230 million paid memberships in over 190 countries. In addition to great shows and movies, our membership also includes exclusive access to a growing portfolio of high-quality games. The games platform team is looking for a Technical Program Manager to strengthen our member discovery capabilities in Netflix\u2019s relatively nascent opportunity in games.\n    \n \n \n  The game discovery Technical Program Manager will partner closely with the Product Manager to drive impactful cross-functional programs both within the games platform and across the company. The role requires strong coordination and collaboration with engineering teams in our core platform, games and member UI teams, data science, and the Netflix Game Studios organization. This role has the direct opportunity to impact a key objective for games - to move members from saying \u201cWait, Netflix has Games?\u201d to \u201cDid you play the latest Netflix Game?\u201d\n    \n \n  Responsibilities \n \n  Leading multiple cross-functional programs, in collaboration with product, engineering, design, and data science. \n  Provide deep domain expertise to form technical strategies with engineering partners. \n  Drive engagement with internal partners, work to decompose requirements into technical execution plans with measurable milestones, effectively optimize scope and schedule, manage cross-functional dependencies, and proactively manage risks. \n  Craft clear communication of progress toward goals, reporting status to stakeholders and leadership. \n \n \n \n  Requirements \n \n  10+ years of technical program management experience \n  Deep understanding and point of view on product growth and discovery solutions \n  Direct experience in the games industry is beneficial (TPM, Product, Development, etc.) \n  Highly skilled, experienced, and enjoys orchestrating multi-organizational impacting software programs with many moving parts \n  Proven experience creating partnerships with cross-functional teams, driving large-scale technical strategies, debating technical approaches, and building long-term scalable solutions \n  Able to identify gaps in solutions and weigh in on product vs. technology tradeoffs \n  Excellent written and verbal communication skills, including the ability to clearly articulate business impact and technical constraints tailored to the audience \n  Self-starter who enjoys tackling 0 to 1 problem spaces and quickly bringing organization and direction \n  Exemplify the Netflix culture by understanding, advocating, and demonstrating its values \n \n \n \n     Location of work: Our organization has a distributed team across the US. We are considering both candidates who are willing to relocate to Los Gatos, California, and fully remote candidates (remote in the US with travel to Netflix HQ). The expectation is that candidates will work during core Pacific standard time business hours.\n    \n \n \n  At Netflix, we carefully consider a wide range of compensation factors to determine your personal top of market. We rely on market indicators to determine compensation and consider your specific job, skills, and experience to get it right. These considerations can cause your compensation to vary and will also be dependent on your location.\n    \n \n \n  The overall market range for roles in this area of Netflix is typically $100,000 - $600,000.\n    \n \n \n  This market range is based on total compensation (vs. only base salary), which is in line with our compensation philosophy.", "cleaned_desc": "  Requirements \n \n  10+ years of technical program management experience \n  Deep understanding and point of view on product growth and discovery solutions \n  Direct experience in the games industry is beneficial (TPM, Product, Development, etc.) \n  Highly skilled, experienced, and enjoys orchestrating multi-organizational impacting software programs with many moving parts \n  Proven experience creating partnerships with cross-functional teams, driving large-scale technical strategies, debating technical approaches, and building long-term scalable solutions \n  Able to identify gaps in solutions and weigh in on product vs. technology tradeoffs \n  Excellent written and verbal communication skills, including the ability to clearly articulate business impact and technical constraints tailored to the audience \n  Self-starter who enjoys tackling 0 to 1 problem spaces and quickly bringing organization and direction \n  Exemplify the Netflix culture by understanding, advocating, and demonstrating its values ", "techs": ["none"]}, "ab1922ea064493b3": {"terms": ["data science"], "salary_min": 80420.375, "salary_max": 101830.11, "title": "Fraud Behavioral Insights, Card and Disputes Analyst", "company": "Afterpay", "desc": "Company Description \n \n \n \n     It all started with an idea at Block in 2013. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic ecosystem, developing unique financial products, including Afterpay/Clearpay, to provide a better way to send, spend, invest, borrow and save to our 47 million monthly active customers. We want to redefine the world\u2019s relationship with money to make it more relatable, instantly available, and universally accessible.\n     \n  Today, Cash App has thousands of employees working globally across office and remote locations, with a culture geared toward innovation, collaboration and impact. We\u2019ve been a distributed team since day one, and many of our roles can be done remotely from the countries where Cash App operates. No matter the location, we tailor our experience to ensure our employees are creative, productive, and happy.\n     \n  Check out our locations, benefits, and more at cash.app/careers.\n    \n \n \n \n \n  Job Description \n \n \n  Cash App is seeking a Fraud Behavioral Insights, Card and Disputes Analyst to join our dynamic Behavioral Insights Team. A Fraud Behavioral Insights, Card and Disputes Analyst leverages natural analytical and problem-solving skills to analyze large structured and unstructured data sets to identify trends, anomalies and inauthentic behaviors across Cash App accounts and products. This position relies on decisions made independently, with high precision and attention to detail. \n  This position will collaborate often with teammates, as well as work with many organizations within the business, such as Data Science, Machine Learning Modeling, Engineering, Product, Business Operations, Risk Operations, Compliance, and more. You will help drive innovation and influence Cash App\u2019s fraud roadmap, programs, and processes. \n  The ideal candidate possesses exceptional analytical and communication skills. They must also enjoy ambiguous problem solving and have strong self-motivation skills. This role requires a bias toward taking action in a fast-paced and dynamic environment. \n  You Will \n \n  Become an expert on customer behaviors and authentic and inauthentic activity within Cash App\u2019s ecosystem \n  Master the Card and Disputes domain of risk-adjacent behaviors and how your domain affects Cash App \n  Learn to investigate and analyze complex data sets to resolve business challenges, identify opportunities for improvement, and provide insights and solutions \n  Leverage industry experience and expertise to analyze existing risks within product offerings that require a high level of attention to detail \n  Partner with internal business teams to identify and confirm emerging fraud trends and potential customer impact due to risk controls, both ahead of product launches and in an ongoing capacity \n  Respond promptly to internal business partners and exercise exceptional communication skills to optimize each contact \n  Must be able to take initiative, plan, organize and prioritize projects with overlapping deadlines competently; work independently and help others; must be highly motivated and detail-oriented \n  Foster a culture of professionalism, accountability, collaboration, speed, innovation, excellence, and a fun work environment while continuously elevating the quality and caliber of our risk controls \n  Other responsibilities as assigned \n \n \n \n \n \n  Qualifications \n \n \n \n  3+ years experience in risk and/or fraud detection in financial services or technology with an emphasis on debit card, disputes, and Reg E processes \n  Experience working with machine learning teams \n  Superior writing and editing skills, with the ability to produce copy requiring minimal rework; technical or procedural writing experience a plus \n  Experience working with teams across countries and time zones \n  Ability to synthesize information and make clear, concise recommendations on a course of action \n  Flexibility to adapt and able to manage multiple assignments while working independently \n \n  Even Better \n \n  Bachelor's Degree in Finance, Accounting, Mathematics, Economics, Computer Science, Information Management or Statistics \n  CFE, ACAMS, or similar accreditation \n  SQL experience \n \n \n \n \n \n  Additional Information \n \n \n  Block takes a market-based approach to pay, and pay may vary depending on your location. U.S. locations are categorized into one of four zones based on a cost of labor index for that geographic area. The successful candidate\u2019s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. These ranges may be modified in the future.    Zone A: USD $114,200 - USD $139,600  Zone B: USD $106,200 - USD $129,800  Zone C: USD $97,100 - USD $118,700  Zone D: USD $85,700 - USD $104,700 \n \n  To find a location\u2019s zone designation, please refer to this resource. If a location of interest is not listed, please speak with a recruiter for additional information. \n  Full-time employee benefits include the following: \n \n  Healthcare coverage (Medical, Vision and Dental insurance) \n  Health Savings Account and Flexible Spending Account \n  Retirement Plans including company match \n  Employee Stock Purchase Program \n  Wellness programs, including access to mental health, 1:1 financial planners, and a monthly wellness allowance \n  Paid parental and caregiving leave \n  Paid time off (including 12 paid holidays) \n  Paid sick leave (1 hour per 26 hours worked (max 80 hours per calendar year to the extent legally permissible) for non-exempt employees and covered by our Flexible Time Off policy for exempt employees) \n  Learning and Development resources \n  Paid Life insurance, AD&D, and disability benefits \n  Additional Perks such as WFH reimbursements and free access to caregiving, legal, and discounted resources \n \n  These benefits are further detailed in Block's policies. This role is also eligible to participate in Block's equity plan subject to the terms of the applicable plans and policies, and may be eligible for a sign-on bonus. Sales roles may be eligible to participate in a commission plan subject to the terms of the applicable plans and policies. Pay and benefits are subject to change at any time, consistent with the terms of any applicable compensation or benefit plans. \n  We\u2019re working to build a more inclusive economy where our customers have equal access to opportunity, and we strive to live by these same values in building our workplace. Block is a proud equal opportunity employer. We work hard to evaluate all employees and job applicants consistently, without regard to race, color, religion, gender, national origin, age, disability, veteran status, pregnancy, gender expression or identity, sexual orientation, citizenship, or any other legally protected class. \n  We believe in being fair, and are committed to an inclusive interview experience, including providing reasonable accommodations to disabled applicants throughout the recruitment process. We encourage applicants to share any needed accommodations with their recruiter, who will treat these requests as confidentially as possible.  Want to learn more about what we\u2019re doing to build a workplace that is fair and square? \n  Additionally, we consider qualified applicants with criminal histories for employment on our team, assessing candidates in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance. \n \n \n  Block, Inc. (NYSE: SQ) is a global technology company with a focus on financial services. Made up of Square, Cash App, Spiral, TIDAL, and TBD, we build tools to help more people access the economy. Square helps sellers run and grow their businesses with its integrated ecosystem of commerce solutions, business software, and banking services. With Cash App, anyone can easily send, spend, or invest their money in stocks or Bitcoin. Spiral (formerly Square Crypto) builds and funds free, open-source Bitcoin projects. Artists use TIDAL to help them succeed as entrepreneurs and connect more deeply with fans. TBD is building an open developer platform to make it easier to access Bitcoin and other blockchain technologies without having to go through an institution.", "cleaned_desc": " \n \n \n \n  Qualifications \n \n \n \n  3+ years experience in risk and/or fraud detection in financial services or technology with an emphasis on debit card, disputes, and Reg E processes \n  Experience working with machine learning teams \n  Superior writing and editing skills, with the ability to produce copy requiring minimal rework; technical or procedural writing experience a plus \n  Experience working with teams across countries and time zones \n  Ability to synthesize information and make clear, concise recommendations on a course of action \n  Flexibility to adapt and able to manage multiple assignments while working independently \n \n  Even Better ", "techs": ["machine learning", "writing and editing skills", "procedural writing", "cross-country teamwork", "time zone coordination"]}, "c7a146e384e20db9": {"terms": ["data science"], "salary_min": 130000.0, "salary_max": -1.0, "title": "Remote Senior Data Scientist", "company": "Intoxalock", "desc": "Consumer Safety Technology (CST)  and our family of brands have helped millions of individuals to live and drive responsibly. We provide products and services to consumers and program monitoring authorities to effectively deter impaired driving and support individuals as they navigate the license restoration process. We are the largest provider of IIDs in the United States and the only company working to assist individuals in successfully navigating the often-daunting DUI process. \n We hire people who we expect will produce exceptional results, deliver amazing service to our clients including customers, attorneys, state associations and more, and inspire positive change within the company. \n We are hiring a  Remote Senior Data Scientist . \n Job Summary:  The  Senior Data Scientist  is responsible for leading key data science initiatives for CST and Brands. The Senior Data Scientist has oversight of the production, automation, and distribution of key metrics that encompass all operational, technology and customer experience metrics. The Senior Data Scientist applies and inspires adoption of advanced analytics across the CST Brands, in a way that contributes deepened insights on highlights & opportunities to optimize performance. \n \n Duties and Responsibilities: \n \n \n Lead key business analysis efforts as defined by VP Finance; Collaborate on useful modifications to analysis requests \n Partner with analytical peers to adopt best practices, data definition standards and explore new tools/technology \n Oversee preparation and distribution of key periodic (daily, weekly, monthly, quarterly) reports \n Strive to eliminate manual processes through automation and testing of technologies \n Identify data patterns that are key business indicators; communicate trends and recommendations \n Provide mentorship to junior analysts \u2013 share and help to grow technical knowledge, skills and professional maturity \n Participate in budgeting and forecast processes \u2013 implementing improved forecasting models \n Be a cross disciplinary partner \u2013 sharing best practices and unifying business logic bringing consistency to reporting and analysis \n Present insights to senior level leadership, distilling complex statistical findings to non technical audiences \n Respond to ad hoc analytical requests as needed \n \n \n \n Job Requirements: \n \n \n You have a MS in Data Science, Business Analytics, Statistics, or Computer Science \n You have 10+ years\u2019 experience working with relational databases and usage of SQL \n You have 10+ years\u2019 experience distilling data into dashboards/summary reports (PowerBI, Tableau, Visual Studio, SSRS, etc.) \n You have 10+ years\u2019 experience working with statistical analysis software (SAS, R, Python, SPSS, etc.) \n  - You have 10+ years reporting/analytics experience (Finance, Operations, Marketing, Sales - any combination)\n   \n \n You are flexible and enjoy working in a fast-paced environment with regular opportunities for new development \n You are a curious problem-solver that can work independently and deliver on a clear timeline \n Strong verbal and written communication skills required, including a high level of comfort in interacting with senior management \n \n \n \n \n \n Why work for us? \n  Check out this list of just a few of the many good reasons why\u2026\n   \n \n Pay starts at $130,000 \n Our Mission is to help people live and drive responsibly. Last year our product stopped 243,000 illicit startup attempts by people who were too intoxicated to drive. \n CST won the 2022 Top Workplace Award locally and nationally\u2013and 2023 Best Place for Working Parents Award \n We are the nation\u2019s largest interlock provider \n Growth Oriented- 7 years of over 10%+ growth annually. Doubled in size over the past 2-3 years \n Full-time/40 hours guaranteed weekly \n Benefits include Paid Time Off, 401(k) & Health/Life/Vision/Dental insurance \n Ongoing Professional Training online via Litmos   \n \n \n   Equal Opportunity Employer  It is and will continue to be the policy of CST, LLC to practice a program of equal employment opportunity designed to assure that employment and advancement opportunities are made available to all employees and applicants on the basis of individual qualifications and without unlawful regard to race, religion, color, veteran status, national origin, disability, age, gender identity, sexual orientation, sex or genetic information.", "cleaned_desc": "", "techs": ""}, "82b85eee5dbb1716": {"terms": ["data science", "machine learning engineer"], "salary_min": 144470.88, "salary_max": 182932.31, "title": "Machine Learning Engineer", "company": "Cisco Systems", "desc": "Who We Are \n \n \n   We are a part of Outshift by Cisco focused on identifying breakthrough emerging solutions that create new markets and businesses for Cisco. We incubate these new opportunities in partnership with our business groups, corporate partners, and other startups. The team also continues to progress Cisco\u2019s important work with Standards bodies and runs research partnerships with groundbreaking Universities.\n  \n \n   Our organization is anticipating high growth. We are seeking talent with the agility and creativity to explore opportunities and fill in needs as they arise across our teams. Applicants should be seeking a flexible role, in which they not only provide leadership in their primary function, but also contribute in meaningful ways to other projects. We are looking for individuals who are passionate about shifting quickly to different domains that may be outside of their normal scope of responsibilities.\n  \n \n   Learn more about us at https://outshift.com.\n  \n \n \n  Who You'll Work With \n \n \n   The Outshift team is a highly visible team within Cisco. Outshift focuses on the next wave of innovation by anticipating, investing in, and incubating new technologies and business ventures. You will be part of the incubation team to develop new products and bring them to market in a startup-like environment.\n  \n \n \n  What You'll Do \n \n \n   In this role, you will work in an innovative team, apply and advance powerful AI technologies in products that make tangible business impacts, create the latest AI-powered user experiences on various platforms, work alongside a committed generative AI product management team, gain expertise in the most in-demand AI domains for the future, and contribute to shaping Cisco\u2019s AI strategies for the next decade. You will also collaborate across teams within Cisco, to drive a common AI strategy across the company.\n  \n \n \n  The Impact You\u2019ll Make \n \n \n   Want the challenge of fast-paced growth along with the happiness of seeing thoughtful ideas come to life? The pride in helping grow a world-class AI team. This is the place for you!\n  \n \n \n  Your responsibilities will include \n \n \n   Design and develop end-to-end products to enable easy adoption of generative AI for enterprises.\n  \n \n   Collaborate with multi-functional teams including product managers, applied scientists, and other engineers and identify and implement the most effective system design and solutions.\n  \n \n   Design and build services and integrations for ML pipelines for LLM fine-tuning, prompt tuning and engineering, Benchmarking and RAG for various generative AI models.\n  \n \n   Stay up to date with the latest advancements in the field of AI and apply them to develop cutting- edge solutions.\n  \n \n \n  Minimum Requirements \n \n \n   Bachelor's degree or equivalent experience in Computer Science, Computer Engineering, Statistics, or a related field.\n  \n \n   7+ years strong programming skills in Java, C++, Python or other related languages.\n  \n \n   5+ years deep coding experience in developing and delivering complex, distributed, enterprise class software.\n  \n \n   Understanding of infrastructure needed for building and adoption of Large Language Models, Natural Language Processing, Computer Vision, Image Processing, and generative AI techniques \n  \n \n \n Preferred Requirements \n \n \n   Strong problem-solving skills and ability to work independently or in a team.\n  \n \n   Comfortable and capable of interacting with technologists as with business executives.\n  \n \n   Excellent verbal and written communication skills.\n  \n \n \n  Why Cisco? \n \n \n \n   #WeAreCisco. We are all unique, but collectively we bring our talents to work as a team, to develop innovative technology and power a more inclusive, digital future for everyone. How do we do it? Well, for starters \u2013 with people like you!\n  \n \n \n   Nearly every internet connection around the world touches Cisco. We\u2019re the Internet\u2019s optimists. Our technology makes sure the data travelling at light speed across connections does so securely, yet it\u2019s not what we make but what we make happen which marks us out. We\u2019re helping those who work in the health service to connect with patients and each other; schools, colleges, and universities to teach in even the most challenging of times. We\u2019re helping businesses of all shapes and size to connect with their employees and customers in new ways, providing people with access to the digital skills they need and connecting the most remote parts of the world \u2013 whether through 5G, or otherwise.\n  \n \n \n   We tackle whatever challenges come our way. We have each other\u2019s backs, we recognize our accomplishments, and we grow together. We celebrate and support one another \u2013 from big and small things in life to big career moments. And giving back is in our DNA (we get 10 days off each year to do just that).\n  \n \n \n   We know that powering an inclusive future starts with us. Because without diversity and a dedication to equality, there is no moving forward. Our 30 Inclusive Communities, that bring people together around commonalities or passions, are leading the way. Together we\u2019re committed to learning, listening, caring for our communities, whilst supporting the most vulnerable with a collective effort to make this world a better place either with technology, or through our actions.\n  \n \n \n   So, you have colorful hair? Don\u2019t care. Tattoos? Show off your ink. Like polka dots? That\u2019s cool. Pop culture geek? Many of us are. Passion for technology and world changing? Be you, with us! #WeAreCisco\n  \n \n \n  #LI-TA2\n  \n \n   #LI-Remote\n  \n \n \n \n Message to applicants applying to work in the U.S.: \n \n \n \n  When available, the salary range posted for this position reflects the projected hiring range for new hire, full-time salaries in U.S. locations, not including equity or benefits. For non-sales roles the hiring ranges reflect base salary only; employees are also eligible to receive annual bonuses. Hiring ranges for sales positions include base and incentive compensation target. Individual pay is determined by the candidate's hiring location and additional factors, including but not limited to skillset, experience, and relevant education, certifications, or training. Applicants may not be eligible for the full salary range based on their U.S. hiring location. The recruiter can share more details about compensation for the role in your location during the hiring process.\n  \n \n  U.S. employees have \n   access  to quality medical, dental and vision insurance, a 401(k) plan with a Cisco matching contribution, short and long-term disability coverage, basic life insurance and numerous wellbeing offerings. Employees receive up to twelve paid holidays per calendar year, which includes one floating holiday, plus a day off for their birthday. Employees accrue up to 20 days of Paid Time Off (PTO) each year and have access to paid time away to deal with critical or emergency issues without tapping into their PTO. We offer additional paid time to volunteer and give back to the community. Employees are also able to purchase company stock through our Employee Stock Purchase Program.\n  \n \n  Employees on sales plans earn performance-based incentive pay on top of their base salary, which is split between quota and non-quota components. For quota-based incentive pay, Cisco pays at the standard rate of 1% of incentive target for each 1% revenue attainment against the quota up to 100%. Once performance exceeds 100% quota attainment, incentive rates may increase up to five times the standard rate with no cap on incentive compensation. For non-quota-based sales performance elements such as strategic sales objectives, Cisco may pay up to 125% of target. Cisco sales plans do not have a minimum threshold of performance for sales incentive compensation to be paid.", "cleaned_desc": "  \n \n \n  The Impact You\u2019ll Make \n \n \n   Want the challenge of fast-paced growth along with the happiness of seeing thoughtful ideas come to life? The pride in helping grow a world-class AI team. This is the place for you!\n  \n \n \n  Your responsibilities will include \n \n \n   Design and develop end-to-end products to enable easy adoption of generative AI for enterprises.\n  \n \n   Collaborate with multi-functional teams including product managers, applied scientists, and other engineers and identify and implement the most effective system design and solutions.\n  \n \n   Design and build services and integrations for ML pipelines for LLM fine-tuning, prompt tuning and engineering, Benchmarking and RAG for various generative AI models.\n  \n \n   Stay up to date with the latest advancements in the field of AI and apply them to develop cutting- edge solutions.\n    \n \n  Minimum Requirements \n \n \n   Bachelor's degree or equivalent experience in Computer Science, Computer Engineering, Statistics, or a related field.\n  \n \n   7+ years strong programming skills in Java, C++, Python or other related languages.\n  \n \n   5+ years deep coding experience in developing and delivering complex, distributed, enterprise class software.\n  \n \n   Understanding of infrastructure needed for building and adoption of Large Language Models, Natural Language Processing, Computer Vision, Image Processing, and generative AI techniques \n  \n \n \n Preferred Requirements \n \n \n   Strong problem-solving skills and ability to work independently or in a team.\n  \n ", "techs": ["java", "c++", "python", "large language models", "natural language processing", "computer vision", "image processing", "generative ai techniques"]}, "5ebad3df55af0175": {"terms": ["data science"], "salary_min": 92125.375, "salary_max": 116651.25, "title": "Senior Data Analyst", "company": "Glowforge", "desc": "At Glowforge, we help people bring home the future and make it their own. Our printer uses a laser to carve and engrave products from raw materials like wood, leather, acrylic \u2013 even cardboard. Take a look and see for yourself. \n  We build magical products to delight our customers, and we do it while taking care of each other. We hire people who are outstanding at what they do, who thrive in tight-knit teams, and who want to make things that make a difference. \n  Together, we've built a product we're incredibly proud of, and the reward has been incredible growth. \n  We work together because we believe in the power of creativity. We believe we can bring about a future where anyone can print anything. \n  We're a remote-first company - just let us know where you prefer to work from! \n  Why we need you \n  At Glowforge, we are passionate about making solid, fast decisions informed by razor-sharp analysis and insights. \n  Without you, our vast treasure trove of data is wasted potential. Your curiosity, talent for problem-solving, and passion for data allow you to unearth hidden patterns that fuel our growth, improve our products, enable us to deliver legendary customer service, and operate an efficient business. \n  How did we ever get along without you? \n  Here's what you'll be doing: \n  As a vital part of the Glowforge Data team, you'll collaborate with business partners and data engineers to deliver accurate and reliable reports, dashboards, models, metrics, and analyses to partners across the company. Your responsibilities will include: \n \n Work with data engineers, marketers, product managers, and more to define, refine, and detail requirements that empower you to deliver business-defining insights. \n Coaching and mentoring your co-workers across the organization to wisely self-serve their own accurate analysis, focusing only on what's statistically significant, and ruthlessly eliminating false conclusions. \n Building and iterating on reports and dashboards using modern data tools to ensure data accuracy, reliability, and storytelling \n Put LLMs like GPT-4 to work cleaning data, analyzing unstructured inputs, and writing code for sophisticated analyses \n Developing and maintaining SQL queries and automation scripts to create data streams from various sources, working with data engineers to ensure clean and normalized inputs. \n \n You need these qualifications \n \n 5+ years of professional experience in a similar role \n Excellent communication skills, both technical and non-technical communication skills \n Fluency in SQL and data visualizations, with experience in modifying existing data models, crafting new ones, and sharing them using data visualization tools (e.g., Tableau, Metabase, Looker) \n Proficiency in Python and its use in data analysis and manipulation \n Familiarity with statistical techniques beyond simple regressions and significance tests; you know when and why to break out Bayesian methods, cluster analysis, and other advanced methods. \n You\u2019re no stranger to cloud-based data warehousing and analytics stacks (e.g., Airflow, dbt, BigQuery, Segment) \n You\u2019ve already been using GPT-4 or ChatGPT to turbocharge your work \n \n It would be nice if you... \n \n Possess analytics engineering experience, particularly around transformations \n Have startup experience in a fast-paced and demanding environment \n Are a creative individual who loves making things and exploring new ideas \n \n We love cover letters. We read them before the resume. Please tell us about a product that you worked on that you\u2019re proud of, and what contribution you made that you\u2019re most excited about. \n  In your cover letter, in addition to whatever you\u2019d like to say, please tell us about the product or feature you\u2019re most proud of in your portfolio. What about it makes you grin from ear to ear? \n  There's one more, very important thing. We are an equal opportunity employer. We search for amazing people of diverse backgrounds, experiences, abilities, and perspectives. We take care of each other to create an inclusive work environment where we love to come to work every day. We'd be happy to provide reasonable accommodations to help you apply - just email us at jobs@glowforge.com. We hope you can join us.", "cleaned_desc": " Building and iterating on reports and dashboards using modern data tools to ensure data accuracy, reliability, and storytelling \n Put LLMs like GPT-4 to work cleaning data, analyzing unstructured inputs, and writing code for sophisticated analyses \n Developing and maintaining SQL queries and automation scripts to create data streams from various sources, working with data engineers to ensure clean and normalized inputs. \n \n You need these qualifications \n \n 5+ years of professional experience in a similar role   Excellent communication skills, both technical and non-technical communication skills \n Fluency in SQL and data visualizations, with experience in modifying existing data models, crafting new ones, and sharing them using data visualization tools (e.g., Tableau, Metabase, Looker) \n Proficiency in Python and its use in data analysis and manipulation \n Familiarity with statistical techniques beyond simple regressions and significance tests; you know when and why to break out Bayesian methods, cluster analysis, and other advanced methods. \n You\u2019re no stranger to cloud-based data warehousing and analytics stacks (e.g., Airflow, dbt, BigQuery, Segment) \n You\u2019ve already been using GPT-4 or ChatGPT to turbocharge your work \n ", "techs": ["tableau", "metabase", "looker", "python", "airflow", "dbt", "bigquery", "gpt-4", "chatgpt"]}, "0a1725c98c70e9c4": {"terms": ["data science", "machine learning engineer"], "salary_min": 110875.31, "salary_max": 140392.84, "title": "Machine Learning Engineer", "company": "EX Squared Outcoding", "desc": "Become an Outcoder as a Machine Learning Engineer \n We seek a Machine Learning (ML) Engineer to help us create artificial intelligence products. \n Machine Learning Engineer responsibilities include creating machine learning models and retraining systems. To do this job successfully, you need exceptional skills in statistics and programming. We want to meet you if you know data science and software engineering. \n Your ultimate goal will be to shape and build efficient self-learning applications.     What you'll need to be successful: \n \n Study and transform data science prototypes \n  Design machine learning systems \n  Research and implement appropriate ML algorithms and tools \n  Develop machine learning applications according to requirements \n  Select appropriate datasets and data representation methods \n  Run machine learning tests and experiments \n  Perform statistical analysis and fine-tuning using test results \n  Train and retrain systems when necessary \n  Extend existing ML libraries and frameworks \n  Keep abreast of developments in the field \n \n About us:  EX\u00b2 Outcoding is a premier solution provider of a broad range of outsourcing services, combining proven expertise in technology and project execution for companies searching for high-quality software development solutions. We specialize in delivering the best technical solution and enhancing that solution creatively by working closely with stakeholders to understand the business context. \n #LI-REMOTE", "cleaned_desc": "", "techs": ""}, "af6c3706d16ba369": {"terms": ["data science"], "salary_min": 117914.93, "salary_max": 149306.58, "title": "Data Scientist", "company": "SAIC", "desc": "Job ID: 2314395 \n  Location:  AUSTIN, TX, US \n  Date Posted:  2023-10-18 \n  Category:  Information Technology \n  Subcategory:  Data Scientist \n  Schedule:  Full-time \n  Shift:  Day Job \n  Travel:  No \n  Minimum Clearance Required:  None \n  Clearance Level Must Be Able to Obtain:  Public Trust \n  Potential for Remote Work:  Yes \n  Description   \n SAIC is seeking a seasoned Data Scientist.  This role can be 100% remote. \n \n  SAIC is seeking a seasoned a Data Scientist who possesses knowledge of appropriate data sources to address the specific requirements of projects for data modeling. Understand business requirements and translating into technical work. Design and implement features in collaboration with team engineers, product owners, data analysts, and business partners using Agile / Scrum methodology.     Responsibilities \n \n  Ability to build programs or systems that can take data and turn it into meaningful information that can be studied. \n \n \n  Build ETL/ELT jobs and workflows to combine data from disparate sources.  \n \n \n  Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses.  \n \n \n  Build data workflows using SQL Server Integration Services (SSIS) \n \n \n  Build data workflows using Microsoft Azure (Azure Data Factory, Storage Accounts, Synapse) \n \n \n  Build data workflows using Databricks \n \n \n  Collaborate with business stakeholders, business operations, and product engineering teams in  \n \n \n  Analyzing business problems, in building and testing solutions and data models  \n \n \n  Experience implementing and operating analytic models and services.  \n \n \n  Document the current-state and target-state software architecture and create roadmap plans for success on various software components. \n \n \n  Knowledge of dimensional modeling techniques (star & snowflake). \n \n \n  Knowledge of MPP database architecture. \n \n \n  Knowledge of Data Quality, MDM solutions. \n \n \n  Experience with tuning big data pipelines using data bricks. \n \n \n  Working knowledge of data visualization tools i.e. Power BI. \n \n \n  Assist in the design, implementation, and maintenance of complex solutions. \n \n \n  Build systems that collect, manage, and convert raw data into usable information for business analysts to interpret.  \n \n \n  Make data accessible for evaluation and optimization  \n \n \n  Collaborate with business stakeholders, business operations, and product engineering teams \n \n \n  Coordinate activities with other technical personnel as appropriate. \n \n  Qualifications   \n \n Must have a Bachelor's degree and 5 years of experience, Masters and 3 years of experience. May consider an additional 4 years of experience in lieu of a degree. \n Bachelors in and in computer science, systems engineering, or related technical discipline is preferred. \n 5 years of experience as a Data Engineer/Administrator or similar role. 10 years of experience is preferred. \n Works the back end data and organizes it into table using SQL scripts and SSIS. SSIS, SSMS \n Ability to work independently with minimal direction providing technical and non-technical support to multiple users \n Capable of working under pressure, while handling multiple tasks simultaneously \n Ability to work overtime and weekends required on occasion \n Experience providing services to the federal government is preferred \n Must have Azure/Cloud experience \n \n \n  Preferred \n \n  Works the back end data and organizes it into table using SQL scripts and SSIS. SSIS, SSMS \n \n \n  Experience with Microsoft Azure \n \n \n  Experience with Databricks \n \n \n  Experience using Python or other scripting languages in data pipelines \n \n \n  Experience with Microsoft Power BI \n \n \n  Ability to work independently with minimal direction providing technical and non-technical support to multiple users \n \n \n  Capable of working under pressure, while handling multiple tasks simultaneously \n \n \n  Ability to work overtime and weekends required on occasion \n \n \n  Experience providing services to the federal government is preferred \n \n \n   Covid Policy: SAIC does not require COVID-19 vaccinations or boosters. Customer site vaccination requirements must be followed when work is performed at a customer site.", "cleaned_desc": " \n \n  Build data workflows using SQL Server Integration Services (SSIS) \n \n \n  Build data workflows using Microsoft Azure (Azure Data Factory, Storage Accounts, Synapse) \n \n \n  Build data workflows using Databricks \n \n \n  Collaborate with business stakeholders, business operations, and product engineering teams in  \n \n \n  Analyzing business problems, in building and testing solutions and data models  \n \n \n  Experience implementing and operating analytic models and services.  \n \n \n  Document the current-state and target-state software architecture and create roadmap plans for success on various software components. \n \n    Knowledge of dimensional modeling techniques (star & snowflake). \n \n \n  Knowledge of MPP database architecture. \n \n \n  Knowledge of Data Quality, MDM solutions. \n \n \n  Experience with tuning big data pipelines using data bricks. \n \n \n  Working knowledge of data visualization tools i.e. Power BI. \n \n \n  Assist in the design, implementation, and maintenance of complex solutions. \n \n \n  Build systems that collect, manage, and convert raw data into usable information for business analysts to interpret.  \n \n \n  Make data accessible for evaluation and optimization  \n   \n  Collaborate with business stakeholders, business operations, and product engineering teams \n \n \n  Coordinate activities with other technical personnel as appropriate. \n \n  Qualifications   \n \n Must have a Bachelor's degree and 5 years of experience, Masters and 3 years of experience. May consider an additional 4 years of experience in lieu of a degree. \n Bachelors in and in computer science, systems engineering, or related technical discipline is preferred. \n 5 years of experience as a Data Engineer/Administrator or similar role. 10 years of experience is preferred. \n Works the back end data and organizes it into table using SQL scripts and SSIS. SSIS, SSMS \n Ability to work independently with minimal direction providing technical and non-technical support to multiple users \n Capable of working under pressure, while handling multiple tasks simultaneously \n Ability to work overtime and weekends required on occasion \n Experience providing services to the federal government is preferred \n Must have Azure/Cloud experience \n \n \n  Preferred \n \n  Works the back end data and organizes it into table using SQL scripts and SSIS. SSIS, SSMS \n   \n  Experience with Microsoft Azure \n \n \n  Experience with Databricks \n \n \n  Experience using Python or other scripting languages in data pipelines \n \n \n  Experience with Microsoft Power BI \n \n \n  Ability to work independently with minimal direction providing technical and non-technical support to multiple users \n \n \n  Capable of working under pressure, while handling multiple tasks simultaneously \n \n \n  Ability to work overtime and weekends required on occasion \n \n \n  Experience providing services to the federal government is preferred ", "techs": ["sql server integration services (ssis)", "microsoft azure (azure data factory", "storage accounts", "synapse)", "databricks", "dimensional modeling techniques", "mpp database architecture", "data quality", "mdm solutions", "power bi", "sql scripts", "ssms", "python", "microsoft power bi."]}, "ec671d53be496e9b": {"terms": ["data science", "data analyst"], "salary_min": 80000.0, "salary_max": 80000.0, "title": "Sr Analyst, Clinical Analytics", "company": "Evolent Health", "desc": "Your Future Evolves Here\n  \n \n \n \n    Evolent Health has a bold mission to change the health of the nation by changing the way health care is delivered. Evolenteers make a difference wherever they are, whether it is at a medical center, in the office, or while working from home across 48 states. We empower you to work from where you work best, which makes juggling careers, families, and social lives so much easier. Through our recognition programs, we also highlight employees who live our values, give back to our communities each year, and are champions for bringing their whole selves to work each day. If you\u2019re looking for a place where your work can be personally and professionally rewarding, don\u2019t just join a company with a mission. Join a mission with a company behind it.\n   \n \n \n    Why We\u2019re Worth the Application:\n   \n \n  We continue to grow year over year. \n  Recognized as a leader in driving important \n     \n     diversity, equity, and inclusion (DE&I) efforts\n     . \n  Achieved a 100% score two years in a row on the \n     \n     Human Rights Campaign's Corporate Equality Index\n      recognizing us as a best place to work for LGBTQ+ equality. \n  Named to Parity.org\u2019s list of the best companies for women to advance for \n     \n     3 years in a row\n      (2020, 2021 and 2022). \n  Continue to prioritize the employee experience and achieved a 90% overall engagement score on our employee survey in May 2022. \n  Publish an annual \n     \n     DE&I report\n      to share our progress on how we\u2019re building an equitable workplace. \n \n \n \n    What You\u2019ll Be Doing:\n   \n \n \n \n   Who You\u2019ll Be Working With:\n  \n \n \n   A senior analyst, RASQ Analytics will be working with a highly advanced team of analysts, actuaries, and data scientists to develop and maintain risk adjustment & quality improvement analytic capabilities.\n  \n \n \n   What You\u2019ll Be Doing:\n  \n \n \n \n \n     Extract, transform, analyze, and summarize claims, member encounter, and other health data to answer business questions and provide exploratory analyses.\n    \n \n \n     Quantify and forecast program financial and operational returns related to risk adjustment.\n    \n \n \n     Work in a collaborative environment with other innovative professionals to develop best-in-breed risk adjustment.\n    \n \n \n     Explain highly technical details to non-technical audiences and develop supportive materials to educate executives and partners on capabilities.\n    \n \n \n     Monitor industry trends to influence future enhancements.\n    \n \n \n     Use cutting edge tools & techniques to produce insights to improve our processes and research to share internally and externally.\n    \n \n \n \n   The Experience You\u2019ll Need (Required):\n  \n \n \n \n \n     Bachelor\u2019s degree in public health, computer science, statistics, actuarial science, economics, health science, health administration, or related field\n    \n \n \n     Deep knowledge of Risk Adjustment methodologies/programs and related functional areas.\n    \n \n \n     Strong technical abilities with advanced data analytics tools and programing languages with an emphasis on loading & processing data files, including:\n    \n \n \n \n       2-3 plus years\u2019 experience in SQL, SAS and or Python.\n      \n \n \n       Writing data Extract-Transform-Load (ETL) scripts in SQL and or (CSV, Excel, Test, etc.)\n      \n \n \n \n     Ability to understand and apply highly technical specifications to healthcare datasets.\n    \n \n \n     Strong verbal & written skills and excellent communication & presentation skills. Comfortable presenting complex analyses\n    \n \n \n \n   Finishing Touches (Preferred):\n  \n \n \n \n \n     Master\u2019s degree in epidemiology, biostatistics, public health, data science, operations research, or related field\n    \n \n \n     Progress toward Actuarial Credentials\n    \n \n \n     Experience with predictive modeling or machine learning\n    \n \n \n     Familiarity with Risk Scoring Models (e.g., CMS-HCC, HHS-HCC, CDPS)\n    \n \n \n     Experience with healthcare data sources (claims, billing data, eligibility, etc.) & detailed knowledge of CPT/HCPCS/ICD9/ICD10\n    \n \n \n \n   Technical Requirements:\n  \n \n \n   We require that all employees have the following technical capability at their home: High speed internet over 10 Mbps and, specifically for all call center employees, the ability to plug in directly to the home internet router. These at-home technical requirements are subject to change with any scheduled re-opening of our office locations.\n  \n \n \n   Evolent Health is an equal opportunity employer and considers all qualified applicants equally without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran status, or disability status.\n  \n  Compensation Range: The minimum salary for this position is $80,000, plus benefits. Salaries are determined by the skill set required for the position and commensurate with experience and may vary above and below the stated amounts.", "cleaned_desc": " \n     Strong technical abilities with advanced data analytics tools and programing languages with an emphasis on loading & processing data files, including:\n    \n \n \n \n       2-3 plus years\u2019 experience in SQL, SAS and or Python.\n      \n \n \n       Writing data Extract-Transform-Load (ETL) scripts in SQL and or (CSV, Excel, Test, etc.)\n      \n \n \n \n     Ability to understand and apply highly technical specifications to healthcare datasets.\n    \n \n \n     Strong verbal & written skills and excellent communication & presentation skills. Comfortable presenting complex analyses\n    \n \n \n \n   Finishing Touches (Preferred):\n  \n \n \n \n ", "techs": ["sql", "sas", "python"]}, "d7a6a168405310c5": {"terms": ["data science", "data engineer"], "salary_min": 91428.0, "salary_max": 105143.0, "title": "Data Engineer", "company": "Crossover Health Management Services, Inc.", "desc": "About Crossover Health \n \n  Crossover Health is creating the future of health as it should be. A national, team-based medical group with a focus on wellbeing and prevention that extends beyond traditional sick care, the company delivers an entirely new model of healthcare\u2014Primary Health\u2014built on the foundation of trusted relationships, an interdisciplinary care team approach, and outcomes-based payment. Crossover\u2019s Primary Health model integrates primary care, physical medicine, mental health, health coaching, care navigation and more, and delivers care in surround-sound\u2014in-person, virtually and via asynchronous messaging. Together we are building a community of members that embraces healthcare as a proactive part of their lifestyle. \n \n  Job Summary \n  Crossover\u2019s Data Engineer is responsible for managing and developing data sources for analytics at scale. This is a critical role for supporting Crossover\u2019s growing analytics team, and serves as the connection between Crossover\u2019s Product and Technology teams, Data Science team, and data infrastructure vendors. In this role, the successful candidate will build out new data sources within the enterprise data warehouse, guide data modeling efforts for new and existing projects, and manage data ingress and egress between Crossover teams, clients, partners, and vendors. The ideal candidate will have experience with both clinical healthcare data as well as healthcare claims data.\n  \n  Job Responsibilities \n \n  Develop and maintain data sources within Crossover\u2019s enterprise data warehouse (inclusive of our current vendor and/or future data infrastructure) \n  Assist with recommendations for data architecture, data storage, data integration, data quality, and data models \n  Contribute to design sessions based on technical requirements, and build data models to clean and transform datasets for use by Crossover\u2019s Data Science and Analytics teams \n  Assist with ETL, ELT, and reverse-ETL design and development initiatives including data analysis, source-target mapping, data profiling, change data capture, QA testing, and performance tuning to guarantee quality and repeatability of data model results \n  Create and maintain data model standards, including MDM (Master Data Management) and codebase standardization \n  Migrate Enterprise Workloads to Snowflake using industry standard methodologies \n  Automate and deploy as well as build CI/CD pipelines to support cloud based workload \n  Design, deliver cloud native, hybrid, and multi-cloud Workloads \n  Invest in documentation, including all system design, architecture and ongoing changes \n  Design and support production job schedules, including alerting, monitoring, break fixes, and performance tuning \n  Build solutions that are automated, scalable, and sustainable while minimizing defects and technical debt \n  Assist stakeholders including analytics, design, product, and executive teams with data-related technical issues \n  Ability to work independently with little instruction or direct oversight \n  Perform other duties as assigned \n \n \n  Minimum Qualifications \n \n  Bachelors in Computer Science or Data Engineering, related degree, or equivalent professional experience \n  3+ years relevant work experience within a complex, dynamic environment, with preference for experience with clinical healthcare data \n  3+ years architecting , implementing, and supporting data infrastructure and topologies \n \n \n  Experience building and operating highly available, distributed systems of extraction, ingestion, and processing of large data sets across a variety of applications (OLTP, OLAP and DSS) \n  3+ years Experience with Data warehousing, methodologies, modeling techniques, design patterns, and technologies. \n  Experience with data migration tools and deploying cloudbase solutions \n  Experience in writing advanced SQL (DML & DDL), including Stored Procedures, Indexes, user defined functions, windows functions, correlated subqueries and CTE's, and related data query and management technology \n  Coding ability in R, Python, and Shell Scripting to build and deploy Pipelines \n  Working knowledge of Git, or similar collaborative code management software \n  Experience with data integration tools such as FiveTran, DBT, Informatica, Matillion, or similar ETL/ELT tools \n  Experience with Snowflake\u2019s data platform \n \n \n  Preferred Qualifications \n \n  Masters in Computer Science, Data Engineering, or related degree \n  Healthcare data acquisition, ingestion, processing, and analytics knowledge highly preferred \n  Previous experience with health informatics, taxonomies, terminologies, and code sets \n  Knowledge and understanding of product features: IAAS, PAAS and SAAS solutions \n  Experience with healthcare claims data, formats, and analytics \n  Experience with Health Catalyst\u2019s data and analytics platform \n  Experience with Tableau Cloud administration \n  Experience with Master Data Management \n  Understand Cloud Ecosystem \n \n  The base pay range for this position is $91,428.00 to $105,143.00 per year. Pay range may vary depending on work location, applicable knowledge, skills, and experience. This position will be eligible for an annual bonus opportunity and comprehensive benefits package that includes Medical Insurance, Dental Insurance, Vision Insurance, Short- and Long-Term Disability, Life Insurance, Paid Time Off and 401K.\n  \n  Crossover Health is committed to Equal Employment Opportunity regardless of race, color, national origin, gender, sexual orientation, age, religion, veteran status, disability, history of disability or perceived disability. If you need assistance or an accommodation due to a disability, you may email us at careers@crossoverhealth.com. \n \n  To all recruitment agencies : We do not accept unsolicited agency resumes and are not responsible for any fees related to unsolicited resumes. \n  #LI-Remote", "cleaned_desc": "  Contribute to design sessions based on technical requirements, and build data models to clean and transform datasets for use by Crossover\u2019s Data Science and Analytics teams \n  Assist with ETL, ELT, and reverse-ETL design and development initiatives including data analysis, source-target mapping, data profiling, change data capture, QA testing, and performance tuning to guarantee quality and repeatability of data model results \n  Create and maintain data model standards, including MDM (Master Data Management) and codebase standardization \n  Migrate Enterprise Workloads to Snowflake using industry standard methodologies \n  Automate and deploy as well as build CI/CD pipelines to support cloud based workload \n  Design, deliver cloud native, hybrid, and multi-cloud Workloads \n  Invest in documentation, including all system design, architecture and ongoing changes \n  Design and support production job schedules, including alerting, monitoring, break fixes, and performance tuning \n  Build solutions that are automated, scalable, and sustainable while minimizing defects and technical debt \n  Assist stakeholders including analytics, design, product, and executive teams with data-related technical issues \n  Ability to work independently with little instruction or direct oversight    Perform other duties as assigned \n \n \n  Minimum Qualifications \n \n  Bachelors in Computer Science or Data Engineering, related degree, or equivalent professional experience \n  3+ years relevant work experience within a complex, dynamic environment, with preference for experience with clinical healthcare data \n  3+ years architecting , implementing, and supporting data infrastructure and topologies \n \n \n  Experience building and operating highly available, distributed systems of extraction, ingestion, and processing of large data sets across a variety of applications (OLTP, OLAP and DSS)    3+ years Experience with Data warehousing, methodologies, modeling techniques, design patterns, and technologies. \n  Experience with data migration tools and deploying cloudbase solutions \n  Experience in writing advanced SQL (DML & DDL), including Stored Procedures, Indexes, user defined functions, windows functions, correlated subqueries and CTE's, and related data query and management technology \n  Coding ability in R, Python, and Shell Scripting to build and deploy Pipelines \n  Working knowledge of Git, or similar collaborative code management software \n  Experience with data integration tools such as FiveTran, DBT, Informatica, Matillion, or similar ETL/ELT tools \n  Experience with Snowflake\u2019s data platform \n \n \n  Preferred Qualifications \n ", "techs": ["snowflake", "etl", "elt", "mdm (master data management)", "ci/cd pipelines", "snowflake's data platform", "r", "python", "shell scripting", "git", "fivetran", "dbt", "informatica", "matillion"]}, "71795742664033dc": {"terms": ["data science", "machine learning engineer"], "salary_min": 109437.32, "salary_max": 138572.03, "title": "AI Lead Developer", "company": "Altria", "desc": "Overview: \n  \n  Are you looking for an opportunity to join a Fortune 200 company where your expertise and understanding of the Artificial Intelligence technology landscape can shape the future use of AI in driving business strategy? If so, we want to speak with you! \n \n \n  We are currently seeking an \n   AI Lead Developer  to join our team. \n   We are open to remote work arrangements. \n \n \n  You will work closely with the AI Principal Engineer and AI Solutions Architect to develop and implement AI models and applications. The ideal candidate will have a solid background with cloud development and a proven track record in leading and delivering projects on time and within budget.\n  \n \n  Key Responsibilities: \n \n \n \n  Develop and implement AI models and Azure applications \n Collaborate to ensure the successful delivery of AI projects \n Lead the development team and ensure that project timelines and budgets are met \n Evaluate new AI technologies and determine their potential impact on the business \n Develop and maintain relationships with key partners to ensure successful project outcomes \n Develop and implement best practices and standards for development \n \n \n \n  Requirements: \n \n \n \n  Bachelor's or Master's degree in Computer Science, Mathematics, or related field \n 7+ years of experience in development, including experience in leading development teams \n Solid understanding of cloud technologies or AI technologies such as machine learning, natural language processing, and computer vision \n Experience in designing and implementing AI models and/or Azure based applications \n Demonstrable ability to lead projects on time and within budget \n Strong communication and interpersonal skills, with the ability to work closely with multi-functional teams \n Experience working in an agile development environment \n \n \n \n  In addition to the opportunity to apply and develop your skills toward key business objectives, we offer an excellent compensation package including a competitive base salary, comprehensive health/vision/dental insurance, participation in our incentive compensation and deferred profit-sharing programs, as well as a relocation assistance package. \n  Company Overview: Altria has a leading portfolio of tobacco products for U.S. tobacco consumers 21+. Our tobacco companies \u2013 which have been the undisputed market leaders in the U.S. tobacco industry for decades \u2013 include some of the most enduring names in American business. In combustibles, we own Philip Morris USA, the maker of Marlboro cigarettes and John Middleton, manufacturer of Black & Mild cigars. Our smoke-free portfolio includes ownership of U.S. Smokeless Tobacco Company, the maker of Copenhagen and Skoal, and Helix Innovations, the maker of on! oral nicotine pouches. Additionally, we have a majority-owned joint venture with JT Group, Horizon Innovations, for the U.S. marketing and commercialization of heated tobacco stick products. Through a separate agreement with Philip Morris International, we have the exclusive U.S. commercialization rights to the IQOS* Tobacco Heating System\u00ae and Marlboro HeatSticks\u00ae through April 2024. Our equity investments include Anheuser-Busch InBev SA/NV, the world\u2019s largest brewer and Cronos Group, a leading Canadian cannabinoid company. Each Altria company is an equal opportunity employer. We are committed to providing individuals with criminal records, including formerly incarcerated individuals and individuals with conviction records, a fair chance at employment. Learn more about Altria at www.altria.com and follow us on Twitter, Facebook and LinkedIn", "cleaned_desc": " Solid understanding of cloud technologies or AI technologies such as machine learning, natural language processing, and computer vision \n Experience in designing and implementing AI models and/or Azure based applications \n Demonstrable ability to lead projects on time and within budget \n Strong communication and interpersonal skills, with the ability to work closely with multi-functional teams \n Experience working in an agile development environment \n \n \n ", "techs": ["machine learning", "natural language processing", "computer vision", "azure based applications", "agile development environment"]}, "46afedc7d92d5754": {"terms": ["data science", "data analyst", "machine learning engineer"], "salary_min": 106022.18, "salary_max": 134247.7, "title": "Sr. Data Analyst", "company": "Bainbridge, Inc.", "desc": "Sr. Data Analyst-BC Capital , LLC \n  Position location:  Remote (work from home, must be U.S. based) \n  Position Type:   Full-Time or Contract \n  Pay Scale:  $75,000.00-$150,000.00 (commensurate with experience) \n  How to Apply:  Please submit resume and cover letter \n \n  About Us \n  Bainbridge is Forbes-ranked, Strategy Analytics & Capital Advisory firm serving industry leaders across the Fortune 1000 to the small & mid-cap private US businesses. Founded out of MIT, Bainbridge has a strong technological and academic heritage that, along with its differentiated work-product, continues to make us the choice Strategy & Analytics partner for global firms. To serve our clients, we have an in-house B2B data analytics team, comprehensive marketing platform & a successful M&A platform, making Bainbridge a true laboratory of data, analytics & marketing-sciences driven execution. Every team member at Bainbridge is a product owner, leader & entrepreneur. We are a disruptive team of technologists and strategists that believe in innovating at every turn. If this approach resonates with you, we encourage you to apply to our company! \n \n  Position Summary:  \n Seeking an experienced Sr. Data Analyst responsible for utilizing their expertise in data analysis to drive strategic decisions, optimize business performance, and identify opportunities for growth. Ability to work with CapitalSphere management team to identify business KPI metrics, do analysis, submit reports, and make dashboards for CapitalSphere board members. \n  Responsibilities: \n \n  Data analysis and interpretation:  Collect, clean, and analyze large datasets using various tools and techniques. Apply statistical methods and data modeling to uncover trends, patterns, and insights. Interpret findings and present them in a clear and meaningful manner to stakeholders. \n  Strategic decision-making:  Collaborate with business stakeholders, managers, and executives to understand their requirements and provide data-driven insights and recommendations. Support strategic initiatives and help shape the organization's long-term goals. \n  Business performance optimization:  Identify areas of improvement within the organization by analyzing key performance indicators (KPIs) and operational metrics. Develop and implement data-driven strategies to enhance business processes, efficiency, and effectiveness. \n  Data visualization and reporting:  Create visually appealing and informative dashboards, reports, and presentations to communicate complex data analysis results to non-technical audiences. Use data visualization tools (such as Tableau, Power BI, or Excel) to illustrate trends, patterns, and key findings. \n  Data quality and integrity:  Ensure the accuracy, reliability, and consistency of data through data cleansing, validation, and quality assurance techniques. Develop and implement data governance processes and standards to maintain data integrity. \n  Data-driven insights:  Identify new data sources and implement data collection methodologies to gather relevant information for analysis. Stay up to date with industry trends, emerging technologies, and best practices in data analysis to continuously enhance analytical capabilities. \n  Team collaboration and leadership:  Collaborate with cross-functional teams, including data engineers, data scientists, and business stakeholders, to gather requirements, exchange insights, and deliver high-quality analysis. Provide mentorship and guidance to junior analysts and contribute to their professional development. \n  Technical expertise:  Possess strong proficiency in data analysis tools and programming languages (such as SQL, Python, R, or SAS). Have a deep understanding of data manipulation, data warehousing, and data visualization techniques. Stay updated with the latest advancements in data analysis methodologies and tools. \n  Project management:  Lead and manage data analysis projects from initiation to completion, ensuring timely delivery of high-quality results. Define project objectives, develop work plans, allocate resources, and monitor progress. Communicate project updates to stakeholders and address any issues or risks. \n  Data privacy and security:  Adhere to data privacy regulations and ensure the security of sensitive data throughout the data analysis process. Implement measures to protect data confidentiality and comply with relevant industry standards (such as GDPR or HIPAA). \n \n \n  Qualifications: \n \n  Advanced Degree:  A master's or Ph.D. in a quantitative field such as Data Science, Computer Science, Statistics, or Mathematics is typically required. \n  Technical Expertise : Proficiency in programming languages such as Python or R, along with expertise in data manipulation, statistical analysis, and machine learning techniques. \n  Data Engineering:  Experience in data wrangling, data preprocessing, and working with large-scale databases and distributed computing frameworks. \n  Analytical Skills:  Strong analytical thinking and problem-solving abilities, with a deep understanding of statistical methods, hypothesis testing, and experimental design. \n  Business Acumen:  The ability to translate complex data analysis into actionable insights and strategic recommendations for the organization. \n  Communication and Visualization:  Excellent written and verbal communication skills, with the ability to present complex findings to both technical and non-technical stakeholders using data visualizations and storytelling techniques. \n  Leadership and Mentoring:  Demonstrated leadership skills, with the ability to guide and mentor junior team members, provide technical direction, and collaborate effectively with cross-functional teams. \n  Industry Knowledge:  Familiarity with the specific industry or domain in which the organization operates, along with a deep understanding of the business goals and challenges. \n \n \n  Benefits: \n  We know that it is our people that make the difference. We are proud to offer a comprehensive benefits package to all full-time employees. \n \n  #LI-REMOTE \n   \n 3MWofFHjkq", "cleaned_desc": "  Data visualization and reporting:  Create visually appealing and informative dashboards, reports, and presentations to communicate complex data analysis results to non-technical audiences. Use data visualization tools (such as Tableau, Power BI, or Excel) to illustrate trends, patterns, and key findings. \n  Data quality and integrity:  Ensure the accuracy, reliability, and consistency of data through data cleansing, validation, and quality assurance techniques. Develop and implement data governance processes and standards to maintain data integrity. \n  Data-driven insights:  Identify new data sources and implement data collection methodologies to gather relevant information for analysis. Stay up to date with industry trends, emerging technologies, and best practices in data analysis to continuously enhance analytical capabilities. \n  Team collaboration and leadership:  Collaborate with cross-functional teams, including data engineers, data scientists, and business stakeholders, to gather requirements, exchange insights, and deliver high-quality analysis. Provide mentorship and guidance to junior analysts and contribute to their professional development. \n  Technical expertise:  Possess strong proficiency in data analysis tools and programming languages (such as SQL, Python, R, or SAS). Have a deep understanding of data manipulation, data warehousing, and data visualization techniques. Stay updated with the latest advancements in data analysis methodologies and tools. \n  Project management:  Lead and manage data analysis projects from initiation to completion, ensuring timely delivery of high-quality results. Define project objectives, develop work plans, allocate resources, and monitor progress. Communicate project updates to stakeholders and address any issues or risks. \n  Data privacy and security:  Adhere to data privacy regulations and ensure the security of sensitive data throughout the data analysis process. Implement measures to protect data confidentiality and comply with relevant industry standards (such as GDPR or HIPAA). \n   \n  Qualifications: \n \n  Advanced Degree:  A master's or Ph.D. in a quantitative field such as Data Science, Computer Science, Statistics, or Mathematics is typically required. \n  Technical Expertise : Proficiency in programming languages such as Python or R, along with expertise in data manipulation, statistical analysis, and machine learning techniques. \n  Data Engineering:  Experience in data wrangling, data preprocessing, and working with large-scale databases and distributed computing frameworks. \n  Analytical Skills:  Strong analytical thinking and problem-solving abilities, with a deep understanding of statistical methods, hypothesis testing, and experimental design. \n  Business Acumen:  The ability to translate complex data analysis into actionable insights and strategic recommendations for the organization. ", "techs": ["data visualization tools (tableau", "power bi", "excel)", "sql", "python", "r", "sas", "gdpr", "hipaa"]}, "038ae045a4dc338d": {"terms": ["data science"], "salary_min": 120000.0, "salary_max": 160000.0, "title": "Software Engineer (algorithms)", "company": "VivoSense", "desc": "VivoSense develops and validates real-world digital clinical measures and provides end-to-end services and solutions for their delivery in regulated clinical trials. \n \n  VivoSense: Data Algorithm Engineer \n  USA \u2013 Remote (accepting applicants in CA, CO, MA, MD, NJ, NY, NC, TX, FL, NV, OH, OR, GA) \n  About Us \n  Since 2010, VivoSense has been the premier science and technology company delivering end-to-end services and solutions for clients collecting clinical data from digital health technologies (DHTs), such as wearable sensors, mobile applications, and connected health monitoring tools. Working with drug developers, healthcare providers and academics, VivoSense develops and validates real-world digital clinical measures that matter to patients, and provides advanced software, analytics, and scientific expertise to improve the quality, accuracy, timeliness and ease of data analysis and insight generation from complex DHT data. \n  In 2022, VivoSense secured Series A financing, and we are growing our team as we evolve our software platform, establish R&D capabilities and expand our client-facing business. We are seeking a talented and motivated individual to join our science team to bring expertise and the highest levels of quality to our client partnerships. \n \n \n  Job Description \n  We are looking for an ambitious individual with a passion for learning new things, and a self-starter attitude. As a small company, this Data Algorithm Engineer will have the opportunity to come in on the ground floor, build greenfield products, enhance existing algorithms, design, and architect the solutions, and share in the success of our rapidly growing company. This person should be comfortable with navigating through an ambiguous environment, coming up with solutions that fit the user's needs, and then implementing them. \n  What you'll do: \n \n Develop and implement data algorithms and machine learning models for tasks such as signal processing, anomaly detection, classification, and prediction using biometric (physiological, anthropometric etc.) data. \n Utilize advanced signal processing and mathematical modeling principles to create and enhance algorithms tailored for applications in areas such as activity tracking and sleep analysis. \n Clean and preprocess raw physiological data to remove noise, outliers, and errors. Apply filtering, normalization, and feature extraction techniques to prepare the data for analysis. \n Evaluate the performance of different algorithms and models using appropriate metrics, such as accuracy, sensitivity, specificity, and AUC-ROC. Choose the best-performing models for specific tasks. \n Create informative data visualizations and dashboards to present biometric data and analysis results to healthcare professionals, researchers, and stakeholders. \n \n Who you are: \n \n Master's or Ph.D. in a field related to data science, machine learning, computer science, bioinformatics, biomedical engineering, \n Understanding physiological data and its clinical or research applications \n Proficiency in signal processing techniques of filtering, feature extraction, and time-series analysis \n Strong grasp of Programming, with fluency in Python / R / data manipulation libraries. \n Experience in developing and optimizing algorithms for data analysis and machine learning, particularly for physiological data applications. This includes anomaly detection, classification, prediction, and feature engineering. \n 0 to 6 years of experience (will accept no experience if PhD) \n \n \n \n  Nice to haves: \n \n Work within a regulated Quality Management System, such as ISO 13485 or 21CFR820 \n Able to work in a small team fast paced environment \n Experience / Knowledge with any of the following: \n \n AWS \n Medical terminology, healthcare regulations, and relevant physiological processes. \n \n \n Base Salary Range: \n  $120,000 - $160,000 DOE \n \n \n  Additional Benefits/Perks: \n \n \n Unlimited PTO \n \n \n Board approved stock options \n \n \n Board approved annual bonus \n \n \n Direct access to senior leadership \n \n \n Healthcare \n \n \n Vision/Dental \n \n \n Life Insurance \n \n \n Professional growth training \n \n \n 401K with Safeharbor employer contribution \n \n \n Remote work \n \n \n Flexible working hours \n \n \n Amazing culture and team to work with", "cleaned_desc": "VivoSense develops and validates real-world digital clinical measures and provides end-to-end services and solutions for their delivery in regulated clinical trials. \n \n  VivoSense: Data Algorithm Engineer \n  USA \u2013 Remote (accepting applicants in CA, CO, MA, MD, NJ, NY, NC, TX, FL, NV, OH, OR, GA) \n  About Us \n  Since 2010, VivoSense has been the premier science and technology company delivering end-to-end services and solutions for clients collecting clinical data from digital health technologies (DHTs), such as wearable sensors, mobile applications, and connected health monitoring tools. Working with drug developers, healthcare providers and academics, VivoSense develops and validates real-world digital clinical measures that matter to patients, and provides advanced software, analytics, and scientific expertise to improve the quality, accuracy, timeliness and ease of data analysis and insight generation from complex DHT data. \n  In 2022, VivoSense secured Series A financing, and we are growing our team as we evolve our software platform, establish R&D capabilities and expand our client-facing business. We are seeking a talented and motivated individual to join our science team to bring expertise and the highest levels of quality to our client partnerships. \n \n \n  Job Description \n  We are looking for an ambitious individual with a passion for learning new things, and a self-starter attitude. As a small company, this Data Algorithm Engineer will have the opportunity to come in on the ground floor, build greenfield products, enhance existing algorithms, design, and architect the solutions, and share in the success of our rapidly growing company. This person should be comfortable with navigating through an ambiguous environment, coming up with solutions that fit the user's needs, and then implementing them. \n  What you'll do: \n \n Develop and implement data algorithms and machine learning models for tasks such as signal processing, anomaly detection, classification, and prediction using biometric (physiological, anthropometric etc.) data. \n Utilize advanced signal processing and mathematical modeling principles to create and enhance algorithms tailored for applications in areas such as activity tracking and sleep analysis. \n Clean and preprocess raw physiological data to remove noise, outliers, and errors. Apply filtering, normalization, and feature extraction techniques to prepare the data for analysis.   Evaluate the performance of different algorithms and models using appropriate metrics, such as accuracy, sensitivity, specificity, and AUC-ROC. Choose the best-performing models for specific tasks. \n Create informative data visualizations and dashboards to present biometric data and analysis results to healthcare professionals, researchers, and stakeholders. \n \n Who you are: \n \n Master's or Ph.D. in a field related to data science, machine learning, computer science, bioinformatics, biomedical engineering, \n Understanding physiological data and its clinical or research applications \n Proficiency in signal processing techniques of filtering, feature extraction, and time-series analysis \n Strong grasp of Programming, with fluency in Python / R / data manipulation libraries. \n Experience in developing and optimizing algorithms for data analysis and machine learning, particularly for physiological data applications. This includes anomaly detection, classification, prediction, and feature engineering. \n 0 to 6 years of experience (will accept no experience if PhD) \n \n \n \n  Nice to haves: \n ", "techs": ["vivosense", "wearable sensors", "mobile applications", "connected health monitoring tools", "data algorithms", "machine learning models", "signal processing", "anomaly detection", "classification", "prediction", "biometric data", "advanced signal processing", "mathematical modeling", "activity tracking", "sleep analysis", "data visualization", "dashboards", "healthcare professionals", "researchers", "stakeholders", "data science", "machine learning", "computer science", "bioinformatics", "biomedical engineering", "python", "r", "data manipulation libraries", "algorithm optimization"]}, "ce3c9e470a7ad592": {"terms": ["data science"], "salary_min": 113842.055, "salary_max": 144149.4, "title": "Data Scientist - GameOps (eSports)", "company": "PrizePicks", "desc": "At PrizePicks, we are the fastest growing sports company in North America, as recognized by Inc. 5000. As the leading platform for Daily Fantasy Sports, we cover a diverse range of sports leagues, including the NFL, NBA, and Esports titles like League of Legends and CS:GO. Our team of over 350 employees thrives in an inclusive culture that values individuals from diverse backgrounds, regardless of their level of sports fandom. Ready to reimagine the DFS industry together? \n \n  The Analytics Team is responsible for building and maintaining analytics tools and workflows to support the PrizePicks business across all departments - at the core of these operations is data and the insights driven from that data. PrizePicks is looking for a Data Scientist with 2+ years of experience to join our Data Science team. You will be working closely with other data scientists, reporting analysts, and cross departmental directors to test business flows, make business recommendations, and provide novel business insights to leadership focused on driving revenue growth, optimizing marketing efficiency and optimizing retention efforts. \n  What you'll do: \n \n Conduct data cleaning operations, data wrangling, and create visualizations. \n Develop advanced data simulations to predict outcomes of upcoming esports games (League of Legends, Dota2, CSGO, CS2, etc). \n Participate in selecting features, building classifiers, and optimizing them using machine learning techniques under guidance. \n Play a role in the development of processes and tools for monitoring and analyzing model performance and data accuracy. \n \n What you have: \n \n Strong understanding of how various esports are played and modeled within data. \n Intermediate knowledge of machine learning, data analysis, and statistical modeling. \n Proficiency in statistics and statistical software applications, such as Python or R. \n Some practical experience with relational databases like PostgreSQL. \n Experience with data visualization and report building is a plus. \n Strong analytical and problem-solving skills, with the potential to grow in these areas. \n Demonstrated ability to work collaboratively and contribute to a team. \n \n Where you'll live: \n \n Anywhere in the US is fine but Atlanta would be preferred. \n \n Benefits you'll receive: \n  In addition to your great compensation package, company subsidized medical/dental/vision coverage plans and matching 401(k), we'll shower you with perks including: \n \n Break room with ping pong, endless snacks and in-office lunch once a week \n Unlimited PTO to encourage a healthy work/life balance (2 week min required!) \n Modern work schedule focused on getting the job done, not hours clocked \n Workplace flexibility  \n Company and team outings, we encourage a tight-knit workplace \n Generous Maternity AND Paternity leave (16 weeks!) \n Annual bonus & stock options  \n Wellness program \n Company equipment provided (Windows & Mac options) \n Annual performance reviews with opportunity for growth and career development \n \n \n \n  You must be authorized to work for any employer in the U.S. We are unable to sponsor or take over sponsorship of an employment Visa at this time. \n  PrizePicks is an Equal Opportunity Employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.", "cleaned_desc": " Play a role in the development of processes and tools for monitoring and analyzing model performance and data accuracy. \n \n What you have: \n \n Strong understanding of how various esports are played and modeled within data. \n Intermediate knowledge of machine learning, data analysis, and statistical modeling. \n Proficiency in statistics and statistical software applications, such as Python or R. \n Some practical experience with relational databases like PostgreSQL. ", "techs": ["python", "r", "postgresql"]}, "56e19962e353b1b3": {"terms": ["data science"], "salary_min": 93300.0, "salary_max": 212000.0, "title": "Data Scientist, Senior", "company": "Booz Allen Hamilton", "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Washington,DC,US \n         \n \n \n \n         Remote Work: \n         \n \n         Yes \n         \n \n \n \n         Job Number: \n         \n \n         R0182692\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Data Scientist, Senior\n           The Opportunity: \n  As an analytics professional, you\u2019re excited at the prospect of unlocking the secrets held by a data set, and you\u2019re fascinated by the possibilities presented by IoT, machine learning, and artificial intelligence. If you care about moving a mission forward as much as advancing the field of data science, this is the opportunity for you. Your deep data science and machine learning expertise, coupled with an original approach to your work, will guide clients and stakeholders as they make sense of their data and encourage actionable results. We\u2019re looking for someone like you to land and lead complex data exploration and analytics projects through your experience with machine learning development and deployment for a multitude of use cases in civilian U.S. agencies. \n \n  As an advanced data scientist and researcher on our AI team team, you\u2019ll learn and apply innovative AI and data science methodologies and deployment techniques to make a real-world impact on the mission of our civilian clients You\u2019ll grow your skills in data science, and machine learning operationalization process, and shape the future of analytics through a variety of means like white papers, client presentations, and client interactions. \n \n  We\u2019ll keep you sharp and moving forward in your career, with access to online courses, and the latest tools and methods. Whether you\u2019re using AI to find fraud or noncompliance, obtain operational efficiencies, improve citizen experience or other help other mission needs, you\u2019ll guide a team that serves critical missions from end to end. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  5+ years of experience with data science using open source tools such as R or Python \n  Experience creating models using machine learning techniques intended for operational decisions \n  Experience working with and presenting to non-technical clients \n  Experience with persuading stakeholders to take different courses of action \n  Ability to obtain and maintain a Public Trust or Suitability/Fitness determination based on client requirements \n  Bachelor's degree \n \n \n  Nice If You Have: \n \n  Experience with the aspects full life cycle of machine learning development and deployment, including gathering requirements, identifying data, preparing data, building, validating, and using deployable predictive models with the usage having tangible results \n  Experience with providing technical direction and leadership to data scientists \n  Experience with developing predictive models around fraud, risk, or rare events \n  Experience with cloud AI environments, such as Databricks, Azure ML, or AWS Sagemaker \n  Knowledge of Agile and Scrum processes \n  Possession of excellent verbal and written communication skills \n \n  Vetting:  Applicants selected will be subject to a government investigation and may need to meet eligibility requirements of the U.S. government client. \n  Create Your Career: \n \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll build your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $93,300.00 to $212,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.", "cleaned_desc": " \n \n \n \n \n \n \n \n         Data Scientist, Senior\n           The Opportunity: \n  As an analytics professional, you\u2019re excited at the prospect of unlocking the secrets held by a data set, and you\u2019re fascinated by the possibilities presented by IoT, machine learning, and artificial intelligence. If you care about moving a mission forward as much as advancing the field of data science, this is the opportunity for you. Your deep data science and machine learning expertise, coupled with an original approach to your work, will guide clients and stakeholders as they make sense of their data and encourage actionable results. We\u2019re looking for someone like you to land and lead complex data exploration and analytics projects through your experience with machine learning development and deployment for a multitude of use cases in civilian U.S. agencies. \n \n  As an advanced data scientist and researcher on our AI team team, you\u2019ll learn and apply innovative AI and data science methodologies and deployment techniques to make a real-world impact on the mission of our civilian clients You\u2019ll grow your skills in data science, and machine learning operationalization process, and shape the future of analytics through a variety of means like white papers, client presentations, and client interactions. \n \n  We\u2019ll keep you sharp and moving forward in your career, with access to online courses, and the latest tools and methods. Whether you\u2019re using AI to find fraud or noncompliance, obtain operational efficiencies, improve citizen experience or other help other mission needs, you\u2019ll guide a team that serves critical missions from end to end. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  5+ years of experience with data science using open source tools such as R or Python    Experience creating models using machine learning techniques intended for operational decisions \n  Experience working with and presenting to non-technical clients \n  Experience with persuading stakeholders to take different courses of action \n  Ability to obtain and maintain a Public Trust or Suitability/Fitness determination based on client requirements \n  Bachelor's degree \n \n \n  Nice If You Have: \n \n  Experience with the aspects full life cycle of machine learning development and deployment, including gathering requirements, identifying data, preparing data, building, validating, and using deployable predictive models with the usage having tangible results \n  Experience with providing technical direction and leadership to data scientists \n  Experience with developing predictive models around fraud, risk, or rare events \n  Experience with cloud AI environments, such as Databricks, Azure ML, or AWS Sagemaker \n  Knowledge of Agile and Scrum processes \n  Possession of excellent verbal and written communication skills \n \n  Vetting:  Applicants selected will be subject to a government investigation and may need to meet eligibility requirements of the U.S. government client. \n  Create Your Career: \n \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. ", "techs": ["r", "python", "machine learning", "artificial intelligence", "iot", "white papers", "online courses", "open source tools", "databricks", "azure ml", "aws sagemaker", "agile", "scrum"]}, "f9e50f3012946c3b": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Director Data Engineering", "company": "Providence", "desc": "Description \n This position is remote with some in person meetings required and can only be located in the states of WA, OR, or CA. \n Leads highly technical data engineers. Accountable for all aspects of the technical design and build of modern data-centric solutions and applications to support clinical and operational processes across all parts of the enterprise health system. These solutions leverage cloud, big data, data science, and modern software development methodologies (such as SAFe) and tools and services (such as Snowflake and Databricks in Azure). Responsible for the buildout of our data engineering center of excellence for the enterprise and a community of practice across teams. Collaborates on technical solutions with teams at the Providence Global Center at Hyderabad, India. \n Providence caregivers are not simply valued \u2013 they\u2019re invaluable. Join our team at Enterprise Information Services and thrive in our culture of patient-focused, whole-person care built on understanding, commitment, and mutual respect. Your voice matters here, because we know that to inspire and retain the best people, we must empower them. \n Required Qualifications: \n \n Bachelor's Degree - Computer Engineering, Computer Science, Mathematics, Engineering. Or equivalent educ/experience, \n 10 or more years - Related experience in engineering or development roles. \n 8 years Leadership experience leading teams in a complex and fast-paced moving environment. \n Experience in cloud computing and data warehousing, Linux, Hadoop, Spark, and other NoSQL platforms. \n Strong experience working with both the product and technical sides of issues. \n Practical solutions development experience in a data-centric domain. \n Strong experience in managing and coaching a team of technical resources. \n \n Preferred Qualifications: \n \n Bachelor's Degree in Computer Science and Engineering, Mathematics, Engineering and related technical fields. \n \n The salary range listed for this position MIN:$79.20 to MAX:$131.66 per hour is based upon the primary work location Renton, WA posted. This position is remote. Salary range and offers are determined by internal pay equity and geographic cost of living differences. Salary range will vary from State and region. Salary max is limited to 75% range in order to continue to offer internal pay growth. We welcome open and transparent discussions on salary at Providence. \n Why Join Providence? \n Our best-in-class benefits are uniquely designed to support you and your family in staying well, growing professionally, and achieving financial security. We take care of you, so you can focus on delivering our Mission of caring for everyone, especially the most vulnerable in our communities. \n About Providence \n At Providence, our strength lies in Our Promise of \u201cKnow me, care for me, ease my way.\u201d Working at our family of organizations means that regardless of your role, we\u2019ll walk alongside you in your career, supporting you so you can support others. We provide best-in-class benefits and we foster an inclusive workplace where diversity is valued, and everyone is essential, heard and respected. Together, our 120,000 caregivers (all employees) serve in over 50 hospitals, over 1,000 clinics and a full range of health and social services across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. As a comprehensive health care organization, we are serving more people, advancing best practices and continuing our more than 100-year tradition of serving the poor and vulnerable. \n The amounts listed are the base pay range; additional compensation may be available for this role, such as shift differentials, standby/on-call, overtime, premiums, extra shift incentives, or bonus opportunities. \n Check out our benefits page for more information about our Benefits and Rewards. \n About the Team \n Providence Shared Services is a service line within Providence that provides a variety of functional and system support services for our family of organizations across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. We are focused on supporting our Mission by delivering a robust foundation of services and sharing of specialized expertise. \n We are committed to the principle that every workforce member has the right to work in surroundings that are free from all forms of unlawful discrimination and harassment. \n We are committed to cultural diversity and equal employment for all individuals. It is our policy to recruit, hire, promote, compensate, transfer, train, retain, terminate, and make all other employment-related decisions without regard to race, color, religious creed (including religious dress and grooming practices), national origin (including certain language use restrictions), ancestry, disability (mental and physical including HIV and AIDS), medical condition (including cancer and genetic characteristics), genetic information, marital status, age, sex (which includes pregnancy, childbirth, breastfeeding and related medical conditions), gender, gender identity, gender expression, sexual orientation, genetic information, and military and veteran status or any other applicable legally protected status. We will also provide reasonable accommodation to known physical or mental limitations of an otherwise qualified caregiver or applicant for employment, unless the accommodation would impose undue hardship on the operation of our business. \n We are a community where all people, regardless of differences, are welcome, secure, and valued. We value respect, appreciation, collaboration, diversity, and a shared commitment to serving our communities. We expect that all workforce members in our community will act in ways which reflect a commitment to and accountability for, racial and social justice and equality in the workplace. As such, we will maintain a workplace free of discrimination and harassment based on any applicable legally protected status. We also expect that all workforce members will maintain a positive workplace free from any unacceptable conduct which creates an intimidating, hostile, or offensive work environment. \n Requsition ID:  226882  \n Company:  Providence Jobs  \n Job Category:  Development/Engineering  \n Job Function:  Information Technology  \n Job Schedule:  Full time  \n Job Shift:  Day  \n Career Track:  Leadership  \n Department:  4011 SS IS HI DP 3  \n Address:  WA Renton 1801 Lind Ave SW  \n Work Location:  Providence Valley Office Park-Renton  \n Pay Range:  $79.20 - $131.66  \n The amounts listed are the base pay range; additional compensation may be available for this role, such as shift differentials, standby/on-call, overtime, premiums, extra shift incentives, or bonus opportunities.  \n Check out our benefits page for more information about our Benefits and Rewards. \n Providence is proud to be an Equal Opportunity Employer. Providence does not discriminate on the basis of race, color, gender, disability, veteran, military status, religion, age, creed, national origin, sexual identity or expression, sexual orientation, marital status, genetic information, or any other basis prohibited by local, state, or federal law.", "cleaned_desc": " 8 years Leadership experience leading teams in a complex and fast-paced moving environment. \n Experience in cloud computing and data warehousing, Linux, Hadoop, Spark, and other NoSQL platforms. \n Strong experience working with both the product and technical sides of issues. \n Practical solutions development experience in a data-centric domain. \n Strong experience in managing and coaching a team of technical resources. \n \n Preferred Qualifications: \n ", "techs": ["cloud computing", "data warehousing", "linux", "hadoop", "spark", "nosql platforms"]}, "42132be136ff18fe": {"terms": ["data science"], "salary_min": 175491.12, "salary_max": 222210.88, "title": "Head of Data Analytics", "company": "Professional Search Group, Inc.", "desc": "Job Title:  Head of Data Analytics \n \n  We are actively seeking a highlyexperienced Head of Data Analytics to lead our client's data-driven initiatives. They are a growing provider of technology and consulting solutions within Insurance and Highly Regulated Markets. \n \n  The ideal candidate will be responsible for developing and implementing data strategies, leading a team of analysts, and driving data-driven decision-making within the organization. \n \n \n Key Responsibilities: \n  Develop and execute the company's data strategy to drive business growth and enhance decision-making. \n \n  Lead and mentor a team of data analysts, fostering a culture of continuous learning and professional development. \n \n  Oversee data collection, analysis, and reporting, ensuring data accuracy and consistency. \n \n  Collaborate with cross-functional teams to identify data-driven insights and opportunities. \n \n  Create and maintain data governance policies and procedures to safeguard data integrity and compliance. \n \n  Stay up-to-date with industry trends and emerging technologies in data analytics and recommend their integration as needed. \n \n  Prepare and deliver clear and concise reports and data-driven recommendations to senior management. \n \n \n Qualifications: \n  Bachelor's degree in a relevant field (e.g., Data Science, Statistics, Computer Science), Master's degree preferred. \n \n  Proven experience in a leadership role within data analytics, with a minimum of 8 years of experience. \n \n  Strong expertise in data analysis, data visualization, and data management tools and platforms. \n \n  Exceptional problem-solving and critical-thinking abilities. \n \n  Excellent communication and interpersonal skills. \n \n  Proficiency in programming languages (e.g., Python, R) and data analysis software. \n \n  Strong project management skills and experience leading data-related projects. \n \n  Ability to work independently in a remote setting while maintaining high levels of productivity and confidentiality. \n \n \n Location:  Remote - Must be in US. Not considering sponsorship of any kind. Must be free to work for any employer with no need for additional sponsorship.", "cleaned_desc": "  Bachelor's degree in a relevant field (e.g., Data Science, Statistics, Computer Science), Master's degree preferred. \n \n  Proven experience in a leadership role within data analytics, with a minimum of 8 years of experience. \n \n  Strong expertise in data analysis, data visualization, and data management tools and platforms. \n \n  Exceptional problem-solving and critical-thinking abilities. \n    Excellent communication and interpersonal skills. \n \n  Proficiency in programming languages (e.g., Python, R) and data analysis software. \n \n  Strong project management skills and experience leading data-related projects. \n \n  Ability to work independently in a remote setting while maintaining high levels of productivity and confidentiality. \n ", "techs": ["python", "r"]}, "7558a840bfa4768d": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Director Data Engineering", "company": "Providence", "desc": "Description \n This position is remote with some in person meetings required and can only be located in the states of WA, OR, or CA. \n Leads highly technical data engineers. Accountable for all aspects of the technical design and build of modern data-centric solutions and applications to support clinical and operational processes across all parts of the enterprise health system. These solutions leverage cloud, big data, data science, and modern software development methodologies (such as SAFe) and tools and services (such as Snowflake and Databricks in Azure). Responsible for the buildout of our data engineering center of excellence for the enterprise and a community of practice across teams. Collaborates on technical solutions with teams at the Providence Global Center at Hyderabad, India. \n Providence caregivers are not simply valued \u2013 they\u2019re invaluable. Join our team at Enterprise Information Services and thrive in our culture of patient-focused, whole-person care built on understanding, commitment, and mutual respect. Your voice matters here, because we know that to inspire and retain the best people, we must empower them. \n Required Qualifications: \n \n Bachelor's Degree - Computer Engineering, Computer Science, Mathematics, Engineering. Or equivalent educ/experience, \n 10 or more years - Related experience in engineering or development roles. \n 8 years Leadership experience leading teams in a complex and fast-paced moving environment. \n Experience in cloud computing and data warehousing, Linux, Hadoop, Spark, and other NoSQL platforms. \n Strong experience working with both the product and technical sides of issues. \n Practical solutions development experience in a data-centric domain. \n Strong experience in managing and coaching a team of technical resources. \n \n Preferred Qualifications: \n \n Bachelor's Degree in Computer Science and Engineering, Mathematics, Engineering and related technical fields. \n \n The salary range listed for this position MIN:$79.20 to MAX:$131.66 per hour is based upon the primary work location Renton, WA posted. This position is remote. Salary range and offers are determined by internal pay equity and geographic cost of living differences. Salary range will vary from State and region. Salary max is limited to 75% range in order to continue to offer internal pay growth. We welcome open and transparent discussions on salary at Providence. \n Why Join Providence? \n Our best-in-class benefits are uniquely designed to support you and your family in staying well, growing professionally, and achieving financial security. We take care of you, so you can focus on delivering our Mission of caring for everyone, especially the most vulnerable in our communities. \n About Providence \n At Providence, our strength lies in Our Promise of \u201cKnow me, care for me, ease my way.\u201d Working at our family of organizations means that regardless of your role, we\u2019ll walk alongside you in your career, supporting you so you can support others. We provide best-in-class benefits and we foster an inclusive workplace where diversity is valued, and everyone is essential, heard and respected. Together, our 120,000 caregivers (all employees) serve in over 50 hospitals, over 1,000 clinics and a full range of health and social services across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. As a comprehensive health care organization, we are serving more people, advancing best practices and continuing our more than 100-year tradition of serving the poor and vulnerable. \n The amounts listed are the base pay range; additional compensation may be available for this role, such as shift differentials, standby/on-call, overtime, premiums, extra shift incentives, or bonus opportunities. \n Check out our benefits page for more information about our Benefits and Rewards. \n About the Team \n Providence Shared Services is a service line within Providence that provides a variety of functional and system support services for our family of organizations across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. We are focused on supporting our Mission by delivering a robust foundation of services and sharing of specialized expertise. \n We are committed to the principle that every workforce member has the right to work in surroundings that are free from all forms of unlawful discrimination and harassment. \n We are committed to cultural diversity and equal employment for all individuals. It is our policy to recruit, hire, promote, compensate, transfer, train, retain, terminate, and make all other employment-related decisions without regard to race, color, religious creed (including religious dress and grooming practices), national origin (including certain language use restrictions), ancestry, disability (mental and physical including HIV and AIDS), medical condition (including cancer and genetic characteristics), genetic information, marital status, age, sex (which includes pregnancy, childbirth, breastfeeding and related medical conditions), gender, gender identity, gender expression, sexual orientation, genetic information, and military and veteran status or any other applicable legally protected status. We will also provide reasonable accommodation to known physical or mental limitations of an otherwise qualified caregiver or applicant for employment, unless the accommodation would impose undue hardship on the operation of our business. \n We are a community where all people, regardless of differences, are welcome, secure, and valued. We value respect, appreciation, collaboration, diversity, and a shared commitment to serving our communities. We expect that all workforce members in our community will act in ways which reflect a commitment to and accountability for, racial and social justice and equality in the workplace. As such, we will maintain a workplace free of discrimination and harassment based on any applicable legally protected status. We also expect that all workforce members will maintain a positive workplace free from any unacceptable conduct which creates an intimidating, hostile, or offensive work environment. \n Requsition ID:  226882  \n Company:  Providence Jobs  \n Job Category:  Development/Engineering  \n Job Function:  Information Technology  \n Job Schedule:  Full time  \n Job Shift:  Day  \n Career Track:  Leadership  \n Department:  4011 SS IS HI DP 3  \n Address:  WA Renton 1801 Lind Ave SW  \n Work Location:  Providence Valley Office Park-Renton  \n Pay Range:  $79.20 - $131.66  \n The amounts listed are the base pay range; additional compensation may be available for this role, such as shift differentials, standby/on-call, overtime, premiums, extra shift incentives, or bonus opportunities.  \n Check out our benefits page for more information about our Benefits and Rewards. \n Providence is proud to be an Equal Opportunity Employer. Providence does not discriminate on the basis of race, color, gender, disability, veteran, military status, religion, age, creed, national origin, sexual identity or expression, sexual orientation, marital status, genetic information, or any other basis prohibited by local, state, or federal law.", "cleaned_desc": " 8 years Leadership experience leading teams in a complex and fast-paced moving environment. \n Experience in cloud computing and data warehousing, Linux, Hadoop, Spark, and other NoSQL platforms. \n Strong experience working with both the product and technical sides of issues. \n Practical solutions development experience in a data-centric domain. \n Strong experience in managing and coaching a team of technical resources. \n \n Preferred Qualifications: \n ", "techs": ["cloud computing", "data warehousing", "linux", "hadoop", "spark", "nosql platforms"]}, "bb58c9d3cf52e52e": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Director of Client Analytics", "company": "Vanco", "desc": "Description: \n   At Vanco, we serve those who enrich our communities. Vanco provides businesses, nonprofits and educational organizations a complete range of payment solutions and administrative software. Our solutions make payment processing simple and ease administrative burdens for faith-based groups, nonprofits and schools. We are a software payments company for community organizations, and every transaction tells a story. \n  The Team \n  Client Analytics at Vanco is part of the data team which also includes of Business Intelligence and Enterprise Data Management (Data Engineering). We are responsible for analytics, data warehousing, business data, and client data. We use state of the art tools and technology to enable data-driven performance inside the company and with our employees. We come from a variety of backgrounds, but our common ground is that we are curious, attentive to detail, and biased to action. We relentlessly pursue answers and serve up our best analysis and solutions for each project and challenge we face. \n  The Role \n  Vanco has a huge opportunity to serve our clients and attract new ones through the development of embedded analytics, data products, and data services. As Director of Client Analytics, you will be building a new team that collaborates with the product organization to build and own these products and features. This role is a technical lead. You are expected to use your extensive knowledge and experience of data tools and design to create long-lasting solutions to serve our clients. This role is also a management role overseeing both contract and regular employees that will be experts at building and maintaining our client-facing data environment.  Requirements:\n  \n  Requirements \n \n  College degree in Data Analytics, Finance, Statistics, Computer Science, or related quantitative field. \n  Extensive experience with analytics, data science, business intelligence in a medium or large business \n  Experience with Sigma, Looker and other common data reporting platforms \n  Experience with Snowflake and other common data warehousing tools \n  10+ years\u2019 experience in client-facing analytics work \n  Understanding of data warehousing, data management, data structures, and pro-level relational database knowledge. \n  Demonstrable project management skills \n  Outstanding communications skills with both technical and non-technical colleagues. \n  Strong organizational skills, time management, portfolio prioritization experience, and accountability required.", "cleaned_desc": "  College degree in Data Analytics, Finance, Statistics, Computer Science, or related quantitative field. \n  Extensive experience with analytics, data science, business intelligence in a medium or large business \n  Experience with Sigma, Looker and other common data reporting platforms    Experience with Snowflake and other common data warehousing tools \n  10+ years\u2019 experience in client-facing analytics work \n  Understanding of data warehousing, data management, data structures, and pro-level relational database knowledge. ", "techs": ["college degree in data analytics", "finance", "statistics", "computer science\nextensive experience with analytics", "data science", "business intelligence\nexperience with sigma", "looker and other common data reporting platforms\nexperience with snowflake and other common data warehousing tools\n10+ years\u2019 experience in client-facing analytics work\nunderstanding of data warehousing", "data management", "data structures\npro-level relational database knowledge"]}, "fb41e5a1200e0e8b": {"terms": ["data science"], "salary_min": 78346.96, "salary_max": 99204.71, "title": "Property Claims Adjuster, Wind & Hail (Remote, US)", "company": "Openly", "desc": "Openly is rebuilding insurance from the ground up. We are re-envisioning and enhancing every aspect of the customer experience. Doing this requires a rapidly growing team of exceptional, curious, empathetic people with a wide range of skill sets, spanning technology, data science, product, marketing, sales, service, claims handling, finance, etc. \n  Now is the perfect time to join the journey. Here's why \n \n It's working . We're in multiple states and on our way to operating countrywide. We have thousands of agents selling our product and millions of dollars of annual customer premiums. \n We're well-backed & stable.  We closed our $100M Series D fundraise. We are supported by some of the top investors globally, including Google's \"Gradient\" AI-focused fund, Obvious Ventures, Advance Venture Partners, Eden Global Partners, and Clocktower Technology Ventures. \n It's not too late!  Despite this traction and stability, we're still early enough in the journey that there's time to make a real difference during Openly's formative period. \n \n If you'd like to understand more about Openly's mission, consider checking out this video (https://vimeo.com/267654520) from a company pitch we gave several years ago at Techstars. \n \n \n \n  Job Details \n  Openly is building an advanced claims organization leveraging technology and experienced property claims professionals to build a best-in-class end-to-end customer experience. This role is a remote-only position and applicants must have an adequate working environment. \n \n \n  Knowledge, Skills, and Abilities \n \n Full knowledge of insurance contracts, investigation techniques, legal requirements, and insurance regulations. \n Ability to work effectively in teams and with a wide variety of people. \n An aptitude for evaluating, analyzing, and interpreting information. \n \n Excellent skills in the areas of: \n \n Customer service \n Investigation techniques \n Organization \n Time management and the ability to multitask \n Verbal and written communication \n Negotiation and reserving \n Problem solving \n Innovative thinking and Continuous Improvement \n Current Claims Adjuster licenses in one or more states preferred but must be able to obtain additional state licenses \n \n \n \n  Key Responsibilities \n  End to end property claim handling to include: \n \n Provide superior customer service \n Investigation and coverage analysis \n Complete estimates using CoreLogic estimating software \n Adhering to estimating best practices \n Manage and collaborate with vendor partners \n Determine appropriate method of inspection \n Conduct virtual inspections (video, AI, etc) \n Examines potential subrogation and identifies potential fraudulent issues. \n Prepares and maintains file documentation \n Negotiates settlement of claims with insureds, claimants and vendors. Discussing and giving updates to insureds, claimants, agents and leadership throughout the process \n Provide input and ideas for continuous process improvement \n Be logged into phone queues to assist customers \n Work CAT hours during storm events or times of high volume as needed \n \n \n \n  Requirements \n \n 5+ years in property claims experience required \n 5+ years in customer service and conflict resolution required \n Field and desk/virtual claim handling experience with Wind & Hail claims required \n Catastrophe claim handling experience preferred \n Must be willing to work extended hours during high CAT volume (CAT Pay included) \n Experience with other perils is a plus; otherwise, must be willing to expand knowledge and learning to include other perils beyond Wind & Hail \n Education equivalent to a college degree \n Must be able and eligible to acquire an adjuster licenses in all required states and maintain it as a condition of continued employment \n Estimating experience in CoreLogic (preferred), Xactimate, or similar platform \n Experience working independently and in a fast-paced environment \n Proficient in Microsoft and Google Products \n Must be tech savvy as high end technology tools will be used for adjusting (virtual inspections, estimating, etc.) \n We are a rapidly growing company, with growth comes change. Candidates must be comfortable with constant change, adaptability and flexibility. \n \n  #LI-HK1 \n \n  Benefits & Perks \n \n Remote-First Culture - We supported #remotelife long before it was a given. We'll keep promoting it. \n Competitive Salary & Equity \n Comprehensive Medical, Dental, and Vision Plan Offerings \n Life and disability coverage including voluntary options \n Competitive PTO - 20 days and 11 paid holidays (including floating holidays) per year under the Company's vacation and holiday policies.  \n Parental Leave - 12 weeks paid for eligible employees \n 401K Company Contribution - Openly contributes 3% of the employee's gross income, even if the employee does not contribute. \n Work-from-home stipend - We provide a $1,500 allowance to spend on setting up your home workplace \n Annual Professional Development Fund: Each employee has $2,000 in professional development (PD) funds to spend on activities or resources annually. We want each Openly employee to achieve personal and professional success and to feel supported, confident, and informed about improving their efficiency and productivity. \n Be Well Program - Employees receive $50 per month to use towards your overall well-being \n Paid Volunteer Service Hours \n Referral Program and Reward \n \n Depending on position, Employees generally are eligible for cash incentive compensation, including commissions for sales eligible roles. In all cases, eligibility for compensation and benefits is subject to applicable plan and policy terms in effect from time to time. \n  U.S. Citizens, Green Card Holders, and those authorized to work in the U.S. for any employer and currently residing in the US will be considered. \n  Openly is committed to equal employment opportunity and non-discrimination for all employees and qualified applicants without regard to a person's race, color, sex, gender identity or expression, age, religion, national origin, ancestry, ethnicity, disability, veteran status, genetic information, sexual orientation, marital status, or any characteristic protected under applicable law. Openly is an E-Verify Employer in the United States. Openly will make reasonable accommodations for qualified individuals with known disabilities under applicable law.", "cleaned_desc": "", "techs": ""}, "77c120f03b258fd4": {"terms": ["data science"], "salary_min": 170000.0, "salary_max": 190000.0, "title": "Senior Data Architect", "company": "GE Healthcare", "desc": "Job Description Summary  The Senior Data Architect is responsible for designing and managing the data infrastructure needed to support all Caption Health products. Duties include identifying the company\u2019s internal and external data sources, developing company data standards, documenting, and optimizing data flows, collaborating with department heads to determine their data needs, and developing the infrastructure and processes to manage all data securely. Design and build out the enterprise data warehouse (EDW).\n  \n  Job Description \n  Caption Health\u2019s mission is to detect disease early \u2013 when there is the highest potential for impact \u2013 by leveraging artificial intelligence and ultrasound. Our breakthrough AI platform enables any healthcare professional to perform high-quality ultrasound exams for early disease detection, in convenient and lower-cost outpatient settings including patients\u2019 homes. It was recognized as one of TIME\u2019s 100 Best Inventions of 2021 and one of Fast Company\u2019s Next Big Things in Health Tech. Through our work with health plans, providers, patients, and industry partners, we are transforming care, expanding access, and reducing costs. \n \n \n  Duties/Responsibilities: \n \n  Own companydata architecture and standards. \n  Design and implement effective database solutions and models to store and retrieve company data. \n  Build and manage data infrastructure, including but not limited to: patient demographic and visit details,DICOM ultrasound scans and associated meta data, productdata stores and data flows. \n  Ensure data storagemeets government regulations and guidelines for technical systems and safeguarding of data, including international data compliance. \n  Define data securityand backup procedures. \n  Define disaster recoverystrategy. \n  Determine data storage strategyto minimize cloud storage cost. \n  Design and build Caption Health\u2019senterprise data warehouse. \n  Design and build ETL tools for data migration into EDW. \n  Help integrate BI tools to the EDW and establish standardreports. \n  Perform other dutiesas assigned. \n \n \n  Required  Knowledge/ Skills/Abilities: \n \n  Proven work experience as a Data Architect. \n  In-depth understanding of database structureprinciples. \n  Experience gathering and analyzing systemrequirements. \n  Knowledge of data mining and segmentation techniques. \n  Expertise in SQL and Postgresdatabase administration. \n  Excellent verbal and writtencommunication skills. \n  Proficient with MicrosoftOffice 365 or similar software. \n  Experience with BI tools, DOMO, PowerBI. \n  Use of modeling tools to create and maintain an ERD + data dictionary. \n  Understanding of software lifecycle, versioning, automated deployment. \n  Plus: experience with Azure Cloud. \n  Plus: experience with Github. \n \n  Education and  Experience: \n \n  Bachelor's degreein computer science,information systems, or a similarfield. \n  A minimum of 8-10 years\u2019experience in a similar role. \n  Planning and execution of big data solutions in healthcare experience preferred. \n \n \n  We expect all employees to live and breathe our behaviors: to act with humility and build trust; lead with transparency; deliver with focus, and drive ownership \u2013always with unyielding integrity. \n \n  Our total rewards are designed to unlock your ambition by giving you the boost and flexibility you need to turn your ideas into world-changing realities. Our salary and benefits are everything you\u2019d expect from an organization with global strength and scale, and you\u2019ll be surrounded by career opportunities in a culture that fosters care, collaboration and support. \n \n  While GE Healthcare does not currently require U.S. employees to be vaccinated against COVID-19, some GE Healthcare customers have vaccination mandates that may apply to certain GE Healthcare employees. \n \n  GE offers a great work environment, professional development, challenging careers, and competitive compensation. GE is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law. \n \n  GE will only employ those who are legally authorized to work in the United States for this opening. Any offer of employment is conditioned upon the successful completion of a drug screen (as applicable). \n \n  For U.S. based positions only, the pay range for this position is 170,000.00 -190,000.00 USD Annual. It is not typical for an individual to be hired at or near the top of the pay range and compensation decisions are dependent on the facts and circumstances of each case. The specific compensation offered to a candidate may be influenced by a variety of factors including skills, qualifications, experience and location. In addition, this position may also be eligible to earn performance-based incentive compensation, which may include cash bonus(es) and/or long-term incentives (LTI). GE HealthCare offers a competitive benefits package, including not but limited to medical, dental, vision, paid time off, a 401(k) plan with employee and company contribution opportunities, life, disability, and accident insurance, and tuition reimbursement. \n \n  #LI-MH1 \n  #LI-Remote \n \n  Additional Information \n \n \n \n \n \n \n \n  GE offers a great work environment, professional development, challenging careers, and competitive compensation. GE is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  GE will only employ those who are legally authorized to work in the United States for this opening. Any offer of employment is conditioned upon the successful completion of a drug screen (as applicable).  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Relocation Assistance Provided:  No", "cleaned_desc": "Job Description Summary  The Senior Data Architect is responsible for designing and managing the data infrastructure needed to support all Caption Health products. Duties include identifying the company\u2019s internal and external data sources, developing company data standards, documenting, and optimizing data flows, collaborating with department heads to determine their data needs, and developing the infrastructure and processes to manage all data securely. Design and build out the enterprise data warehouse (EDW).\n  \n  Job Description \n  Caption Health\u2019s mission is to detect disease early \u2013 when there is the highest potential for impact \u2013 by leveraging artificial intelligence and ultrasound. Our breakthrough AI platform enables any healthcare professional to perform high-quality ultrasound exams for early disease detection, in convenient and lower-cost outpatient settings including patients\u2019 homes. It was recognized as one of TIME\u2019s 100 Best Inventions of 2021 and one of Fast Company\u2019s Next Big Things in Health Tech. Through our work with health plans, providers, patients, and industry partners, we are transforming care, expanding access, and reducing costs. \n \n \n  Duties/Responsibilities: \n \n  Own companydata architecture and standards. \n  Design and implement effective database solutions and models to store and retrieve company data. \n  Build and manage data infrastructure, including but not limited to: patient demographic and visit details,DICOM ultrasound scans and associated meta data, productdata stores and data flows. \n  Ensure data storagemeets government regulations and guidelines for technical systems and safeguarding of data, including international data compliance. \n  Define data securityand backup procedures. \n  Define disaster recoverystrategy. \n  Determine data storage strategyto minimize cloud storage cost. \n  Design and build Caption Health\u2019senterprise data warehouse. \n  Design and build ETL tools for data migration into EDW. \n  Help integrate BI tools to the EDW and establish standardreports. \n  Perform other dutiesas assigned.   \n \n  Required  Knowledge/ Skills/Abilities: \n \n  Proven work experience as a Data Architect. \n  In-depth understanding of database structureprinciples. \n  Experience gathering and analyzing systemrequirements. \n  Knowledge of data mining and segmentation techniques. \n  Expertise in SQL and Postgresdatabase administration. \n  Excellent verbal and writtencommunication skills. \n  Proficient with MicrosoftOffice 365 or similar software. \n  Experience with BI tools, DOMO, PowerBI. \n  Use of modeling tools to create and maintain an ERD + data dictionary. \n  Understanding of software lifecycle, versioning, automated deployment. \n  Plus: experience with Azure Cloud. \n  Plus: experience with Github. \n \n  Education and  Experience: \n ", "techs": ["postgres", "sql", "domo", "powerbi", "erd", "data dictionary", "azure cloud", "github"]}, "bbed8c6c18ccfc30": {"terms": ["data science", "machine learning engineer"], "salary_min": 73100.0, "salary_max": 166000.0, "title": "Machine Learning Engineer", "company": "Booz Allen Hamilton", "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Washington,DC,US \n         \n \n \n \n         Remote Work: \n         \n \n         Hybrid \n         \n \n \n \n         Job Number: \n         \n \n         R0182783\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Machine Learning Engineer\n          \n  The Opportunity: \n  Do you enjoy creating innovative solutions to complex challenges while working within a community of dynamic technology professionals? As an experienced data professional, you know that machine learning is critical to understanding and processing massive datasets. We need your technical expertise to support federal healthcare. \n \n  As a machine learning engineer, you\u2019ll train, test, deploy, and maintain models that learn from data. Your ability to conduct statistical analyses on business processes using machine learning (ML) techniques is key and makes you an integral part of delivering a customer-focused solution. In this role, you\u2019ll own and define the direction of mission-critical solutions by applying best-fit ML algorithms and technologies. You\u2019ll be part of a large community of machine learning engineers across the firm and collaborate with data engineers, data scientists, solutions architects, and product owners to deliver world class solutions to deliver mentorship, training, and solutions to real world problems, process data and information at a massive scale, perform A/B testing tasks on statistical models, ML algorithms, and systems .  Your advanced consulting skills and extensive technical expertise will guide clients as they navigate the landscape of ML algorithms, tools, and frameworks. If you have the drive to solve real-world challenges and define ML strategy for healthcare in federal government, there\u2019s a place for you here. At Booz Allen, you\u2019ll make a difference with us, and, in return, we\u2019ll invest in your future. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  2+ years of experience with data science, data analytics, machine learning engineering, or postdoctoral research for machine learning \n  Experience with natural language processing and language models \n  Experience with deploying machine learning models into a production environment \n  Experience with programming in Python, Java, or C++ \n  Secret clearance \n  Bachelor's degree \n \n \n  Nice If You Have: \n \n  Experience with developing software architectures with containerization tools, including Docker and Kubernetes \n  Experience with machine learning, including linear, reinforcement learning, tree based, or deep learning-based methods and regularization approaches \n  Experience with databases, including SQL \n  Experience with software development, including API development or database management, and model deployment and usage with Javascript frameworks, including React, Angular, or Node.js \n  Knowledge of AWS, Azure, and GCP \n  Ability to work in a Linux environment with Bash Scripting \n  Master's degree \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. \n \n  Create Your Career: \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll build your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $73,100.00 to $166,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.", "cleaned_desc": " \n \n \n \n \n \n \n \n         Machine Learning Engineer\n          \n  The Opportunity: \n  Do you enjoy creating innovative solutions to complex challenges while working within a community of dynamic technology professionals? As an experienced data professional, you know that machine learning is critical to understanding and processing massive datasets. We need your technical expertise to support federal healthcare. \n \n  As a machine learning engineer, you\u2019ll train, test, deploy, and maintain models that learn from data. Your ability to conduct statistical analyses on business processes using machine learning (ML) techniques is key and makes you an integral part of delivering a customer-focused solution. In this role, you\u2019ll own and define the direction of mission-critical solutions by applying best-fit ML algorithms and technologies. You\u2019ll be part of a large community of machine learning engineers across the firm and collaborate with data engineers, data scientists, solutions architects, and product owners to deliver world class solutions to deliver mentorship, training, and solutions to real world problems, process data and information at a massive scale, perform A/B testing tasks on statistical models, ML algorithms, and systems .  Your advanced consulting skills and extensive technical expertise will guide clients as they navigate the landscape of ML algorithms, tools, and frameworks. If you have the drive to solve real-world challenges and define ML strategy for healthcare in federal government, there\u2019s a place for you here. At Booz Allen, you\u2019ll make a difference with us, and, in return, we\u2019ll invest in your future. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  2+ years of experience with data science, data analytics, machine learning engineering, or postdoctoral research for machine learning \n  Experience with natural language processing and language models    Experience with deploying machine learning models into a production environment \n  Experience with programming in Python, Java, or C++ \n  Secret clearance \n  Bachelor's degree \n \n \n  Nice If You Have: \n \n  Experience with developing software architectures with containerization tools, including Docker and Kubernetes \n  Experience with machine learning, including linear, reinforcement learning, tree based, or deep learning-based methods and regularization approaches \n  Experience with databases, including SQL \n  Experience with software development, including API development or database management, and model deployment and usage with Javascript frameworks, including React, Angular, or Node.js \n  Knowledge of AWS, Azure, and GCP \n  Ability to work in a Linux environment with Bash Scripting \n  Master's degree \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. \n \n  Create Your Career: ", "techs": ["python", "java", "c++", "docker", "kubernetes", "sql", "react", "angular", "node.js", "aws", "azure", "gcp", "bash scripting"]}, "819e6223f5a3517b": {"terms": ["data science", "machine learning engineer"], "salary_min": 152917.31, "salary_max": 193627.4, "title": "Lead Data Scientist, Acquisition", "company": "Varo Bank", "desc": "Varo is an entirely new kind of bank. All digital, mission-driven, FDIC insured and designed for the way our customers live their lives. A bank for all of us.\n  \n \n \n  About The Data Science Team \n \n \n   Varo\u2019s Data Science Team builds algorithms that make it easier for the right people to get access to funds, help protect customers from fraudsters, and transform the in-app banking experience with real-time recommendations. Unlike some organizations where data takes a support role, here at Varo data science is front and center. Since we are in hyper-growth mode, you will get to build data science systems from scratch from day one. We rely on advanced techniques in machine learning, cloud platforms, and big data and are primarily PhDs and ex-academics with a collegial work atmosphere. If you are interested in working with an impressive team of Data pros who collaborate and challenge each other and want to solve interesting problems to propel the company\u2019s growth, apply now!\n  \n What you'll be doing \n \n  Develop production ML models to drive customer acquisition and engagement marketing \n  Improve our understanding of customers through clustering, segmentation, and LTV models \n  Design experiments that provide insights to the marketing and product teams as well as measure & optimize the online performance of machine learning models. \n  Work with stakeholders throughout the marketing and product organization to identify opportunities for leveraging data to better drive business decisions \n  Collaborate cross-functionally with the engineering team to improve our production pipeline and engineer new features and metrics \n  Have the opportunity to mentor junior data scientists \n \n  You\u2019ll bring the following required skills and experiences \n \n  An advanced degree in a quantitative field that offers training in ML and/or causal inference - statistics, economics, biostatistics, etc. \n  6+ years of experience as a Data Scientist, Economist, or Statistician as an individual contributor, including relevant experience from your PhD research \n  Experience applying a wide range of statistical techniques to large data sets, and understanding their real-world advantages/drawbacks \n  Experienced in using Python for analysis and modeling (pandas, numpy, scikit, scipy, statsmodels, matplotlib, etc.) \n  Ability to thrive in a fast-paced environment \n  Experience in marketing optimization is nice to have \n \n \n \n  We recognize not everyone will have all of these requirements. If you meet most of the criteria above and you\u2019re excited about the opportunity and willing to learn, we\u2019d love to hear from you! \n \n \n \n  About Varo \n \n \n   Varo launched in 2017 with the vision to bring the best of fintech into the regulated banking system. We\u2019re a new kind of bank \u2013 all-digital, mission-driven, FDIC-insured, and designed around the modern American consumer.\n  \n \n \n  As the first consumer fintech to be granted a national bank charter in 2020, we make financial inclusion and opportunity for all a reality by empowering everyone with the products, insights, and support they need to get ahead. Through our core product offerings and suite of customer-first features, we aim to address a broad range of consumer needs while profitably serving underserved communities that have been historically excluded from the traditional financial system.\n  \n \n \n  We are growing quickly in our hub locations of San Francisco, Salt Lake City, and Charlotte along with colleagues located across the country. We have been recognized among Fast Company\u2019s Most Innovative Companies, Forbes\u2019 Fintech 50, and earned the No. 7 spot on Inc. 5000\u2019s list of fastest-growing companies across the country.\n  \n \n \n  Varo. A bank for all of us.\n  \n \n \n  Our Core Values \n \n \n Customers First \n Take Ownership \n Respect \n Stay Curious \n Make it Better \n \n \n \n  Learn more about Varo by following us: \n \n \n   Facebook - https://www.facebook.com/varomoney\n  \n \n   Instagram - www.instagram.com/varobank\n  \n \n   LinkedIn - https://www.linkedin.com/company/varobank\n  \n \n   Twitter - https://twitter.com/varobank\n  \n \n   Engineering Blog - https://medium.com/engineering-varo\n  \n \n   SoundCloud - https://soundcloud.com/varobank\n  \n \n \n  Varo is an equal opportunity employer. Varo embraces diversity and we are committed to building teams that represent a variety of backgrounds, perspectives, and skills. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.\n  \n \n \n  Beware of fraudulent job postings! \n \n \n   Varo will never ask for payment to process documents, refer you to a third party to process applications or visas, or ask you to pay costs. Never send money to anyone suggesting they can provide work with Varo. If you suspect you have received a phony offer, please e-mail careers@varomoney.com with the pertinent information and contact information.\n   \n \n \n \n \n CCPA Notice at Collection for California Employees and Applicants:  \n \n \n  https://varomoney.box.com/s/q7eockvma9nd2b0utwryruh4ze6gf8eg", "cleaned_desc": "Varo is an entirely new kind of bank. All digital, mission-driven, FDIC insured and designed for the way our customers live their lives. A bank for all of us.\n  \n \n \n  About The Data Science Team \n \n \n   Varo\u2019s Data Science Team builds algorithms that make it easier for the right people to get access to funds, help protect customers from fraudsters, and transform the in-app banking experience with real-time recommendations. Unlike some organizations where data takes a support role, here at Varo data science is front and center. Since we are in hyper-growth mode, you will get to build data science systems from scratch from day one. We rely on advanced techniques in machine learning, cloud platforms, and big data and are primarily PhDs and ex-academics with a collegial work atmosphere. If you are interested in working with an impressive team of Data pros who collaborate and challenge each other and want to solve interesting problems to propel the company\u2019s growth, apply now!\n  \n What you'll be doing \n \n  Develop production ML models to drive customer acquisition and engagement marketing \n  Improve our understanding of customers through clustering, segmentation, and LTV models \n  Design experiments that provide insights to the marketing and product teams as well as measure & optimize the online performance of machine learning models. \n  Work with stakeholders throughout the marketing and product organization to identify opportunities for leveraging data to better drive business decisions \n  Collaborate cross-functionally with the engineering team to improve our production pipeline and engineer new features and metrics \n  Have the opportunity to mentor junior data scientists \n \n  You\u2019ll bring the following required skills and experiences \n ", "techs": ["machine learning", "cloud platforms", "big data", "clustering", "segmentation", "ltv models", "experiments", "marketing", "product", "online performance", "business decisions", "engineering", "production pipeline", "mentorship"]}, "7d99679f59031910": {"terms": ["data science"], "salary_min": 51333.0, "salary_max": 87267.0, "title": "Help Desk Analyst - Remote", "company": "ICF", "desc": "*We are open to supporting 100% remote work anywhere within the continental US.*\n   \n \n \n \n \n  ICF\u2019s Digital Modernization Division is a rapidly growing, entrepreneurial, technology driven department. We are seeking a motivated Help Desk Analyst to support a portfolio of Salesforce projects with our federal customer.\n   \n \n \n \n \n  The Work\n   \n \n \n \n    The Help Desk Analyst will work directly with customers to troubleshoot application issues, provide guidance on how to utilize the system, collaborate with ICF\u2019s technology team to resolve issues identified and document new requirements when needed.\n   \n \n \n \n \n  Responsibilities:\n   \n \n \n \n \n \n \n       Document, troubleshoot and resolve customer requests via phone, email, ticketing system\n      \n \n \n       Must be able to critically analyze, triage and resolve incidents, problems and requests\n      \n \n \n       Must be able to understand technical end user problems and provide clear and timely resolutions\n      \n \n \n       Build and utilize decision trees to evaluate and elevate issues to internal teams\n      \n \n \n       Update knowledge base to ensure procedures and known fixes are up-to-date\n      \n \n \n \n \n \n \n \n \n       Ensure SLA\u2019s are met\n      \n \n \n       Work with operations teams to prepare for releases and create scripts/documentation for customer support\n      \n \n \n       Gather and supply feedback from customers in a useable format to product teams\n      \n \n \n       Report incidents and problems to appropriate teams and communicate effectively through product management to the customer\n      \n \n \n       Assess system and product metrics on a routine basis and produce reports for management\n      \n \n \n \n \n \n \n \n \n       Provide training and demos related to new processes or application features\n      \n \n \n       Develop manual testing scripts, test scenarios, and test scripts\n      \n \n \n       Assist other QA Engineers with functional and regression testing as needed.\n      \n \n \n \n \n \n \n \n  Basic Qualifications:\n    \n \n \n \n \n \n       1+ year experience working in a customer orientated service role as a service/help desk engineer\n      \n \n \n       US Citizenship is required (required by the federal government for this position)\n      \n \n \n       Must be able to obtain Public Trust clearance\n      \n \n \n       MUST RESIDE IN THE United States (U.S.) and the work MUST BE PERFORMED in the United States (U.S.), as this work is for a federal contract and laws do apply.\n      \n \n \n \n \n \n \n \n  Preferred qualifications:\n    \n \n \n \n \n \n       Bachelors or Associate degree, preferred in engineering or IT related field\n      \n \n \n       Experience building and managing dashboards, a plus\n      \n \n \n       Experience with Salesforce is a plus\n      \n \n \n \n \n \n \n \n \n       Functional and Regression testing of low code platforms such as Salesforce.com is a plus\n      \n \n \n       Must be able to manage work across multiple projects, concurrently\n      \n \n \n       Excellent communication skills\n      \n \n \n       Track record of working across multiple teams to resolve issues\n      \n \n \n       Able to prioritize work to meet deadlines\n      \n \n \n \n \n \n \n \n \n       Adaptable, dependable and independent\n      \n \n \n \n \n \n  Working at ICF\n  \n  ICF is a global advisory and technology services provider, but we\u2019re not your typical consultants. We combine unmatched expertise with cutting-edge technology to help clients solve their most complex challenges, navigate change, and shape the future.\n  \n \n   We can only solve the world's toughest challenges by building an inclusive workplace that allows everyone to thrive. We are an equal opportunity employer, committed to hiring regardless of any protected characteristic, such as race, ethnicity, national origin, color, sex, gender identity/expression, sexual orientation, religion, age, disability status, or military/veteran status. Together, our employees are empowered to share their expertise and collaborate with others to achieve personal and professional goals. For more information, please read our \n   \n   EEO & AA policy\n   .\n  \n \n \n   Reasonable Accommodations are available, including, but not limited to, for disabled veterans, individuals with disabilities, and individuals with sincerely held religious beliefs, in all phases of the application and employment process. To request an accommodation please email \n   \n   icfcareercenter@icf.com\n    and we will be happy to assist. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. Read more about non-discrimination: \n   \n   Know Your Rights\n    and \n   \n   Pay Transparency Statement.\n   \n \n \n \n  Pay Range - There are multiple factors that are considered in determining final pay for a position, including, but not limited to, relevant work experience, skills, certifications and competencies that align to the specified role, geographic location, education and certifications as well as contract provisions regarding labor categories that are specific to the position. The pay range for this position is:\n   $51,333.00 - $87,267.00\n   Nationwide Remote Office (US99)", "cleaned_desc": " \n \n  Preferred qualifications:\n    \n \n \n \n \n \n       Bachelors or Associate degree, preferred in engineering or IT related field\n      \n \n \n       Experience building and managing dashboards, a plus\n      \n \n \n       Experience with Salesforce is a plus\n      \n \n \n \n \n \n \n \n \n       Functional and Regression testing of low code platforms such as Salesforce.com is a plus\n      \n \n \n       Must be able to manage work across multiple projects, concurrently\n      \n \n \n       Excellent communication skills\n      \n \n \n       Track record of working across multiple teams to resolve issues\n      \n ", "techs": ["salesforce.com"]}, "b3759b9ecf563a08": {"terms": ["data science", "data engineer"], "salary_min": 80510.0, "salary_max": 116513.0, "title": "LEAD DATA ENGINEER", "company": "Lumen", "desc": "About Lumen \n  Lumen is a global technology leader, digitally connecting people, data and applications \u2013 quickly, securely, and effortlessly. Together, we are building a culture and company from the people up \u2013 committed to teamwork, trust and transparency. People power progress. We\u2019re looking for top-tier talent and offer the flexibility you need to thrive and deliver lasting impact. Join us as we digitally connect the world and shape the future. \n \n \n \n  The Role \n \n \n  Are you interested in serving as an integral part of our digital marketing team developing new tools and capabilities that will continue to advance Lumen\u2019s reputation as a technology leader?    In this role, you will be partnering closely with marketing, operations, and data science teams to utilize terabytes of data and translate them into actionable insights to create a competitive advantage for marketing/sales initiatives to win market share. Furthermore, you will be accountable for building and operationalizing critical components and tools to ensure the data coming in and going out are of the highest data quality and integrity. In the end state, the data solutions built and operated by you would rival the absolute best in the industry in engineering, operations, and usability excellence. \n \n \n \n \n  The Main Responsibilities \n \n \n  You are a great fit for this position if you: \n \n  Have strong passion in building reliable, accurate datasets that power end-to-end user scenarios and used in business decisions. \n  Highly believe that data is an asset that must be accessible to and applicable by every function in a modern business to guide and assess growth investments. \n  Are passionate about Data Engineering and believe that it is one of a kind emerging discipline and career path that you want to grow in. \n  Enjoy building and operating data services at terabyte and higher scales to enable data driven organizations. \n \n \n \n \n \n  What We Look For in a Candidate \n \n \n  Qualifications: \n \n  Experience building data models and performing complex queries using SQL \n  Experience performance tuning large datasets \n  Experience building large data pipelines and/or web services \n  Strong programming skills with Python and other scripting languages \n  4+ years of Business Intelligence or software development experience using industry technologies \n  3+ years of experience in building integration with upstream and downstream systems with REST APIs \n  Excellent problem solving, critical thinking, and communication skills \n  Ability to communicate effectively with technical and business teams, drive issues to closure \n  Strong understanding of data engineering and data stewardship roles in an organization \n  Strong time management and organization skills. Ability to work on multiple projects concurrently. \n  BA/BS in Computer Science, Engineering or related technical field such as Statistics or Data Science \n \n \n  Other Qualifications: \n \n  Strong familiarity with Azure ecosystem is highly valuable \n  Knowledge of Lumen data, systems and processes including paid media, financial and inventory systems highly desirable \n  Experience with ETL and data integration development using multiple tools, including Informatica, Microsoft SSIS or other technologies \n  Combined IT and Marketing background \n  Machine Learning, Data Science, and statistical modeling experience are highly valued \n \n \n \n \n \n  Compensation \n \n \n  The starting salary for this role differs based on the employee's primary work location. Employees typically do not start at the top of the range, though compensation depends on each individual's qualifications. \n  Location Based Pay Ranges \n  $80510 - $100635  in these states: AR, ID, KY, LA, ME, MS, NE, SC, and SD.   $84740 - $105923  in these states: AZ, FL, GA, IN, IA, KS, MO, MT, NM, ND, OH, OK, PA, TN, UT, VT, WV, WI, and WY.   $88980 - $111218  in these states: CO, HI, MI, MN, NV, NH, NC, OR, and RI.   $93210 - $116513  in these states: AK, CA, CT, DE, DC, IL, MD, MA, NJ, NY, TX, VA, and WA. \n  As with the pay range variety that's based on the region of a country, specific offers are determined by various factors such as experience, education, skills, certifications and other business needs. \n \n \n \n  Requisition #: 331444 \n  Background Screening \n  If you are selected for a position, there will be a background screen, which may include checks for criminal records and/or motor vehicle reports and/or drug screening, depending on the position requirements. For more information on these checks, please refer to the Post Offer section of our FAQ page. Job-related concerns identified during the background screening may disqualify you from the new position or your current role. Background results will be evaluated on a case-by-case basis. \n  Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. \n  Equal Employment Opportunities \n  We are committed to providing equal employment opportunities to all persons regardless of race, color, ancestry, citizenship, national origin, religion, veteran status, disability, genetic characteristic or information, age, gender, sexual orientation, gender identity, gender expression, marital status, family status, pregnancy, or other legally protected status (collectively, \u201cprotected statuses\u201d). We do not tolerate unlawful discrimination in any employment decisions, including recruiting, hiring, compensation, promotion, benefits, discipline, termination, job assignments or training. \n  Disclaimer \n  The job responsibilities described above indicate the general nature and level of work performed by employees within this classification. It is not intended to include a comprehensive inventory of all duties and responsibilities for this job. Job duties and responsibilities are subject to change based on evolving business needs and conditions. \n \n  Salary Range \n \n  Salary Min :  \n 80510 \n \n \n  Salary Max :  \n 116513 \n \n \n  This information reflects the anticipated base salary range for this position based on current national data. Minimums and maximums may vary based on location. Individual pay is based on skills, experience and other relevant factors.  \n This position is eligible for either short-term incentives or sales compensation. Director and VP positions also are eligible for long-term incentive. To learn more about our bonus structure, you can view additional information here. We're able to answer any additional questions you may have as you move through the selection process. \n  As part of our comprehensive benefits package, Lumen offers a broad range of Health, Life, Voluntary Lifestyle and other benefits and perks that enhance your physical, mental, emotional and financial wellbeing. You can learn more by clicking here. \n  Note: For union-represented postings, wage rates and ranges are governed by applicable collective bargaining agreement provisions.", "cleaned_desc": " \n  Have strong passion in building reliable, accurate datasets that power end-to-end user scenarios and used in business decisions. \n  Highly believe that data is an asset that must be accessible to and applicable by every function in a modern business to guide and assess growth investments. \n  Are passionate about Data Engineering and believe that it is one of a kind emerging discipline and career path that you want to grow in. \n  Enjoy building and operating data services at terabyte and higher scales to enable data driven organizations. \n \n \n \n \n \n  What We Look For in a Candidate \n \n \n  Qualifications: \n \n  Experience building data models and performing complex queries using SQL \n  Experience performance tuning large datasets    Experience building large data pipelines and/or web services \n  Strong programming skills with Python and other scripting languages \n  4+ years of Business Intelligence or software development experience using industry technologies \n  3+ years of experience in building integration with upstream and downstream systems with REST APIs \n  Excellent problem solving, critical thinking, and communication skills \n  Ability to communicate effectively with technical and business teams, drive issues to closure \n  Strong understanding of data engineering and data stewardship roles in an organization \n  Strong time management and organization skills. Ability to work on multiple projects concurrently. \n  BA/BS in Computer Science, Engineering or related technical field such as Statistics or Data Science \n \n \n  Other Qualifications: \n \n  Strong familiarity with Azure ecosystem is highly valuable \n  Knowledge of Lumen data, systems and processes including paid media, financial and inventory systems highly desirable \n  Experience with ETL and data integration development using multiple tools, including Informatica, Microsoft SSIS or other technologies \n  Combined IT and Marketing background ", "techs": ["sql", "python", "rest apis", "azure", "lumen", "informatica", "microsoft ssis"]}, "d1e2189927421f85": {"terms": ["data science", "machine learning engineer"], "salary_min": 116002.0, "salary_max": 168000.0, "title": "Software Engineer, Machine Learning", "company": "Meta", "desc": "Meta is embarking on the most transformative change to its business and technology in company history, and our Machine Learning Engineers are at the forefront of this evolution. By leading crucial projects and initiatives that have never been done before, you have an opportunity to help us advance the way people connect around the world.The ideal candidate will have industry experience working on a range of recommendation, classification, and optimization problems. You will bring the ability to own the whole ML life-cycle, define projects and drive excellence across teams. You will work alongside the world\u2019s leading engineers and researchers to solve some of the most exciting and massive social data and prediction problems that exist on the web.\n  \n \n \n Software Engineer, Machine Learning Responsibilities:    \n \n Develop highly scalable classifiers and tools leveraging machine learning, data regression, and rules based models \n  Suggest, collect and synthesize requirements and create effective feature roadmap \n  Code deliverables in tandem with the engineering team \n  Adapt standard machine learning methods to best exploit modern parallel environments (e.g. distributed clusters, multicore SMP, and GPU) \n \n \n \n \n Minimum Qualifications:   \n \n  2+ years of experience in one or more of the following areas: machine learning, recommendation systems, pattern recognition, data mining or artificial intelligence \n  Proven experience to translate insights into business recommendations \n  Experience with Hadoop/HBase/Pig or MapReduce/Sawzall/Bigtable \n  Knowledge developing and debugging in C/C++ and Java \n  Experience with scripting languages such as Perl, Python, PHP, and shell scripts \n  Currently has, or is in the process of obtaining a Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience. Degree must be completed prior to joining Meta. \n \n \n \n \n Preferred Qualifications:   \n \n  Exposure to architectural patterns of large scale software applications \n \n \n \n \n About Meta:    Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today\u2014beyond the constraints of screens, the limits of distance, and even the rules of physics.\n  \n \n \n \n  Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment. \n   \n  Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.", "cleaned_desc": "  2+ years of experience in one or more of the following areas: machine learning, recommendation systems, pattern recognition, data mining or artificial intelligence \n  Proven experience to translate insights into business recommendations \n  Experience with Hadoop/HBase/Pig or MapReduce/Sawzall/Bigtable \n  Knowledge developing and debugging in C/C++ and Java \n  Experience with scripting languages such as Perl, Python, PHP, and shell scripts \n  Currently has, or is in the process of obtaining a Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience. Degree must be completed prior to joining Meta. \n \n ", "techs": ["machine learning", "recommendation systems", "pattern recognition", "data mining", "artificial intelligence", "hadoop", "hbase", "pig", "mapreduce", "sawzall", "bigtable", "c/c++", "java", "perl", "python", "php", "shell scripts", "bachelor's degree in computer science", "computer engineering"]}, "af4f72302b4b8b54": {"terms": ["data science", "data analyst"], "salary_min": null, "salary_max": null, "title": "Data Governance Analyst - I", "company": "Freedom Mortgage", "desc": "Key Responsibilities: \n \n  Collaborate with various departments to understand their data and reporting needs. \n  Develop and maintain data governance policies, procedures, and standards. \n  Implement data quality controls to ensure data accuracy and consistency. \n  Create and maintain documentation related to data governance and reporting processes. \n  Monitor and enforce data security and privacy regulations. \n  Identify opportunities for process improvement and data quality enhancement. \n  Perform data analysis to identify trends, anomalies, and insights. \n  Generate reports and dashboards that provide actionable insights for decision-makers. \n  Ensure compliance with data governance best practices and industry standards. \n \n \n  Qualifications: \n \n  Bachelor's degree in a related field (e.g., Data Science, Information Technology, Business, or a related discipline). \n  Proven experience working in data governance, reporting, or a related field. \n  Strong understanding of data governance principles and best practices. \n  Proficiency in data analysis and reporting tools (e.g., SQL, Tableau, Power BI, Excel, etc.). \n  Excellent communication and collaboration skills. \n  Strong attention to detail and problem-solving abilities. \n  Ability to work both independently and as part of a team. \n  Knowledge of data modeling and ETL processes. \n  Familiarity with data visualization best practices. \n  Project management skills. \n \n \n  Remote", "cleaned_desc": "  Bachelor's degree in a related field (e.g., Data Science, Information Technology, Business, or a related discipline). \n  Proven experience working in data governance, reporting, or a related field. \n  Strong understanding of data governance principles and best practices. \n  Proficiency in data analysis and reporting tools (e.g., SQL, Tableau, Power BI, Excel, etc.). \n  Excellent communication and collaboration skills.    Strong attention to detail and problem-solving abilities. \n  Ability to work both independently and as part of a team. \n  Knowledge of data modeling and ETL processes. \n  Familiarity with data visualization best practices. \n  Project management skills. ", "techs": ["sql", "tableau", "power bi", "excel"]}, "cebc7463847e59ae": {"terms": ["data science"], "salary_min": 117005.25, "salary_max": 148154.72, "title": "Data Scientist", "company": "The Hiller Companies Llc", "desc": "The Hiller Companies, LLC has an immediate opening for a qualified  Data Scientist. \n  Hiller offers fire protection and life safety products and services that are preserving lives and property all around the world. Headquartered in Mobile, Alabama, Hiller extends its reach globally as well as in domestic markets with offices across the United States. For more than 100 years, we have been laser-focused on one goal \u2013 making the world a safer place. We are proud to be on the forefront of technology and innovation by creating adaptable safety solutions. As we continue to grow and expand our life safety footprint, we pledge to keep our customers top of mind while striving to design, install and service the most compliant, reliable systems available. \n  Job Summary:   The Data Scientist supports Hiller\u2019s evolution towards digitization and data driven culture as the lead of the Data & Analytics (D&A) team responsible for implementing the data & analytics vision. This will range from crafting our enterprise data model (EDM) to streamlining our decision tools to supporting strategic implementation through A/B testing among other approaches across the portfolio.  \n If as a data scientist, you\u2019re excited at the prospect of unlocking the secrets held by a data set, and you\u2019re fascinated by the possibilities presented by advanced data modeling, machine learning, and artificial intelligence, then we would love to talk with you about this opportunity.  \n Job Responsibilities:  \n \n Implement And Lead Hiller\u2019s End-to-End BI Transformation \n \n  Implement a KPI based model from leadership summaries to cross-functional tracking dashboards to customized branch templates (where applicable) \n  Centralize and maintain BI reporting on the D&A Team when applicable to more than one site. \n  Driving all business process and reviews from BI tools where possible \n \n  Implement Advanced Data Models and Decision Tools Per Use Case \n \n  Collaborate with cross-functional teams to understand business requirements, and identify pain points for data-driven insights \n  Upon review of major pain points in the business, this role will design, develop, and deploy advanced analytics solutions to solve or streamline where possible.  \n Design and conduct experiments, collect the data necessary to perform statistical hypothesis testing, and create inferences and recommendations \n  Conduct exploratory data analysis and apply deep business knowledge to customer and marketplace data to uncover new business insights \n \n  Lead The Enterprise Data Model (EDM) Creation and Maintenance  \n \n Develop and support data SMEs on the completion of an analytical layer of master data sets that will be the foundation of all data models and reporting \n  Data governance based on the data needs of priority analysis in the D&A pipeline \n  This role will lead both the data governance process and prioritize the data enhancements needed for the IT team based on business need \n \n  Democratize Data Via Data Literacy Training \n \n  Host general and targeted training to allow users to self-service their needs quarterly. \n  Support branch/corporate users understand the data that is available as applicable \n \n  Process Improvement Via New Technologies \n \n  Stay up to date on the latest technology available for data and analytics \n  As applicable, this role will suggest technology enhancements to leapfrog our teams toward better performance  \n \n Support Thought leadership For Our Technology Stack and System   Integration Transformation \n \n  Candidates for this role will need to develop a full insight lifecycle, from design and development to deployment and support, ensuring seamless integration with existing systems, processes, and workflows. \n  This role would be included in several transformation projects as a thought leader to give guidance on improved techniques or technology to ensure end to end performance increases  \n This role will be included in long term planning workshops where technology investments are debated on their value add and need to get Hiller to best in class data and analytics  \n \n Mentor and guide junior data and analytics team members, and fostering a   culture of continuous learning and development within the team. \n \n \n  Education, Licensure & Certifications:   \n \n Bachelor\u2019s degree or higher in computer science, data science, statistics, or a related field \n \n   \n Experience: \n \n  6+ years of experience with hands-on data exploration, data cleaning, data analysis, data visualization, or data mining, analyzing structured and unstructured data sources, including experience with statistical and general-purpose programming languages for data analysis \n  Experienced with the following programming languages: Python, R, SQL, DAX, Python and relevant libraries including Pandas, PyTorch and Tensorflow. \n  Demonstrated ability to design, develop, and deploy end-to-end data-driven solutions in the construction industry \n  Experience developing predictive data models, quantitative analyses and visualization of targeted data sources \n  Experience leading a team, including projects and deliverables \n  Experience leading the development of solutions to complex programs \n  Prefer candidates experienced in:\n    \n  AI, large language models, and machine learning techniques, including supervised and unsupervised learning, natural language processing, and deep learning. \n  Big data technologies, such as Spark, Databricks, and cloud platforms, such as Azure and AWS. \n  Cloud-based machine learning resources such as those from AWS \n  Translating analytical work into presentations (e.g. PowerPoint) suitable for non-technical audiences \n \n \n \n  Knowledge, Skills, Capabilities:   \n \n Experience establishing relationships and building credibility with partners and colleagues \n  Exceptional communication and presentation skills, with the ability to convey complex ideas in a clear and concise manner \n  Strong MS Office skills including Excel, PowerPoint, and Word \n  Ability to design, develop, and deploy advanced analytics solutions \n  Ability to design, develop, and deploy BI solutions for management reporting and tracking \n  In-depth knowledge of data and analytics industry and core analytical techniques and some proficiency with others: \n    \n multi-variate linear regression  \n logistic regression  \n time series modeling \n  statistical design of experiments and hypothesis testing \n  clustering \n  dimension reduction techniques \n  classification \n  gradient-boosting \n  natural language processing algorithms \n \n \n \n  Hiller is a drug-free workplace, an equal opportunity employer and ADA compliant. \n  We are proud to operate according to our Core Values: Passion to Perform, Trust to Act, Act Responsibly, and Make it Fun. \n  We offer competitive pay and most employee benefits start from the first day of employment, including: \n \n  Medical, Dental & Vision Insurance \n  401(k) with fully vested employer matching funds \n  Company Paid & Voluntary Life Insurance \n  Voluntary Short Term & Long Term Disability Insurance \n  PTO \n  8 Paid Holidays", "cleaned_desc": "  This role would be included in several transformation projects as a thought leader to give guidance on improved techniques or technology to ensure end to end performance increases  \n This role will be included in long term planning workshops where technology investments are debated on their value add and need to get Hiller to best in class data and analytics  \n \n Mentor and guide junior data and analytics team members, and fostering a   culture of continuous learning and development within the team. \n \n \n  Education, Licensure & Certifications:   \n \n Bachelor\u2019s degree or higher in computer science, data science, statistics, or a related field \n \n   \n Experience: \n \n  6+ years of experience with hands-on data exploration, data cleaning, data analysis, data visualization, or data mining, analyzing structured and unstructured data sources, including experience with statistical and general-purpose programming languages for data analysis \n  Experienced with the following programming languages: Python, R, SQL, DAX, Python and relevant libraries including Pandas, PyTorch and Tensorflow. \n  Demonstrated ability to design, develop, and deploy end-to-end data-driven solutions in the construction industry \n  Experience developing predictive data models, quantitative analyses and visualization of targeted data sources \n  Experience leading a team, including projects and deliverables \n  Experience leading the development of solutions to complex programs    Prefer candidates experienced in:\n    \n  AI, large language models, and machine learning techniques, including supervised and unsupervised learning, natural language processing, and deep learning. \n  Big data technologies, such as Spark, Databricks, and cloud platforms, such as Azure and AWS. \n  Cloud-based machine learning resources such as those from AWS \n  Translating analytical work into presentations (e.g. PowerPoint) suitable for non-technical audiences \n \n \n \n  Knowledge, Skills, Capabilities:   \n \n Experience establishing relationships and building credibility with partners and colleagues \n  Exceptional communication and presentation skills, with the ability to convey complex ideas in a clear and concise manner \n  Strong MS Office skills including Excel, PowerPoint, and Word \n  Ability to design, develop, and deploy advanced analytics solutions \n  Ability to design, develop, and deploy BI solutions for management reporting and tracking \n  In-depth knowledge of data and analytics industry and core analytical techniques and some proficiency with others: \n    \n multi-variate linear regression  ", "techs": ["python", "r", "sql", "dax", "pandas", "pytorch", "tensorflow", "ai", "large language models", "machine learning techniques", "natural language processing", "deep learning", "spark", "databricks", "azure", "aws", "powerpoint", "excel", "word", "multi-variate linear regression"]}, "8b078adaff19ece8": {"terms": ["data science"], "salary_min": 115000.0, "salary_max": 160000.0, "title": "Assistant Vice President, Risk Analytics", "company": "Wedbush Securities", "desc": "Job Description: \n  Wedbush Securities is one of the largest securities firms and investment banks in the nation. We provide innovative financial solutions through our Wealth Management, Capital Markets, Futures and Advanced Clearing & Prime Services divisions. Headquartered in Los Angeles, California with over 100 offices and more than 80 correspondent offices, our commitment to providing relentless, customized service is the foundation of our consistent growth.  \n  Our Los Angeles office is hiring for an experienced Assistant Vice President, Risk Analytics to join our Risk and Credit Group for a 100% remote opportunity. The primary function of this role is to act as a Data Scientist for the Risk Management Department, and a Project Manager/Liaison for all related Risk systems and IT functions. You will need to design SQL queries and relational databases to carry out daily tasks and automate reports for the risk management department.  \n  Responsibilities will include, but are not limited to:  \n \n  Build, monitor, distribute risk reports and margin calculations \n  Design SQL query and relational databases to carry out daily tasks and automate reports \n  Create and Manage risk dashboards \n  Perform complex data analysis on account balances and positions across the firm \n  Manage ad hoc projects as requested by leadership \n  Be the system administrator and point of contact for various risk systems and tools \n  Present and explain analysis in a non-technical and accessible manner alongside data visualization \n  Perform other tasks and duties as required and assigned \n \n \n  Experience and Skills: \n \n  Bachelor\u2019s Degree from an accredited University, preferably in Computer Science, Data Science, or related field \n  Advanced proficiency in SQL and understanding of data access tools \n  5+ years\u2019 experience in Information Technology, preferably for a financial services firm \n  5+ years\u2019 experience in Data Analytics, Risk Analysis, or related role \n  Understanding of Equities, Options, and Margin is a plus \n  Must be detail oriented and maintain data integrity \n  Creative, solution-oriented mindset with the ability to handle pressure to meet deadlines \n  Able to work with minimal supervision, taking ownership of work and completing tasks in timely manner, while adapting rapidly to changing work environments, priorities and organizational needs \n  Ability to identify gaps in existing processes and gain efficiency through automation. \n  Experience working with multiple teams across different time zones \n \n \n  Job Benefits: \n  Wedbush Securities offers robust benefits to our colleagues.  \n \n Comprehensive medical, dental, and vision coverage with multiple health plan options for you and your family \n  Health Savings Account with company-sponsored contributions \n  Flexible Spending Accounts (FSA) traditional and dependent care \n  Pre-Tax Commuter Benefits \n  401(k) plan with discretionary, competitive company matching and profit-sharing contributions \n  Tuition reimbursement up to $5,250/year \n  3 weeks of Paid Time Off \n  2 weeks of Paid Sick Time (may vary by location) \n  10 Paid Holidays \n  Charitable Donation Matching Contributions \n  Paid Leave (Military, Jury Duty, Volunteer Time Off, Disability, etc.) \n  FINRA License Sponsorship \n  Travel & Employee Assistance and Employee Discount Programs \n \n  The reasonable estimate of the compensation range for this role has not been adjusted for the applicable geographic location. A reasonable estimate of the current hiring range is $115,000-$160,000. Colleagues may be eligible for additional, discretionary incentive compensation based on the individual and the firm's performance. At Wedbush, it is not typical for an individual to be hired at, or near, the top of the range for their role. Decisions regarding compensation are determined on a case-by-case basis and are dependent on a variety of factors including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs.  \n Wedbush Securities (WS) is proud to be an Equal Employment Opportunity employer. WS does not discriminate based on race, religion, color, creed, sex, sexual orientation, gender, gender identity or expression, national origin, ancestry, citizenship status, registered domestic partner status, uniform service member status, marital status, pregnancy, age, medical condition, disability, genetic information, family care or medical leave status, or any other consideration made unlawful by applicable federal, state, or local laws, or on the basis that an applicant or Colleague is perceived to have these characteristics or is associated with someone who is perceived to have these characteristics. WS aims to foster a culture of inclusion where all Colleagues are valued for their unique contributions to the firm as well as provided equal opportunities to succeed.  \n Wedbush uses E-Verify, an Internet-based system, to confirm the eligibility of all newly hired employees to work in the United States. Learn more about E-Verify, including your rights and responsibilities here https://www.e-verify.gov/employees/e-verify-overview    From: Wedbush Securities", "cleaned_desc": "  Advanced proficiency in SQL and understanding of data access tools \n  5+ years\u2019 experience in Information Technology, preferably for a financial services firm \n  5+ years\u2019 experience in Data Analytics, Risk Analysis, or related role \n  Understanding of Equities, Options, and Margin is a plus \n  Must be detail oriented and maintain data integrity \n  Creative, solution-oriented mindset with the ability to handle pressure to meet deadlines \n  Able to work with minimal supervision, taking ownership of work and completing tasks in timely manner, while adapting rapidly to changing work environments, priorities and organizational needs \n  Ability to identify gaps in existing processes and gain efficiency through automation. \n  Experience working with multiple teams across different time zones ", "techs": ["sql", "data access tools", "equities", "options", "margin", "automation"]}, "8933467acfee3af1": {"terms": ["data science", "data analyst"], "salary_min": 97449.945, "salary_max": 123393.35, "title": "EEO Compliance Data Analyst (Remote)", "company": "University of California San Francisco", "desc": "This role is primarily responsible for producing data supporting the development of the annual Affirmative Action Plan, a critical compliance obligation of UCSF as a federal contractor.\n     \n  Under general direction of the Director of Data and Analytics, this position plays a key role in the development, deployment and adoption of data pipelines and administrative info r mat ion systems for the Vice Chancellor of Diversity and Outreach and its units.\n     \n  The staff member will be a resource for the Director of Data and Analytics to design, develop and manage technology that advances the mission of the Vice Chancellor of Diversity and Outreach's units. Focused on advocating for customer needs and influencing technology recommendations and decisions, this position ensures that our work is aligned with broadly defined enterprise IT objectives.\n     \n  This position is expected to work with minimal supervision and in partnership with the Director of Data and Analytics, to whom the role reports.\n     \n  This position is a key role within the Office of Diversity and Outreach responsible for developing the data infrastructure for the accurate and timely production of UCSF\u2019s affirmative action and equal employment opportunity programs in compliance with state and federal laws and regulations.\n     \n  In support of UCSF\u2019s equity and inclusion programs, this role is responsible for the design, specifications, coding, testing, implementation, maintenance, documentation, debugging, and troubleshooting of data warehouse solutions. Its work includes analyzing source system data, designing dimensional data models, developing ETLs, and creating data visualization products such as reports and dashboards. The position plays a critical role in requirement gathering, project plan planning, technical architecture design, data security, go-live implementation, and ongoing system support. The role also includes participation in the management of and / or development of standard data practices and guidelines, dictionaries, registries and / or services to be shared and used by other UCSF data resources. In addition to these duties, the position is required to perform any other tasks assigned to support the department\u2019s function.\n     \n  A data engineer is responsible for designing, developing, testing, documenting, and maintaining data warehouse and analytics architecture to meet the UCSF Office of Diversity and Outreach data and analytics needs.\n     \n  Collaborate with business and technology partners to gather business requirements and create architectural designs. \n  Use business domain knowledge to profile data and determine the best approaches to extract data into data warehouses. \n  Apply the Kimball dimensional data modeling technique to build and enhance the enterprise data warehouse. \n  Design, develop, test, document, and support new and existing ETL processes using Microsoft SQL Server Integration Services (SSIS), or other tools. \n  Demonstrate advanced proficiency in SQL programming and performance tuning. \n  Participates to create optimal and scalable technology standards to be used within department and throughout UCSF data community \n  Serves as leaders in data community to provide consultation of technical standards / guidelines \n  Develop business intelligence products, such as reports and dashboards, using Tableau or other data visualization tools. \n  Document business rules and metadata in the data dictionary and keep the information updated. \n  Possess excellent communication skills and the ability to articulate system designs and patterns to varying levels of leadership. \n  Participate in project planning, including scoping backlogs and determining estimates. \n  Maintain appropriate business domain knowledge in healthcare, education, research, finance, or business administration. \n \n \n  To see the salary range for this position (we recommend that you make a note of the job code and use that to look up):  TCS Non-Academic Titles Search (ucop.edu) \n  Please note: The compensation ranges listed online for roles not covered by a bargaining unit agreement are very wide, however a job offer will typically fall in the range of 80% - 120% of the established mid-point. An offer will take into consideration the experience of the final candidate AND the current salary level of individuals working at UCSF in a similar role. \n  For roles covered by a bargaining unit agreement, there will be specific rules about where a new hire would be placed on the range. \n  To learn more about the benefits of working at UCSF, including total compensation, please visit: https://ucnet.universityofcalifornia.edu/compensation-and-benefits/index.html \n \n \n \n Department Description \n \n    The University of California, San Francisco (UCSF), has been at the forefront of addressing health care disparities and community health needs, while promoting diversity and inclusion among its students, trainees, staff and faculty. UCSF\u2019s commitment to diversity and inclusion is integral to fulfilling UCSF\u2019s mission to deliver the highest standard of excellence in health care delivery, scholarly research, community service, and training the next generation of health care professionals.\n     \n  The Office of Diversity and Outreach (ODO) serves as the campus leader in building diversity in all aspects of the UC San Francisco mission through ongoing assessment, development of new programs and building consensus. We collaborate with the four professional schools, the Graduate Division, and the medical centers, to promote diversity, equity, and inclusion across UCSF.\n     \n  The Vice Chancellor's Office of Diversity and Outreach (VCDO) includes oversight for the Center for Science Education and Outreach, Disability, LGBT, Multicultural and CARE Resource Centers, the Office for the Prevention of Harassment and Discrimination, Sexual Violence Prevention and Response, and the direct administrative office of the Vice Chancellor of Diversity and Outreach.\n     \n  The mission of the Office is to build a broadly diverse faculty, student, trainee and staff community, to nurture a culture that is welcoming and supportive, and to engage diverse ideas for the provision of culturally competent education, discovery and patient care. Our priority is to develop and execute a comprehensive strategic plan for diversity and outreach that supports UCSF\u2019s mission of advancing health worldwide, and the recruitment and retention of talented employees and students who contribute to our commitment to diversity and excellence.\n    \n \n \n Required Qualifications \n \n \n Bachelor's degree in related area and minimum 10 years of experience or equivalent experience/training \n  Must be able to work with multiple SQL Server and Oracle RDBMS environments \n  Experience developing and executing complex test plans. \n  Possesses advanced level skills required to gather, organize and review analyses on diverse equal employment opportunity affirmative action programs and initiatives, as well as those to present findings and make recommendations that are significant to a department or unit, verbally and in writing. \n  At least 3 years designing and creating reports, scorecards, and dashboards using Tableau, Power BI, or any data visualization tools. \n  Minimum of 5 years using at least one ETL tool such as Microsoft SQL Server Integration Services (SSIS). Capable of designing and developing data extraction, integration, and transformation solutions. Demonstrate the ability to create, code, and test ETL routines. Possess an understanding of the principles of effective ETL design. \n  At least 5 years writing Oracle SQL. Experienced in writing complex SQL queries and stored procedures. Understanding of query performance tuning. \n  At least 8 years writing T-SQL. Experienced in writing complex SQL queries and stored procedures. Understanding of query performance tuning. \n  Possess experience and skills in developing logical and physical dimensional data models with demonstrated understanding of fact and dimension design principles. Experienced in creating database objects and applying security. \n  Demonstrate complex problem-solving skills. \n  Self-motivated and works independently and as part of a team. Able to learn effectively and meet deadlines. \n  Demonstrate effective communication and interpersonal skills. Demonstrate ability to communicate technical information to technical and non-technical personnel at various levels in the organization. \n \n \n \n \n Preferred Qualifications \n \n \n Master\u2019s degree in related area \n  Formal Education or Training in ETL development \n  Formal Education or Training in data modeling (esp Kimball Methodology) \n  Experience developing R scripts using Tidyverse and the Tidyverse design philosophy \n  Experience documenting, developing and communicating business processes and data flows using swim lane diagrams, sequence diagrams and flow charts, etc. \n  Experience with Office of Federal Compliance Programs (OFCCP) compliance obligations and affirmative action data requirements \n  Demonstrable experience actively engaged in the improvement of diversity and inclusion within a business, non-profit or academic enterprise. \n  Knowledge and appreciation for the value of diversity in improving performance of teams and enterprises. \n  Able to resolve and improve performance issues. Experience in working with other technical and business teams to carry out system performance tuning. \n  Excellent project leadership and management skills. \n  Highly advanced skills associated with software specification, design, modification, implementation and deployment of large-scale scope. \n  Advanced knowledge of secure software development \n  Experience in Python or R programming language \n  Familiarity with Affirmative Action reporting requirements for the production of the affirmative action plan \n  Experience designing SQL to query UC Path, Brassring, UC Recruit and other UC systems \n  Understanding of advanced statistical methods and data science principles. \n \n \n \n \n About UCSF \n \n    The University of California, San Francisco (UCSF) is a leading university dedicated to promoting health worldwide through advanced biomedical research, graduate-level education in the life sciences and health professions, and excellence in patient care. It is the only campus in the 10-campus UC system dedicated exclusively to the health sciences. We bring together the world\u2019s leading experts in nearly every area of health. We are home to five Nobel laureates who have advanced the understanding of cancer, neurodegenerative diseases, aging and stem cells.\n    \n \n \n Pride Values \n \n    UCSF is a diverse community made of people with many skills and talents. We seek candidates whose work experience or community service has prepared them to contribute to our commitment to professionalism, respect, integrity, diversity and excellence \u2013 also known as our PRIDE values. \n     \n  In addition to our PRIDE values, UCSF is committed to equity \u2013 both in how we deliver care as well as our workforce. We are committed to building a broadly diverse community, nurturing a culture that is welcoming and supportive, and engaging diverse ideas for the provision of culturally competent education, discovery, and patient care. Additional information about UCSF is available at diversity.ucsf.edu \n     \n  Join us to find a rewarding career contributing to improving healthcare worldwide.\n    \n \n \n Equal Employment Opportunity \n \n    The University of California San Francisco is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, protected veteran or disabled status, or genetic information.\n    \n \n \n Organization \n \n    Campus\n    \n \n \n Job Code and Payroll Title \n \n    000599 DATA SYS ANL 4 \n    \n \n \n Job Category \n \n    Clinical Systems / IT Professionals \n    \n \n \n Bargaining Unit \n \n    99 - Policy-Covered (No Bargaining Unit) \n    \n \n \n Employee Class \n \n    Career\n    \n \n \n Percentage \n \n    100%\n    \n \n \n Location \n \n    Fully Offsite \n    \n \n \n Shift \n \n    Days\n    \n \n \n Shift Length \n \n    8 Hours \n    \n \n \n Additional Shift Details \n \n    M-F, 8am-5pm", "cleaned_desc": "This role is primarily responsible for producing data supporting the development of the annual Affirmative Action Plan, a critical compliance obligation of UCSF as a federal contractor.\n     \n  Under general direction of the Director of Data and Analytics, this position plays a key role in the development, deployment and adoption of data pipelines and administrative info r mat ion systems for the Vice Chancellor of Diversity and Outreach and its units.\n     \n  The staff member will be a resource for the Director of Data and Analytics to design, develop and manage technology that advances the mission of the Vice Chancellor of Diversity and Outreach's units. Focused on advocating for customer needs and influencing technology recommendations and decisions, this position ensures that our work is aligned with broadly defined enterprise IT objectives.\n     \n  This position is expected to work with minimal supervision and in partnership with the Director of Data and Analytics, to whom the role reports.\n     \n  This position is a key role within the Office of Diversity and Outreach responsible for developing the data infrastructure for the accurate and timely production of UCSF\u2019s affirmative action and equal employment opportunity programs in compliance with state and federal laws and regulations.\n     \n  In support of UCSF\u2019s equity and inclusion programs, this role is responsible for the design, specifications, coding, testing, implementation, maintenance, documentation, debugging, and troubleshooting of data warehouse solutions. Its work includes analyzing source system data, designing dimensional data models, developing ETLs, and creating data visualization products such as reports and dashboards. The position plays a critical role in requirement gathering, project plan planning, technical architecture design, data security, go-live implementation, and ongoing system support. The role also includes participation in the management of and / or development of standard data practices and guidelines, dictionaries, registries and / or services to be shared and used by other UCSF data resources. In addition to these duties, the position is required to perform any other tasks assigned to support the department\u2019s function.\n     \n  A data engineer is responsible for designing, developing, testing, documenting, and maintaining data warehouse and analytics architecture to meet the UCSF Office of Diversity and Outreach data and analytics needs.\n     \n  Collaborate with business and technology partners to gather business requirements and create architectural designs. \n  Use business domain knowledge to profile data and determine the best approaches to extract data into data warehouses. \n  Apply the Kimball dimensional data modeling technique to build and enhance the enterprise data warehouse. \n  Design, develop, test, document, and support new and existing ETL processes using Microsoft SQL Server Integration Services (SSIS), or other tools. \n  Demonstrate advanced proficiency in SQL programming and performance tuning. \n  Participates to create optimal and scalable technology standards to be used within department and throughout UCSF data community \n  Serves as leaders in data community to provide consultation of technical standards / guidelines \n  Develop business intelligence products, such as reports and dashboards, using Tableau or other data visualization tools. \n  Document business rules and metadata in the data dictionary and keep the information updated. \n  Possess excellent communication skills and the ability to articulate system designs and patterns to varying levels of leadership. \n  Participate in project planning, including scoping backlogs and determining estimates. \n  Maintain appropriate business domain knowledge in healthcare, education, research, finance, or business administration. \n \n \n  To see the salary range for this position (we recommend that you make a note of the job code and use that to look up):  TCS Non-Academic Titles Search (ucop.edu) \n  Please note: The compensation ranges listed online for roles not covered by a bargaining unit agreement are very wide, however a job offer will typically fall in the range of 80% - 120% of the established mid-point. An offer will take into consideration the experience of the final candidate AND the current salary level of individuals working at UCSF in a similar role. \n  For roles covered by a bargaining unit agreement, there will be specific rules about where a new hire would be placed on the range. \n  To learn more about the benefits of working at UCSF, including total compensation, please visit: https://ucnet.universityofcalifornia.edu/compensation-and-benefits/index.html \n   \n \n Department Description \n \n    The University of California, San Francisco (UCSF), has been at the forefront of addressing health care disparities and community health needs, while promoting diversity and inclusion among its students, trainees, staff and faculty. UCSF\u2019s commitment to diversity and inclusion is integral to fulfilling UCSF\u2019s mission to deliver the highest standard of excellence in health care delivery, scholarly research, community service, and training the next generation of health care professionals.\n     \n  The Office of Diversity and Outreach (ODO) serves as the campus leader in building diversity in all aspects of the UC San Francisco mission through ongoing assessment, development of new programs and building consensus. We collaborate with the four professional schools, the Graduate Division, and the medical centers, to promote diversity, equity, and inclusion across UCSF.\n     \n  The Vice Chancellor's Office of Diversity and Outreach (VCDO) includes oversight for the Center for Science Education and Outreach, Disability, LGBT, Multicultural and CARE Resource Centers, the Office for the Prevention of Harassment and Discrimination, Sexual Violence Prevention and Response, and the direct administrative office of the Vice Chancellor of Diversity and Outreach.\n     \n  The mission of the Office is to build a broadly diverse faculty, student, trainee and staff community, to nurture a culture that is welcoming and supportive, and to engage diverse ideas for the provision of culturally competent education, discovery and patient care. Our priority is to develop and execute a comprehensive strategic plan for diversity and outreach that supports UCSF\u2019s mission of advancing health worldwide, and the recruitment and retention of talented employees and students who contribute to our commitment to diversity and excellence.\n    \n \n \n Required Qualifications \n \n \n Bachelor's degree in related area and minimum 10 years of experience or equivalent experience/training \n  Must be able to work with multiple SQL Server and Oracle RDBMS environments \n  Experience developing and executing complex test plans. \n  Possesses advanced level skills required to gather, organize and review analyses on diverse equal employment opportunity affirmative action programs and initiatives, as well as those to present findings and make recommendations that are significant to a department or unit, verbally and in writing. \n  At least 3 years designing and creating reports, scorecards, and dashboards using Tableau, Power BI, or any data visualization tools. \n  Minimum of 5 years using at least one ETL tool such as Microsoft SQL Server Integration Services (SSIS). Capable of designing and developing data extraction, integration, and transformation solutions. Demonstrate the ability to create, code, and test ETL routines. Possess an understanding of the principles of effective ETL design. \n  At least 5 years writing Oracle SQL. Experienced in writing complex SQL queries and stored procedures. Understanding of query performance tuning. \n  At least 8 years writing T-SQL. Experienced in writing complex SQL queries and stored procedures. Understanding of query performance tuning. \n  Possess experience and skills in developing logical and physical dimensional data models with demonstrated understanding of fact and dimension design principles. Experienced in creating database objects and applying security. \n  Demonstrate complex problem-solving skills. \n  Self-motivated and works independently and as part of a team. Able to learn effectively and meet deadlines. \n  Demonstrate effective communication and interpersonal skills. Demonstrate ability to communicate technical information to technical and non-technical personnel at various levels in the organization. \n \n \n \n   Preferred Qualifications \n \n \n Master\u2019s degree in related area \n  Formal Education or Training in ETL development \n  Formal Education or Training in data modeling (esp Kimball Methodology) \n  Experience developing R scripts using Tidyverse and the Tidyverse design philosophy \n  Experience documenting, developing and communicating business processes and data flows using swim lane diagrams, sequence diagrams and flow charts, etc. \n  Experience with Office of Federal Compliance Programs (OFCCP) compliance obligations and affirmative action data requirements \n  Demonstrable experience actively engaged in the improvement of diversity and inclusion within a business, non-profit or academic enterprise. \n  Knowledge and appreciation for the value of diversity in improving performance of teams and enterprises. \n  Able to resolve and improve performance issues. Experience in working with other technical and business teams to carry out system performance tuning. \n  Excellent project leadership and management skills. \n  Highly advanced skills associated with software specification, design, modification, implementation and deployment of large-scale scope. \n  Advanced knowledge of secure software development \n  Experience in Python or R programming language \n  Familiarity with Affirmative Action reporting requirements for the production of the affirmative action plan \n  Experience designing SQL to query UC Path, Brassring, UC Recruit and other UC systems \n  Understanding of advanced statistical methods and data science principles. \n \n \n \n \n About UCSF \n \n    The University of California, San Francisco (UCSF) is a leading university dedicated to promoting health worldwide through advanced biomedical research, graduate-level education in the life sciences and health professions, and excellence in patient care. It is the only campus in the 10-campus UC system dedicated exclusively to the health sciences. We bring together the world\u2019s leading experts in nearly every area of health. We are home to five Nobel laureates who have advanced the understanding of cancer, neurodegenerative diseases, aging and stem cells.\n    \n \n \n Pride Values \n \n    UCSF is a diverse community made of people with many skills and talents. We seek candidates whose work experience or community service has prepared them to contribute to our commitment to professionalism, respect, integrity, diversity and excellence \u2013 also known as our PRIDE values. \n     ", "techs": ["tableau", "power bi", "microsoft sql server integration services (ssis)", "oracle sql", "t-sql", "tidyverse", "r", "python", "uc path", "brassring", "uc recruit"]}, "06dca8db8afd7888": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Director Data Engineering", "company": "Providence", "desc": "Description \n This position is remote with some in person meetings required and can only be located in the states of WA, OR, or CA. \n Leads highly technical data engineers. Accountable for all aspects of the technical design and build of modern data-centric solutions and applications to support clinical and operational processes across all parts of the enterprise health system. These solutions leverage cloud, big data, data science, and modern software development methodologies (such as SAFe) and tools and services (such as Snowflake and Databricks in Azure). Responsible for the buildout of our data engineering center of excellence for the enterprise and a community of practice across teams. Collaborates on technical solutions with teams at the Providence Global Center at Hyderabad, India. \n Providence caregivers are not simply valued \u2013 they\u2019re invaluable. Join our team at Enterprise Information Services and thrive in our culture of patient-focused, whole-person care built on understanding, commitment, and mutual respect. Your voice matters here, because we know that to inspire and retain the best people, we must empower them. \n Required Qualifications: \n \n Bachelor's Degree - Computer Engineering, Computer Science, Mathematics, Engineering. Or equivalent educ/experience, \n 10 or more years - Related experience in engineering or development roles. \n 8 years Leadership experience leading teams in a complex and fast-paced moving environment. \n Experience in cloud computing and data warehousing, Linux, Hadoop, Spark, and other NoSQL platforms. \n Strong experience working with both the product and technical sides of issues. \n Practical solutions development experience in a data-centric domain. \n Strong experience in managing and coaching a team of technical resources. \n \n Preferred Qualifications: \n \n Bachelor's Degree in Computer Science and Engineering, Mathematics, Engineering and related technical fields. \n \n The salary range listed for this position MIN:$79.20 to MAX:$131.66 per hour is based upon the primary work location Renton, WA posted. This position is remote. Salary range and offers are determined by internal pay equity and geographic cost of living differences. Salary range will vary from State and region. Salary max is limited to 75% range in order to continue to offer internal pay growth. We welcome open and transparent discussions on salary at Providence. \n Why Join Providence? \n Our best-in-class benefits are uniquely designed to support you and your family in staying well, growing professionally, and achieving financial security. We take care of you, so you can focus on delivering our Mission of caring for everyone, especially the most vulnerable in our communities. \n About Providence \n At Providence, our strength lies in Our Promise of \u201cKnow me, care for me, ease my way.\u201d Working at our family of organizations means that regardless of your role, we\u2019ll walk alongside you in your career, supporting you so you can support others. We provide best-in-class benefits and we foster an inclusive workplace where diversity is valued, and everyone is essential, heard and respected. Together, our 120,000 caregivers (all employees) serve in over 50 hospitals, over 1,000 clinics and a full range of health and social services across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. As a comprehensive health care organization, we are serving more people, advancing best practices and continuing our more than 100-year tradition of serving the poor and vulnerable. \n The amounts listed are the base pay range; additional compensation may be available for this role, such as shift differentials, standby/on-call, overtime, premiums, extra shift incentives, or bonus opportunities. \n Check out our benefits page for more information about our Benefits and Rewards. \n About the Team \n Providence Shared Services is a service line within Providence that provides a variety of functional and system support services for our family of organizations across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. We are focused on supporting our Mission by delivering a robust foundation of services and sharing of specialized expertise. \n We are committed to the principle that every workforce member has the right to work in surroundings that are free from all forms of unlawful discrimination and harassment. \n We are committed to cultural diversity and equal employment for all individuals. It is our policy to recruit, hire, promote, compensate, transfer, train, retain, terminate, and make all other employment-related decisions without regard to race, color, religious creed (including religious dress and grooming practices), national origin (including certain language use restrictions), ancestry, disability (mental and physical including HIV and AIDS), medical condition (including cancer and genetic characteristics), genetic information, marital status, age, sex (which includes pregnancy, childbirth, breastfeeding and related medical conditions), gender, gender identity, gender expression, sexual orientation, genetic information, and military and veteran status or any other applicable legally protected status. We will also provide reasonable accommodation to known physical or mental limitations of an otherwise qualified caregiver or applicant for employment, unless the accommodation would impose undue hardship on the operation of our business. \n We are a community where all people, regardless of differences, are welcome, secure, and valued. We value respect, appreciation, collaboration, diversity, and a shared commitment to serving our communities. We expect that all workforce members in our community will act in ways which reflect a commitment to and accountability for, racial and social justice and equality in the workplace. As such, we will maintain a workplace free of discrimination and harassment based on any applicable legally protected status. We also expect that all workforce members will maintain a positive workplace free from any unacceptable conduct which creates an intimidating, hostile, or offensive work environment. \n Requsition ID:  226882  \n Company:  Providence Jobs  \n Job Category:  Development/Engineering  \n Job Function:  Information Technology  \n Job Schedule:  Full time  \n Job Shift:  Day  \n Career Track:  Leadership  \n Department:  4011 SS IS HI DP 3  \n Address:  WA Renton 1801 Lind Ave SW  \n Work Location:  Providence Valley Office Park-Renton  \n Pay Range:  $79.20 - $131.66  \n The amounts listed are the base pay range; additional compensation may be available for this role, such as shift differentials, standby/on-call, overtime, premiums, extra shift incentives, or bonus opportunities.  \n Check out our benefits page for more information about our Benefits and Rewards. \n Providence is proud to be an Equal Opportunity Employer. Providence does not discriminate on the basis of race, color, gender, disability, veteran, military status, religion, age, creed, national origin, sexual identity or expression, sexual orientation, marital status, genetic information, or any other basis prohibited by local, state, or federal law.", "cleaned_desc": " 8 years Leadership experience leading teams in a complex and fast-paced moving environment. \n Experience in cloud computing and data warehousing, Linux, Hadoop, Spark, and other NoSQL platforms. \n Strong experience working with both the product and technical sides of issues. \n Practical solutions development experience in a data-centric domain. \n Strong experience in managing and coaching a team of technical resources. \n \n Preferred Qualifications: \n ", "techs": ["cloud computing", "data warehousing", "linux", "hadoop", "spark", "nosql platforms"]}, "d4c658ebe903afda": {"terms": ["data science", "data engineer"], "salary_min": 84981.15, "salary_max": 107605.07, "title": "Junior Data Mining and Analytics Engineer", "company": "Amivero", "desc": "Description: \n   The Amivero Team \n  Amivero\u2019s team of IT professionals delivers digital services that elevate the federal government, whether national security or improved government services. Our human-centered, data-driven approach is focused on truly understanding the environment and the challenge, and reimagining with our customer how outcomes can be achieved. \n  Our team of technologists leverage modern, agile methods to design and develop equitable, accessible, and innovative data and software services that impact hundreds of millions of people. \n  As a member of the Amivero team you will use your empathy for a customer\u2019s situation, your passion for service, your energy for solutioning, and your bias towards action to bring modernization to very important, mission-critical, and public service government IT systems. \n  Special Requirements \n \n  Active Top Secret Security Clearance \n  Bachelor\u2019s degree in Computer Science, Mathematics, Engineering, or related field \n  Practical working experience and advanced knowledge of cyber threats, tools, techniques, and processes. \n  Experience in data modeling and working with datasets of all sizes using a variety of data mining and data analysis methods/tools \n  This role is remote, but will require occasional meetings at the client location (Arlington, VA or Pensacola, FL) \n \n  The Gist\u2026 \n  We are looking for a Junior Data Mining and Analytics Engineer, your skillset will create useful and actionable insight for the customer through the development of analytic solutions (hardware, analytics, tools, techniques, practices, deployment, standards, performance specifications, etc.) for analytic use cases developed during the performance of this project. You will work closely with the Analytics Research team to identify platform enhancements that support the forward-looking analytics under consideration. The ideal candidate has extensive knowledge of a wide variety of systems and networks to include high-volume/high-availability systems. You are focused on results, a self-starter, and have demonstrated success for using analytics to drive the understanding, growth, and success of the analysis. \n  What Your Day Might Include\u2026 \n \n  Perform knowledge elicitation from customer subject matter experts and convert that to build analytic solutions \n  Design, engineer, and optimize sustainment of large-scale distributed computation platforms and supporting environment (ecosystems) for various stakeholders, business owners, and industry partner \n  Oversee the transition of services from third-party vendors to the analytic environment and be responsible for ad hoc and formal end-user training \n  Identify applicable data to perform analytics and create solutions to acquire, transform, and load or correlate data components to and from the analytic environment \n  Develop custom data modeling procedures to assist with data mining, modeling, and production \n  Assess the effectiveness and accuracy of new data sources and data gathering techniques \n  Develop processes and tools to monitor and analyze model performance and data accuracy \n  Interpret and communicate results to non-technical customers \n  Requirements:\n      You\u2019ll Bring These Qualifications\u2026 \n \n  Interpersonal skills and the ability to communicate effectively with various clients in order to explain and elaborate on technical details \n  Experience in developing analytic tools, processes, and governance for storing, modeling, capturing, and delivering data to the client\u2019s enterprise \n  Experience with computational notebook software such as Zeppelin or Jupyter \n  Experience with the application of visual analytics to computational analytic results \n  Fluency in one or more programming languages (e.g., Python, JavaScript, R, etc.) \n  Experience with database querying like SQL \n  Readiness to collaborate with engineering teams, product teams, and customers to develop prototypes and software products \n  Scaled Agile Framework (SAFe) experience \n  Amazon Web Services (AWS) Certified Cloud Practitioner or higher desired \n  Master\u2019s degree in Computer Science, Mathematics, Engineering, or related field \n  CompTIA Security+ or higher cybersecurity certification preferred \n \n  EOE/M/F/VET/DISABLEDAll qualified applicants will receive consideration without regard to race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. Amivero complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities.", "cleaned_desc": "  Bachelor\u2019s degree in Computer Science, Mathematics, Engineering, or related field \n  Practical working experience and advanced knowledge of cyber threats, tools, techniques, and processes. \n  Experience in data modeling and working with datasets of all sizes using a variety of data mining and data analysis methods/tools \n  This role is remote, but will require occasional meetings at the client location (Arlington, VA or Pensacola, FL) \n \n  The Gist\u2026 \n  We are looking for a Junior Data Mining and Analytics Engineer, your skillset will create useful and actionable insight for the customer through the development of analytic solutions (hardware, analytics, tools, techniques, practices, deployment, standards, performance specifications, etc.) for analytic use cases developed during the performance of this project. You will work closely with the Analytics Research team to identify platform enhancements that support the forward-looking analytics under consideration. The ideal candidate has extensive knowledge of a wide variety of systems and networks to include high-volume/high-availability systems. You are focused on results, a self-starter, and have demonstrated success for using analytics to drive the understanding, growth, and success of the analysis. \n  What Your Day Might Include\u2026   \n  Perform knowledge elicitation from customer subject matter experts and convert that to build analytic solutions \n  Design, engineer, and optimize sustainment of large-scale distributed computation platforms and supporting environment (ecosystems) for various stakeholders, business owners, and industry partner \n  Oversee the transition of services from third-party vendors to the analytic environment and be responsible for ad hoc and formal end-user training \n  Identify applicable data to perform analytics and create solutions to acquire, transform, and load or correlate data components to and from the analytic environment \n  Develop custom data modeling procedures to assist with data mining, modeling, and production \n  Assess the effectiveness and accuracy of new data sources and data gathering techniques \n  Develop processes and tools to monitor and analyze model performance and data accuracy    Interpret and communicate results to non-technical customers \n  Requirements:\n      You\u2019ll Bring These Qualifications\u2026 \n \n  Interpersonal skills and the ability to communicate effectively with various clients in order to explain and elaborate on technical details \n  Experience in developing analytic tools, processes, and governance for storing, modeling, capturing, and delivering data to the client\u2019s enterprise \n  Experience with computational notebook software such as Zeppelin or Jupyter \n  Experience with the application of visual analytics to computational analytic results    Fluency in one or more programming languages (e.g., Python, JavaScript, R, etc.) \n  Experience with database querying like SQL \n  Readiness to collaborate with engineering teams, product teams, and customers to develop prototypes and software products \n  Scaled Agile Framework (SAFe) experience \n  Amazon Web Services (AWS) Certified Cloud Practitioner or higher desired \n  Master\u2019s degree in Computer Science, Mathematics, Engineering, or related field \n  CompTIA Security+ or higher cybersecurity certification preferred \n ", "techs": ["bachelor's degree in computer science", "mathematics", "engineering", "or related field,\npractical working experience and advanced knowledge of cyber threats", "tools", "techniques", "and processes,\nexperience in data modeling and working with datasets of all sizes using a variety of data mining and data analysis methods/tools,\ncomputational notebook software such as zeppelin or jupyter,\none or more programming languages (e.g.", "python", "javascript", "r", "etc.),\ndatabase querying like sql,\nscaled agile framework (safe) experience,\namazon web services (aws) certified cloud practitioner or higher desired,\nmaster's degree in computer science", "mathematics", "engineering", "or related field,\ncomptia security+ or higher cybersecurity certification preferred."]}, "d33ff4836c5b6067": {"terms": ["data science"], "salary_min": 60000.0, "salary_max": 85000.0, "title": "Benefits Specialist (Remote Eligible)", "company": "Mathematica Policy Research", "desc": "Position Description:   About Mathematica:    Mathematica applies expertise at the intersection of data, methods, policy, and practice to improve well-being around the world. We collaborate closely with public- and private-sector partners to translate big questions into deep insights that improve programs, refine strategies, and enhance understanding using data science and analytics. Our work yields actionable information to guide decisions in wide-ranging policy areas, from health, education, early childhood, and family support to nutrition, employment, disability, and international development. Mathematica offers our employees competitive salaries, and a comprehensive benefits package, as well as the advantages of being 100 percent employee owned. As an employee stock owner, you will experience financial benefits of ESOP holdings that have increased in tandem with the company\u2019s growth and financial strength. You will also be part of an independent, employee-owned firm that is able to define and further our mission, enhance our quality and accountability, and steadily grow our financial strength. Read more about our benefits here: https://www.mathematica.org/career-opportunities/benefits-at-a-glance.     About the opportunity:    Mathematica's Human Resources department is seeking a Benefits Specialist to support and administer leave requests under the Family and Medical Leave Act (FMLA), parental leave, personal leave, workers-compensation, short-term or long-term disability plans in conjunction with state and local leave laws.     Responsibilities: \n \n \n  Manages HR Benefits Mailbox and responds to benefits inquiries from managers and employees on leave and disability \n  Provides staff guidance regarding coordination of benefits, eligibility notices, timesheets, PTO, benefit deductions, and parental leave \n  Maintains leave related internal guidance documents \n  Completes data entry for all leave related absences \n  Provides leave reporting to the payroll team on a semi-monthly cadence and ad-hoc leave reporting \n  Grants permissions to leave restricted timesheet codes \n  Plans, executes, and coordinates communication for leave law changes \n  Administers Parental Leave and Adoption benefit programs \n  Conducts bi-weekly claim review calls with The Hartford to manage the leave management partnership and act as an employee advocate for any claim issues \n  Identify and track claim related issues \n  Actively support the advancement of organizational diversity, equity, and inclusion efforts, and apply diversity, equity, and inclusion lens across job responsibilities. \n  Additional duties may be assigned as needed \n \n \n \n \n Position Requirements:     \n \n Bachelor\u2019s degree in Human Resources, Business Administration, or related degree (or equivalent experience) \n  Three plus years\u2019 experience in leave management administration \n  Proficiency with Microsoft Office, Excel, Word, PowerPoint, and Outlook \n  Working understanding of human resource and employee benefit principles, practices, and procedures \n  Ability to effectively communicate complex information in simple terms with all levels of employees and vendors \n  Ability to handle highly confidential information with discretion \n  High level of accuracy and attention to detail \n  Capable of multi-tasking, highly organized, and able to meet deadlines \n  The ability to manage work in a high-volume, fast-paced environment, and juggle multiple priorities \n  Excellent written and verbal communication skills \n  This position offers an anticipated annual base salary of $60,000 - $85,000.\n      \n  Available locations: Washington, DC; Princeton, NJ; Remote \n      \n \n \n We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.", "cleaned_desc": "", "techs": ""}, "a6ba29ef102b8ffc": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 180000.0, "title": "Technical Product Manager", "company": "Focal Systems", "desc": "What we\u2019re looking for \n  We\u2019re looking for a Sr. Technical Product Manager who is passionate about solving complex problems and who will push boundaries, influence strategy, and have a strong impact on product execution and quality.\n  \n \n  Reporting to the Head of Product, you will take on product leadership responsibilities while helping to envision, define and design the future of our platform. \n  In this role you will be responsible for developing products that enable retailers to improve their operations through data driven decision making, powered by deep learning and computer vision. \n \n \n  What you will be doing: \n \n \n  Guide the FocalOS product roadmap and prioritization. \n  Oversee and guide software development of our FocalOS products. \n  Work closely with the engineering and product design teams on executing the product vision. \n  Partner with the largest retailers in the world on integrating our technology into their operational processes. \n  Ensure features and bugs are reported and prioritized. \n  Keep JIRA and product charters up to date and maintained. \n  Run scrums and check-ins. \n  Plan, monitor and analyze key metrics for the performance of our models and infrastructure. \n  Proactively seek a firsthand understanding of issues and areas for improvement for our FocalOS products, including frequent client interviews and visits. \n \n \n  What you need to be successful: \n \n \n  6+ years professional experience including  3+ years in a Product Management  role managing an enterprise product, experience with analytics and/or computer vision products a plus and  2+ years as a Software Engineer \n  Technical degree (CS / EE / Math) required. \n  Strong knowledge of software development processes, in particular web development. \n  Knowledge of SQL and data science required. \n  Knowledge of product design processes and experience conducting user research required. \n  Knowledge of React, Redux and Python preferred. \n  Proven ability to plan and manage a long-term product roadmap. \n  Demonstrated skill to devise and implement product processes for maximum efficiency and productivity. \n  Startup mentality, team player and willing to work 40+ hours a week. \n  Knowledge of retail is a plus. \n \n \n  Why join Focal Systems: \n \n \n  Accelerate your career growth by joining our fast-paced start-up where advancement opportunities are plentiful. \n  You will be presented with attractive equity that is increasing in value every year in addition to competitive salary. \n  Work with our exceptional team of A-players who are hard-working, fun-loving professionals from some of the most eminent universities, research labs, and tech companies of our time. \n  Join an organization with strong Values and Mission, which define our approach to business and have successfully guided us since inception. \n  Be surrounded by outstanding partners. We work with 10+ of the largest retailers in the world and have a world-class roster of investors, advisors, and partners to support & advise us in our endeavors. \n \n \n  What we offer \n  We care deeply about the health, happiness, and wellbeing of all our employees.\n    We offer:\n  \n \n  Competitive Salary & Attractive Stock. \n  Health Insurance. \n  Catered lunches. \n  Paid Time Off. \n  Quarterly Team Retreats. \n  Education grant. \n  Learning plans. \n \n \n  Location:  Although we have a slight preference for someone based in the Bay Area, we will also happily consider US-based remote candidates", "cleaned_desc": " \n  6+ years professional experience including  3+ years in a Product Management  role managing an enterprise product, experience with analytics and/or computer vision products a plus and  2+ years as a Software Engineer \n  Technical degree (CS / EE / Math) required. \n  Strong knowledge of software development processes, in particular web development. \n  Knowledge of SQL and data science required. \n  Knowledge of product design processes and experience conducting user research required. \n  Knowledge of React, Redux and Python preferred. \n  Proven ability to plan and manage a long-term product roadmap. \n  Demonstrated skill to devise and implement product processes for maximum efficiency and productivity. \n  Startup mentality, team player and willing to work 40+ hours a week. \n  Knowledge of retail is a plus. \n ", "techs": ["react", "redux", "python", "sql"]}, "c65d0af899a3cdb2": {"terms": ["data science"], "salary_min": 8075.0, "salary_max": 9834.0, "title": "RESEARCH SCIENTIST, INFECTIOUS DISEASE MODELING", "company": "University of Washington", "desc": "Research Scientist, Infectious Disease Modeling \n \n \n \n \n \n \n \n \n \n        Req #:\n        \n \n        227871\n        \n \n \n \n \n        Department:\n        \n \n        INSTITUTE FOR HEALTH METRICS & EVALUATIONS (IHME)\n        \n \n \n \n \n        Job Location:\n        \n \n        Remote/Hybrid, Seattle - Other \n        \n \n \n \n \n        Job Location Detail:\n        \n \n        Office is located in Seattle; position is eligible to work fully remote within the U.S. (excluding U.S. territories)\n        \n \n \n \n \n        Posting Date:\n        \n \n        10/18/2023\n        \n \n \n \n \n        Closing Info:\n        \n \n        Closes On 11/01/2023\n        \n \n \n \n \n        Salary:\n        \n \n        $8,075 to $9,834 per month\n        \n \n \n \n \n        Other Compensation:\n        \n \n \n \n \n \n        Union Position:\n        \n \n        Yes\n        \n \n \n \n \n        Shift:\n        \n \n        First Shift \n        \n \n \n \n \n        Benefits:\n        \n \n        As a UW employee, you will enjoy generous benefits and work/life programs. \n        \n \n \n \n \n \n \n \n \n \n    As a UW employee, you have a unique opportunity to change lives on our campuses, in our state and around the world. UW employees offer their boundless energy, creative problem-solving skills and dedication to build stronger minds and a healthier world. \n     \n  UW faculty and staff also enjoy outstanding benefits, professional growth opportunities and unique resources in an environment noted for diversity, intellectual excitement, artistic pursuits and natural beauty. \n     \n  The Institute for Health Metrics and Evaluation (IHME) is an independent research center at the University of Washington. Its mission is to deliver to the world timely, relevant, and scientifically valid evidence to improve health policy and practice. IHME carries out its mission through a range of projects within different research areas including the Global Burden of Diseases, Injuries, and Risk Factors; Future Health Scenarios; Cost Effectiveness and Efficiency; Resource Tracking; and Impact Evaluations. Our vision is to provide policymakers, donors, and researchers with the highest-quality quantitative evidence base so all people live long lives in full health. \n     \n  IHME is committed to providing the evidence base necessary to help solve the world\u2019s most important health problems. This requires creativity and innovation, which are cultivated by an inclusive, diverse, and equitable environment that respects and appreciates differences, embraces collaboration, and invites the voices of all IHME team members. \n     \n \n IHME has an excellent opportunity for a Research Scientist to join our Infectious Disease Modeling team. \n \n \n POSITION PURPOSE \n  We are looking for someone ready to advance in their career in global health research. As a Research Scientist, you will be contributing to research design and training, leading, and/or mentoring junior staff. IHME researchers analyze and produce key estimates for their assigned research team and will assess all available relevant quantitative data \u2013 including those on causes of death, epidemiology, and a range of determinants such as education and income \u2013 from surveys, vital registration, censuses, literature, registries, and administrative records. \n     \n  You will be integrally involved in producing, critiquing, improving, and disseminating results. You are someone who is capable of keeping your team on track to meet deadlines and research objectives. You already have a publication record, and at IHME, you will build out your portfolio with several peer-reviewed papers. You thrive in a collaborative work environment and are capable of working on multiple projects concurrently while meeting deadlines. You keep current on recent scientific, engineering, and technical advances and are able to translate these into your research. \n     \n  This position is contingent on project funding availability and is currently funded through at least May 2026. \n     \n \n DUTIES AND RESPONSIBILITIES \n \n Exhibit command of malaria epidemiology and malaria programmatic activity including the methodology and its components.    \n Independently carry out quantitative analyses and participate in reciprocal research projects. Interpret and vet results from junior staff, formulate conclusions, and inform team leaders.    \n Develop, quality check, and distribute complex datasets to be used in epidemiological and statistical analyses.    \n Develop and implement new computational and statistical methods. Create, test, and use relevant computer code (R preferred). Maintain, modify, and execute analytic machinery that generates results.    \n Draft presentations and manuscripts and contribute to funding proposals. Lead and co-author scientific articles in peer-reviewed journals.    \n Maintain scientific awareness and intellectual agility with data, methods, and analytic techniques.    \n May lead and/or mentor junior staff.    \n Provide ideas and content for the development of internal trainings. Teach established trainings.    \n Contribute to research design.    \n Other duties as assigned that fall within reasonable scope of research team, including collaboration with colleagues in malaria programs in malaria endemic countries.      MINIMUM REQUIREMENTS     \n Master\u2019s Degree in public health, epidemiology, statistics, biostatistics, math, economics, quantitative social sciences, or related discipline plus four years' related experience, or equivalent combination of education and experience.      ADDITIONAL REQUIREMENTS     \n The ideal candidate would have some experience working with a malaria program in a malaria-endemic setting.    \n Excellent analytic, critical thinking, and quantitative skills.    \n Results- and detail-oriented individual who can initiate and complete tasks under tight deadlines and changing priorities both independently and in a team environment. Flexibility with hours and workload is key.    \n Experience devising and executing statistical modeling techniques.    \n Demonstrated ability to quickly recognize problems in results and identify root causes in data, methods, and code.    \n Ease in designing, executing, and troubleshooting code in R.    \n Excellent written and oral communication skills required, including track record of success in coauthorship on multiple scientific papers, presenting results, and representing research at meetings.    \n Ability to work both independently and in collaboration with a team.    \n A long-term interest in a research scientist position contributing to the overall mission of our research.    \n A commitment to working to alongside others at IHME to illuminate the health impacts of systemic racism and to work within IHME to make our organization more diverse and inclusive. See IHME\u2019s DEI statement here: . https://www.healthdata.org/about/careers/dei      DESIRED QUALIFICATIONS     \n PhD in public health, epidemiology, statistics, biostatistics, math, economics, or quantitative social sciences plus two years\u2019 experience preferred.    \n Experience with machine learning, data mining, and analytic techniques.    \n Experience mentoring and developing junior employees on soft and technical skills.    \n Experience with project management methods.    \n Peer-reviewed publication record.      CONDITIONS OF EMPLOYMENT     \n Weekend and evening work sometimes required.    \n This position is open to anyone authorized to work in the US. The UW is not able to sponsor visas for staff positions.    \n Office is located in Seattle, Washington. This position is eligible to work fully remote in the US; work schedule required to overlap 50% of IHME office hours, between 8 a.m. and 6 p.m. Pacific Time.      Application Process:  The application process may include completion of a variety of online assessments to obtain additional information that will be used in the evaluation process. These assessments may include Work Authorization, Cover Letter and/or others. Any assessments that you need to complete will appear on your screen as soon as you select \u201cApply to this position\u201d. Once you begin an assessment, it must be completed at that time; if you do not complete the assessment you will be prompted to do so the next time you access your \u201cMy Jobs\u201d page. If you select to take it later, it will appear on your \"My Jobs\" page to take when you are ready. Please note that your application will not be reviewed, and you will not be considered for this position until all required assessments have been completed.   \n \n \n \n \n \n \n Committed to attracting and retaining a diverse staff, the University of Washington will honor your experiences, perspectives and unique identity. Together, our community strives to create and maintain working and learning environments that are inclusive, equitable and welcoming. \n \n \n The University of Washington is an affirmative action and equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, gender expression, national origin, age, protected veteran or disabled status, or genetic information. \n To request disability accommodation in the application process, contact the Disability Services Office at 206-543-6450 or dso@uw.edu. \n \n \n Applicants considered for this position will be required to disclose if they are the subject of any substantiated findings or current investigations related to sexual misconduct at their current employment and past employment. Disclosure is required under Washington state law.", "cleaned_desc": "", "techs": ""}, "c5c7814645cbbc1b": {"terms": ["data science"], "salary_min": 70000.0, "salary_max": 90000.0, "title": "Quality Assurance Analyst (Remote Eligible)", "company": "Mathematica Policy Research", "desc": "Position Description:     \n Mathematica applies expertise at the intersection of data, methods, policy, and practice to improve well-being around the world. We collaborate closely with public- and private-sector partners to translate big questions into deep insights that improve programs, refine strategies, and enhance understanding using data science and analytics. Our work yields actionable information to guide decisions in wide-ranging policy areas, from health, education, early childhood, and family support to nutrition, employment, disability, and international development. Mathematica offers our employees competitive salaries, and a comprehensive benefits package, as well as the advantages of being 100 percent employee owned. As an employee stock owner, you will experience financial benefits of ESOP holdings that have increased in tandem with the company\u2019s growth and financial strength. You will also be part of an independent, employee-owned firm that is able to define and further our mission, enhance our quality and accountability, and steadily grow our financial strength. Read more about our benefits here:  https://www.mathematica.org/career-opportunities/benefits-at-a-glance \n  We are seeking an energetic and highly motivated person to join our team as a  Quality Assurance Analyst  where you will play a key role on client projects by using business and technical requirements to develop test plans and perform testing procedures. You will collaborate with both technical and non-technical staff to deliver high quality software and systems. As part of the Health Analytic Systems and Technology (AST) department, this position requires a high degree of technical aptitude related to systems and software development and a willingness to develop business and technical knowledge to meet project demands. \n  Our ideal candidate thrives working in collaborative team environments; is comfortable interacting with staff who have varying degrees of technical knowledge; has strong problem-solving skills with a drive to understand how things work; and isn\u2019t afraid to ask questions. As a Quality Assurance Analyst, teams will rely on your expertise and aptitude to devise testing approaches (manual and/or automated) that effectively root out issues in data platforms with emphasis on data quality and accuracy, ETL pipelines and client-facing visualization artifacts (e.g., reports, dashboards). \n  Responsibilities: \n \n  Review requirements, identify test scenarios and write test cases for data validation across all facets of data platforms \n  Execute test cases (manual or automated), analyze and present results for data validation across all facets of data platforms \n  Report defects and coordinate with the development team for defect resolution and retesting \n  Write technical documentation, including test strategy/test plans and requirements traceability matrices (RTMs) \n  Evaluate product code and resultant output according to specifications. \n  Understand and provide constructive feedback on business, security, and technical requirements from the testing and test automation perspective \n  Analyze bugs and errors for continuous quality improvement \n  Present and report bugs and defects using tools (e.g., Jira, Confluence) to technical and non-technical team members \n  Prepare regular reporting on progress and testing statistics \n  Work with cross-functional teams to ensure quality throughout the systems development lifecycle \n \n \n \n \n Position Requirements:     \n Requirements: \n \n  Bachelor\u2019s degree in Computer Science, Computer Information Systems, or similar degree, or equivalent experience and skills \n  3+ years of experience as a QA engineer or tester \n  Experience with end\u2013to-end testing framework and processes for enterprise data platforms including BI platforms \n  Experience with SQL and relational databases like MySQL, SQL Server, etc. \n  Experience with programming languages such as Python, .NET \n  Experience using Agile and iterative development methodologies \n  Knowledge of the systems development life cycle (SDLC) including coding standards and reviews, version control, and testing \n  Familiar with automation frameworks and tools for test automation \n \n  This position offers an anticipated annual base salary range of $70,000- $90,000. This position may be eligible for a discretionary bonus based on company and individual performance. \n  STAFFING AGENCIES AND THIRD PARTY RECRUITERS: Mathematica is not accepting candidates for this role or any technical role from staffing agencies or third party recruiters. Please do not contact technical or senior staff at Mathematica or share unsolicited resumes. All agency inquiries go through the talent acquisition team and will be routed accordingly. \n  Available Locations:  Remote; Washington, DC; Princeton, NJ \n  To choose \"remote\" as your location, select \"no preference.\" \n  #LI-AR1 \n \n \n \n We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.", "cleaned_desc": "  Report defects and coordinate with the development team for defect resolution and retesting \n  Write technical documentation, including test strategy/test plans and requirements traceability matrices (RTMs) \n  Evaluate product code and resultant output according to specifications. \n  Understand and provide constructive feedback on business, security, and technical requirements from the testing and test automation perspective \n  Analyze bugs and errors for continuous quality improvement \n  Present and report bugs and defects using tools (e.g., Jira, Confluence) to technical and non-technical team members \n  Prepare regular reporting on progress and testing statistics \n  Work with cross-functional teams to ensure quality throughout the systems development lifecycle    3+ years of experience as a QA engineer or tester \n  Experience with end\u2013to-end testing framework and processes for enterprise data platforms including BI platforms \n  Experience with SQL and relational databases like MySQL, SQL Server, etc. \n  Experience with programming languages such as Python, .NET \n  Experience using Agile and iterative development methodologies \n  Knowledge of the systems development life cycle (SDLC) including coding standards and reviews, version control, and testing \n  Familiar with automation frameworks and tools for test automation \n ", "techs": ["jira", "confluence", "mysql", "sql server", "python", ".net"]}, "93ce0fa2d914da5f": {"terms": ["data science", "mlops"], "salary_min": 116975.45, "salary_max": 148116.98, "title": "Sr Data Scientist (A.I.)", "company": "Blackpoint Cyber", "desc": "Blackpoint Cyber is a provider of leading-edge cybersecurity threat hunting, detection, and response technology. Blackpoint was founded by former National Security Agency (NSA) cyber operations experts that applied their expertise to bring nation/state grade technologies to commercial customers around the world \n  What You\u2019ll Do  Blackpoint Cyber is a provider of leading-edge cybersecurity threat hunting, detection, and response technology. Blackpoint was founded by former National Security Agency (NSA) cyber operations experts that applied their expertise to bring nation/state grade technologies to commercial customers around the world.    We are looking for an experienced Sr. Data Scientist who will operate in a technical lead role for the data science function of our A.I. business unit. Candidates will directly support Blackpoint\u2019s cyber security mission, helping to stop cyber-attacks, and protecting Blackpoint\u2019s rapidly growing customer base.     Summary: \n  As Sr. Data Scientist, you will be responsible for building out Blackpoint Cyber\u2019s data science solutions to support development of our A.I. products and features. You will report directly to the Head of Artificial Intelligence.     Who You Are:  Blackpoint Cyber is looking for someone who has: \n \n  5+ years of experience in hands-on Data Science, with a track record of delivering A.I. products and services into production. \n  Experience building in the well-architected mindset\u2014for efficiency, performance, security, and reliability. \n  Strong analytical and problem-solving abilities, with a focus on data-driven decision-making. \n \n \n  Excellent communication and interpersonal skills, with the ability to influence and collaborate with stakeholders at all levels. \n \n  What You\u2019ll Bring: \n \n  Experienced in: \n \n \n  Cloud-based ML development (AWS) \n \n \n  Data Ingestion & Wrangling (S3, EC2, SageMaker) \n  Feature Engineering (Feature Pipelines, Feature Store) \n  Model Development, Analysis, & Deployment (SageMaker) \n  Inference Streams & Event-driven Processing (Kafka, Kinesis) \n  Scripting Language (Python, Bash) \n \n \n  Query Language (SQL, KsqlDB) \n  Containerized Services (Docker, Kubernetes) \n  MLOps Workflows (Sagemaker, MLFlow) \n  GitFlow & DevOps Best Practices \n \n \n  Nice to Have: \n \n \n  Time-Series Analysis \n  Transformer Neural Nets \n  Kubeflow \n  DVC (data versioning) \n  Agile Scrum \n \n \n  Programming (Java, Scala) \n  Experience in Cybersecurity, IoT, or NLP fields \n \n  How You\u2019ll Make an Impact: \n \n  Define, implement, train, and evaluate ML models. \n \n \n  Design and implement algorithms to ingest, wrangle, and transform model input data. \n  Conduct feature engineering to extract, construct, derive, and evaluate model inputs. \n  Perform statistical analyses per stakeholder requirements and modeling objectives. \n  Deploy models and feature engineering algorithms as scalable containerized solutions. \n  Develop model governance utilities and dashboards to monitor, report, and visualize performance of deployed solutions. \n \n \n  Implement data, feature, and model lifecycle best practices. \n  Contribute to A.I. architecture and design decisions. \n  Collaborate closely with cross-functional teams, including Engineering, Blackpoint Cyber\u2019s Security Operations Center (SOC), and our Adversary Pursuit Group (APG). \n \n  Interested? \n  To apply, please prepare a resume and cover letter. For more information about Blackpoint Cyber, visit our website at www.blackpointcyber.com. \n  Blackpoint Cyber welcomes and encourages applications from qualified individuals of all races, colors, religions, sex, sexual orientation, gender identity or expression, national origin, age, marital status, or any other legally protected status. We are committed to equality of opportunity in all aspects of employment. \n  We thank everyone for their interest, but only those candidates selected for an interview will be contacted. \n  Blackpoint\u2019s Response to COVID-19 \n  We take a very proactive response to COVID-19 with all staff working remotely from home. Hygiene protocols are in place throughout the building and office if there is a need to visit. Our company\u2019s systems and processes are set in such a manner that there should be no limitations to your productivity when working from home. We are in constant communication globally. During these challenging times, Blackpoint Cyber takes the opportunity to envision a new way of working together while continuing to collaborate meaningfully with those whom we serve and defend. \n  Blackpoint Cyber welcomes and encourages applications from qualified individuals of all races, colors, religions, sex, sexual orientation, gender identity or expression, national origin, age, marital status, or any other legally protected status. We are committed to equality of opportunity in all aspects of employment. \n  We thank everyone for their interest, but only those candidates selected for an interview will be contacted.", "cleaned_desc": "", "techs": ""}, "7c89fe57b8bea287": {"terms": ["data science"], "salary_min": 124699.51, "salary_max": 157897.36, "title": "Senior Program Manager", "company": "Atlas AI", "desc": "Unit: Applied Data Science / Function: Spatial Data Science & Machine Learning Programs \n  Atlas AI has built a geospatial artificial intelligence platform that helps every organization anticipate changing societal conditions\u2014where people live, where wealth and poverty are concentrated, how the physical makeup of communities is evolving, and more\u2014to determine where to invest today to prepare for the world of tomorrow. Our customers, which range from the World Bank and global NGOs to multinational corporations, use our platform to accelerate growth, future proof supply chains, target resources to vulnerable populations and build greater resilience to climate change. We operate globally and are proud to do so with a global team that integrates frontier AI research with world class engineering, all aimed at promoting a more inclusive and low carbon future for society. \n  We are looking to meet candidates passionate about the use of technology to advance sustainable development objectives, and with the drive to build a high-growth global software and analytics company. \n  As a Senior Program Manager at Atlas AI, you will help advance our partners\u2019 missions by leading processes to define, scope, plan, resource, and execute existing and planned programs and studies. The Senior Program Manager is a leader in our Applied Data Science team, reporting to the Vice President, Data & Analytics and sits at the intersection of business development, analytics, and program delivery at the company. This role requires a scrappy entrepreneur, someone able to advance a range of strategic priorities \u2013 from working with Atlas AI\u2019s applied data science and software engineering team to advancing key business opportunities, to exploring new markets, to facilitating technical roadmap discussions \u2013 whatever it takes to build on the company\u2019s momentum to-date. Ultimately success in this role will be measured by the ability to advance a winning program development and management agenda and to facilitate clear objectives, and ongoing alignment and roadmap execution across a deeply talented and mission-driven engineering and research organization. \n  The Senior Program Manager will interface with leading US and international-based multi-disciplinary scholars, stakeholders, sponsors, practitioners, data scientists, machine learning engineers, and field research teams. Your management and leadership of programs will culminate in pragmatic reports, policy briefs, and publications. You will also identify and explore promising avenues for data product and platform development in a global setting. In this senior role, you will influence the trajectory and portfolio of our applied data science activities. \n  As a Senior Program Manager, you will: \n \n  Manage a subset of ongoing well-funded, multi-year development initiatives \n  Build relationships with program partners, sponsors and beneficiary stakeholders \n  Mentor and help build the Applied Data Science team in your areas of expertise \n  Identify and develop successful proposals for program opportunities that are aligned with our mission and goals \n  Design mixed methods work flows, and oversee its execution \n  Assure quality of results in relation to the motivation and objectives of the program scope \n  Manage budget, resources, and associated contract requirements \n  Author peer-reviewed as well as practitioner-focused publications \n  Develop narratives to communicate results to broad and diverse audiences \n  Assist the Product Engineering team in designing and scaling up research prototypes \n  Close the feedback loop with Innovation, Product, and Engineering teams to deliver customer experience and market insights \n \n  What you\u2019ll bring: \n \n  PhD or equivalent experience in a quantitative or mixed-methods discipline applied to a domain such as energy, transportation, telecommunications, networks, civil infrastructure systems, built environment, or economic development \n  Technical knowledge in artificial intelligence, geospatial engineering, ML solutions engineering or other relevant domains underpinning the company\u2019s product strategy \n  Seven or more years of work experience in research and program management, technical consulting, project management, or similar senior management roles \n  A track record of leading research and applied investigative engagements through to completion, with an emphasis on the delivery of contractual obligations \n  Facility with individual as well as collaborative work products and modes such as models, papers, reports, workshops, focus groups \n  A startup background or at minimum an understanding of how to thrive in a startup environment and culture \n  Exceptional writing skills to both inform and influence internal and customer stakeholders \n  A coalition building mindset - someone who can be the glue across disparate teams and personnel \n  A proclivity towards naturally defining needed processes and building systems where they don\u2019t exist \n \n  What we\u2019re looking for: \n \n  Exceptional interpersonal communication, both written and oral \n  Independence and ownership of work in an entrepreneurial, start-up environment \n  Intellectual curiosity and an investigative mindset \n  Desire to contribute across cultures in a dynamic global environment \n \n  We are ideally looking for a candidate in New York, NY (remote with meet-ups occasionally in-person) or remote. We're a distributed team that offers a casual and inclusive working environment, competitive compensation, and great benefits. We are a values-driven company, and take great pride in building products that are designed to improve lives and foster development across emerging markets. \n  Salary range for candidates depending upon level of experience and location: $130,000 - $160,000. \n  Atlas AI is an affirmative action and equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, disability, age, sexual orientation, gender identity, national origin, veteran status, or genetic information. Atlas AI is committed to providing access, equal opportunity and reasonable accommodation for individuals with disabilities in employment, its services, programs, and activities. To request reasonable accommodation, contact Whitney Jones, Head of Operations at: whitney@atlasai.us.   \n   \n p6aDQ4hoin", "cleaned_desc": "", "techs": ""}, "b9e03ad536f7ef77": {"terms": ["data science", "data analyst"], "salary_min": 70000.0, "salary_max": 90000.0, "title": "Business Intelligence Analyst", "company": "LifeStance Health", "desc": "At LifeStance Health, we strive to help individuals, families, and communities with their mental health needs. Everywhere. Every day. It\u2019s a lofty goal; we know. But we make it happen with the best team in mental healthcare.\n  \n \n \n  Thank you for taking the time to explore a career with us. As the fastest growing mental health practice group in the country, now is the perfect time to join our corporate team!\n   \n \n \n \n \n ROLE OVERVIEW   \n \n \n \n \n  The Business Intelligence Analyst is responsible for the development and support of BI solutions. They are customer centric, enjoy challenges, possess a proactive approach to getting things done in developing environment and can manage multiple priorities and deadlines. This role will bring value to the organization by developing an understanding of how data is captured, accessed, and used across the different business functions. In addition, utilizing their ability to critically define and address business challenges presented with data query and modeling techniques.\n   \n \n \n \n \n BENEFITS \n \n \n   As a full-time employee of LifeStance Health, the following benefits are offered: medical, dental, vision, AD&D, short and long-term disability, and life insurance. Additional benefits include a 401k retirement savings with employer match, paid parental leave, paid time off, holiday pay and an Employee Assistance Program.\n  \n \n \n  RESPONSIBILITIES \n \n \n \n  Lead data analysis, data modeling, and evaluation of new or underutilized features of the company\u2019s BI platform \n  Maintain business intelligence workspace structure and access according to established protocol \n  Troubleshoot end-user experience issues and provide solutions through break fixes and/or user training and education \n  Translate business needs into cross-platform requirements, understand where the required data resides, and develop proofs of concept for end-users \n  Understand how data is captured in source systems, how its structured in the data warehouse, and how to develop modeling proofs of concept to address business requirements \n  Develop, publish, and disseminate BI content with a scalable and user-friendly approach while adhering to sound data governance protocol \n  Help define how data can increasingly become an integral part of day-to-day decision making \n  Partner with data engineering and development operations colleagues to maintain shared customer service standards and resolve issues in a timely manner \n \n \n \n  SKILLS & EXPERIENCE \n \n \n   \n \n \n  Bachelor's degree in Analytics, Data Science, Statistics, Finance or other discipline providing a foundation for practical application of modeling and analytics in a business setting \n  1+ year of experience in a business intelligence or related role.  New graduates considered with demonstration of critical thinking and potential through references and/or project results \n  Experience with data modeling and visualization platforms such as Power BI, Tableau, Spotfire, Qlik or others with the ability to be \u2018tool agnostic\u2019 \n  SQL, JSON, M, R, DAX, Python or other relevant data and query languages \n  Proactively learn new skills and techniques to address current challenges or as part of an always-be-learning mindset \n  Is well-spoken and comfortable interacting with colleagues at different levels and functions of the organization \n  Qualified candidates must be legally authorized to be employed in the United States \n  LifeStance is an EEO/Affirmative Action Employer and does not discriminate on the basis of age, race, color, religion, gender, sexual orientation, gender identity, gender expression, national origin, protected veteran status, disability or any other legally protected status \n  Demonstrates awareness, inclusivity, sensitivity, humility, and experience in working with individuals from diverse ethnic backgrounds, socioeconomic statuses, sexual orientations, gender identities, and other various aspects of culture \n \n \n  LifeStance Health (NASDAQ: LFST) is one of the nation\u2019s largest providers of virtual and in-person outpatient mental health care for children, adolescents and adults experiencing a variety of mental health conditions. LifeStance Health is based in Scottsdale, Arizona.\n  \n \n \n  Our Vision: A truly healthy society where mental and physical healthcare are unified to make lives better. \n  \n \n  Our Mission: To help people lead healthier, more fulfilling lives by improving access to trusted, affordable and personalized mental healthcare. \n  \n \n  Our Values:\n   \n \n \n \n \n Delivering Compassion  - We care for people unconditionally and act with empathy always. \n  \n \n Building Relationships  - We are collaborative, building enduring relationships to achieve more together. \n  \n \n Celebrating Difference  - We respect the diversity of every individual\u2019s lived experiences.\n  \n \n \n  Learn more at www.lifestance.com.", "cleaned_desc": "  Troubleshoot end-user experience issues and provide solutions through break fixes and/or user training and education \n  Translate business needs into cross-platform requirements, understand where the required data resides, and develop proofs of concept for end-users \n  Understand how data is captured in source systems, how its structured in the data warehouse, and how to develop modeling proofs of concept to address business requirements \n  Develop, publish, and disseminate BI content with a scalable and user-friendly approach while adhering to sound data governance protocol \n  Help define how data can increasingly become an integral part of day-to-day decision making \n  Partner with data engineering and development operations colleagues to maintain shared customer service standards and resolve issues in a timely manner \n \n \n \n  SKILLS & EXPERIENCE \n \n \n   \n \n \n  Bachelor's degree in Analytics, Data Science, Statistics, Finance or other discipline providing a foundation for practical application of modeling and analytics in a business setting \n  1+ year of experience in a business intelligence or related role.  New graduates considered with demonstration of critical thinking and potential through references and/or project results ", "techs": ["troubleshoot end-user experience issues", "translate business needs into cross-platform requirements", "develop proofs of concept for end-users", "understand how data is captured in source systems", "develop modeling proofs of concept", "develop", "publish", "and disseminate bi content", "adhere to data governance protocol", "define how data can become an integral part of decision making", "partner with data engineering and development operations", "maintain shared customer service standards", "resolve issues in a timely manner", "bachelor's degree in analytics", "data science", "statistics", "finance", "1+ year of experience in a business intelligence role."]}, "32b2ee61bad29c5b": {"terms": ["data science"], "salary_min": 72095.98, "salary_max": 91289.57, "title": "Fraud Behavioral Insights, Customer Identity Analyst", "company": "Afterpay", "desc": "Company Description \n \n \n \n     It all started with an idea at Block in 2013. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic ecosystem, developing unique financial products, including Afterpay/Clearpay, to provide a better way to send, spend, invest, borrow and save to our 47 million monthly active customers. We want to redefine the world\u2019s relationship with money to make it more relatable, instantly available, and universally accessible.\n     \n  Today, Cash App has thousands of employees working globally across office and remote locations, with a culture geared toward innovation, collaboration and impact. We\u2019ve been a distributed team since day one, and many of our roles can be done remotely from the countries where Cash App operates. No matter the location, we tailor our experience to ensure our employees are creative, productive, and happy.\n     \n  Check out our locations, benefits, and more at cash.app/careers.\n    \n \n \n \n \n  Job Description \n \n \n  Cash App is seeking a Fraud Behavioral Insights, Customer Identity Analyst to join our dynamic Behavioral Insights Team. A Fraud Behavioral Insights, Customer Identity Fraud Analyst leverages natural analytical and problem-solving skills to analyze large structured and unstructured data sets to identify trends, anomalies and inauthentic behaviors across Cash App accounts and products. This position relies on decisions made independently, with high precision and attention to detail. \n  This position will collaborate often with teammates, as well as work with many organizations within the business, such as Data Science, Machine Learning Modeling, Engineering, Product, Business Operations, Risk Operations, Compliance, and more. You will help drive innovation and influence Cash App\u2019s fraud roadmap, programs, and processes. \n  The ideal candidate possesses exceptional analytical and communication skills. They must also enjoy ambiguous problem solving and have strong self-motivation skills. This role requires a bias toward taking action in a fast-paced and dynamic environment. \n  You Will \n \n  Become an expert on customer behaviors and authentic and inauthentic activity within Cash App\u2019s ecosystem \n  Master the Identity domain of risk-adjacent behaviors and how your domain affects Cash App \n  Learn to investigate and analyze complex data sets to resolve business challenges, identify opportunities for improvement, and provide insights and solutions \n  Leverage industry experience and expertise to analyze existing risks within product offerings that require a high level of attention to detail \n  Partner with internal business teams to identify and confirm emerging fraud trends and potential customer impact due to risk controls, both ahead of product launches and in an ongoing capacity \n  Respond promptly to internal business partners and exercise exceptional communication skills to optimize each contact \n  Must be able to take initiative, plan, organize and prioritize projects with overlapping deadlines competently; work independently and help others; must be highly motivated and detail-oriented \n  Foster a culture of professionalism, accountability, collaboration, speed, innovation, excellence, and a fun work environment while continuously elevating the quality and caliber of our risk controls \n  Other responsibilities as assigned \n \n \n \n \n \n  Qualifications \n \n \n \n  3+ years experience in risk and/or fraud detection in financial services or technology with an emphasis on KYC/CIP/onboarding processes. \n  Experience working with machine learning teams \n  Superior writing and editing skills, with the ability to produce copy requiring minimal rework; technical or procedural writing experience a plus \n  Experience working with teams across countries and time zones \n  Ability to synthesize information and make clear, concise recommendations on a course of action \n  Flexibility to adapt and able to manage multiple assignments while working independently \n \n  Even Better \n \n  Bachelor's Degree in Finance, Accounting, Mathematics, Economics, Computer Science, Information Management or Statistics \n  CFE, ACAMS, or similar accreditation \n  SQL experience \n \n \n \n \n \n  Additional Information \n \n \n  Block takes a market-based approach to pay, and pay may vary depending on your location. U.S. locations are categorized into one of four zones based on a cost of labor index for that geographic area. The successful candidate\u2019s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. These ranges may be modified in the future.    Zone A: USD $114,200 - USD $139,600  Zone B: USD $106,200 - USD $129,800  Zone C: USD $97,100 - USD $118,700  Zone D: USD $85,700 - USD $104,700 \n \n  To find a location\u2019s zone designation, please refer to this resource. If a location of interest is not listed, please speak with a recruiter for additional information. \n  Full-time employee benefits include the following: \n \n  Healthcare coverage (Medical, Vision and Dental insurance) \n  Health Savings Account and Flexible Spending Account \n  Retirement Plans including company match \n  Employee Stock Purchase Program \n  Wellness programs, including access to mental health, 1:1 financial planners, and a monthly wellness allowance \n  Paid parental and caregiving leave \n  Paid time off (including 12 paid holidays) \n  Paid sick leave (1 hour per 26 hours worked (max 80 hours per calendar year to the extent legally permissible) for non-exempt employees and covered by our Flexible Time Off policy for exempt employees) \n  Learning and Development resources \n  Paid Life insurance, AD&D, and disability benefits \n  Additional Perks such as WFH reimbursements and free access to caregiving, legal, and discounted resources \n \n  These benefits are further detailed in Block's policies. This role is also eligible to participate in Block's equity plan subject to the terms of the applicable plans and policies, and may be eligible for a sign-on bonus. Sales roles may be eligible to participate in a commission plan subject to the terms of the applicable plans and policies. Pay and benefits are subject to change at any time, consistent with the terms of any applicable compensation or benefit plans. \n  US and Canada EEOC Statement \n  We\u2019re working to build a more inclusive economy where our customers have equal access to opportunity, and we strive to live by these same values in building our workplace. Block is a proud equal opportunity employer. We work hard to evaluate all employees and job applicants consistently, without regard to race, color, religion, gender, national origin, age, disability, pregnancy, gender expression or identity, sexual orientation, citizenship, or any other legally protected class. \n  We believe in being fair, and are committed to an inclusive interview experience, including providing reasonable accommodations to disabled applicants throughout the recruitment process. We encourage applicants to share any needed accommodations with their recruiter, who will treat these requests as confidentially as possible.  Want to learn more about what we\u2019re doing to build a workplace that is fair and square? \n  Additionally, we consider qualified applicants with criminal histories for employment on our team, and always assess candidates on an individualized basis. \n \n \n  Block, Inc. (NYSE: SQ) is a global technology company with a focus on financial services. Made up of Square, Cash App, Spiral, TIDAL, and TBD, we build tools to help more people access the economy. Square helps sellers run and grow their businesses with its integrated ecosystem of commerce solutions, business software, and banking services. With Cash App, anyone can easily send, spend, or invest their money in stocks or Bitcoin. Spiral (formerly Square Crypto) builds and funds free, open-source Bitcoin projects. Artists use TIDAL to help them succeed as entrepreneurs and connect more deeply with fans. TBD is building an open developer platform to make it easier to access Bitcoin and other blockchain technologies without having to go through an institution.", "cleaned_desc": " \n \n \n \n  Qualifications \n \n \n \n  3+ years experience in risk and/or fraud detection in financial services or technology with an emphasis on KYC/CIP/onboarding processes. \n  Experience working with machine learning teams \n  Superior writing and editing skills, with the ability to produce copy requiring minimal rework; technical or procedural writing experience a plus \n  Experience working with teams across countries and time zones \n  Ability to synthesize information and make clear, concise recommendations on a course of action \n  Flexibility to adapt and able to manage multiple assignments while working independently \n \n  Even Better ", "techs": ["machine learning teams"]}, "3d85e33ea693d217": {"terms": ["data science"], "salary_min": 100000.0, "salary_max": 200000.0, "title": "Forward Deployment AI Engineer - Remote", "company": "Reality Defender", "desc": "About The Role\n  \n \n   Reality Defender seeks an AI engineer to work on product-oriented cutting-edge deep learning approaches for audio or computer vision generative deepfake media detection.\n  \n \n \n  Responsibilities\n  \n \n Work on deepfake detection and classification problems. \n \n \n   - Independently implement and deploy deep learning solutions on modern deep learning stack - Python, PyTorch, and GPU-enabled cloud compute, like AWS.\n  \n \n Collaborate with scientists and engineers across the organization. \n \n \n \n  About You\n  \n \n MS or equivalent experience in computer science, or a related field. \n In-depth understanding of deep learning research in audio synthesis or computer vision and deep learning using neural networks CNNs, Transformers, etc. \n You have implemented papers from top research venues CVPR, InterSpeech, etc. \n Excellent software engineering skills. \n Team player with a positive attitude and good communication skills. \n \n \n \n  #LI-Remote", "cleaned_desc": " \n   - Independently implement and deploy deep learning solutions on modern deep learning stack - Python, PyTorch, and GPU-enabled cloud compute, like AWS.\n  \n \n Collaborate with scientists and engineers across the organization. \n ", "techs": ["python", "pytorch", "gpu-enabled cloud compute (like aws)"]}, "7315958edb3747e4": {"terms": ["data science"], "salary_min": 146188.16, "salary_max": 185106.78, "title": "VP, AI", "company": "Clario", "desc": "ESSENTIAL DUTIES AND RESPONSIBILITIES:\n  \n \n  Strategic Leadership:\n    \n  Set the vision and strategy for the adoption of AI technologies across the clinical trial endpoint data collection spectrum. \n  Collaborate with C-level executives to align AI capabilities with the company\u2019s strategic objectives. \n \n  Research and Development:\n    \n  Oversee the research and development of AI-powered tools and platforms that enhance data collection, analysis, and decision-making in clinical trials. \n  Lead the development and deployment of advanced AI models to enhance user experience, safety, and outcomes across the entire product funnel. This includes ideation, model development, validation, and implementation. \n  Stay updated with the latest advancements in AI and machine learning to ensure the company remains at the forefront of technology in the industry. \n  Implement AI tools to optimize operational efficiency across the organization, working closely with cross-functional teams to understand their needs and develop AI solutions that drive improvement. Foster a data-driven culture within the organization, promoting the use of AI in decision-making processes. \n \n  Operational Excellence:\n    \n  Ensure the seamless integration of AI-driven technologies into existing systems and workflows. \n  Establish performance metrics and monitor the success of AI initiatives, ensuring ROI. \n \n  Stakeholder Collaboration:\n    \n  Collaborate with clinical, regulatory, and data management teams to understand their requirements and develop AI solutions tailored to their needs. \n  Engage with external stakeholders, partners, and vendors to ensure that the company's AI initiatives are externally recognized and are industry leading. \n  Collaborates closely with the engineering, user experience, architecture, and cross-functional teams to ensure a wide portfolio of products are delivered on time, within budget, and at the highest level of quality. \n \n  Risk Management:\n    \n  Establish governance and protocols for the ethical use of AI, ensuring data privacy and regulatory compliance. \n  Proactively address technical and operational challenges, ensuring minimal disruption to ongoing clinical trials. \n \n  Team Leadership:\n    \n  Hires, leads, mentors, and expands the AI organization ensuring the team is high-performing, innovative, and aligned with business goals. \n  Partners with Talent Acquisition to attract and retain top AI talent. \n  Employs a strong focus on Employee Engagement and Talent Development. \n  Effectively manages all annual people-related processes. \n  Proactively manages employee performance, providing timely and ongoing feedback. \n \n \n \n \n   QUALIFICATIONS AND SKILLS NEEDED:\n  \n \n   (Key wording should include if degree is needed, any travel requirements, special qualifications needed, skills, etc.)\n  \n \n \n  Develops and monitors budgets and allocates resources within budget constraints to maximize budgeted resources. \n \n \n \n   Basic Experience:\n  \n \n \n  15 or more years of work experience with a Bachelor\u2019s Degree or at least 12 years of work experience with an Advanced degree (e.g. Masters/MBA/ JD/MD) or a minimum of 10 years of work experience with a PhD. \n \n \n \n   Preferred Experience:\n  \n \n  18 or more years of experience with an Advanced Degree (e.g. Masters, MBA, JD, MD, PhD) \n  Minimum of 15+ years\u2019 direct experience in AI and ML, with a focus on guiding business strategy through technological innovation. \n  Deep knowledge of the clinical trial process and challenges associated with endpoint data collection. \n  A strong research background in AI and ML, evidenced by publications in top-tier conferences or journals. \n  Professional certifications in AI, ML, Data Science, or related fields a plus. \n  Demonstrable experience in employing LLMs and GAI in a business context. \n  Strong technical acumen with an understanding of programming languages such as Python, R, or Java. \n  Familiarity with AI & ML platforms, tools and libraries, and comfort with adopting new technologies as they emerge. \n  Proficiency in cloud-based AI solutions and big data technologies is highly desired. \n  Proven experience designing and deploying successful AI-driven solutions in complex environments. \n  Exceptional communication skills with a knack for translating complex technical jargon into understandable language for non-technical stakeholders. \n  A firm grasp of data governance and privacy regulations is essential in the clinical trial industry. \n  Ability to prioritize competing opportunities and priorities, balance stakeholder needs with business priorities, and drive detailed trade-offs. \n  Outstanding collaboration skills, ability to establish common ground while managing conflicting points of view and articulate rationale behind decisions. \n  Demonstrated technical proficiency and effectiveness working closely with engineers and IT departments. \n  Strong analytical and problem-solving skills, with the ability to interpret complex data and make strategic recommendations. \n \n \n  The Department Head has the discretion to hire personnel with a combination of experience and education, which may vary from the above listed qualifications. \n \n \n \n   EEO Statement\n    Clario is an equal opportunity employer. Clario evaluates qualified applicants without regard to race, color, religion, gender, national origin, age, sexual orientation, gender identity or expression, protected veteran status, disability/handicap status, or any other legally protected characteristic.", "cleaned_desc": "ESSENTIAL DUTIES AND RESPONSIBILITIES:\n  \n \n  Strategic Leadership:\n    \n  Set the vision and strategy for the adoption of AI technologies across the clinical trial endpoint data collection spectrum. \n  Collaborate with C-level executives to align AI capabilities with the company\u2019s strategic objectives. \n \n  Research and Development:\n    \n  Oversee the research and development of AI-powered tools and platforms that enhance data collection, analysis, and decision-making in clinical trials. \n  Lead the development and deployment of advanced AI models to enhance user experience, safety, and outcomes across the entire product funnel. This includes ideation, model development, validation, and implementation. \n  Stay updated with the latest advancements in AI and machine learning to ensure the company remains at the forefront of technology in the industry. \n  Implement AI tools to optimize operational efficiency across the organization, working closely with cross-functional teams to understand their needs and develop AI solutions that drive improvement. Foster a data-driven culture within the organization, promoting the use of AI in decision-making processes. \n \n  Operational Excellence:\n      \n \n   Basic Experience:\n  \n \n \n  15 or more years of work experience with a Bachelor\u2019s Degree or at least 12 years of work experience with an Advanced degree (e.g. Masters/MBA/ JD/MD) or a minimum of 10 years of work experience with a PhD. \n \n \n \n   Preferred Experience:\n  \n \n  18 or more years of experience with an Advanced Degree (e.g. Masters, MBA, JD, MD, PhD) \n  Minimum of 15+ years\u2019 direct experience in AI and ML, with a focus on guiding business strategy through technological innovation. \n  Deep knowledge of the clinical trial process and challenges associated with endpoint data collection. \n  A strong research background in AI and ML, evidenced by publications in top-tier conferences or journals.    Professional certifications in AI, ML, Data Science, or related fields a plus. \n  Demonstrable experience in employing LLMs and GAI in a business context. \n  Strong technical acumen with an understanding of programming languages such as Python, R, or Java. \n  Familiarity with AI & ML platforms, tools and libraries, and comfort with adopting new technologies as they emerge. \n  Proficiency in cloud-based AI solutions and big data technologies is highly desired. \n  Proven experience designing and deploying successful AI-driven solutions in complex environments. \n  Exceptional communication skills with a knack for translating complex technical jargon into understandable language for non-technical stakeholders. \n  A firm grasp of data governance and privacy regulations is essential in the clinical trial industry. \n  Ability to prioritize competing opportunities and priorities, balance stakeholder needs with business priorities, and drive detailed trade-offs. \n  Outstanding collaboration skills, ability to establish common ground while managing conflicting points of view and articulate rationale behind decisions. \n  Demonstrated technical proficiency and effectiveness working closely with engineers and IT departments. \n  Strong analytical and problem-solving skills, with the ability to interpret complex data and make strategic recommendations. \n \n \n  The Department Head has the discretion to hire personnel with a combination of experience and education, which may vary from the above listed qualifications. \n \n ", "techs": ["r&d", "ai", "ml", "user experience", "safety", "outcomes", "ideation", "model development", "validation", "implementation", "operational efficiency", "data-driven culture", "cloud-based ai solutions", "big data technologies", "llms", "gai", "python", "r", "java", "data governance", "privacy regulations", "collaboration", "engineers", "it", "analytical skills", "problem-solving skills."]}, "aa9a90843f98f477": {"terms": ["data science"], "salary_min": 150105.89, "salary_max": 190067.52, "title": "Sr Director, Service Development", "company": "Signify Health", "desc": "How will this role have an impact?    The Senior Director of Service Development is a leadership role focused on process improvement and initiatives critical to the achievement of both near and long term outcomes and results for Diagnostic and Preventative Services business line and HCS Operations teams overall.    The key responsibilities for this role include: \n \n \n Tight partnership with with Delivery Operations and Product teams on identification of issues/defects, development of roadmaps and project management / support in deployment of new processes / technical features \n \n \n Partnership with Product on development of new service launch plans focused on operational needs/staffing, processes and measurement of performance \n \n \n Maintain process maps, SOPs and documentation related to relevant current state operations and associated product/technology \n \n \n \n  In this leadership role you will play an integral part in shaping the organization's performance focused culture and building trust across diverse teams and stakeholders to ensure delivery to meet member/patient, client and company expectations.    The Senior Director will report to the VP of Service Development but serve as the primary point contact for Product, Delivery Operations and other business partners focused on the Diagnostic and Preventative Services service line representing the SVP of Production and SVP of Network Operations. There is an expectation to continue to grow and scale the Service Development function with a high-performing team that the Senior Director would have management oversight for and full autonomy on critical decisions. \n    What will you do? \n \n Work with leaders across the company to develop and execute process changes required to optimize performance \n Provide leadership for management of the Service Development function partnering closely with key stakeholders to achieve shared goals / outcomes \n Develop and maintain accurate and detailed documentation of all critical processes, associated product/technology and cross-functional organizing approach \n Act as a centralized point for Operations in the coordination and development of plans for the launch of new products / services; pilot project plans and coordination, staffing models and resourcing needs, vendor management etc. \n Maintain \"Operations\" roadmap for all Operations teams involved in supporting DPS services and lead the quarterly and annual planning process \n Ensure exceptional working relationships with key stakeholders at Manager to VP+ level across Operations and Product \n Review and monitor operating metrics trends and results; develop, enhance and partner with Analytics to obtain new or updated visibility into data when needed \n Development of a high-performing team based on analytical and process improvement skill sets \n Accountable for a comprehensive and effective change management and continuous improvement strategy that promotes our vision, strategy, and accountabilities \n Promote a high-performing, engaging culture of two-way communications and create opportunities for staff participation \n Manage time and people effectively \n Ensure execution and compliance with Signify Health's strategic initiatives \n Respond well to coaching and supervision \n Actively demonstrate teamwork at all times \n This role is primarily remote with some occasional travel \n \n \n   We are looking for someone with: \n \n 10-15 years of accomplished healthcare leadership experience is preferred \n Experience managing change and developing and maintaining excellent relations with executives, customers, operations and Product Management staff at all levels \n Experience in a large, complex and healthcare / healthcare technology organization \n Prior performance improvement or project management experience \n Knowledge of CMS guidelines \n Understanding of key metrics and best practices for reporting / metric development \n Proven ability to prioritize with a team and advocate for priorities with other teams \n Experience in clinical decision support, data science or advanced analytics leadership \n Demonstrates competency in technology applications related to business and clinical functions and in process improvement methodologies \n \n \n   Education/Licensing Requirements: \n \n Bachelor's degree in Business, Health Management or related field \n Master's degree in Business, Finance or Healthcare Administration (preferred) \n \n \n   About Us:  Signify Health is helping build the healthcare system we all want to experience by transforming the home into the healthcare hub. We coordinate care holistically across individuals' clinical, social, and behavioral needs so they can enjoy more healthy days at home. By building strong connections to primary care providers and community resources, we're able to close critical care and social gaps, as well as manage risk for individuals who need help the most. This leads to better outcomes and a better experience for everyone involved.    Our high-performance networks are powered by more than 9,000 mobile doctors and nurses covering every county in the U.S., 3,500 healthcare providers and facilities in value-based arrangements, and hundreds of community-based organizations. Signify's intelligent technology and decision-support services enable these resources to radically simplify care coordination for more than 1.5 million individuals each year while helping payers and providers more effectively implement value-based care programs.    To learn more about how we're driving outcomes and making healthcare work better, please visit us at www.signifyhealth.com.     Diversity and Inclusion are core values at Signify Health, and fostering a workplace culture reflective of that is critical to our continued success as an organization.     We are committed to equal employment opportunities for employees and job applicants in compliance with applicable law and to an environment where employees are valued for their differences.", "cleaned_desc": "", "techs": ""}, "d0fc2b0d89d80ce9": {"terms": ["data science"], "salary_min": 70560.0, "salary_max": 78400.0, "title": "Quality Assurance Manager", "company": "StrongHearts Native Helpline", "desc": "Job Description \n BASIC INFORMATION \n FLSA Status  Exempt \n Provisional Period  180 days \n Job Title  Quality Assurance Manager \n Location  Remote \n Funding Source  Grant Funded \n Position Type  Full-time \n Reports to  Chief Operations Officer \n Supervises  Data Coordinator and Grant Compliance Specialist \n Shift  8am-5pm CST \n Salary/Hourly Rate  $70,560.00 - $78,400.00 \n GENERAL POSITION PURPOSE STATEMENT \n Organizational Summary: StrongHearts Native Helpline is a safe, anonymous and confidential helpline for Native Americans and Alaska Natives affected by domestic, dating and sexual violence. By dialing 1-844-7NATIVE (1-844-762-8483), nationwide 24/7, callers can connect at no cost one-on-one with knowledgeable StrongHearts advocates who can provide lifesaving tools and immediate support to enable survivors to find safety and live lives free of abuse. \n JOB SUMMARY \n As the Quality Assurance Manager at StrongHearts Native Helpline, you will play a pivotal role in providing essential direction and oversight to our Quality program. Your primary focus will be on continuous quality improvement, data analysis and grant compliance, strategically engaging all areas of the organization and fostering a culture of accountability and transparency. Your dedication to maintaining and enhancing the overall quality, effectiveness, and efficiency of our helpline services for Native American and Alaska Native communities will be critical. \n ESSENTIAL RESPONSIBILITIES, DUTIES AND ABILITIES \n Overall: \u25cf Drive activities and initiatives relative to Quality Assurance - collaboration with the department managers. \u25cf Serve as subject matter expert for Salesforce database and various criteria of grant programs. \u25cf Oversee work of and supervise Grant Compliance Specialist and Database Coordinator, supporting these positions in meeting stated goals. \u25cf Strong capability to work remotely, with proven experience effectively communicating and collaborating in a virtual environment. \n Quality Management \u25cf Develop and implement quality assurance policies, procedures, and standards to ensure consistent and exceptional service delivery. \u25cf Monitor and evaluate helpline calls, text messages, and online chats to assess the quality and effectiveness of interactions with callers. \u25cf Conduct regular audits of helpline conversations to ensure adherence to established protocols and compliance with relevant regulations. \u25cf Conduct contact satisfaction surveys to ensure service provision is meeting the needs \n of those who contact StrongHearts \u25cf Collaborate with the HR/Training team to identify areas for improvement in advocate training and development. \n Data Analysis and Reporting: \u25cf Oversee the Salesforce database, become Salesforce certified, work with Database \n Coordinator to ensure data integrity and meaningful data analysis \u25cf Maintain service provider database, ensuring annual update is completed \u25cf Collect and analyze data on call volume, caller demographics, trends in issues faced by Native \n American and Alaska Native communities, and organizational marketing tactics. \u25cf Generate regular reports on helpline performance and present findings to the management team. \u25cf Utilize data-driven insights to identify opportunities for service improvement and innovation. \u25cf Design and implementation of various intra-system and inter-system data quality controls to ensure communication programs are protected from data or process errors \u25cf Fully investigate errors and discrepancies and work with appropriate business groups to identify patterns, trends and inconsistencies \n Grant Compliance Oversight: \u25cf Develop and implement a comprehensive grant compliance program to ensure adherence to all grant requirements and regulations. \u25cf Stay up-to-date with grant guidelines, federal and state regulations, and reporting deadlines, and communicate changes to relevant staff members. \u25cf Work closely with peer managers and the finance department to ensure all grant activities are in compliance with funding agency guidelines. \u25cf Stay informed about industry best practices, helpline standards, and relevant laws/regulations to maintain compliance. \u25cf Foster a culture of compliance throughout the organization by promoting awareness and understanding of grant-related rules and regulations. \n \u25cf Ensure the helpline adheres to all relevant confidentiality and reporting requirements. \n Continuous Improvement: \u25cf Partner with HR to participate in internal quality improvement initiatives to enhance helpline operations. \u25cf Collaborate with other departments to address cross-functional quality concerns and implement solutions. \n KNOWLEDGE AND SKILLS \n A Bachelor's Degree in data science; nonprofit management, business administration or a related field is Preferred. Must have at least 3 years of demonstrated experience in quality process and improvement. Must have 2 years leadership or supervisory experience. Must have advanced experience in using techniques and tools to present data in visual format including formulas, data management and complex Excel features. Required experience in Salesforce, audit, process improvement, policy implementation, data visualization, and quality data analysis experience. Proficiency preferred. Preferred work experience working with American Indian and Alaska Native communities. Preferred work experience with community-based domestic violence/victim assistance programs, human services, social services or related direct client services. Knowledge of the history of the battered women\u2019s movement in the United States and the impact on Native Americans. \n Any equivalent combination of education and experience that will allow the applicant to satisfactorily perform the duties of the job may be considered. \n PHYSICAL AND SENSORY REQUIREMENT \n The responsibilities of this position require certain physical and sensory abilities, which must be performed with or without reasonable accommodation. Must be able to hear and speak clearly. Ability to use hands and fingers on a keyboard and use a mouse. Ability to clearly see and view the details of words, tables and images on a computer screen for long periods of time. \n BENEFITS \n StrongHearts offers the work life balance, opportunities for growth and the upward mobility you've been searching for! Benefits include employer paid health, dental, vision, and life insurance benefits that begin two full calendar months after your official start date. Benefits also include generous paid time off so you can spend more time with your family and enjoy a positive work life balance. \n *StrongHearts is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, or veteran status. StrongHearts is a drug-free workplace.* \n Job Type: Full-time \n Pay: $70,560.00 - $78,400.00 per year \n Benefits: \n \n Dental insurance \n Health insurance \n Life insurance \n Paid time off \n Parental leave \n Retirement plan \n Vision insurance \n \n Schedule: \n \n 8 hour shift \n \n Work Location: Remote", "cleaned_desc": " Data Analysis and Reporting: \u25cf Oversee the Salesforce database, become Salesforce certified, work with Database \n Coordinator to ensure data integrity and meaningful data analysis \u25cf Maintain service provider database, ensuring annual update is completed \u25cf Collect and analyze data on call volume, caller demographics, trends in issues faced by Native \n American and Alaska Native communities, and organizational marketing tactics. \u25cf Generate regular reports on helpline performance and present findings to the management team. \u25cf Utilize data-driven insights to identify opportunities for service improvement and innovation. \u25cf Design and implementation of various intra-system and inter-system data quality controls to ensure communication programs are protected from data or process errors \u25cf Fully investigate errors and discrepancies and work with appropriate business groups to identify patterns, trends and inconsistencies \n Grant Compliance Oversight: \u25cf Develop and implement a comprehensive grant compliance program to ensure adherence to all grant requirements and regulations. \u25cf Stay up-to-date with grant guidelines, federal and state regulations, and reporting deadlines, and communicate changes to relevant staff members. \u25cf Work closely with peer managers and the finance department to ensure all grant activities are in compliance with funding agency guidelines. \u25cf Stay informed about industry best practices, helpline standards, and relevant laws/regulations to maintain compliance. \u25cf Foster a culture of compliance throughout the organization by promoting awareness and understanding of grant-related rules and regulations. \n \u25cf Ensure the helpline adheres to all relevant confidentiality and reporting requirements. \n Continuous Improvement: \u25cf Partner with HR to participate in internal quality improvement initiatives to enhance helpline operations. \u25cf Collaborate with other departments to address cross-functional quality concerns and implement solutions. \n KNOWLEDGE AND SKILLS \n A Bachelor's Degree in data science; nonprofit management, business administration or a related field is Preferred. Must have at least 3 years of demonstrated experience in quality process and improvement. Must have 2 years leadership or supervisory experience. Must have advanced experience in using techniques and tools to present data in visual format including formulas, data management and complex Excel features. Required experience in Salesforce, audit, process improvement, policy implementation, data visualization, and quality data analysis experience. Proficiency preferred. Preferred work experience working with American Indian and Alaska Native communities. Preferred work experience with community-based domestic violence/victim assistance programs, human services, social services or related direct client services. Knowledge of the history of the battered women\u2019s movement in the United States and the impact on Native Americans. \n Any equivalent combination of education and experience that will allow the applicant to satisfactorily perform the duties of the job may be considered. \n PHYSICAL AND SENSORY REQUIREMENT ", "techs": ["salesforce", "database coordinator", "data analysis", "data integrity", "service provider database", "call volume analysis", "caller demographics analysis", "organizational marketing tactics", "helpline performance reports", "data-driven insights", "intra-system data quality controls", "inter-system data quality controls", "grant compliance program", "grant guidelines", "federal and state regulations", "grant reporting deadlines", "industry best practices", "helpline standards", "confidentiality requirements", "quality improvement initiatives", "cross-functional quality concerns", "data science", "nonprofit management", "business administration", "quality process improvement", "leadership experience", "data visualization tools", "salesforce", "audit", "process improvement", "policy implementation", "data visualization", "quality data analysis", "american indian communities", "alaska native communities", "community-based domestic violence/victim assistance programs", "human services", "social services", "history of the battered women\u2019s movement"]}, "d2ce210d6e8279b4": {"terms": ["data science"], "salary_min": 100000.0, "salary_max": 120000.0, "title": "Sr. Financial Analyst", "company": "Teladoc Health", "desc": "Teladoc Health is a global, whole person care company made up of a diverse community of people dedicated to transforming the healthcare experience. As an employee, you\u2019re empowered to show up every day as your most authentic self and be a part of something bigger \u2013 thriving both personally and professionally. Together, let\u2019s empower people everywhere to live their healthiest lives.  \n \n Position Summary  \n The Sr. Finance Analyst, Operations Finance is a very highly visible role, and you will be at the forefront of driving the US COGS/COS and OPEX optimization by thoroughly analyzing Operations key metrics and performance drivers and communicating actionable insights to senior management. The ideal candidate is a highly cerebral and strategic leader who possesses an excellent understanding of forecasting and data driven actionable insights. She/he will partner with the Operations functions to forecast US COGS/COS and OPEX on a monthly basis as well as for the AOP and the LRP, help set targets, timely report and measure against targets, and drive optimization/value creation. The Sr. Finance Analyst, Operations Finance will be a trusted advisor who can thrive in a fast-paced dynamic environment.  \n \n Reporting to the Sr. Finance Manager, you will provide critical business intelligence and actionable financial insights that empower decision-making throughout the Company. In this role, you will use your analytical skills, thought leadership, business savvy, modeling, and forecasting chops to track and influence business performance and enhance our predictive and prescriptive capabilities. You will work at the intersection of finance and data analysis through a strategic lens - developing and maintaining financial information while helping steer the company through your analysis. You will regularly be collaborating alongside Operations, Product, HR, Data Science, FP&A, and T&D.  \n \n Role and Responsibilities  \n \n Partner with Operations to develop the monthly forecast, annual plan, and LRP for the US COGS/COS and OPEX and report to senior management with a very clear and thorough presentation on drivers, actionable insights, and risks and opportunities  \n Implement a proactive standardized and effective forecasting framework and review process with cross functional business partners.  \n Conduct \u201cwhat-if\u201d and scenario planning analysis  \n Analyze US visit SLA trends and timely communicate predictive insights and partner with cross functional business partners to make better decisions around provider capacity and optimize throughput  \n Work collaboratively within the Commercial Finance team as well as with cross-functional business partners such as Operations, Product, HR, Data Science, FP&A, and T&D.  \n Translate unstructured business problems into analytical framework. Apply framework to uncover insights and actionable recommendations. Ensure information and insights are being cascaded throughout the cross functional groups  \n Apply evidenced-based thinking and teach past learnings to influence decision making  \n Design advanced analytics strategy, derive, and communicate insights that inform key decisions and help optimize the business  \n Partner with Data Science to build standardized reports and dashboards in Tableau  \n \n \n Qualifications/Requirements  \n \n BS/BA degree in Finance, Accounting, or related field  \n Combination of strong financial planning, forecasting, and reporting experience \u2013 minimum of 5 years of experience.  \n Experience in building data and actionable insights driven scalable predictive COGS/COS and OPEX forecasting models  \n Proven experience with analyzing large amounts of financial and operational data to derive meaningful trends, map connections, and identify drivers of key P&L line items like COGS/COS and OPEX  \n Excellent oral and written communication and presentation skills  \n Must be able to very successfully partner with various stakeholder to produce a very robust and predictive US COGS/COS monthly, annual, and LRP forecast  \n Demonstrated ability to work in a matrixed environment with many cross-functional partners  \n Ability to understand and influence decisions of senior management  \n Is very organized, detail oriented, and efficient with time management.  \n Must be proficient with all Microsoft Office software with advanced PowerPoint and Excel skills  \n Proficiency with Tableau and Oracle is a plus  \n Flexibility for some travel  \n \n \n The base salary range for this position is $100,000 - $120,000  .  In addition to a base salary, this position is eligible for performance bonus, RSU\u2019s, and benefits (subject to eligibility requirements) listed here: Teladoc Health Benefits 2023 . Total compensation is based on several factors including, but not limited to, type of position, location, education level, work experience, and certifications. This information is applicable for all full-time positions.  \n \n \n \n \n \n \n \n \n \n \n \n \n Why Join Teladoc Health?   \n   A New Category in Healthcare:  Teladoc Health is transforming the healthcare experience and empowering people everywhere to live healthier lives.      Our Work Truly Matters  : Recognized as the world leader in whole-person virtual care, Teladoc Health uses proprietary health signals and personalized interactions to drive better health outcomes across the full continuum of care, at every stage in a person\u2019s health journey.      Make an Impact:  In more than 175 countries and ranked Best in KLAS for Virtual Care Platforms in 2020, Teladoc Health leverages more than a decade of expertise and data-driven insights to meet the growing virtual care needs of consumers and healthcare professionals.      Focus on PEOPLE:  Teladoc Health has been recognized as a top employer by numerous media and professional organizations. Talented, passionate individuals make the difference, in this fast-moving, collaborative, and inspiring environment.      Diversity and Inclusion:  At Teladoc Health we believe that personal and professional diversity is the key to innovation. We hire based solely on your strengths and qualifications, and the way in which those strengths can directly contribute to your success in your new position.      Growth and Innovation:  We\u2019ve already made healthcare yet remain on the threshold of very big things. Come grow with us and support our mission to make a tangible difference in the lives of our Members.   \n \n As an Equal Opportunity Employer, we never have and never will discriminate against any job candidate or employee due to age, race, religion, color, ethnicity, national origin, gender, gender identity/expression, sexual orientation, membership in an employee organization, medical condition, family history, genetic information, veteran status, marital status, parental status or pregnancy.  \n \n Teladoc Health respects your privacy and is committed to maintaining the confidentiality and security of your personal information. In furtherance of your employment relationship with Teladoc Health, we collect personal information responsibly and in accordance with applicable data privacy laws, including but not limited to, the California Consumer Privacy Act (CCPA). Personal information is defined as: Any information or set of information relating to you, including (a) all information that identifies you or could reasonably be used to identify you, and (b) all information that any applicable law treats as personal information. Teladoc Health\u2019s Notice of Privacy Practices for U.S. Employees\u2019 Personal information is available at this link.", "cleaned_desc": " Qualifications/Requirements  \n \n BS/BA degree in Finance, Accounting, or related field  \n Combination of strong financial planning, forecasting, and reporting experience \u2013 minimum of 5 years of experience.  \n Experience in building data and actionable insights driven scalable predictive COGS/COS and OPEX forecasting models  \n Proven experience with analyzing large amounts of financial and operational data to derive meaningful trends, map connections, and identify drivers of key P&L line items like COGS/COS and OPEX  \n Excellent oral and written communication and presentation skills  \n Must be able to very successfully partner with various stakeholder to produce a very robust and predictive US COGS/COS monthly, annual, and LRP forecast  \n Demonstrated ability to work in a matrixed environment with many cross-functional partners  \n Ability to understand and influence decisions of senior management  ", "techs": ["financial planning", "forecasting", "reporting", "building data", "actionable insights", "predictive forecasting models", "analyzing large amounts of financial and operational data", "oral and written communication", "presentation skills", "partnering with stakeholders", "working in a matrixed environment", "understanding and influencing decisions of senior management"]}, "10537b8571662def": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Inside Sales Representative", "company": "Ashfield Nordic AB", "desc": "Inizio Engage has a long-standing partnership with worldwide leading pharmaceutical company to offer support for launch and established brands in the Respiratory arena.\n  \n \n \n   We are seeking candidates who bring successful documented sales success and can make an impact quickly in your remote territory. The Inside Sales Representative will achieve sales and activity targets on assigned territories across primary and specialist care customers and meet all relevant standards as set by Inizio and Regional Sales Manager or Manager, Call Center Operations.\n  \n \n \n   This is your opportunity to join Inizio Engage and represent a top biotechnology company!\n  \n \n \n   What\u2019s in it for you?\n  \n \n  Competitive compensation \n  Excellent Benefits \u2013 accrued time off, medical, dental, vision, 401k, disability & life insurance, paid maternity and bonding time benefits, employee discounts/promotions \n  Generous performance-driven Incentive Compensation package \n  Competitive environment with company wide recognition, contests, and coveted awards \n  Exceptional company culture \n  Recognized as a Top Workplace USA 2021 \n  Awarded a \u201cGreat Place to Work\u201d award in 2022 and 2023 \n  Fortune Best Workplaces in Biopharma 2022 \n \n \n \n   What will you be doing?\n  \n \n  Develop a sound understanding of the relevant product and disease area to facilitate detailed discussions with medical professionals. \n  Facilitate account management skills (account planning, field resource coordination; close, support customer education and promotion needs, reporting). \n  Demonstrate effectiveness working independently and in team environments. \n  Establish phone presence; commanding & disarming, ability to create rapport, network, build, and maintain productive business relationships. \n  Demonstrate clinical and technical skills. \n  Adhere to new therapeutic areas and channels of business and adapt to organizational change. \n  Leverage and use customer networks, resources and tools via phone/web to expand connectivity, reach and interest across stakeholders. \n  Identify, prioritize and drive opportunities to create access, policy, programs and processes that drive product demand. \n  Engage targeted healthcare professionals in in-depth informational/promotional communications in accordance with policies and procedures set by the client. \n  Verify and complete required data entry including details of the target\u2019s responses, notes and any follow through actions in accordance with policies and procedures set by the client. \n  Profile and manage targeted list of healthcare professionals and provide value-added benefits to grow product volume. \n  Maintain call productivity and metrics, which are required by Inizio and the client. \n  Manage daily sales call activity to optimize time and maximize the achievement of sales and market share objectives. \n  Listen and respond appropriately to customer needs and questions, thereby ensuring acceptance of, or agreement with a \u201ccall plan\u201d objective. \n  Maintain the required product expertise including competitive product knowledge. \n  Demonstrate thorough knowledge of the Client\u2019s products and ensure clear, concise and accurate communication of product information with target audiences using proper medical terminology. \n  Successfully complete the Client\u2019s product training (self-study, testing, field work and classroom training at the Client\u2019s site or electronically) and meet training expectations set by the Client in order to proceed to servicing the Client\u2019s customers within the parameters of the program. \n  Effectively and timely communicate with the Regional Sales Manager, the Client Account Director and Field (as appropriate) on project\u2019s progress. \n  Create and maintain a positive impression with the Client and the Client\u2019s customers. \n  Execute sales strategies in compliance with Federal Healthcare Program requirements, FDA\u2019s promotional regulations, and Client policy. \n  Must safeguard patient privacy and confidentiality by following the guidelines set forth in the Privacy and Security Rules of the Health Insurance Portability and Accountability Act (HIPAA). \n \n \n \n   What do you need for this position?\n  \n \n  Bachelor\u2019s degree or equivalent work experience \n  1 year Business to Business sales experience required \n  Pharmaceutical Sales preferred \n  Strong technical abilities are required \n  Respiratory Sales experience preferred \n  Strong work ethic, interpersonal and relationship building skills \n  Positive attitude \n  Excellent oral and written communication skills \n  Multi-lingual is preferred \n  Documented track record of sales success \n  Must have stable, reliable, high speed home internet. \n  Must have a designated separate home office space that is quiet and away from distractions \n \n \n \n   About Inizio Engage\n    Inizio Engage is a strategic, commercial, and creative engagement partner that specializes in healthcare. Our passionate, global workforce augments local expertise and diverse mix of skills with data, science, and technology to deliver bespoke engagement solutions that help clients reimagine how they engage with their patients, payers, people and providers to improve treatment outcomes. Our mission is to partner with our clients, improving lives by helping healthcare professionals and patients get the medicines, knowledge and support they need.\n  \n \n \n   To learn more about Inizio Engage, visit us at: \n   \n   https://inizio.health/\n   \n \n \n \n   We believe in our values: We empower everyone/We rise to the challenge/We work as one/We ask what if/We do the right thing, and we will ask you how your personal values align to them.\n  \n \n \n   Inizio Engage is proud to be an equal opportunity employer. Individuals seeking employment at Inizio are considered without regards to age, ancestry, color, gender, gender identity or expression, genetic information, marital status, medical condition (including pregnancy, childbirth, or related medical conditions), mental or physical disability, national origin, protected family care or medical leave status, race, religion (including beliefs and practices or the absence thereof), sexual orientation, military or veteran status, or any other characteristic protected by federal, state, or local laws. Further, pursuant to applicable local ordinances, Inizio will consider for employment qualified applicants with arrest and conviction records.\n  \n \n \n   Inizio Engage is an equal opportunity employer M/F/V/D. We appreciate your interest in our company, however, only qualified candidates will be considered.", "cleaned_desc": "", "techs": ""}, "7af2d645bf1f8087": {"terms": ["data science"], "salary_min": 101559.04, "salary_max": 128596.37, "title": "Senior Data Scientist (Exempt)", "company": "Mercy", "desc": "We're a Little Different \n \n  Our mission is clear. We bring to life a healing ministry through our compassionate care and exceptional service. \n  \n  At Mercy, we believe in careers that match the unique gifts of unique individuals - careers that not only make the most of your skills and talents, but also your heart. Join us and discover why Modern Healthcare Magazine named us in its \"Top 100 Places to Work.\"\n  \n \n Overview:Data Scientist - Research \n \n \n Position can be Remote (work from home) \n \n \n \n Please note that as of the posting date of this job announcement, Mercy is unable to offer immigration sponsorship or visa assistance for this position. We encourage all eligible candidates, including U.S. citizens, permanent residents, and those with existing work authorization, to apply. \n \n  Mercy is seeking a Senior Data Scientist - Research to work within a team of other advanced professional analysts, data scientists, and clinical leaders in the generation, extraction, and compilation of data to perform creative, high-quality, state-of-the-art analyses and evaluations that produce insights, support decision-making, and drive impact within a leading and transforming healthcare organization. This position will support Mercy's Research efforts, providing essential context for evaluating the effectiveness of interventions and innovations. Through meticulous statistical evaluations, you will identify patterns and trends, offering critical benchmarks for measuring the impact of our initiatives.\n  \n \n Job Description Responsibilities:  \n \n \n Data Collection and Curation: Collaborate with research teams to acquire and curate diverse datasets, including clinical data, genomics, imaging, and other relevant sources, ensuring data quality and integrity. \n \n \n  Data Analysis and Interpretation: Utilize advanced statistical techniques and data mining methods to analyze complex medical datasets. Extract meaningful patterns and insights, identify associations, and draw actionable conclusions that contribute to medical research outcomes. \n  Predictive Modeling: Develop predictive models to forecast patient outcomes, disease progression, and treatment responses. Employ machine learning algorithms to support evidence-based decision-making in clinical and research settings. \n  Research Design and Methodology: Contribute to the design and development of research studies, incorporating appropriate statistical methodologies to ensure rigor and validity. \n  Collaborative Research: Work closely with interdisciplinary teams of researchers, clinicians, and scientists to support their research objectives and provide data-driven insights for publications and presentations. \n  Data Visualization and Communication: Effectively communicate complex data analyses and research findings to both technical and non-technical stakeholders using data visualizations, presentations, and reports. \n \n  Ethical Considerations: Ensure compliance with data privacy regulations and maintain ethical standards in handling sensitive medical information\n  \n \n Qualifications: \n \n \n  Experience:  At least 4 years of experience in a similar role in academia or industry or PhD + 2 years in a similar role in academia or industry \n  Required Education:  Graduate degree in Public Health, Health Care Research, Epidemiology, Statistics, Data Science, Health Policy, Economic, Finance, Simulation/Simulation-Based Optimization, or related field. \n  Other:  \n Have a strong knowledge of electronic medical record data, clinical data, claims data, or financial data. \n \n  Technical Expertise: Proficiency in data analysis and programming languages such as Python, R, SQL, or other relevant tools commonly used in medical research. \n  Ability to quickly learn new analytic tools and packages \n  Strong background in statistical methods, including regression analysis, hypothesis testing, survival analysis, and machine learning algorithms. \n  Prior experience in medical or clinical research, working with healthcare-related datasets, and contributing to scientific publications is preferred. \n  Excellent problem-solving skills \n  Strong organizational skills, an orientation toward detail, and collaboration oriented.Present complex data (qualitative and quantitative) in a clear, concise, and compelling manner to both technical and non-technical audiences to inspire action. \n \n \n \n  We Offer Great Benefits: \n \n  Day-one comprehensive health, vision and dental coverage, PTO, tuition reimbursement and employer-matched retirement funds are just a few of the great benefits offered to eligible co-workers, including those working 32 hours or more per pay period!\n  \n \n We're bringing to life a healing ministry through compassionate care. \n \n  At Mercy, our supportive community will be behind you every step of your day, especially the tough ones. You will have opportunities to pioneer new models of care and transform the health care experience through advanced technology and innovative procedures. We're expanding to help our communities grow. Join us and be a part of it all.\n  \n \n What Makes You a Good Match for Mercy?  \n \n  Compassion and professionalism go hand-in-hand with us. Having a positive outlook and a strong sense of advocacy is in perfect step with our mission and vision. We're also collaborative and unafraid to do a little extra to deliver excellent care - that's just part of our commitment. If that sounds like a good fit for you, we encourage you to apply.", "cleaned_desc": " \n  Data Analysis and Interpretation: Utilize advanced statistical techniques and data mining methods to analyze complex medical datasets. Extract meaningful patterns and insights, identify associations, and draw actionable conclusions that contribute to medical research outcomes. \n  Predictive Modeling: Develop predictive models to forecast patient outcomes, disease progression, and treatment responses. Employ machine learning algorithms to support evidence-based decision-making in clinical and research settings. \n  Research Design and Methodology: Contribute to the design and development of research studies, incorporating appropriate statistical methodologies to ensure rigor and validity. \n  Collaborative Research: Work closely with interdisciplinary teams of researchers, clinicians, and scientists to support their research objectives and provide data-driven insights for publications and presentations. \n  Data Visualization and Communication: Effectively communicate complex data analyses and research findings to both technical and non-technical stakeholders using data visualizations, presentations, and reports. \n \n  Ethical Considerations: Ensure compliance with data privacy regulations and maintain ethical standards in handling sensitive medical information\n  \n \n Qualifications: \n   \n  Experience:  At least 4 years of experience in a similar role in academia or industry or PhD + 2 years in a similar role in academia or industry \n  Required Education:  Graduate degree in Public Health, Health Care Research, Epidemiology, Statistics, Data Science, Health Policy, Economic, Finance, Simulation/Simulation-Based Optimization, or related field. \n  Other:  \n Have a strong knowledge of electronic medical record data, clinical data, claims data, or financial data. \n \n  Technical Expertise: Proficiency in data analysis and programming languages such as Python, R, SQL, or other relevant tools commonly used in medical research. \n  Ability to quickly learn new analytic tools and packages \n  Strong background in statistical methods, including regression analysis, hypothesis testing, survival analysis, and machine learning algorithms. \n  Prior experience in medical or clinical research, working with healthcare-related datasets, and contributing to scientific publications is preferred. \n  Excellent problem-solving skills \n  Strong organizational skills, an orientation toward detail, and collaboration oriented.Present complex data (qualitative and quantitative) in a clear, concise, and compelling manner to both technical and non-technical audiences to inspire action. ", "techs": ["advanced statistical techniques", "data mining methods", "machine learning algorithms", "statistical methodologies", "data visualizations", "data privacy regulations", "electronic medical record data", "clinical data", "claims data", "financial data", "python", "r", "sql", "regression analysis", "hypothesis testing", "survival analysis", "scientific publications"]}, "21902bf924bee7ba": {"terms": ["data science"], "salary_min": 155000.0, "salary_max": 200640.0, "title": "Data Scientist V Data Science (100% remote from CA, GA, HI, CO, VA, MD, DC, OR, Washington states)", "company": "Kaiser Permanente", "desc": "Job Summary: \n \n  In addition to the responsibilities listed below, this position is also responsible for solving complex client analytics problems; communicating results and methodologies; developing experimental design approaches; defining validity of information, how long information is meaningful, and relation to other information; working with data steward to ensure information is in compliance with regulatory and security policies; and qualifying where information can be stored or what information may be used in support of the use case. \n  \n  This position is also responsible for utilizing patterns and variations in the volume, speed and other characteristics of data supporting an initiative, data type, and speed or sudden variations in data collection; developing usage and access control policies and systems in collaboration with the data steward; partnering with data stewards in continuous improvement processes impacting data; ensuring the organization understands principles and math behind the process; and leading on-going tracking and monitoring of performance of decision systems and statistical models.\n  \n \n  Essential Responsibilities: \n \n \n \n \n Practices self-leadership and promotes learning in others by building relationships with cross-functional stakeholders; communicating information and providing advice to drive projects forward; influencing team members within assigned unit; listening and responding to, seeking, and addressing performance feedback; adapting to competing demands and new responsibilities; providing feedback to others, including upward feedback to leadership and mentoring junior team members; creating and executing plans to capitalize on strengths and develop weaknesses; and adapting to and learning from change, difficulties, and feedback. \n  Conducts or oversees business-specific projects by applying deep expertise in subject area; promoting adherence to all procedures and policies; developing work plans to meet business priorities and deadlines; determining and carrying out processes and methodologies; coordinating and delegating resources to accomplish organizational goals; partnering internally and externally to make effective business decisions; solving complex problems; escalating issues or risks as appropriate; monitoring progress and results; recognizing and capitalizing on improvement opportunities; and evaluating recommendations made by others. \n  Interprets complex data analyses by applying findings to contextual settings; and developing insights, reports, and presentations telling a compelling story to stakeholders to enable and influence decision making; participating in peer reviews; and providing context related to data interpretations and/or limitations as appropriate. \n  Leads the development of advanced analytical and/or statistical models enabling informed business decisions by determining data and analytical requirements; translating models and gaining stakeholder buy-in for implementation; creating complex models leading to actionable insights; and testing, refining, and validating models. \n  Designs, implements, and automates business and reporting solutions by partnering with stakeholders to advise in their design, planning, and implementation while ensuring consistency and coherency; evaluating and summarizing data and results; creating summary statistics; designing data reports, visualizations, and/or interactive Business Intelligence (BI) reports; reporting to stakeholders on key findings; identifying needs for the development and implementation of additional reporting solutions; and preparing documentation as appropriate. \n  Drives the execution of creative data analytic approaches leading to actionable outcomes across functional areas, business and/or clinical lines by defining and calculating complex metrics to be analyzed; defining, calculating, and validating algorithms; and conducting complex analyses, including descriptive, correlational, inferential, and/or predictive statistics. \n  Prepares data for analytic efforts by integrating and consolidating data; ensuring data quality and accuracy; profiling data inaccuracies and recommending process improvements or system changes to enhance overall quality of the data; collaborating with stakeholders and source system owners to resolve data quality issues as appropriate; and cleaning and creating final data set(s) for analysis. \n  Gathers data and information on targeted variables in an established systematic fashion by validating data sources; querying, merging, and extracting data across internal and external sources; completing routine data refresh and update; developing and/or delivering complex tools for electronic data collection; and providing user training, support, and documentation. \n  Drives strategic data-informed decisions by consulting with clients and leadership to identify and clarify key business needs across functional areas, business and/or clinical lines; developing outcomes and process measures; translating business requirements; determining data/information needs and data collection methods; developing complex analysis plans; evaluating the impact of business decisions on clients, customers, and/or members; partnering with clients and staff to identify opportunities and methods to improve efficiencies with analysis; supporting and training end-users; and documenting processes and deliverables. \n \n \n  Minimum Qualifications: \n \n \n \n Minimum five (5) years machine learning experience. \n Minimum five (5) years statistical analysis and modeling experience. \n Minimum three (3) years experience working with data visualization tools. \n Minimum five (5) years programming experience. \n Minimum three (3) years experience in a leadership role with or without direct reports. \n Bachelors degree in Mathematics, Statistics, Engineering, Social/Physical/Life Science, Business, or related field and Minimum eight (8) years experience in data analytics or a directly related field. Additional equivalent work experience in a directly related field may be substituted for the degree requirement. \n \n \n \n  Additional Requirements: \n \n \n \n Knowledge, Skills, and Abilities (KSAs): Negotiation; Business Planning; Written Communication; Data Extraction; Data Mining; Data Visualization Tools; Statistical Programming Language; Relational Database Management; Vendor Management; Project Management \n \n  PrimaryLocation : California,Pasadena,Walnut Center - Regional Offices\n   HoursPerWeek : 40\n   Shift : Day\n   Workdays : Mon, Tue, Wed, Thu, Fri\n   WorkingHoursStart : 08:00 AM\n   WorkingHoursEnd : 05:00 PM\n   Job Schedule : Full-time\n   Job Type : Standard\n   Employee Status : Regular\n   Employee Group/Union Affiliation : NUE-PO-01|NUE|Non Union Employee\n   Job Level : Individual Contributor\n   Job Category : Data Analytics\n   Department : One Kaiser Plaza - NCA Ongoing Operating Exp - 0315\n   Travel : No\n   Kaiser Permanente is an equal opportunity employer committed to a diverse and inclusive workforce. Applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy), age, sexual orientation, national origin, marital status, parental status, ancestry, disability, gender identity, veteran status, genetic information, other distinguishing characteristics of diversity and inclusion, or any other protected status.", "cleaned_desc": "Job Summary: \n \n  In addition to the responsibilities listed below, this position is also responsible for solving complex client analytics problems; communicating results and methodologies; developing experimental design approaches; defining validity of information, how long information is meaningful, and relation to other information; working with data steward to ensure information is in compliance with regulatory and security policies; and qualifying where information can be stored or what information may be used in support of the use case. \n  \n  This position is also responsible for utilizing patterns and variations in the volume, speed and other characteristics of data supporting an initiative, data type, and speed or sudden variations in data collection; developing usage and access control policies and systems in collaboration with the data steward; partnering with data stewards in continuous improvement processes impacting data; ensuring the organization understands principles and math behind the process; and leading on-going tracking and monitoring of performance of decision systems and statistical models.\n  \n \n  Essential Responsibilities: \n \n \n   \n Practices self-leadership and promotes learning in others by building relationships with cross-functional stakeholders; communicating information and providing advice to drive projects forward; influencing team members within assigned unit; listening and responding to, seeking, and addressing performance feedback; adapting to competing demands and new responsibilities; providing feedback to others, including upward feedback to leadership and mentoring junior team members; creating and executing plans to capitalize on strengths and develop weaknesses; and adapting to and learning from change, difficulties, and feedback. \n  Conducts or oversees business-specific projects by applying deep expertise in subject area; promoting adherence to all procedures and policies; developing work plans to meet business priorities and deadlines; determining and carrying out processes and methodologies; coordinating and delegating resources to accomplish organizational goals; partnering internally and externally to make effective business decisions; solving complex problems; escalating issues or risks as appropriate; monitoring progress and results; recognizing and capitalizing on improvement opportunities; and evaluating recommendations made by others. \n  Interprets complex data analyses by applying findings to contextual settings; and developing insights, reports, and presentations telling a compelling story to stakeholders to enable and influence decision making; participating in peer reviews; and providing context related to data interpretations and/or limitations as appropriate. \n  Leads the development of advanced analytical and/or statistical models enabling informed business decisions by determining data and analytical requirements; translating models and gaining stakeholder buy-in for implementation; creating complex models leading to actionable insights; and testing, refining, and validating models. \n  Designs, implements, and automates business and reporting solutions by partnering with stakeholders to advise in their design, planning, and implementation while ensuring consistency and coherency; evaluating and summarizing data and results; creating summary statistics; designing data reports, visualizations, and/or interactive Business Intelligence (BI) reports; reporting to stakeholders on key findings; identifying needs for the development and implementation of additional reporting solutions; and preparing documentation as appropriate. \n  Drives the execution of creative data analytic approaches leading to actionable outcomes across functional areas, business and/or clinical lines by defining and calculating complex metrics to be analyzed; defining, calculating, and validating algorithms; and conducting complex analyses, including descriptive, correlational, inferential, and/or predictive statistics. \n  Prepares data for analytic efforts by integrating and consolidating data; ensuring data quality and accuracy; profiling data inaccuracies and recommending process improvements or system changes to enhance overall quality of the data; collaborating with stakeholders and source system owners to resolve data quality issues as appropriate; and cleaning and creating final data set(s) for analysis. \n  Gathers data and information on targeted variables in an established systematic fashion by validating data sources; querying, merging, and extracting data across internal and external sources; completing routine data refresh and update; developing and/or delivering complex tools for electronic data collection; and providing user training, support, and documentation. \n  Drives strategic data-informed decisions by consulting with clients and leadership to identify and clarify key business needs across functional areas, business and/or clinical lines; developing outcomes and process measures; translating business requirements; determining data/information needs and data collection methods; developing complex analysis plans; evaluating the impact of business decisions on clients, customers, and/or members; partnering with clients and staff to identify opportunities and methods to improve efficiencies with analysis; supporting and training end-users; and documenting processes and deliverables. \n ", "techs": ["analytical models", "reporting solutions", "data reports", "visualizations", "interactive business intelligence (bi) reports", "data analytic approaches", "metrics", "algorithms", "complex analyses", "data integration", "data quality", "data profiling", "data refresh", "data extraction", "electronic data collection", "user training", "outcomes and process measures", "analysis plans"]}, "2faf0871a03fa628": {"terms": ["data science"], "salary_min": 101255.3, "salary_max": 128211.766, "title": "Product Engineer - Search Quality", "company": "Objective, Inc.", "desc": "About Objective, Inc. \n  Objective is a seed stage startup building a search platform that enables every developer to ship AI-native search through a simple SaaS API. Our mission is to make content in every application accessible the way people already think and talk about it. \n  We are backed by Matrix Partners, Two Sigma Ventures, Firsthand Ventures, StartX and former execs in top tech companies like Apple, AirBnB, Oracle, LinkedIn, and more, as well as researchers from MIT and Google X. Read about our funding round in TechCrunch. Our founders are ex-Apple engineers with deep experience shipping ML and search systems to hundreds of millions of users across the globe and we have an incredibly talented founding team of ex-Apple, Google and Amazon engineers. We are moving quickly and are passionate about providing a magical experience for our growing customer base. \n  The Role \n  We are hiring a Product Engineer to own Search Quality. You will be responsible for ensuring that we are accurately measuring the quality of our systems for all our customers, demos and application areas. You will devise evaluation strategies, build evaluation sets, run benchmarks, ensure quality monitoring is in place, and set the agenda / prioritization for where to focus our quality iterations. You will work with customers to enable them to align our system with their business objectives and measure the success achieving them. You will be empowered to model & prototype solutions and will either get them implemented in production or work with one of our other ML engineers and Applied Scientists to make sure it gets implemented at the highest standard of quality. You have exceptional attention to detail, love finding the root cause problems for things. You understand the arguments for Data Centric ML and are excited by the latest developments in LLMs, pre-training, fine-tuning, instruction-tuning and in-context learning. This is a key pillar in our product strategy, and you will be the primary leader in this area. You will work with the founders to drive the product roadmap, design the Org that we need to build to complement what we don't have, and steer the product direction to double down on what we're best at. \n  Who you are \n \n You love to learn and look for ways to learn at an accelerated pace \n You are compassionate and help others around you \n You can quickly hit the ground running, map out challenges and opportunities and develop a plan to improve things in the short and long term \n You have strong ownership of any task that you take on, driving it to success whether or not you've done it before \n You can cut through ambiguity and deliver amazing results even when there isn't a lot of guidance \n You are always looking for better ways of doing things, trying out new tools and processes \n You form meaningful relationships wherever you go: people respect and like you because you value them \n You seek continuous feedback from those around you and are willing to share feedback across all levels of the company \n \n Requirements & Skills \n \n Strong background in statistics and analytical thinking \n Experience with machine learning, specifically LLMs and prompt engineering \n Experience working with and managing graders, evaluating labeling quality, managing productivity \n Tech stack: Node/Typescript/NextJS, Python/PyTorch, AWS \n Experience in search and recommendations is welcome but not required \n Preferred Masters in Computer Science, Data Science, Machine Learning, or related scientific fields \n \n Benefits \n \n Competitive salary and equity. \n Platinum-level health, dental, and vision insurance for you and your family. We cover 99% of employee premiums and 95% of dependent premiums. \n Flexible Work - remote or in-person. We have a flexible work environment - work remotely from any U.S. timezone, or join us in-person at our San Francisco office. \n Unlimited PTO - take time when you need it to rest, relax, and recharge with unlimited PTO (minimum 4 weeks encouraged). \n Team events. Distributed work is awesome, but so is getting together in-person. Hang out with your colleagues at planned team events around the country. \n Brand new MacBook Pro (or PC if you prefer) \n \n Don't meet every single requirement? Studies have shown that women and people of color are less likely to apply to jobs unless they meet every single qualification. At Objective we are dedicated to building a diverse, inclusive and authentic workplace, so if you're excited about this role but your past experience doesn't align perfectly with every qualification in the job description, we encourage you to apply anyways. You may be just the right candidate for this or other roles. \n  Objective, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.", "cleaned_desc": "", "techs": ""}, "728e80effe92e8cf": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Inside Sales Representative", "company": "Inizio Engage", "desc": "Inizio Engage has a long-standing partnership with worldwide leading pharmaceutical company to offer support for launch and established brands in the Respiratory arena.\n  \n \n \n   We are seeking candidates who bring successful documented sales success and can make an impact quickly in your remote territory. The Inside Sales Representative will achieve sales and activity targets on assigned territories across primary and specialist care customers and meet all relevant standards as set by Inizio and Regional Sales Manager or Manager, Call Center Operations.\n  \n \n \n   This is your opportunity to join Inizio Engage and represent a top biotechnology company!\n  \n \n \n   What\u2019s in it for you?\n  \n \n  Competitive compensation \n  Excellent Benefits \u2013 accrued time off, medical, dental, vision, 401k, disability & life insurance, paid maternity and bonding time benefits, employee discounts/promotions \n  Generous performance-driven Incentive Compensation package \n  Competitive environment with company wide recognition, contests, and coveted awards \n  Exceptional company culture \n  Recognized as a Top Workplace USA 2021 \n  Awarded a \u201cGreat Place to Work\u201d award in 2022 and 2023 \n  Fortune Best Workplaces in Biopharma 2022 \n \n \n \n   What will you be doing?\n  \n \n  Develop a sound understanding of the relevant product and disease area to facilitate detailed discussions with medical professionals. \n  Facilitate account management skills (account planning, field resource coordination; close, support customer education and promotion needs, reporting). \n  Demonstrate effectiveness working independently and in team environments. \n  Establish phone presence; commanding & disarming, ability to create rapport, network, build, and maintain productive business relationships. \n  Demonstrate clinical and technical skills. \n  Adhere to new therapeutic areas and channels of business and adapt to organizational change. \n  Leverage and use customer networks, resources and tools via phone/web to expand connectivity, reach and interest across stakeholders. \n  Identify, prioritize and drive opportunities to create access, policy, programs and processes that drive product demand. \n  Engage targeted healthcare professionals in in-depth informational/promotional communications in accordance with policies and procedures set by the client. \n  Verify and complete required data entry including details of the target\u2019s responses, notes and any follow through actions in accordance with policies and procedures set by the client. \n  Profile and manage targeted list of healthcare professionals and provide value-added benefits to grow product volume. \n  Maintain call productivity and metrics, which are required by Inizio and the client. \n  Manage daily sales call activity to optimize time and maximize the achievement of sales and market share objectives. \n  Listen and respond appropriately to customer needs and questions, thereby ensuring acceptance of, or agreement with a \u201ccall plan\u201d objective. \n  Maintain the required product expertise including competitive product knowledge. \n  Demonstrate thorough knowledge of the Client\u2019s products and ensure clear, concise and accurate communication of product information with target audiences using proper medical terminology. \n  Successfully complete the Client\u2019s product training (self-study, testing, field work and classroom training at the Client\u2019s site or electronically) and meet training expectations set by the Client in order to proceed to servicing the Client\u2019s customers within the parameters of the program. \n  Effectively and timely communicate with the Regional Sales Manager, the Client Account Director and Field (as appropriate) on project\u2019s progress. \n  Create and maintain a positive impression with the Client and the Client\u2019s customers. \n  Execute sales strategies in compliance with Federal Healthcare Program requirements, FDA\u2019s promotional regulations, and Client policy. \n  Must safeguard patient privacy and confidentiality by following the guidelines set forth in the Privacy and Security Rules of the Health Insurance Portability and Accountability Act (HIPAA). \n \n \n \n   What do you need for this position?\n  \n \n  Bachelor\u2019s degree or equivalent work experience \n  1 year Business to Business sales experience required \n  Pharmaceutical Sales preferred \n  Strong technical abilities are required \n  Respiratory Sales experience preferred \n  Strong work ethic, interpersonal and relationship building skills \n  Positive attitude \n  Excellent oral and written communication skills \n  Multi-lingual is preferred \n  Documented track record of sales success \n  Must have stable, reliable, high speed home internet. \n  Must have a designated separate home office space that is quiet and away from distractions \n \n \n \n   About Inizio Engage\n    Inizio Engage is a strategic, commercial, and creative engagement partner that specializes in healthcare. Our passionate, global workforce augments local expertise and diverse mix of skills with data, science, and technology to deliver bespoke engagement solutions that help clients reimagine how they engage with their patients, payers, people and providers to improve treatment outcomes. Our mission is to partner with our clients, improving lives by helping healthcare professionals and patients get the medicines, knowledge and support they need.\n  \n \n \n   To learn more about Inizio Engage, visit us at: \n   \n   https://inizio.health/\n   \n \n \n \n   We believe in our values: We empower everyone/We rise to the challenge/We work as one/We ask what if/We do the right thing, and we will ask you how your personal values align to them.\n  \n \n \n   Inizio Engage is proud to be an equal opportunity employer. Individuals seeking employment at Inizio are considered without regards to age, ancestry, color, gender, gender identity or expression, genetic information, marital status, medical condition (including pregnancy, childbirth, or related medical conditions), mental or physical disability, national origin, protected family care or medical leave status, race, religion (including beliefs and practices or the absence thereof), sexual orientation, military or veteran status, or any other characteristic protected by federal, state, or local laws. Further, pursuant to applicable local ordinances, Inizio will consider for employment qualified applicants with arrest and conviction records.\n  \n \n \n   Inizio Engage is an equal opportunity employer M/F/V/D. We appreciate your interest in our company, however, only qualified candidates will be considered.", "cleaned_desc": "", "techs": ""}, "3e039391245c16c6": {"terms": ["data science", "data analyst"], "salary_min": 63671.273, "salary_max": 80622.02, "title": "IT Procurement Analyst (Remote, US)", "company": "Openly", "desc": "Openly is rebuilding insurance from the ground up. We are re-envisioning and enhancing every aspect of the customer experience. Doing this requires a rapidly growing team of exceptional, curious, empathetic people with a wide range of skill sets, spanning technology, data science, product, marketing, sales, service, claims handling, finance, etc. \n  Now is the perfect time to join the journey. Here's why \n \n It's working . We're in multiple states and on our way to operating countrywide. We have thousands of agents selling our product and millions of dollars of annual customer premiums. \n We're well-backed & stable.  We closed our $100M Series D fundraise. We are supported by some of the top investors globally, including Google's \"Gradient\" AI-focused fund, Obvious Ventures, Advance Venture Partners, Eden Global Partners, and Clocktower Technology Ventures. \n It's not too late!  Despite this traction and stability, we're still early enough in the journey that there's time to make a real difference during Openly's formative period. \n \n If you'd like to understand more about Openly's mission, consider checking out this video (https://vimeo.com/267654520) from a company pitch we gave several years ago at Techstars. \n \n  Job Details \n  We are pleased to announce that we are currently in search of an experienced IT Procurement Specialist to join our team. As an IT Procurement Specialist, you will play a crucial role in our organization, managing the procurement of IT hardware, software, and services. You will work closely with our IT department to ensure that all IT procurement meets the needs of the organization, while maintaining a high level of quality. \n  Key Responsibilities \n \n Execute procurement strategies for IT hardware, software, and services in order to meet the organization's needs and goals \n Work with existing software/hardware suppliers and identify the best value for our organization \n Track renewals for software licenses and send out reminders to business owners \n Managing the entire purchasing process from start to finish, which includes placing orders and delivery tracking. This will ensure that the procurement process is efficient and effective. \n Analyze data to identify areas of opportunity to consolidate and reduce spend for procurement and sourcing categories \n Staying up-to-date with industry trends and best practices in IT procurement, so that you can bring new ideas and approaches to the organization. \n Update our asset inventory system with new equipment and user assignment \n Work through the laptop depreciation cycle (report, order and coordinate replacements or disposal) \n Process receipts for IT purchases in our finance system \n Coordinate vendor meetings for quarterly updates with appropriate business owners \n Create reports for IT spend \n \n Requirements \n \n A Bachelor's degree in computer science or equivalent experience \n A minimum of 3 years of experience in IT procurement or a related field. \n Strong negotiation skills and the ability to build and maintain relationships with suppliers, which will help you get the best value for our organization. \n Knowledge of IT hardware, software, and services procurement processes, which will enable you to make informed decisions during the procurement process. \n Excellent organizational and communication skills, which are essential when working on complex procurement projects. \n \n If you are a detail-oriented IT procurement professional with a passion for delivering high-quality results, we encourage you to apply for this exciting opportunity. By joining our team, you will have the opportunity to work with a group of talented professionals who are committed to achieving our organization's goals. \n  #LI-AH1 \n \n  Benefits & Perks \n \n Remote-First Culture - We supported #remotelife long before it was a given. We'll keep promoting it. \n Competitive Salary & Equity \n Comprehensive Medical, Dental, and Vision Plan Offerings \n Life and disability coverage including voluntary options \n Competitive PTO - 20 days and 11 paid holidays (including floating holidays) per year under the Company's vacation and holiday policies.  \n Parental Leave - 12 weeks paid for eligible employees \n 401K Company Contribution - Openly contributes 3% of the employee's gross income, even if the employee does not contribute. \n Work-from-home stipend - We provide a $1,500 allowance to spend on setting up your home workplace \n Annual Professional Development Fund: Each employee has $2,000 in professional development (PD) funds to spend on activities or resources annually. We want each Openly employee to achieve personal and professional success and to feel supported, confident, and informed about improving their efficiency and productivity. \n Be Well Program - Employees receive $50 per month to use towards your overall well-being \n Paid Volunteer Service Hours \n Referral Program and Reward \n \n Depending on position, Employees generally are eligible for cash incentive compensation, including commissions for sales eligible roles. In all cases, eligibility for compensation and benefits is subject to applicable plan and policy terms in effect from time to time. \n  U.S. Citizens, Green Card Holders, and those authorized to work in the U.S. for any employer and currently residing in the US will be considered. \n  Openly is committed to equal employment opportunity and non-discrimination for all employees and qualified applicants without regard to a person's race, color, sex, gender identity or expression, age, religion, national origin, ancestry, ethnicity, disability, veteran status, genetic information, sexual orientation, marital status, or any characteristic protected under applicable law. Openly is an E-Verify Employer in the United States. Openly will make reasonable accommodations for qualified individuals with known disabilities under applicable law.", "cleaned_desc": "", "techs": ""}, "4183505971d6bd4a": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Director Remote Monitoring, Reliability & Performance Analytics", "company": "Fluence Energy", "desc": "About Fluence:  Fluence Energy, Inc. (Nasdaq: FLNC) is a global market leader in energy storage products and services, and optimization software for renewables and storage. With a presence in over 47 markets globally, Fluence provides an ecosystem of offerings to drive the clean energy transition, including modular, scalable energy storage products, comprehensive service offerings, and the Fluence IQ Platform, which delivers AI-enabled SaaS products for managing and optimizing renewables and storage from any provider. Fluence is transforming the way we power our world by helping customers create more resilient and sustainable electric grids.\n   \n \n    For more information, visit our website, or follow us on LinkedIn or Twitter. To stay up to date on the latest industry insights, sign up for Fluence's Full Potential Blog.\n   \n \n \n \n  OUR CULTURE AND VALUES \n \n \n \n  We are guided by our passion to transform the way we power our world. Achieving our goals requires creativity, diversity of ideas and backgrounds, and building trust to effect change and move with speed.\n   \n \n \n  We are Leading  \n \n \n   Fluence currently has thousands of MW of energy storage projects operated or awarded worldwide in addition to the thousands of MW of projects managed by our trading platform\u2014and we are growing every day.\n    \n \n \n \n \n We are Responsible  \n \n \n   Fluence is defined by its unwavering commitment to safety, quality, and integrity.\n    \n \n \n \n \n We are Agile  \n \n \n   We achieve our goals and meet our customer\u2019s needs by cultivating curiosity, adaptability, and self-reflection in our teams.\n   \n \n \n  We are Fun  \n \n \n   We value the diversity in thought and experience of our coworkers and customers. Through honest, forthcoming, and respectful communications we work to ensure that Fluence is an inclusive and welcoming environment for all.\n   \n \n \n  ABOUT THIS POSITON\n   \n \n \n  Location - Hybrid in Arlington, VA \n \n \n \n  The Director of Remote Monitoring, Reliability & Performance Analytics is a key global role responsible for taking the digital service operations within the energy storage sector to the next level. This person will play a critical role in enhancing product monitoring, availability, and overall service business performance by leveraging digital technologies and data-driven insights. The job requires collaboration between service regions and with software and product teams to develop and implement digital strategies, processes, and tools aimed at optimizing service delivery, maintenance, and customer support.\n   \n \n \n  Transform current remote asset monitoring approach of Fluence Battery Energy Storage systems \n  Lead coordination between service, digital and product team to develop and implement a leading industry performance management and alert system. Thereby prioritize functionality and development requests from the service regions \n  Provide insights from a deep understanding of energy storage and service business to drive functionality, displays, rapid troubleshooting and identification of issues \n  Prioritize/support rollout of new functionality to existing fleets \n  Identify opportunities for optimization, automation, and standardization of service and maintenance process and drive the implementation of best practices \n  Develop and execute a comprehensive strategy for performance analytics of the Fluence energy storage assets (enabling future digital service models). \n  Identify key measures for the improvement of availability and guide the regional teams on maximizing asset performance \n  Monitor fleet key metrics to identify operational issues and drive actions to correct. \n  Drive data automation initiatives to optimize the performance analytics function \n  Lead the development of reliability models for next product generations including \n  oversight of the development of reliability test plans, reliability data gathering and active support of new product development using historical performance data \n  Establish a robust failure library and ensure relevant KPIs are considered across the organization for the overall quality and performance improvement \n  Be the single source of truth for all installed base data monitoring \n  Support global sales and commercial teams on all performance and reliability data requests \n  Field custom performance dashboarding requests from customers \n  Foster and maintain strong relationships with customers on performance concerns and technical issues supporting the Field Service Engineering team. \n  Ensure lessons learned are captured and shared and implemented between service regions \n \n \n \n \n \n  What does the ideal candidate bring to Fluence? \n \n \n  Bachelors\u2019 degree Electrical or Controls Engineering or data science or equivalent required. \n  Experience in leading global teams in interaction with cross-organization departments \n  At Least 5 years proven experience in data analytics, reliability engineering and preferably in energy storage or renewable energy sector. \n  Experience with project management and change management methodologies. \n  Strong communication skills (written and verbal) \n  Strong analytical and problem-solving \n \n \n \n \n \n \n   At Fluence we are dedicated to building a diverse, inclusive, and authentic workplace; if you are excited about this role but your past experience doesn't align perfectly with every qualification in the job description, we encourage you to apply!\n   \n \n \n \n    Unlimited PTO\n   \n \n    Medical, Dental, Vision, Life and Pet Insurance\n   \n \n    Generous 401K Match\n   \n \n    Annual Bonus Incentive\n   \n \n \n \n    #energy #sustainability #inclusionmatters\n   \n \n \n \n \n \n    Follow Fluence on LinkedIn: Fluence LinkedIn\n   \n \n    Fluence Career Page: Fluence Careers\n   \n \n \n  Fluence IS AN EQUAL OPPORTUNITY EMPLOYER and fully subscribes to the principles of Equal Employment Opportunity to ensure that all applicants and employees are considered for hire, promotion, and job status without regard to race, color, religion, sex, national origin, age, disability, veteran status, sexual orientation, marital or familial status.", "cleaned_desc": " \n \n \n \n  What does the ideal candidate bring to Fluence? \n \n \n  Bachelors\u2019 degree Electrical or Controls Engineering or data science or equivalent required. \n  Experience in leading global teams in interaction with cross-organization departments \n  At Least 5 years proven experience in data analytics, reliability engineering and preferably in energy storage or renewable energy sector. \n  Experience with project management and change management methodologies. \n  Strong communication skills (written and verbal) \n  Strong analytical and problem-solving \n \n \n \n \n \n \n   At Fluence we are dedicated to building a diverse, inclusive, and authentic workplace; if you are excited about this role but your past experience doesn't align perfectly with every qualification in the job description, we encourage you to apply!\n   \n \n \n \n    Unlimited PTO\n   ", "techs": ["project management", "change management methodologies", "data analytics", "reliability engineering", "energy storage", "renewable energy sector"]}, "5612135415d8d844": {"terms": ["data science", "data analyst"], "salary_min": 69477.0, "salary_max": 135480.0, "title": "Sr. Data Analyst (Certified Coder) - REMOTE - CA ONLY", "company": "Molina Healthcare", "desc": "JOB DESCRIPTION \n \n  Job Summary \n \n  Designs and implements processes and solutions associated with a wide variety of data sets used for data/text mining, analysis, modeling, and predicting to enable informed business decisions. Gains insight into key business problems and deliverables by applying statistical analysis techniques to examine structured and unstructured data from multiple disparate sources. Collaborates across departments and with customers to define requirements and understand business problems. Uses advanced mathematical, statistical, querying, and reporting methods to develop solutions. Develops information tools, algorithms, dashboards, and queries to monitor and improve business performance. Creates solutions from initial concept to fully tested production and communicates results to a broad range of audiences. Effectively uses current and emerging technologies. \n \n  KNOWLEDGE/SKILLS/ABILITIES \n \n  With limited supervision, the Sr. Analyst, Data is responsible for data compilation, data management, data analysis, and reporting \n \n  Extracts and compiles various sources of information and large data sets from various systems or applications \n \n  Set up process for monitoring, tracking and trending information and data using various systems or applications \n \n  Prepares well-organized, easily understood reports, analysis, and summary of findings for use by management \n \n  Assists in preparation of regularly produced reports to support executive decision-making \n \n  Researches and analyze report results identifying opportunities and trends \n \n  Works with internal, external and enterprise individuals as needed to research, develop, and document new standard reports or processes \n \n  Consolidates data from multiple sources, using industry-based tools or manually; able to process data effectively using Microsoft Excel \n \n  Supports management and other team members as requested on all things data related. \n \n  JOB QUALIFICATIONS \n \n  Required Education \n \n  Associate degree or equivalent combination of education and experience \n \n  Required Experience \n \n  3-5 years \n \n  Preferred Education \n \n  Bachelor's Degree or equivalent combination of education and experience \n \n  Preferred Experience \n \n  5-7 years \n \n \n To all current Molina employees:  If you are interested in applying for this position, please apply through the intranet job listing. \n \n  Molina Healthcare offers a competitive benefits and compensation package. Molina Healthcare is an Equal Opportunity Employer (EOE) M/F/D/V. \n \n \n Pay Range:  $69,477 - $135,480 a year* \n \n \n Actual compensation may vary from posting based on geographic location, work experience, education and/or skill level.", "cleaned_desc": "JOB DESCRIPTION \n \n  Job Summary \n \n  Designs and implements processes and solutions associated with a wide variety of data sets used for data/text mining, analysis, modeling, and predicting to enable informed business decisions. Gains insight into key business problems and deliverables by applying statistical analysis techniques to examine structured and unstructured data from multiple disparate sources. Collaborates across departments and with customers to define requirements and understand business problems. Uses advanced mathematical, statistical, querying, and reporting methods to develop solutions. Develops information tools, algorithms, dashboards, and queries to monitor and improve business performance. Creates solutions from initial concept to fully tested production and communicates results to a broad range of audiences. Effectively uses current and emerging technologies. \n \n  KNOWLEDGE/SKILLS/ABILITIES \n \n  With limited supervision, the Sr. Analyst, Data is responsible for data compilation, data management, data analysis, and reporting \n ", "techs": ["data mining", "data analysis", "statistical analysis techniques", "structured data", "unstructured data", "mathematical methods", "statistical methods", "querying methods", "reporting methods", "information tools", "algorithms", "dashboards", "queries", "current technologies", "emerging technologies"]}, "7f9d838cfe296e9f": {"terms": ["data science", "machine learning engineer"], "salary_min": 112309.37, "salary_max": 142208.69, "title": "Machine Learning Infra Engineer", "company": "Cyberjin", "desc": "Remote Position \n  Our client is looking for a Machine Learning Engineer (infra hacker) who has scaled ML systems to 1M + users, is willing to go deep in the weeds on r&d, cares a ton about how backend systems work, has worked on large systems but executes like a startup, fast, ships and iterates.  \n Additional: \n  Ideal candidate traits \n  Previously scaled ML systems to 1M + users \n  Willing to go deep in the weeds on research & development \n \n \ufe0f Cares a ton about how backend systems work \n \n  Has worked on large systems but executes like a startup, fast, ships and iterates \n   \n HgFzj1rWR4", "cleaned_desc": "", "techs": ""}, "abbf6d196e1342b6": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Insurance Product Manager", "company": "Openly", "desc": "Openly is rebuilding insurance from the ground up. We are re-envisioning and enhancing every aspect of the customer experience. Doing this requires a rapidly growing team of exceptional, curious, empathetic people with a wide range of skill sets, spanning technology, data science, product, marketing, sales, service, claims handling, finance, etc. \n  Now is the perfect time to join the journey. Here's why \n \n It's working . We're in multiple states and on our way to operating countrywide. We have thousands of agents selling our product and millions of dollars of annual customer premiums. \n We're well-backed & stable.  We closed our $100M Series D fundraise. We are supported by some of the top investors globally, including Google's \"Gradient\" AI-focused fund, Obvious Ventures, Advance Venture Partners, Eden Global Partners, and Clocktower Technology Ventures. \n It's not too late!  Despite this traction and stability, we're still early enough in the journey that there's time to make a real difference during Openly's formative period. \n \n If you'd like to understand more about Openly's mission, consider checking out this video (https://vimeo.com/267654520) from a company pitch we gave several years ago at Techstars. \n \n  We are seeking an  Insurance Product Manager  to help drive our state expansion efforts and bring Openly insurance products to independent agents across the country. Reporting to the Senior Manager of Insurance Product Management, this highly visible role offers the opportunity to lead key insurance product management initiatives and interact with business leaders across Technology and Operations Teams. This role requires a self-motivated, high-energy individual who can efficiently function in a fast-paced, performance-driven environment. \n \n \n  Key Responsibilities \n \n Developing and calibrating Openly's homeowners program for established states and new state entries including UW eligibility, coverage offerings, premium rates, and Openly proprietary models \n Assisting with rate filings and DOI correspondence to ensure timely regulatory approval \n Collaborating with our Technology and Operations teams to successfully implement and launch the product in new states \n Analyzing key performance indicators and drivers of profitability, including loss ratios, actuarial indications, frequency/severity trends, sales conversion, persistency, and other data as we continue to grow our geographic footprint \n Leading other product management initiatives, such as external data evaluations, market/competitor intelligence, and new product development \n \n Requirements \n \n 3-5 years of experience in insurance product management and product development roles \n A degree in Mathematics, Actuarial Science, Economics, Statistics, or similar study \n Solid technical (SQL) and analytical skills, capable of developing quantitative analyses through data manipulation \n Ability to identify and define complex business problems and develop relevant analytical frameworks to deliver solutions, often operating in ambiguity and leveraging creativity \n Strong communication and project management skills, and the ability to collaborate effectively with people at all levels across the company \n Strong decision-making skills \n P&C insurance experience is required, and homeowners insurance experience is a plus \n Insurance product compliance and/or state launch experience is a plus \n \n #LI-CB1 \n \n  Benefits & Perks \n \n Remote-First Culture - We supported #remotelife long before it was a given. We'll keep promoting it. \n Competitive Salary & Equity \n Comprehensive Medical, Dental, and Vision Plan Offerings \n Life and disability coverage including voluntary options \n Competitive PTO - 20 days and 11 paid holidays (including floating holidays) per year under the Company's vacation and holiday policies.  \n Parental Leave - 12 weeks paid for eligible employees \n 401K Company Contribution - Openly contributes 3% of the employee's gross income, even if the employee does not contribute. \n Work-from-home stipend - We provide a $1,500 allowance to spend on setting up your home workplace \n Annual Professional Development Fund: Each employee has $2,000 in professional development (PD) funds to spend on activities or resources annually. We want each Openly employee to achieve personal and professional success and to feel supported, confident, and informed about improving their efficiency and productivity. \n Be Well Program - Employees receive $50 per month to use towards your overall well-being \n Paid Volunteer Service Hours \n Referral Program and Reward \n \n Depending on position, Employees generally are eligible for cash incentive compensation, including commissions for sales eligible roles. In all cases, eligibility for compensation and benefits is subject to applicable plan and policy terms in effect from time to time. \n  U.S. Citizens, Green Card Holders, and those authorized to work in the U.S. for any employer and currently residing in the US will be considered. \n  Openly is committed to equal employment opportunity and non-discrimination for all employees and qualified applicants without regard to a person's race, color, sex, gender identity or expression, age, religion, national origin, ancestry, ethnicity, disability, veteran status, genetic information, sexual orientation, marital status, or any characteristic protected under applicable law. Openly is an E-Verify Employer in the United States. Openly will make reasonable accommodations for qualified individuals with known disabilities under applicable law.", "cleaned_desc": " Requirements \n \n 3-5 years of experience in insurance product management and product development roles \n A degree in Mathematics, Actuarial Science, Economics, Statistics, or similar study \n Solid technical (SQL) and analytical skills, capable of developing quantitative analyses through data manipulation \n Ability to identify and define complex business problems and develop relevant analytical frameworks to deliver solutions, often operating in ambiguity and leveraging creativity \n Strong communication and project management skills, and the ability to collaborate effectively with people at all levels across the company \n Strong decision-making skills \n P&C insurance experience is required, and homeowners insurance experience is a plus \n Insurance product compliance and/or state launch experience is a plus ", "techs": ["sql", "mathematics", "actuarial science", "economics", "statistics", "project management", "communication", "decision-making", "p&c insurance", "homeowners insurance", "insurance product compliance", "state launch experience"]}, "7e621a84bb065507": {"terms": ["data science", "machine learning engineer"], "salary_min": 138601.61, "salary_max": 175500.52, "title": "AI Optimization Engineer (i4)", "company": "webAI", "desc": "Title:  AI Optimization Engineer \n  Company:  WebAI \n  Location : Austin, TX or Remote \n  Type:  Full-Time, Salaried Exempt \n  Experience:  5+ years \n  Education:  Bachelor's Degree, minimum \n \n \n  About the Company: \n  WebAI is at the forefront of artificial intelligence, pioneering innovations in machine learning, computer vision, and NLP. We are looking for a talented AI Optimization Engineer to join our team and help us make our machine learning models run efficiently on various hardware platforms. \n  Responsibilities: \n \n Collaborate with data scientists and machine learning engineers to understand model requirements. \n Optimize machine learning models for deployment on specific hardware including CPUs, GPUs, and TPUs. \n Implement model quantization, pruning, and other optimization techniques. \n Conduct benchmarks and performance analysis of optimized models. \n Work closely with hardware teams to co-design software and hardware solutions. \n \n Qualifications: \n \n Bachelor's or Master's degree in Computer Science, Electrical Engineering, or related field. \n 3+ years experience in machine learning optimization for hardware deployment. \n Strong programming skills in Python and C/C++. \n Familiarity with machine learning frameworks like TensorFlow, PyTorch, or ONNX. \n Experience with hardware-software co-design and computer architecture. \n Exceptional problem-solving and debugging skills. \n \n Nice to Have: \n \n Prior experience in embedded systems. \n Knowledge of FPGAs and ASICs. \n Publications in relevant conferences and journals. \n \n Personality Traits: \n \n Confidence: Willingness to take ownership of projects and make informed decisions. \n Detail-Oriented: Thorough in reviewing and refining code to ensure accuracy and functionality. \n Mature: Professional demeanor and ability to handle challenges with composure. \n Organized: Efficiently manage tasks, projects, and priorities in a fast-paced environment. \n Team Player: Collaborate effectively with cross-functional teams to achieve common goals. \n Creative Thinker: Bring innovative ideas to the table for enhancing user experiences. \n \n Benefits: \n \n Competitive salary and performance-based incentives. \n Comprehensive health, dental, and vision benefits package. \n Flexible work week \n Free parking, for in-office employees \n Unlimited PTO \n Parental, Bereavement Leave \n \n If you're a self-driven AI Optimization Engineer seeking an opportunity to make a significant impact within a forward-thinking company, we encourage you to apply. \n  WebAI is an Equal Opportunity Employer and does not discriminate against any employee or applicant on the basis of age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We adhere to these principles in all aspects of employment, including recruitment, hiring, training, compensation, promotion, benefits, social and recreational programs, and discipline. In addition, it is the policy of WebAI to provide reasonable accommodation to qualified employees who have protected disabilities to the extent required by applicable laws, regulations and ordinances where a particular employee works.", "cleaned_desc": "  Responsibilities: \n \n Collaborate with data scientists and machine learning engineers to understand model requirements. \n Optimize machine learning models for deployment on specific hardware including CPUs, GPUs, and TPUs. \n Implement model quantization, pruning, and other optimization techniques. \n Conduct benchmarks and performance analysis of optimized models. \n Work closely with hardware teams to co-design software and hardware solutions. \n \n Qualifications: \n   Bachelor's or Master's degree in Computer Science, Electrical Engineering, or related field. \n 3+ years experience in machine learning optimization for hardware deployment. \n Strong programming skills in Python and C/C++. \n Familiarity with machine learning frameworks like TensorFlow, PyTorch, or ONNX. \n Experience with hardware-software co-design and computer architecture. \n Exceptional problem-solving and debugging skills. \n \n Nice to Have: \n \n Prior experience in embedded systems. ", "techs": ["cpus", "gpus", "tpus", "model quantization", "pruning", "benchmarks", "performance analysis", "python", "c/c++", "tensorflow", "pytorch", "onnx", "hardware-software co-design", "computer architecture", "embedded systems."]}, "09eda34f8b118632": {"terms": ["data science", "data analyst"], "salary_min": 39.18, "salary_max": 47.18, "title": "Senior Data Analyst/Developer on contract 'W2'", "company": "WorkCog", "desc": "Senior Data Analyst/Developer \n Healthcare Client \n 100% Remote | CST or EST Hours \n 12+ Month Contract \n MUST Have: \n \n 10+ years\u2019 experience \n Experience with Identity and Access Management in a large organization. \n Well versed with MySQL database queries and creation of database views. \n Development experience with REST, SOAP, LDAP, MySQL \n Development experience with Java \n Self-starter who is excellent with managing external relationships and communications (important: following up) with technical contacts \n \n Nice To Have: \n \n IAM Tools/Systems: \n Radiant Logic HDAP  (High-Availability Directory Access Protocol) \n ICS  (Industrial Control System) \n FID  (Federated Identity)... Formally, known as VDS (Virtual Desk Service). \n \n Job Type: Contract \n Pay: $39.18 - $47.18 per hour \n Expected hours: 40 per week \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n \n Compensation package: \n \n Hourly pay \n \n Experience level: \n \n 11+ years \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n SQL: 1 year (Preferred) \n \n Work Location: Remote", "cleaned_desc": " Development experience with REST, SOAP, LDAP, MySQL \n Development experience with Java \n Self-starter who is excellent with managing external relationships and communications (important: following up) with technical contacts \n \n Nice To Have: \n \n IAM Tools/Systems: \n Radiant Logic HDAP  (High-Availability Directory Access Protocol) \n ICS  (Industrial Control System) ", "techs": ["rest", "soap", "ldap", "mysql", "java", "radiant logic hdap", "ics"]}, "316622d5a8305223": {"terms": ["data science", "machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Pre-sales Applied Data Scientist - (USA - East Coast)", "company": "causaLens", "desc": "causaLens is the pioneer of Causal AI \u2014 a giant leap in machine intelligence.    We are on a mission to build truly intelligent machines \u2014 it\u2019s hard but super fun! If you want to build the future and are looking for a place that values your curiosity and ambition, then causaLens is the right place for you. Everything we do is at the forefront of technological advancements, and we are always on the lookout for people to join us whose skills and passion tower above the rest.    Since the company was established in 2017, causaLens has:  Launched decisionOS, the first and only enterprise decision making platform powered by Causal AI - here \n  Raised $45 million in Series A funding  Been named a leading provider of Causal AI solutions by Gartner - here  Included in Otta\u2019s 2022 Rocket List as one of the fastest-growing companies to launch your career \n \n  Our Mission \n  To radically advance human decision-making. \n \n  Our Vision \n  A world in which humans leverage trustworthy AI to solve the greatest challenges in the economy, society and healthcare.  Head to our website homepage and watch the \u2018Why Causal AI\u2019 video to learn more. \n \n  The Role \n  We are looking for a Senior Pre-Sales Applied Data Scientist based in the USA to join us in spreading our Causal AI technology to every business on the planet. This is a full-time placement with significant opportunities for personal development. The Pre-Sales Applied Data Scientist will develop causal-AI-driven models and decision applications using our technology to illustrate how causal approaches can impact client business needs. \n \n  What you will do \n  The Pre-Sales Applied Data Scientist will work alongside our team of world class researchers, engineers, consultants, and executives to help us become one of the most recognized names in Tech. You will be required to work directly with our customers, illustrating how our technology can solve their most pressing business needs. Some of your responsibilities will include: \n \n  Using our causal AI framework to build causal models and decision applications, using our proprietary causal discovery, modeling, and decision intelligence architectures on client-supplied data sets and use cases. \n  Work directly with business stakeholders on the customer side to demonstrate how their domain knowledge fits into the modeling process and to show them how they could integrate insights into their decision workflows. \n  Together with client and causaLens stakeholders, craft a long-term vision and plan for successfully pushing causal models and insights into the customers\u2019 strategy. \n  Work closely with the product and research teams to shape the development of our platform. \n \n \n  At least 2 years of commercial data science experience with time series or tabular use-cases (preferably using Python) \n  Strong academic record in a quantitative field (MEng, MSci, EngD or PhD) \n  Excellent and proven communication and teamwork skills \n  Previous experience in high growth technology companies or technical consultancy is a plus \n  Previous experience in sales, pre-sales, and/or other technical evangelism is a plus \n  Experience in supply chain, demand forecasting, retail/cpg, manufacturing, marketing, financial services, or public sector is a plus \n \n \n  About causaLens  Current machine learning approaches have severe limitations when applied to real-world business problems and fail to unlock the true potential of AI for the enterprise. causaLens is pioneering Causal AI, a new category of intelligent machines that understand cause and effect \u2014 a major step towards true artificial intelligence. Our enterprise platform goes beyond predictions and provides causal insights and suggested actions that directly improve business outcomes for leading businesses in asset management, banking, insurance, logistics, retail, utilities, energy, telecommunications, and many others. \n \n  We may be biased, but we believe you\u2019ll be in good company. We offer a hybrid working setup and are dedicated to building an inclusive culture where diverse people and perspectives are welcomed. Aside from joining a smart and inspiring team, you\u2019ll be amongst people who are always there to support your ideas and encourage you to grow. We celebrate our differences and come together to share our triumphs! \n \n  What we offer  We care about our people\u2019s lives, both inside and outside of causaLens. Beyond the core benefits like competitive remuneration, pension scheme, paid holiday, and a good work-life balance, we offer the following: \n \n  Access to mental health support through Spill \n  Competitive salary \n  Annual Discretionary Bonus \n  25 days of paid holiday, plus bank holidays \n  Share options \n  Referral bonus program \n \n \n  Logistics \n  Our interview process consists of a few screening interviews and a \"Day 0\" which is spent with the team (virtually). We will always be as transparent as possible so please don\u2019t hesitate to reach out if you have any questions.", "cleaned_desc": "  Work directly with business stakeholders on the customer side to demonstrate how their domain knowledge fits into the modeling process and to show them how they could integrate insights into their decision workflows. \n  Together with client and causaLens stakeholders, craft a long-term vision and plan for successfully pushing causal models and insights into the customers\u2019 strategy. \n  Work closely with the product and research teams to shape the development of our platform. \n \n \n  At least 2 years of commercial data science experience with time series or tabular use-cases (preferably using Python) \n  Strong academic record in a quantitative field (MEng, MSci, EngD or PhD) \n  Excellent and proven communication and teamwork skills ", "techs": ["python"]}, "992e46b86561a44e": {"terms": ["data science", "data analyst"], "salary_min": 109722.76, "salary_max": 138933.45, "title": "Senior Data Analyst, Product", "company": "Docker", "desc": "Senior Data Analyst, Product \n \n Location (Remote): Canada, Mexico, United States \n \n \n \n  Docker is a remote first company with employees across Europe and the Americas that simplifies the lives of developers who are making world-changing apps. We raised our Series C funding in March 2022 for $105M at a $2.1B valuation. We saw a 4x year-over-year ARR growth last year and continue to grow! Join us for a whale of a ride!\n  \n \n \n  The Product team at Docker is looking for a Senior Data Analyst. You will help to transform billions of data points generated from the Docker products and services into actionable insights to directly influence product strategy and development. You will leverage your analytics, reporting, and communication skills to support Product Development teams to make data informed decisions.\n   \n  In this role, you'll help design and implement data models that support mission-critical reporting and analysis. You will partner with data engineers, analysts, product managers, and subject matter experts to deliver impactful reporting and analytics using tools such as Snowflake, Looker, Segment, and dbt. You will participate in high-visibility projects and directly influence product development and process optimization, building out self-serve analytic capabilities in areas such as product usage, active users, and cohort analysis. As the company grows, you will establish and promote data standards, best practices and help train and onboard new team members.\n   \n \n Responsibilities: \n \n \n Design, build and automate business metrics into self-serve dashboards via Looker \n Collaborate with product managers and analysts throughout the company to deliver reliable reports, transformed data sets, and self-serve dashboards that power actionable insights \n Create and maintain documentation for data sources including data dictionaries, common business data language, data nuances, and tracking aggregate tables. \n Present data insights and deliver presentations with the goal of educating and championing a data informed culture. \n Applying your expertise in quantitative analysis to see beyond the numbers and provide actionable insights \n Conducting exploratory data analysis including hypothesis testing, statistical inference and statistical analysis \n Build and maintain reports, dashboards and metrics, in addition to monitoring the integrity and validity of the data reported. \n \n \n Qualifications: \n \n \n 3+ years of experience in a data analytics related role \n Experience working with a Data Warehouse platform (e.g. Snowflake, Redshift, BigQuery, AWS Athena, or Spectrum). \n Ability to write, improve, and troubleshoot complex SQL queries \n Analytical background and experience in querying and transforming data to compute metrics and conduct a variety of analyses to inform decisions \n Experience working in Python or R to perform statistical analysis \n Experience building dashboards in a modern business intelligence tool (e.g. Looker, Tableau, or PowerBI) \n You can explain complex ideas simply. \n You have effective written, verbal, and visual communication skills. \n \n \n Perks: \n \n \n Freedom & flexibility; fit your work around your life \n Variety of virtual and in-person social events to build connections and have fun \n Home office setup; we want you comfortable while you work \n Generous maternity and parental leave \n Technology stipend equivalent to $100 net/month \n PTO plan that encourages you to take time to do the things you enjoy \n Whaleness Days: companywide day off each month \n Quarterly, company-wide hackathons \n Training stipend for conferences, courses and classes \n Stock Options; we are a growing start-up and want all employees to have a share in the success of the company \n Docker Swag \n Medical benefits, retirement and holidays vary by country \n \n \n  Docker embraces diversity and equal opportunity. We are committed to building a team that represents a variety of backgrounds, perspectives, and skills. We believe the more inclusive we are, the better our company will be.\n  \n \n \n \n   CA/NY/ Boulder, CO & Denver, CO - 145,000 - 196,000\n   \n \n   CO - 140,000 - 189,000\n   \n \n Salary range can change depending on level. \n \n \n \n \n  Due to the remote nature of this role, we are unable to provide visa sponsorship.\n   \n  #LI-REMOTE", "cleaned_desc": " Responsibilities: \n \n \n Design, build and automate business metrics into self-serve dashboards via Looker \n Collaborate with product managers and analysts throughout the company to deliver reliable reports, transformed data sets, and self-serve dashboards that power actionable insights \n Create and maintain documentation for data sources including data dictionaries, common business data language, data nuances, and tracking aggregate tables. \n Present data insights and deliver presentations with the goal of educating and championing a data informed culture. \n Applying your expertise in quantitative analysis to see beyond the numbers and provide actionable insights \n Conducting exploratory data analysis including hypothesis testing, statistical inference and statistical analysis \n Build and maintain reports, dashboards and metrics, in addition to monitoring the integrity and validity of the data reported. \n \n \n Qualifications: \n \n   3+ years of experience in a data analytics related role \n Experience working with a Data Warehouse platform (e.g. Snowflake, Redshift, BigQuery, AWS Athena, or Spectrum). \n Ability to write, improve, and troubleshoot complex SQL queries \n Analytical background and experience in querying and transforming data to compute metrics and conduct a variety of analyses to inform decisions \n Experience working in Python or R to perform statistical analysis \n Experience building dashboards in a modern business intelligence tool (e.g. Looker, Tableau, or PowerBI) \n You can explain complex ideas simply. \n You have effective written, verbal, and visual communication skills. \n \n \n Perks: \n \n \n Freedom & flexibility; fit your work around your life \n Variety of virtual and in-person social events to build connections and have fun ", "techs": ["looker", "snowflake", "redshift", "bigquery", "aws athena", "spectrum", "sql", "python", "r", "tableau", "powerbi."]}, "51c92c1e604e0abd": {"terms": ["data science"], "salary_min": 120000.0, "salary_max": 135000.0, "title": "Economist - Health Researcher (Remote Eligible)", "company": "Mathematica Policy Research", "desc": "Position Description:     \n About the opportunity \n  Mathematica economists and health researchers collaborate with staff to design rigorous methods for evaluating programs and policies, conduct analyses, draft reports, present findings to policy and professional audiences, and publish in professional journals. A qualified researcher should have strong analytic and quantitative skills and possess a Ph.D. in economics or a related field by Spring 2024. They should also have a strong interest in working in a collaborative, multidisciplinary environment that emphasizes quality, rigor, critical thinking, objectivity, diversity and inclusion, equity, and professional development. Excellent written and oral communication skills are essential. Experience in policy research is a plus. \n \n \n \n Position Requirements:     \n \n Ph.D. or equivalent in economics, public health, epidemiology, public policy, health services research, social sciences, or other relevant discipline. \n  Strong foundation in quantitative research methods and a broad understanding of health policy issues. \n  Excellent written and oral communication skills, including an ability to translate research findings for a policy audience. \n  Ability to work well in teams. \n \n  To Apply for the Health Economist Position    A cover letter, CV, and writing sample and/or job market paper must be submitted at the time of application via our online application system.     Letters of reference should be emailed to HumanResources@mathematica-mpr.com. \n  Application Submission Deadline: November 27th, 2023 @ 12PM EST     Complete application packages that are submitted before 12pm EST on November 27th, 2023 will be considered.    Mathematica will be conducting virtual interviews starting December 11th 2023. \n  Additional information \n  This position offers an anticipated base salary of $120,000 - $135,000 annually. This position is eligible for an annual bonus based on company and individual performance.    Available locations: Washington, DC; Princeton, NJ; Cambridge, MA; Chicago, IL; Oakland, CA; Remote    We welcome applications from candidates who wish to work remotely/virtually full-time.   \n About Mathematica    Mathematica applies expertise at the intersection of data, methods, policy, and practice to improve well-being around the world. We collaborate closely with public- and private-sector partners to translate big questions into deep insights that improve programs, refine strategies, and enhance understanding using data science and analytics. Our work yields actionable information to guide decisions in wide-ranging policy areas, from health, education, early childhood, and family support to nutrition, employment, disability, and international development. Mathematica offers our employees competitive salaries, and a comprehensive benefits package, as well as the advantages of being 100 percent employee owned. As an employee stock owner, you will experience financial benefits of ESOP holdings that have increased in tandem with the company\u2019s growth and financial strength. You will also be part of an independent, employee-owned firm that is able to define and further our mission, enhance our quality and accountability, and steadily grow our financial strength. Read more about our benefits here: https://www.mathematica.org/career-opportunities/benefits-at-a-glance   \n \n \n \n We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.", "cleaned_desc": "", "techs": ""}, "639db2ab31477865": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Digital Analyst/Web Analyst (Hybrid)", "company": "The Hartford", "desc": "Sr Spec Digital Marketing - ME08AE\n  \n \n   We\u2019re determined to make a difference and are proud to be an insurance company that goes well beyond coverages and policies. Working here means having every opportunity to achieve your goals \u2013 and to help others accomplish theirs, too. Join our team as we help shape the future.\n  \n \n \n  As an integral member of the Digital Analytics team, the successful candidate will work directly with lines of business to develop, maintain and enhance reporting and analytics capabilities (online, offline, and mobile) by providing thorough analysis and insight into customer behavior, activities and preferences across various channels. To facilitate this goal, the position works closely with business partners to provide reporting, analysis and data-supported decision-making tools to shape the current and future digital strategy of the organization.\n  \n \n \n   Using data from various sources (online, offline/data warehouse, etc.) the incumbent will clearly identify and recommend actions to improve the overall effectiveness and efficiency of the digital channel, processes and marketing campaigns, while maintaining a path toward growth within the business line. This role will develop clear business and measurement objectives for each digital initiative through collaboration with internal customers.\n  \n \n \n   This position requires strong analytical skills, an eye for numbers, intellectual curiosity, proficiency at problem solving, an understanding of digital and traditional media, and strong presentation skills. Most importantly, the successful candidate should have a strong desire to help shape the organization\u2019s digital commerce future.\n  \n \n \n   Specific deliverables include:\n  \n \n \n \n     Develop a true working partnership with the various marketing teams to design and implement a comprehensive strategy to support existing and future digital business initiatives. Become immersed in the process, business objectives and data to provide deep insight and analytical value to the organization to shape digital projects.\n    \n \n \n     Develop an effective set of dashboards, reports, KPIs and metrics to inform day-to-day business decisions and to expose areas of opportunity. These reports will be used by our business-partners to better understand the effectiveness of web site behavior, decision making, web site optimization, business impact, social media effectiveness and marketing campaign management.\n    \n \n \n     Leverage appropriate resources to guide the development of enhanced (ad hoc) analyses for the business to provide insight in short, medium and long-term strategic initiatives. Utilize new tools and reporting techniques to identify areas of opportunities for business growth.\n    \n \n \n     Interpret online and offline behavior from various data sources with a focus on strengthening The Hartford's web experience. Facilitate conversations with stakeholders, technical and analytical resources to focus on key performance indicators such as acquisition, conversion and retention to ensure that the proper value is associated with the data or data combinations. Utilize data sources to stitch together a comprehensive customer-centric view of our digital properties. This will span online and offline data sources (the web, call centers, policy and demographics) to be presented to line of business owners for improvements or system/process performance.\n    \n \n \n     Perform advanced analytics, BI and reporting for digital initiatives, ensuring achievement of expected results.\n    \n \n \n     End to end ownership of analyses involving multiple data sets, exploring new data sources and leverage techniques to ensure competitive advantage and new business opportunities.\n    \n \n \n     Extract data from data environments, work with large and complex data sets to cleanse and manipulate data to formulate insights.\n    \n \n \n     Develop test plans, define success metrics. Create compelling data visualizations and business dashboards based on multi-channel analytics data.\n    \n \n \n     Utilize data by joining online, offline, customer characteristic and third party data. Identifies opportunities to drive data quality improvements to ensure accuracy.\n    \n \n \n   Requirements:\n  \n \n \n \n     Significant hands-on experience with digital analytics tools such as Google Analytics, Adobe Analytics, etc.\n    \n \n \n     Advanced skills in data and visualization tools. Visualization Platforms, Qlik Sense, Power BI, Tableau, SnowSQL, SQL, SAS, R, Python, Spark, MS Office Suite with advanced knowledge of Excel.\n    \n \n \n     Hands on experience with analytics querying using tools such as SQL, SnowSQL, in addition to experience with ETL and database structures.\n    \n \n \n     Direct experience developing visualizations and dashboards with BI tools.\n    \n \n \n     Proven track record harnessing digital channel data to drive actionable insights\n    \n \n \n     Extensive experience in blending data from multiple data sources.\n    \n \n \n     Strong background in quantitative analysis and proficiency in analyzing data from internal and external sources.\n    \n \n \n     Demonstrable experience debugging JavaScript code using tools like Fiddler, FireBug ,Chrome Developer etc\n    \n \n \n     Demonstrable experience with Platform Support and Implementation using tag management system (Tealium or other industry leading tag management solutions )\n    \n \n \n     Familiarity with scripting for web analytics tool; Adobe Insight, Google Analytics\n    \n \n \n     Good understanding of scripting using JavaScript or jQuery /Angular/ReactJS for data capture and event handling methods via the DOM event model\n    \n \n \n     3 plus years of E-commerce experience in large scale digital commerce, with end to end digital analytics accountability with a statistical background.\n    \n \n \n     Bachelors or Masters in mathematics, statistics, economics, bus analysis.\n    \n \n \n     Strong stakeholder management experience coupled with experience presenting to small groups\n    \n \n \n     Project Management experience with a track record of meeting deadlines independently and managing small projects or portions of larger projects.\n    \n \n \n     3 plus years\u2019 experience in Analytics, Data Science or Statistics, Insurance or Financial Services preferred.\n    \n \n     Additional Details:\n    \n \n \n     Must be authorized to work in the US without company sponsorship.\n    \n \n \n     Sustaining The Hartford\u2019s unique workplace culture is vital to delivering on our purpose \u2013 underwriting human achievement \u2013 and continuously producing outstanding results. Our enterprise work model, which reflects a mix of in-office, hybrid and fully remote roles, helps us attract, retain and develop the talent we need to achieve the company\u2019s strategic goals. This role will have a Hybrid work arrangement\n    \n \n \n \n   Compensation\n  \n \n   The listed annualized base pay range is primarily based on analysis of similar positions in the external market. Actual base pay could vary and may be above or below the listed range based on factors including but not limited to performance, proficiency and demonstration of competencies required for the role. The base pay is just one component of The Hartford\u2019s total compensation package for employees. Other rewards may include short-term or annual bonuses, long-term incentives, and on-the-spot recognition. The annualized base pay range for this role is:\n  \n  $79,280 - $118,920\n  \n \n   Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age", "cleaned_desc": "    \n \n \n     Leverage appropriate resources to guide the development of enhanced (ad hoc) analyses for the business to provide insight in short, medium and long-term strategic initiatives. Utilize new tools and reporting techniques to identify areas of opportunities for business growth.\n    \n \n \n     Interpret online and offline behavior from various data sources with a focus on strengthening The Hartford's web experience. Facilitate conversations with stakeholders, technical and analytical resources to focus on key performance indicators such as acquisition, conversion and retention to ensure that the proper value is associated with the data or data combinations. Utilize data sources to stitch together a comprehensive customer-centric view of our digital properties. This will span online and offline data sources (the web, call centers, policy and demographics) to be presented to line of business owners for improvements or system/process performance.\n    \n \n \n     Perform advanced analytics, BI and reporting for digital initiatives, ensuring achievement of expected results.\n    \n \n \n     End to end ownership of analyses involving multiple data sets, exploring new data sources and leverage techniques to ensure competitive advantage and new business opportunities.\n    \n \n \n     Extract data from data environments, work with large and complex data sets to cleanse and manipulate data to formulate insights.\n    \n \n \n     Develop test plans, define success metrics. Create compelling data visualizations and business dashboards based on multi-channel analytics data.\n    \n \n \n     Utilize data by joining online, offline, customer characteristic and third party data. Identifies opportunities to drive data quality improvements to ensure accuracy.\n      \n \n   Requirements:\n  \n \n \n \n     Significant hands-on experience with digital analytics tools such as Google Analytics, Adobe Analytics, etc.\n    \n \n \n     Advanced skills in data and visualization tools. Visualization Platforms, Qlik Sense, Power BI, Tableau, SnowSQL, SQL, SAS, R, Python, Spark, MS Office Suite with advanced knowledge of Excel.\n    \n \n \n     Hands on experience with analytics querying using tools such as SQL, SnowSQL, in addition to experience with ETL and database structures.\n    \n \n \n     Direct experience developing visualizations and dashboards with BI tools.\n    \n \n \n     Proven track record harnessing digital channel data to drive actionable insights\n    \n \n \n     Extensive experience in blending data from multiple data sources.\n      \n \n     Strong background in quantitative analysis and proficiency in analyzing data from internal and external sources.\n    \n \n \n     Demonstrable experience debugging JavaScript code using tools like Fiddler, FireBug ,Chrome Developer etc\n    \n \n \n     Demonstrable experience with Platform Support and Implementation using tag management system (Tealium or other industry leading tag management solutions )\n    \n \n \n     Familiarity with scripting for web analytics tool; Adobe Insight, Google Analytics\n    \n \n \n     Good understanding of scripting using JavaScript or jQuery /Angular/ReactJS for data capture and event handling methods via the DOM event model\n    \n \n \n     3 plus years of E-commerce experience in large scale digital commerce, with end to end digital analytics accountability with a statistical background.\n    \n \n \n     Bachelors or Masters in mathematics, statistics, economics, bus analysis.\n    \n ", "techs": ["google analytics", "adobe analytics", "visualization platforms", "qlik sense", "power bi", "tableau", "snowsql", "sql", "sas", "r", "python", "spark", "ms office suite", "excel", "sql", "snowsql", "etl", "database structures", "bi tools", "javascript", "fiddler", "firebug", "chrome developer", "tealium", "adobe insight", "google analytics", "javascript", "jquery", "angular", "reactjs."]}, "5a7c3ec2d2ee03dc": {"terms": ["data science"], "salary_min": 104484.81, "salary_max": 132301.06, "title": "TSS Data Scientist", "company": "General Dynamics Information Technology", "desc": "GDIT is seeking a Data Scientist to support its Technology Shared Services (TSS) Data Science team, developing predictive models, machine learning algorithms, and delivering data-driven solutions. As the Data Scientist, you will support GDIT's customers with data-informed solutions tailored to their unique needs.\n  \n  You will find yourself at the heart of GDIT's customer-centric approach, playing a pivotal role in ensuring our customers successfully meet their strategic goals. You will use your project management and data skills to promote organizational goals to completion. If you enjoy collaborating with others in a fast-paced environment, you will find this role to be both rewarding and challenging.\n  \n  GDIT is your place. You make it your own. Bring your creativity to help us find simple solutions to complex problems. By owning your opportunity at GDIT, you'll play an essential part in preparing our nation for the future. At GDIT, our employees are driven, resourceful, and unwavering.\n  \n \n GDIT is committed to fostering economic growth and prosperity in Louisiana, with established operations in multiple locations throughout the state, including facilities in New Orleans, Natchitoches, and our Integrated Technology Center in Bossier City, LA. This position offers the flexibility to work 100% remotely from anywhere within the state of Louisiana.  \n \n \n HOW A DATA SCIENTIST WILL MAKE AN IMPACT \n \n \n  Present insights to both technical and non-technical team members and stakeholders, assisting in making informed, data-driven decisions. \n  Contribute to a variety of complex data-related projects, including machine learning, predictive modeling, and analytics. \n  Leverage large sets of structured and unstructured data to develop tools and techniques for robust data analysis. \n  Collaborate with different teams to understand their data needs and create solutions that solve problems and streamline workflows. \n  Continually evaluate emerging technologies and stay updated on modern data science trends to implement in future projects. \n  Provide input into the development of data science approaches for current client projects and the scoping of future projects. \n \n \n  WHAT YOU'LL NEED TO SUCCEED \n \n Education:  \n \n \n BA/BS (or equivalent years of experience) \n \n \n  Required Experience :\n  \n \n  2+ years of relevant experience \n \n \n  Required Skills and Abilities: \n \n \n  Excellent communication and presentation skills with the ability to present complex data insights to both technical and non-technical audiences. \n  Strong analytical skills with the ability to collect, organize, analyze, and disseminate insights with attention to detail and accuracy. \n  Good team player, able to manage multiple assignments, and adapt to changing client needs. \n  Skilled in implementing advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, and proper usage, etc.) \n  Experienced in implementing some machine learning techniques (may include supervised and unsupervised learning, deep learning, natural language processing, ensemble methods, dimensionality reduction) \n  Skilled in programming languages like Python, R, SQL, and experience in working with data visualization tools like Tableau, Power BI. \n  Familiarity with machine learning frameworks (like Keras or PyTorch), libraries (like scikit-learn), and computing platforms (like Jupyter) \n \n \n  Preferred Skills: \n \n \n  Demonstrated experience consulting with internal and external customers to understand business needs and make recommendations. \n  Previous experience in the defense or government sector \n  Familiarity with cloud services: AWS, Google Cloud, Microsoft Azure, etc.) and big data tools is plus. \n  Experience in optimization algorithms and natural language processing is a plus. \n  Experience with web applications is a plus. \n  Data science and cloud certifications are a plus (Certified Data Scientist (CDS), AWS Certified Machine Learning - Specialty, Microsoft Certified: Azure Data Scientist Associate, IBM Data Science Professional) \n \n \n  GDIT IS YOUR PLACE: \n \n \n Full-flex work week to own your priorities at work and at home** (remove if not eligible)** \n 401K with company match \n Comprehensive health and wellness packages \n Internal mobility team dedicated to helping you own your career \n Professional growth opportunities including paid education and certifications \n Cutting-edge technology you can learn from \n Rest and recharge with paid vacation and holidays **(remove if not eligible)** \n \n  Work Requirements\n  \n  .cls-1{fill:none;stroke:#5b6670;stroke-miterlimit:10;stroke-width:2px;} \n   Years of Experience \n   2 + years of related experience\n  \n \n \n may vary based on technical training, certification(s),  or  degree \n \n  .cls-1,.cls-2{fill:none;stroke:#5b6670;stroke-miterlimit:10;}.cls-1{stroke-width:1.77px;}.cls-2{stroke-width:2px;} \n   Certification\n  \n  .cls-1{fill:none;stroke:#5b6670;stroke-miterlimit:10;stroke-width:2px;} \n   Travel Required \n   None\n  \n  About Our Work\n  \n  We are GDIT. A global technology and professional services company that delivers consulting, technology and mission services to every major agency across the U.S. government, defense and intelligence community. Our 30,000 experts extract the power of technology to create immediate value and deliver solutions at the edge of innovation. We operate across 30 countries worldwide, offering leading capabilities in digital modernization, AI/ML, Cloud, Cyber and application development. Together with our clients, we strive to create a safer, smarter world by harnessing the power of deep expertise and advanced technology. \n  \n  GDIT is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status, or any other protected class.", "cleaned_desc": "GDIT is seeking a Data Scientist to support its Technology Shared Services (TSS) Data Science team, developing predictive models, machine learning algorithms, and delivering data-driven solutions. As the Data Scientist, you will support GDIT's customers with data-informed solutions tailored to their unique needs.\n  \n  You will find yourself at the heart of GDIT's customer-centric approach, playing a pivotal role in ensuring our customers successfully meet their strategic goals. You will use your project management and data skills to promote organizational goals to completion. If you enjoy collaborating with others in a fast-paced environment, you will find this role to be both rewarding and challenging.\n  \n  GDIT is your place. You make it your own. Bring your creativity to help us find simple solutions to complex problems. By owning your opportunity at GDIT, you'll play an essential part in preparing our nation for the future. At GDIT, our employees are driven, resourceful, and unwavering.\n  \n \n GDIT is committed to fostering economic growth and prosperity in Louisiana, with established operations in multiple locations throughout the state, including facilities in New Orleans, Natchitoches, and our Integrated Technology Center in Bossier City, LA. This position offers the flexibility to work 100% remotely from anywhere within the state of Louisiana.  \n \n \n HOW A DATA SCIENTIST WILL MAKE AN IMPACT \n \n \n  Present insights to both technical and non-technical team members and stakeholders, assisting in making informed, data-driven decisions. \n  Contribute to a variety of complex data-related projects, including machine learning, predictive modeling, and analytics. \n  Leverage large sets of structured and unstructured data to develop tools and techniques for robust data analysis. \n  Collaborate with different teams to understand their data needs and create solutions that solve problems and streamline workflows. \n  Continually evaluate emerging technologies and stay updated on modern data science trends to implement in future projects.   \n \n  Excellent communication and presentation skills with the ability to present complex data insights to both technical and non-technical audiences. \n  Strong analytical skills with the ability to collect, organize, analyze, and disseminate insights with attention to detail and accuracy. \n  Good team player, able to manage multiple assignments, and adapt to changing client needs. \n  Skilled in implementing advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, and proper usage, etc.) \n  Experienced in implementing some machine learning techniques (may include supervised and unsupervised learning, deep learning, natural language processing, ensemble methods, dimensionality reduction) \n  Skilled in programming languages like Python, R, SQL, and experience in working with data visualization tools like Tableau, Power BI. \n  Familiarity with machine learning frameworks (like Keras or PyTorch), libraries (like scikit-learn), and computing platforms (like Jupyter) \n \n \n  Preferred Skills: \n \n \n  Demonstrated experience consulting with internal and external customers to understand business needs and make recommendations. \n  Previous experience in the defense or government sector \n  Familiarity with cloud services: AWS, Google Cloud, Microsoft Azure, etc.) and big data tools is plus. \n  Experience in optimization algorithms and natural language processing is a plus. ", "techs": ["tableau", "power bi", "python", "r", "sql", "keras", "pytorch", "scikit-learn", "jupyter", "aws", "google cloud", "microsoft azure"]}, "592589cc9edba0ab": {"terms": ["data science", "machine learning engineer", "mlops"], "salary_min": 116777.984, "salary_max": 147866.95, "title": "Machine Learning Engineer", "company": "webAI", "desc": "Machine Learning Engineer \n \n \n \n  We are seeking a talented and experienced Machine Learning Engineer to join our team! As a Machine Learning Engineer at webAI, you garner experience developing and deploying ML models alongside our researchers to bolster our platform. An ideal candidate will have experience with both unstructured and structured data machine learning use-cases.\n  \n \n \n Responsibilities: \n \n \n Research, design, implement, and fine-tune machine learning models, including deep learning architectures, to be included in or to advance our platform. \n Compile/pre-process datasets for training purposes \n Extract meaningful features from data through feature engineering to improve model performance \n Extend and develop the organizations existing ML libraries and proprietary frameworks \n Collaborate with R&D and systems software engineering teams \n Promote and adhere to MLOps best practices within the organization \n Ensure production intent code is properly documented and tested \n Stay up to date on latest AI trends and research papers \n \n \n Qualifications: \n \n \n Proven experience as a Machine Learning Engineer or similar role \n Batchelor's (Master's prefered) in Computer Science, Machine Learning, Data Science, or a related field \n Understanding of data structures, data modeling and software architecture \n Deep knowledge of math, probability, statistics and algorithms \n Ability to write robust code in Python (Rust, C/C++, Cuda, or MPS experience a plus) \n Expertise in data preprocessing, feature engineering, and model evaluation technique \n Experience working with Tensorflow and/or PyTorch along with scikit-learn, numpy, pandas, and opencv \n Experience with cloud computing platforms and model deployment techniques using Docker containerization \n Experience with MLOps tools like, MLFlow, KubeFlow, Airflow or similar \n Passionate about learning \n Strong verbal and written communication skills", "cleaned_desc": " Proven experience as a Machine Learning Engineer or similar role \n Batchelor's (Master's prefered) in Computer Science, Machine Learning, Data Science, or a related field \n Understanding of data structures, data modeling and software architecture \n Deep knowledge of math, probability, statistics and algorithms \n Ability to write robust code in Python (Rust, C/C++, Cuda, or MPS experience a plus) \n Expertise in data preprocessing, feature engineering, and model evaluation technique ", "techs": ["machine learning engineer", "computer science", "machine learning", "data science", "data structures", "data modeling", "software architecture", "math", "probability", "statistics", "algorithms", "python", "rust", "c/c++", "cuda", "mps", "data preprocessing", "feature engineering", "model evaluation technique"]}, "d67743038861f0ce": {"terms": ["data science", "machine learning engineer"], "salary_min": 112309.37, "salary_max": 142208.69, "title": "Machine Learning Infra Engineer", "company": "Cyberjin", "desc": "Hybrid/Remote role \n  Our client is looking for a Machine Learning Engineer (infra hacker) who has scaled ML systems to 1M + users, is willing to go deep in the weeds on r&d, cares a ton about how backend systems work, has worked on large systems but executes like a startup, fast, ships and iterates.  \n Ideal candidate traits: \n  Previously scaled ML systems to 1M + users \n  Willing to go deep in the weeds on research & development \n \n \ufe0f Cares a ton about how backend systems work \n \n  Has worked on large systems but executes like a startup, fast, ships and iterates \n \n   \n   \n uImfydCO2f", "cleaned_desc": "", "techs": ""}, "1619d80b8961418b": {"terms": ["data science", "machine learning engineer"], "salary_min": 139063.17, "salary_max": 176084.95, "title": "Sr. Data Scientist - Remote, US", "company": "Packsize, LLC", "desc": "About Packsize  Packsize is redefining the way businesses and their customers use and experience packaging around the world. We build the technology, design the right solutions, and automate the processes that propel the industry forward. To us, packaging is much more than a box\u2014it\u2019s delivering what\u2019s right for our customers, their customers, our people, and the planet. \n About the Role  Packsize is seeking a skilled Data Scientist with Operational AI and Business Intelligence expertise. The ideal candidate will bring technical prowess in artificial intelligence solutions and business intelligence tools and will also be instrumental in establishing the company's foundational best practices for data science projects. This role is critical to our strategy of integrating AI with our traditional analytics, enabling data-driven decision-making across the organization. \n What You'll Do \n \n Operational AI/Data Science Implementation: \n \n This is a technical position that requires hands-on AI Solutions Development.   \n Establish and implement best practices for data science projects, ensuring consistency, scalability, and reproducibility.   \n Set up a process for code base management, ensuring version control, code reviews, and seamless collaboration among team members.   \n Develop comprehensive documentation standards for data science projects, including data sources, methodologies, model decisions, and results.   \n Oversee the development and scalable deployment of AI models and tools into BI processes.   \n Continuously evaluate the latest AI technologies and BI tools, ensuring the team leverages best-in-class solutions.   \n \n Prescriptive Analytics: \n \n Lead the company's transition from relying primarily on descriptive analytics to leveraging advanced prescriptive analytics, ensuring a holistic understanding of data insights.   \n Develop models to analyze complex business scenarios and provide actionable recommendations.   \n Translate complex analytical findings into clear, actionable insights for non-technical stakeholders.   \n \n Project Management:  \n \n Lead data science projects from inception to completion, ensuring timely delivery and quality.   \n Projects may span the domains of supply chain management, inventory monitoring, optimization of fleets of machines or vehicles and personnel, optimization of business workflows for improved financial or resource planning, etc.   \n Prioritize projects based on potential business impact and resource availability.   \n \n Collaboration & Communication: \n \n Work closely with cross-functional teams to ensure that AI and BI insights are translated into actionable business strategies. \n Communicate complex data findings clearly and promptly to senior leadership and non-technical stakeholders.   \n Coordinate with the Business Intelligence team, including data analysts, BI developers, and data engineers, to ensure alignment and collaboration.   \n \n \n What You'll Bring: \n \n Bachelor\u2019s degree in Computer Science, Data Science, Information Systems, Statistics, Mathematics, or a related field. Master\u2019s degree or Ph.D. in a related field is a plus   \n Minimum of 5 years of data science experience, focusing on Operational AI and business intelligence.   \n Proficiency in machine learning algorithms, deep learning frameworks, LLMs, and statistical modeling   \n Hands-on experience with AI/ML platforms such as TensorFlow, PyTorch, or Keras   \n Understanding of model training, validation, optimization, and edge-to-cloud deployment techniques   \n Strong programming skills in Python, R, or similar programming languages. Familiarity with SQL and database querying is essential   \n Strong understanding of data modeling, ETL processes, and data visualization   \n Ability to think critically, conceptualize complex problems, and develop AI/ML solutions that address business challenges   \n Experience in collaborating with cross-functional teams, including data engineers, IT, and business stakeholders   \n \n Salary & Benefits \n The salary range for this role is  [$140k - $160k USD + 10% Bonus] ; however, Packsize considers several factors when determining compensation  when extending  a job  offer, including but not limited to, the role  being offered, the  associated responsibilities,  the  candidate's  prior  work experience, education/training, and  any  special  skills. \n Packsize is an Equal Opportunity employer and is committed to diversity in its workforce. In compliance with applicable federal and state laws, Packsize policy of equal employment opportunity prohibits discrimination on the basis of race or ethnicity, religion, color, national origin, sex, age, sexual orientation, gender identity/expression, veteran\u2019s status, status as a qualified person with a disability, or genetic information. Individuals from historically underrepresented groups, such as minorities, women, qualified persons with disabilities and protected veterans are strongly encouraged to apply. Reasonable accommodations in the application process will be provided to qualified individuals with disabilities. \n #LI-AS1", "cleaned_desc": " Develop comprehensive documentation standards for data science projects, including data sources, methodologies, model decisions, and results.   \n Oversee the development and scalable deployment of AI models and tools into BI processes.   \n Continuously evaluate the latest AI technologies and BI tools, ensuring the team leverages best-in-class solutions.   \n \n Prescriptive Analytics: \n \n Lead the company's transition from relying primarily on descriptive analytics to leveraging advanced prescriptive analytics, ensuring a holistic understanding of data insights.   \n Develop models to analyze complex business scenarios and provide actionable recommendations.   \n Translate complex analytical findings into clear, actionable insights for non-technical stakeholders.     Work closely with cross-functional teams to ensure that AI and BI insights are translated into actionable business strategies. \n Communicate complex data findings clearly and promptly to senior leadership and non-technical stakeholders.   \n Coordinate with the Business Intelligence team, including data analysts, BI developers, and data engineers, to ensure alignment and collaboration.   \n \n \n What You'll Bring: \n \n Bachelor\u2019s degree in Computer Science, Data Science, Information Systems, Statistics, Mathematics, or a related field. Master\u2019s degree or Ph.D. in a related field is a plus   \n Minimum of 5 years of data science experience, focusing on Operational AI and business intelligence.     Proficiency in machine learning algorithms, deep learning frameworks, LLMs, and statistical modeling   \n Hands-on experience with AI/ML platforms such as TensorFlow, PyTorch, or Keras   \n Understanding of model training, validation, optimization, and edge-to-cloud deployment techniques   \n Strong programming skills in Python, R, or similar programming languages. Familiarity with SQL and database querying is essential   \n Strong understanding of data modeling, ETL processes, and data visualization   \n Ability to think critically, conceptualize complex problems, and develop AI/ML solutions that address business challenges   \n Experience in collaborating with cross-functional teams, including data engineers, IT, and business stakeholders   \n \n Salary & Benefits ", "techs": ["develop comprehensive documentation standards for data science projects", "oversee the development and scalable deployment of ai models and tools into bi processes", "continuously evaluate the latest ai technologies and bi tools", "lead the company's transition from relying primarily on descriptive analytics to leveraging advanced prescriptive analytics", "develop models to analyze complex business scenarios and provide actionable recommendations", "translate complex analytical findings into clear", "actionable insights for non-technical stakeholders", "work closely with cross-functional teams to ensure that ai and bi insights are translated into actionable business strategies", "communicate complex data findings clearly and promptly to senior leadership and non-technical stakeholders", "coordinate with the business intelligence team", "proficiency in machine learning algorithms", "deep learning frameworks", "llms", "and statistical modeling", "hands-on experience with ai/ml platforms such as tensorflow", "pytorch", "or keras", "understanding of model training", "validation", "optimization", "and edge-to-cloud deployment techniques", "strong programming skills in python", "r", "or similar programming languages", "familiarity with sql and database querying", "strong understanding of data modeling", "etl processes", "and data visualization", "ability to think critically and develop ai/ml solutions that address business challenges", "experience in collaborating with cross-functional teams."]}, "ac718a262fb45057": {"terms": ["data science"], "salary_min": 92824.05, "salary_max": 117535.92, "title": "Property Claims Adjuster - Virtual (Remote, US)", "company": "Openly", "desc": "Openly is rebuilding insurance from the ground up. We are re-envisioning and enhancing every aspect of the customer experience. Doing this requires a rapidly growing team of exceptional, curious, empathetic people with a wide range of skill sets, spanning technology, data science, product, marketing, sales, service, claims handling, finance, etc. \n  Now is the perfect time to join the journey. Here's why \n \n It's working . We're in multiple states and on our way to operating countrywide. We have thousands of agents selling our product and millions of dollars of annual customer premiums. \n We're well-backed & stable.  We closed our $100M Series D fundraise. We are supported by some of the top investors globally, including Google's \"Gradient\" AI-focused fund, Obvious Ventures, Advance Venture Partners, Eden Global Partners, and Clocktower Technology Ventures. \n It's not too late!  Despite this traction and stability, we're still early enough in the journey that there's time to make a real difference during Openly's formative period. \n \n If you'd like to understand more about Openly's mission, consider checking out this video (https://vimeo.com/267654520) from a company pitch we gave several years ago at Techstars. \n \n  Job Details \n  Openly is building an advanced claims organization leveraging technology and experienced property claims professionals to build a best-in-class end-to-end customer experience. This role is a remote-only position, and applicants must have an adequate working environment. The ideal candidate has experience in Homeowner's property claims handling, including estimate writing, is comfortable utilizing today's technology, hungry for change and innovation, and truly able to deliver an excellent customer experience. \n  Knowledge, Skills & Abilities: \n \n Knowledge of insurance contracts, investigation techniques, legal requirements, and insurance regulations \n Ability to work effectively in teams and with a wide variety of people \n An aptitude for evaluating, analyzing, and interpreting data and information \n Can create estimates and review losses up to $50,000 \n Has experience with remote/virtual property loss estimating and loves finding creative ways to quickly solve problems for customers \n Has knowledge and experience utilizing software and/or technology to scope claims virtually (video software, drones, etc.) \n Ability to adapt to changing environment while leveraging new technologies \n Experience handling water losses, including the water mitigation portion of the loss, is required \n Excellent written and verbal communication skills \n Organization and time management skills \n Innovative mindset and focus on continuous improvement \n Strong negotiation and problem-solving skills \n \n \n \n  Key Responsibilities \n  End to end property claims handling to include: \n \n Provide superior customer service \n Investigation and coverage analysis \n Complete estimates using CoreLogic estimating software \n Adhere to estimating best practices \n Manage and collaborate with vendor partners \n Determine the appropriate method of inspection \n Conduct virtual inspections (video, AI, etc.) \n Examine potential subrogation and identify potential fraudulent issues \n Prepare and maintain file documentation \n Negotiate settlement of claims with customers, claimants, and vendors. Discus and give updates to customers,, claimants, agents, and leadership throughout the process \n Provide input and ideas for continuous process improvement \n \n \n \n  Requirements \n \n 10+ years of property claims experience \n 5+ years handling water claims preferred \n 5+ year handling virtual weather-related claims \n 3+ years in customer service and conflict resolution \n Education equivalent to a college degree \n Must be able and eligible to acquire an adjuster license in all required states and maintain it as a condition of continued employment \n Estimating experience in Xactimate, CoreLogic (Symbility), or a similar platform \n Experience working independently and in a fast-paced environment \n Proficient in Microsoft and Google Products \n Must be tech-savvy as high-end technology tools will be used for adjusting (virtual inspections, estimating, etc.) \n We are a rapidly growing company; with growth comes change. Candidates must be comfortable with constant change, adaptability, and flexibility \n Knowledge of insurance contracts, investigation techniques, legal requirements, and insurance regulations \n Ability to work effectively in teams and with a wide variety of people \n Must have an aptitude for evaluating, analyzing, and interpreting information \n \n #LI-HK1 \n \n  Benefits & Perks \n \n Remote-First Culture - We supported #remotelife long before it was a given. We'll keep promoting it. \n Competitive Salary & Equity \n Comprehensive Medical, Dental, and Vision Plan Offerings \n Life and disability coverage including voluntary options \n Competitive PTO - 20 days and 11 paid holidays (including floating holidays) per year under the Company's vacation and holiday policies.  \n Parental Leave - 12 weeks paid for eligible employees \n 401K Company Contribution - Openly contributes 3% of the employee's gross income, even if the employee does not contribute. \n Work-from-home stipend - We provide a $1,500 allowance to spend on setting up your home workplace \n Annual Professional Development Fund: Each employee has $2,000 in professional development (PD) funds to spend on activities or resources annually. We want each Openly employee to achieve personal and professional success and to feel supported, confident, and informed about improving their efficiency and productivity. \n Be Well Program - Employees receive $50 per month to use towards your overall well-being \n Paid Volunteer Service Hours \n Referral Program and Reward \n \n Depending on position, Employees generally are eligible for cash incentive compensation, including commissions for sales eligible roles. In all cases, eligibility for compensation and benefits is subject to applicable plan and policy terms in effect from time to time. \n  U.S. Citizens, Green Card Holders, and those authorized to work in the U.S. for any employer and currently residing in the US will be considered. \n  Openly is committed to equal employment opportunity and non-discrimination for all employees and qualified applicants without regard to a person's race, color, sex, gender identity or expression, age, religion, national origin, ancestry, ethnicity, disability, veteran status, genetic information, sexual orientation, marital status, or any characteristic protected under applicable law. Openly is an E-Verify Employer in the United States. Openly will make reasonable accommodations for qualified individuals with known disabilities under applicable law.", "cleaned_desc": "", "techs": ""}, "1130707ea583e921": {"terms": ["data science", "data analyst"], "salary_min": 81688.16, "salary_max": 103435.41, "title": "Sr. Global Business Shared Services Data Analyst", "company": "Lamb Weston", "desc": "Title: Sr. Global Business Shared Services Data Analyst\n  \n  Location: Statewide Multi Use, WA\n  \n \n  About Lamb Weston\n  \n \n \n   Lamb Weston is a leading supplier of frozen potato, sweet potato, appetizer and vegetable products to restaurants and retailers around the world. For more than 60 years, we\u2019ve produced innovative, inventive products that make life better for our customers and their customers.\n  \n \n \n   Job Description Summary\n  \n \n  Seeking, experienced Data Analyst with strong technical and data management skills who has a good understanding of data structure and Finance Shared Services business processes. They should have a strong track record of executing well on daily tasks and have experience in cleaning, validating, and smart loading data primarily related to customer setup, order pricing, customer trade promotion and customer hierarchy business partners assignments for indirect and direct customers. Platforms include Salesforce, Evolve, S4 Hana Order/Pricing/Billing and Trade Promotion Management data.\n  \n  The primary mission for this role is to assist the Department in leveraging data to ensure the ability to effectively manage our business. This role will perform administrative management of data \u2014 including detection and correction of data-quality issues, process incoming data, taxonomy, and data standardization. This individual will collaborate with the Supply Chain, Invoice to Cash, Commercial Finance/Sales, Master data management, IT, and the business to engage in the ongoing and detailed evaluation of data quality and lead assignments .\n  \n \n   Job Description\n  \n \n   Job Description\n  \n \n  Accountable for executing and processing of data change requests \n  Responsible for maintenance, administration, and support of data elements from systems. \n  Ensures metadata, reference documentation, data files and data flows are accurate and up to date that may need to flow into a data lake with IT support. \n  Assist IT to create mappings between fields from various sources or systems. \n  Work with IT on loading data and resolving any break-fixes. \n  Liaison between teams to ensure data loaded is accurate for final reporting. \n  Support with data validation, quality issues, integrity, accuracy, consistency and works to resolve issues related to data elements including de-duplication and cleaning when applicable. \n  Ensuring sufficient data quality is maintained so that the data can effectively support the business processes and reporting accuracy. \n  Identifying, investigating, and managing the resolution and escalation of data quality issues \n  Perform ongoing data quality audits \n  Creation and generation of reports on various metrics both quantitative and qualitative in Excel, Domo, Power BI, and other systems/tools \n  Perform special projects as needed \n  Weekly connect with master data management as a data steward with support of the work. \n  Analyze data and data quality and identify line of business system effectiveness with areas of improvement. Perform root cause analysis to understand key trends / issues. \n  Maintain knowledge and experience of SAP S4/HANA. \n  Create, review, and maintain quality process documentation (Business process documents, process flows, policies and procedures, strategies, etc.) \n  Be the subject matter expert on your area and provide support to all teams. \n  Create, review, and maintain quality process documentation (Business process documents, process flows, policies and procedures, strategies, etc.) \n  Other duties as assigned. \n \n \n \n   Basic & Preferred Qualifications\n  \n \n   Job Qualifications\n  \n \n  Bachelors\u2019 degree in Business Management or Business Information Systems preferred \n  3 years related experience required \n  Keen interest in building new and repeatable data capabilities for a large organization \n  Demonstrated ability to be the data subject matter expert \n \n \n  Knowledge in cloud and data management \n \n \n  Exposure to SOX data standards and management best practices \n  Advanced knowledge of Excel; proficient in formulas, Data Model, VLOOKUP\u2019s, pivot tables, macros \n  Strong Data Quality, Data Governance and Data Management experience required; Database/Microsoft SQL skills is a plus \n  Experience with integration technologies i.e., ETL, data migration and packaged applications \n  Experience using industry-leading BI tools for reporting and visualization (e.g., DOMO, Tableau, Power BI, etc.). \n  Strong aptitude for learning quickly and applying sound logic when analyzing problems or defining solutions. \n  Must be comfortable in agile environment with rapidly changing and sometimes ambiguous work situation. \n  Ability to manage and prioritize multiple workloads and deliverables efficiently \n  Ability to interface with and influence personnel across the Lamb Weston Enterprise \n  Ability to read, write and speak in English required. Bilingual/Multilingual skills desirable. \n  Excellent verbal and written communication skills with the ability to: describe, educate, and persuade as well as elicit and document business requirements. \n  The ability to travel independently, valid U.S. drivers\u2019 license, and ability to meet Company driving standards. \n  Travel up to 10% of the time. \n \n \n \n   Industry-Competitive Benefits\n  \n \n \n   Coupled with our compensation and bonus incentive programs, our benefits deliver rewards that are market competitive. Some of the most attractive elements of our benefit programs include:\n  \n \n \n \n     Health Insurance Benefits - Medical, Dental, Vision\n    \n \n \n     Flexible Spending Accounts for Health and Dependent Care, and Health Reimbursement Accounts\n    \n \n \n     Well-being programs including companywide events and a wellness incentive program\n    \n \n \n     Paid Time Off\n    \n \n \n     Financial Wellness \u2013 Industry leading 401(k) plan with generous company contributions, Financial Planning Services, Employee Stock purchase program, and Health Savings Accounts, Life and Accident insurance\n    \n \n \n     Family-Friendly Employee events\n    \n \n \n     Employee Assistance Program services \u2013 mental health and other concierge type services\n    \n \n \n \n   Benefits may vary based on location, job role/level, job status, and/or the terms of any applicable collective bargaining agreements.\n  \n \n  Job Requisition ID: Req-233444\n  \n  Time Type: Full time\n  \n  In compliance with applicable state and local laws, Lamb Weston has opted to include a reasonable estimate of the compensation for this role. This compensation is specific to this position and takes into account a number of variables. Actual compensation may be higher or lower in the range posted based on various factors, including, but not limited to, job duties, experience and expertise. A candidate\u2019s work location could also impact the actual compensation being outside of the range to reflect local cost of labor. A reasonable annual estimate of the range for this role based on the variables previously mentioned is: $79,240.00 - $118,860.00\n  \n \n  Lamb Weston is an Equal Opportunity Employer and considers qualified applicants for employment without regard to race, color, creed, religion, national origin, sex, sexual orientation, gender identity and expression, age, disability, veteran status or any other protected factor under federal, state or local law", "cleaned_desc": "  \n \n  Accountable for executing and processing of data change requests \n  Responsible for maintenance, administration, and support of data elements from systems. \n  Ensures metadata, reference documentation, data files and data flows are accurate and up to date that may need to flow into a data lake with IT support. \n  Assist IT to create mappings between fields from various sources or systems. \n  Work with IT on loading data and resolving any break-fixes. \n  Liaison between teams to ensure data loaded is accurate for final reporting. \n  Support with data validation, quality issues, integrity, accuracy, consistency and works to resolve issues related to data elements including de-duplication and cleaning when applicable. \n  Ensuring sufficient data quality is maintained so that the data can effectively support the business processes and reporting accuracy. \n  Identifying, investigating, and managing the resolution and escalation of data quality issues \n  Perform ongoing data quality audits \n  Creation and generation of reports on various metrics both quantitative and qualitative in Excel, Domo, Power BI, and other systems/tools \n  Perform special projects as needed \n  Weekly connect with master data management as a data steward with support of the work. \n  Analyze data and data quality and identify line of business system effectiveness with areas of improvement. Perform root cause analysis to understand key trends / issues. \n  Maintain knowledge and experience of SAP S4/HANA. \n  Create, review, and maintain quality process documentation (Business process documents, process flows, policies and procedures, strategies, etc.) \n  Be the subject matter expert on your area and provide support to all teams. \n  Create, review, and maintain quality process documentation (Business process documents, process flows, policies and procedures, strategies, etc.) \n  Other duties as assigned. \n \n \n \n   Basic & Preferred Qualifications   \n \n   Job Qualifications\n  \n \n  Bachelors\u2019 degree in Business Management or Business Information Systems preferred \n  3 years related experience required \n  Keen interest in building new and repeatable data capabilities for a large organization \n  Demonstrated ability to be the data subject matter expert \n \n \n  Knowledge in cloud and data management \n \n \n  Exposure to SOX data standards and management best practices \n  Advanced knowledge of Excel; proficient in formulas, Data Model, VLOOKUP\u2019s, pivot tables, macros \n  Strong Data Quality, Data Governance and Data Management experience required; Database/Microsoft SQL skills is a plus \n  Experience with integration technologies i.e., ETL, data migration and packaged applications \n  Experience using industry-leading BI tools for reporting and visualization (e.g., DOMO, Tableau, Power BI, etc.). \n  Strong aptitude for learning quickly and applying sound logic when analyzing problems or defining solutions. \n  Must be comfortable in agile environment with rapidly changing and sometimes ambiguous work situation. \n  Ability to manage and prioritize multiple workloads and deliverables efficiently \n  Ability to interface with and influence personnel across the Lamb Weston Enterprise \n  Ability to read, write and speak in English required. Bilingual/Multilingual skills desirable. \n  Excellent verbal and written communication skills with the ability to: describe, educate, and persuade as well as elicit and document business requirements. ", "techs": ["excel", "domo", "power bi", "sap s4/hana", "microsoft sql", "etl", "tableau"]}, "6ab29e7efb9bcf3e": {"terms": ["data science"], "salary_min": 100000.0, "salary_max": 135000.0, "title": "Principal Analytics Analyst: Procurement & Financial Shared Service", "company": "Vail Resorts", "desc": "As a leading mountain resort operator with over 40 resorts in sixteen states and four countries. We exist to create an  Experience of a Lifetime  for our employees, so they can, in turn, provide and  Experience of a Lifetime  for our guests. We are looking for leaders, innovators, creators, and ambitious professionals to join our talented team. If you\u2019re ready to pursue your fullest potential, we want to get to know you! \n  Many of our Corporate function teams can now live and work in any of the states in which Vail Resorts currently operates* \u2013 enabling flexible remote work alongside a commitment to building and maintaining strong culture both in person and virtually. If you\u2019re ready to pursue your fullest potential, we want to get to know you. Find your purpose with us at www.vailresortscareers.com. \n \n  Job Summary: \n  The Vail Resorts Procurement & Financial Shared Services Team is committed to Building Leaders and Driving Value. We are creating a world class procurement and financial shared services organization in our corporate headquarters to support a growing company of 41 resorts, 55,000+ employees and a market capitalization of over $9.5 billion. We are transforming our organization to bring best-in-class S2C, P2P, OTC, R2R, Payroll, and analytical tools to enable data-driven decision making at Vail Resorts \u2013 the ski industry\u2019s global leader. \n  Our team will be driven by top-tier talent, state-of-the-art systems and tools, and strategic process management to identify and deliver against the Company\u2019s biggest value opportunities. We are creating a sustainable high-performing team that will develop talent and prioritize career growth through accelerated opportunities and progression. This is an opportunity to join the Procurement and Financial Shared Services team at a critical inflection point and shape how we create value into the future. \n \n  The Principal Analytics Analyst of Financial Shared Services and Procurement is responsible for driving value and leading innovation that will use deep analytical capabilities to strategically inform decision making for the highest priority spend management and revenue preservation opportunities and risks impacting the enterprise. S/he will be responsible for performing in-depth spend and cost impact analysis, including benchmarking and trending to inform enterprise insights, target-setting, budgeting and forecasting processes. The role will have significant senior leadership exposure, particularly with the Operations SLT and FP&A team of Vail Resorts. \n \n  The Principal Analytics Analyst of Financial Shared Services and Procurement will have the opportunity to analyze the key issues arising across our enterprise wide spend, payroll and revenue preservation and have a significant impact on decision making that impacts the bottom line. S/he will use financial acumen, strategic synthesis and data-driven insights to advise senior leaders and will gain great perspective on key business and operations drivers, while working on our most interesting and challenging business questions. \n \n  Job Specifications: \n \n  Expected Pay Range: $100,000 - $135,000 + Annual Bonus \n  Shift & Schedule Availability: Full Time, Year Round \n \n \n  Job Responsibilities: \n \n \n \n  Possesses strong business acumen to partner with business leaders to build and deploy best in class financial service analytics including: order to cash reporting, payroll analysis, third party spend, category analytics, supplier performance management, market and cost intelligence \n  Leads efforts to frame spend and revenue preservation issues and questions with data-driven approaches to problem solving, including selecting the right metrics, interpreting the data and the ability to communicate complex quantitative analysis in a clear, precise, and actionable manner. \n  Serves as a thought partner with the Financial Shared Services and Procurement Leadership Team to identify business challenges. Use fact based analysis to help influence changes to operations, process or policies. \n  Maintains and ensures quality assurance of key data sets, reports and metrics that are relevant and insightful and highlight key trends in market dynamics, collaborating with subject matter experts across FP&A and IT to promote data governance. \n  Drive partnerships with Finance IT team and vendors to deliver necessary data management tools, capabilities and system solutions. \n  Leads Financial Shared Services specific program evaluation and program outcomes analyses. \n  Actively participates in external professional organizations and builds a powerful network to understand and shape the emerging analytical trends. \n \n \n  Job Requirements: \n \n \n \n  Bachelor\u2019s degree in Finance, Supply Chain, STEM \n  MBA or MS in Data Science is strongly preferred \n  6+ years\u2019 experience in analytics, with demonstrated success in managing analytical talent, cost modeling, and analysis. \n  Outstanding analytical skills with ability to synthesize information, develop insights and communicate effectively in presentations and in-person meetings. \n  Deep curiosity and passion for understanding and analyzing financial results in the context of creating shareholder value. \n  Excellent communication skills with ability to develop the \u201cstory\u201d and form recommendations. \n  Ability to operate in a fast-paced environment with strong initiative and ability to multi-task. \n  Superb attention to detail balanced by ability to focus on the \"big picture.\" \n  Effectively manage and build capabilities and culture for high performing professional team. \n  Preferred skills:\n    \n  High intellect and ambition. \n  Unquestioned ethics and integrity. \n  Excellent listener, open to feedback, and communicates with candor and respect. \n  Outstanding organizational, analytical and project management skills. \n  Connects well with others and highly collaborative team approach to work. \n  Excellent individual initiative and objective-oriented drive. \n  Ability to handle difficult situations with a high-degree of diplomacy and composure \n  Expert in Excel, PowerPoint and experience with Coupa, PeopleSoft, Power BI and Tableau is a plus \n \n \n \n  The expected Total Compensation for this role is $100,000 - $135,000 + Annual Bonus. Individual compensation decisions are based on a variety of factors. \n  The perks include a free ski pass, and a set of benefits including... \n \n  Medical, Dental, Vision insurance, and a 401(k) retirement plan \n  Hourly employees are generally eligible for accrued Paid Time Off (PTO) and Sick Time. Salaried employees are generally eligible for Flexible Time Off (FTO) \n  Paid Parental Leave for eligible mothers and fathers \n  Healthcare & Dependent Care Flexible Spending Accounts \n  Life, AD&D, and disability insurance \n \n \n  Reach Your Peak at Vail Resorts.  At Vail Resorts, our team is made whole by the brave, passionate individuals who ambitiously push boundaries and challenge the status quo. Whether you\u2019re looking for seasonal work or the career of a lifetime, join us today to reach your peak. \n \n   Remote work is currently permitted from British Columbia and the 16 U.S. states in which we currently operate. This includes: California, Colorado, Indiana, Michigan, Minnesota, Missouri, New Hampshire, New York, Nevada, Ohio, Pennsylvania, Utah, Vermont, Washington State, Wisconsin, and Wyoming. Please note that the ability to work remotely, and the particulars related to such work, are subject to change at any time; and, accordingly, the Company reserves the right to change its policies and/or require in-person/in-office work at any time in its sole discretion. \n \n \n  Vail Resorts is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability, protected veteran status or any other status protected by applicable law. \n \n  Requisition ID 498598   Reference Date: 10/17/2023   Job Code Function:", "cleaned_desc": " \n \n  Job Requirements: \n \n \n \n  Bachelor\u2019s degree in Finance, Supply Chain, STEM \n  MBA or MS in Data Science is strongly preferred \n  6+ years\u2019 experience in analytics, with demonstrated success in managing analytical talent, cost modeling, and analysis. \n  Outstanding analytical skills with ability to synthesize information, develop insights and communicate effectively in presentations and in-person meetings. \n  Deep curiosity and passion for understanding and analyzing financial results in the context of creating shareholder value. \n  Excellent communication skills with ability to develop the \u201cstory\u201d and form recommendations. \n  Ability to operate in a fast-paced environment with strong initiative and ability to multi-task. \n  Superb attention to detail balanced by ability to focus on the \"big picture.\"    Effectively manage and build capabilities and culture for high performing professional team. \n  Preferred skills:\n    \n  High intellect and ambition. \n  Unquestioned ethics and integrity. \n  Excellent listener, open to feedback, and communicates with candor and respect. \n  Outstanding organizational, analytical and project management skills. \n  Connects well with others and highly collaborative team approach to work. \n  Excellent individual initiative and objective-oriented drive. \n  Ability to handle difficult situations with a high-degree of diplomacy and composure \n  Expert in Excel, PowerPoint and experience with Coupa, PeopleSoft, Power BI and Tableau is a plus \n \n \n ", "techs": ["coupa", "peoplesoft", "power bi", "tableau"]}, "b57797c358859277": {"terms": ["data science"], "salary_min": 64.0, "salary_max": 65.0, "title": "Enterprise Data manger", "company": "Logix Group", "desc": "The Enterprise Data Manager (EDM) leads the client\u2019s core data governance team who understands core governance principles, concepts of data lineage, and the data interdependencies across programs and systems to drive standards and consistency. The EDM will establish governance rules, controls, and processes to provide public health decision makers with accessible, timely, reliable, and meaningful data to drive policies and interventions. The EDM will work with program leaders and other stakeholders on discovery and business requirement sessions and understand the data flows across the department. The EDM will be involved with understanding the capabilities of analytics and business intelligence using the data lakes available within the Enterprise Data Warehouse (EDW). Additionally, the EDM will monitor the usage of data on an on-going basis to provide for suggestions for continuous process improvement and improvements to our governance rules and standards. \n \n Knowledge and experience of data governance processes and frameworks. \n \n \n Strong communication and interpersonal skills to be able to interact with all levels of the Department. \n \n \n Ability to accurately capture business requirements and effectively convey business needs to IT counterparts, while ensuring that IT projects are in sync with business goals and that their end results satisfactorily meet business needs. \n \n \n Interface with cross-functional teams and management to establish, implement, and ensure adherence to data policies and processes. \n \n \n Strong analytical and computation skills and understanding of the integration of different data points across systems to present an enterprise view. \n \n \n Ability to communicate and present results with a variety of internal and external stakeholders. \n \n \n Experience with identifying relevant data gaps for evaluation and evidence needs and developing roadmaps for addressing data gaps. \n \n \n Ability to draft current and future workflows of data flows for presentations with various stakeholders. \n \n \n Based on data collection needs, works with various stakeholders to obtain input and feedback on final engagement outputs. \n \n \n Experienced in creating and maintaining data catalogues. \n \n \n Understating of relational databases and experience with transformations and data mappings. \n \n \n Strong data modelling knowledge and ability to interpret complete data from multiple data sources and develop findings and recommendations. \n \n \n Experienced in consolidating internal and external data to explore patterns and improve outcomes. \n \n \n Experience fulfilling an Agile Product Owner role in an IT or data related project. \n \n \n Experience with establishing interoperability with healthcare IT systems (such as Electronic Medical Record systems) preferred. \n \n \n Knowledge of EDW and Data Maturity Model preferred. \n \n \n Experience with Tableau or Power BI preferred. \n \n \n This position requires a high degree of skill, leadership, ability to take initiative, and dedication. Bachelor\u2019s or graduate degree in Health Informatics, Public Health, Data Science, Epidemiology, Biostatistics, Public Policy, Health Policy, Health Services Research, Health Information Sciences, Computer Science, or a closely related field. \n 3-5 years of relevant experience in leading data governance efforts and managing data sharing related projects, including experience functioning in the role of an  Agile Product Owner. \n Experience setting up an enterprise-wide data governance structure, knowledge of data lakes and data maturity models preferred. Familiarity and experience with programs relative to health and human services is considered helpful. \n \n Job Types: Contract, Full-time \n Salary: $64.00 - $65.00 per hour \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n leading data governance: 4 years (Preferred) \n Agile Product Owner: 4 years (Preferred) \n data maturity models: 4 years (Preferred) \n Enterprise Data Manager: 4 years (Preferred) \n \n Work Location: Remote", "cleaned_desc": "The Enterprise Data Manager (EDM) leads the client\u2019s core data governance team who understands core governance principles, concepts of data lineage, and the data interdependencies across programs and systems to drive standards and consistency. The EDM will establish governance rules, controls, and processes to provide public health decision makers with accessible, timely, reliable, and meaningful data to drive policies and interventions. The EDM will work with program leaders and other stakeholders on discovery and business requirement sessions and understand the data flows across the department. The EDM will be involved with understanding the capabilities of analytics and business intelligence using the data lakes available within the Enterprise Data Warehouse (EDW). Additionally, the EDM will monitor the usage of data on an on-going basis to provide for suggestions for continuous process improvement and improvements to our governance rules and standards. \n \n Knowledge and experience of data governance processes and frameworks. \n \n \n Strong communication and interpersonal skills to be able to interact with all levels of the Department. \n \n \n Ability to accurately capture business requirements and effectively convey business needs to IT counterparts, while ensuring that IT projects are in sync with business goals and that their end results satisfactorily meet business needs. \n \n \n Interface with cross-functional teams and management to establish, implement, and ensure adherence to data policies and processes. \n \n   Strong analytical and computation skills and understanding of the integration of different data points across systems to present an enterprise view. \n \n \n Ability to communicate and present results with a variety of internal and external stakeholders. \n \n \n Experience with identifying relevant data gaps for evaluation and evidence needs and developing roadmaps for addressing data gaps. \n \n \n Ability to draft current and future workflows of data flows for presentations with various stakeholders. \n \n \n Based on data collection needs, works with various stakeholders to obtain input and feedback on final engagement outputs. \n   \n Experienced in creating and maintaining data catalogues. \n \n \n Understating of relational databases and experience with transformations and data mappings. \n \n \n Strong data modelling knowledge and ability to interpret complete data from multiple data sources and develop findings and recommendations. \n \n \n Experienced in consolidating internal and external data to explore patterns and improve outcomes. \n \n \n Experience fulfilling an Agile Product Owner role in an IT or data related project.   \n \n Experience with establishing interoperability with healthcare IT systems (such as Electronic Medical Record systems) preferred. \n \n \n Knowledge of EDW and Data Maturity Model preferred. \n \n \n Experience with Tableau or Power BI preferred. \n \n \n This position requires a high degree of skill, leadership, ability to take initiative, and dedication. Bachelor\u2019s or graduate degree in Health Informatics, Public Health, Data Science, Epidemiology, Biostatistics, Public Policy, Health Policy, Health Services Research, Health Information Sciences, Computer Science, or a closely related field. \n 3-5 years of relevant experience in leading data governance efforts and managing data sharing related projects, including experience functioning in the role of an  Agile Product Owner. \n Experience setting up an enterprise-wide data governance structure, knowledge of data lakes and data maturity models preferred. Familiarity and experience with programs relative to health and human services is considered helpful. ", "techs": ["enterprise data manager", "edm", "data governance", "data lineage", "data interdependencies", "standards", "consistency", "governance rules", "controls", "processes", "public health", "accessible data", "timely data", "reliable data", "meaningful data", "policies", "interventions", "program leaders", "stakeholders", "discovery", "business requirements", "data flows", "department", "analytics", "business intelligence", "data lakes", "enterprise data warehouse", "monitor data usage", "process improvement", "improvement suggestions", "communication skills", "interpersonal skills", "it counterparts", "cross-functional teams", "data policies", "data processes", "analytical skills", "computation skills", "data integration", "enterprise view", "presenting results", "data gaps", "roadmaps", "data workflows", "stakeholder engagement", "data catalogues", "relational databases", "data transformations", "data mappings", "data modelling", "data interpretation", "data sources", "findings", "recommendations", "data consolidation", "agile product owner", "interoperability", "healthcare it systems", "electronic medical record systems", "edw", "data maturity model", "tableau", "power bi", "skill", "leadership", "initiative", "dedication", "health informatics", "public health", "data science", "epidemiology", "biostatistics", "public policy", "health policy", "health services research", "health information sciences", "computer science", "bachelor\u2019s degree", "graduate degree", "data governance efforts", "data sharing projects", "agile product owner role", "enterprise-wide data governance structure", "data lakes", "data maturity models", "health and human services programs."]}, "c3c50c851c80a2f1": {"terms": ["data science"], "salary_min": 115000.0, "salary_max": 160000.0, "title": "Assistant Vice President, Risk Analytics", "company": "Wedbush Securities", "desc": "Job Description: \n  Wedbush Securities is one of the largest securities firms and investment banks in the nation. We provide innovative financial solutions through our Wealth Management, Capital Markets, Futures and Advanced Clearing & Prime Services divisions. Headquartered in Los Angeles, California with over 100 offices and more than 80 correspondent offices, our commitment to providing relentless, customized service is the foundation of our consistent growth.  \n  Our Jersey City office is hiring for an experienced Assistant Vice President, Risk Analytics to join our Risk and Credit Group for a 100% remote opportunity. The primary function of this role is to act as a Data Scientist for the Risk Management Department, and a Project Manager/Liaison for all related Risk systems and IT functions. You will need to design SQL queries and relational databases to carry out daily tasks and automate reports for the risk management department.  \n  Responsibilities will include, but are not limited to:  \n \n  Build, monitor, distribute risk reports and margin calculations \n  Design SQL query and relational databases to carry out daily tasks and automate reports \n  Create and Manage risk dashboards \n  Perform complex data analysis on account balances and positions across the firm \n  Manage ad hoc projects as requested by leadership \n  Be the system administrator and point of contact for various risk systems and tools \n  Present and explain analysis in a non-technical and accessible manner alongside data visualization \n  Perform other tasks and duties as required and assigned \n \n \n  Experience and Skills: \n \n  Bachelor\u2019s Degree from an accredited University, preferably in Computer Science, Data Science, or related field \n  Advanced proficiency in SQL and understanding of data access tools \n  5+ years\u2019 experience in Information Technology, preferably for a financial services firm \n  5+ years\u2019 experience in Data Analytics, Risk Analysis, or related role \n  Understanding of Equities, Options, and Margin is a plus \n  Must be detail oriented and maintain data integrity \n  Creative, solution-oriented mindset with the ability to handle pressure to meet deadlines \n  Able to work with minimal supervision, taking ownership of work and completing tasks in timely manner, while adapting rapidly to changing work environments, priorities and organizational needs \n  Ability to identify gaps in existing processes and gain efficiency through automation. \n  Experience working with multiple teams across different time zones \n \n \n  Job Benefits: \n  Wedbush Securities offers robust benefits to our colleagues.  \n \n Comprehensive medical, dental, and vision coverage with multiple health plan options for you and your family \n  Health Savings Account with company-sponsored contributions \n  Flexible Spending Accounts (FSA) traditional and dependent care \n  Pre-Tax Commuter Benefits \n  401(k) plan with discretionary, competitive company matching and profit-sharing contributions \n  Tuition reimbursement up to $5,250/year \n  3 weeks of Paid Time Off \n  2 weeks of Paid Sick Time (may vary by location) \n  10 Paid Holidays \n  Charitable Donation Matching Contributions \n  Paid Leave (Military, Jury Duty, Volunteer Time Off, Disability, etc.) \n  FINRA License Sponsorship \n  Travel & Employee Assistance and Employee Discount Programs \n \n  The reasonable estimate of the compensation range for this role has not been adjusted for the applicable geographic location. A reasonable estimate of the current hiring range is $115,000-$160,000.Colleagues may be eligible for additional, discretionary incentive compensation based on the individual and the firm's performance. At Wedbush, it is not typical for an individual to be hired at, or near, the top of the range for their role. Decisions regarding compensation are determined on a case-by-case basis and are dependent on a variety of factors including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs.  \n Wedbush Securities (WS) is proud to be an Equal Employment Opportunity employer. WS does not discriminate based on race, religion, color, creed, sex, sexual orientation, gender, gender identity or expression, national origin, ancestry, citizenship status, registered domestic partner status, uniform service member status, marital status, pregnancy, age, medical condition, disability, genetic information, family care or medical leave status, or any other consideration made unlawful by applicable federal, state, or local laws, or on the basis that an applicant or Colleague is perceived to have these characteristics or is associated with someone who is perceived to have these characteristics. WS aims to foster a culture of inclusion where all Colleagues are valued for their unique contributions to the firm as well as provided equal opportunities to succeed.  \n Wedbush uses E-Verify, an Internet-based system, to confirm the eligibility of all newly hired employees to work in the United States. Learn more about E-Verify, including your rights and responsibilities here https://www.e-verify.gov/employees/e-verify-overview    From: Wedbush Securities", "cleaned_desc": "  Advanced proficiency in SQL and understanding of data access tools \n  5+ years\u2019 experience in Information Technology, preferably for a financial services firm \n  5+ years\u2019 experience in Data Analytics, Risk Analysis, or related role \n  Understanding of Equities, Options, and Margin is a plus \n  Must be detail oriented and maintain data integrity \n  Creative, solution-oriented mindset with the ability to handle pressure to meet deadlines \n  Able to work with minimal supervision, taking ownership of work and completing tasks in timely manner, while adapting rapidly to changing work environments, priorities and organizational needs \n  Ability to identify gaps in existing processes and gain efficiency through automation. \n  Experience working with multiple teams across different time zones ", "techs": ["sql", "data access tools", "equities", "options", "margin", "automation"]}, "a6ae123115c5fb43": {"terms": ["data science", "machine learning engineer"], "salary_min": 100829.17, "salary_max": 127672.2, "title": "AI Engineer Board Member (Volunteer)", "company": "Center for Societal Aspiration", "desc": "Company Description \n The Center for Societal Aspiration (CSACO) is a 501(c)(3) nonprofit organization based in Dallas, Texas. Founded in 2023, we are a startup organization dedicated to cultivating prosperous individuals and societies. Currently, we are focusing on serving people experiencing addiction, homelessness, and poverty through our system that integrates comprehensive health, structural community development, and artificial intelligence to develop and maintain the essential elements of your health. \n Our mission is \"to provide comprehensive health-based care to foster growth in the essential elements of the livelihood of individuals and their societies while nourishing a healthy, conscientious, and equitable relationship between a society and all of its people.\" \n Role Description \n This is a  volunteer  Artificial Intelliegence Engineer Board Member role at the Center for Societal Aspiration. The role involves attending regular board meetings, contributing to board discussions and decision-making, and providing guidance and feedback to support the organization's mission and vision. We will hold board meetings every two months. We would prefer to have the board meetings in person, however, virtual attendance is accepted. \n Qualifications \n \n Commitment to the Mission, Vision, and Philosophy of Care : Board members should have a deep passion for the organization's mission and a clear understanding of its goals and objectives. They should be committed to advancing the organization's cause. \n Ethical and Legal Integrity : Board members must adhere to high ethical standards and be knowledgeable about the legal responsibilities and obligations of nonprofit board service. \n Technology Expertise : A bachelor's or advanced degree in computer science, artificial intelligence, machine learning, data science, or a related field is typically required. Strong programming skills in languages commonly used in AI, such as Python, Java, or C++. Proficiency in AI and machine learning technologies, frameworks, and libraries (e.g., TensorFlow, PyTorch, scikit-learn). Experience with neural network architectures, including convolutional neural networks (CNNs), recurrent neural networks (RNNs), and transformer models. \n Networking : Building and bring relationships and connections in key areas to the nonprofit organization. Board members with strong networks can help open doors to potential donors, partners, and supporters. \n Time Commitment : Serving on a nonprofit board can be time-consuming. Board members should have the availability and willingness to attend meetings, participate in committee work, and fulfill their duties effectively. \n Passion for Learning : The nonprofit landscape is ever-evolving. Board members who are committed to ongoing learning and staying informed about best practices can bring valuable insights to the organization. \n Compliance with Policies : Board members should be willing to follow the organization's bylaws, policies, and procedures. \n \n Job Type: Contract \n Schedule: \n \n Choose your own hours \n \n Work Location: Remote", "cleaned_desc": " Ethical and Legal Integrity : Board members must adhere to high ethical standards and be knowledgeable about the legal responsibilities and obligations of nonprofit board service. \n Technology Expertise : A bachelor's or advanced degree in computer science, artificial intelligence, machine learning, data science, or a related field is typically required. Strong programming skills in languages commonly used in AI, such as Python, Java, or C++. Proficiency in AI and machine learning technologies, frameworks, and libraries (e.g., TensorFlow, PyTorch, scikit-learn). Experience with neural network architectures, including convolutional neural networks (CNNs), recurrent neural networks (RNNs), and transformer models. \n Networking : Building and bring relationships and connections in key areas to the nonprofit organization. Board members with strong networks can help open doors to potential donors, partners, and supporters. \n Time Commitment : Serving on a nonprofit board can be time-consuming. Board members should have the availability and willingness to attend meetings, participate in committee work, and fulfill their duties effectively. ", "techs": ["ethics", "legal responsibilities", "nonprofit board service", "computer science", "artificial intelligence", "machine learning", "data science", "programming skills", "python", "java", "c++", "ai", "machine learning technologies", "tensorflow", "pytorch", "scikit-learn", "neural network architectures", "convolutional neural networks", "recurrent neural networks", "transformer models", "networking", "building relationships", "connections", "nonprofit organization", "donors", "partners", "supporters", "time commitment", "nonprofit board", "meetings", "committee work", "duties"]}, "04fc55df7caebb04": {"terms": ["data science", "machine learning engineer"], "salary_min": 51.0, "salary_max": 55.0, "title": "Machine Learning Engineer", "company": "Tech Matrix Software Solutions Pvt. Ltd", "desc": "Role: Senior Machine Learning Engineer/AI Engineer \n Location: Remote \n Job Description \n \n position: \u2002this\u2002for\u2002responsibilities\u20025-10\u2002Top \n platforms\u2002AIML\u2002developing\u2002Experience&cloud. \u2002native\u2002and\u2002Kubernetes\u2002on\u2002preferably\u2002programming),\u2002distributed/parallel\u2002inferencing,\u2002training,\u2002model\u2002as\u2002such\u2002offerings\u2002core\u2002(including\u2002frameworks \n languages \u2002programming\u2002JAVA\u2002or\u2002Python\u2002with\u2002skilled\u2002Highly \n SQL\u2002like\u2002languages\u2002database\u2002with\u2002skilled\u2002Highly&NoSQL \n languages. \u2002other\u2002and\u2002Python\u2002using\u2002applications\u2002distributed\u2002testable\u2002and\u2002extensible,\u2002maintainable,\u2002highly\u2002deploying\u2002and\u2002developing,\u2002designing,\u2002Experience \n Django \u2002or\u2002Flask\u2002using\u2002Python\u2002in\u2002APIs\u2002REST\u2002and\u2002pipelines\u2002ETL\u2002developing\u2002Experience \n CI/CD\u2002and\u2002tools,\u2002orchestration\u2002Workflow\u2002Notebooks,\u2002Charts,\u2002Helm\u2002Kubernetes,\u2002including\u2002technologies/frameworks\u2002with\u2002Experienced&frameworks. \u2002monitoring \n Skills: \u2002/\u2002Qualifications\u2002Preferred \n TensorFlow \u2002Pytorch,\u2002Spark,\u2002Argo,\u2002Jupyter,\u2002using\u2002datasets\u2002large\u2002in\u2002projects\u2002open-source\u2002AI/ML\u2002with\u2002Experience \n UnitTest \u2002PyTest,\u2002using\u2002cases\u2002test\u2002Functional\u2002and\u2002Unit\u2002creating\u2002Experience \n Learning \u2002Machine\u2002in\u2002models\u2002tuning\u2002and\u2002training\u2002with\u2002Experience \n Hub \u2002Jupyter\u2002with\u2002working\u2002Experience \n PostgreSQL \u2002like\u2002system\u2002management\u2002DB\u2002with\u2002Experience \n Splunk/Kibana \u2002using\u2002logs\u2002analyzing\u2002and\u2002monitoring,\u2002searching,\u2002in\u2002Experience \n knowledge \u2002implementation\u2002GraphQL/Swagger \n Service \u2002Kubernetes\u2002Azure\u2002in\u2002applications\u2002of\u2002scalability\u2002and\u2002availability\u2002for\u2002Kubernetes\u2002with\u2002experience\u2002and\u2002understanding\u2002Strong \n Gitlab \u2002and\u2002Charts\u2002Helm\u2002Kubernetes,\u2002Artifactory,\u2002Docker,\u2002Jenkins,\u2002Cloudbees\u2002using\u2002pipelines\u2002CI/CD\u2002building\u2002Experience \n Kafka \u2002Spark,\u2002Apache\u2002Scikit,\u2002TensorFlow,\u2002MLFlow,\u2002Kubeflow,\u2002Hub,\u2002Jupyter\u2002like\u2002tools\u2002with\u2002Experience \n workflows \u2002Argo\u2002Airflow,\u2002Apache\u2002as\u2002such\u2002tools\u2002orchestration\u2002workflow\u2002with\u2002Experience \n builds \u2002package\u2002Node.js\u2002and\u2002PyPi,\u2002Conda,\u2002with\u2002Familiarity \n \n Job Type: Contract \n Salary: $51.00 - $55.00 per hour \n Experience level: \n \n 8 years \n \n Schedule: \n \n 8 hour shift \n \n Application Question(s): \n \n Are you comfortable to work on W2 contract, we need only W2 candidates? \n \n Experience: \n \n Machine learning: 8 years (Preferred) \n Data science: 8 years (Preferred) \n TensorFlow: 5 years (Preferred) \n PyTorch: 5 years (Preferred) \n Python: 2 years (Preferred) \n \n Work Location: Remote", "cleaned_desc": "Role: Senior Machine Learning Engineer/AI Engineer \n Location: Remote \n Job Description \n \n position: \u2002this\u2002for\u2002responsibilities\u20025-10\u2002Top \n platforms\u2002AIML\u2002developing\u2002Experience&cloud. \u2002native\u2002and\u2002Kubernetes\u2002on\u2002preferably\u2002programming),\u2002distributed/parallel\u2002inferencing,\u2002training,\u2002model\u2002as\u2002such\u2002offerings\u2002core\u2002(including\u2002frameworks \n languages \u2002programming\u2002JAVA\u2002or\u2002Python\u2002with\u2002skilled\u2002Highly \n SQL\u2002like\u2002languages\u2002database\u2002with\u2002skilled\u2002Highly&NoSQL \n languages. \u2002other\u2002and\u2002Python\u2002using\u2002applications\u2002distributed\u2002testable\u2002and\u2002extensible,\u2002maintainable,\u2002highly\u2002deploying\u2002and\u2002developing,\u2002designing,\u2002Experience   Django \u2002or\u2002Flask\u2002using\u2002Python\u2002in\u2002APIs\u2002REST\u2002and\u2002pipelines\u2002ETL\u2002developing\u2002Experience \n CI/CD\u2002and\u2002tools,\u2002orchestration\u2002Workflow\u2002Notebooks,\u2002Charts,\u2002Helm\u2002Kubernetes,\u2002including\u2002technologies/frameworks\u2002with\u2002Experienced&frameworks. \u2002monitoring \n Skills: \u2002/\u2002Qualifications\u2002Preferred \n TensorFlow \u2002Pytorch,\u2002Spark,\u2002Argo,\u2002Jupyter,\u2002using\u2002datasets\u2002large\u2002in\u2002projects\u2002open-source\u2002AI/ML\u2002with\u2002Experience \n UnitTest \u2002PyTest,\u2002using\u2002cases\u2002test\u2002Functional\u2002and\u2002Unit\u2002creating\u2002Experience \n Learning \u2002Machine\u2002in\u2002models\u2002tuning\u2002and\u2002training\u2002with\u2002Experience \n Hub \u2002Jupyter\u2002with\u2002working\u2002Experience \n PostgreSQL \u2002like\u2002system\u2002management\u2002DB\u2002with\u2002Experience \n Splunk/Kibana \u2002using\u2002logs\u2002analyzing\u2002and\u2002monitoring,\u2002searching,\u2002in\u2002Experience   knowledge \u2002implementation\u2002GraphQL/Swagger \n Service \u2002Kubernetes\u2002Azure\u2002in\u2002applications\u2002of\u2002scalability\u2002and\u2002availability\u2002for\u2002Kubernetes\u2002with\u2002experience\u2002and\u2002understanding\u2002Strong \n Gitlab \u2002and\u2002Charts\u2002Helm\u2002Kubernetes,\u2002Artifactory,\u2002Docker,\u2002Jenkins,\u2002Cloudbees\u2002using\u2002pipelines\u2002CI/CD\u2002building\u2002Experience \n Kafka \u2002Spark,\u2002Apache\u2002Scikit,\u2002TensorFlow,\u2002MLFlow,\u2002Kubeflow,\u2002Hub,\u2002Jupyter\u2002like\u2002tools\u2002with\u2002Experience \n workflows \u2002Argo\u2002Airflow,\u2002Apache\u2002as\u2002such\u2002tools\u2002orchestration\u2002workflow\u2002with\u2002Experience \n builds \u2002package\u2002Node.js\u2002and\u2002PyPi,\u2002Conda,\u2002with\u2002Familiarity \n \n Job Type: Contract \n Salary: $51.00 - $55.00 per hour ", "techs": ["aiml", "kubernetes", "programming", "distributed/parallel inferencing", "training", "model", "frameworks", "java", "python", "sql", "database", "nosql", "django", "flask", "apis", "rest", "pipelines", "etl", "ci/cd", "orchestration", "workflow", "notebooks", "charts", "helm", "tensorflow", "pytorch", "spark", "argo", "jupyter", "unittest", "machine learning", "hub", "postgresql", "splunk/kibana", "graphql/swagger", "service", "scalability", "availability", "gitlab", "artifactory", "docker", "jenkins", "cloudbees", "kafka", "mlflow", "kubeflow", "workflows", "argo", "airflow", "node.js", "pypi", "conda"]}, "70e539c357b570ae": {"terms": ["data science", "data engineer", "machine learning engineer"], "salary_min": 121292.23, "salary_max": 153582.98, "title": "SENIOR DATA ENGINEER", "company": "AIR HAMBURG Luftverkehrsgesellschaft mbH", "desc": "Requisition ID\n       \n \n       2023-3757 \n       \n \n \n \n       City \n       \n \n       Fort Lauderdale \n       \n \n \n \n       Position Type\n       \n \n       Permanent Full-Time \n       \n \n \n \n       Work Base\n       \n \n       Remote \n       \n \n \n \n       Category\n       \n \n       Engineering \n       \n \n \n \n \n \n Job Profile  \n \n \n \n \n About Team \n \n \n      The Data Foundation Team is highly critical for the organization to provide timely, accurate and most up to date data so that the business can take decisions accordingly. The team works with several application teams, data analytics, data science team etc. We are looking for a highly skilled and experienced \n      Senior Data Engineer  to design, implement, and maintain robust and scalable data pipelines.\n     \n \n \n  About Company \n \n \n      Vista Tech plays a vital role in the Vista group operations by delivering and accelerating comprehensive technology solutions across all brands. Vista\u2019s end-to-end and click-to-flight solutions offer the industry's only comprehensive flight booking platform, seamlessly integrating global operations, and leveraging AI and machine learning to optimize pricing and fleet movement. Comprised of the Product Management, Engineering, and IT teams, Vista Tech\u2019s mission is to enhance transparency and accessibility in private aviation through the development of the world's largest digital private aviation marketplace. In achieving this, Vista Tech always ensures the utmost safety and efficiency for FLIGHT CREW, EMPLOYEES and Members, while fostering a culture of innovation and excellence.\n     \n \n \n  You will report to Engineering Manager and play a crucial role in driving the technical direction of our projects and guiding the team in adopting best practices and cutting-edge technologies. This position is a 100% remote role with regular shif timings (9 AM to 6 AM EST). You will collaborate with cross-functional teams, provide technical leadership, and contribute to the entire software development lifecycle.\n     \n \n \n \n Your Responsibilities  \n \n \n \n \n Scalable Data Infrastructure:  Lead the development and maintenance of highly scalable data pipelines, playing a crucial role in fortifying our data foundation. \n  Technical Excellence:  Demonstrate hands-on technical expertise in designing, building, and documenting complex data pipelines while adhering to data engineering best practices. \n  Cross-Functional Collaboration:  Collaborate closely with data engineering, analytics, and data science leadership to continuously enhance the functionality and capabilities of our data systems. \n  Process Optimization:  Identify opportunities for internal process improvements, spearheading automation of manual tasks, optimizing data delivery mechanisms, and redesigning infrastructure to ensure greater scalability and efficiency. \n  Data Integration Mastery:  Define and construct the infrastructure necessary to facilitate efficient extraction, transformation, and loading (ETL) of data from a diverse array of sources. \n \n \n \n \n Required Skills, Qualifications, and Experience  \n \n \n \n \n \n \n Strong Analytical Foundation:  A robust background in mathematics, statistics, computer science, data science, or a related discipline, showcasing your analytical prowess.\n       \n \n \n  Programming Proficiency:  Advanced expertise in programming languages, particularly Python and SQL, to tackle complex data challenges.\n       \n \n \n  Production Experience:  Proven experience in the production environment with a range of essential tools and platforms, including Snowflake, DBT, Airflow, Amazon Web Services (AWS), Docker/Kubernetes, and PostgreSQL.\n       \n \n \n  Database Mastery:  Proficiency in database technologies, including Snowflake, PostgreSQL, Redshift, and others, enabling efficient data management.\n       \n \n \n  Exceptional Organizational Skills:  Strong organizational capabilities, allowing you to manage multiple projects and priorities concurrently while consistently meeting deadlines.\n       \n \n \n  Additional Assets:  Familiarity and experience with additional tools and technologies, such as AWS certification, Kafka Streaming/Kafka Connect, MongoDB, and CI/CD tools like GitLab, Jira, and Confluence, are highly advantageous.", "cleaned_desc": " Job Profile  \n \n \n \n \n About Team \n \n \n      The Data Foundation Team is highly critical for the organization to provide timely, accurate and most up to date data so that the business can take decisions accordingly. The team works with several application teams, data analytics, data science team etc. We are looking for a highly skilled and experienced \n      Senior Data Engineer  to design, implement, and maintain robust and scalable data pipelines.\n     \n \n \n  About Company \n \n \n      Vista Tech plays a vital role in the Vista group operations by delivering and accelerating comprehensive technology solutions across all brands. Vista\u2019s end-to-end and click-to-flight solutions offer the industry's only comprehensive flight booking platform, seamlessly integrating global operations, and leveraging AI and machine learning to optimize pricing and fleet movement. Comprised of the Product Management, Engineering, and IT teams, Vista Tech\u2019s mission is to enhance transparency and accessibility in private aviation through the development of the world's largest digital private aviation marketplace. In achieving this, Vista Tech always ensures the utmost safety and efficiency for FLIGHT CREW, EMPLOYEES and Members, while fostering a culture of innovation and excellence.\n     \n \n \n  You will report to Engineering Manager and play a crucial role in driving the technical direction of our projects and guiding the team in adopting best practices and cutting-edge technologies. This position is a 100% remote role with regular shif timings (9 AM to 6 AM EST). You will collaborate with cross-functional teams, provide technical leadership, and contribute to the entire software development lifecycle.      \n \n \n \n Your Responsibilities  \n \n \n \n \n Scalable Data Infrastructure:  Lead the development and maintenance of highly scalable data pipelines, playing a crucial role in fortifying our data foundation. \n  Technical Excellence:  Demonstrate hands-on technical expertise in designing, building, and documenting complex data pipelines while adhering to data engineering best practices. \n  Cross-Functional Collaboration:  Collaborate closely with data engineering, analytics, and data science leadership to continuously enhance the functionality and capabilities of our data systems. \n  Process Optimization:  Identify opportunities for internal process improvements, spearheading automation of manual tasks, optimizing data delivery mechanisms, and redesigning infrastructure to ensure greater scalability and efficiency. \n  Data Integration Mastery:  Define and construct the infrastructure necessary to facilitate efficient extraction, transformation, and loading (ETL) of data from a diverse array of sources. \n \n \n \n \n Required Skills, Qualifications, and Experience  \n \n   \n \n \n \n Strong Analytical Foundation:  A robust background in mathematics, statistics, computer science, data science, or a related discipline, showcasing your analytical prowess.\n       \n \n \n  Programming Proficiency:  Advanced expertise in programming languages, particularly Python and SQL, to tackle complex data challenges.\n       \n \n \n  Production Experience:  Proven experience in the production environment with a range of essential tools and platforms, including Snowflake, DBT, Airflow, Amazon Web Services (AWS), Docker/Kubernetes, and PostgreSQL.\n       \n \n \n  Database Mastery:  Proficiency in database technologies, including Snowflake, PostgreSQL, Redshift, and others, enabling efficient data management.\n       \n \n \n  Exceptional Organizational Skills:  Strong organizational capabilities, allowing you to manage multiple projects and priorities concurrently while consistently meeting deadlines.", "techs": ["snowflake", "dbt", "airflow", "amazon web services (aws)", "docker/kubernetes", "postgresql", "snowflake", "postgresql", "redshift"]}, "b93b81bddd338416": {"terms": ["data science", "data engineer", "machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Sr. Databricks Data Engineer", "company": "Metric5", "desc": "Sr. Databricks Data Engineer \n Description \n Metric5 is currently seeking a Databricks Data Engineer to work within a team providing Data Warehouse and Business Intelligence services to our government customer using Agile processes. As a Data Engineer, you will work with varying huge data sources with different schemas and data elements to design and implement solutions while aligning the technical roadmap for expanding the usage of Databricks Lakehouse Platform. You will be a Big Data Analytics expert on aspects of architecture and design; support the program by authoring reference architectures, how-tos, and demo applications. You have an eye for spotting data correlations and a desire to dig into large datasets to find technical solutions and deliver business value.  \n Program Details \n The program you will be supporting has a mission to provide development, security, and operations (DevSecOps) support to U.S. Citizenship and Immigration Services (USCIS) with a focus on development, operations, and modernization of the Agency\u2019s Enterprise Data Warehouse/Data Lake. The team utilizes open-source, AWS Cloud, and Big Data technologies, agile project management practices, and modern DevSecOps delivery to provide the business intelligence support systems to meet the reporting, data analytics, and machine learning/artificial intelligence needs critical to USCIS leadership, data/business analysts, data scientists, and other decision-makers. \n Requirements: \n \n Designing and implementing data ingestion pipelines from multiple sources using big data technologies  \n Developing scalable and re-usable frameworks for ingesting of data sets \n Integrating the end-to-end data pipeline - to take data from source systems to target data repositories ensuring the quality and consistency of data is maintained at all times \n Working with event based / streaming technologies to ingest and process data \n Working with other members of the project team to support delivery of additional project components (API interfaces, Search) \n Evaluating the performance and applicability of multiple tools against customer requirements \n Implementing Databricks Unity Catalog and Delta Share features \n \n \n Required Skills:  \n \n 3+ years in a customer-facing, technical architecture role with expertise in at least one of the following technologies: Big data engineering (Ex: Spark, Delta, Hadoop, Kafka) \n 5+ years of experience with ETL development ingesting data from diverse and huge data sources Data Warehousing & ETL (Ex: SQL, OLTP/OLAP/DSS) \n 5+ years of experience Data Applications (Ex: Logs Analysis, Threat Detection, Real-time Systems Monitoring, Risk Analysis and more) \n 5+ years of experience with relational databases used to support BI analytics \n 3+ years of experience producing and consuming Rest APIs.  \n 4+ years of experience with coding and scripting (Bash, Python, SQL, Java and Scala) \n 4+ years of experience using build and deployment tools (Jenkins, Docker). \n Experience in Data Science and Machine Learning (Ex: pandas, scikit-learn, HPO) \n Experience with structured streaming with Delta Sharing and integration with Unity Catalog \n Experience in a Data Warehouse/Data Lake and Business Intelligence environment \n Self-driven with the ability to adapt quickly, work in a challenging and fast paced environment within cross-functional teams, and to promote creative problem solving within their team \n Hands on deep working knowledge with AWS including ECS/EC2/EKS, Security groups IAM roles, Instance profile and AWS S3 bucket security. \n Experience of architecting and development of event-based architecture use cases using SQS/SNS including efficient usage of serverless functions (AWS Lambda) \n Strong working knowledge and implementation of CI, CD pipelines using (Maven/Jenkins/Github/Gitlabs) including Code quality, code smells and configure reporting (e.g.: SONAR) \n Experience with Agile development practices, including Scrum and Kanban, and management tools (e.g., Jira, Confluence) \n Experience building solutions with public cloud providers such as AWS, Azure, or GCP \n Strong teamwork, co-ordination, planning and influencing skills \n Excellent communication and organizational skills \n Experience with Microsoft Office Suite including Excel, PowerPoint, and Visio \n \n \n Desired Skills: \n \n \n Experience demonstrating technical concepts, including presenting and white-boarding \n Experience with AWS Database Migration Service (DMS), Databricks/Apache Spark, and/or Kafka experience \n Experience with Postgres and Oracle \n Experience with Scaled Agile Framework SAFe \n \n \n Education:  Bachelor\u2019s degree in a technical discipline preferred \u2013 Computer Science, Mathematics, or equivalent technical degree, or the equivalent combination of education, professional training, and work experience. \n Location : Reston, VA \u2013 Currently fully remote  \n Clearance : Must be a US Citizen and be able to obtain a government agency Suitability Clearance. USCIS Entry on Duty (EOD) preferred.", "cleaned_desc": "Sr. Databricks Data Engineer \n Description \n Metric5 is currently seeking a Databricks Data Engineer to work within a team providing Data Warehouse and Business Intelligence services to our government customer using Agile processes. As a Data Engineer, you will work with varying huge data sources with different schemas and data elements to design and implement solutions while aligning the technical roadmap for expanding the usage of Databricks Lakehouse Platform. You will be a Big Data Analytics expert on aspects of architecture and design; support the program by authoring reference architectures, how-tos, and demo applications. You have an eye for spotting data correlations and a desire to dig into large datasets to find technical solutions and deliver business value.  \n Program Details \n The program you will be supporting has a mission to provide development, security, and operations (DevSecOps) support to U.S. Citizenship and Immigration Services (USCIS) with a focus on development, operations, and modernization of the Agency\u2019s Enterprise Data Warehouse/Data Lake. The team utilizes open-source, AWS Cloud, and Big Data technologies, agile project management practices, and modern DevSecOps delivery to provide the business intelligence support systems to meet the reporting, data analytics, and machine learning/artificial intelligence needs critical to USCIS leadership, data/business analysts, data scientists, and other decision-makers. \n Requirements: \n \n Designing and implementing data ingestion pipelines from multiple sources using big data technologies  \n Developing scalable and re-usable frameworks for ingesting of data sets \n Integrating the end-to-end data pipeline - to take data from source systems to target data repositories ensuring the quality and consistency of data is maintained at all times   Working with event based / streaming technologies to ingest and process data \n Working with other members of the project team to support delivery of additional project components (API interfaces, Search) \n Evaluating the performance and applicability of multiple tools against customer requirements \n Implementing Databricks Unity Catalog and Delta Share features \n \n \n Required Skills:  \n \n 3+ years in a customer-facing, technical architecture role with expertise in at least one of the following technologies: Big data engineering (Ex: Spark, Delta, Hadoop, Kafka) \n 5+ years of experience with ETL development ingesting data from diverse and huge data sources Data Warehousing & ETL (Ex: SQL, OLTP/OLAP/DSS)   5+ years of experience Data Applications (Ex: Logs Analysis, Threat Detection, Real-time Systems Monitoring, Risk Analysis and more) \n 5+ years of experience with relational databases used to support BI analytics \n 3+ years of experience producing and consuming Rest APIs.  \n 4+ years of experience with coding and scripting (Bash, Python, SQL, Java and Scala) \n 4+ years of experience using build and deployment tools (Jenkins, Docker). \n Experience in Data Science and Machine Learning (Ex: pandas, scikit-learn, HPO) \n Experience with structured streaming with Delta Sharing and integration with Unity Catalog \n Experience in a Data Warehouse/Data Lake and Business Intelligence environment \n Self-driven with the ability to adapt quickly, work in a challenging and fast paced environment within cross-functional teams, and to promote creative problem solving within their team \n Hands on deep working knowledge with AWS including ECS/EC2/EKS, Security groups IAM roles, Instance profile and AWS S3 bucket security.   Experience of architecting and development of event-based architecture use cases using SQS/SNS including efficient usage of serverless functions (AWS Lambda) \n Strong working knowledge and implementation of CI, CD pipelines using (Maven/Jenkins/Github/Gitlabs) including Code quality, code smells and configure reporting (e.g.: SONAR) \n Experience with Agile development practices, including Scrum and Kanban, and management tools (e.g., Jira, Confluence) \n Experience building solutions with public cloud providers such as AWS, Azure, or GCP \n Strong teamwork, co-ordination, planning and influencing skills \n Excellent communication and organizational skills \n Experience with Microsoft Office Suite including Excel, PowerPoint, and Visio \n \n \n Desired Skills:   \n \n Experience demonstrating technical concepts, including presenting and white-boarding \n Experience with AWS Database Migration Service (DMS), Databricks/Apache Spark, and/or Kafka experience \n Experience with Postgres and Oracle \n Experience with Scaled Agile Framework SAFe \n \n \n Education:  Bachelor\u2019s degree in a technical discipline preferred \u2013 Computer Science, Mathematics, or equivalent technical degree, or the equivalent combination of education, professional training, and work experience. \n Location : Reston, VA \u2013 Currently fully remote  ", "techs": ["databricks data engineer", "agile", "databricks lakehouse platform", "big data analytics", "reference architectures", "how-tos", "demo applications", "devsecops", "u.s. citizenship and immigration services", "enterprise data warehouse/data lake", "open-source", "aws cloud", "big data technologies", "agile project management practices", "devsecops delivery", "reporting", "data analytics", "machine learning", "artificial intelligence", "data ingestion pipelines", "big data technologies", "scalable and re-usable frameworks", "end-to-end data pipeline", "event based/streaming technologies", "api interfaces", "search", "performance evaluation", "databricks unity catalog", "delta share features", "spark", "delta", "hadoop", "kafka", "etl development", "sql", "oltp/olap/dss", "data applications", "relational databases", "rest apis", "coding", "scripting", "build and deployment tools", "data science", "machine learning", "pandas", "scikit-learn", "hpo", "structured streaming", "delta sharing", "unity catalog", "data warehouse/data lake", "business intelligence", "aws", "ecs/ec2/eks", "security groups", "iam roles", "instance profile", "aws s3 bucket security", "event-based architecture", "sqs/sns", "aws lambda", "ci", "cd pipelines", "maven", "jenkins", "github", "gitlabs", "sonar", "agile development practices", "scrum", "kanban", "jira", "confluence", "public cloud providers", "microsoft office suite", "excel", "powerpoint", "visio", "aws database migration service", "postgres", "oracle", "scaled agile framework safe", "bachelor's degree"]}, "34462dd8761c6ab5": {"terms": ["data science", "data engineer", "machine learning engineer"], "salary_min": 94420.0, "salary_max": 136665.0, "title": "Sr. Lead Data Engineer", "company": "Lumen", "desc": "About Lumen \n  Lumen is a global technology leader, digitally connecting people, data and applications \u2013 quickly, securely, and effortlessly. Together, we are building a culture and company from the people up \u2013 committed to teamwork, trust and transparency. People power progress. We\u2019re looking for top-tier talent and offer the flexibility you need to thrive and deliver lasting impact. Join us as we digitally connect the world and shape the future. \n \n \n \n  The Role \n \n \n  Are you interested in serving as an integral part of our digital marketing team developing new tools and capabilities that will continue to advance Lumen\u2019s reputation as a technology leader?    In this role, you will be taking the lead in partnering closely with marketing, operations, and data science teams to utilize terabytes of data and translate them into actionable insights to create a competitive advantage for marketing/sales initiatives to win market share. Furthermore, you will be accountable for building and operationalizing critical components and tools to ensure the data coming in and going out are of the highest data quality and integrity. In the end state, the data solutions built and operated by you would rival the absolute best in the industry in engineering, operations, and usability excellence. \n \n \n \n \n  The Main Responsibilities \n \n \n  You are a great fit for this position if you: \n \n  Have strong passion in building reliable, accurate datasets that power end-to-end user scenarios and used in business decisions. \n  Highly believe that data is an asset that must be accessible to and applicable by every function in a modern business to guide and assess growth investments. \n  Are passionate about Data Engineering and believe that it is one of a kind emerging discipline and career path that you want to grow in. \n  Enjoy building and operating data services at terabyte and higher scales to enable data driven organizations. \n \n \n \n \n \n  What We Look For in a Candidate \n \n \n  Qualifications: \n \n  Experience building data models and performing complex queries using SQL \n  Experience performance tuning large datasets \n  Experience building large data pipelines and/or web services \n  Experience with programming skills (Python and other scripting languages) \n  8+ years of Business Intelligence or software development experience using industry technologies \n  4+ years of experience in building integration with upstream and downstream systems with REST APIs \n  Excellent problem solving, critical thinking, and communication skills \n  Ability to communicate effectively with technical and business teams, drive issues to closure \n  Strong understanding of data engineering and data stewardship roles in an organization \n  Ability to foster an innovative and inclusive team-oriented work environment. You\u2019ll play an active role in counselling and mentoring junior team members across the organization by providing structured and on-the-job feedback. \n  Ability to work on multiple priorities that span different areas of focus. You should feel comfortable talking to business stakeholders, analysts, data scientists and developers. \n  An entrepreneurial spirit who is excited by ambiguity, operates autonomously and can make informed decisions on the fly, grounded in a digital transformation point of view for marketing/sales initiatives. \n  BA/BS in Computer Science, Engineering or related technical field such as Statistics or Data Science \n \n \n  Other Qualifications: \n \n  Strong familiarity with big data and Hadoop ecosystem of tools is highly valuable \n  Knowledge of Lumen data, systems and processes including paid media, financial and inventory systems highly desirable \n  Experience with ETL and data integration development using multiple tools, including Informatica, Microsoft SSIS or other technologies \n  Experience with cloud data platforms is helpful \n  Combined IT and Marketing background \n  Machine Learning, Data Science, and statistical modeling experience are highly valued \n \n \n \n \n \n  Compensation \n \n \n  The starting salary for this role differs based on the employee's primary work location. Employees typically do not start at the top of the range, though compensation depends on each individual's qualifications. \n  Location Based Pay Ranges \n  $94420 - $118028  in these states: AR, ID, KY, LA, ME, MS, NE, SC, and SD.   $99390 - $124230  in these states: AZ, FL, GA, IN, IA, KS, MO, MT, NM, ND, OH, OK, PA, TN, UT, VT, WV, WI, and WY.   $104360 - $130448  in these states: CO, HI, MI, MN, NV, NH, NC, OR, and RI.   $109330 - $136665  in these states: AK, CA, CT, DE, DC, IL, MD, MA, NJ, NY, TX, VA, and WA. \n  As with the pay range variety that's based on the region of a country, specific offers are determined by various factors such as experience, education, skills, certifications and other business needs. \n \n \n \n \n  What to Expect Next \n \n \n \n \n  Requisition #: 331486 \n  Background Screening \n  If you are selected for a position, there will be a background screen, which may include checks for criminal records and/or motor vehicle reports and/or drug screening, depending on the position requirements. For more information on these checks, please refer to the Post Offer section of our FAQ page. Job-related concerns identified during the background screening may disqualify you from the new position or your current role. Background results will be evaluated on a case-by-case basis. \n  Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. \n  Equal Employment Opportunities \n  We are committed to providing equal employment opportunities to all persons regardless of race, color, ancestry, citizenship, national origin, religion, veteran status, disability, genetic characteristic or information, age, gender, sexual orientation, gender identity, gender expression, marital status, family status, pregnancy, or other legally protected status (collectively, \u201cprotected statuses\u201d). We do not tolerate unlawful discrimination in any employment decisions, including recruiting, hiring, compensation, promotion, benefits, discipline, termination, job assignments or training. \n  Disclaimer \n  The job responsibilities described above indicate the general nature and level of work performed by employees within this classification. It is not intended to include a comprehensive inventory of all duties and responsibilities for this job. Job duties and responsibilities are subject to change based on evolving business needs and conditions. \n \n  Salary Range \n \n  Salary Min :  \n 94420 \n \n \n  Salary Max :  \n 136665 \n \n \n  This information reflects the anticipated base salary range for this position based on current national data. Minimums and maximums may vary based on location. Individual pay is based on skills, experience and other relevant factors.  \n This position is eligible for either short-term incentives or sales compensation. Director and VP positions also are eligible for long-term incentive. To learn more about our bonus structure, you can view additional information here. We're able to answer any additional questions you may have as you move through the selection process. \n  As part of our comprehensive benefits package, Lumen offers a broad range of Health, Life, Voluntary Lifestyle and other benefits and perks that enhance your physical, mental, emotional and financial wellbeing. You can learn more by clicking here. \n  Note: For union-represented postings, wage rates and ranges are governed by applicable collective bargaining agreement provisions.", "cleaned_desc": "  Highly believe that data is an asset that must be accessible to and applicable by every function in a modern business to guide and assess growth investments. \n  Are passionate about Data Engineering and believe that it is one of a kind emerging discipline and career path that you want to grow in. \n  Enjoy building and operating data services at terabyte and higher scales to enable data driven organizations. \n \n \n \n \n \n  What We Look For in a Candidate \n \n \n  Qualifications: \n \n  Experience building data models and performing complex queries using SQL \n  Experience performance tuning large datasets \n  Experience building large data pipelines and/or web services \n  Experience with programming skills (Python and other scripting languages) \n  8+ years of Business Intelligence or software development experience using industry technologies \n  4+ years of experience in building integration with upstream and downstream systems with REST APIs    Excellent problem solving, critical thinking, and communication skills \n  Ability to communicate effectively with technical and business teams, drive issues to closure \n  Strong understanding of data engineering and data stewardship roles in an organization \n  Ability to foster an innovative and inclusive team-oriented work environment. You\u2019ll play an active role in counselling and mentoring junior team members across the organization by providing structured and on-the-job feedback. \n  Ability to work on multiple priorities that span different areas of focus. You should feel comfortable talking to business stakeholders, analysts, data scientists and developers. \n  An entrepreneurial spirit who is excited by ambiguity, operates autonomously and can make informed decisions on the fly, grounded in a digital transformation point of view for marketing/sales initiatives. \n  BA/BS in Computer Science, Engineering or related technical field such as Statistics or Data Science \n \n \n  Other Qualifications: \n \n  Strong familiarity with big data and Hadoop ecosystem of tools is highly valuable \n  Knowledge of Lumen data, systems and processes including paid media, financial and inventory systems highly desirable \n  Experience with ETL and data integration development using multiple tools, including Informatica, Microsoft SSIS or other technologies \n  Experience with cloud data platforms is helpful \n  Combined IT and Marketing background \n  Machine Learning, Data Science, and statistical modeling experience are highly valued \n \n ", "techs": ["sql", "python", "rest apis", "informatica", "microsoft ssis", "big data", "hadoop ecosystem", "lumen data", "etl", "cloud data platforms", "machine learning", "data science", "statistical modeling"]}, "9d98dea56fde5cbf": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Sr. Financial Analyst - Customer Success", "company": "Genesys", "desc": "Build something new with a world-class team.\n  \n \n \n   At Genesys, we allow our employees to make their mark by entrusting them to make decisions and do what they\u2019ve been hired to do: their very best. Your potential is waiting; why are you?\n  \n \n \n   The Strategic Finance team at Genesys is responsible for leading the company\u2019s financial forecasting and reporting for executives and investors, including developing the company\u2019s annual budget and long-range plans and providing executives with regular analysis of the company\u2019s performance across key strategic goals. This Senior Financial Analyst role will lead Product Support and TAM (Technical Account Managers) organizations (CSS Organization) expense forecasting and analytics workstreams and work closely with finance and business partners at all levels of the company. We are looking for a driven and accomplished finance professional with a proven track record of delivering results who is looking to grow their career by being a key strategic partner for the CSS business.\n  \n \n \n   Key Responsibilities\n  \n \n  Become a trusted partner and advisor for the Product Support and TAM leaders and other cross-functional teams to provide financial decision-making support. \n  Develop and own Product Support and TAM budget and forecasting process including headcount and non-labor expenses. \n  Partner with business leads, HR, and other Finance teams to execute on the roadmap. \n  Generate variance analyses, bridges, and presentations that explain trends and takeaways for leadership, board of directors, and other external investor communications. \n  Perform month-end closing activities including accrual preparation and coordination with accounting. \n  Reconcile and ensure consistency of data from various sources and assist in driving the automation of reports and analyses. \n  Analyze and interpret data to develop insights and recommendations. \n  Support ad-hoc finance projects to help leadership make financially sound decisions. \n \n \n  Key Qualifications\n  \n \n  BS/BA or equivalent in Finance, Economics, Accounting, Data Science, or related field. \n  2+ years of experience in corporate finance, consulting, or accounting environments; SaaS/Cloud industry experience is a plus. \n  Advanced Excel & financial modeling skills. \n  Superior attention to detail and quality. \n  Proficient in PowerPoint, business intelligence (Tableau/PowerBI), planning, ERP, Workday Adaptive, and reporting systems. Prior experience with Hyperion Planning a plus. \n  Excellent communication, interpersonal, collaboration and consultative skills. Inquisitive and growth mindset in approaching complex problem \n \n \n \n   #LI-Remote\n  \n \n   #LI-DJ1\n  \n \n \n   Compensation:\n  \n \n   This role has a market-competitive salary with an anticipated base compensation range listed below. Actual salaries will vary depending on a candidate\u2019s experience, qualifications, skills, and location. This role might also be eligible for a commission or performance-based bonus opportunities.\n  \n  $61,100.00 - $126,900.00\n  \n \n   Benefits:\n  \n \n \n \n     Medical, Dental, and Vision Insurance.\n    \n \n \n     Telehealth coverage\n    \n \n \n     Flexible work schedules and work from home opportunities\n    \n \n \n     Development and career growth opportunities\n    \n \n \n     Open Time Off in addition to 10 paid holidays\n    \n \n \n     401(k) matching program\n    \n \n \n     Adoption Assistance\n    \n \n \n     Fertility treatments\n    \n \n \n \n   More details about our company benefits can be found at the following link: \n   \n   https://mygenesysbenefits.com\n   \n \n \n \n   If a Genesys employee referred you, please use the link they sent you to apply.\n  \n \n \n   About Genesys:\n  \n \n   Every year, Genesys orchestrates billions of remarkable customer experiences for organizations in more than 100 countries. Through the power of our cloud, digital and AI technologies, organizations can realize Experience as a Service\u2122 our vision for empathetic customer experiences at scale. With Genesys, organizations have the power to deliver proactive, predictive, and hyper personalized experiences to deepen their customer connection across every marketing, sales, and service moment on any channel, while also improving employee productivity and engagement. By transforming back-office technology to a modern revenue velocity engine Genesys enables true intimacy at scale to foster customer trust and loyalty. Visit \n   \n   www.genesys.com\n   .\n  \n \n \n   Reasonable Accommodations:\n  \n \n   If you require a reasonable accommodation to complete any part of the application process or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you or someone you know may complete the \n   \n   Reasonable Accommodations Form \n   for assistance. Please use the Candidate field in the dropdown menu to ensure a timely response.\n  \n \n \n   This form is designed to assist job seekers who seek reasonable accommodation for the application process. Submissions entered for non-accommodation-related issues, such as following up on an application or submitting a resume, may not receive a response.\n  \n \n \n   Genesys is an equal opportunity employer committed to diversity in the workplace. We evaluate qualified applicants without regard to race, color, age, religion, sex, sexual orientation, gender identity or expression, marital status, domestic partner status, national origin, genetics, disability, military and veteran status, and other protected characteristics.\n  \n \n \n  Please note that recruiters will never ask for sensitive personal or financial information during the application phase.", "cleaned_desc": "", "techs": ""}, "75eebfd87f152acc": {"terms": ["data science"], "salary_min": 150000.0, "salary_max": 185000.0, "title": "Senior Manager, Data Engineering (Remote)", "company": "Abercrombie and Fitch Co.", "desc": "Company Description\n   Job Description \n  The primary responsibility of the data engineering manager is to work with data engineering team driving the design, build, launching of new data models and data pipeliles utilizing modern data engineering standards, design patterns and practices. Their mission is to build high performing teams driving delivery, onboarding of new data and data quality for trusted data that is easy to access, understand, and derive value. The role requires forward thinking with a focus on transforming existing incumbent solutions into sustainable and scalable solutions on modern cloud data technology. \n  The data engineering manager will facilitate the adoption of modern data standards, engineering practices, devops, test driven development, and simplification of data engineering within the organization. They will work with engineering teams and architects to design solutions which meet enterprise standards. \n  Besides, the Data Engineering Manager will be responsible for identifying/promoting emerging technology trends in data engineering space to ensure the company is leveraging them when appropriate to increase efficiency, drive business agility, reduce costs, and drive value. \n  What Will You Be Doing? \n \n  Team up  with our engineering and enterprise architecture teams to define and create data engineering principles, standards, and design patterns related to metadata management, data integration, data storage, data security, data modeling, data quality, and data access control \n  Promote best practice  and provide guidance to our Data Engineering and Data Science teams to facilitate the buildout of data products that drive business value \n  Partner with the engineering and business teams   to serve as an evangelist in promoting the use of event streams, cloud-based data solutions, Data Ownership, Data Stewardship, and self-service \n  Support the migration of  1000+ integrations and data pipelines  from diverse on-prem technologies to cloud-based integration tools and technology \n  Collaborate with project portfolio management team and technology stakeholders on integrations solutions design ensuring data engineering standards and practices building scalable and flexible solution \n  Partner with the infrastructure and security teams  on data engineering, solutions design, centralized logging/monitoring, and transformation efforts to ensure proper scope, resources and costs allocated for needs \n  Serve as an evangelist in promoting and adopting modern data engineering standards and practices across IT \n  Ensure that all application development initiatives are well managed and delivered to meet expectations on functionality, timeliness, and cost. \n  Lead and/or participate on technical user groups, task forces, and committees \n \n  What Do You Need To Bring? \n \n  Able to manage a team thru major/complex data transformation to event driven architecture (Kafka) and modern cloud data architecture (Azure, Databricks, Snowflake, Power BI) \n  Provide leadership and management to build high-performing teams and continuously upskill team members to keep them current thru professional development programs \n  Ability to prioritize personal and team responsibilities to meet organizational objectives \n  Drive the cultural changes necessary to enable a continuous delivery model, modern data engineering standards, and foster a strong focus on automation and agile delivery methods. \n  Willingness to learn new things and adapt quickly to a team and enterprise undergoing positive transformation \n  High interpersonal skills to operate in a large, distributed, and diverse global technology team \n  Success working as a technical leader in a large enterprise organization \n  Sets team goals to ensure the success of the department in accordance with milestones developed by IT Senior Management \n  Develop and retain high caliber data engineering talent \n  Ability to foster a culture of transparency and a sense of purpose among the team and create clear accountabilities and metrics. \n  Bachelor\u2019s degree in Computer Science or related field and  10-15 years' experience  in various roles of technical leadership within a large-scale organization \n  Personal Attributes: Self-starter, Collaborative, Curious, Strong work ethic, Highly motivated, Team oriented \n  Successfully led data engineering and delivery of complex business technology solutions into production that have achieved or surpassed business goals. \n  Experience with modern data engineering development and design concepts; software development lifecycle; project management; advanced and systems administration practices and principles; planning, design, and problem resolution \n  Experience with management and supervisory practices leading people; human resource practices \n  Experience in leading data engineering team in delivering quality software solutions leveraging Azure cloud, Databricks, Snowflake, Power BI, API/micro services, and Kafka event driven technologies. \n  Demonstrated ability in developing a culture that embraces innovation, and challenges existing paradigms. \n \n  Our Company \n  Abercrombie & Fitch Co. (A&F Co.) is a global retailer of five iconic, omnichannel lifestyle brands catering to the kid through millennial customer: Abercrombie & Fitch, abercrombie kids, Hollister, Gilly Hicks and Social Tourist. At A&F Co., we\u2019re here for our associates, customers and communities on the journey to being and becoming who they are \u2013 and because no journey is the same, we strive to create an inclusive culture, where everyone is free to share ideas. \n  Our Values \n  We lead with purpose and always put our people first, which is evidenced by our Great Place to Work\u2122 Certification, as well as being a 2021 recipient of Fortune\u2019s Best Workplaces in Retail, and named a Best Place to Work for LGBTQ+ Equality by the Human Rights Campaign for 16 consecutive years. We\u2019re proud to offer equitable compensation and benefits, including flexibility and competitive Paid Time Off, as well as education and engagement events, including various Associate Resource Groups, volunteer opportunities and additional time off to give back to our global communities. \n  What You'll Get \n  As an Abercrombie & Fitch Co. (A&F Co.) associate, you\u2019ll be eligible to participate in a variety of benefit programs designed to fit you and your lifestyle. A&F is committed to providing simple, competitive, and comprehensive benefits that align with our Company\u2019s culture and values, but most importantly \u2013 with you! We also provide competitive incentives to reward the commitment our associates have for moving our global business forward: \n \n  Incentive Bonus Program \n  Paid Time Off and Work From Anywhere Flexibility \n  Paid Volunteer Day per Year, allowing you to give back to your community \n  Merchandise Discount \n  Medical, Dental and Vision Insurance Available \n  Life and Disability Insurance \n  Associate Assistance Program \n  Paid Parental and Adoption Leave \n  Access to Carrot to support your unique parenthood journey \n  Access to Headspace dedicated to creating healthier, happier lives from the inside out \n  401(K) Savings Plan with Company Match \n  Opportunities for Career Advancement, we believe in promoting from within \n  A Global Team of People Who'll Celebrate you for Being YOU \n \n \n \n \n Additional Information\n   ABERCROMBIE & FITCH CO. IS AN EQUAL OPPORTUNITY EMPLOYER \n  Notice (For Colorado, New York, California and Washington): The recruiting pay range for this position is $150,000 - $185,000. Factors that may be used to determine your actual salary may include your specific skills, your years of experience, your work location, comparison to other employees in similar or related roles, or market demands. The range may be modified in the future.", "cleaned_desc": "Company Description\n   Job Description \n  The primary responsibility of the data engineering manager is to work with data engineering team driving the design, build, launching of new data models and data pipeliles utilizing modern data engineering standards, design patterns and practices. Their mission is to build high performing teams driving delivery, onboarding of new data and data quality for trusted data that is easy to access, understand, and derive value. The role requires forward thinking with a focus on transforming existing incumbent solutions into sustainable and scalable solutions on modern cloud data technology. \n  The data engineering manager will facilitate the adoption of modern data standards, engineering practices, devops, test driven development, and simplification of data engineering within the organization. They will work with engineering teams and architects to design solutions which meet enterprise standards. \n  Besides, the Data Engineering Manager will be responsible for identifying/promoting emerging technology trends in data engineering space to ensure the company is leveraging them when appropriate to increase efficiency, drive business agility, reduce costs, and drive value. \n  What Will You Be Doing? \n \n  Team up  with our engineering and enterprise architecture teams to define and create data engineering principles, standards, and design patterns related to metadata management, data integration, data storage, data security, data modeling, data quality, and data access control \n  Promote best practice  and provide guidance to our Data Engineering and Data Science teams to facilitate the buildout of data products that drive business value \n  Partner with the engineering and business teams   to serve as an evangelist in promoting the use of event streams, cloud-based data solutions, Data Ownership, Data Stewardship, and self-service \n  Support the migration of  1000+ integrations and data pipelines  from diverse on-prem technologies to cloud-based integration tools and technology \n  Collaborate with project portfolio management team and technology stakeholders on integrations solutions design ensuring data engineering standards and practices building scalable and flexible solution    Partner with the infrastructure and security teams  on data engineering, solutions design, centralized logging/monitoring, and transformation efforts to ensure proper scope, resources and costs allocated for needs \n  Serve as an evangelist in promoting and adopting modern data engineering standards and practices across IT \n  Ensure that all application development initiatives are well managed and delivered to meet expectations on functionality, timeliness, and cost. \n  Lead and/or participate on technical user groups, task forces, and committees \n \n  What Do You Need To Bring? \n \n  Able to manage a team thru major/complex data transformation to event driven architecture (Kafka) and modern cloud data architecture (Azure, Databricks, Snowflake, Power BI) \n  Provide leadership and management to build high-performing teams and continuously upskill team members to keep them current thru professional development programs \n  Ability to prioritize personal and team responsibilities to meet organizational objectives \n  Drive the cultural changes necessary to enable a continuous delivery model, modern data engineering standards, and foster a strong focus on automation and agile delivery methods. \n  Willingness to learn new things and adapt quickly to a team and enterprise undergoing positive transformation    High interpersonal skills to operate in a large, distributed, and diverse global technology team \n  Success working as a technical leader in a large enterprise organization \n  Sets team goals to ensure the success of the department in accordance with milestones developed by IT Senior Management \n  Develop and retain high caliber data engineering talent \n  Ability to foster a culture of transparency and a sense of purpose among the team and create clear accountabilities and metrics. \n  Bachelor\u2019s degree in Computer Science or related field and  10-15 years' experience  in various roles of technical leadership within a large-scale organization \n  Personal Attributes: Self-starter, Collaborative, Curious, Strong work ethic, Highly motivated, Team oriented \n  Successfully led data engineering and delivery of complex business technology solutions into production that have achieved or surpassed business goals. \n  Experience with modern data engineering development and design concepts; software development lifecycle; project management; advanced and systems administration practices and principles; planning, design, and problem resolution \n  Experience with management and supervisory practices leading people; human resource practices \n  Experience in leading data engineering team in delivering quality software solutions leveraging Azure cloud, Databricks, Snowflake, Power BI, API/micro services, and Kafka event driven technologies. \n  Demonstrated ability in developing a culture that embraces innovation, and challenges existing paradigms. ", "techs": ["kafka", "azure", "databricks", "snowflake", "power bi", "api/micro services"]}, "c031d6618edf761a": {"terms": ["data science"], "salary_min": 67896.0, "salary_max": 134849.0, "title": "Senior Quality Analyst (Remote)", "company": "CareFirst BlueCross BlueShield", "desc": "Resp & Qualifications   \n PURPOSE:   We are looking for an experienced professional to work remotely from within the greater Baltimore / Washington, DC metropolitan area. The incumbent will be expected to come into a CareFirst location periodically for meetings, training and/or other business related activities.  \n The Senior Quality Analyst is responsible for the most complex work of the team in defining, measuring, analyzing, and evaluating population health, while prioritizing, developing, and operationalizing innovative initiatives to improve the quality of care and experience, resulting in industry-leading outcomes at a population level. Independently responsible and accountable for ensuring that their work aligns with and helps to achieve the organization's vision as it relates to population health, quality, and member experience. Serves as peer mentor within the team.     ESSENTIAL FUNCTIONS: \n \n  Act as the organizations subject matter expert in population health, measurement science, accreditation, and quality improvement for the line of business. Utilizes the framework of NCQA Accreditation to accomplish and document the work products. \n  Define, measure, and document the performance of the health plan in facilitating quality healthcare, positive outcomes, and excellent experience for members. \n  Analyze and evaluate health plan performance using qualitative and quantitative methodologies, producing actionable and insightful reports and visualizations addressing population health quality opportunities.  \n Prioritize, develop, and operationalize these opportunities in collaboration with other areas of the organization into innovative Clinical Quality, Customer Service and Resource Use (QCR) programs and Quality related Performance Improvement programs.  \n Mentor team members and provides guidance on most complex work efforts. Assist with special projects and/or department initiatives that require thought leadership and subject matter expertise in a consultative manner. \n \n  QUALIFICATIONS:     Education Level:  Bachelor's Degree in Population Health, Public Health, Healthcare Administration, Business Administration, Health Policy, Economics, Statistics, Mathematics, Data Science, or a related field OR in lieu of a Bachelor's degree, an additional 4 years of relevant work experience is required in addition to the required work experience. \n  Licenses/Certifications  RN-BC - Certified General Nursing Practice Preferred.\n  \n \n Experience:  5 years professional experience in a business environment (public health, health insurance, management consulting fields preferred); evidence of progressing levels of responsibility.     Preferred Qualifications: \n \n  Certification in Quality or Process Improvement Methods. \n  Direct experience with accreditation, HEDIS, CAHPS and other quality related activities a healthcare related environment and/or payor organization, specifically for line of business.  Data analytics experience working with large data sets to answer clinical, operational, or business questions; prior experience with healthcare data expected. \n  \n \n Knowledge, Skills and Abilities (KSAs) \n \n  Expertise in qualitative and quantitative data analyses and presentations. \n  End-to-end experience designing, developing, and implementing innovative strategies to improve population health. \n  Experience self-managing multiple projects and provide regular status reports. \n  Ability to conduct advanced analytics using SQL, Python, R, or similar. \n  Fluent in the use of Microsoft tools including Excel, Word, Power Point and Outlook. \n  Expertise with healthcare claims, survey, clinical, and health data. \n  Ability to mentor and guide other team members and lead initiatives in a matrix environment.  Must be able to meet established deadlines and handle multiple customer service demands from internal and external customers, within set expectations for service excellence. Must be able to effectively communicate and provide positive customer service to every internal and external customer, including customers who may be demanding or otherwise challenging.   \n \n   Salary Range:  $67,896 - $134,849 \n  Salary Range Disclaimer   \n The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the work is being performed. This compensation range is specific and considers factors such as (but not limited to) the scope and responsibilites of the position, the candidate's work experience, education/training, internal peer equity, and market and business consideration. It is not typical for an individual to be hired at the top of the range, as compensation decisions depend on each case's facts and circumstances, including but not limited to experience, internal equity, and location. In addition to your compensation, CareFirst offers a comprehensive benefits package, various incentive programs/plans, and 401k contribution programs/plans (all benefits/incentives are subject to eligibility requirements). \n  Department   \n Quality \n  Equal Employment Opportunity   \n CareFirst BlueCross BlueShield is an Equal Opportunity (EEO) employer. It is the policy of the Company to provide equal employment opportunities to all qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, protected veteran or disabled status, or genetic information. \n  Where To Apply   \n Please visit our website to apply: www.carefirst.com/careers \n  Federal Disc/Physical Demand   \n Note: The incumbent is required to immediately disclose any debarment, exclusion, or other event that makes him/her ineligible to perform work directly or indirectly on Federal health care programs. \n  PHYSICAL DEMANDS: \n  The associate is primarily seated while performing the duties of the position. Occasional walking or standing is required. The hands are regularly used to write, type, key and handle or feel small controls and objects. The associate must frequently talk and hear. Weights up to 25 pounds are occasionally lifted. \n  Sponsorship in US   \n Must be eligible to work in the U.S. without Sponsorship \n  #LI-CT1", "cleaned_desc": "  \n \n Knowledge, Skills and Abilities (KSAs) \n \n  Expertise in qualitative and quantitative data analyses and presentations. \n  End-to-end experience designing, developing, and implementing innovative strategies to improve population health. \n  Experience self-managing multiple projects and provide regular status reports. \n  Ability to conduct advanced analytics using SQL, Python, R, or similar. \n  Fluent in the use of Microsoft tools including Excel, Word, Power Point and Outlook. ", "techs": ["qualitative data analyses", "quantitative data analyses", "presentations", "innovative strategies", "population health", "self-managing projects", "status reports", "advanced analytics", "sql", "python", "r", "microsoft tools", "excel", "word", "power point", "outlook"]}, "f1eaa4bed06d4b35": {"terms": ["data science", "machine learning engineer"], "salary_min": 111000.0, "salary_max": 140000.0, "title": "AI Software Engineer III", "company": "SelectQuote", "desc": "Founded in 1985, SelectQuote provides solutions that help consumers protect their most valuable assets: their families, health and property. The company pioneered the model of providing unbiased comparisons from multiple, highly rated insurance companies allowing consumers to choose the policy and terms that best meet their unique needs. Two foundational pillars underpin SelectQuote's success: a strong force of highly trained and skilled agents, who provide consultative needs analysis for every consumer, and proprietary technology that sources and routes high-quality leads. The company has three core business lines: SelectQuote Senior, SelectQuote Life and SelectQuote Auto and Home. SelectQuote Senior, the largest and fastest-growing business, serves the needs of a demographic that sees 10,000 people turn 65 each day with a range of Medicare Advantage and Medicare Supplement plans. \n \n Job Summary: \n \n We are seeking an experienced AI Software Engineer to join our dynamic team at Selectquote. As an AI Software Engineer, you will play a crucial role in developing cutting-edge artificial intelligence solutions and contributing to the advancement of our AI capabilities. You will work closely with a talented team of engineers and data scientists to design, develop, and deploy AI-driven software applications. This is an exciting opportunity to work on innovative projects and make a significant impact in the field of AI. \n Supervisory Responsibilities: \n This position has no direct supervisory responsibilities. \n Essential Duties and Responsibilities \n \n Develop and/or implement AI algorithms and models to solve complex problems in various domains. \n  Collaborate with cross-functional teams to understand business requirements and translate them into technical solutions. \n  Design, develop, and optimize software applications that leverage machine learning and deep learning techniques. \n  Conduct research and stay up-to-date with the latest advancements in AI technologies. \n  Perform data preprocessing, feature engineering, and model evaluation to ensure high-quality and reliable AI solutions. \n  Optimize AI models for performance, scalability, and efficiency. \n  Collaborate with software engineers to integrate AI solutions into existing software systems. \n  Participate in code reviews, testing, and debugging processes to maintain code quality and ensure robustness of AI systems. \n  Document technical specifications, user guides, and other relevant documentation. \n  Stay informed about industry trends and best practices in AI software engineering. \n \n RESPONSIBILITIES: \n \n Strong proficiency in programming languages and environments such as JavaScript, Node.js, or Python. \n  Solid understanding of software development principles, design patterns, and best practices. \n  Experience with data preprocessing, feature engineering, and model evaluation. \n  Experience with machine learning and deep learning algorithms, frameworks (e.g., TensorFlow, PyTorch), and libraries \n  Experience with developing and deploying AI models. \n  Familiarity with cloud platforms and services (e.g., AWS, Azure, GCP). \n  Strong analytical and problem-solving skills. \n  Excellent communication and collaboration abilities. \n  Ability to work effectively in a fast-paced, team-oriented environment. \n \n Skills/Abilities: \n \n Creative Problem Solving \n  Strong initiative, innovative thinking skills, and the ability to analyze details and adopt a strategic view \n  Strong leadership skills to be able to effectively direct staff. \n  Analytical skills to evaluate information related to the projects they are working on to determine how effective their projects are. \n  Strong oral and written communication skills. Ability to explain complex technical information to technical and non-technical contacts \n  Strong interpersonal skills; ability to effectively build relationships, promote a collaborative team environment, and influence others \n \n Education and Experience: \n \n 7+ years of industry experience in software engineering or related roles. \n  Relevant experience with AI/ML development or implementation is a plus. \n \n \n \n \n Benefits: \n It's an exciting time to join  SelectQuote . We became a publicly traded company in 2020 with the first 100% virtual IPO (non-biotech) in American history. We have also been recognized nationally on the 2021 Top Workplaces USA list and by the Kansas City Business Journal as a 2020 Best Places to Work honoree. \n \n  Full-time employees are eligible for medical, dental, vision, voluntary short-term disability, company-paid long term disability, company-paid life insurance and accidental death & dismemberment (AD&D), 401(k) + company match and 100% vesting after 4 years, discretionary profit sharing, employee stock purchase program (espp), paid time off, floating holidays, paid maternity leave, paid parental bonding leave, tuition reimbursement, jury duty pay, and other paid leaves vary based on work location.", "cleaned_desc": "  Collaborate with cross-functional teams to understand business requirements and translate them into technical solutions. \n  Design, develop, and optimize software applications that leverage machine learning and deep learning techniques. \n  Conduct research and stay up-to-date with the latest advancements in AI technologies. \n  Perform data preprocessing, feature engineering, and model evaluation to ensure high-quality and reliable AI solutions. \n  Optimize AI models for performance, scalability, and efficiency. \n  Collaborate with software engineers to integrate AI solutions into existing software systems. \n  Participate in code reviews, testing, and debugging processes to maintain code quality and ensure robustness of AI systems. \n  Document technical specifications, user guides, and other relevant documentation. \n  Stay informed about industry trends and best practices in AI software engineering. \n   RESPONSIBILITIES: \n \n Strong proficiency in programming languages and environments such as JavaScript, Node.js, or Python. \n  Solid understanding of software development principles, design patterns, and best practices. \n  Experience with data preprocessing, feature engineering, and model evaluation. \n  Experience with machine learning and deep learning algorithms, frameworks (e.g., TensorFlow, PyTorch), and libraries \n  Experience with developing and deploying AI models. \n  Familiarity with cloud platforms and services (e.g., AWS, Azure, GCP). \n  Strong analytical and problem-solving skills. \n  Excellent communication and collaboration abilities. ", "techs": ["javascript", "node.js", "python", "tensorflow", "pytorch", "aws", "azure", "gcp"]}, "4cd21f0e70c040c1": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Actuary (Remote, US)", "company": "Openly", "desc": "Openly is rebuilding insurance from the ground up. We are re-envisioning and enhancing every aspect of the customer experience. Doing this requires a rapidly growing team of exceptional, curious, empathetic people with a wide range of skill sets, spanning technology, data science, product, marketing, sales, service, claims handling, finance, etc. \n  Now is the perfect time to join the journey. Here's why \n \n It's working . We're in multiple states and on our way to operating countrywide. We have thousands of agents selling our product and millions of dollars of annual customer premiums. \n We're well-backed & stable.  We closed our $100M Series D fundraise. We are supported by some of the top investors globally, including Google's \"Gradient\" AI-focused fund, Obvious Ventures, Advance Venture Partners, Eden Global Partners, and Clocktower Technology Ventures. \n It's not too late!  Despite this traction and stability, we're still early enough in the journey that there's time to make a real difference during Openly's formative period. \n \n If you'd like to understand more about Openly's mission, consider checking out this video (https://vimeo.com/267654520) from a company pitch we gave several years ago at Techstars. \n \n  Job Details \n  We are seeking a  Actuary  to lead insurance product forecasting. You will play a critical role in guiding strategic decisions across insurance product, reinsurance, and operations by providing insight into various future growth and profitability outcomes. In addition to thoroughly evaluating our data and performing comprehensive scenario analyses, we will look to you to drive the continuous improvement of the underlying forecasting models to best leverage our rapidly growing data volume using the latest technology & prediction methods. As a member of the Actuarial & Product Analysis team within Insurance Product Research, you will have the support of Actuarial Engineering and Data Science. We are looking for a self-motivated, high-energy individual who thrives in a fast-paced, performance-driven environment. \n  Our tech stack consists of GitHub, GCP/BigQuery, Python. \n  Key Responsibilities \n \n Spearheading our loss and premium forecasting capabilities, revolutionizing our approach to monitor actual outcomes, uncover insights, and translate them into valuable recommendations for product enhancement to help drive success of the organization. \n Collaborate closely with our Actuarial and Prediction Engineering teams, leveraging advanced modeling tools to construct a durable forecasting framework, harnessing the power of cutting-edge technology and data-driven insights to develop a robust system that enables accurate and insightful forecasts. \n Support the refinement of our actuarial analytical framework by contributing to the design of enhancements or exploring the development of fresh methodologies and approaches. \n Design and develop a resilient methodology for projecting catastrophe losses that can adapt and expand in tandem with our growth. \n Collaborate cross-functionally to acquire valuable insights into drivers of our profitability and offer useful feedback based on our comprehensive analyses. \n Mentor, guide, and support junior team members \u2013 utilize your experience and expertise to share valuable insights, provide constructive feedback, and help cultivate their skills and growth. \n \n Requirements \n \n ACAS/FCAS with 7+ years of actuarial experience \n Significant experience in personal lines insurance or actuarial forecasting. \n Experience working in SQL. \n Demonstrated aptitude for working in Python. \n Ability to operate in ambiguity \u2013 identifying/defining complex business problems and developing creative analytical solutions. \n Strong communication and collaboration skills. \n Strong decision-making skills. \n \n #LI-CB1 \n \n  Benefits & Perks \n \n Remote-First Culture - We supported #remotelife long before it was a given. We'll keep promoting it. \n Competitive Salary & Equity \n Comprehensive Medical, Dental, and Vision Plan Offerings \n Life and disability coverage including voluntary options \n Competitive PTO - 20 days and 11 paid holidays (including floating holidays) per year under the Company's vacation and holiday policies.  \n Parental Leave - 12 weeks paid for eligible employees \n 401K Company Contribution - Openly contributes 3% of the employee's gross income, even if the employee does not contribute. \n Work-from-home stipend - We provide a $1,500 allowance to spend on setting up your home workplace \n Annual Professional Development Fund: Each employee has $2,000 in professional development (PD) funds to spend on activities or resources annually. We want each Openly employee to achieve personal and professional success and to feel supported, confident, and informed about improving their efficiency and productivity. \n Be Well Program - Employees receive $50 per month to use towards your overall well-being \n Paid Volunteer Service Hours \n Referral Program and Reward \n \n Depending on position, Employees generally are eligible for cash incentive compensation, including commissions for sales eligible roles. In all cases, eligibility for compensation and benefits is subject to applicable plan and policy terms in effect from time to time. \n  U.S. Citizens, Green Card Holders, and those authorized to work in the U.S. for any employer and currently residing in the US will be considered. \n  Openly is committed to equal employment opportunity and non-discrimination for all employees and qualified applicants without regard to a person's race, color, sex, gender identity or expression, age, religion, national origin, ancestry, ethnicity, disability, veteran status, genetic information, sexual orientation, marital status, or any characteristic protected under applicable law. Openly is an E-Verify Employer in the United States. Openly will make reasonable accommodations for qualified individuals with known disabilities under applicable law.", "cleaned_desc": " \n Requirements \n \n ACAS/FCAS with 7+ years of actuarial experience \n Significant experience in personal lines insurance or actuarial forecasting. \n Experience working in SQL. \n Demonstrated aptitude for working in Python. \n Ability to operate in ambiguity \u2013 identifying/defining complex business problems and developing creative analytical solutions. \n Strong communication and collaboration skills. \n Strong decision-making skills. ", "techs": ["acas/fcas", "sql", "python"]}, "246bbabbac0b39d5": {"terms": ["data science"], "salary_min": 114444.88, "salary_max": 144912.72, "title": "Data Scientist - GameOps (MLB)", "company": "PrizePicks", "desc": "At PrizePicks, we are the fastest growing sports company in North America, as recognized by Inc. 5000. As the leading platform for Daily Fantasy Sports, we cover a diverse range of sports leagues, including the NFL, NBA, and Esports titles like League of Legends and CS:GO. Our team of over 350 employees thrives in an inclusive culture that values individuals from diverse backgrounds, regardless of their level of sports fandom. Ready to reimagine the DFS industry together? \n \n  The Analytics Team is responsible for building and maintaining analytics tools and workflows to support the PrizePicks business across all departments - at the core of these operations is data and the insights driven from that data. PrizePicks is looking for a Data Scientist with 2+ years of experience to join our Data Science team. You will be working closely with other data scientists, reporting analysts, and cross departmental directors to test business flows, make business recommendations, and provide novel business insights to leadership focused on driving revenue growth, optimizing marketing efficiency and optimizing retention efforts. \n  What you'll do: \n \n Lead data cleaning, wrangling, and visualization efforts for our baseball tech stack. \n Develop advanced data simulations to predict outcomes of upcoming baseball games. \n Guide feature selection and optimize classifiers. \n Design processes and tools for monitoring model performance and data accuracy. \n Contribute to research and innovation in data science initiatives. \n \n What you have: \n \n Expertise in machine learning, data analysis, and statistical modeling, specifically with respect to baseball. \n Strong understanding of how baseball is played and modeled within data. \n Proficiency in statistics and statistical software (e.g., Python, R). \n Strong experience with relational databases like PostgreSQL. \n Preferred skills in data visualization and report building. \n Outstanding analytical and problem-solving capabilities. \n 2+ years of experience working with sports modeling, with an emphasis on baseball specifically. \n \n Where you'll live: \n \n Anywhere in the US is fine but Atlanta would be preferred. \n \n Benefits you'll receive: \n  In addition to your great compensation package, company subsidized medical/dental/vision coverage plans and matching 401(k), we'll shower you with perks including: \n \n Break room with ping pong, endless snacks and in-office lunch once a week \n Unlimited PTO to encourage a healthy work/life balance (2 week min required!) \n Modern work schedule focused on getting the job done, not hours clocked \n Workplace flexibility  \n Company and team outings, we encourage a tight-knit workplace \n Generous Maternity AND Paternity leave (16 weeks!) \n Annual bonus & stock options  \n Wellness program \n Company equipment provided (Windows & Mac options) \n Annual performance reviews with opportunity for growth and career development \n \n \n \n  You must be authorized to work for any employer in the U.S. We are unable to sponsor or take over sponsorship of an employment Visa at this time. \n  PrizePicks is an Equal Opportunity Employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.", "cleaned_desc": " Design processes and tools for monitoring model performance and data accuracy. \n Contribute to research and innovation in data science initiatives. \n \n What you have: \n \n Expertise in machine learning, data analysis, and statistical modeling, specifically with respect to baseball. \n Strong understanding of how baseball is played and modeled within data. \n Proficiency in statistics and statistical software (e.g., Python, R).   Strong experience with relational databases like PostgreSQL. \n Preferred skills in data visualization and report building. \n Outstanding analytical and problem-solving capabilities. \n 2+ years of experience working with sports modeling, with an emphasis on baseball specifically. \n \n Where you'll live: \n \n Anywhere in the US is fine but Atlanta would be preferred. ", "techs": ["python", "r", "postgresql"]}, "cb2ae987b985b4aa": {"terms": ["data science", "machine learning engineer"], "salary_min": 144470.88, "salary_max": 182932.31, "title": "Machine Learning Engineer", "company": "Cisco Systems", "desc": "Who We Are \n \n \n   We are a part of Outshift by Cisco focused on identifying breakthrough emerging solutions that create new markets and businesses for Cisco. We incubate these new opportunities in partnership with our business groups, corporate partners, and other startups. The team also continues to progress Cisco\u2019s important work with Standards bodies and runs research partnerships with groundbreaking Universities.\n  \n \n   Our organization is anticipating high growth. We are seeking talent with the agility and creativity to explore opportunities and fill in needs as they arise across our teams. Applicants should be seeking a flexible role, in which they not only provide leadership in their primary function, but also contribute in meaningful ways to other projects. We are looking for individuals who are passionate about shifting quickly to different domains that may be outside of their normal scope of responsibilities.\n  \n \n   Learn more about us at https://outshift.com.\n  \n \n \n  Who You'll Work With \n \n \n   The Outshift team is a highly visible team within Cisco. Outshift focuses on the next wave of innovation by anticipating, investing in, and incubating new technologies and business ventures. You will be part of the incubation team to develop new products and bring them to market in a startup-like environment.\n  \n \n \n  What You'll Do \n \n \n   In this role, you will work in an innovative team, apply and advance powerful AI technologies in products that make tangible business impacts, create the latest AI-powered user experiences on various platforms, work alongside a committed generative AI product management team, gain expertise in the most in-demand AI domains for the future, and contribute to shaping Cisco\u2019s AI strategies for the next decade. You will also collaborate across teams within Cisco, to drive a common AI strategy across the company.\n  \n \n \n  The Impact You\u2019ll Make \n \n \n   Want the challenge of fast-paced growth along with the happiness of seeing thoughtful ideas come to life? The pride in helping grow a world-class AI team. This is the place for you!\n  \n \n \n  Your responsibilities will include \n \n \n   Design and develop end-to-end products to enable easy adoption of generative AI for enterprises.\n  \n \n   Collaborate with multi-functional teams including product managers, applied scientists, and other engineers and identify and implement the most effective system design and solutions.\n  \n \n   Design and build services and integrations for ML pipelines for LLM fine-tuning, prompt tuning and engineering, Benchmarking and RAG for various generative AI models.\n  \n \n   Stay up to date with the latest advancements in the field of AI and apply them to develop cutting- edge solutions.\n  \n \n \n  Minimum Requirements \n \n \n   Bachelor's degree or equivalent experience in Computer Science, Computer Engineering, Statistics, or a related field.\n  \n \n   7+ years strong programming skills in Java, C++, Python or other related languages.\n  \n \n   5+ years deep coding experience in developing and delivering complex, distributed, enterprise class software.\n  \n \n   Understanding of infrastructure needed for building and adoption of Large Language Models, Natural Language Processing, Computer Vision, Image Processing, and generative AI techniques \n  \n \n \n Preferred Requirements \n \n \n   Strong problem-solving skills and ability to work independently or in a team.\n  \n \n   Comfortable and capable of interacting with technologists as with business executives.\n  \n \n   Excellent verbal and written communication skills.\n  \n \n \n  Why Cisco? \n \n \n \n   #WeAreCisco. We are all unique, but collectively we bring our talents to work as a team, to develop innovative technology and power a more inclusive, digital future for everyone. How do we do it? Well, for starters \u2013 with people like you!\n  \n \n \n   Nearly every internet connection around the world touches Cisco. We\u2019re the Internet\u2019s optimists. Our technology makes sure the data travelling at light speed across connections does so securely, yet it\u2019s not what we make but what we make happen which marks us out. We\u2019re helping those who work in the health service to connect with patients and each other; schools, colleges, and universities to teach in even the most challenging of times. We\u2019re helping businesses of all shapes and size to connect with their employees and customers in new ways, providing people with access to the digital skills they need and connecting the most remote parts of the world \u2013 whether through 5G, or otherwise.\n  \n \n \n   We tackle whatever challenges come our way. We have each other\u2019s backs, we recognize our accomplishments, and we grow together. We celebrate and support one another \u2013 from big and small things in life to big career moments. And giving back is in our DNA (we get 10 days off each year to do just that).\n  \n \n \n   We know that powering an inclusive future starts with us. Because without diversity and a dedication to equality, there is no moving forward. Our 30 Inclusive Communities, that bring people together around commonalities or passions, are leading the way. Together we\u2019re committed to learning, listening, caring for our communities, whilst supporting the most vulnerable with a collective effort to make this world a better place either with technology, or through our actions.\n  \n \n \n   So, you have colorful hair? Don\u2019t care. Tattoos? Show off your ink. Like polka dots? That\u2019s cool. Pop culture geek? Many of us are. Passion for technology and world changing? Be you, with us! #WeAreCisco\n  \n \n \n  #LI-TA2\n  \n \n   #LI-Remote\n  \n \n \n \n Message to applicants applying to work in the U.S.: \n \n \n \n  When available, the salary range posted for this position reflects the projected hiring range for new hire, full-time salaries in U.S. locations, not including equity or benefits. For non-sales roles the hiring ranges reflect base salary only; employees are also eligible to receive annual bonuses. Hiring ranges for sales positions include base and incentive compensation target. Individual pay is determined by the candidate's hiring location and additional factors, including but not limited to skillset, experience, and relevant education, certifications, or training. Applicants may not be eligible for the full salary range based on their U.S. hiring location. The recruiter can share more details about compensation for the role in your location during the hiring process.\n  \n \n  U.S. employees have \n   access  to quality medical, dental and vision insurance, a 401(k) plan with a Cisco matching contribution, short and long-term disability coverage, basic life insurance and numerous wellbeing offerings. Employees receive up to twelve paid holidays per calendar year, which includes one floating holiday, plus a day off for their birthday. Employees accrue up to 20 days of Paid Time Off (PTO) each year and have access to paid time away to deal with critical or emergency issues without tapping into their PTO. We offer additional paid time to volunteer and give back to the community. Employees are also able to purchase company stock through our Employee Stock Purchase Program.\n  \n \n  Employees on sales plans earn performance-based incentive pay on top of their base salary, which is split between quota and non-quota components. For quota-based incentive pay, Cisco pays at the standard rate of 1% of incentive target for each 1% revenue attainment against the quota up to 100%. Once performance exceeds 100% quota attainment, incentive rates may increase up to five times the standard rate with no cap on incentive compensation. For non-quota-based sales performance elements such as strategic sales objectives, Cisco may pay up to 125% of target. Cisco sales plans do not have a minimum threshold of performance for sales incentive compensation to be paid.", "cleaned_desc": "  \n \n \n  The Impact You\u2019ll Make \n \n \n   Want the challenge of fast-paced growth along with the happiness of seeing thoughtful ideas come to life? The pride in helping grow a world-class AI team. This is the place for you!\n  \n \n \n  Your responsibilities will include \n \n \n   Design and develop end-to-end products to enable easy adoption of generative AI for enterprises.\n  \n \n   Collaborate with multi-functional teams including product managers, applied scientists, and other engineers and identify and implement the most effective system design and solutions.\n  \n \n   Design and build services and integrations for ML pipelines for LLM fine-tuning, prompt tuning and engineering, Benchmarking and RAG for various generative AI models.\n  \n \n   Stay up to date with the latest advancements in the field of AI and apply them to develop cutting- edge solutions.\n    \n \n  Minimum Requirements \n \n \n   Bachelor's degree or equivalent experience in Computer Science, Computer Engineering, Statistics, or a related field.\n  \n \n   7+ years strong programming skills in Java, C++, Python or other related languages.\n  \n \n   5+ years deep coding experience in developing and delivering complex, distributed, enterprise class software.\n  \n \n   Understanding of infrastructure needed for building and adoption of Large Language Models, Natural Language Processing, Computer Vision, Image Processing, and generative AI techniques \n  \n \n \n Preferred Requirements \n \n \n   Strong problem-solving skills and ability to work independently or in a team.\n  \n ", "techs": ["java", "c++", "python", "large language models", "natural language processing", "computer vision", "image processing", "generative ai techniques"]}, "09c2b8daf2ec2dd9": {"terms": ["data science", "machine learning engineer"], "salary_min": 144470.88, "salary_max": 182932.31, "title": "Machine Learning Engineer", "company": "Cisco Systems", "desc": "Who We Are \n \n \n   We are a part of Outshift by Cisco focused on identifying breakthrough emerging solutions that create new markets and businesses for Cisco. We incubate these new opportunities in partnership with our business groups, corporate partners, and other startups. The team also continues to progress Cisco\u2019s important work with Standards bodies and runs research partnerships with groundbreaking Universities.\n  \n \n   Our organization is anticipating high growth. We are seeking talent with the agility and creativity to explore opportunities and fill in needs as they arise across our teams. Applicants should be seeking a flexible role, in which they not only provide leadership in their primary function, but also contribute in meaningful ways to other projects. We are looking for individuals who are passionate about shifting quickly to different domains that may be outside of their normal scope of responsibilities.\n  \n \n   Learn more about us at https://outshift.com.\n  \n \n \n  Who You'll Work With \n \n \n   The Outshift team is a highly visible team within Cisco. Outshift focuses on the next wave of innovation by anticipating, investing in, and incubating new technologies and business ventures. You will be part of the incubation team to develop new products and bring them to market in a startup-like environment.\n  \n \n \n  What You'll Do \n \n \n   In this role, you will work in an innovative team, apply and advance powerful AI technologies in products that make tangible business impacts, create the latest AI-powered user experiences on various platforms, work alongside a committed generative AI product management team, gain expertise in the most in-demand AI domains for the future, and contribute to shaping Cisco\u2019s AI strategies for the next decade. You will also collaborate across teams within Cisco, to drive a common AI strategy across the company.\n  \n \n \n  The Impact You\u2019ll Make \n \n \n   Want the challenge of fast-paced growth along with the happiness of seeing thoughtful ideas come to life? The pride in helping grow a world-class AI team. This is the place for you!\n  \n \n \n  Your responsibilities will include \n \n \n   Design and develop end-to-end products to enable easy adoption of generative AI for enterprises.\n  \n \n   Collaborate with multi-functional teams including product managers, applied scientists, and other engineers and identify and implement the most effective system design and solutions.\n  \n \n   Design and build services and integrations for ML pipelines for LLM fine-tuning, prompt tuning and engineering, Benchmarking and RAG for various generative AI models.\n  \n \n   Stay up to date with the latest advancements in the field of AI and apply them to develop cutting- edge solutions.\n  \n \n \n  Minimum Requirements \n \n \n   Bachelor's degree or equivalent experience in Computer Science, Computer Engineering, Statistics, or a related field.\n  \n \n   7+ years strong programming skills in Java, C++, Python or other related languages.\n  \n \n   5+ years deep coding experience in developing and delivering complex, distributed, enterprise class software.\n  \n \n   Understanding of infrastructure needed for building and adoption of Large Language Models, Natural Language Processing, Computer Vision, Image Processing, and generative AI techniques \n  \n \n \n Preferred Requirements \n \n \n   Strong problem-solving skills and ability to work independently or in a team.\n  \n \n   Comfortable and capable of interacting with technologists as with business executives.\n  \n \n   Excellent verbal and written communication skills.\n  \n \n \n  Why Cisco? \n \n \n \n   #WeAreCisco. We are all unique, but collectively we bring our talents to work as a team, to develop innovative technology and power a more inclusive, digital future for everyone. How do we do it? Well, for starters \u2013 with people like you!\n  \n \n \n   Nearly every internet connection around the world touches Cisco. We\u2019re the Internet\u2019s optimists. Our technology makes sure the data travelling at light speed across connections does so securely, yet it\u2019s not what we make but what we make happen which marks us out. We\u2019re helping those who work in the health service to connect with patients and each other; schools, colleges, and universities to teach in even the most challenging of times. We\u2019re helping businesses of all shapes and size to connect with their employees and customers in new ways, providing people with access to the digital skills they need and connecting the most remote parts of the world \u2013 whether through 5G, or otherwise.\n  \n \n \n   We tackle whatever challenges come our way. We have each other\u2019s backs, we recognize our accomplishments, and we grow together. We celebrate and support one another \u2013 from big and small things in life to big career moments. And giving back is in our DNA (we get 10 days off each year to do just that).\n  \n \n \n   We know that powering an inclusive future starts with us. Because without diversity and a dedication to equality, there is no moving forward. Our 30 Inclusive Communities, that bring people together around commonalities or passions, are leading the way. Together we\u2019re committed to learning, listening, caring for our communities, whilst supporting the most vulnerable with a collective effort to make this world a better place either with technology, or through our actions.\n  \n \n \n   So, you have colorful hair? Don\u2019t care. Tattoos? Show off your ink. Like polka dots? That\u2019s cool. Pop culture geek? Many of us are. Passion for technology and world changing? Be you, with us! #WeAreCisco\n  \n \n \n  #LI-TA2\n  \n \n   #LI-Remote\n  \n \n \n \n Message to applicants applying to work in the U.S.: \n \n \n \n  When available, the salary range posted for this position reflects the projected hiring range for new hire, full-time salaries in U.S. locations, not including equity or benefits. For non-sales roles the hiring ranges reflect base salary only; employees are also eligible to receive annual bonuses. Hiring ranges for sales positions include base and incentive compensation target. Individual pay is determined by the candidate's hiring location and additional factors, including but not limited to skillset, experience, and relevant education, certifications, or training. Applicants may not be eligible for the full salary range based on their U.S. hiring location. The recruiter can share more details about compensation for the role in your location during the hiring process.\n  \n \n  U.S. employees have \n   access  to quality medical, dental and vision insurance, a 401(k) plan with a Cisco matching contribution, short and long-term disability coverage, basic life insurance and numerous wellbeing offerings. Employees receive up to twelve paid holidays per calendar year, which includes one floating holiday, plus a day off for their birthday. Employees accrue up to 20 days of Paid Time Off (PTO) each year and have access to paid time away to deal with critical or emergency issues without tapping into their PTO. We offer additional paid time to volunteer and give back to the community. Employees are also able to purchase company stock through our Employee Stock Purchase Program.\n  \n \n  Employees on sales plans earn performance-based incentive pay on top of their base salary, which is split between quota and non-quota components. For quota-based incentive pay, Cisco pays at the standard rate of 1% of incentive target for each 1% revenue attainment against the quota up to 100%. Once performance exceeds 100% quota attainment, incentive rates may increase up to five times the standard rate with no cap on incentive compensation. For non-quota-based sales performance elements such as strategic sales objectives, Cisco may pay up to 125% of target. Cisco sales plans do not have a minimum threshold of performance for sales incentive compensation to be paid.", "cleaned_desc": "  \n \n \n  The Impact You\u2019ll Make \n \n \n   Want the challenge of fast-paced growth along with the happiness of seeing thoughtful ideas come to life? The pride in helping grow a world-class AI team. This is the place for you!\n  \n \n \n  Your responsibilities will include \n \n \n   Design and develop end-to-end products to enable easy adoption of generative AI for enterprises.\n  \n \n   Collaborate with multi-functional teams including product managers, applied scientists, and other engineers and identify and implement the most effective system design and solutions.\n  \n \n   Design and build services and integrations for ML pipelines for LLM fine-tuning, prompt tuning and engineering, Benchmarking and RAG for various generative AI models.\n  \n \n   Stay up to date with the latest advancements in the field of AI and apply them to develop cutting- edge solutions.\n    \n \n  Minimum Requirements \n \n \n   Bachelor's degree or equivalent experience in Computer Science, Computer Engineering, Statistics, or a related field.\n  \n \n   7+ years strong programming skills in Java, C++, Python or other related languages.\n  \n \n   5+ years deep coding experience in developing and delivering complex, distributed, enterprise class software.\n  \n \n   Understanding of infrastructure needed for building and adoption of Large Language Models, Natural Language Processing, Computer Vision, Image Processing, and generative AI techniques \n  \n \n \n Preferred Requirements \n \n \n   Strong problem-solving skills and ability to work independently or in a team.\n  \n ", "techs": ["java", "c++", "python", "large language models", "natural language processing", "computer vision", "image processing", "generative ai"]}, "ecc2c4106e00506a": {"terms": ["data science", "data analyst", "machine learning engineer"], "salary_min": 116236.48, "salary_max": 147181.28, "title": "Senior Staff Data Analyst and Visualization Developer - (Remote)", "company": "Stryker", "desc": "Why engineering at Stryker? \n  At Stryker we are dedicated to improving lives, with a passion for researching and developing new medical device products. As an engineer at Stryker, you will be proud of the work that you will be doing, using cutting-edge technologies to make healthcare better. Here, you will work in a supportive culture with other incredibly talented and intelligent people, creating industry-leading medical technology products. You will also have growth opportunities as we have a culture that supports your personal and professional development. \n  Need another reason to apply?  Check out these 8 reasons to join Stryker's engineering team:   https://www.strykercareersblog.com/post/8-reasons-to-join-strykers-engineering-team \n  We are proud to be named one of the World\u2019s Best Workplaces and a Best Workplace for Diversity by Fortune Magazine! Learn more about our award-winning organization by visiting  stryker.com \n \n  Our Data Intelligence R&D team is responsible for data engineering, data analytics, data science, and anatomy and computer vision capabilities, helping Stryker accelerate time to market, maximize the potential of current platforms, and provide new and innovative solutions to make healthcare better. \n \n  We are looking for an ambitious and self-motivated Senior Data Analyst specialized on Medical Data Visualization. In this exciting role, you will provide advanced analytics by gathering, organizing, and visualizing clinical and device data to test hypotheses, understanding relationships within the data, and reaching meaningful conclusions. You will present your findings, leveraging compelling storytelling and visualizations to drive decision-making by senior leaders and stakeholders. As you will be leading technically demanding projects, you should have the flexibility and communication skills to operate effectively within a team of experts. \n \n  This role offers a fascinating opportunity for the right candidate to work with cutting-edge technology in a supportive culture with other incredibly talented and intelligent people, creating industry-leading medical technology products. \n \n  Who We Want: \n \n  Data managers. People who enjoy compiling, organizing, and consolidating large volumes of data and reports. \n  Business-oriented evaluators. People who effectively interpret information to demonstrate the effects of business initiatives, regulation and industry trends for sales, management, and leadership teams. \n  Strategic thinkers. People who enjoy analyzing data or trends for the purposes of planning, forecasting, advising, budgeting, reporting, or sales opportunities. \n \n \n  What You Will Do: \n \n  Discover information hidden in clinical data and reports to derive value for medical products and services. \n  Perform a variety of data mining and data analysis tasks (e.g. ad hoc reporting, root cause analysis, hypothesis testing, statistical modeling, and forecasting) \n  Access, organize, and analyze data from multiple internal and external data stores. \n  Lead the creation and maintenance of data catalogs and dictionaries. \n  Apply statistical methods, such as regression analysis, conduct hypothesis tests, create derived metrics, and visualize relevant information. \n  Create documentation that allows stakeholders to understand the steps of the data analysis process and duplicate or replicate the analysis if necessary. \n  Generate enhanced data visualizations for internal and external customers. \n  Collaborate with stakeholders throughout the organization including clinical research, advanced technology, product development and marketing as well as various customers to understand their needs. \n \n \n  What You Will Need: \n \n  Bachelors degree in Data Analytics, Data Science, Applied Sciences, or a related discipline. \n  6+ years of professional experience as a Data Analyst or comparable work in a healthcare or medical technology environment, with an understanding of regulatory and privacy frameworks such as PHI/PII applied to medical data. \n  Proven record of successful end-to-end data analysis project management: from problem and requirements definition to data validation and results presentation. \n  Proficiency with one or more enterprise BI technologies. (Microsoft Power BI \u2013 preferred, Tableau, MicroStrategy, Oracle BI.) \n  Intermediate level proficiency with an ANSI compliant structured query language. (e.g. simple joins, filters, subqueries, aggregations, etc.) \n  Strong background in common programming languages for data mining and modelling, preferably R or Python. \n  Familiarity with the basic concepts of relational data modelling and database design. \n  Intermediate understanding of statistical and machine learning concepts (e.g. hypothesis testing, correlation analysis, regression analysis, time series forecasting, and predictive modeling.) \n  Comfortable working with structured and semi-structured data. \n  Ability to create enhanced data visualization in ways that are universally understandable, easy to interpret and spot patterns, trends, and correlations as well as suggestion to improve processes. \n  Effective communication skills (story telling) and ability to present complex analytics to stakeholders and customers. \n  Excellent verbal and written English. \n \n \n  $95,100 - $204,00 salary plus bonus eligible + benefits. Actual minimum and maximum may vary based on location. Individual pay is based on skills, experience, and other relevant factors. \n  About Stryker \n  Our benefits:   \n \n 12 paid holidays annually   \n Health benefits include: Medical and prescription drug insurance, dental insurance, vision insurance, critical illness insurance, accident insurance, hospital indemnity insurance, personalized healthcare support, wellbeing program and tobacco cessation program.   \n Financial benefits include Health Savings Account (HSA), Flexible Spending Accounts (FSAs), 401(k) plan, Employee Stock Purchase Plan (ESPP), basic life and AD&D insurance, and short-term disability insurance.   \n \n For a more detailed overview of our benefits or time off, please follow this link to learn more: US Stryker employee benefits     About Stryker  Stryker is one of the world\u2019s leading medical technology companies and, together with its customers, is driven to make healthcare better. The company offers innovative products and services in Medical and Surgical, Neurotechnology, Orthopaedics and Spine that help improve patient and healthcare outcomes. Alongside its customers around the world, Stryker impacts more than 130 million patients annually. More information is available at stryker.com.     Know someone at Stryker?  Be sure to have them submit you as a referral prior to applying for this position. Learn more about our employee referral program on our referral page    Stryker is driven to work together with our customers to make healthcare better. Employees and new hires in sales and field roles that require access to customer accounts as a function of the job may be required, depending on customer requirements, to obtain various vaccinations as an essential function of their role.", "cleaned_desc": "  Discover information hidden in clinical data and reports to derive value for medical products and services. \n  Perform a variety of data mining and data analysis tasks (e.g. ad hoc reporting, root cause analysis, hypothesis testing, statistical modeling, and forecasting) \n  Access, organize, and analyze data from multiple internal and external data stores. \n  Lead the creation and maintenance of data catalogs and dictionaries. \n  Apply statistical methods, such as regression analysis, conduct hypothesis tests, create derived metrics, and visualize relevant information. \n  Create documentation that allows stakeholders to understand the steps of the data analysis process and duplicate or replicate the analysis if necessary. \n  Generate enhanced data visualizations for internal and external customers. \n  Collaborate with stakeholders throughout the organization including clinical research, advanced technology, product development and marketing as well as various customers to understand their needs. \n \n    What You Will Need: \n \n  Bachelors degree in Data Analytics, Data Science, Applied Sciences, or a related discipline. \n  6+ years of professional experience as a Data Analyst or comparable work in a healthcare or medical technology environment, with an understanding of regulatory and privacy frameworks such as PHI/PII applied to medical data. \n  Proven record of successful end-to-end data analysis project management: from problem and requirements definition to data validation and results presentation. \n  Proficiency with one or more enterprise BI technologies. (Microsoft Power BI \u2013 preferred, Tableau, MicroStrategy, Oracle BI.) \n  Intermediate level proficiency with an ANSI compliant structured query language. (e.g. simple joins, filters, subqueries, aggregations, etc.) \n  Strong background in common programming languages for data mining and modelling, preferably R or Python. \n  Familiarity with the basic concepts of relational data modelling and database design. \n  Intermediate understanding of statistical and machine learning concepts (e.g. hypothesis testing, correlation analysis, regression analysis, time series forecasting, and predictive modeling.) ", "techs": ["microsoft power bi", "tableau", "microstrategy", "oracle bi", "r", "python"]}, "cb1d5408f8f7d013": {"terms": ["data science", "mlops"], "salary_min": 153000.0, "salary_max": 191300.0, "title": "AI Engineering Manager", "company": "Agilon Health", "desc": "Company:\n   AHI agilon health, inc.\n  \n \n   Job Posting Location:\n   Remote - USA\n  \n \n   Job Title: \n  AI Engineering Manager\n  \n \n   Job Description: \n  \n \n  agilon health is transforming healthcare by empowering community-based physicians with the resources and expertise they need to innovate the payment and delivery of care for seniors.\n  \n \n \n   The agilon health Total Care Model is powered by our purpose-built platform and frees physicians from the constraints of the traditional fee-for-service reimbursement model, all enabled through a growing national network of like-minded physician partners.\n  \n \n \n   With agilon health, physicians are able to practice team-based, coordinated care to serve the individual needs of their senior patients and to transition to a sustainable and predictable, long-term business model.\n  \n \n \n   As you might imagine, analytics and insights are the heart of how we support our physician partners and is agilon\u2019s special sauce. We have a strong team in place already and are looking for someone to help lead the AI team in solving some of the hardest problems in healthcare.\n  \n \n \n   The team builds traditional predictive and learning ML models across many different business problems to drive targeted and actionable insights and is also looking to apply LLMs to solve our strategic needs, so you will gain exposure to and will be able to make an impact in a large number of domains.\n  \n \n \n   You will coach the team, engage with stakeholders, and have the opportunity to make your own contributions with direct line of sight to improving patient outcomes and reducing medical waste. Come join the team and help make a meaningful impact in our senior members\u2019 lives!\n  \n \n \n   More about this role:\n  \n \n \n Lead an agile AI team in designing, training, and deploying models to support a wide range of health care use cases. \n Build strong collaborations with agilon\u2019s leadership and many different cross-functional teams, including UX, Product, Technology, Clinical, Medical Programs, Finance, and Operations. \n Drive successful project execution and clinical and business value delivery. \n Mentor data scientists to grow and live up to their full potential, and coach high-performing engineering teams. \n Provide guidance to your team on code quality, model training, and MLOps workflows in production. \n \n \n \n   Qualifications:\n  \n \n \n Advanced degree (PhD, MS, MBA, MD) and at least five years of experience working in production environments. \n Strong record of delivering value from machine learning projects. \n Proven experience leading teams and collaborating with stakeholders in an agile setting. \n Three years of experience with machine learning and deep learning models, ideally with hands-on experience with large language models (LLMs) or other forms of generative AI. \n Fluent with Python and SQL. \n Comfortable with AWS and hands-on experience with AWS managed services \n Ability to consistently achieve results, even under tough circumstances. \n Excellent communicator and a nimble learner. \n \n \n \n   If you have an entrepreneurial spirit, a record of leading successful machine learning projects, and are excited about leveraging technology to have a meaningful impact on doctors and patients, we would love to hear from you.\n  \n \n   Location: \n  Remote - MA\n  \n \n   Pay Range: \n  $153,000.00 - $191,300.00\n  \n \n   Salary range shown is a guideline. Individual compensation packages can vary based on factors unique to each candidate, such as skill set, experience, and qualifications.", "cleaned_desc": " Drive successful project execution and clinical and business value delivery. \n Mentor data scientists to grow and live up to their full potential, and coach high-performing engineering teams. \n Provide guidance to your team on code quality, model training, and MLOps workflows in production. \n \n \n \n   Qualifications:\n  \n \n \n Advanced degree (PhD, MS, MBA, MD) and at least five years of experience working in production environments. \n Strong record of delivering value from machine learning projects. \n Proven experience leading teams and collaborating with stakeholders in an agile setting. \n Three years of experience with machine learning and deep learning models, ideally with hands-on experience with large language models (LLMs) or other forms of generative AI. \n Fluent with Python and SQL. ", "techs": ["python", "sql"]}, "67f59c94a69b9f6f": {"terms": ["data science"], "salary_min": 120000.0, "salary_max": 130000.0, "title": "ServiceNow Solutions Engineer / Business Solution Analyst", "company": "Kanini Software Solutions", "desc": "About Kanini \n Kanini provides Agile Software Development, Cloud Computing, Data Science, and Location Intelligence services to public and private organizations. We have successfully served our clients in government, finance, transportation, utility, and software industries since 2003. \n Why you should join \n Working at Kanini is flexible and personal. We are a highly motivated, collaborative team experimenting with the latest technologies. We are committed to everyone having a healthy work/life balance, and we provide extensive mentorship and training resources to help you succeed. \n Kanini is looking for a  ServiceNow Solution Service Engineer /    Business Solutions Analyst  who has a deep experience in ServiceNow Solutions Engineering, User Stories. \n Key Responsibilities \n \n ServiceNow Solution Engineering: \n \n \n Design, configure, and customize ServiceNow applications to meet business requirements. \n \n \n Collaborate with stakeholders to gather and document functional and technical requirements. \n \n \n Develop and maintain ServiceNow workflows, scripts, and integrations. \n \n \n Perform system testing and ensure the quality of ServiceNow solutions. \n \n Business Systems Analysis \n \n Analyze existing business processes and systems to identify areas for improvement. \n \n \n Work closely with business stakeholders to understand their needs and translate them into technical solutions. \n \n \n Create detailed documentation, including user stories, process diagrams, and system specifications. \n \n Qualifications \n \n Bachelor\u2019s degree in computer science, Information Technology, or a related field. \n \n \n Proven experience as a ServiceNow Solution Engineer or Business Systems Analyst. \n \n \n ServiceNow certification (e.g., Certified System Administrator, Certified Implementation Specialist) is a plus. \n \n \n Strong analytical and problem-solving skills. \n \n \n Excellent communication and interpersonal skills. \n \n \n Project management experience is desirable. \n \n \n Knowledge of ITIL principles and practices is a plus. \n \n Kanini Software Solutions, Inc. does not discriminate in employment matters based on race, gender, religion, age, national origin, citizenship, veteran status, family status, disability status, or any other protected class. We support workplace diversity. If you have a disability, please let us know if there is anything we can do to improve the interview process for you; we\u2019re happy to accommodate. \n Kanini Software Solutions, Inc., 25 Century Blvd., Ste. 602, Nashville, TN 37214 \n Job Type: Full-time \n Pay: $120,000.00 - $130,000.00 per year \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "1135c1400eced1b6": {"terms": ["data science", "data engineer"], "salary_min": 153879.28, "salary_max": 194845.47, "title": "Lead data engineer \u2013 R01530706", "company": "Brillio", "desc": "Lead data engineer - R01530706 \n \n \n About Brillio:  \n \n \n  Brillio is the partner of choice for many Fortune 1000 companies seeking to turn disruption into a competitive advantage through innovative digital adoption. Backed by Bain Capital, Brillio is one of the fastest growing digital technology service providers. We help clients harness the transformative potential of the four superpowers of technology - cloud computing, internet of things (IoT), artificial intelligence (AI), and mobility. Born digital in 2014, we apply Customer Experience Solutions, Data Analytics and AI, Digital Infrastructure and Security, and Platform and Product Engineering expertise to help clients quickly innovate for growth, create digital products, build service platforms, and drive smarter, data-driven performance. With delivery locations across United States, Romania, Canada, Mexico, and India, our growing global workforce of over 6,000 Brillians blends the latest technology and design thinking with digital fluency to solve complex business problems and drive competitive differentiation for our clients. Brillio was awarded \u2018Great Place to Work\u2019 in 2021 and 2022\n  \n \n \n  Lead data engineer \n \n  Primary Skills \n \n  SNS, SQS, Athena, CloudWatch, Kinesis, Redshift  \n \n Specialization \n \n  AWS Data EngineerIng Advanced: Associate Data Engineer  \n \n Job requirements \n \n  Role:  Lead Data Engineer\n  \n \n  Years of Experience:  10+ years\n  \n \n  Travel Required:  Yes\n  \n \n  Location:  Remote\n  \n \n \n \n   As a consultant within the DIE team, you will work with our clients to define their digital strategy and execution roadmap, and design and implement differentiated digital solutions to help deliver measurable value.\n  \n \n \n \n  Your responsibilities in this role will include: \n \n \n  Primary focus is on Glue, S3, Redshift, Lambda, PySpark, Spark.  \n Then added skillset which could add value are AWS Step function, NoSQL DB like Dynamo DB and AWS Data Migration Service in that order of priority. \n  Data engineer should have at least 2 years of relevant AWS experience with their services mentioned above.  \n Experience in data security or governance and performance improvement is an added benefit \n  Only focus is on AWS services and tech stack.\" \n \n \n \n  Why should you apply for this role? \n \n \n   As Brillio continues to gain momentum as a trusted partner for our clients in their digital transformation journey, we strive to set new benchmarks for speed and value creation. The DIE team at Brillio is at the forefront of leading this charge by reimagining and executing how we structure, sell and deliver our services to better serve our clients.\n  \n \n \n \n   DAE: https://www.brillio.com/services-data-analytics/\n  \n \n \n  Know what it\u2019s like to work and grow at Brillio:https://www.brillio.com/join-us/\n  \n \n \n  Equal Employment Opportunity Declaration \n \n \n   Brillio is an equal opportunity employer to all, regardless of age, ancestry, colour, disability (mental and physical), exercising the right to family care and medical leave, gender, gender expression, gender identity, genetic information, marital status, medical condition, military or veteran status, national origin, political affiliation, race, religious creed, sex (includes pregnancy, childbirth, breastfeeding, and related medical conditions), and sexual orientation.\n  \n \n \n \n   #LI-RJ1\n  \n \n \n \n   Know what it\u2019s like to work and grow at Brillio: Click here", "cleaned_desc": "  \n \n \n \n   As a consultant within the DIE team, you will work with our clients to define their digital strategy and execution roadmap, and design and implement differentiated digital solutions to help deliver measurable value.\n  \n \n \n \n  Your responsibilities in this role will include: \n \n \n  Primary focus is on Glue, S3, Redshift, Lambda, PySpark, Spark.  \n Then added skillset which could add value are AWS Step function, NoSQL DB like Dynamo DB and AWS Data Migration Service in that order of priority. \n  Data engineer should have at least 2 years of relevant AWS experience with their services mentioned above.  \n Experience in data security or governance and performance improvement is an added benefit ", "techs": ["glue", "s3", "redshift", "lambda", "pyspark", "spark", "aws step function", "dynamo db", "aws data migration service"]}, "9318a6d516f3b2b0": {"terms": ["data science"], "salary_min": 95592.484, "salary_max": 121041.39, "title": "Complex Adjuster, Property", "company": "Openly", "desc": "Openly is rebuilding insurance from the ground up. We are re-envisioning and enhancing every aspect of the customer experience. Doing this requires a rapidly growing team of exceptional, curious, empathetic people with a wide range of skill sets, spanning technology, data science, product, marketing, sales, service, claims handling, finance, etc. \n  Now is the perfect time to join the journey. Here's why \n \n It's working . We're in multiple states and on our way to operating countrywide. We have thousands of agents selling our product and millions of dollars of annual customer premiums. \n We're well-backed & stable.  We closed our $100M Series D fundraise. We are supported by some of the top investors globally, including Google's \"Gradient\" AI-focused fund, Obvious Ventures, Advance Venture Partners, Eden Global Partners, and Clocktower Technology Ventures. \n It's not too late!  Despite this traction and stability, we're still early enough in the journey that there's time to make a real difference during Openly's formative period. \n \n If you'd like to understand more about Openly's mission, consider checking out this video (https://vimeo.com/267654520) from a company pitch we gave several years ago at Techstars. \n \n  Job Details \n  Openly is building an advanced claims organization leveraging technology and experienced property claims professionals to build a best-in-class end-to-end customer experience. This role is a remote-only position and applicants must have an adequate working environment. \n  Knowledge, Skills & Abilities : \n \n Full knowledge of insurance contracts, investigation techniques, legal requirements, and insurance regulations \n Ability to work effectively in teams and with a wide variety of people \n An aptitude for evaluating, analyzing, and interpreting information \n Can create estimates and review losses up to $1,000,000+ \n \n Excellent skills in the areas of: \n \n Customer service \n Investigation techniques \n Organization \n Time management and the ability to multitask \n Verbal and written communication \n Negotiation and reserving \n Innovative thinking \n Current Claims Adjuster licenses in one or more states is preferred, but must be able to obtain additional state licenses \n \n Key Responsibilities \n  End-to-end property claims handling to include: \n \n Provide superior customer service \n Investigation and coverage analysis \n Handling and oversight of all aspects of claims including dwelling, contents, ALE, etc \n Complete estimates using CoreLogic estimating software \n Adhering to estimating best practices \n Manage and collaborate with vendor partners \n Determine appropriate method of inspection \n Conduct virtual inspections (video, AI, etc) \n Examines potential subrogation and identifies potential fraudulent issues \n Prepares and maintains file documentation \n Negotiates settlement of claims with insureds, claimants, and vendors \n Discussing and giving updates to insureds, claimants, agents, and leadership throughout the process \n Provide input and ideas for continuous process improvement \n \n Requirements \n \n 10+ years of property claims experience handling large complex losses in excess of $100,000 \n 10+ years in customer service and conflict resolution \n Must be able and eligible to acquire an adjuster license in all required states and maintain it as a condition of continued employment \n Estimating experience in Xactimate, CoreLogic (Symbility), or similar platform \n Experience working independently and in a fast-paced environment \n Proficient in Microsoft and Google Products \n Excellent written and verbal communication skills \n Organization and time management skills \n Innovative Mindset and Continuous Improvement \n Strong negotiation and problem-solving skills \n Must be tech-savvy, as high-end technology tools will be used for adjusting (virtual inspections, estimating, etc) \n Work CAT hours during storm events or times of high volume as needed \n We are a rapidly growing company, and with growth comes change. Candidates must be comfortable with constant change, adaptability and flexibility \n Have experience and success working with public adjusters and attorneys \n Must have experience with formal claim handling, including proof of loss, reservation of rights, etc. \n \n #LI-HK1 \n \n  Benefits & Perks \n \n Remote-First Culture - We supported #remotelife long before it was a given. We'll keep promoting it. \n Competitive Salary & Equity \n Comprehensive Medical, Dental, and Vision Plan Offerings \n Life and disability coverage including voluntary options \n Competitive PTO - 20 days and 11 paid holidays (including floating holidays) per year under the Company's vacation and holiday policies.  \n Parental Leave - 12 weeks paid for eligible employees \n 401K Company Contribution - Openly contributes 3% of the employee's gross income, even if the employee does not contribute. \n Work-from-home stipend - We provide a $1,500 allowance to spend on setting up your home workplace \n Annual Professional Development Fund: Each employee has $2,000 in professional development (PD) funds to spend on activities or resources annually. We want each Openly employee to achieve personal and professional success and to feel supported, confident, and informed about improving their efficiency and productivity. \n Be Well Program - Employees receive $50 per month to use towards your overall well-being \n Paid Volunteer Service Hours \n Referral Program and Reward \n \n Depending on position, Employees generally are eligible for cash incentive compensation, including commissions for sales eligible roles. In all cases, eligibility for compensation and benefits is subject to applicable plan and policy terms in effect from time to time. \n  U.S. Citizens, Green Card Holders, and those authorized to work in the U.S. for any employer and currently residing in the US will be considered. \n  Openly is committed to equal employment opportunity and non-discrimination for all employees and qualified applicants without regard to a person's race, color, sex, gender identity or expression, age, religion, national origin, ancestry, ethnicity, disability, veteran status, genetic information, sexual orientation, marital status, or any characteristic protected under applicable law. Openly is an E-Verify Employer in the United States. Openly will make reasonable accommodations for qualified individuals with known disabilities under applicable law.", "cleaned_desc": " 10+ years of property claims experience handling large complex losses in excess of $100,000 \n 10+ years in customer service and conflict resolution \n Must be able and eligible to acquire an adjuster license in all required states and maintain it as a condition of continued employment \n Estimating experience in Xactimate, CoreLogic (Symbility), or similar platform \n Experience working independently and in a fast-paced environment \n Proficient in Microsoft and Google Products \n Excellent written and verbal communication skills \n Organization and time management skills \n Innovative Mindset and Continuous Improvement \n Strong negotiation and problem-solving skills \n Must be tech-savvy, as high-end technology tools will be used for adjusting (virtual inspections, estimating, etc) \n Work CAT hours during storm events or times of high volume as needed \n We are a rapidly growing company, and with growth comes change. Candidates must be comfortable with constant change, adaptability and flexibility \n Have experience and success working with public adjusters and attorneys \n Must have experience with formal claim handling, including proof of loss, reservation of rights, etc. \n ", "techs": ["xactimate", "corelogic (symbility)", "microsoft", "google products"]}, "127ea16940d5925c": {"terms": ["data science"], "salary_min": 93300.0, "salary_max": 212000.0, "title": "Data Scientist, Senior", "company": "Booz Allen Hamilton", "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Washington,DC,US \n         \n \n \n \n         Remote Work: \n         \n \n         Yes \n         \n \n \n \n         Job Number: \n         \n \n         R0182690\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Data Scientist, Senior\n           The Opportunity: \n  As an analytics professional, you\u2019re excited at the prospect of unlocking the secrets held by a data set, and you\u2019re fascinated by the possibilities presented by IoT, machine learning, and artificial intelligence. If you care about moving a mission forward as much as advancing the field of data science, this is the opportunity for you. Your deep data science and machine learning expertise, coupled with an original approach to your work, will guide clients and stakeholders as they make sense of their data and encourage actionable results. We\u2019re looking for someone like you to land and lead complex data exploration and analytics projects through your experience with machine learning development and deployment for a multitude of use cases in civilian U.S. agencies. \n \n  As an advanced data scientist and researcher on our AI team team, you\u2019ll learn and apply innovative AI and data science methodologies and deployment techniques to make a real-world impact on the mission of our civilian clients. You\u2019ll grow your skills in data science, machine learning operationalization process, business development and shape the future of analytics through a variety of means like white papers, client presentations, and client interactions. \n \n  We\u2019ll keep you sharp and moving forward in your career, with access to online courses, and the latest tools and methods. Whether you\u2019re using AI to find fraud or noncompliance, obtain operational efficiencies, improve citizen experience or other help other mission needs, you\u2019ll guide a team that serves critical missions from end to end. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  5+ years of experience with data science using open source tools such as R or Python \n  Experience creating models using machine learning techniques intended for operational decisions \n  Experience working with and presenting to non-technical clients \n  Experience with persuading stakeholders to take different courses of action \n  Ability to work on business development capabilities independently, including creating presentation, proposal and white paper writing \n  Ability to come up with good solutions or plans to deal with client lack of AI capabilities \n  Ability to create solutions without having specific business requirements \n  Ability to obtain and maintain a Public Trust or Suitability/Fitness determination based on client requirements \n  Bachelor's degree \n \n \n  Nice If You Have: \n \n  Experience with the aspects full life cycle of machine learning development and deployment, including gathering requirements, identifying data, preparing data, building, validating, and using deployable predictive models with the usage having tangible results \n  Experience with providing technical direction and leadership to data scientists \n  Experience with developing predictive models around fraud, risk, or rare events \n  Experience with cloud AI environments, such as Databricks, Azure ML, or AWS Sagemaker \n  Knowledge of Agile and Scrum processes \n  Possession of excellent verbal and written communication skills \n \n  Vetting:  Applicants selected will be subject to a government investigation and may need to meet eligibility requirements of the U.S. government client. \n \n  Create Your Career: \n \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll build your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $93,300.00 to $212,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.", "cleaned_desc": " \n \n \n \n \n \n \n \n         Data Scientist, Senior\n           The Opportunity: \n  As an analytics professional, you\u2019re excited at the prospect of unlocking the secrets held by a data set, and you\u2019re fascinated by the possibilities presented by IoT, machine learning, and artificial intelligence. If you care about moving a mission forward as much as advancing the field of data science, this is the opportunity for you. Your deep data science and machine learning expertise, coupled with an original approach to your work, will guide clients and stakeholders as they make sense of their data and encourage actionable results. We\u2019re looking for someone like you to land and lead complex data exploration and analytics projects through your experience with machine learning development and deployment for a multitude of use cases in civilian U.S. agencies. \n \n  As an advanced data scientist and researcher on our AI team team, you\u2019ll learn and apply innovative AI and data science methodologies and deployment techniques to make a real-world impact on the mission of our civilian clients. You\u2019ll grow your skills in data science, machine learning operationalization process, business development and shape the future of analytics through a variety of means like white papers, client presentations, and client interactions. \n \n  We\u2019ll keep you sharp and moving forward in your career, with access to online courses, and the latest tools and methods. Whether you\u2019re using AI to find fraud or noncompliance, obtain operational efficiencies, improve citizen experience or other help other mission needs, you\u2019ll guide a team that serves critical missions from end to end. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  5+ years of experience with data science using open source tools such as R or Python    Experience creating models using machine learning techniques intended for operational decisions \n  Experience working with and presenting to non-technical clients \n  Experience with persuading stakeholders to take different courses of action \n  Ability to work on business development capabilities independently, including creating presentation, proposal and white paper writing \n  Ability to come up with good solutions or plans to deal with client lack of AI capabilities \n  Ability to create solutions without having specific business requirements \n  Ability to obtain and maintain a Public Trust or Suitability/Fitness determination based on client requirements \n  Bachelor's degree \n \n \n  Nice If You Have: \n \n  Experience with the aspects full life cycle of machine learning development and deployment, including gathering requirements, identifying data, preparing data, building, validating, and using deployable predictive models with the usage having tangible results \n  Experience with providing technical direction and leadership to data scientists \n  Experience with developing predictive models around fraud, risk, or rare events \n  Experience with cloud AI environments, such as Databricks, Azure ML, or AWS Sagemaker \n  Knowledge of Agile and Scrum processes \n  Possession of excellent verbal and written communication skills \n \n  Vetting:  Applicants selected will be subject to a government investigation and may need to meet eligibility requirements of the U.S. government client. \n ", "techs": ["r", "python", "machine learning", "artificial intelligence", "iot", "white papers", "online courses", "open source tools", "data science methodologies", "deployment techniques", "non-technical clients", "stakeholders", "business development capabilities", "presentation", "proposal", "white paper writing", "ai capabilities", "public trust", "suitability/fitness determination", "full life cycle of machine learning development and deployment", "gathering requirements", "identifying data", "preparing data", "building", "validating", "deployable predictive models", "fraud", "risk", "rare events", "cloud ai environments", "databricks", "azure ml", "aws sagemaker", "agile", "scrum processes", "verbal communication skills", "written communication skills."]}, "750fd90b59b68d35": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Senior Technical Project Manager \u2013 Data and Analytics - Digital Velocity", "company": "CDW", "desc": "Work in CDW\u2019s Digital Velocity organization (DV). The Sr. Technical Project Manager manages all phases of service delivery including: analysis and design, configuration and build, testing and training, and deployment of solutions and will be accountable for all aspects of project management including all project resources (including partners/subcontractors), project planning, scheduling, timeline, budget, risk management, scope management, internal and external communications, status reporting, and resource management (internal and partners). To be successful as a Technical Project Manager you must be highly organized and able to manage multiple initiatives. \n  The DV Data and Analytics Sr. Technical Project Manager has \u201cbig data\u201d experience leading complex data specific engagements. Our customers need a Sr. Technical Project Manager that is capable of providing consultative support as well as executing project plans. The candidate must have experience with cloud data warehousing & engineering, security and business analytics while leading project resources in a distributed environment. \n \n Key Areas of Responsibility \n \n Working with DV/CDW customers as a billable Agile Technical Project Manager  \n Documentation development to support customer projects (Process, Plans, Presentations, Customer Deliverables)  \n Support Sales and Engineering teams providing clear support and direction, identifying resources and constraints through careful project planning  \n Partners with our sales, solutions and services teams to serve clients  \n Ensures the project adheres to budget and time frame guidelines. Oversees the implementation process include setting goals, planning, and monitoring progress to completion  \n Support the delivery of quality solutions to customers exceeding expectations  \n Ensures projects are being managed effectively, establishing deliverables, milestones and risk identification/mitigation  \n Meets with customers and partners during key phases of basic and complex projects  \n Continually seeks and build upon opportunities to increase customer satisfaction and deepen client relationships  \n Executes PMO Operational Duties, including: Status Reporting, Financial Program Management, Escalation engagement, Sales Cycle engagement  \n Proven track record of building effective delivery teams \n Ensures projects are managed with a vision and purpose \n Comfortable managing customer expectations \n Travel Estimated up to 10%  \n Internal Projects as required \n \n   \n Education and/or Skill-Set Qualifications \n \n Bachelor\u2019s degree in MIS, computer science or related field, or equivalent work experience  \n 7+ years of experience in Project Management focusing in one or more of the following, Software defined Lifecycle (SDLC), Infrastructure, or any other related technical environments \n 5+ years of experience in managing Agile software and cloud development projects  \n Knowledge and skill level in identified competencies meet minimum requirements for role  \n Previous direct customer consulting experience or equivalent understanding of role responsibilities \n \n Required Qualifications \n \n An expert in project/program team management including dynamics of virtual teams, matrix reporting relationships and cross-functional resource identification and allocation  \n 7+ years of experience leading Agile Enterprise Data Engineering implementations \n Previous experience leading a team providing Data Governance, Data Engineering, Data Quality, Business Analytics initiatives to customers for large projects \n Previous experience developing Data Governance, Data Science or Data Engineering solutions. \n Previous experience leading delivery team 10+ FTEs \n Experience managing contractors and vendors \n Previous remote work experience \n \n Preferred Qualifications \n \n Previous consulting experience  \n Previous experience with Collaboration Solutions  \n Previous experience with software development engagements  \n Previous experience in Management Consulting \n PMI Agile Certified Practitioner  \n Certified Scrum Master  \n SAFe Scaled Agilist", "cleaned_desc": "Work in CDW\u2019s Digital Velocity organization (DV). The Sr. Technical Project Manager manages all phases of service delivery including: analysis and design, configuration and build, testing and training, and deployment of solutions and will be accountable for all aspects of project management including all project resources (including partners/subcontractors), project planning, scheduling, timeline, budget, risk management, scope management, internal and external communications, status reporting, and resource management (internal and partners). To be successful as a Technical Project Manager you must be highly organized and able to manage multiple initiatives. \n  The DV Data and Analytics Sr. Technical Project Manager has \u201cbig data\u201d experience leading complex data specific engagements. Our customers need a Sr. Technical Project Manager that is capable of providing consultative support as well as executing project plans. The candidate must have experience with cloud data warehousing & engineering, security and business analytics while leading project resources in a distributed environment. \n \n Key Areas of Responsibility \n \n Working with DV/CDW customers as a billable Agile Technical Project Manager  \n Documentation development to support customer projects (Process, Plans, Presentations, Customer Deliverables)  \n Support Sales and Engineering teams providing clear support and direction, identifying resources and constraints through careful project planning  \n Partners with our sales, solutions and services teams to serve clients    Travel Estimated up to 10%  \n Internal Projects as required \n \n   \n Education and/or Skill-Set Qualifications \n \n Bachelor\u2019s degree in MIS, computer science or related field, or equivalent work experience  \n 7+ years of experience in Project Management focusing in one or more of the following, Software defined Lifecycle (SDLC), Infrastructure, or any other related technical environments \n 5+ years of experience in managing Agile software and cloud development projects  ", "techs": ["cdw's digital velocity organization", "sr. technical project manager", "analysis and design", "configuration and build", "testing and training", "deployment of solutions", "project management", "project resources", "project planning", "scheduling", "timeline", "budget", "risk management", "scope management", "internal and external communications", "status reporting", "resource management", "technical project manager", "multiple initiatives", "dv data and analytics", "big data", "complex data specific engagements", "cloud data warehousing", "cloud data engineering", "security", "business analytics", "project resources", "distributed environment", "agile technical project manager", "documentation development", "sales and engineering teams", "project planning", "sales", "solutions and services teams", "mis", "computer science", "project management", "software defined lifecycle (sdlc)", "infrastructure", "agile software", "cloud development projects."]}, "0794e8f16c7d79eb": {"terms": ["data science"], "salary_min": 104829.52, "salary_max": 132737.53, "title": "AEP Developer (remote)", "company": "Blue Acorn iCi", "desc": "Company Description: \n  Blue Acorn iCi is a digital consultancy focused on delivering innovative solutions across customer experience, commerce, and data. Our team of over 400 experts enable clients to navigate large-scale, digital transformation programs. \n  Whether it\u2019s a digitally savvy consumer brand or a legacy manufacturer, Blue Acorn iCi empowers businesses with digital scalability to deliver unprecedented levels of performance and customer experience. With services that include strategy, analytics, design, and engineering, we elevate global brands across industries such as media, consumer goods & retail, financial services, manufacturing, technology and more. \n  Join our innovative and collaborative team as we deliver extraordinary digital experiences for some of the world\u2019s largest brands! \n  Overview : \n  Blue Acorn iCi is seeking an AEP Developer to join our delivery team. The candidate will be responsible to work with Business, DevOps, and Architecture teams to successfully deliver complex cross-functional projects. \n  Responsibilities: \n \n  Work as a core member of AEP Delivery Team and collaborate with AEP onshore, product management, marketing, and fellow technologists \n  Implement Alloy.js and extend CJA to all portfolios \n  Integrate AEP and its application solutions i.e. Real-Time Customer Data Platform (RT-CDP), Customer Journey Analytics (CJA) and Adobe Journey Optimizer (AJO) with Adobe Experience Cloud solutions to drive the users cases. \n  Evaluate new product features, conduct POC\u2019s and help evaluate how they can be used to drive Use cases. \n  Build solutions leveraging the AI capabilities of AEP using Data Science workspace, Attribution AI and Customer AI. \n  Participate in user story analysis, elaboration, and design. Thrives to ensure code quality is high with supporting unit test and automation. \n  Drive software development activities to meet schedules and timelines \n  Research problems discovered by QA or product support and develop solutions to the problems \n  Ensure that software standards and quality targets are met \n \n  Qualifications: \n \n  Experience working in Adobe Experience Platform and hands on experience with one or more key modules of CJA, AJO and Intelligence Services (Data Science, Customer AI, Attribution AI) \n  Experience implementing Alloy.js \n  Understanding of AEP APIs and deployment processes. \n  Possess excellent software architecture, design and problem-solving skills \n  Knowledge of platforms AWS/Salesforce CRM and Marketo. \n  3+ years\u2019 experience with Big Data/cloud platforms or Adobe Experience Cloud products \n  3+ years\u2019 experience with backend technologies including Python, Java, J2EE, Tomcat, REST \n  Experience designing, implementing, and supporting enterprise-grade technical solutions for the cloud. \n  Experience with loading data in and out of CDP from Data Lake/Salesforce and marketing orchestration systems. \n  3+ years\u2019 experience with Adobe Experience Platform \n  Knowledge of using XDM, Attribution AI, Customer AI, DMP & CJA \n  2+ years\u2019 experience with building omni-channel personalization implementation. \n  Working experience with Adobe Analytics, Adobe Target, Adobe Launch, Adobe Marketo Engage or Adobe Campaign. \n  Adobe Certified Expert RT-CDP Expert certification in AEP would be a huge plus. \n  Bachelor\u2019s degree preferably in Computer Science \n \n   \n Full Time, Non-Temporary Employees enjoy a competitive benefits package that includes medical, dental and vision insurance, life insurance, disability, paid time off, 401(k), and more! Additional perks vary by location. \n \n Blue Acorn iCi is an equal opportunity employer and all qualified applicants will receive consideration without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, spouse of protected veteran, or disability.  \n Please click to read  EEO Law  and  Pay Transparency Act  and  IER Right to Work Document  and  Privacy Notice .  \n Blue Acorn iCi will endeavor to make a reasonable accommodation to the known physical or mental limitations of a qualified applicant with a disability unless the accommodation would impose an undue hardship on the operation of our business. If you believe you require such assistance to complete this form or to participate in an interview, please contact us at: engagement@blueacornici.com. \n California applicants: Please click  here  for CCPA disclosures. \n \n tMnV2HTlrM", "cleaned_desc": "  Work as a core member of AEP Delivery Team and collaborate with AEP onshore, product management, marketing, and fellow technologists \n  Implement Alloy.js and extend CJA to all portfolios \n  Integrate AEP and its application solutions i.e. Real-Time Customer Data Platform (RT-CDP), Customer Journey Analytics (CJA) and Adobe Journey Optimizer (AJO) with Adobe Experience Cloud solutions to drive the users cases. \n  Evaluate new product features, conduct POC\u2019s and help evaluate how they can be used to drive Use cases. \n  Build solutions leveraging the AI capabilities of AEP using Data Science workspace, Attribution AI and Customer AI. \n  Participate in user story analysis, elaboration, and design. Thrives to ensure code quality is high with supporting unit test and automation. \n  Drive software development activities to meet schedules and timelines \n  Research problems discovered by QA or product support and develop solutions to the problems    Ensure that software standards and quality targets are met \n \n  Qualifications: \n \n  Experience working in Adobe Experience Platform and hands on experience with one or more key modules of CJA, AJO and Intelligence Services (Data Science, Customer AI, Attribution AI) \n  Experience implementing Alloy.js \n  Understanding of AEP APIs and deployment processes. \n  Possess excellent software architecture, design and problem-solving skills    Knowledge of platforms AWS/Salesforce CRM and Marketo. \n  3+ years\u2019 experience with Big Data/cloud platforms or Adobe Experience Cloud products \n  3+ years\u2019 experience with backend technologies including Python, Java, J2EE, Tomcat, REST \n  Experience designing, implementing, and supporting enterprise-grade technical solutions for the cloud. \n  Experience with loading data in and out of CDP from Data Lake/Salesforce and marketing orchestration systems. \n  3+ years\u2019 experience with Adobe Experience Platform \n  Knowledge of using XDM, Attribution AI, Customer AI, DMP & CJA \n  2+ years\u2019 experience with building omni-channel personalization implementation. ", "techs": ["alloy.js", "cja", "ajo", "rt-cdp", "adobe experience cloud", "data science workspace", "attribution ai", "customer ai", "aws/salesforce crm", "marketo", "python", "java", "j2ee", "tomcat", "rest", "xdm", "dmp."]}, "3b45b7fdbdd239e9": {"terms": ["data science"], "salary_min": 45.0, "salary_max": 45.0, "title": "Forecasting Analyst", "company": "eTeam Inc", "desc": "post1 \n Job Title: Forecasting Analyst  Location: Omaha, NE (100% Remote)  Duration: 12 months Contract  \n Job Description:  Client is the worlds largest professional network, built to help members of all backgrounds and experiences achieve more in their careers. Our vision is to create economic opportunity for every member of the global workforce. Every day our members use our products to make connections, Client opportunities, build skills, and gain insights. We believe amazing things happen when we work together in an environment where everyone feels a true sense of belonging, and that what matters most in a candidate is having the skills needed to succeed. It inspires us to invest in our talent and support career growth. Join us to challenge yourself with work that matters. \n This role, due to the business needs of the team, requires employees to be physically present in the specified office on a full-time basis. This helps to ensure you are best equipped to be successful and have the experience you need to fulfil the responsibilities of the role. \n We are looking for a Planning & Resource Optimization Analyst to join our team. In this role, you will enhance the member and customer experience by providing actionable staffing insights. \n Responsibilities:  Data Analysis: Gather and analyze historical data, trends, and other relevant information to identify patterns and areas for improvement, and opportunities to enhance efficiency. Forecasting Models: Develop and maintain forecasting models and methodologies to predict future demand or supply levels accurately. Accuracy Improvement: Continuously review and refine forecasting models to improve accuracy and reliability. Capacity Planning: Evaluate workforce capabilities and align them with anticipated workloads to maintain optimal staffing levels and operational efficiency. Staff Scheduling: Collaborate with the Managed Service Providers Workforce Management team to align schedules with interval level forecasts to ensure appropriate coverage for different shifts, days off, and peak demand periods. Real-time Monitoring: Continuously monitor operational performance and metrics to recommend real-time adjustments as needed to meet service level goals. Reporting: Prepare regular reports on forecast accuracy, demand trends, and related planning metrics. Performance Metrics: Develop and maintain key performance indicators (KPIs) related to workforce management, such as service level, average handle time, schedule efficiency, adherence, and occupancy. Process Improvement: Propose and implement process improvements to enhance planning practices and achieve better operational outcomes. Collaborate with Teams: Work closely with product, engineering, data science, and operations to understand business strategies, product ramps, efficiencies, and outlooks the forecasting process. Product Ramps: Support the forecasting process for new product ramps based on projected impact and historical data. Training and Development: Assist in the training and development of staff to ensure they understand the planning processes and their roles in meeting performance targets. Technology Utilization: Utilize NICE forecasting software, statistical tools, and advanced Excel skills to develop accurate forecasts, automate scheduling, track performance, and generate reports. \n Basic Qualifications:  2+ years experience with Workforce Management Software 2+ years experience in creating demand, financial or operational forecasts 2+ years experience in an analytical role \n Preferred Qualifications:  Bachelors degree in: Business, Operations Management, Economics, Statistics, Supply Chain Management, or a related field. Proficiency in using statistical analysis software (e.g., SAS, R, Python) and advanced Excel skills for data analysis and modeling. Proficiency in using workforce management software and tools (e.g., WFM software, Excel, data analysis tools). Knowledge of forecasting techniques such as time series analysis, regression, and causal modeling. Knowledge of workforce management principles, operations, and industry best practices. Strong analytical and problem-solving skills to interpret data, develop forecasts, make informed staffing decisions and draw meaningful insights. Understanding of key performance metrics and how to optimize them for operational efficiency. Previous experience with Workforce Management Software, preferably NICE Excellent communication skills to collaborate with cross-functional teams and present forecasting results effectively. Detail-oriented and organized, with the ability to handle large datasets and manage multiple priorities and tasks in a fast-paced environment. Ability to challenge incoming requests, value, and impact, driving data-driven decisions. Flexibility and adaptability to respond to changing business needs and priorities. \n Suggested Skills:  Analytical Forecasting Communication \n Job Type: Contract \n Salary: $45.00 per hour \n Expected hours: 40 per week \n Schedule: \n \n 8 hour shift \n Day shift \n Monday to Friday \n \n Experience: \n \n Forecasting: 2 years (Required) \n Budgeting: 2 years (Required) \n Workforce management: 2 years (Required) \n \n Work Location: Remote", "cleaned_desc": " We are looking for a Planning & Resource Optimization Analyst to join our team. In this role, you will enhance the member and customer experience by providing actionable staffing insights. \n Responsibilities:  Data Analysis: Gather and analyze historical data, trends, and other relevant information to identify patterns and areas for improvement, and opportunities to enhance efficiency. Forecasting Models: Develop and maintain forecasting models and methodologies to predict future demand or supply levels accurately. Accuracy Improvement: Continuously review and refine forecasting models to improve accuracy and reliability. Capacity Planning: Evaluate workforce capabilities and align them with anticipated workloads to maintain optimal staffing levels and operational efficiency. Staff Scheduling: Collaborate with the Managed Service Providers Workforce Management team to align schedules with interval level forecasts to ensure appropriate coverage for different shifts, days off, and peak demand periods. Real-time Monitoring: Continuously monitor operational performance and metrics to recommend real-time adjustments as needed to meet service level goals. Reporting: Prepare regular reports on forecast accuracy, demand trends, and related planning metrics. Performance Metrics: Develop and maintain key performance indicators (KPIs) related to workforce management, such as service level, average handle time, schedule efficiency, adherence, and occupancy. Process Improvement: Propose and implement process improvements to enhance planning practices and achieve better operational outcomes. Collaborate with Teams: Work closely with product, engineering, data science, and operations to understand business strategies, product ramps, efficiencies, and outlooks the forecasting process. Product Ramps: Support the forecasting process for new product ramps based on projected impact and historical data. Training and Development: Assist in the training and development of staff to ensure they understand the planning processes and their roles in meeting performance targets. Technology Utilization: Utilize NICE forecasting software, statistical tools, and advanced Excel skills to develop accurate forecasts, automate scheduling, track performance, and generate reports. \n Basic Qualifications:  2+ years experience with Workforce Management Software 2+ years experience in creating demand, financial or operational forecasts 2+ years experience in an analytical role \n Preferred Qualifications:  Bachelors degree in: Business, Operations Management, Economics, Statistics, Supply Chain Management, or a related field. Proficiency in using statistical analysis software (e.g., SAS, R, Python) and advanced Excel skills for data analysis and modeling. Proficiency in using workforce management software and tools (e.g., WFM software, Excel, data analysis tools). Knowledge of forecasting techniques such as time series analysis, regression, and causal modeling. Knowledge of workforce management principles, operations, and industry best practices. Strong analytical and problem-solving skills to interpret data, develop forecasts, make informed staffing decisions and draw meaningful insights. Understanding of key performance metrics and how to optimize them for operational efficiency. Previous experience with Workforce Management Software, preferably NICE Excellent communication skills to collaborate with cross-functional teams and present forecasting results effectively. Detail-oriented and organized, with the ability to handle large datasets and manage multiple priorities and tasks in a fast-paced environment. Ability to challenge incoming requests, value, and impact, driving data-driven decisions. Flexibility and adaptability to respond to changing business needs and priorities. ", "techs": ["planning & resource optimization analyst", "data analysis", "forecasting models", "capacity planning", "staff scheduling", "real-time monitoring", "reporting", "performance metrics", "process improvement", "collaboration with teams", "product ramps", "training and development", "technology utilization", "workforce management software", "statistical analysis software (e.g.", "sas", "r", "python)", "advanced excel skills", "workforce management software and tools", "forecasting techniques (time series analysis", "regression", "causal modeling)", "understanding of key performance metrics", "excellent communication skills", "detail-oriented and organized", "ability to handle large datasets", "flexibility and adaptability."]}, "95720770afd5700e": {"terms": ["data science", "machine learning engineer", "mlops"], "salary_min": 51.09, "salary_max": 105.94, "title": "Senior Solution Architect Contract \"W2\"", "company": "WorkCog", "desc": "Title: Solution Architect \n Location: Bentonville, AR (Remote work allowed) \n Duration: 6-12 Months Contract \n Key Responsibilities: \n \u00b7  Collaboration & Leadership:  Work collaboratively with cross-functional teams and lead initiatives to advance the capability in API and Microservices development, Integration Architecture, EDA, and AI and MLOPs. Should be able to take initiative and work with cross functional team in a dynamic and unstable environment where there is garage style methodology with lean product development. \n \u00b7  Microservices Architecture:  Develop robust microservices architectures, ensuring optimal functionality and performance in machine learning applications. \n \u00b7  Architect, Design and Develop APIs:  Create scalable and secure APIs enabling seamless integration across diverse systems and data sources, focusing on machine learning applications. \n \u00b7  Machine Learning Integration:  Understand and implement machine learning models, integrating them into the existing system landscape and ensuring their proper interaction. \n \u00b7  UI Design:  Develop intuitive and effective user interfaces by understanding the requirements and peculiarities of machine learning systems. \n \u00b7  Data Management:  Collaborate with data scientists and engineers in managing data sources and ensuring the high quality and availability of data for machine learning models. \n Qualifications: \n \u00b7  Education:  Bachelor\u2019s/master\u2019s degree in computer science, Information Technology, or a related field. \n \u00b7  Experience:  Minimum of 15 years of experience in API architecture and development, with a focus on machine learning systems, AIOPs and MLOPs \n \u00b7  Technical Skills: \n o Proficient in API Integration Architecture in JAVA, Spring Boot, GCP, Big Query, GraphQL, and GCP PaaS services with microservices architecture, machine learning integrations, and user interface designs. \n o Drive and end to end Implementation of Observability, AIOps, MLops, Cloud Cost, \n o Experience with CI/CD/CT in Machine learning and Data science Environment. \n o Experience designing and Implementing Data Pipelines. Design end-to-end data architectures, encompassing data ingestion, storage, processing, and visualization, ensuring scalability, security, and performance. \n o In-depth knowledge of GCP services, including BigQuery, Dataflow, Pub/Sub, Cloud Storage, and related technologies. \n \u00b7  Knowledge:  In-depth understanding of various machine learning models, algorithms, and their applications. \n \u00b7  Soft Skills:  Excellent communication, collaboration, and problem-solving skills. \n Preferred Skills \n \u00b7  Certifications:  Certifications in GCP, API Development, TOGAF, AI/ML or related fields. \n \u00b7  Advanced Knowledge:  Familiarity with the latest trends and advancements in machine learning and API development. \n Industry Experience:  Previous experience in Retail will be an advantage \n Job Type: Contract \n Pay: $51.09 - $105.94 per hour \n Expected hours: 40 per week \n Benefits: \n \n Referral program \n \n Experience level: \n \n 11+ years \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n Software development: 1 year (Preferred) \n Salesforce: 1 year (Preferred) \n \n Work Location: Remote", "cleaned_desc": "Title: Solution Architect \n Location: Bentonville, AR (Remote work allowed) \n Duration: 6-12 Months Contract \n Key Responsibilities: \n \u00b7  Collaboration & Leadership:  Work collaboratively with cross-functional teams and lead initiatives to advance the capability in API and Microservices development, Integration Architecture, EDA, and AI and MLOPs. Should be able to take initiative and work with cross functional team in a dynamic and unstable environment where there is garage style methodology with lean product development. \n \u00b7  Microservices Architecture:  Develop robust microservices architectures, ensuring optimal functionality and performance in machine learning applications. \n \u00b7  Architect, Design and Develop APIs:  Create scalable and secure APIs enabling seamless integration across diverse systems and data sources, focusing on machine learning applications. \n \u00b7  Machine Learning Integration:  Understand and implement machine learning models, integrating them into the existing system landscape and ensuring their proper interaction. \n \u00b7  UI Design:  Develop intuitive and effective user interfaces by understanding the requirements and peculiarities of machine learning systems.   \u00b7  Data Management:  Collaborate with data scientists and engineers in managing data sources and ensuring the high quality and availability of data for machine learning models. \n Qualifications: \n \u00b7  Education:  Bachelor\u2019s/master\u2019s degree in computer science, Information Technology, or a related field. \n \u00b7  Experience:  Minimum of 15 years of experience in API architecture and development, with a focus on machine learning systems, AIOPs and MLOPs \n \u00b7  Technical Skills: \n o Proficient in API Integration Architecture in JAVA, Spring Boot, GCP, Big Query, GraphQL, and GCP PaaS services with microservices architecture, machine learning integrations, and user interface designs. \n o Drive and end to end Implementation of Observability, AIOps, MLops, Cloud Cost, \n o Experience with CI/CD/CT in Machine learning and Data science Environment. \n o Experience designing and Implementing Data Pipelines. Design end-to-end data architectures, encompassing data ingestion, storage, processing, and visualization, ensuring scalability, security, and performance.   o In-depth knowledge of GCP services, including BigQuery, Dataflow, Pub/Sub, Cloud Storage, and related technologies. \n \u00b7  Knowledge:  In-depth understanding of various machine learning models, algorithms, and their applications. \n \u00b7  Soft Skills:  Excellent communication, collaboration, and problem-solving skills. \n Preferred Skills \n \u00b7  Certifications:  Certifications in GCP, API Development, TOGAF, AI/ML or related fields. \n \u00b7  Advanced Knowledge:  Familiarity with the latest trends and advancements in machine learning and API development. \n Industry Experience:  Previous experience in Retail will be an advantage \n Job Type: Contract \n Pay: $51.09 - $105.94 per hour ", "techs": ["java", "spring boot", "gcp", "big query", "graphql", "gcp paas services", "observability", "aiops", "mlops", "cloud cost", "ci/cd/ct", "data pipelines", "gcp services", "bigquery", "dataflow", "pub/sub", "cloud storage", "machine learning models", "algorithms", "gcp certification", "api development certification", "togaf certification", "ai/ml certification"]}, "9efd4a436a794c42": {"terms": ["data science"], "salary_min": 232000.0, "salary_max": 290000.0, "title": "Head of Data Analytics", "company": "Care.com", "desc": "About Care.com \n  Care.com is a consumer tech company with heart. We're on a mission to solve a human challenge we all face: finding great care for the ones we love. We're moms and dads and pet parents. We have parents and grandparents, so we understand that everyone, at some point in their lives, could use a helping hand. Our culture and our products reflect that. \n  Here, entrepreneurs, self-starters, team players, and big thinkers unite behind a common cause. Here, we're applying data analytics, AI, and the latest technologies to solve universal problems and connect people in new ways. If you like having autonomy, if you thrive on collaboration and building new things, and if you're all about using your talent for good, Care.com is the place for you. \n  Position Overview: \n  Care.com is seeking a dynamic and visionary leader for the role of Vice President of Analytics. In this critical position, you will spearhead our Data Science and Business Intelligence efforts, playing an integral role in shaping our data-driven future. You will be responsible for driving the strategic direction of analytics, fostering innovation, and ensuring that data insights empower our mission of connecting families with trusted caregivers. This role reports directly to the CFO and will advise leadership on data-driven strategies and best practices. \n  The ideal candidate has a unique combination of business acumen, strategic thinking, critical thinking, analytical rigor and leadership experience. S/he/they will enjoy working with data and be able to prioritize and deliver in a fast paced environment and lead high performing teams across both data science and business intelligence. \n  Responsibilities \n \n Lead and inspire a cross-functional team of data scientists, analysts, and BI experts to deliver data-driven solutions and insights. \n Develop and execute a data strategy that aligns with our business objectives, leveraging data for innovation and decision-making. \n Translate complex data findings into actionable recommendations and strategies, driving continuous improvement. \n Monitor industry trends and emerging technologies to stay at the forefront of analytics and data science. \n Advise leadership on best practices in data analysis, ensuring that data is used effectively to drive business decisions and outcomes. \n \n Qualifications: \n \n Bachelor's or advanced degree in Data Science, Computer Science, Statistics, or a related field. \n Proven experience in leading and managing data science and analytics teams with a minimum of 10 years of relevant experience. \n Strong expertise in data analytics, machine learning, and statistical modeling. \n Familiarity with technologies such as Python, R, SQL for data analysis. \n Experience with data warehousing and ETL tools. \n Knowledge of data visualization tools like Tableau, Power BI, or Looker. \n Understanding of Data cloud platforms, such as Snowflake, S3, BigQuery for data storage and processing. \n Excellent communication and leadership skills to influence and inspire the organization. \n Strategic thinking with a focus on the practical application of data for business impact. \n Previous experience in a consumer-focused, high-growth technology company is a plus. \n \n For a list of our Perks + Benefits, click here! \n  **Care.com supports diverse families and communities and seeks employees who are just as diverse. As an equal opportunity employer, Care.com recognizes the power of a diverse and inclusive workforce and encourages applications from individuals with varied experiences, perspectives, and backgrounds. Care.com is committed to providing reasonable accommodations for qualified individuals with disabilities. If you need assistance or an accommodation, please reach out to talent@care.com.** \n  ___________________________________________________________________________ \n  Company Overview: \n  Available in more than 20 countries, Care.com is the world's leading platform for finding and managing high-quality family care. Care.com is designed to meet the evolving needs of today's families and caregivers, offering everything from household tax and payroll services and customized corporate benefits packages covering the care needs of working families, to innovating new ways for caregivers to be paid and obtain professional benefits. Since 2007, families have relied on Care.com's industry-leading products\u2014from child and elder care to pet care and home care. Care.com is an IAC company (NASDAQ: IAC). \n  Salary Range: 232,000 - 290,000. The base salary range above represents the anticipated low and high end of the salary range for this position. Actual salaries may vary and may be above or below the range based on various factors including but not limited to work location, experience, and performance. The range listed is just one component of Care's total compensation package for employees. Other rewards may include annual bonuses and short- and long-term incentives. In addition, Care.com provides a variety of benefits to employees, including health insurance coverage, life, and disability insurance, a generous 401K employer matching program, paid holidays, and paid time off (PTO).", "cleaned_desc": "  Responsibilities \n \n Lead and inspire a cross-functional team of data scientists, analysts, and BI experts to deliver data-driven solutions and insights. \n Develop and execute a data strategy that aligns with our business objectives, leveraging data for innovation and decision-making. \n Translate complex data findings into actionable recommendations and strategies, driving continuous improvement. \n Monitor industry trends and emerging technologies to stay at the forefront of analytics and data science.   Advise leadership on best practices in data analysis, ensuring that data is used effectively to drive business decisions and outcomes. \n \n Qualifications: \n \n Bachelor's or advanced degree in Data Science, Computer Science, Statistics, or a related field. \n Proven experience in leading and managing data science and analytics teams with a minimum of 10 years of relevant experience.   Strong expertise in data analytics, machine learning, and statistical modeling. \n Familiarity with technologies such as Python, R, SQL for data analysis. \n Experience with data warehousing and ETL tools. \n Knowledge of data visualization tools like Tableau, Power BI, or Looker. \n Understanding of Data cloud platforms, such as Snowflake, S3, BigQuery for data storage and processing. \n Excellent communication and leadership skills to influence and inspire the organization. ", "techs": ["python", "r", "sql", "tableau", "power bi", "looker", "snowflake", "s3", "bigquery"]}, "ca3810dab1c34dde": {"terms": ["data science"], "salary_min": 75000.0, "salary_max": 75000.0, "title": "Digital SEO/SEM Manager", "company": "AnswerNet Tech solution", "desc": "Digital SEO/SEM Technical Manager \n Work Hours: 9 am - 6 pm EST Monday through Friday Pay Scale: Salary 75,000 annually but DOE Reports to: Marketing Director Job Type: Full-time \n Company Overview AnswerNet is a full-service provider of inbound, outbound, automated, and business process outsourcing (BPO) contact center and AI services. Our network consists of physical and virtual contact centers across the U.S. Canada, offering the broadest selection of services and experience in the market. Position Overview We are looking for an experienced Digital SEO/SEM Manager to join our team. The perfect candidate should demonstrate leadership skills, analytic skills, a passion for the collaborative process, take initiative, be a self- starter, thrive under pressure, and love to adapt to ever-changing plans. In this role, you will be developing and implementing effective search engine optimization (SEO) strategies, coordinating content and design, pay-per-click (PPC) marketing and full funnel activities to drive traffic. As the digital SEO/SEM manager you oversee planning and managing marketing campaigns that promote a company's brand, products, and services to increase our company\u2019s profitability. Responsibilities: \uf0b7 Develop and execute successful SEO forward websites. \uf0b7 Collect, analyze, and interpret data from various digital marketing channels, including website analytics, SEO, PPC, email marketing, social media, and more. \uf0b7 Monitor key performance indicators (KPIs) to assess the effectiveness of digital marketing campaigns and initiatives. \uf0b7 Create regular and ad-hoc reports to communicate insights and performance metrics to stakeholders. Develop dashboards for real-time tracking. \uf0b7 Collaborate with the marketing team to identify opportunities for improving conversion rates on websites and landing pages. \uf0b7 Conduct in-depth keyword research and analysis to inform SEO and content strategies Review technical SEO/SEM issues and recommend fixes. \uf0b7 Manage and optimize tracking tags, pixels, and scripts for accurate data collection. Collect data and report on traffic, rankings, and other SEO aspects. \uf0b7 Stay up to date with industry trends and emerging digital marketing technologies. Keep abreast of SEO and integrated marketing trends. \uf0b7 Responsible for the operation of all company websites. \uf0b7 Coordinating with advertising and media experts to improve marketing results. \uf0b7 Working with your team to brainstorm new and innovative growth strategies. \n Requirements and Qualifications : \uf0b7 5+ years\u2019 experience as SEO, SEM Manager \uf0b7 Bachelor's degree in marketing, statistics, data science, or a related field preferred or equivalent applicable experience. \uf0b7 Google Analytics certification \uf0b7 Google AdWords certification \uf0b7 Proven ability to achieve top search ranking results \uf0b7 Technical understanding of SEO: o On-Page SEO (Image Alts, Meta Tags, etc.) o Off-Page SEO (Link health review, Link Building, etc.) o Technical SEO (Page Speed Optimization, Rich Snippets, etc.) o Knowledge in Title Tagging and Meta Descriptions o SEO audits of client websites to ensure that all ranking factors are implemented correctly \uf0b7 Experience with CRMs \uf0b7 Familiarity with relevant tools (e.g. Conductor, Screaming Frog, MOZ) and web analytics tools (e.g. Google Analytics, Web Trends) \uf0b7 Experience working in Google Data Studio, Adobe T&amp;T, Adobe Analytics, Google 360, Google Search Console, BrightEdge, SEM Rush, SEM Ranking \uf0b7 Excellent communication skills \uf0b7 Strong organizational and leadership skills \uf0b7 Analytical mindset with numerical aptitude \uf0b7 Proficient in MS Office applications. Strong on Excel \n Inbound, Outbound, and Automated Call Center Solutions 3930 Commerce Ave., Willow Grove, PA 19090 | P: 800-411-5777 E: Answer@AnswerNet.com | Blog.AnswerNet.com | www.AnswerNet.com \n Job Type: Full-time \n Pay: $75,000.00 per year \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n Paid time off \n \n Schedule: \n \n 8 hour shift \n Day shift \n Monday to Friday \n \n Education: \n \n Bachelor's (Required) \n \n Experience: \n \n SEO/SEM Manager: 5 years (Required) \n \n License/Certification: \n \n Google AdWords Certification (Preferred) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "bb80b0bfdcbcc632": {"terms": ["data science"], "salary_min": 120363.016, "salary_max": 152406.39, "title": "Deep Learning Engineer", "company": "Cyberjin", "desc": "Hybrid/Remote role \n  Locations in multiple States \n  We're looking for a Deep Learning Engineer to join us as part of the founding engineering team. You will have the opportunity to work closely with the CEO to build new features and roll out new products - all in the deep learning on mobile space. \n \n  Ideal candidate traits \n  Enjoys significant ownership over user-facing product \n  \u200d Can work independently \n  Is comfortable turning research papers into product \n  Has 2 - 10 years experience with deep learning or has a PhD in a STEM field \n  Builds with a product-first approach. You ship code quickly and care about the real world impact of your code. \n  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred \n   \n wU3JsbDGhY", "cleaned_desc": "  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred ", "techs": ["tensorflow"]}, "64cdc9ba55fe19e4": {"terms": ["data science"], "salary_min": 120675.25, "salary_max": 152801.75, "title": "Deep Learning Engineer", "company": "Cyberjin", "desc": "Remote Position \n  We're looking for a Deep Learning Engineer to join Dyneti as part of the founding engineering team. You will have the opportunity to work closely with the CEO to build new features and roll out new products - all in the deep learning on mobile space. \n \n  Ideal candidate traits \n  Enjoys significant ownership over user-facing product \n  \u200d Can work independently \n  Is comfortable turning research papers into product \n  Has 2 - 10 years experience with deep learning or has a PhD in a STEM field \n  Builds with a product-first approach. You ship code quickly and care about the real world impact of your code. \n  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred \n   \n xkPh4CJwlu", "cleaned_desc": "", "techs": ""}, "b456d9155e289be0": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Director Product Management \u2013 Calix Cloud Infrastructure", "company": "Calix", "desc": "Calix provides the cloud, software platforms, systems and services required for communications service providers to simplify their businesses, excite their subscribers and grow their value.\n  \n \n   Calix is looking for a technical product management leader for the Calix Cloud team. The focus of this role will be on developing and launching products/technologies within Cloud Infrastructure.\n  \n \n \n   As director of product management for Calix cloud platform and infrastructure you will be responsible for leading the product strategy and roadmap for Calix cloud infrastructure. This includes defining the vision and direction of the product, conducting market research to understand customer needs and the competitive landscape, and collaborating with cross-functional teams to develop and deliver innovative product solutions. This product management leader should possess a combination of technical skills, business acumen, and leadership abilities, including in-depth knowledge of cloud technologies.\n  \n \n \n   Responsibilities and Duties:\n  \n \n  Chatbots for Self-Service Support leveraging the latest advances in Large Language Models \n  Notification Framework: Pub-Sub integration with external partners and customers for notifications and business process transactions \n  Event-based workflow system that facilitates the automation of business processes inside Calix cloud applications allowing for real-time processing and decision-making for our users \n  Self Service natural language query-based analytics and its proliferation into all Cloud applications \n  Defining Performance Requirements and Validation for Data Lake Query Engines \n  Building tools that ease the onboarding and management of our cloud tenants: Scalable IDP/SSO/LDAP/ Federated Login for customers and partners. Defining the tools and capabilities needed for managing hierarchical relationships between Calix Cloud Tenants \n  Access and Premises Telemetry Data Collection infrastructure including flow data to Wi-Fi performance data from millions of connected devices generating terabytes of data on a weekly basis. Telemetry infrastructure monitoring tools with insights that can be easily integrated by Calix\u2019s customers and partners. \n  Building cloud-to-cloud VPN solutions to enable secure communication between two or more cloud networks, allowing for seamless integration and data transfer. \n  Language translation and Localization Engines critical for Calix\u2019s international expansion. \n \n \n \n  10+ years of product management experience with cross-functional teams to prioritize and execute technical roadmaps. \n  History of strong collaboration with engineering teams to ensure successful delivery on time and within budget \n  Experience defining and measuring key performance metrics to track product success \n  Experience working with large datasets, and joining data from multiple sources. \n  Experience with public cloud services e.g. AWS, GCP. \n  Experience with Data Lake Integrations, Data Lake Scale / Optimizations/Validations for Query Performance \n  Technical expertise regarding data models, data mining, and segmentation techniques. \n  Strong knowledge of and experience in databases (SQL) and programming (Python). \n  Excellent command of SQL \n  Knowledge of statistics and experience using data science packages (Pandas/NumPy/Matplotlib) for analyzing datasets. \n  Expert in building relationships and collaborating in a matrixed environment. \n  BS/MS in Engineering, Math, Computer Science, or equivalent experience. \n \n \n   Preferred Skills:\n  \n \n  AWS Certifications \u2013 Cloud Practitioner/Solutions Architect", "cleaned_desc": "Calix provides the cloud, software platforms, systems and services required for communications service providers to simplify their businesses, excite their subscribers and grow their value.\n  \n \n   Calix is looking for a technical product management leader for the Calix Cloud team. The focus of this role will be on developing and launching products/technologies within Cloud Infrastructure.\n  \n \n \n   As director of product management for Calix cloud platform and infrastructure you will be responsible for leading the product strategy and roadmap for Calix cloud infrastructure. This includes defining the vision and direction of the product, conducting market research to understand customer needs and the competitive landscape, and collaborating with cross-functional teams to develop and deliver innovative product solutions. This product management leader should possess a combination of technical skills, business acumen, and leadership abilities, including in-depth knowledge of cloud technologies.   Event-based workflow system that facilitates the automation of business processes inside Calix cloud applications allowing for real-time processing and decision-making for our users \n  Self Service natural language query-based analytics and its proliferation into all Cloud applications \n  Defining Performance Requirements and Validation for Data Lake Query Engines \n  Building tools that ease the onboarding and management of our cloud tenants: Scalable IDP/SSO/LDAP/ Federated Login for customers and partners. Defining the tools and capabilities needed for managing hierarchical relationships between Calix Cloud Tenants \n  Access and Premises Telemetry Data Collection infrastructure including flow data to Wi-Fi performance data from millions of connected devices generating terabytes of data on a weekly basis. Telemetry infrastructure monitoring tools with insights that can be easily integrated by Calix\u2019s customers and partners. \n  Building cloud-to-cloud VPN solutions to enable secure communication between two or more cloud networks, allowing for seamless integration and data transfer. \n  Language translation and Localization Engines critical for Calix\u2019s international expansion. \n   \n \n  10+ years of product management experience with cross-functional teams to prioritize and execute technical roadmaps. \n  History of strong collaboration with engineering teams to ensure successful delivery on time and within budget \n  Experience defining and measuring key performance metrics to track product success \n  Experience working with large datasets, and joining data from multiple sources. \n  Experience with public cloud services e.g. AWS, GCP. \n  Experience with Data Lake Integrations, Data Lake Scale / Optimizations/Validations for Query Performance    Technical expertise regarding data models, data mining, and segmentation techniques. \n  Strong knowledge of and experience in databases (SQL) and programming (Python). \n  Excellent command of SQL \n  Knowledge of statistics and experience using data science packages (Pandas/NumPy/Matplotlib) for analyzing datasets. \n  Expert in building relationships and collaborating in a matrixed environment. \n  BS/MS in Engineering, Math, Computer Science, or equivalent experience. \n \n ", "techs": ["calix cloud", "cloud infrastructure", "event-based workflow system", "self service natural language query-based analytics", "data lake query engines", "scalable idp/sso/ldap/ federated login", "telemetry data collection infrastructure", "cloud-to-cloud vpn solutions", "language translation and localization engines", "aws", "gcp", "sql", "python", "pandas/numpy/matplotlib"]}, "93e2ac4143ebcaef": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Digital Analyst/Web Analyst (Hybrid)", "company": "The Hartford", "desc": "Sr Spec Digital Marketing - ME08AE\n  \n \n   We\u2019re determined to make a difference and are proud to be an insurance company that goes well beyond coverages and policies. Working here means having every opportunity to achieve your goals \u2013 and to help others accomplish theirs, too. Join our team as we help shape the future.\n  \n \n \n  As an integral member of the Digital Analytics team, the successful candidate will work directly with lines of business to develop, maintain and enhance reporting and analytics capabilities (online, offline, and mobile) by providing thorough analysis and insight into customer behavior, activities and preferences across various channels. To facilitate this goal, the position works closely with business partners to provide reporting, analysis and data-supported decision-making tools to shape the current and future digital strategy of the organization.\n  \n \n \n   Using data from various sources (online, offline/data warehouse, etc.) the incumbent will clearly identify and recommend actions to improve the overall effectiveness and efficiency of the digital channel, processes and marketing campaigns, while maintaining a path toward growth within the business line. This role will develop clear business and measurement objectives for each digital initiative through collaboration with internal customers.\n  \n \n \n   This position requires strong analytical skills, an eye for numbers, intellectual curiosity, proficiency at problem solving, an understanding of digital and traditional media, and strong presentation skills. Most importantly, the successful candidate should have a strong desire to help shape the organization\u2019s digital commerce future.\n  \n \n \n   Specific deliverables include:\n  \n \n  Develop a true working partnership with the various marketing teams to design and implement a comprehensive strategy to support existing and future digital business initiatives. Become immersed in the process, business objectives and data to provide deep insight and analytical value to the organization to shape digital projects. \n  Develop an effective set of dashboards, reports, KPIs and metrics to inform day-to-day business decisions and to expose areas of opportunity. These reports will be used by our business-partners to better understand the effectiveness of web site behavior, decision making, web site optimization, business impact, social media effectiveness and marketing campaign management. \n  Leverage appropriate resources to guide the development of enhanced (ad hoc) analyses for the business to provide insight in short, medium and long-term strategic initiatives. Utilize new tools and reporting techniques to identify areas of opportunities for business growth. \n  Interpret online and offline behavior from various data sources with a focus on strengthening The Hartford's web experience. Facilitate conversations with stakeholders, technical and analytical resources to focus on key performance indicators such as acquisition, conversion and retention to ensure that the proper value is associated with the data or data combinations. Utilize data sources to stitch together a comprehensive customer-centric view of our digital properties. This will span online and offline data sources (the web, call centers, policy and demographics) to be presented to line of business owners for improvements or system/process performance. \n  Perform advanced analytics, BI and reporting for digital initiatives, ensuring achievement of expected results. \n  End to end ownership of analyses involving multiple data sets, exploring new data sources and leverage techniques to ensure competitive advantage and new business opportunities. \n  Extract data from data environments, work with large and complex data sets to cleanse and manipulate data to formulate insights. \n  Develop test plans, define success metrics. Create compelling data visualizations and business dashboards based on multi-channel analytics data. \n  Utilize data by joining online, offline, customer characteristic and third party data. Identifies opportunities to drive data quality improvements to ensure accuracy. \n \n \n   Requirements:\n  \n \n  Significant hands-on experience with digital analytics tools such as Google Analytics, Adobe Analytics, etc. \n  Advanced skills in data and visualization tools. Visualization Platforms, Qlik Sense, Power BI, Tableau, SnowSQL, SQL, SAS, R, Python, Spark, MS Office Suite with advanced knowledge of Excel. \n  Hands on experience with analytics querying using tools such as SQL, SnowSQL, in addition to experience with ETL and database structures. \n  Direct experience developing visualizations and dashboards with BI tools. \n  Proven track record harnessing digital channel data to drive actionable insights \n  Extensive experience in blending data from multiple data sources. \n  Strong background in quantitative analysis and proficiency in analyzing data from internal and external sources. \n  Demonstrable experience debugging JavaScript code using tools like Fiddler, FireBug ,Chrome Developer etc \n  Demonstrable experience with Platform Support and Implementation using tag management system (Tealium or other industry leading tag management solutions ) \n  Familiarity with scripting for web analytics tool; Adobe Insight, Google Analytics \n  Good understanding of scripting using JavaScript or jQuery /Angular/ReactJS for data capture and event handling methods via the DOM event model \n  3 plus years of E-commerce experience in large scale digital commerce, with end to end digital analytics accountability with a statistical background. \n  Bachelors or Masters in mathematics, statistics, economics, bus analysis. \n  Strong stakeholder management experience coupled with experience presenting to small groups \n  Project Management experience with a track record of meeting deadlines independently and managing small projects or portions of larger projects. \n  3 plus years\u2019 experience in Analytics, Data Science or Statistics, Insurance or Financial Services preferred.\n    \n     Additional Details:\n    \n \n \n     Must be authorized to work in the US without company sponsorship.\n    \n  Sustaining The Hartford\u2019s unique workplace culture is vital to delivering on our purpose \u2013 underwriting human achievement \u2013 and continuously producing outstanding results. Our enterprise work model, which reflects a mix of in-office, hybrid and fully remote roles, helps us attract, retain and develop the talent we need to achieve the company\u2019s strategic goals. This role will have a Hybrid work arrangement \n \n \n \n   Compensation\n  \n \n   The listed annualized base pay range is primarily based on analysis of similar positions in the external market. Actual base pay could vary and may be above or below the listed range based on factors including but not limited to performance, proficiency and demonstration of competencies required for the role. The base pay is just one component of The Hartford\u2019s total compensation package for employees. Other rewards may include short-term or annual bonuses, long-term incentives, and on-the-spot recognition. The annualized base pay range for this role is:\n  \n  $79,280 - $118,920\n  \n \n   Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age", "cleaned_desc": "  Extract data from data environments, work with large and complex data sets to cleanse and manipulate data to formulate insights. \n  Develop test plans, define success metrics. Create compelling data visualizations and business dashboards based on multi-channel analytics data. \n  Utilize data by joining online, offline, customer characteristic and third party data. Identifies opportunities to drive data quality improvements to ensure accuracy. \n \n \n   Requirements:\n  \n \n  Significant hands-on experience with digital analytics tools such as Google Analytics, Adobe Analytics, etc. \n  Advanced skills in data and visualization tools. Visualization Platforms, Qlik Sense, Power BI, Tableau, SnowSQL, SQL, SAS, R, Python, Spark, MS Office Suite with advanced knowledge of Excel. \n  Hands on experience with analytics querying using tools such as SQL, SnowSQL, in addition to experience with ETL and database structures. \n  Direct experience developing visualizations and dashboards with BI tools. \n  Proven track record harnessing digital channel data to drive actionable insights \n  Extensive experience in blending data from multiple data sources.    Strong background in quantitative analysis and proficiency in analyzing data from internal and external sources. \n  Demonstrable experience debugging JavaScript code using tools like Fiddler, FireBug ,Chrome Developer etc \n  Demonstrable experience with Platform Support and Implementation using tag management system (Tealium or other industry leading tag management solutions ) \n  Familiarity with scripting for web analytics tool; Adobe Insight, Google Analytics \n  Good understanding of scripting using JavaScript or jQuery /Angular/ReactJS for data capture and event handling methods via the DOM event model \n  3 plus years of E-commerce experience in large scale digital commerce, with end to end digital analytics accountability with a statistical background. \n  Bachelors or Masters in mathematics, statistics, economics, bus analysis. \n  Strong stakeholder management experience coupled with experience presenting to small groups \n  Project Management experience with a track record of meeting deadlines independently and managing small projects or portions of larger projects. \n  3 plus years\u2019 experience in Analytics, Data Science or Statistics, Insurance or Financial Services preferred.\n    \n     Additional Details:\n    \n ", "techs": ["google analytics", "adobe analytics", "visualization platforms", "qlik sense", "power bi", "tableau", "snowsql", "sql", "sas", "r", "python", "spark", "ms office suite", "excel", "sql", "snowsql", "etl", "bi tools", "javascript", "fiddler", "firebug", "chrome developer", "tealium", "adobe insight", "google analytics", "javascript", "jquery", "angular", "reactjs", "dom event model"]}, "54a6a1c0ff2f0edd": {"terms": ["data science", "data analyst"], "salary_min": 88630.81, "salary_max": 112226.36, "title": "Senior Data Analyst (Remote)", "company": "Epsilon", "desc": "Job Description\n   Epsilon is partnering with our client who is working on data management platforms. They are looking for resources to help with various data analysis and data integration projects to help them consolidate and create various data integrations. The Data Analyst is responsible for conducting data analyses using SQL and other tools in support of a variety of analytic solutions. \n  Roles & Responsibilities: \n \n  Collaborate with internal/external stakeholders to manage data logistics \u2013 including data specifications, transfers, structures, and rules. \n  Supports project tasks:\n    \n  Identify the data to analyze \n  Collect the data \n  Clean the data in preparation for analysis \n  Analyze and visualize the data \n  Interpret and present the results of the analysis \n \n  Access and extract data from a variety of sources of all sizes (including client marketing databases) via SAS Access, SQL, etc. \n  Master and perform all steps required to create analysis-ready data sets, including data integration/merging, variable preparation, and quality control (QA/QC) \n  Develop and execute SQL (or related) programs with detailed direction and supervision. \n  Provide problem solving and data analysis, derived from programming experience. \n  Past experience working with Data Visualization solutions like Power BI, Tableau are a must to help summarize and present data summaries and performance numbers where needed. \n  Document and articulate steps taken in an analysis to project managers/ stakeholders / SMEs. \n  Answer questions about data sets and analyses, create and maintain data dictionaries. \n  Follow all policies and procedures for programming, project documentation, and system management. \n  Participate in the design, planning & execution of projects \n  Effectively manage time and resources in order to deliver on time / correctly on a limited number (1-4) of concurrent projects \n  Proactively communicate with supervisor regarding workload and the status of assignments \n  Prepare basic report content (Word, Excel, PowerPoint) in support of deliverables \n  Directly responsible for accuracy of data as financial and operational decisions are made based on the data provided. \n  Reviews, extracts, and analyses data to be used in formulation of procedures, processes, and other requirements, including data integrity and quality control. \n \n  Minimum Qualifications: \n \n  Bachelor\u2019s degree in a quantitative discipline (e.g., Statistics, Economics, Mathematics, Marketing Analytics, computer engg, programming) or significant relevant coursework \n  1-2 years of experience in the marketing or data analytics field \n  Demonstrated proficiency in SQL programming; minimum 2 years of experience \n  Strong analytic thought process and ability to interpret findings \n  Acute attention to detail (QA/QC) \n  Working knowledge of MS Office; including PowerPoint, Word, Excel, and Outlook \n  Tools: SQL, Tableau, Microsoft Power BI, etc. \n  Ability to work on multiple assignments concurrently \n  Excellent verbal and written communication skills \n  Highly motivated and collaborative team player with strong interpersonal skills \n  Effective organization and time management skills \n \n  Desirable Qualifications: \n \n  Database marketing experience/knowledge \n  Banking Industry Knowledge \n  Ability to learn and use newer and emerging solutions such as SAS, R, and Python \n \n \n \n \n Additional Information\n   About Epsilon \n  Epsilon is a global advertising and marketing technology company positioned at the center of Publicis Groupe. Epsilon accelerates clients\u2019 ability to harness the power of their first-party data to activate campaigns across channels and devices, with an unparalleled ability to prove outcomes. The company\u2019s industry-leading technology connects advertisers with consumers to drive performance while respecting and protecting consumer privacy. Epsilon\u2019s people-based identity graph allows brands, agencies and publishers to reach real people, not cookies or devices, across the open web. For more information, visit epsilon.com. \n  When you\u2019re one of us, you get to run with the best.  For decades, we\u2019ve been helping marketers from the world\u2019s top brands personalize experiences for millions of people with our cutting-edge technology, solutions and services. Epsilon\u2019s best-in-class identity gives brands a clear, privacy-safe view of their customers, which they can use across our suite of digital media, messaging and loyalty solutions. We process 400+ billion consumer actions each day and hold many patents of proprietary technology, including real-time modeling languages and consumer privacy advancements. Thanks to the work of every employee, Epsilon has been consistently recognized as industry-leading by Forrester, Adweek and the MRC. Positioned at the core of Publicis Groupe, Epsilon is a global company with more than 8,000 employees around the world. Check out a few of these resources to learn more about what makes Epsilon so EPIC: \n \n  Our Culture : https://www.epsilon.com/us/about-us/our-culture-epsilon \n  Life at Epsilon : https://www.epsilon.com/us/about-us/epic-blog \n  DE&I : https://www.epsilon.com/us/about-us/diversity-equity-inclusion \n  CSR : https://www.epsilon.com/us/about-us/corporate-social-responsibility \n \n  Great People Deserve Great Benefits \n  We know that we have some of the brightest and most talented associates in the world, and we believe in rewarding them accordingly. If you work here, expect competitive pay, comprehensive health coverage, and endless opportunities to advance your career. \n  Epsilon is an Equal Opportunity Employer.  Epsilon\u2019s policy is not to discriminate against any applicant or employee based on actual or perceived race, age, sex or gender (including pregnancy), marital status, national origin, ancestry, citizenship status, mental or physical disability, religion, creed, color, sexual orientation, gender identity or expression (including transgender status), veteran status, genetic information, or any other characteristic protected by applicable federal, state or local law. Epsilon also prohibits harassment of applicants and employees based on any of these protected categories. Epsilon will provide accommodations to applicants needing accommodations to complete the application process. \n  For San Francisco Bay and Los Angeles Areas:  Epsilon will consider for employment qualified applicants with criminal histories in a manner consistent with the City of Los Angeles\u2019 Fair Chance Initiative for Hiring Ordinance and San Francisco Police Code Sections 4901-4919, commonly referred to as the San Francisco Fair Chance Ordinance. \n  Applicants with criminal histories are welcome to apply. \n  #LI-SJ1 \n  REF211877B", "cleaned_desc": "Job Description\n   Epsilon is partnering with our client who is working on data management platforms. They are looking for resources to help with various data analysis and data integration projects to help them consolidate and create various data integrations. The Data Analyst is responsible for conducting data analyses using SQL and other tools in support of a variety of analytic solutions. \n  Roles & Responsibilities: \n \n  Collaborate with internal/external stakeholders to manage data logistics \u2013 including data specifications, transfers, structures, and rules. \n  Supports project tasks:\n    \n  Identify the data to analyze \n  Collect the data \n  Clean the data in preparation for analysis \n  Analyze and visualize the data \n  Interpret and present the results of the analysis \n    Access and extract data from a variety of sources of all sizes (including client marketing databases) via SAS Access, SQL, etc. \n  Master and perform all steps required to create analysis-ready data sets, including data integration/merging, variable preparation, and quality control (QA/QC) \n  Develop and execute SQL (or related) programs with detailed direction and supervision. \n  Provide problem solving and data analysis, derived from programming experience. \n  Past experience working with Data Visualization solutions like Power BI, Tableau are a must to help summarize and present data summaries and performance numbers where needed. \n  Document and articulate steps taken in an analysis to project managers/ stakeholders / SMEs. \n  Answer questions about data sets and analyses, create and maintain data dictionaries. \n  Follow all policies and procedures for programming, project documentation, and system management. \n  Participate in the design, planning & execution of projects \n  Effectively manage time and resources in order to deliver on time / correctly on a limited number (1-4) of concurrent projects \n  Proactively communicate with supervisor regarding workload and the status of assignments \n  Prepare basic report content (Word, Excel, PowerPoint) in support of deliverables \n  Directly responsible for accuracy of data as financial and operational decisions are made based on the data provided.    Reviews, extracts, and analyses data to be used in formulation of procedures, processes, and other requirements, including data integrity and quality control. \n \n  Minimum Qualifications: \n \n  Bachelor\u2019s degree in a quantitative discipline (e.g., Statistics, Economics, Mathematics, Marketing Analytics, computer engg, programming) or significant relevant coursework \n  1-2 years of experience in the marketing or data analytics field \n  Demonstrated proficiency in SQL programming; minimum 2 years of experience \n  Strong analytic thought process and ability to interpret findings \n  Acute attention to detail (QA/QC) \n  Working knowledge of MS Office; including PowerPoint, Word, Excel, and Outlook \n  Tools: SQL, Tableau, Microsoft Power BI, etc. \n  Ability to work on multiple assignments concurrently \n  Excellent verbal and written communication skills    Highly motivated and collaborative team player with strong interpersonal skills \n  Effective organization and time management skills \n \n  Desirable Qualifications: \n \n  Database marketing experience/knowledge \n  Banking Industry Knowledge \n  Ability to learn and use newer and emerging solutions such as SAS, R, and Python \n \n \n \n \n Additional Information", "techs": ["sql", "tableau", "microsoft power bi", "sas", "r", "python"]}, "925ec58265c4a16d": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Applied Statistician (Remote)", "company": "Pratt & Whitney", "desc": "Date Posted:  2023-09-18\n   Country:  United States of America\n   Location:  PW100: East Hartford 400 Main Street, East Hartford, CT, 06118 USA\n   Position Role Type:  Remote\n   Pratt & Whitney is working to once again transform the future of flight\u2014designing, building and servicing engines unlike any the world has ever seen. And because transformation begins from within, we\u2019re seeking the people to drive it. So, calling all curious.  \n \n Come ready to explore and you\u2019ll find a place where your talent takes flight\u2014beyond the borders of title, a country or your comfort zone. Bring your passion and commitment and we\u2019ll welcome you into a tight-knit team that takes our mission personally. Channel your drive to make a difference into shaping an organization and an industry that\u2019s evolving fast to the future.  \n \n Innovation through diversity of thought.  At Pratt & Whitney, we believe diversity of thought enables creativity, innovation, and a foundation for inclusion. By fostering an inclusive culture, we accept a shared accountability and responsibility to recognize, sponsor, coach, hire and promote talent equally. We welcome our employees to be their whole - best - selves at work because trust, respect and integrity, are a part of our DNA. \n \n  At Pratt & Whitney, the difference you make is on display every day. Just look up. Are you ready to go beyond? \n \n  Job Summary: \n  Perform diverse types of statistical analyses for both the military and commercial programs. Assist multifunctional teams with problem solving, process improvement, and data based decision making through the use of statistical methods, analyses, and tools with applications spanning such areas as Metallurgical (mechanical test, microstructural analysis), Manufacturing, Non destructive Examination \u2013 all inclusive of P&W Supplier & Customer support. \n   \n Key Responsibilities: \n \n  Perform diverse types of statistical analyses for both the military and commercial programs. \n  Assist multifunctional teams with problem solving, process improvement, and data based decision making through the use of statistical methods, analyses, and tools with applications spanning such areas as Metallurgical (mechanical test, microstructural analysis), Manufacturing, Non destructive Examination \u2013 all inclusive of P&W Supplier & Customer support. \n \n  Basic Qualifications: \n \n  BS/BA in Statistics or related field (Mathematics, Data Science, Industrial Engineering, Biostatistics) or equivalent experience and minimum 5 years prior relevant experience, or An Advanced Degree in a related field and minimum 3 years experience \n  Computer Language experience with SAS, Minitab, R \n  U.S. citizenship is required, as only U.S. citizens are authorized to access information under this program/contract. \n \n \n  Preferred Qualifications: \n \n  3+ years of work experience applying statistical methods, preferably in a manufacturing environment. \n  Experience with Exploratory Data Analysis, Sample size determination, Linear and logistic regression, Probability Theory and Experimental Design / Design of Experiments. \n  Categorical Data analysis, Statistical Process Control and Process Capability, Multivariate Data Analysis and Confidence, Prediction, and Tolerance Intervals. \n  Sampling Plans, Nonparametric Methods and Distribution Fitting. \n  Hypothesis testing, Monte Carlo Simulations, and Statistical methods for small data sets. \n  Manufacturing and/or Engineering. \n  Desired Professional Society memberships: American Society for Quality (ASQ) and American Statistical Association (ASA). \n \n \n  Preferred Certificates: \n  ASQ \u2013 Six Sigma Black Belt (CSSBB), Certified Quality Engineer (CQE)  ASA \u2013 Accredited Professional Statistician \n  What is my role type? \n  In addition to transforming the future of flight, we are also transforming how and where we work. We\u2019ve introduced role types to help you understand how you will operate in our blended work environment. This role is: \n \n  Remote: Employees who are working in Remote roles will work primarily offsite (from home). \n \n  Candidates will learn more about role type and current site status throughout the recruiting process. For onsite and hybrid roles, commuting to and from the assigned site is the employee\u2019s personal responsibility. \n  The salary range for this role is 75,000 USD - 161,000 USD; however, RTX considers several factors when extending an offer, including but not limited to, the role and associated responsibilities, a candidate\u2019s work experience, location, education/training, and key skills. Hired applicants may be eligible for benefits, including but not limited to, medical, dental, vision, life insurance, short-term disability, long-term disability, 401(k) match, flexible spending accounts, flexible work schedules, employee assistance program, Employee Scholar Program, parental leave, paid time off, and holidays. Specific benefits are dependent upon the specific business unit as well as whether or not the position is covered by a collective-bargaining agreement. Hired applicants may be eligible for annual short-term and/or long-term incentive compensation programs depending on the level of the position and whether or not it is covered by a collective-bargaining agreement. Payments under these annual programs are not guaranteed and are dependent upon a variety of factors including, but not limited to, individual performance, business unit performance, and/or the company\u2019s performance.\n  \n  RTX is An Equal  Opportunity/Affirmative  Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status, age or any other federally protected class. \n  Privacy Policy and Terms: \n \n  Click on this link to read the Policy and Terms", "cleaned_desc": "", "techs": ""}, "d9b9e4aee5a0cdc2": {"terms": ["data science"], "salary_min": 0.0, "salary_max": 120000.0, "title": "Sr Project Manager", "company": "Maximus", "desc": "Job Introduction: \n  \n   Maximus is currently looking for a remote Sr Manager Project/Program. This opportunity requires working hours to be performed on Eastern or Central Standard time. This position is responsible for overseeing the Project Management team at a senior level. The incumbent will work closely with business development and sales groups, and develop and implement strategies for upcoming and existing product lines.\n   Job Summary: \n  \n   Essential Duties and Responsibilities:\n   \n \n Develop strategies and tactical implementation of new products and improvements to existing product lines. \n Work closely with business development and sales groups to identify upcoming needs. \n Develop a detailed plan for implementation and roll out. \n Follow up by evaluating product performance. \n \n  Minimum Requirements:\n  \n \n Bachelor's degree with 7+ years of project management experience. \n Delivers multiple small and large projects with high values and high risk. \n Provides leadership for the project team to ensure that the project is delivered to specifications, on time and within budget. \n Develops innovative methodologies, techniques, and criteria for projects. \n Advanced knowledge of workflows and project mapping. \n Facilitates the tracking and resolution of issues impacting projects. \n  Education and Experience Requirements: \n  \n   Bachelor's degree or equivalent combination of education, technical training or work experience considered in lieu of degree with 7+ years of experience\n  \n \n \n \n  Manage a huge analytics content repository for major internal and external customers. \n Manage expectations regarding project schedule and scope, as well as budget and financial impact. \n Lead talks with data analysts and business stakeholders to explore opportunities for applying data analytics concepts to real-world business problems. \n Mentor and coach new and advanced data analytics teammates in the development of their abilities and the resolution of challenging business problems. \n Demonstrate a creative ability to recommend data visualizations that enable key company stakeholders to easily digest complex information and swiftly find significant insights. \n \n \n \n  Experience Preferred:\n  \n \n \n  Bachelor\u2019s degree in Data Analytics, Business Analytics, Data Science, Computer Science, Computer Information Systems, or other relevant engineering/technical field preferred.  \n Master\u2019s degree in Data Analytics, Business Analytics, Data Science, Computer Science, Computer Information Systems, or other relevant engineering/technical field preferred. \n Project management and related experience preferred \n Project Management Professional (PMP) certification plus \n Leadership experience preferred. \n Familiarity with programming languages central to data analytics (e.g. SQL, Python, R, DAX) preferred. \n Background of advising both immediate team and broader organization on solutions preferred.  \n Familiar with development & utilization of applications and process automation tools to improve analytics processes (e.g. Power Apps, Power Automate) a plus  \n Experience with project management tools & framework (e.g. scrum and agile frameworks) preferred. \n Experience/advanced in data governance concepts including the need for documented definitions, calculations, sources, lineage, etc. preferred. \n Experience leading a team and peers through end-to-end data analytics projects (e.g. from problem and requirements definition to code/model validation and reporting deployment) preferred.  \n Knowledge and experience in business intelligence and analytics platforms (e.g. Power BI, Tableau) a plus.  \n Familiar with common data analysis processes (e.g. data transformation, cleansing, modeling, relational database concepts) preferred \n Verbal and written communication skills, including presentation skills. \n Advanced data analysis skills \n Data visualization and design expertise. \n Experience creating and presenting data-driven insights. \n Initiative to solve complex problems; takes an outside in perspective to identify innovative solutions. \n \n \n \n \n  This position is fully remote and will require a home office.\n  \n \n  Home office requirements:\n  \n \n   Reliable high-speed internet service\n    Minimum 25 Mpbs download speeds/50 Mpbs for shared internet connectivity\n    Minimum 5 Mpbs upload speeds\"\n  \n \n \n  This position requires working hours to be performed in Eastern or Central Standard Time.\n  \n \n \n  This position has the potential to work weekends and holidays based on business needs.\n  \n \n \n  The 6 month time in position rule can be waived for CCO employees under the following circumstances : employees who were in an acting role and have returned to their home base position, employees who are currently in an acting/limited-service role applying to the same role that is RFT, employees who were unable to return to a homebase position at the end of their acting role, or limited-service employees that are unable to secure a lateral or promotional position for continued employment at the end of their limited assignment.\n   MAXIMUS Introduction: Since 1975, Maximus has operated under its founding mission of Helping Government Serve the People, enabling citizens around the globe to successfully engage with their governments at all levels and across a variety of health and human services programs. Maximus delivers innovative business process management and technology solutions that contribute to improved outcomes for citizens and higher levels of productivity, accuracy, accountability and efficiency of government-sponsored programs. With more than 30,000 employees worldwide, Maximus is a proud partner to government agencies in the United States, Australia, Canada, Saudi Arabia, Singapore and the United Kingdom. For more information, visit https://www.maximus.com. EEO Statement: EEO Statement: Active military service members, their spouses, and veteran candidates often embody the core competencies MAXIMUS deems essential, and bring a resiliency and dependability that greatly enhances our workforce. We recognize your unique skills and experiences, and want to provide you with a career path that allows you to continue making a difference for our country. We\u2019re proud of our connections to organizations dedicated to serving veterans and their families. If you are transitioning from military to civilian life, have prior service, are a retired veteran or a member of the National Guard or Reserves, or a spouse of an active military service member, we have challenging and rewarding career opportunities available for you. A committed and diverse workforce is our most important resource. MAXIMUS is an Affirmative Action/Equal Opportunity Employer. MAXIMUS provides equal employment opportunities to all qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status or disabled status. Pay Transparency: Maximus compensation is based on various factors including but not limited to job location, a candidate's education, training, experience, expected quality and quantity of work, required travel (if any), external market and internal value analysis including seniority and merit systems, as well as internal pay alignment. Annual salary is just one component of Maximus's total compensation package. Other rewards may include short- and long-term incentives as well as program-specific awards. Additionally, Maximus provides a variety of benefits to employees, including health insurance coverage, life and disability insurance, a retirement savings plan, paid holidays and paid time off. Compensation ranges may differ based on contract value but will be commensurate with job duties and relevant work experience. An applicant's salary history will not be used in determining compensation. Maximus will comply with regulatory minimum wage rates and exempt salary thresholds in all instances. Posted Max: USD $120,000.00/Yr. Posted Min: USD $63,100.00/Yr.", "cleaned_desc": " Bachelor's degree with 7+ years of project management experience. \n Delivers multiple small and large projects with high values and high risk. \n Provides leadership for the project team to ensure that the project is delivered to specifications, on time and within budget. \n Develops innovative methodologies, techniques, and criteria for projects. \n Advanced knowledge of workflows and project mapping. \n Facilitates the tracking and resolution of issues impacting projects. \n  Education and Experience Requirements: \n  \n   Bachelor's degree or equivalent combination of education, technical training or work experience considered in lieu of degree with 7+ years of experience\n  \n \n \n \n  Manage a huge analytics content repository for major internal and external customers. \n Manage expectations regarding project schedule and scope, as well as budget and financial impact. \n Lead talks with data analysts and business stakeholders to explore opportunities for applying data analytics concepts to real-world business problems.   Mentor and coach new and advanced data analytics teammates in the development of their abilities and the resolution of challenging business problems. \n Demonstrate a creative ability to recommend data visualizations that enable key company stakeholders to easily digest complex information and swiftly find significant insights. \n \n \n \n  Experience Preferred:\n  \n \n \n  Bachelor\u2019s degree in Data Analytics, Business Analytics, Data Science, Computer Science, Computer Information Systems, or other relevant engineering/technical field preferred.  \n Master\u2019s degree in Data Analytics, Business Analytics, Data Science, Computer Science, Computer Information Systems, or other relevant engineering/technical field preferred. \n Project management and related experience preferred \n Project Management Professional (PMP) certification plus \n Leadership experience preferred. \n Familiarity with programming languages central to data analytics (e.g. SQL, Python, R, DAX) preferred. \n Background of advising both immediate team and broader organization on solutions preferred.    Familiar with development & utilization of applications and process automation tools to improve analytics processes (e.g. Power Apps, Power Automate) a plus  \n Experience with project management tools & framework (e.g. scrum and agile frameworks) preferred. \n Experience/advanced in data governance concepts including the need for documented definitions, calculations, sources, lineage, etc. preferred. \n Experience leading a team and peers through end-to-end data analytics projects (e.g. from problem and requirements definition to code/model validation and reporting deployment) preferred.  \n Knowledge and experience in business intelligence and analytics platforms (e.g. Power BI, Tableau) a plus.  \n Familiar with common data analysis processes (e.g. data transformation, cleansing, modeling, relational database concepts) preferred \n Verbal and written communication skills, including presentation skills. \n Advanced data analysis skills \n Data visualization and design expertise. \n Experience creating and presenting data-driven insights. \n Initiative to solve complex problems; takes an outside in perspective to identify innovative solutions. \n \n \n \n \n  This position is fully remote and will require a home office.", "techs": ["pmp certification", "sql", "python", "r", "dax", "power apps", "power automate", "scrum", "agile frameworks", "power bi", "tableau"]}, "7e9f4184c588422d": {"terms": ["data science"], "salary_min": 132428.67, "salary_max": 167684.2, "title": "Senior Site Reliability Engineer (Remote, US)", "company": "Openly", "desc": "Openly is rebuilding insurance from the ground up. We are re-envisioning and enhancing every aspect of the customer experience. Doing this requires a rapidly growing team of exceptional, curious, empathetic people with a wide range of skill sets, spanning technology, data science, product, marketing, sales, service, claims handling, finance, etc. \n  Now is the perfect time to join the journey. Here's why \n \n It's working . We're in multiple states and on our way to operating countrywide. We have thousands of agents selling our product and millions of dollars of annual customer premiums. \n We're well-backed & stable.  We closed our $100M Series D fundraise. We are supported by some of the top investors globally, including Google's \"Gradient\" AI-focused fund, Obvious Ventures, Advance Venture Partners, Eden Global Partners, and Clocktower Technology Ventures. \n It's not too late!  Despite this traction and stability, we're still early enough in the journey that there's time to make a real difference during Openly's formative period. \n \n If you'd like to understand more about Openly's mission, consider checking out this video (https://vimeo.com/267654520) from a company pitch we gave several years ago at Techstars. \n \n \n \n  Job Details \n  We're hiring a  Senior Site Reliability Engineer  to be a part of our team to build the technology infrastructure for Openly's insurance platform. You will play a crucial role in building, testing, and maintaining the infrastructure and the overall technology ecosystem that powers our insurance products and customer experiences. \n \n \n  What You'll Do \n \n Build internal tooling to help other engineers and the rest of the company understand and operate our system \n Design and implement security best practices for our team and infrastructure \n Automate repetitive tasks to reduce toil. This includes building and maintaining CI/CD infrastructure, developing CLI and ChatOps tools, and automating manual processes \n Build infrastructure as code using declarative provisioning tools \n Develop high signal-to-noise ratio monitoring and alerting policies and technology to help us meet our SLOs \n Lead incident response and postmortems \n Contribute to important architectural and operational decisions like microservices vs. monoliths, deployment techniques, technologies, policies, etc. \n \n Our stack \n \n Backend /Core:  Go,  Temporal & PostgreSQL \n Frontend: Browser-based, VueJS, Webpack, Nuxt &, Tailwind \n Research/Data Science: R, ArcGIS, H2O, & Python \n Infrastructure: Google Cloud, specifically Cloud Run, GKE, and CloudSQL, managed with Terraform. We use GitHub for code hosting, DataDog for monitoring and CircleCI for running our CI/CD pipelines. \n Remote work tools: Slack, Zoom, Gather.Town, Donut \n \n Requirements \n \n If you don't think you meet all of the criteria below but still are interested in the job, please apply. Nobody checks every box, and we're looking for someone excited to join the team. \n \n \n 4+ years of professional/production experience developing and using infrastructure automation tools and techniques \n Proven track record of creating improvements in business-critical systems around stability, performance, and scalability \n Demonstrated ability to deliver complete systems from start to finish in a reasonable time frame \n Understands the consequences of running software in production and are willing to share your knowledge with the rest of the team \n Ability to explain complex technical challenges to non-technical audiences \n Go experience or willing to learn -  *Previous experience developing in Go is not a requirement to apply. Please note that part of the interview process includes completing a code challenge in Go. \n \n #LI-CB1 \n \n  Benefits & Perks \n \n Remote-First Culture - We supported #remotelife long before it was a given. We'll keep promoting it. \n Competitive Salary & Equity \n Comprehensive Medical, Dental, and Vision Plan Offerings \n Life and disability coverage including voluntary options \n Competitive PTO - 20 days and 11 paid holidays (including floating holidays) per year under the Company's vacation and holiday policies.  \n Parental Leave - 12 weeks paid for eligible employees \n 401K Company Contribution - Openly contributes 3% of the employee's gross income, even if the employee does not contribute. \n Work-from-home stipend - We provide a $1,500 allowance to spend on setting up your home workplace \n Annual Professional Development Fund: Each employee has $2,000 in professional development (PD) funds to spend on activities or resources annually. We want each Openly employee to achieve personal and professional success and to feel supported, confident, and informed about improving their efficiency and productivity. \n Be Well Program - Employees receive $50 per month to use towards your overall well-being \n Paid Volunteer Service Hours \n Referral Program and Reward \n \n Depending on position, Employees generally are eligible for cash incentive compensation, including commissions for sales eligible roles. In all cases, eligibility for compensation and benefits is subject to applicable plan and policy terms in effect from time to time. \n  U.S. Citizens, Green Card Holders, and those authorized to work in the U.S. for any employer and currently residing in the US will be considered. \n  Openly is committed to equal employment opportunity and non-discrimination for all employees and qualified applicants without regard to a person's race, color, sex, gender identity or expression, age, religion, national origin, ancestry, ethnicity, disability, veteran status, genetic information, sexual orientation, marital status, or any characteristic protected under applicable law. Openly is an E-Verify Employer in the United States. Openly will make reasonable accommodations for qualified individuals with known disabilities under applicable law.", "cleaned_desc": "", "techs": ""}, "b5bce08b65e987b3": {"terms": ["data science"], "salary_min": 107280.0, "salary_max": 140805.0, "title": "Senior Manager, Claims Reporting", "company": "Oscar Health", "desc": "Hi, we're Oscar. We're hiring a Senior Manager, Claims Reporting to join our Claims & Benefits Life Cycle team. \n  Oscar is the first health insurance company built around a full stack technology platform and a focus on serving our members. We started Oscar in 2012 to create the kind of health insurance company we would want for ourselves\u2014one that behaves like a doctor in the family. \n  About the role \n  As the Senior Manager, Claims Reporting, you will be responsible for developing and overseeing the efficient and accurate reporting and monitoring of claims data. Specifically, you will be responsible for connecting the dots between activities that drive claims payment and trends in paid claims, in order to support accurate prediction of claims payments and ensure appropriate monitoring is in place. In addition, you will be responsible for evaluating and addressing claims reporting needs from Claims leadership and other key stakeholders. Critical to your success will be partnering cross-functionally with Actuarial, Finance, Business Analytics, Data Science and Claims management. \n  You will report to the Senior Director, Claims Quality. \n  Work Location: \n  Oscar is a blended work culture where everyone, regardless of work type or location, feels connected to their teammates, our culture and our mission. \n  If you live within commutable distance to our New York City office ( in Hudson Square), our Tempe office (off the 101 at University Ave), or our Los Angeles office (in Marina Del Rey), you will be expected to come into the office at least two days each week. Otherwise, this is a remote / work-from-home role. \n  You must reside in one of the following states: Alabama, Arizona, California, Colorado, Connecticut, Florida, Georgia, Illinois, Kentucky, Maryland, Massachusetts, Michigan, New Hampshire, New Jersey, New Mexico, New York, North Carolina, Ohio, Oregon, Pennsylvania, Rhode Island, Tennessee, Texas, Utah, Virginia, Washington, or Washington, D.C. Note, this list of states is subject to change. #LI-Remote \n  Pay Transparency: \n  The base pay for this role in the states of California, Connecticut, New Jersey, New York, and Washington is: $119,200 - $156,450 per year. The base pay for this role in all other locations is: $107,280 - $140,805 per year. You are also eligible for employee benefits, participation in Oscar's unlimited vacation program and annual performance bonuses. \n  Responsibilities \n \n Identify, monitor and report timely on factors that cause variability in claims payment (such as claims volume, denial rates, payment integrity activities, changes in inventory and other driving factors). \n  Provide daily monitoring of claims payment factors, surfacing unexpected data points and tracking down the explanation behind such data points. \n  Proactively raise issues and influence the thinking of the Claims team and other key stakeholders on the potential impact and resolution of such underlying issues. \n  Partner closely with Finance and Actuarial to develop a strong working model; connect the dots between claims payment factors monitored and daily paid claims data, enabling Actuarial to better predict claims spend. \n  Ensure effective monitoring and oversight of claims activities that drive claims payment; recommend and develop additional controls where needed. \n  Partner with and provide claims expertise to our Data Science team on projects to design, develop and deep dive on claims performance metrics. \n  Represent Claims in monthly close activities with Actuarial and Finance to ensure a common understanding of claims activity and inventory. \n  Develop dashboards and reporting to support proactive management of our strategic provider partners from a claims perspective. \n  Evaluate business needs and develop dashboards and reporting that improve our ability to monitor claims activity and manage and improve claims performance. \n  Compliance with all applicable laws and regulations \n  Other duties as assigned \n \n Qualifications \n \n 6+ years of data, analytics or reporting experience \n  3+ years of experience working with healthcare claims data \n  Strong working knowledge of health plan claims department operations, key performance metrics, processes and information flow \n  Familiarity with Actuary and Finance work regarding claims payments and estimating claims trends and experience working with such teams \n  Analytic and technical ability to develop dashboards and reports \n  Strong written and verbal communication skills \n \n Bonus Points \n \n Proficiency in Looker and Periscope \n \n \n  This is an authentic Oscar Health job opportunity. Learn more about how you can safeguard yourself from recruitment fraud here. \n  At Oscar, being an Equal Opportunity Employer means more than upholding discrimination-free hiring practices. It means that we cultivate an environment where people can be their most authentic selves and find both belonging and support. We're on a mission to change health care - an experience made whole by our unique backgrounds and perspectives.. \n  Pay Transparency: \n  Final offer amounts, within the base pay set forth above, are determined by factors including your relevant skills, education, and experience. \n  Full-time employees are eligible for benefits including: medical, dental, and vision benefits, 11 paid holidays, paid sick time, paid parental leave, 401(k) plan participation, life and disability insurance, and paid wellness time and reimbursements. \n  Reasonable Accommodation: \n  Oscar applicants are considered solely based on their qualifications, without regard to applicant's disability or need for accommodation. Any Oscar applicant who requires reasonable accommodations during the application process should contact the Oscar Benefits Team (accommodations@hioscar.com) to make the need for an accommodation known.", "cleaned_desc": " 6+ years of data, analytics or reporting experience \n  3+ years of experience working with healthcare claims data \n  Strong working knowledge of health plan claims department operations, key performance metrics, processes and information flow \n  Familiarity with Actuary and Finance work regarding claims payments and estimating claims trends and experience working with such teams \n  Analytic and technical ability to develop dashboards and reports \n  Strong written and verbal communication skills \n \n Bonus Points \n ", "techs": ["dashboards", "reports"]}, "98b7ef251656ba75": {"terms": ["data science"], "salary_min": 56.0, "salary_max": 61.0, "title": "Coverage Review Pharmacist", "company": "The Judge Group", "desc": "***Applicant must have Tennessee Pharmacist License. *** \n Preference listed in order:  1. Medical (provider-administered) coverage review experience 2. Coverage review experience (self-administered) 3. Previous positions with health plan/PBM. \n Qualifications: \n Doctor of Pharmacy (PharmD) Degree \n Licensed in Tennessee to practice Pharmacy, or eligible for licensure in the state of Tennessee to practice Pharmacy \n 3 years - Clinical experience required \n At least 2 years of Coverage Review or PBM exp required \n Ability to work independently with minimal supervision or function in a team environment sharing responsibility, roles and accountability. \n Competency in compendia navigation and research \n Proficient in Microsoft Office (Outlook, Word, Excel and Powerpoint) \n Must be a team player, be organized and have the ability to handle multiple projects \n Excellent oral and communication skills \n Strong interpersonal and organizational skills \n Solid understanding of regulatory guidelines (FDA, NCQA, EQRO, CMS) required \n Knowledge of medical and pharmacy products \n Responsibilities: \n Responsible for various activities associated with coverage reviews and appeals including the review of medication related prior \n authorizations, pharmacy appeals, and member grievances focused on medications. \n Performs prospective and retrospective coverage reviews and appeals per State and Federal regulations \n Responds to prescriber, pharmacy provider, member appeals, grievances and complaints related to the provision of \n pharmaceutical services within established time periods \n Builds and maintains decision trees in the prior authorization system \n Maintains denial rationale associated with clinical criteria and ensures that decision letters meet regulatory compliance \n Job Type: Contract \n Salary: $56.00 - $61.00 per hour \n Schedule: \n \n 8 hour shift \n Day shift \n Monday to Friday \n No weekends \n \n Education: \n \n Doctorate (Required) \n \n Experience: \n \n Clinical Pharmacist: 3 years (Required) \n Coverage Review or PBM: 2 years (Required) \n \n License/Certification: \n \n Registered Pharmacist (Required) \n Licensed Pharmacist in State of TN (Required) \n \n Work Location: Remote", "cleaned_desc": " Proficient in Microsoft Office (Outlook, Word, Excel and Powerpoint) \n Must be a team player, be organized and have the ability to handle multiple projects \n Excellent oral and communication skills \n Strong interpersonal and organizational skills \n Solid understanding of regulatory guidelines (FDA, NCQA, EQRO, CMS) required \n Knowledge of medical and pharmacy products \n Responsibilities: \n Responsible for various activities associated with coverage reviews and appeals including the review of medication related prior \n authorizations, pharmacy appeals, and member grievances focused on medications. ", "techs": ["microsoft office (outlook", "word", "excel", "powerpoint)", "fda", "ncqa", "eqro", "cms"]}, "739fd2ebfd5f4e28": {"terms": ["data science", "machine learning engineer"], "salary_min": 80.0, "salary_max": 90.0, "title": "Data Scientist/NLP Data Scientist", "company": "US Tech Solutions Private Limited", "desc": "Job Title: Data Scientist/NLP Data Scientist \n Location: (Remote) \n Duration: 06+ Months \n Position Type: Contract \n Description: \n \n We're seeking a talented and innovative NLP/Information Retrieval Scientist to join our team. In this role, you will play a pivotal part in enhancing Large Language Models (LLMs) to provide more accurate, context-aware, and creatively curated responses with real-world applications. \n As an NLP/Information Retrieval Scientist, you will develop and to improve the usability and creativity of our LLM responses. You will collaborate closely with our multidisciplinary team of researchers and engineers to not only advance the technical aspects but also bring real-world relevance and creativity into our language models. \n The successful candidate will use the latest innovations in NLP and LLM to propose software solutions to improve customer experience. The Remote Sensing Data Scientist will design and test algorithms, conduct prototyping to evaluate possible scenarios leveraging computational and statistical techniques for the development of novel approaches for remotely sensed data. \n \n Responsibilities: \n \n Expertise with NLP or Information \n Proficiency in Python or in another high-level programming language \n Experience in developing statistical, and machine learning models for environmental and agronomical applications \n Familiarity with LLM \n Experience analyzing and presenting complex data and proven problem-solving abilities \n Strong publication record in leading scientific journals \n \n Experience: \n \n Ph.D. with 5-6 years of experience (or MS with 7-8+ years of post-MS experience), Computer Science, Electrical Engineering, Physics, Mathematics, Statistics or an Analytics discipline. \n \n Skills: \n \n Experience working with agricultural/biological scientific data is highly desired \n Drive for translating business problems into research initiatives that deliver business value \n Creativity in defining challenging exploratory projects. \n \n Education: \n \n Master's or PhD in Computer Science, Electrical Engineering, Physics, Mathematics, Statistics or an Analytics discipline.. \n \n About US Tech Solutions: \n US Tech Solutions is a global staff augmentation firm providing a wide range of talent on-demand and total workforce solutions. To know more about US Tech Solutions, please visit www.ustechsolutions.com. \n Recruiter Details: \n Name:  Simant Rai Email:  simant.rai@ustechsolutionsinc.com Internal Reference Id:  23-31369 \n Job Types: Contract, Full-time \n Salary: $80.00 - $90.00 per hour \n Schedule: \n \n 8 hour shift \n \n Work Location: Remote", "cleaned_desc": " The successful candidate will use the latest innovations in NLP and LLM to propose software solutions to improve customer experience. The Remote Sensing Data Scientist will design and test algorithms, conduct prototyping to evaluate possible scenarios leveraging computational and statistical techniques for the development of novel approaches for remotely sensed data. \n \n Responsibilities: \n \n Expertise with NLP or Information \n Proficiency in Python or in another high-level programming language \n Experience in developing statistical, and machine learning models for environmental and agronomical applications \n Familiarity with LLM   Experience analyzing and presenting complex data and proven problem-solving abilities \n Strong publication record in leading scientific journals \n \n Experience: \n \n Ph.D. with 5-6 years of experience (or MS with 7-8+ years of post-MS experience), Computer Science, Electrical Engineering, Physics, Mathematics, Statistics or an Analytics discipline. \n \n Skills: ", "techs": ["nlp", "llm", "python", "high-level programming language", "statistical techniques", "machine learning models", "environmental applications", "agronomical applications", "llm", "data analysis", "problem-solving", "scientific journals"]}, "0747b67cc572cfb9": {"terms": ["data science", "machine learning engineer"], "salary_min": 114918.08, "salary_max": 145511.89, "title": "Kubernetes Engineer(W2)", "company": "Amaze Systems", "desc": "W2 ONLY \n Job Title: Kubernetes Enginner Location: Cupertino ,CA / Remote is Fine too Duration: 6 Months Contract with Possible ext \n Long term contract W2 \n Must Have skills: Kubernetes \u2013 Very Strong and #1 \u2013 4 to 5 years Data Pipelines \u2013 ETL Preferred \u2013 Bring data to send back to other team Understanding of Python is good and will code in Python \u2013 Not working on API\u2019s Good Understanding of Machine Learning Pipelines Argo WorkFlow Experience Docker and Jenkins \u2013 Would be good Workflow Experience \u2013 Would be good \n Job Description: \n \n Summary of the project/initiatives which describes what\u2019s being done: \n \n o Build, modernize and maintain the U.S. Bank AI/Client Platform & related frameworks / solutions. o Participate and contribute in architecture & design reviews. o Build/Deploy AI/Client platform in Azure with open-source applications (Argo, Jupyter Hub/Kubeflow) and/or cloud/SaaS solutions (Azure Client, Databricks). o You will design, develop, test, deploy, and maintain distributed & GPU-enabled Machine Learning Pipelines using K8s/AKS based Argo Workflow Orchestration solutions, while collaborating with Data Scientists. o Enable/Support platform to do distributed data processing using Apache Spark and other distributed / scale technologies. o Build ETL pipelines, ingress / egress methodologies in context to AIML use-cases. o Build highly scalable backend REST APIs for metadata management and other misc. business needs. o Deploy Application in Azure Kubernetes Service using GitLab, Jenkins, Docker, Kubectl, Helm and Manifest o Experience in branching, tagging, and maintaining the versions across different environments in GitLab. o Review code developed by other developers and provide feedback to ensure best practices (e.g., design patterns, accuracy, testability, efficiency etc.) o Work with relevant engineering, operations, business lines, and infrastructure groups to ensure effective architectures and designs and communicate findings clearly to technical and non-technical partners. o Perform functional, benchmark & performance testing and tuning to achieve performant AIML workflow(s), interactive notebook user experiences, and pipelines. o Assess, design & optimize the resources capacities for Client based resource (GPU) intensive workloads. o Communicate processes and results of the application with all parties involved in the product team, like engineers, product owner, scrum master and third-party vendors. \n Top 5-10 responsibilities for this position: o Experience developing AIML platforms & frameworks (including core offerings such as model training, inferencing, distributed/parallel programming), preferably on Kubernetes and native cloud. o Highly skilled with Python or JAVA programming languages o Highly skilled with database languages like SQL & NoSQL o Experience designing, developing, and deploying highly maintainable, extensible, and testable distributed applications using Python and other languages. o Experience developing ETL pipelines and REST APIs in Python using Flask or Django o Experienced with technologies/frameworks including Kubernetes, Helm Charts, Notebooks, Workflow orchestration tools, and CI/CD & monitoring frameworks. \n Basic Qualifications: \n \n Bachelor\u2019s/master\u2019s degree in computer science or data science \n 6 \u2013 8 years of experience in software development and with data structures/algorithms \n \n Required Technical Qualifications / Skills: \n \n Experience with AI/Client open-source projects in large datasets using Jupyter, Argo, Spark, Pytorch, TensorFlow \n Experience creating Unit and Functional test cases using PyTest, UnitTest \n Experience with training and tuning models in Machine Learning \n Experience working with Jupyter Hub \n Experience with DB management system like PostgreSQL \n Experience in searching, monitoring, and analyzing logs using Splunk/Kibana \n GraphQL/Swagger implementation knowledge \n Strong understanding and experience with Kubernetes for availability and scalability of applications in Azure Kubernetes Service \n Experience building CI/CD pipelines using Cloudbees Jenkins, Docker, Artifactory, Kubernetes, Helm Charts and Gitlab \n Experience with tools like Jupyter Hub, Kubeflow, MLFlow, TensorFlow, Scikit, Apache Spark, Kafka \n Experience with workflow orchestration tools such as Apache Airflow, Argo workflows \n Familiarity with Conda, PyPi, and Node.js package builds \n \n Preferred Qualifications / Skills: \n \n Experience with AI/Client open-source projects in large datasets using Jupyter, Argo, Spark, Pytorch, TensorFlow \n Experience creating Unit and Functional test cases using PyTest, UnitTest \n Experience with training and tuning models in Machine Learning \n Experience working with Jupyter Hub \n Experience with DB management system like PostgreSQL \n Experience in searching, monitoring, and analyzing logs using Splunk/Kibana \n GraphQL/Swagger implementation knowledge \n Strong understanding and experience with Kubernetes for availability and scalability of applications in Azure Kubernetes Service \n Experience building CI/CD pipelines using Cloudbees Jenkins, Docker, Artifactory, Kubernetes, Helm Charts and Gitlab \n Experience with tools like Jupyter Hub, Kubeflow, MLFlow, TensorFlow, Scikit, Apache Spark, Kafka \n Experience with workflow orchestration tools such as Apache Airflow, Argo workflows \n Familiarity with Conda, PyPi, and Node.js package builds \n \n ESSENTIAL FUNCTIONS: \n Designs and writes complex code in several languages relevant to our existing product stack, with a focus on automation \n \n Configures, tunes, maintains and installs applications systems and validates system functionality \n Monitors and fine tunes applications system to achieve optimum performance levels and works with hardware teams to resolve issues with hardware and software \n Develops and maintains department's knowledge database containing enterprise issues and possible resolutions. \n Develops models of task problem domain for which a system will be designed or built. \n Uses models, hypotheses, and cognitive analysis techniques to elicit real problem-solving knowledge from the experts \n Mediates between the expert and knowledge base; encodes for the knowledge base \n Acts as subject matter expert for difficult or complex application problems requiring interpretation of AI tools and principles \n Researches and prepares reports and studies on various aspects of knowledge acquisition, modeling, management, and presentation \n Develops and maintains processes, procedures, models, and templates for collecting and organizing knowledge into specialized knowledge representation programs \n Acts as vendor liaison for products and services to support development tools \n Maintains the definition, documentation, training, testing, and activation of Disaster Recovery/Business Continuity Planning to meet compliance standards \n Maintains a comprehensive operating system hardware and software configuration database/library of all supporting documentation to ensure data integrity \n Acts to improve the overall reliability of systems and to increase efficiency \n Works collaboratively with cross functional teams, using Agile / DevOps principles to bring products to life, achieve business objectives and serve customer needs \n \n Thanks and Regrads \n Rahul Sharma | Talent Acquisition Specialist \n Amaze Systems Inc. \n USA: 8951 Cypress Waters Blvd, Suite 160, Dallas, TX 75019 \n Canada: 55 York Street, Suite 401, Toronto, Ontario M5J 1R7 Canada \n UK: 3rd Floor, Chancery House ST Nicholas Way, Sutton Surrey SM1 1JB \n D: 669-305-7610 |Ext-916 \n E:  Rahul.sharma@amaze-systems.com   |  www.amaze-systems.com/ \n https://www.linkedin.com/in/rahul-sharma-552396191/ \n USA | Canada | UK | India \n Job Type: Contract \n Pay: $60,000.00 - $70,000.00 per hour \n Experience level: \n \n 8 years \n \n Schedule: \n \n Monday to Friday \n \n Work Location: Remote", "cleaned_desc": "W2 ONLY \n Job Title: Kubernetes Enginner Location: Cupertino ,CA / Remote is Fine too Duration: 6 Months Contract with Possible ext \n Long term contract W2 \n Must Have skills: Kubernetes \u2013 Very Strong and #1 \u2013 4 to 5 years Data Pipelines \u2013 ETL Preferred \u2013 Bring data to send back to other team Understanding of Python is good and will code in Python \u2013 Not working on API\u2019s Good Understanding of Machine Learning Pipelines Argo WorkFlow Experience Docker and Jenkins \u2013 Would be good Workflow Experience \u2013 Would be good \n Job Description: \n \n Summary of the project/initiatives which describes what\u2019s being done: \n \n o Build, modernize and maintain the U.S. Bank AI/Client Platform & related frameworks / solutions. o Participate and contribute in architecture & design reviews. o Build/Deploy AI/Client platform in Azure with open-source applications (Argo, Jupyter Hub/Kubeflow) and/or cloud/SaaS solutions (Azure Client, Databricks). o You will design, develop, test, deploy, and maintain distributed & GPU-enabled Machine Learning Pipelines using K8s/AKS based Argo Workflow Orchestration solutions, while collaborating with Data Scientists. o Enable/Support platform to do distributed data processing using Apache Spark and other distributed / scale technologies. o Build ETL pipelines, ingress / egress methodologies in context to AIML use-cases. o Build highly scalable backend REST APIs for metadata management and other misc. business needs. o Deploy Application in Azure Kubernetes Service using GitLab, Jenkins, Docker, Kubectl, Helm and Manifest o Experience in branching, tagging, and maintaining the versions across different environments in GitLab. o Review code developed by other developers and provide feedback to ensure best practices (e.g., design patterns, accuracy, testability, efficiency etc.) o Work with relevant engineering, operations, business lines, and infrastructure groups to ensure effective architectures and designs and communicate findings clearly to technical and non-technical partners. o Perform functional, benchmark & performance testing and tuning to achieve performant AIML workflow(s), interactive notebook user experiences, and pipelines. o Assess, design & optimize the resources capacities for Client based resource (GPU) intensive workloads. o Communicate processes and results of the application with all parties involved in the product team, like engineers, product owner, scrum master and third-party vendors. \n Top 5-10 responsibilities for this position: o Experience developing AIML platforms & frameworks (including core offerings such as model training, inferencing, distributed/parallel programming), preferably on Kubernetes and native cloud. o Highly skilled with Python or JAVA programming languages o Highly skilled with database languages like SQL & NoSQL o Experience designing, developing, and deploying highly maintainable, extensible, and testable distributed applications using Python and other languages. o Experience developing ETL pipelines and REST APIs in Python using Flask or Django o Experienced with technologies/frameworks including Kubernetes, Helm Charts, Notebooks, Workflow orchestration tools, and CI/CD & monitoring frameworks. \n Basic Qualifications: \n \n Bachelor\u2019s/master\u2019s degree in computer science or data science \n 6 \u2013 8 years of experience in software development and with data structures/algorithms \n \n Required Technical Qualifications / Skills:   \n Experience with AI/Client open-source projects in large datasets using Jupyter, Argo, Spark, Pytorch, TensorFlow \n Experience creating Unit and Functional test cases using PyTest, UnitTest \n Experience with training and tuning models in Machine Learning \n Experience working with Jupyter Hub \n Experience with DB management system like PostgreSQL \n Experience in searching, monitoring, and analyzing logs using Splunk/Kibana \n GraphQL/Swagger implementation knowledge \n Strong understanding and experience with Kubernetes for availability and scalability of applications in Azure Kubernetes Service \n Experience building CI/CD pipelines using Cloudbees Jenkins, Docker, Artifactory, Kubernetes, Helm Charts and Gitlab \n Experience with tools like Jupyter Hub, Kubeflow, MLFlow, TensorFlow, Scikit, Apache Spark, Kafka \n Experience with workflow orchestration tools such as Apache Airflow, Argo workflows \n Familiarity with Conda, PyPi, and Node.js package builds \n \n Preferred Qualifications / Skills: \n   Experience with AI/Client open-source projects in large datasets using Jupyter, Argo, Spark, Pytorch, TensorFlow \n Experience creating Unit and Functional test cases using PyTest, UnitTest \n Experience with training and tuning models in Machine Learning \n Experience working with Jupyter Hub \n Experience with DB management system like PostgreSQL \n Experience in searching, monitoring, and analyzing logs using Splunk/Kibana \n GraphQL/Swagger implementation knowledge \n Strong understanding and experience with Kubernetes for availability and scalability of applications in Azure Kubernetes Service \n Experience building CI/CD pipelines using Cloudbees Jenkins, Docker, Artifactory, Kubernetes, Helm Charts and Gitlab \n Experience with tools like Jupyter Hub, Kubeflow, MLFlow, TensorFlow, Scikit, Apache Spark, Kafka \n Experience with workflow orchestration tools such as Apache Airflow, Argo workflows \n Familiarity with Conda, PyPi, and Node.js package builds \n \n ESSENTIAL FUNCTIONS: \n Designs and writes complex code in several languages relevant to our existing product stack, with a focus on automation \n   Configures, tunes, maintains and installs applications systems and validates system functionality \n Monitors and fine tunes applications system to achieve optimum performance levels and works with hardware teams to resolve issues with hardware and software \n Develops and maintains department's knowledge database containing enterprise issues and possible resolutions. \n Develops models of task problem domain for which a system will be designed or built. \n Uses models, hypotheses, and cognitive analysis techniques to elicit real problem-solving knowledge from the experts \n Mediates between the expert and knowledge base; encodes for the knowledge base \n Acts as subject matter expert for difficult or complex application problems requiring interpretation of AI tools and principles \n Researches and prepares reports and studies on various aspects of knowledge acquisition, modeling, management, and presentation \n Develops and maintains processes, procedures, models, and templates for collecting and organizing knowledge into specialized knowledge representation programs \n Acts as vendor liaison for products and services to support development tools \n Maintains the definition, documentation, training, testing, and activation of Disaster Recovery/Business Continuity Planning to meet compliance standards \n Maintains a comprehensive operating system hardware and software configuration database/library of all supporting documentation to ensure data integrity \n Acts to improve the overall reliability of systems and to increase efficiency \n Works collaboratively with cross functional teams, using Agile / DevOps principles to bring products to life, achieve business objectives and serve customer needs \n \n Thanks and Regrads ", "techs": ["kubernetes", "data pipelines", "python", "machine learning pipelines", "argo workflow", "docker", "jenkins", "apache spark", "gitlab", "kubectl", "helm", "manifest", "postgresql", "splunk", "kibana", "graphql", "swagger", "cloudbees jenkins", "artifactory", "kubeflow", "mlflow", "tensorflow", "scikit", "apache airflow", "conda", "pypi", "node.js"]}, "77fe95125afcc520": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Senior Ansible Automation Engineer", "company": "Frontier Technology Inc.", "desc": "Overview: \n  \n   FTI is looking for a Senior Ansible Automation Engineer to join our team and who is excited as we are to build upon a culture that embodies excellence in all we do. Our culture revolves around the 4C\u2019s: Core Values, Commitment, Compassion, and Charity. It is very important to us to show our Passions for our Employees and Customers, while showing Love to our Neighbors in the Community. This DevOps Engineer position requires at least a DoD Secret clearance. This position is hybrid with 3 days a week onsite and is located in Colorado Springs, CO.\n   Responsibilities: \n  \n   FTI is looking for an experienced Ansible Automation professional to join our growing organization. This position requires experience with Continuous Integration/Continuous Delivery (CI/CD) using a pipeline to automatically take committed code, run it through tests, and optionally, deploy that code into production. A keen attention to detail, problem-solving abilities, and solid knowledge base are essential. The Automation Engineer will support the development, testing, and deployment of an advanced cyber operations program under U.S. Space Force (USSF). The Automation Engineer will collaborate with a diverse program team and must be able to communicate effectively in obtaining and synthesizing requirements. This role will understand Software Automation tools and develop relationships with development partners across the Cyber Operations (SZYO) program office in the following related tasks:\n  \n \n  Reponsibilities include the ability to identify areas for process automation improvement, automate existing and new processes, maintain, and deploy cloud infrastructure, and support the Agile software development lifecycle build process \n  The ideal candidate will have deep experience of Python & Ansible with networking technologies, such as routing, switching; managing heterogeneous environment \n  Full lifecycle of software systems; including development, testing and deployment \n  The candidate will be responsible for the development of automation solutions utilizing Ansible Automation Platform and RedHat \n  Leverage automation tools to reduce security compliance errors/vulnerabilities and improve Gitlab security reporting \n  Integrate with internal back-end infrastructure systems \n  Perform root cause analysis for security relevant issues for development environment \n  Investigate and resolve security technical CI/CD issues \n  Identifying technical problems and developing software updates and fixes \n  Assist in baselining and maintaining container standards and enforcement \n  Constantly looking to align to industry best practices to integrate security within a Software Factory \n  Experience analyzing Gitlab security scanning and working with development teams to resolve those issues \n  Travel: 10% \n \n \n  Demonstrated working Knowledge & Experience in the following Areas : Version control, Continuous Integration, Configuration management, Deployment Automation, Containers, Infrastructure Orchestration, Software Security Testing, Code Quality tools, Docker, Puppet, scripting, & Linux.\n  \n \n \n  Hands on Experience in the following technologies:  Ansible, Python, Elastic Search, Gitlab, NoSQL databases\n  \n \n  Education/Qualifications: \n  \n Bachelor\u2019s degree in Computer Science, Software Engineering, Data Science, Software Development or related field required \n  8+ years of experience with Automation \n  Requires at least a DoD Secret clearance with ability to obtain and maintain a Top Secret / SCI Eligibility. \n  Experience with Linux infrastructures, database SQL (MS SQL), CI/CD tools, scripting such as Python, Perl, Ruby, Scrum/Kanban/SAFe, Agile workflow methodologies \n  Experience with provisioning and orchestration tools including Jenkins and Terraform in both cloud and on-prem environments strongly preferred \n  Hands-on experience with building and managing release systems, code merging and promotion, and CI/CD workflows and tools \n  Experience with Puppet and Ansible in production environments \n  Experience with revision control source code repositories (Git, SVN, Mercurial, Perforce) \n  Experience working with and delivering using Agile practices \n  Monitoring experience with Splunk, Elk, Kibana, Grafana, etc. \n  Previous experience with infrastructure development, or development and operations \n  Experience with development and automated testing \n  Good interpersonal skills and communication with all levels of management \n  Able to multitask, prioritize, and manage time efficiently \n  Ability to work independently with geographically dispersed team \n \n \n   For this role, the targeted compensation range for candidates in Colorado is ($150K- $180K negotiable). Note: Starting pay will be based on a number of factors and commensurate with qualifications & experience. FTI has a location-based compensation structure; there may be a different range for candidates in other locations.\n  \n \n   #LI-GH1\n  \n \n   #LI-Onsite", "cleaned_desc": "  The candidate will be responsible for the development of automation solutions utilizing Ansible Automation Platform and RedHat \n  Leverage automation tools to reduce security compliance errors/vulnerabilities and improve Gitlab security reporting \n  Integrate with internal back-end infrastructure systems \n  Perform root cause analysis for security relevant issues for development environment \n  Investigate and resolve security technical CI/CD issues \n  Identifying technical problems and developing software updates and fixes \n  Assist in baselining and maintaining container standards and enforcement \n  Constantly looking to align to industry best practices to integrate security within a Software Factory \n  Experience analyzing Gitlab security scanning and working with development teams to resolve those issues \n  Travel: 10% \n    8+ years of experience with Automation \n  Requires at least a DoD Secret clearance with ability to obtain and maintain a Top Secret / SCI Eligibility. \n  Experience with Linux infrastructures, database SQL (MS SQL), CI/CD tools, scripting such as Python, Perl, Ruby, Scrum/Kanban/SAFe, Agile workflow methodologies \n  Experience with provisioning and orchestration tools including Jenkins and Terraform in both cloud and on-prem environments strongly preferred \n  Hands-on experience with building and managing release systems, code merging and promotion, and CI/CD workflows and tools \n  Experience with Puppet and Ansible in production environments \n  Experience with revision control source code repositories (Git, SVN, Mercurial, Perforce) \n  Experience working with and delivering using Agile practices \n  Monitoring experience with Splunk, Elk, Kibana, Grafana, etc. \n  Previous experience with infrastructure development, or development and operations \n  Experience with development and automated testing ", "techs": ["ansible automation platform", "redhat", "gitlab", "ci/cd tools", "python", "perl", "ruby", "scrum/kanban/safe", "jenkins", "terraform", "puppet", "ansible", "git", "svn", "mercurial", "perforce", "splunk", "elk", "kibana", "grafana"]}, "2b24cf50a80c4369": {"terms": ["data science"], "salary_min": 232000.0, "salary_max": 290000.0, "title": "Head of Data Analytics", "company": "Care.com", "desc": "About Care.com \n  Care.com is a consumer tech company with heart. We're on a mission to solve a human challenge we all face: finding great care for the ones we love. We're moms and dads and pet parents. We have parents and grandparents, so we understand that everyone, at some point in their lives, could use a helping hand. Our culture and our products reflect that. \n  Here, entrepreneurs, self-starters, team players, and big thinkers unite behind a common cause. Here, we're applying data analytics, AI, and the latest technologies to solve universal problems and connect people in new ways. If you like having autonomy, if you thrive on collaboration and building new things, and if you're all about using your talent for good, Care.com is the place for you. \n  Position Overview: \n  Care.com is seeking a dynamic and visionary leader for the role of Vice President of Analytics. In this critical position, you will spearhead our Data Science and Business Intelligence efforts, playing an integral role in shaping our data-driven future. You will be responsible for driving the strategic direction of analytics, fostering innovation, and ensuring that data insights empower our mission of connecting families with trusted caregivers. This role reports directly to the CFO and will advise leadership on data-driven strategies and best practices. \n  The ideal candidate has a unique combination of business acumen, strategic thinking, critical thinking, analytical rigor and leadership experience. S/he/they will enjoy working with data and be able to prioritize and deliver in a fast paced environment and lead high performing teams across both data science and business intelligence. \n  Responsibilities \n \n Lead and inspire a cross-functional team of data scientists, analysts, and BI experts to deliver data-driven solutions and insights. \n Develop and execute a data strategy that aligns with our business objectives, leveraging data for innovation and decision-making. \n Translate complex data findings into actionable recommendations and strategies, driving continuous improvement. \n Monitor industry trends and emerging technologies to stay at the forefront of analytics and data science. \n Advise leadership on best practices in data analysis, ensuring that data is used effectively to drive business decisions and outcomes. \n \n Qualifications: \n \n Bachelor's or advanced degree in Data Science, Computer Science, Statistics, or a related field. \n Proven experience in leading and managing data science and analytics teams with a minimum of 10 years of relevant experience. \n Strong expertise in data analytics, machine learning, and statistical modeling. \n Familiarity with technologies such as Python, R, SQL for data analysis. \n Experience with data warehousing and ETL tools. \n Knowledge of data visualization tools like Tableau, Power BI, or Looker. \n Understanding of Data cloud platforms, such as Snowflake, S3, BigQuery for data storage and processing. \n Excellent communication and leadership skills to influence and inspire the organization. \n Strategic thinking with a focus on the practical application of data for business impact. \n Previous experience in a consumer-focused, high-growth technology company is a plus. \n \n For a list of our Perks + Benefits, click here! \n  **Care.com supports diverse families and communities and seeks employees who are just as diverse. As an equal opportunity employer, Care.com recognizes the power of a diverse and inclusive workforce and encourages applications from individuals with varied experiences, perspectives, and backgrounds. Care.com is committed to providing reasonable accommodations for qualified individuals with disabilities. If you need assistance or an accommodation, please reach out to talent@care.com.** \n  ___________________________________________________________________________ \n  Company Overview: \n  Available in more than 20 countries, Care.com is the world's leading platform for finding and managing high-quality family care. Care.com is designed to meet the evolving needs of today's families and caregivers, offering everything from household tax and payroll services and customized corporate benefits packages covering the care needs of working families, to innovating new ways for caregivers to be paid and obtain professional benefits. Since 2007, families have relied on Care.com's industry-leading products\u2014from child and elder care to pet care and home care. Care.com is an IAC company (NASDAQ: IAC). \n  Salary Range: 232,000 - 290,000. The base salary range above represents the anticipated low and high end of the salary range for this position. Actual salaries may vary and may be above or below the range based on various factors including but not limited to work location, experience, and performance. The range listed is just one component of Care's total compensation package for employees. Other rewards may include annual bonuses and short- and long-term incentives. In addition, Care.com provides a variety of benefits to employees, including health insurance coverage, life, and disability insurance, a generous 401K employer matching program, paid holidays, and paid time off (PTO).", "cleaned_desc": "  Responsibilities \n \n Lead and inspire a cross-functional team of data scientists, analysts, and BI experts to deliver data-driven solutions and insights. \n Develop and execute a data strategy that aligns with our business objectives, leveraging data for innovation and decision-making. \n Translate complex data findings into actionable recommendations and strategies, driving continuous improvement. \n Monitor industry trends and emerging technologies to stay at the forefront of analytics and data science.   Advise leadership on best practices in data analysis, ensuring that data is used effectively to drive business decisions and outcomes. \n \n Qualifications: \n \n Bachelor's or advanced degree in Data Science, Computer Science, Statistics, or a related field. \n Proven experience in leading and managing data science and analytics teams with a minimum of 10 years of relevant experience.   Strong expertise in data analytics, machine learning, and statistical modeling. \n Familiarity with technologies such as Python, R, SQL for data analysis. \n Experience with data warehousing and ETL tools. \n Knowledge of data visualization tools like Tableau, Power BI, or Looker. \n Understanding of Data cloud platforms, such as Snowflake, S3, BigQuery for data storage and processing. \n Excellent communication and leadership skills to influence and inspire the organization. ", "techs": ["python", "r", "sql", "tableau", "power bi", "looker", "snowflake", "s3", "bigquery"]}, "2c026534cfc8d80f": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Director of Product Management", "company": "Raytheon Technologies Corporate Headquarters", "desc": "Date Posted:  2023-06-21\n   Country:  United States of America\n   Location:  UTNY1: UT-NY-Remote Remote Location, Remote City, NY, 10001 USA\n   Position Role Type:  Remote\n   RTX Corporation is an Aerospace and Defense company that provides advanced systems and services for commercial, military and government customers worldwide. It comprises three industry-leading businesses \u2013 Collins Aerospace Systems, Pratt & Whitney, and Raytheon. Its 185,000 employees enable the company to operate at the edge of known science as they imagine and deliver solutions that push the boundaries in quantum physics, electric propulsion, directed energy, hypersonics, avionics and cybersecurity. The company, formed in 2020 through the combination of Raytheon Company and the United Technologies Corporation aerospace businesses, is headquartered in Arlington, VA. \n \n  To realize our full potential, RTX is committed to creating a company where all employees are respected, valued and supported in the pursuit of their goals. We know companies that embrace diversity in all its forms not only deliver stronger business results, but also become a force for good, fueling stronger business performance and greater opportunity for employees, partners, investors and communities to succeed. \n \n  The following position is to join our RTX Corporate, Enterprise Services, Research Center or BBN team: \n  Director of Product Management \u2013 Enterprise Data Services (EDX) \n \n  Overview: \n  We are seeking a Product Management leader to oversee and grow the Product Management team within RTX\u2019s Enterprise Data Services unit (\u2018the EDX\u2019). In addition to serving as the day-to-day Director of the discipline, this leader will also drive the roadmap and business outcomes for Xeta, RTX\u2019s suite of enterprise productivity tools. \n \n  Xeta comprises three tools that deliver critical capabilities to RTX\u2019s teams. XetaAnalytics is RTX\u2019s enterprise data platform, which provides data practitioners (business analysts, data scientists) easy access to data management and analysis capabilities while also accelerating time-to-insight for RTX\u2019s decision makers. XetaDev is RTX\u2019s DevSecOps offering, providing software development teams with the tools they need to release high-quality code faster. Xeta Cloud is RTX\u2019s enterprise cloud offering; moving to the cloud is a major component of RTX\u2019s Digital Transformation strategy. While this role will primarily focus on product management oversight for XetaAnalytics, this leader will also lead the effort to harmonize the user experience across all three components of the Xeta portfolio. \n \n  The role will require deep and effective collaboration with leaders from the EDX\u2019s other disciplines: Design, Program Management, Software Engineering, and Applied Data. \n \n  Raytheon Technologies is in the midst of a multi-year digital and data transformation. In addition to responsibilities at the EDX, this role will entail engagement with executive stakeholders and leaders from across our business units. As the Director of Product Management, you will evangelize a \u2018product mindset\u2019 across the enterprise, helping business leaders appreciate the business value of contemporary product development frameworks centered on continuous product optimization. \n \n  Reporting to the VP of Data, Strategy & Products, the successful candidate will have strong communication skills, a passion for mentoring and growing a team, and the ability to navigate the complexities of a large, Fortune 50 global enterprise. \n \n  Job Responsibilities: \n \n  Ensure that the XetaAnalytics platform and other EDX products deliver business outcomes that align with Raytheon Technologies\u2019 overall business strategy. \n \n \n  Work across EDX teams and stakeholders to continuously evolve the vision for XetaAnalytics to strengthen stakeholder support and buy-in. \n  Lead the harmonization of the user experience across the Xeta Portolio (XetaAnalytics, XetaDev, XetaCloud). \n  Drive collaboration across the EDX disciplines to achieve alignment on the XetaAnalytics vision and roadmap. \n  Lead the definition and execution of the go-to-market strategy for XetaAnalytics with the intent of driving adoption and accelerating business outcomes. \n  Oversee the EDX\u2019s Product Management team, providing mentoring to all members and helping them chart a course for their own professional development. \n  Establish best practices and set standards for all product management deliverables including product visions, product roadmaps, backlog prioritization, measurement strategies, go-to-market strategies, and ROI projections and analysis. \n \n \n  Basic Qualifications: \n \n  15+ years of experience in software product development. \n  An established leader with a proven track record of leading teams and influencing executive decision makers. \n  Significant experience with modern data platforms: setting the platform vision and scaling up to achieve the desired business value. \n  Given that XetaAnalytics incorporates several COTS tools, deep familiarity with applications such as Databricks, Snowflake, Kobai, Jupyter, is required. \n  Expertise in practices related to understanding customer needs and market opportunity including user interviews, observational research, surveys, prototype testing, A/B testing, and opportunity sizing. \n  Expertise in Agile software delivery practices and expectations. \n \n \n  Proven ability to translate market and user needs into product strategies that deliver target business outcomes. \n  Expert working knowledge of financial analysis methodologies, including NPV, IRR, ROI and cash flow. \n  Experience with building business cases for multi-year investments in enterprise platforms and software products. \n  Ability to communicate clearly and effectively to influence multi-disciplinary teams and develop strong partnerships across functions to drive measurable operational results. \n  U.S. citizenship is required, as only U.S. citizens are authorized to access information under this program/contract. \n \n \n  Preferred Qualifications: \n \n  Possesses strong interpersonal skills to interact effectively at all levels within the company. \n  Ability to excel in a fast-paced and entrepreneurial environment with high degree of autonomy and accountability. \n  Ideal candidate is a highly technical, collaborative, detail-oriented, reliable individual who strives to deliver the highest quality products. \n  Experience within the Aerospace and Defense industry a plus. \n \n \n  Location: \n \n  Hybrid (preferred) or fully Remote options available for this role. \n \n  (Candidates local to the greater New York office will be expected to support a Hybrid work arrangement working both onsite and offsite as needed.) \n \n  Education: \n \n  Bachelor's degree in a related discipline. \n  Advanced degree in Computer Science or Data Science is a plus. \n  MBA is a plus. \n \n \n  Typically requires: \n \n  A University Degree or equivalent experience and minimum 14 years prior relevant experience, or An Advanced Degree in a related field and minimum 12 years\u2019 experience. \n \n \n  Engineering/Other Technical Positions:  \n \n Typically requires a degree in Science, Technology, Engineering or Mathematics (STEM) and a minimum of 14 years of prior relevant experience unless prohibited by local laws/regulations. \n \n \n  Requires: \n \n  Advanced business knowledge, general management and \n \n  leadership capability to lead business or functional teams. \n  The salary range for this role is 165,000 USD - 331,000 USD; however, Raytheon Technologies considers several factors when extending an offer, including but not limited to, the role and associated responsibilities, a candidate\u2019s work experience, location, education/training, and key skills. Hired applicants may be eligible for benefits, including but not limited to, medical, dental, vision, life insurance, short-term disability, long-term disability, 401(k) match, flexible spending accounts, flexible work schedules, employee assistance program, Employee Scholar Program, parental leave, paid time off, and holidays. Specific benefits are dependent upon the specific business unit as well as whether or not the position is covered by a collective-bargaining agreement. Hired applicants may be eligible for annual short-term and/or long-term incentive compensation programs depending on the level of the position and whether or not it is covered by a collective-bargaining agreement. Payments under these annual programs are not guaranteed and are dependent upon a variety of factors including, but not limited to, individual performance, business unit performance, and/or the company\u2019s performance.\n   RTX is An Equal  Opportunity/Affirmative  Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status, age or any other federally protected class. \n  Privacy Policy and Terms: \n  Click on this link to read the Policy and Terms", "cleaned_desc": " \n  15+ years of experience in software product development. \n  An established leader with a proven track record of leading teams and influencing executive decision makers. \n  Significant experience with modern data platforms: setting the platform vision and scaling up to achieve the desired business value. \n  Given that XetaAnalytics incorporates several COTS tools, deep familiarity with applications such as Databricks, Snowflake, Kobai, Jupyter, is required. \n  Expertise in practices related to understanding customer needs and market opportunity including user interviews, observational research, surveys, prototype testing, A/B testing, and opportunity sizing. \n  Expertise in Agile software delivery practices and expectations. \n \n \n  Proven ability to translate market and user needs into product strategies that deliver target business outcomes. \n  Expert working knowledge of financial analysis methodologies, including NPV, IRR, ROI and cash flow. \n  Experience with building business cases for multi-year investments in enterprise platforms and software products. \n  Ability to communicate clearly and effectively to influence multi-disciplinary teams and develop strong partnerships across functions to drive measurable operational results. \n  U.S. citizenship is required, as only U.S. citizens are authorized to access information under this program/contract. \n \n \n  Preferred Qualifications: \n ", "techs": ["databricks", "snowflake", "kobai", "jupyter"]}, "d588b85f17ac264c": {"terms": ["data science"], "salary_min": 100000.0, "salary_max": 158000.0, "title": "Senior Sales Analytics and Insights Analyst", "company": "Rippling", "desc": "About Rippling \n \n \n   Rippling gives businesses one place to run HR, IT, and Finance. It brings together all of the workforce systems that are normally scattered across a company, like payroll, expenses, benefits, and computers. For the first time ever, you can manage and automate every part of the employee lifecycle in a single system.\n  \n \n \n  Take onboarding, for example. With Rippling, you can hire a new employee anywhere in the world and set up their payroll, corporate card, computer, benefits, and even third-party apps like Slack and Microsoft 365\u2014all within 90 seconds.\n  \n \n \n  Based in San Francisco, CA, Rippling has raised $1.2B from the world\u2019s top investors\u2014including Kleiner Perkins, Founders Fund, Sequoia, Greenoaks, and Bedrock\u2014and was named one of America's best startup employers by Forbes.\n  \n \n \n  About the role \n \n \n \n  Rippling is looking for a standout Senior Sales Analyst to develop visualizations and uncover insights that support the growth of the company and sales team. You\u2019ll work closely with colleagues to provide visibility into the performance of the business, identify key trends, and meet our analytics needs as the organization grows. You\u2019ll also collaborate closely with strategy, sales leadership and other key cross-functional partners to define, build, and track KPIs.\n  \n \n \n  The ideal candidate will have worked in fast-paced environments before, ideally at a multi-product SaaS company and will have made a measurable impact to the sales organization. You should also be comfortable tackling ambiguous and challenging problems and working independently as well as part of a team. This is an opportunity to work on high-visibility strategic initiatives in a rapidly growing sales organization.\n  \n \n \n  What you will do \n \n \n  Partner with Sales Development & Sales teams to understand their work. Use your understanding to define, document and own actionable metrics to help guide decision-making at Rippling. \n  Develop and own critical reporting and self-serve dashboards that provide insights into Rippling\u2019s business performance. \n  Collaborate with partners within data science and data engineering to build, document, and manage our core data tables for Sales Analytics. \n  Individually own and drive analyses, workstreams, and high priority projects. \n  Proactively provide insights on sales performance and business processes. \n \n \n \n  What you will need \n \n \n  3+ years working with data, ideally partnering with GTM orgs (Marketing, Sales, Customer Success) \n  Ability to write complex SQL and build data pipelines, ideally within Snowflake and DBT \n  You have a \u201cget it done\u201d attitude and want to build something that lasts. Not only do you have the ability and the desire to architect the high level strategy, you want to operationalize it and have high attention to detail \n  Proficiency in data visualization, with expertise with tools like Tableau, Snowflake, DBT, Github \n  Adept at tailoring presentations to executives, managers, and individual contributors within the organization. \n  Experience in developing definitional documentation, as well as leading educational sessions for business teams on dashboards and analytical insights. \n  Experience with Python or R a plus \n \n \n \n  Additional Information \n \n \n   Rippling is an equal opportunity employer. We are committed to building a diverse and inclusive workforce and do not discriminate based on race, religion, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, age, sexual orientation, veteran or military status, or any other legally protected characteristics, Rippling is committed to providing reasonable accommodations for candidates with disabilities who need assistance during the hiring process. To request a reasonable accommodation, please email accomodations@rippling.com\n  \n \n \n  Rippling highly values having employees working in-office to foster a collaborative work environment and company culture. For office-based employees (employees who live within a 40 mile radius of a Rippling office), Rippling considers working in the office, at least three days a week under current policy, to be an essential function of the employee's role.\n  \n \n \n  This role will receive a competitive salary + benefits + equity. The salary for US-based employees will be aligned with one of the ranges below based on location.\n  \n \n \n  A variety of factors are considered when determining someone\u2019s compensation\u2013including a candidate\u2019s professional background, experience, and location. Final offer amounts may vary from the amounts listed below.", "cleaned_desc": " \n \n  3+ years working with data, ideally partnering with GTM orgs (Marketing, Sales, Customer Success) \n  Ability to write complex SQL and build data pipelines, ideally within Snowflake and DBT \n  You have a \u201cget it done\u201d attitude and want to build something that lasts. Not only do you have the ability and the desire to architect the high level strategy, you want to operationalize it and have high attention to detail \n  Proficiency in data visualization, with expertise with tools like Tableau, Snowflake, DBT, Github \n  Adept at tailoring presentations to executives, managers, and individual contributors within the organization. \n  Experience in developing definitional documentation, as well as leading educational sessions for business teams on dashboards and analytical insights. \n  Experience with Python or R a plus \n \n \n \n  Additional Information ", "techs": ["snowflake", "dbt", "tableau", "github", "python", "r"]}, "30b07e5d3d703199": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Senior Actuary (Remote, US)", "company": "Openly", "desc": "Openly is rebuilding insurance from the ground up. We are re-envisioning and enhancing every aspect of the customer experience. Doing this requires a rapidly growing team of exceptional, curious, empathetic people with a wide range of skill sets, spanning technology, data science, product, marketing, sales, service, claims handling, finance, etc. \n  Now is the perfect time to join the journey. Here's why \n \n It's working . We're in multiple states and on our way to operating countrywide. We have thousands of agents selling our product and millions of dollars of annual customer premiums. \n We're well-backed & stable.  We closed our $100M Series D fundraise. We are supported by some of the top investors globally, including Google's \"Gradient\" AI-focused fund, Obvious Ventures, Advance Venture Partners, Eden Global Partners, and Clocktower Technology Ventures. \n It's not too late!  Despite this traction and stability, we're still early enough in the journey that there's time to make a real difference during Openly's formative period. \n \n If you'd like to understand more about Openly's mission, consider checking out this video (https://vimeo.com/267654520) from a company pitch we gave several years ago at Techstars. \n \n  Job Details \n  We are seeking a  Senior Actuary  to lead insurance product forecasting. You will play a critical role in guiding strategic decisions across insurance product, reinsurance, and operations by providing insight into various future growth and profitability outcomes. In addition to thoroughly evaluating our data and performing comprehensive scenario analyses, we will look to you to drive the continuous improvement of the underlying forecasting models to best leverage our rapidly growing data volume using the latest technology & prediction methods. As a member of the Actuarial & Product Analysis team within Insurance Product Research, you will have the support of Actuarial Engineering and Data Science. We are looking for a self-motivated, high-energy individual who thrives in a fast-paced, performance-driven environment. \n  Our tech stack consists of GitHub, GCP/BigQuery, Python. \n  Key Responsibilities \n \n Spearheading our loss and premium forecasting capabilities, revolutionizing our approach to monitor actual outcomes, uncover insights, and translate them into valuable recommendations for product enhancement to help drive success of the organization. \n Collaborate closely with our Actuarial and Prediction Engineering teams, leveraging advanced modeling tools to construct a durable forecasting framework, harnessing the power of cutting-edge technology and data-driven insights to develop a robust system that enables accurate and insightful forecasts. \n Support the refinement of our actuarial analytical framework by contributing to the design of enhancements or exploring the development of fresh methodologies and approaches. \n Design and develop a resilient methodology for projecting catastrophe losses that can adapt and expand in tandem with our growth. \n Collaborate cross-functionally to acquire valuable insights into drivers of our profitability and offer useful feedback based on our comprehensive analyses. \n Mentor, guide, and support junior team members \u2013 utilize your experience and expertise to share valuable insights, provide constructive feedback, and help cultivate their skills and growth. \n \n Requirements \n \n ACAS/FCAS with 7+ years of actuarial experience \n Significant experience in personal lines insurance or actuarial forecasting. \n Experience working in SQL. \n Demonstrated aptitude for working in Python. \n Ability to operate in ambiguity \u2013 identifying/defining complex business problems and developing creative analytical solutions. \n Strong communication and collaboration skills. \n Strong decision-making skills. \n \n #LI-CB1 \n \n  Benefits & Perks \n \n Remote-First Culture - We supported #remotelife long before it was a given. We'll keep promoting it. \n Competitive Salary & Equity \n Comprehensive Medical, Dental, and Vision Plan Offerings \n Life and disability coverage including voluntary options \n Competitive PTO - 20 days and 11 paid holidays (including floating holidays) per year under the Company's vacation and holiday policies.  \n Parental Leave - 12 weeks paid for eligible employees \n 401K Company Contribution - Openly contributes 3% of the employee's gross income, even if the employee does not contribute. \n Work-from-home stipend - We provide a $1,500 allowance to spend on setting up your home workplace \n Annual Professional Development Fund: Each employee has $2,000 in professional development (PD) funds to spend on activities or resources annually. We want each Openly employee to achieve personal and professional success and to feel supported, confident, and informed about improving their efficiency and productivity. \n Be Well Program - Employees receive $50 per month to use towards your overall well-being \n Paid Volunteer Service Hours \n Referral Program and Reward \n \n Depending on position, Employees generally are eligible for cash incentive compensation, including commissions for sales eligible roles. In all cases, eligibility for compensation and benefits is subject to applicable plan and policy terms in effect from time to time. \n  U.S. Citizens, Green Card Holders, and those authorized to work in the U.S. for any employer and currently residing in the US will be considered. \n  Openly is committed to equal employment opportunity and non-discrimination for all employees and qualified applicants without regard to a person's race, color, sex, gender identity or expression, age, religion, national origin, ancestry, ethnicity, disability, veteran status, genetic information, sexual orientation, marital status, or any characteristic protected under applicable law. Openly is an E-Verify Employer in the United States. Openly will make reasonable accommodations for qualified individuals with known disabilities under applicable law.", "cleaned_desc": " \n Requirements \n \n ACAS/FCAS with 7+ years of actuarial experience \n Significant experience in personal lines insurance or actuarial forecasting. \n Experience working in SQL. \n Demonstrated aptitude for working in Python. \n Ability to operate in ambiguity \u2013 identifying/defining complex business problems and developing creative analytical solutions. \n Strong communication and collaboration skills. \n Strong decision-making skills. ", "techs": ["acas/fcas", "sql", "python"]}, "feeff1dbf446c3bc": {"terms": ["data science"], "salary_min": 120363.016, "salary_max": 152406.39, "title": "Deep Learning Engineer", "company": "Cyberjin", "desc": "Hybrid/Remote role \n  Locations in multiple States \n  We're looking for a Deep Learning Engineer to join us as part of the founding engineering team. You will have the opportunity to work closely with the CEO to build new features and roll out new products - all in the deep learning on mobile space. \n \n  Ideal candidate traits \n  Enjoys significant ownership over user-facing product \n  \u200d Can work independently \n  Is comfortable turning research papers into product \n  Has 2 - 10 years experience with deep learning or has a PhD in a STEM field \n  Builds with a product-first approach. You ship code quickly and care about the real world impact of your code. \n  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred \n   \n Zp8NTSdgeL", "cleaned_desc": "  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred ", "techs": ["python", "deep learning", "tensorflow"]}, "49623b275e9979a6": {"terms": ["data science"], "salary_min": 120675.25, "salary_max": 152801.75, "title": "Deep Learning Engineer", "company": "Cyberjin", "desc": "Remote Position \n  We're looking for a Deep Learning Engineer to join Dyneti as part of the founding engineering team. You will have the opportunity to work closely with the CEO to build new features and roll out new products - all in the deep learning on mobile space. \n \n  Ideal candidate traits \n  Enjoys significant ownership over user-facing product \n  \u200d Can work independently \n  Is comfortable turning research papers into product \n  Has 2 - 10 years experience with deep learning or has a PhD in a STEM field \n  Builds with a product-first approach. You ship code quickly and care about the real world impact of your code. \n  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred \n   \n xUguadvg1c", "cleaned_desc": "", "techs": ""}, "96b157c2c406383e": {"terms": ["data science"], "salary_min": 120363.016, "salary_max": 152406.39, "title": "Deep Learning Engineer", "company": "Cyberjin", "desc": "Hybrid/Remote role \n  Locations in multiple States \n  We're looking for a Deep Learning Engineer to join Dyneti as part of the founding engineering team. You will have the opportunity to work closely with the CEO to build new features and roll out new products - all in the deep learning on mobile space. \n \n  Ideal candidate traits \n  Enjoys significant ownership over user-facing product \n  \u200d Can work independently \n  Is comfortable turning research papers into product \n  Has 2 - 10 years experience with deep learning or has a PhD in a STEM field \n  Builds with a product-first approach. You ship code quickly and care about the real world impact of your code. \n  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred \n   \n qiBU6ZmDFz", "cleaned_desc": "  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred ", "techs": ["python", "deep learning", "tensorflow"]}, "3f745a3ea04acaab": {"terms": ["data science"], "salary_min": 120363.016, "salary_max": 152406.39, "title": "Deep Learning Engineer", "company": "Cyberjin", "desc": "Hybrid/Remote role \n  Multiple Locations \n  We're looking for a Deep Learning Engineer to join us as part of the founding engineering team. You will have the opportunity to work closely with the CEO to build new features and roll out new products - all in the deep learning on mobile space. \n \n  Ideal candidate traits \n  Enjoys significant ownership over user-facing product \n  \u200d Can work independently \n  Is comfortable turning research papers into product \n  Has 2 - 10 years experience with deep learning or has a PhD in a STEM field \n  Builds with a product-first approach. You ship code quickly and care about the real world impact of your code. \n  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred \n   \n owsC5Yyyj1", "cleaned_desc": "  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred ", "techs": ["python", "deep learning", "tensorflow"]}, "5890dd194d241634": {"terms": ["data science"], "salary_min": 120363.016, "salary_max": 152406.39, "title": "Deep Learning Engineer", "company": "Cyberjin", "desc": "Hybrid/Remote position \n  We're looking for a Deep Learning Engineer to join us as part of the founding engineering team. You will have the opportunity to work closely with the CEO to build new features and roll out new products - all in the deep learning on mobile space. \n \n  Ideal candidate traits \n  Enjoys significant ownership over user-facing product \n  \u200d Can work independently \n  Is comfortable turning research papers into product \n  Has 2 - 10 years experience with deep learning or has a PhD in a STEM field \n  Builds with a product-first approach. You ship code quickly and care about the real world impact of your code. \n  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred \n   \n 758QEUyVzN", "cleaned_desc": "", "techs": ""}, "318cd9c9f0c8af0e": {"terms": ["data science"], "salary_min": 80.0, "salary_max": 90.0, "title": "Sr. Cogito Developer", "company": "MetaSense Inc", "desc": "Job Title:  Sr. Cogito Developer Location:  Philadelphia, PA 19104 Duration:  6 Months Duties: The Senior Cogito Developer will join the Cogito Product team within the Data and Analytics team in the Center for Healthcare Quality and Analytics, and will be responsible for empowering users with Epic-based data across the institution, providing a unique blend of clinical, business, technical, and analytical expertise. The Cogito Product team oversees the development and utilization of Epic reporting tools throughout the enterprise to drive strategic initiatives, improve safety & quality of care, and streamline operations. The team combines business knowledge with data and technology to empower decision makers and believes that user-friendly, self-service, embedded analytics products can improve patient outcomes, optimize processes, and reduce costs. We believe in providing actionable insights which drive real, measurable, impact! The team is looking for creative problem solvers who are excited about joining a collaborative team to utilize data to transform facility into a data-driven organization; one that practices data-driven decision making and utilizes data to improve the experience of our patients, families, and staff. The Senior Cogito Developer is passionate about healthcare delivery in a patient care setting. A successful candidate is articulate, analytical, and a team player who understands the power of data storytelling to drive change. The developer enjoys coordinating with interdisciplinary teams to create solutions for improving operational and clinical decision making. The developer learns quickly, works independently, and is relentless in overcoming technical, process, and organizational obstacles. \n The Senior Cogito Developer will lead high-profile strategic projects and will be a reliable expert in translating clinical and business requirements into meaningful analysis within the Epic Cogito suite of tools. When necessary, the developer will appropriately apply data science techniques and other advanced analytics to solve problems as we expand into cognitive computing. The individual will need to build relationships with key stakeholders, be an expert in multiple Epic data sources, and implement sustainable solutions. The individual should bring project management experience and share best practices with the team. The analyst must be comfortable with mentorship and partnering with the Cogito Product and other teams within the Data and Analytics group. \n Skills: Position is fully remote, with the possibility of extension. \n Position is contract only at this time, but could become temp to perm if needs align. \n Job Responsibilities: 1.Individual Contributor \u2022Guides clinical teams and business stakeholders on large scope projects: gathering requirements, developing metrics, retrieving data, ensuring validity of results, and building out the appropriate Epic tool for the end-user. \u2022Proposes and creates innovative and appropriate data solutions (dashboards, reports, etc.) for the measurement of processes and outcomes \u2022Adept at learning new information systems and how the data generated contributes to the data development lifecycle \u2022Advises on new SlicerDicer data models, testing frameworks, and documentation and build practices \u2022Works with Cogito Product Team to periodically upgrade the Epic system \u2022Demonstrates excellent data storytelling skills through outstanding presentation and communication to share findings in an understandable and actionable manner tailored to audience and customer's needs 2.Project Management \u2022Responsible for the coordination and completion of assigned projects, including project definition, assignment of task responsibilities, setting deadlines, and all other aspects of project management. \u2022Independently identifies and works to remediate project obstacles 3.Leadership \u2022Identifies, defines, and implements new data-driven strategies and processes for the organization. \u2022Communicates work plans, progress, findings, and interpretations effectively with a continual focus on educating and developing analytic capability of business customers and the organization overall. \u2022Trains and mentors team members \u2022Develops a \u00e2\u20ac\u0153trusted advisor\u00e2\u20ac\u009d reputation through expertise in data and the mentoring of others in the use of the Epic Cogito suite of tools Additional Technical Requirements \u2022Experience with SQL \u2022Knowledge of relational database structures \u2022Experience in project management \n Required Licenses, Certifications, Registrations: Epic Cogito Fundamentals Epic Cogito Tools Administration \n Required Education: \n Bachelor's Degree in Health Science, Computer Science, Math, Engineering, Business, or related quantitative fields. \n Required Experience: \n Five (5) years of experience in analytics / business intelligence within a healthcare system using the Epic Systems electronic health record. \n Preferred Education: \n Master's degree \n Preferred Experience:  Eight (8) years of experience in analytics / business intelligence Experience with data visualization tools preferred (Qlik, Tableau, Power BI, etc) Experience with Epic's Cogito product suite including SlicerDicer, Custom SQL Metrics, Crystal Reports, Radar, Reporting Workbench, CogitoSQL Templates Experience working as a data analyst within a healthcare setting Experience with clinical, access, and/or revenue Epic applications \n Preferred Licenses/certificates/registrations: Certification in at least one of the following Data Models: Clinical Data Model \n Revenue Data Model Access Data Model \n Certification in at least one of the following other Cogito tools: \u2022SlicerDicer \u2022CogitoSQL Templates \u2022Radar SQL Metrics \u2022Implementing Cognitive Computing #IND6 \n Job Type: Contract \n Pay: $80.00 - $90.00 per hour \n Schedule: \n \n 8 hour shift \n Day shift \n Monday to Friday \n \n Experience: \n \n Hospital: 8 years (Required) \n Business intelligence: 8 years (Required) \n Data visualization: 6 years (Required) \n Epic Cogito: 7 years (Required) \n \n Work Location: Remote", "cleaned_desc": "Job Title:  Sr. Cogito Developer Location:  Philadelphia, PA 19104 Duration:  6 Months Duties: The Senior Cogito Developer will join the Cogito Product team within the Data and Analytics team in the Center for Healthcare Quality and Analytics, and will be responsible for empowering users with Epic-based data across the institution, providing a unique blend of clinical, business, technical, and analytical expertise. The Cogito Product team oversees the development and utilization of Epic reporting tools throughout the enterprise to drive strategic initiatives, improve safety & quality of care, and streamline operations. The team combines business knowledge with data and technology to empower decision makers and believes that user-friendly, self-service, embedded analytics products can improve patient outcomes, optimize processes, and reduce costs. We believe in providing actionable insights which drive real, measurable, impact! The team is looking for creative problem solvers who are excited about joining a collaborative team to utilize data to transform facility into a data-driven organization; one that practices data-driven decision making and utilizes data to improve the experience of our patients, families, and staff. The Senior Cogito Developer is passionate about healthcare delivery in a patient care setting. A successful candidate is articulate, analytical, and a team player who understands the power of data storytelling to drive change. The developer enjoys coordinating with interdisciplinary teams to create solutions for improving operational and clinical decision making. The developer learns quickly, works independently, and is relentless in overcoming technical, process, and organizational obstacles. \n The Senior Cogito Developer will lead high-profile strategic projects and will be a reliable expert in translating clinical and business requirements into meaningful analysis within the Epic Cogito suite of tools. When necessary, the developer will appropriately apply data science techniques and other advanced analytics to solve problems as we expand into cognitive computing. The individual will need to build relationships with key stakeholders, be an expert in multiple Epic data sources, and implement sustainable solutions. The individual should bring project management experience and share best practices with the team. The analyst must be comfortable with mentorship and partnering with the Cogito Product and other teams within the Data and Analytics group. \n Skills: Position is fully remote, with the possibility of extension. \n Position is contract only at this time, but could become temp to perm if needs align. \n Job Responsibilities: 1.Individual Contributor \u2022Guides clinical teams and business stakeholders on large scope projects: gathering requirements, developing metrics, retrieving data, ensuring validity of results, and building out the appropriate Epic tool for the end-user. \u2022Proposes and creates innovative and appropriate data solutions (dashboards, reports, etc.) for the measurement of processes and outcomes \u2022Adept at learning new information systems and how the data generated contributes to the data development lifecycle \u2022Advises on new SlicerDicer data models, testing frameworks, and documentation and build practices \u2022Works with Cogito Product Team to periodically upgrade the Epic system \u2022Demonstrates excellent data storytelling skills through outstanding presentation and communication to share findings in an understandable and actionable manner tailored to audience and customer's needs 2.Project Management \u2022Responsible for the coordination and completion of assigned projects, including project definition, assignment of task responsibilities, setting deadlines, and all other aspects of project management. \u2022Independently identifies and works to remediate project obstacles 3.Leadership \u2022Identifies, defines, and implements new data-driven strategies and processes for the organization. \u2022Communicates work plans, progress, findings, and interpretations effectively with a continual focus on educating and developing analytic capability of business customers and the organization overall. \u2022Trains and mentors team members \u2022Develops a \u00e2\u20ac\u0153trusted advisor\u00e2\u20ac\u009d reputation through expertise in data and the mentoring of others in the use of the Epic Cogito suite of tools Additional Technical Requirements \u2022Experience with SQL \u2022Knowledge of relational database structures \u2022Experience in project management \n Required Licenses, Certifications, Registrations: Epic Cogito Fundamentals Epic Cogito Tools Administration   Preferred Experience:  Eight (8) years of experience in analytics / business intelligence Experience with data visualization tools preferred (Qlik, Tableau, Power BI, etc) Experience with Epic's Cogito product suite including SlicerDicer, Custom SQL Metrics, Crystal Reports, Radar, Reporting Workbench, CogitoSQL Templates Experience working as a data analyst within a healthcare setting Experience with clinical, access, and/or revenue Epic applications \n Preferred Licenses/certificates/registrations: Certification in at least one of the following Data Models: Clinical Data Model \n Revenue Data Model Access Data Model \n Certification in at least one of the following other Cogito tools: \u2022SlicerDicer \u2022CogitoSQL Templates \u2022Radar SQL Metrics \u2022Implementing Cognitive Computing #IND6 \n Job Type: Contract \n Pay: $80.00 - $90.00 per hour ", "techs": ["sr. cogito developer", "philadelphia", "pa 19104", "cogito product", "epic reporting tools", "data and technology", "decision makers", "embedded analytics products", "patient outcomes", "data-driven organization", "healthcare delivery", "data storytelling", "technical skills", "data science techniques", "cognitive computing", "project management", "mentorship", "remote work", "slicerdicer", "data models", "sql", "relational database structures", "project management", "epic cogito fundamentals", "epic cogito tools administration", "data visualization tools", "qlik", "tableau", "power bi", "crystal reports", "radar", "reporting workbench", "cogitosql templates", "healthcare setting", "clinical applications", "access applications", "revenue applications", "certification in data models", "certification in cogito tools."]}, "6f3fba0c1078ceb2": {"terms": ["data science"], "salary_min": 90.0, "salary_max": 95.0, "title": "Sr. Cogito Developer", "company": "TalentBurst, Inc.", "desc": "Job Title: Senior Cogito Developer \n \n Location: REMOTE (Local to Philadelphia PA candidates preferred) \n \n Duration: 6 months plus extension \n \n Pay Rate: $90/hr. - $95/hr. \n \n \n Job Requirements: \n \n Epic Cogito Fundamentals \n Epic Cogito Tools Administration \n \n Required Education: \n \n Bachelor's Degree in Health Science, Computer Science, Math, Engineering, Business, or related quantitative fields. \n \n Required Experience: \n \n Five (5) years of experience in analytics/business intelligence within a healthcare system using the Epic Systems electronic health record. \n \n Preferred Education: \n \n Master's degree \n \n Preferred Experience: \n \n Eight (8) years of experience in analytics/business intelligence \n Experience with data visualization tools preferred (Qlik, Tableau, Power BI, etc) \n Experience with  Epic's Cogito  product suite including SlicerDicer, Custom SQL Metrics, Crystal Reports, Radar, Reporting Workbench, CogitoSQL Templates \n Experience working as a data analyst within a healthcare setting \n Experience with clinical, access, and/or revenue Epic applications \n \n Preferred Licenses/certificates/registrations: \n \n \n Certification  in at least one of the following Data Models \n  \n Clinical Data Model \n Revenue Data Model \n Access Data Model \n Certification in at least one of the following other Cogito tools: \n SlicerDicer \n CogitoSQL Templates \n Radar SQL Metrics \n Implementing Cognitive Computing \n \n Job Description: \n \n The Senior Cogito Developer will join the Cogito Product team within the Data and Analytics team in the Center for Healthcare Quality and Analytics and will be responsible for empowering users with Epic-based data across the institution, providing a unique blend of clinical, business, technical, and analytical expertise. \n The Cogito Product team oversees the development and utilization of Epic reporting tools throughout the enterprise to drive strategic initiatives, improve safety & quality of care, and streamline operations. \n The team combines business knowledge with data and technology to empower decision-makers and believes that user-friendly, self-service, embedded analytics products can improve patient outcomes, optimize processes, and reduce costs. \n We believe in providing actionable insights which drive real, measurable, impact! \n The team is looking for creative problem solvers who are excited about joining a collaborative team to utilize data to transform the Client into a data-driven organization; one that practices data-driven decision-making and utilizes data to improve the experience of our patients, families, and staff. \n The Senior Cogito Developer is passionate about healthcare delivery in a patient care setting. \n A successful candidate is articulate, analytical, and a team player who understands the power of data storytelling to drive change. \n The developer enjoys coordinating with interdisciplinary teams to create solutions for improving operational and clinical decision-making. \n The developer learns quickly, works independently, and is relentless in overcoming technical, process, and organizational obstacles. \n \n Also: \n \n The Senior Cogito Developer will lead high-profile strategic projects and will be a reliable expert in translating clinical and business requirements into meaningful analysis within the  Epic Cogito  suite of tools. \n When necessary, the developer will appropriately apply data science techniques and other advanced analytics to solve problems as we expand into cognitive computing. \n The individual will need to build relationships with key stakeholders, be an expert in multiple Epic data sources, and implement sustainable solutions. \n The individual should bring project management experience and share best practices with the team. \n The analyst must be comfortable with mentorship and partnering with the Cogito Product and other teams within the Data and Analytics group. \n The position is fully remote, with the possibility of extension. The position is contract only at this time but could become temp to perm if needs align.\n  \n \n Job Responsibilities: \n \n  1. Individual Contributor \n  \n Guides clinical teams and business stakeholders on large-scope projects: gathering requirements, developing metrics, retrieving data, ensuring validity of results, and building out the appropriate Epic tool for the end-user. \n Proposes and creates innovative and appropriate data solutions (dashboards, reports, etc) for the measurement of processes and outcomes \n Adept at learning new information systems and how the data generated contributes to the data development lifecycle \n Advises on new SlicerDicer data models, testing frameworks, and documentation and build practices \n Works with the Cogito Product Team to periodically upgrade the Epic system \n Demonstrates excellent data storytelling skills through outstanding presentation and communication to share findings in an understandable and actionable manner tailored to the audience and customer's needs \n 2. Project Management \n  \n Responsible for the coordination and completion of assigned projects, including project definition, assignment of task responsibilities, setting deadlines, and all other aspects of project management. \n Independently identifies and works to remediate project obstacles. \n 3. Leadership \n  \n Identifies, defines, and implements new data-driven strategies and processes for the organization. \n Communicates work plans, progress, findings, and interpretations effectively with a continual focus on educating and developing the analytic capability of business customers and the organization overall. \n Trains and mentors team members \n Develops a \"trusted advisor\u201d reputation through expertise in data and the mentoring of others in the use of the Epic Cogito suite of tools \n \n Additional Technical Requirements: \n \n Experience with SQL \n Knowledge of relational database structures \n Experience in project management \n TB_HL", "cleaned_desc": " \n Five (5) years of experience in analytics/business intelligence within a healthcare system using the Epic Systems electronic health record. \n \n Preferred Education: \n \n Master's degree \n \n Preferred Experience: \n \n Eight (8) years of experience in analytics/business intelligence \n Experience with data visualization tools preferred (Qlik, Tableau, Power BI, etc) \n Experience with  Epic's Cogito  product suite including SlicerDicer, Custom SQL Metrics, Crystal Reports, Radar, Reporting Workbench, CogitoSQL Templates \n Experience working as a data analyst within a healthcare setting \n Experience with clinical, access, and/or revenue Epic applications \n \n Preferred Licenses/certificates/registrations: \n \n \n Certification  in at least one of the following Data Models    \n Clinical Data Model \n Revenue Data Model \n Access Data Model \n Certification in at least one of the following other Cogito tools: \n SlicerDicer \n CogitoSQL Templates \n Radar SQL Metrics \n Implementing Cognitive Computing \n \n Job Description: \n \n The Senior Cogito Developer will join the Cogito Product team within the Data and Analytics team in the Center for Healthcare Quality and Analytics and will be responsible for empowering users with Epic-based data across the institution, providing a unique blend of clinical, business, technical, and analytical expertise. \n The Cogito Product team oversees the development and utilization of Epic reporting tools throughout the enterprise to drive strategic initiatives, improve safety & quality of care, and streamline operations. \n The team combines business knowledge with data and technology to empower decision-makers and believes that user-friendly, self-service, embedded analytics products can improve patient outcomes, optimize processes, and reduce costs. \n We believe in providing actionable insights which drive real, measurable, impact! \n The team is looking for creative problem solvers who are excited about joining a collaborative team to utilize data to transform the Client into a data-driven organization; one that practices data-driven decision-making and utilizes data to improve the experience of our patients, families, and staff. \n The Senior Cogito Developer is passionate about healthcare delivery in a patient care setting. \n A successful candidate is articulate, analytical, and a team player who understands the power of data storytelling to drive change.   The developer enjoys coordinating with interdisciplinary teams to create solutions for improving operational and clinical decision-making. \n The developer learns quickly, works independently, and is relentless in overcoming technical, process, and organizational obstacles. \n \n Also: \n \n The Senior Cogito Developer will lead high-profile strategic projects and will be a reliable expert in translating clinical and business requirements into meaningful analysis within the  Epic Cogito  suite of tools. \n When necessary, the developer will appropriately apply data science techniques and other advanced analytics to solve problems as we expand into cognitive computing. \n The individual will need to build relationships with key stakeholders, be an expert in multiple Epic data sources, and implement sustainable solutions. \n The individual should bring project management experience and share best practices with the team. \n The analyst must be comfortable with mentorship and partnering with the Cogito Product and other teams within the Data and Analytics group. \n The position is fully remote, with the possibility of extension. The position is contract only at this time but could become temp to perm if needs align.\n  \n \n Job Responsibilities: \n \n  1. Individual Contributor \n  \n Guides clinical teams and business stakeholders on large-scope projects: gathering requirements, developing metrics, retrieving data, ensuring validity of results, and building out the appropriate Epic tool for the end-user. \n Proposes and creates innovative and appropriate data solutions (dashboards, reports, etc) for the measurement of processes and outcomes   Adept at learning new information systems and how the data generated contributes to the data development lifecycle \n Advises on new SlicerDicer data models, testing frameworks, and documentation and build practices \n Works with the Cogito Product Team to periodically upgrade the Epic system \n Demonstrates excellent data storytelling skills through outstanding presentation and communication to share findings in an understandable and actionable manner tailored to the audience and customer's needs \n 2. Project Management \n  \n Responsible for the coordination and completion of assigned projects, including project definition, assignment of task responsibilities, setting deadlines, and all other aspects of project management. \n Independently identifies and works to remediate project obstacles. \n 3. Leadership \n  \n Identifies, defines, and implements new data-driven strategies and processes for the organization. \n Communicates work plans, progress, findings, and interpretations effectively with a continual focus on educating and developing the analytic capability of business customers and the organization overall. \n Trains and mentors team members \n Develops a \"trusted advisor\u201d reputation through expertise in data and the mentoring of others in the use of the Epic Cogito suite of tools \n \n Additional Technical Requirements: \n \n Experience with SQL \n Knowledge of relational database structures ", "techs": ["epic systems electronic health record", "qlik", "tableau", "power bi", "epic's cogito product suite", "slicerdicer", "custom sql metrics", "crystal reports", "radar", "reporting workbench", "cogitosql templates", "clinical data model", "revenue data model", "access data model", "sql", "relational database structures"]}, "81db339c5f422a19": {"terms": ["data analyst"], "salary_min": null, "salary_max": null, "title": "Healthcare RCM Data Analyst", "company": "Advantum Health", "desc": "In this role, the Data Analyst will identify unique insights and solve complex business challenges using a variety of data sources \n The individual in this role will support the adoption of modernized analytics across Advantum Health \n This includes supporting the identification of opportunities, establishing operational processes, driving documentation standards, and embracing modern analytic capabilities \n Support the transition to modernized analytics \n Collaborate with key customers to understand key priorities and represent the voice of the customer in all planning and development discussions and decisions \n Research, evaluate, and deploy new tools, frameworks, and patterns, including identification of gaps and opportunities for improvement of existing solutions \n Support communication efforts on the benefits and value of the adoption of modernized analytics \n Effectively communicate data and analytic findings with many levels of the organization, business stakeholders/SME, project managers, developers, system architects, quality assurance, operations, etc \n \n Job Type: Full-time \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n \n Application Question(s): \n \n Please list the area of specialties that you have experience in: \n Please list EHR systems that you have experience with: \n \n Experience: \n \n report generating and writing: 2 years (Required) \n building masterfiles/dictionaries: 2 years (Required) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "32404f94d73e5aee": {"terms": ["data analyst"], "salary_min": 77517.984, "salary_max": 98155.05, "title": "Data Analyst", "company": "VXForward", "desc": "VXForward has a great opportunity for a Data Analyst - 100% Remote with one of our clients.\n  \n \n Roles and Responsibilities: \n \n \n Data Engineer/Analyst needed to research root causes of data issues/defects from file ingestion through multiple environments. \n Would be responsible for updating user stories, working to solution, and dev support. \n \n Required Skills: \n \n \n History in health claim data analytics \n SQL \n \n Desired Skills: \n \n \n ADF \n Snowflake \n \n \n This is a remote position.", "cleaned_desc": "", "techs": ""}, "6038378bfdc741cc": {"terms": ["data analyst"], "salary_min": 60000.0, "salary_max": 90000.0, "title": "Economic Data and Research Analyst", "company": "Camoin Associates", "desc": "Camoin Associates is looking for a Remote Economic Data and Research Analyst who is highly analytical, experienced with data analysis and associated tools, research oriented, organized, able to work independently, self-motivated and has either a Master\u2019s Degree or prior professional experience. This position is geared towards individuals who have the skills needed to analyze and interpret economic and financial data, enjoy research projects, and are looking for an opportunity to use those skills to support our team in various economic development related projects. Come be part of a firm that is working around the country to support clients as they navigate ever-changing economic conditions to expand opportunities for all. \n Camoin Associates is proud to be an equal opportunity employer. Our company is committed to a diverse and multi-cultural workforce that strives to represent the communities where we live and work. Black, Indigenous, and People of Color (BIPOC), immigrants, women, LGBTQ people, individuals with disabilities, and members of other marginalized groups are strongly encouraged to apply. \n Role: \n The person chosen for this position will serve as a research and data analyst for a variety of projects, including real estate and industry market analysis, housing need assessments, development feasibility studies, economic and fiscal impact analysis, and economic and workforce development strategies. The person will work closely with the firm\u2019s project managers and other analysts. Example projects include: \n \n Collecting, analyzing, and presenting data to understand the economic base of a region, including socioeconomic characteristics, industry and occupation trends, and the real estate market. \n Measuring the economic and fiscal impact of a proposed mixed-use development on the host community, including the cost of providing community services. \n Providing research and data to support projects that cover a wide range of topics, including: housing, economic resiliency, downtown revitalization, green technology, target sector trends, supply chain analysis, real estate changes, and more. \n Assisting with proposal preparation and marketing materials. \n \n \n \n Qualifications: \n \n Undergraduate and Master\u2019s level degree in economics, finance, statistics, business, or other related quantitative field preferred. \n Two years of professional work experience may be considered as a substitute for Master\u2019s degree. \n Strong analytic skills in data analysis and economic research, professional-level competencies in Excel, and data visualization. \n Excellent writing and communication skills required. \n \n Note: those with more experience are encouraged to apply as well. We are looking for the right fit and will adjust compensation to match experience. \n \n   \n Additional Skills Desired:  \n \n Aptitude for assessing and understanding numeric data and ability to identify trends and critical points. \n Ability to interpret information and succinctly articulate its meaning in written and graphic form for a non-technical audience. \n Demonstrated interest and ability in research techniques, analytical tools, AI innovations, API applications, and desire to utilize new tools for gaining insights into research topics. \n Knowledge of research methods including survey analysis and web-based research. \n Excellent attention to detail, time-management, and organizational skills. \n A good communicator, strong collaborator, and team player. \n \n Camoin Associates provides all analysts with equipment (PC, dual monitors, camera, and optional headset for video conferencing). Please note that we are only making this position available to citizens and residents with all necessary authorizations already in place (OPT does not qualify). \n Compensation and Benefits: \n Compensation for this position is expected to range from $60,000 \u2013 $90,000 depending on experience and education level. Camoin Associates also offers paid time off, a week off at the end of the year, 11 paid holidays, retirement contributions, health insurance, and the flexibility of 100% remote work. \n Please e-mail cover letter and resume to Rachel Selsky, C/O Erin Teets at  eteets@camoinassociates.com.  In your cover letter, please indicate the position you are applying for and why you want to be in a position of research and analytics.  If selected for further consideration, we will request additional documentation at a later date.  Please no telephone inquiries. \n Key Words: economics, finance, economic development, consultant, fiscal, grant, workforce, impact analysis, market research, administration. \n \n \n \n About the Firm: \n  Since 1999, Camoin Associates\u2019 mission has been to support our customers in their efforts to create meaningful employment opportunities. Across our service lines, we offer research, analysis, and business intelligence services that help build healthy and vibrant economies that work for all. \n  Camoin Associates is proud of the efforts made over the last 20 years to offer team members the opportunity to build a dynamic career that includes interaction with a wide variety of people, projects, and communities daily and regular chances for personal and professional growth. \n  We do great work.  As a firm, we pride ourselves on being forward thinking, collaborative, and able to help clients identify and solve their critical economic development related issues. Through our work, we strive to make a positive change, create job opportunities, improve quality of life, and increase prosperity for all. It is interesting work, something different every day, and it makes a positive impact on people\u2019s lives. \n  We have a great team.  We care deeply about the work we do and the people we work with. As a fully remote team of 25+ employees, we have regular check-ins with all staff to foster a culture of close and trusting relationships. We strive to enable staff to work at a level that allows for a healthy life-work balance. We are supportive, collaborative, open to new ideas and approaches, and personal interests and professional development goals are encouraged to be pursued. The firm offers competitive salaries, health insurance benefits, retirement contribution, professional development support, paid time off, holidays, and a flexible work schedule. \n  We have great clients.  Our clients include local and state government, U.S. territories, economic development organizations (EDOs), non-profit organizations, private developers, and corporations. We build long-term relationships with our clients because they trust us to provide honest, accurate, and impactful guidance on pressing decisions. \n  To learn more about our experience and projects in all our service areas, please visit our websites at www.camoinassociates.com.", "cleaned_desc": " \n Note: those with more experience are encouraged to apply as well. We are looking for the right fit and will adjust compensation to match experience. \n \n   \n Additional Skills Desired:  \n \n Aptitude for assessing and understanding numeric data and ability to identify trends and critical points. \n Ability to interpret information and succinctly articulate its meaning in written and graphic form for a non-technical audience. \n Demonstrated interest and ability in research techniques, analytical tools, AI innovations, API applications, and desire to utilize new tools for gaining insights into research topics. ", "techs": ["analyze data", "interpret information", "articulate meaning", "written communication", "graphic representation", "research techniques", "analytical tools", "ai innovations", "api applications", "gaining insights"]}, "abdcb2a0d9d78290": {"terms": ["data analyst"], "salary_min": 87117.555, "salary_max": 110310.24, "title": "Senior Data Analyst", "company": "Luxoft", "desc": "Project  Description \n \n We are seeking a detail-oriented and data-driven Data Analyst (Health) to join our team and assist us in leveraging data to better understand our members and their needs. The Data Analyst will be responsible for collecting, organizing, and interpreting data related to health and wellness initiatives for our customer. \n \n \n \n \n Responsibilities \n \n \n They will use the data they analyze to develop plans for improving the health and wellness of our members.  The ideal candidate for this role should have experience in the healthcare industry and an advanced understanding of data analytics principles. They should be comfortable working with large datasets and have a keen eye for detail. Additionally, they should be able to communicate complex data in an easy-to-understand way to colleagues and senior leadership.  Collect and organize data related to health and wellness initiatives for Blue Shield of California.  Analyze data to gain insights and develop plans for improving the health and wellness of our members. Interpret data accurately and effectively.  Communicate complex data in an easy-to-understand way to colleagues and senior leadership. Utilize data analytics principles and techniques to optimize data analysis.  Work independently and as part of a team.  Maintain accurate records and reports.  Monitor industry trends and recommend strategies for improvement.  Stay up to date with new technologies and processes related to data analysis.  \n \n \n \n Skills \n \n Must have \n \n \n Bachelor's degree in a related field such as healthcare, statistics, or computer science \n At least 3 years of experience in data analysis \n Advanced knowledge of data analytics principles and techniques \n Proven ability to interpret data accurately and effectively \n Excellent communication, presentation, and problem-solving skills \n Ability to work independently and as part of a teamIf you are looking for a challenging and rewarding role, where you can make an impact on the health and wellness of our members.  \n \n \n Nice to have \n \n Healthcare  \n \n \n \n \n \n Languages \n \n English: C2 Proficient \n \n \n Seniority \n \n Senior \n \n \n Relocation package \n \n If needed, we can help you with relocation process. \n \n \n \n \n Vacancy Specialization  \n \n Functional/System Analysis \n \n \n Ref Number \n \n VR-100962", "cleaned_desc": " \n \n \n Skills \n \n Must have \n \n \n Bachelor's degree in a related field such as healthcare, statistics, or computer science \n At least 3 years of experience in data analysis \n Advanced knowledge of data analytics principles and techniques ", "techs": ["none"]}, "dd8532f4ee8fbba0": {"terms": ["data analyst"], "salary_min": 71793.945, "salary_max": 90907.13, "title": "SQL Data Analyst", "company": "Eventbrite", "desc": "THE CHALLENGE \n  At Eventbrite, we are bringing innovative products and a fresh approach to an industry with entrenched interests and diverse competition. We believe that innovative technology and a customer-centric mindset are key elements to building a successful business and creating world-class customer experiences. In a fast-paced sales environment, it\u2019s critical for our sales leadership team to have visibility and insights regarding leading and lagging performance indicators to drive decision-making. Concurrently, as Eventbrite\u2019s customer base grows and evolves, we need to thoughtfully leverage data to ensure our customer experience grows  \n and evolves with them. \n  THE TEAM \n  Partnering daily with Sales, Customer Success, and Integrity Policy & Operations leadership, this role sits in the Business Operations team. We are responsible for supporting the Customer teams by driving global consistency and excellence via analytical insights and operational rigor. \n  THE ROLE \n  The Data Analyst will utilize SQL to identify actionable insights \u2013 both at the strategic and tactical levels - that drive business decisions, regularly presenting to business leaders and executive management. Their work will help optimize decisions by building deliverables that facilitate timely and responsive action, measuring the impact of program changes, and conducting analyses to proactively uncover opportunities for improvement in quality or scale. Also, this analyst will work with stakeholders and internal Business Operations to look for opportunities to automate analysis and reporting. To succeed in this role, they must be disciplined, proactive, and curious. The ideal candidate is a business analyst who loves challenges and succeeds at juggling multiple assignments in a fast-paced environment. \n  We are interested in every qualified candidate who is eligible to work in the United States. However, we are not able to sponsor visas. \n  YOU WILL \n \n Translate both strategic and tactical questions into analytics requirements, collect and analyze data using SQL, and organize the findings in a cohesive narrative to drive action \n Deliver recurring analysis, and insights across the Customer Organization \n Develop scalable reporting and dashboards to monitor leading and lagging indicators \n Identify opportunities to improve process, efficiency, profitability, and productivity \n Assist in setting targets for new initiatives and proactive campaigns, tracking ongoing progress \n \n THE SKILLSET \n \n Minimum 2 years experience with SQL, Excel, and Tableau (or equivalent software) \n Familiarity with sales, integrity operations, customer success metrics \n Proven analytical and quantitative skills with an ability to use data and metrics to back up assumptions, develop business cases, and complete root cause analyses \n \n \n  The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Eventbrite, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $59,400 to $95,040. You may also be eligible to participate in Eventbrite\u2019s incentive program(s) (such as equity, annual incentive bonus and commission plans), subject to the applicable rules and restrictions. \n  WHAT WE OFFER \n  We are committed to providing competitive, valuable and meaningful benefits for our Britelings . \n  We work hard to cultivate a diverse, equitable and inclusive culture where Britelings feel like they belong. \n  Employees can participate in resource groups and we offer programming throughout the year to support a diverse and inclusive workplace. Read more about our Diversity and Inclusion work for our team, culture, and community. \n  We offer comprehensive benefits and a wellness package above and beyond standard medical benefits to support our Britelings\u2019 lifestyle. \n  Eventbrite's global benefit programs are designed to meet you where you are by offering resources and support for your health, well-being, finances, and family. This includes support in a remote/hybrid environment, wellness allowance, Carrot family planning benefit, Origin Financial Planning service, and other offerings to ease the mind and body like Modern Health and BriteBreaks (generally the first Friday of every month off).   \n \n ABOUT EVENTBRITE \n  Eventbrite is a global self-service ticketing, marketing, and experience technology platform that serves a consumers and event creators in nearly 180 countries. Since inception, Eventbrite has been at the center of the experience economy, transforming the way people organize and attend events. With over 280 million tickets distributed for over 5 million total events in 2022, Eventbrite is where people all over the world discover new things to do or new ways to do more of what they love. Learn more at www.eventbrite.com. \n  IS THIS ROLE NOT AN EXACT FIT? \n  Sign up to keep in touch and we\u2019ll let you know when we have new positions on our team.   \n \n Eventbrite is committed to equality of opportunity for all staff, and applications from all suitably qualified individuals are encouraged, regardless of age, disability, sex, gender reassignment, sexual orientation, pregnancy and maternity, race, religion or belief and marriage and civil partnerships. \n  #LI-REMOTE", "cleaned_desc": " Assist in setting targets for new initiatives and proactive campaigns, tracking ongoing progress \n \n THE SKILLSET \n \n Minimum 2 years experience with SQL, Excel, and Tableau (or equivalent software) \n Familiarity with sales, integrity operations, customer success metrics \n Proven analytical and quantitative skills with an ability to use data and metrics to back up assumptions, develop business cases, and complete root cause analyses ", "techs": ["sql", "excel", "tableau"]}, "ce617e9c5303b017": {"terms": ["data analyst"], "salary_min": 68397.33, "salary_max": 86606.25, "title": "Marketing Data Analyst", "company": "Outliant", "desc": "About us:  Outliant is a fully-remote, US-based, digital product development and startup consulting company, with a team of culturally diverse creators whose exceptional skills and talents help conceive seamless digital products. Our teams exhibit work-play energy that supports individual growth, as well as encourages the freedom of creativity and \u201cthinking outside the box.\u201d \n \n  Our Core Values:   Pursuit of Excellence:  We are extremely competitive, ambitious, and driven to be exceptional \u2013 as individuals, teams, and as an organization. There is no standard high enough and we will never settle. We aspire to attract, retain, and empower the very best people.   Startup Mentality:  Outliant began with 5 startup founders, and startup culture is deep in our DNA. It\u2019s a critical advantage that allows us to move faster, be more resourceful, and empower our team at all levels. We are in the early chapters of our journey.   World-Class Remote Collaboration:  Outliant is (and always has been) a 100% remote company \u2013 we have no offices and our teams are distributed around the world. Given the freedom and autonomy this provides, we require that our people excel in this remote structure. \n \n  About the role:  We\u2019re looking to hire a full-time remote Marketing Data Analyst. For this role, your primary focus will be playing a key role in transforming raw data into actionable insights, driving informed marketing decisions, optimizing campaigns, and enhancing overall business performance. \n  You\u2019ll have the opportunity to choose your hours and work and learn with a team of world-class engineers and designers, through a commitment to team collaboration, communication, and product quality. \n \n  Seniority Level:  Mid Level \n \n  Responsibilities: \n \n  Analyze complex data sets to identify trends, patterns, and insights that can be leveraged for marketing strategies. \n  Utilize statistical techniques and advanced analytical tools to interpret data and provide valuable insights into customer behavior, campaign effectiveness, and market trends. \n  Translate big data into actionable dashboards and data visualizations. \n  Design and interpret A/B and multivariate tests. \n  Collaborate with cross-functional teams to define data requirements, ensure data integrity, and establish best practices for data collection and analysis. \n  Design and interpret A/B testing methodologies and analyze results to optimize marketing campaigns, website performance, and customer experiences. \n  Provide actionable recommendations based on data analysis to enhance marketing strategies, improve customer engagement, and drive revenue growth. \n  Continuously monitor and evaluate marketing performance metrics, identifying areas for improvement and proposing solutions. \n  Stay current with industry trends, emerging technologies, and best practices in marketing analytics. \n  Collect and analyze complex data on the effectiveness of marketing initiatives \n  Forecast future marketing performance. \n \n \n  Requirements: \n \n  3+ years of proven experience as a Marketing Data Analyst or similar role, preferably in a digital marketing environment. \n  Proficiency in statistical analysis and marketing tools like Google Tag Manager and Segment. \n  Hands-on experience with marketing automation platforms, web analytics tools, and A/B testing platforms. \n  Exceptional analytical and problem-solving skills, with the ability to translate complex data into understandable insights. \n  Excellent communication skills, both written and verbal, with the ability to convey complex data findings to non-technical stakeholders. \n  Detail-oriented mindset and the ability to work collaboratively in a fast-paced environment. \n \n  Nice to have: \n \n  Experience with Hubspot and Mixpanel     \n \n What\u2019s in it for you?  As a full-time member of our team, you\u2019ll enjoy: \n \n  Flexible hours, work wherever you choose \n  Unlimited PTO \n  Non-working holidays per country of residence \n  Pro-rated 13th-month bonus in select regions \n  Salary increases and performance-based bonuses \n  Referral bonuses \n  Financial support for online courses \n  Mental health and well-being programs \n  Fun and casual work environment \n  Employee engagement activities and virtual gatherings \n  We are a diverse, global team! \n \n \n  Important Notice:  To ensure the legitimacy of jobs, we strongly advise to exclusively rely on positions posted here or on our official website: outliant.com/careers. Our recruitment team communicates solely through email using only @outliant.com email addresses and via LinkedIn.  \n \n Please be assured that we are fully committed to maintaining integrity in our hiring process.", "cleaned_desc": " \n  Analyze complex data sets to identify trends, patterns, and insights that can be leveraged for marketing strategies. \n  Utilize statistical techniques and advanced analytical tools to interpret data and provide valuable insights into customer behavior, campaign effectiveness, and market trends. \n  Translate big data into actionable dashboards and data visualizations. \n  Design and interpret A/B and multivariate tests. \n  Collaborate with cross-functional teams to define data requirements, ensure data integrity, and establish best practices for data collection and analysis. \n  Design and interpret A/B testing methodologies and analyze results to optimize marketing campaigns, website performance, and customer experiences. \n  Provide actionable recommendations based on data analysis to enhance marketing strategies, improve customer engagement, and drive revenue growth. \n  Continuously monitor and evaluate marketing performance metrics, identifying areas for improvement and proposing solutions. \n  Stay current with industry trends, emerging technologies, and best practices in marketing analytics. ", "techs": ["analyze complex data sets", "statistical techniques", "advanced analytical tools", "data visualizations", "a/b and multivariate tests", "data collection and analysis", "a/b testing methodologies", "marketing campaigns", "website performance", "customer experiences", "marketing performance metrics", "industry trends", "emerging technologies"]}, "bda3ac86874b9ac6": {"terms": ["data analyst"], "salary_min": 90000.0, "salary_max": 154000.0, "title": "Principal Business Data Analyst", "company": "VSP Global", "desc": "The Principal Business Data Analyst leads collaborations with business teams to determine needs and opportunities for leveraging data in support of business monitoring and decision management. This position mentors\u2019 others to apply a range of analytics and statistical techniques to generate relevant and accurate insights through data exploration, modeling, analysis and mining. Communicates findings effectively using visualizations, dashboards and presentations with the goal of optimizing business decisions and outcomes.\n  \n \n   Essential Functions\n  \n \n \n   Lead engagements with business leaders and staff to clarify needs and define business requirements for strategic data use; where possible anticipates and proposes opportunities for analysis and exploration in support of business optimization and decision-making\n  \n \n \n   Support decision-makers by performing data exploration, analysis and statistical inference to identify and interpret trends and patterns in datasets and detect influences, opportunities and risks\n  \n \n \n   Develop forecasts, regression models, what-if scenarios and recommendations in consultation with leaders to support strategic/tactical planning and operational decision-making\n  \n \n \n   Lead the creation of dashboards, visualizations and reports to support business performance monitoring, automating where possible, to support stakeholders\u2019 ability to be data driven\n  \n \n \n   Effectively communicates insights for business leaders and colleagues in order to advance the collective intelligence of the organization\n  \n \n \n   Work collaboratively with the enterprise analytics and information management team to articulate business needs for new/revised data models and views/access to the data\n  \n \n \n   Produce business-specific workflows and data models for analysis using enterprise analytics and data management tools, including the integration of external data sets that are approved for use\n  \n \n \n   Serve iterative business needs by developing prototype models that join large volumes of data across multiple data domains to deliver views for use by other analysts; understands the modeling techniques for ensuring integrity and responsiveness in those deliverables\n  \n \n \n   Identify business opportunities for machine learning and collaborates with Data Scientists to deliver value for the business unit\n  \n \n   Contribute to data inventory and stewardship efforts, including contributions to metadata management, data profiling, data quality remediation and data cleansing\n  \n \n \n   Maintain high standards and adheres to all enterprise policies and guidelines regarding data security and privacy, data management, data quality and data governance; regards data as an enterprise asset that is to be protected and used both strategically and appropriately\n  \n \n \n   Job Specifications\n  \n \n \n  Typically has the following skills or abilities: \n \n \n \n   Bachelor\u2019s degree in statistics, analytics, mathematics, economics, computer science or related functional area; or equivalent experience\n  \n \n \n   6+ years of demonstrated data analytics experience including querying and analyzing operational and/or financial data, generating insights and communicating those effectively with colleagues and leaders\n  \n \n \n   Prior experience in successfully leading analytics projects in one or more of the following domains/business functions: Financial Management and Forecasting, Risk Assessment, Insurance Utilization and Pricing, Supply Chain Optimization, Retail Management, eCommerce Management, Consumer Behavior Analysis, Marketing Optimization or Healthcare Management\n  \n \n \n   Proficient in building complex data queries using SQL in order to join, filter, cleanse and aggregate data; understanding of how no/low-code applications apply SQL concepts to do the same\n  \n \n \n   Proficient in designing data workflows and business-oriented data models against relational database structures\n  \n \n \n   Proficient in visualization and dashboard design techniques to create interfaces that monitor business performance against KPIs and highlight trends/patterns\n  \n \n \n   Proficient in using data exploration and analysis platforms such as PowerBI, Cognos Analytics, Tableau, SAS or similar\n  \n \n \n   Experience applying statistical modeling to evaluate complex business problems and develop forecasting and what-if scenarios\n  \n \n \n   Possesses strategic skills, business acumen and curiosity to envision opportunities, document requirements and collaborate for successful outcomes\n  \n \n \n   Capable of mentoring others to elevate the collective skills of the team\n  \n \n \n   Familiarity with Data Science techniques and experience in the use of notebooks (i.e. Jupyter) with programming languages like Python and R\n  \n \n \n   Excellent written and verbal communication, presentation and analytical skills\n  \n \n \n   #LI-REMOTE\n  \n \n   #LI-VISIONCARE\n  \n \n \n   Compensation range for the role is listed below. Applicable salary ranges may differ across markets.\n     Actual pay will be determined based on experience and other job-related factors permitted by law. As a part of the compensation package, this role may include eligible bonuses, equity and commissions. For more information regarding VSP Vision benefits, please \n   \n   click here\n   .\n  \n  Salary Ranges: $90,000.00 - $154,000.00\n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                        VSP Vision is an equal opportunity employer and gives consideration for employment to qualified applicants without regard to age, gender, race, color, religion, sex, national origin, gender identity, sexual orientation, disability or protected veteran status. We maintain a drug-free workplace and perform pre-employment substance abuse testing.\n                       \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n   Notice to Candidates: Fraud Alert - Fake Job Opportunity Solicitations Used to Collect Fees/Personal Information.\n  \n \n  We have been made aware that fake job opportunities are being offered by individuals posing as VSP Vision and affiliate recruiters. \n   \n   Click here \n   to learn about our application process and what to watch for regarding false job opportunities.\n  \n \n \n   As a regular part of doing business, VSP Vision (\u201cVSP\u201d) collects many different types of personal information, including protected health information, about our audiences, including members, doctors, clients, brokers, business partners, and employees. VSP Vision employees will have access to this sensitive personal information and are subject to follow Information Security and Privacy Policies.", "cleaned_desc": "The Principal Business Data Analyst leads collaborations with business teams to determine needs and opportunities for leveraging data in support of business monitoring and decision management. This position mentors\u2019 others to apply a range of analytics and statistical techniques to generate relevant and accurate insights through data exploration, modeling, analysis and mining. Communicates findings effectively using visualizations, dashboards and presentations with the goal of optimizing business decisions and outcomes.\n  \n \n   Essential Functions\n  \n \n \n   Lead engagements with business leaders and staff to clarify needs and define business requirements for strategic data use; where possible anticipates and proposes opportunities for analysis and exploration in support of business optimization and decision-making\n  \n \n \n   Support decision-makers by performing data exploration, analysis and statistical inference to identify and interpret trends and patterns in datasets and detect influences, opportunities and risks\n  \n \n \n   Develop forecasts, regression models, what-if scenarios and recommendations in consultation with leaders to support strategic/tactical planning and operational decision-making\n  \n \n \n   Lead the creation of dashboards, visualizations and reports to support business performance monitoring, automating where possible, to support stakeholders\u2019 ability to be data driven\n  \n \n \n   Effectively communicates insights for business leaders and colleagues in order to advance the collective intelligence of the organization\n  \n \n \n   Work collaboratively with the enterprise analytics and information management team to articulate business needs for new/revised data models and views/access to the data\n  \n \n \n   Produce business-specific workflows and data models for analysis using enterprise analytics and data management tools, including the integration of external data sets that are approved for use\n  \n \n     Serve iterative business needs by developing prototype models that join large volumes of data across multiple data domains to deliver views for use by other analysts; understands the modeling techniques for ensuring integrity and responsiveness in those deliverables\n  \n \n \n   Identify business opportunities for machine learning and collaborates with Data Scientists to deliver value for the business unit\n  \n \n   Contribute to data inventory and stewardship efforts, including contributions to metadata management, data profiling, data quality remediation and data cleansing\n  \n \n \n   Maintain high standards and adheres to all enterprise policies and guidelines regarding data security and privacy, data management, data quality and data governance; regards data as an enterprise asset that is to be protected and used both strategically and appropriately\n  \n \n \n   Job Specifications\n  \n \n \n  Typically has the following skills or abilities: \n \n \n \n   Bachelor\u2019s degree in statistics, analytics, mathematics, economics, computer science or related functional area; or equivalent experience\n  \n \n \n   6+ years of demonstrated data analytics experience including querying and analyzing operational and/or financial data, generating insights and communicating those effectively with colleagues and leaders\n  \n \n \n   Prior experience in successfully leading analytics projects in one or more of the following domains/business functions: Financial Management and Forecasting, Risk Assessment, Insurance Utilization and Pricing, Supply Chain Optimization, Retail Management, eCommerce Management, Consumer Behavior Analysis, Marketing Optimization or Healthcare Management\n  \n \n     Proficient in building complex data queries using SQL in order to join, filter, cleanse and aggregate data; understanding of how no/low-code applications apply SQL concepts to do the same\n  \n \n \n   Proficient in designing data workflows and business-oriented data models against relational database structures\n  \n \n \n   Proficient in visualization and dashboard design techniques to create interfaces that monitor business performance against KPIs and highlight trends/patterns\n  \n \n \n   Proficient in using data exploration and analysis platforms such as PowerBI, Cognos Analytics, Tableau, SAS or similar\n  \n \n \n   Experience applying statistical modeling to evaluate complex business problems and develop forecasting and what-if scenarios\n  \n \n \n   Possesses strategic skills, business acumen and curiosity to envision opportunities, document requirements and collaborate for successful outcomes\n  \n \n \n   Capable of mentoring others to elevate the collective skills of the team\n  \n \n \n   Familiarity with Data Science techniques and experience in the use of notebooks (i.e. Jupyter) with programming languages like Python and R\n  \n \n \n   Excellent written and verbal communication, presentation and analytical skills\n  \n ", "techs": ["sql", "powerbi", "cognos analytics", "tableau", "sas", "python", "r", "jupyter"]}, "cea5896491bd04bc": {"terms": ["data analyst"], "salary_min": 105000.0, "salary_max": 120000.0, "title": "Junior Business Analyst", "company": "Pendrick Capital Partners", "desc": "Pendrick is a leading buyer and servicer of healthcare debt in the US market. The company provides a critical service in the late-stage revenue cycle for the US based healthcare provider segment. For more than a decade, the company has worked with Top Tier healthcare providers (e.g., health systems, hospitals, physician practices, specialty providers) to support and enable their customers (patients) to pay their healthcare bills, thereby keeping down the cost of healthcare for everyone. \n With a core belief of practicing a patient-first mindset, and with its unparalleled compliance program, Pendrick has, since it was founded in 2010, built a robust operating system and platform which is fundamental to the company\u2019s success. It has one of the strongest balance sheets in the healthcare debt sector which means that it is always able to support its clients by buying or leasing, and then collecting on, their outstanding patient payment responsibility invoices. \n The business was further strengthened in 2019 when the company was acquired by a premium Private Equity company, who has deep domain experience in this market segment. With their support, the company has gone on to: \n \u00b7 Make strategic investments in people, data analytics capability & product innovation \n \u00b7 Purchase Phoenix Financial Services, one of the leading collections agencies in the healthcare collections market \n \u00b7 Install an independent Board of Directors which bring decades of healthcare experience to the company from their time running large healthcare companies \n \u00b7 Set a vision to build a much larger, more diverse business, which not only continues to support healthcare providers with their outsourced collections activities but also wishes to support them with the automation, and individualization, of their early-stage invoicing activities and make healthcare more affordable to consumers by providing financing options \n The successful candidate will be joining at an exciting time as healthcare providers look to drive increasing efficiency after the challenges created by Covid and as the company looks to pursue its growth and diversification strategies through both organic and inorganic means. \n Junior Business Data Analyst \n We are looking for a inquisitive Junior Business Data Analyst to join our growing team of analytics experts. You will apply your strategic and analytical skills to major company challenges. You'll team with world-class professionals to develop and test strategies that ultimately impact the bottom line. And you will do it all in a collaborative environment that values your insight, encourages you to take on new responsibility, promotes continuous learning, and rewards innovation. They must be self-directed and comfortable supporting the business needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company\u2019s business strategy to support our expanding bids and collection initiatives. \n Primary Responsibilities \n As a Junior Business Data Analyst at Pendrick Capital, you will apply your strategic and analytical skills to major company challenges \n \n You'll team with world-class professionals to develop and test strategies that ultimately impact the bottom line \n And you will do it all in a collaborative environment that values your insight, encourages you to take on new responsibility, promotes continuous learning, and rewards innovation \n Strategic leadership: Delver business strategies that will drive growth, profitability, and competitive success for Pendrick Capital in the face of shifting consumer and regulatory demands \n Product: Implement new product and pricing strategies for various products; lead product level modeling/analytics \n Build targeted insights to inform the design and development of new collection experiences, as well as breakthrough technology and concepts designed to deliver on competitive bidding \n Build reporting solution that enable business partners to improve our collection and placement strategies \n Credit Risk: Drive step-change improvements in credit performance by connecting drivers of future consumer credit trends to historical behavior, creating collection and cashflow models, and testing hypotheses using rigorous monitoring and analysis \n Execution: Manage and sequence delivery of business intent, build business requirements and execute against the product strategy \n Partnership: Work closely with colleagues across Pendrick Capital including IT, Sales, Operations, Finance and others to drive improvement in quality, volume, service, and profitability \n \n Personal Characteristics \n \n Strategic & analytic orientation: A track record of decision making and problem solving based on analytics \n Deliver on multiple projects and programs concurrently \n Ability to set and manage priorities judiciously \n \n Education/Experience \n \n Bachelor\u2019s degree in Business or quantitative field such as Finance, Economics, Physical Sciences, Math, Statistics, Engineering \n 1+ years of experience in a business analysis role \n Experience with SQL, R or Python, and Git repo \n \n Preferred Qualifications: \n \n Master's Degree in Business or quantitative field such as Finance, Economics, Physical Sciences, Math, Statistics, Engineering \n 2+ years of experience in analysis \n 1+ years of experience in collections or accounts receivable \n 1+ year of experience in consulting \n Experience with Tableau \n \n Job Type: Full-time \n Pay: $105,000.00 - $120,000.00 per year \n Benefits: \n \n 401(k) 3% Match \n AD&D insurance \n Dental insurance \n Dependent health insurance coverage \n Health insurance \n Health savings account \n Life insurance \n Paid time off \n Vision insurance \n \n Compensation package: \n \n Performance bonus \n \n Experience level: \n \n 2 years \n \n Schedule: \n \n Monday to Friday \n \n Experience: \n \n SQL: 1 year (Preferred) \n Business analysis: 1 year (Preferred) \n \n Work Location: Remote", "cleaned_desc": " \n Education/Experience \n \n Bachelor\u2019s degree in Business or quantitative field such as Finance, Economics, Physical Sciences, Math, Statistics, Engineering \n 1+ years of experience in a business analysis role \n Experience with SQL, R or Python, and Git repo \n \n Preferred Qualifications: \n \n Master's Degree in Business or quantitative field such as Finance, Economics, Physical Sciences, Math, Statistics, Engineering \n 2+ years of experience in analysis \n 1+ years of experience in collections or accounts receivable \n 1+ year of experience in consulting \n Experience with Tableau ", "techs": ["sql", "r", "python", "git repo", "tableau"]}, "deb2b6c26100524a": {"terms": ["data analyst"], "salary_min": 75000.0, "salary_max": 125000.0, "title": "Quantitative Data Analyst", "company": "CRED-iQ", "desc": "Quantitative Data Analyst (CRE / CMBS) \n Reports to: Chief Executive Officer \n About CRED iQ \n CRED iQ is the fastest growing commercial real estate data, analytics, and valuation platform providing actionable intelligence to CRE (Commercial Real Estate) and capital markets investors. Launched in 2020, our proprietary platform was developed with leading-edge technologies, and delivers real-time commercial real estate data through a user-friendly interface. \n CRED iQ leverages big data, machine learning technologies, and geospatial analytics to provide solid lead generation opportunities and analytics to the CRE finance community. Subscribers to CRED iQ use this platform to identify opportunities for leasing, refinancing, CMBS investments, mezzanine lending, distressed debt, and acquisitions. The executive team have a successful history of developing commercial real estate analytics platforms. \n Position Overview \n We are actively seeking a Quantitative Data Analyst with a minimum of 5 years of experience to join our Data and Product team. The successful candidate must have a passion for data analytics, expertise, and technology for the rapidly growing global CRE market. This is a key role that will contribute to CRED iQ\u2019s robust platform that serves the CRE and CMBS industries. \n The candidate will align our product roadmap with cutting-edge technologies, hundreds of databases, data lake technologies, and analytical infrastructure. In this position, you will be handling clients and their data and any data inconsistencies within our proprietary datasets. Independent analysis and thorough work completion is vital to this role. The ideal candidate will provide timely model updates that incorporate the latest credit trends, and valuations along with market developments, while allowing clients the ability to fully customize their user experience with a comprehensive and intuitive set of models within our proprietary software. \n You will manage projects through delegation of duties while completing analysis independently on larger projects working directly with management. You are someone who cares about the impact of their work and enjoys working with large datasets, conducting detailed and thorough analysis, building analytic valuation tools and models, and supporting our clients. \n This is a unique opportunity to join a specialized team that is experiencing explosive growth. \n Qualifications & Proficiency \n \n BA/BS in Mathematics, Finance, Statistics, Economics, Commercial Real Estate or another quantitative field \n Minimum 3+ years of professional experience of CRE analysis, valuation and/or credit and loan modeling \n Requires advanced analytical, quantitative, and writing skills. Deep understanding of the CREFC Investor Reporting Package (IRP) within the CMBS industry \n Highly proficient in Excel, Word, PowerPoint, and Adobe skills \n Candidates with programming experience (SQL, Python, Rust) are preferred \n Ability to work in large data sets and with team members to assist clients in their data requirements and issues. High attention to detail, advanced data analytical skills, experience with various CRE databases. \n Must have a strong work ethic and a willingness to go the extra mile in support of the client. \n \n Job Requirements and Duties \n \n Develop and manage data collection tools, dashboards, and reporting systems for all program activities. Extract, clean, and analyze quantitative data, monitoring key metrics and performance measures. \n Provide technical assistance to partners to support their data collection and reporting needs. Work with internal and external partners to identify and resolve data discrepancies and issues with data reporting systems. \n Ability to work and code or code review in existing data pipelines and work with engineering on new data imports, pipelines, and sources. \n Work with internal and external partners to identify and resolve data discrepancies and issues with data reporting systems, and or data output issues with existing UI. \n Respond quickly to relevant data requests from clients, key stakeholders, and leadership. \n Analyze and structure large datasets that include CMBS loan data, market data, ownership contact information. \n Extract and organize relevant data points into a standard, ingestible format. \n Communicate with internal teams and external clients to identify industry-wide quantitative problems and collaborate to explore solutions. \n Perform theoretical research to generate new or fine tune existing models and methodologies in the risk space. \n Conduct empirical research to calibrate new or existing models for financial data clients. \n Back test, document, and guide new models and methodologies through validation to uncover CRE & CMBS trends. \n Collaborate on papers for publication, present original research, including at industry conferences, and speak with institutional clients about relevant research. Provide detailed analysis to identify and support optimization initiatives across a spectrum of real estate-related activities. \n \n Compensation and Comprehensive Benefits Package \n \n Salary of $75K \u2013 $125K \n Equity Options \n Medical, Dental, Vision, Short Term Disability, HSA, and 401K \n Flexible Work Schedule / Remote Work \n A work environment built on teamwork, flexibility, and respect. \n \n CRED iQ is an equal opportunity employer and fintech startup that thrives in a fast-paced dynamic environment. If you would like to apply or learn more about this opportunity, please contact us at careers@cred-iq.com. \n CRED iQ does not discriminate on the basis of race, religion, color, sex, gender identity, sexual orientation, age, non-disqualifying physical or mental disability, national origin, veteran status or any other basis covered by appropriate law. \n Job Type: Full-time \n Pay: $75,000.00 - $125,000.00 per year \n Benefits: \n \n 401(k) \n Dental insurance \n Flexible spending account \n Health insurance \n Paid time off \n Vision insurance \n \n Compensation package: \n \n Stock options \n Yearly pay \n \n Experience level: \n \n 5 years \n \n Schedule: \n \n 8 hour shift \n \n Education: \n \n Bachelor's (Required) \n \n Work Location: Remote", "cleaned_desc": "Quantitative Data Analyst (CRE / CMBS) \n Reports to: Chief Executive Officer \n About CRED iQ \n CRED iQ is the fastest growing commercial real estate data, analytics, and valuation platform providing actionable intelligence to CRE (Commercial Real Estate) and capital markets investors. Launched in 2020, our proprietary platform was developed with leading-edge technologies, and delivers real-time commercial real estate data through a user-friendly interface. \n CRED iQ leverages big data, machine learning technologies, and geospatial analytics to provide solid lead generation opportunities and analytics to the CRE finance community. Subscribers to CRED iQ use this platform to identify opportunities for leasing, refinancing, CMBS investments, mezzanine lending, distressed debt, and acquisitions. The executive team have a successful history of developing commercial real estate analytics platforms. \n Position Overview \n We are actively seeking a Quantitative Data Analyst with a minimum of 5 years of experience to join our Data and Product team. The successful candidate must have a passion for data analytics, expertise, and technology for the rapidly growing global CRE market. This is a key role that will contribute to CRED iQ\u2019s robust platform that serves the CRE and CMBS industries. \n The candidate will align our product roadmap with cutting-edge technologies, hundreds of databases, data lake technologies, and analytical infrastructure. In this position, you will be handling clients and their data and any data inconsistencies within our proprietary datasets. Independent analysis and thorough work completion is vital to this role. The ideal candidate will provide timely model updates that incorporate the latest credit trends, and valuations along with market developments, while allowing clients the ability to fully customize their user experience with a comprehensive and intuitive set of models within our proprietary software. \n You will manage projects through delegation of duties while completing analysis independently on larger projects working directly with management. You are someone who cares about the impact of their work and enjoys working with large datasets, conducting detailed and thorough analysis, building analytic valuation tools and models, and supporting our clients. \n This is a unique opportunity to join a specialized team that is experiencing explosive growth. \n Qualifications & Proficiency \n \n BA/BS in Mathematics, Finance, Statistics, Economics, Commercial Real Estate or another quantitative field \n Minimum 3+ years of professional experience of CRE analysis, valuation and/or credit and loan modeling   Requires advanced analytical, quantitative, and writing skills. Deep understanding of the CREFC Investor Reporting Package (IRP) within the CMBS industry \n Highly proficient in Excel, Word, PowerPoint, and Adobe skills \n Candidates with programming experience (SQL, Python, Rust) are preferred \n Ability to work in large data sets and with team members to assist clients in their data requirements and issues. High attention to detail, advanced data analytical skills, experience with various CRE databases. \n Must have a strong work ethic and a willingness to go the extra mile in support of the client. \n \n Job Requirements and Duties \n \n Develop and manage data collection tools, dashboards, and reporting systems for all program activities. Extract, clean, and analyze quantitative data, monitoring key metrics and performance measures. \n Provide technical assistance to partners to support their data collection and reporting needs. Work with internal and external partners to identify and resolve data discrepancies and issues with data reporting systems. \n Ability to work and code or code review in existing data pipelines and work with engineering on new data imports, pipelines, and sources. \n Work with internal and external partners to identify and resolve data discrepancies and issues with data reporting systems, and or data output issues with existing UI. \n Respond quickly to relevant data requests from clients, key stakeholders, and leadership. \n Analyze and structure large datasets that include CMBS loan data, market data, ownership contact information. ", "techs": ["quantitative data analyst (cre / cmbs)", "cred iq", "commercial real estate data", "analytics", "and valuation platform", "big data", "machine learning technologies", "geospatial analytics", "lead generation opportunities", "analytics", "leasing", "refinancing", "cmbs investments", "mezzanine lending", "distressed debt", "acquisitions", "product roadmap", "databases", "data lake technologies", "analytical infrastructure", "proprietary datasets", "credit trends", "valuations", "market developments", "user experience", "models", "software", "project management", "ba/bs in mathematics", "finance", "statistics", "economics", "commercial real estate", "quantitative field", "professional experience", "cre analysis", "valuation", "credit and loan modeling", "crefc investor reporting package (irp)", "excel", "word", "powerpoint", "adobe skills", "programming experience (sql", "python", "rust)", "data sets", "attention to detail", "data analytical skills", "cre databases", "work ethic", "data collection tools", "dashboards", "reporting systems", "quantitative data", "key metrics", "performance measures", "technical assistance", "data discrepancies", "data reporting systems", "data imports", "data pipelines", "ui", "data requests", "cmbs loan data", "market data", "ownership contact information."]}, "caec7bfde4a16da7": {"terms": ["data analyst"], "salary_min": 57553.6, "salary_max": 84115.2, "title": "Departmental Analyst 12 - Data & Programs Unit", "company": "State of Michigan", "desc": "Salary \n \n \n \n \n \n \n     $57,553.60 - $84,115.20 Annually\n     \n \n \n \n \n \n Location  \n \n \n \n \n \n     Lansing, MI\n     \n \n \n \n \n \n \n \n Job Type \n \n \n \n \n     Permanent Full Time\n     \n \n \n \n \n \n Remote Employment \n \n \n \n \n     Flexible/Hybrid\n     \n \n \n \n \n \n \n \n Job Number \n \n \n \n \n     2301-24-BOE014\n     \n \n \n \n \n \n Department \n \n \n \n \n     Department of State\n     \n \n \n \n \n \n \n \n Opening Date \n \n \n \n \n     10/19/2023\n     \n \n \n \n \n \n Closing Date \n \n \n \n \n     11/2/2023 11:59 PM Eastern\n     \n \n \n \n \n \n \n \n Bargaining Unit \n \n \n \n \n     NON-EXCLUSIVE REPRESENTED EMPLOYEE (NERE)\n     \n \n \n \n \n \n \n \n \n Job Description \n \n \n \n     POSITION DUTIES -  This position will serve as the recognized resource and training lead for the Data & Programs Unit, supporting the internal  documentation of all functionalities of the Qualified Voter File (QVF) software and related applications; prioritize software support and development and coordinate with QVF stakeholders to define business requirements and testing timelines. Additionally, this position is to assist the unit manager in all day-to-day operations that support the Data & Programs work area.     APPOINTMENT TYPE/BENEFITS -  This position is Full-Time. Therefore, you would be eligible to participate in the benefits offered by the state.    This position has the potential to work a hybrid/remote work schedule.    MDOSJOBS \n \n \n Required Education and Experience \n \n \n Education  Possession of a bachelor's degree in any major.     Experience  Three years of professional experience, including one year of experience equivalent to the experienced (P11) level in state service. \n \n \n Additional Requirements and Information \n \n \n Please attach an updated resume, cover letter and a writing sample to your application for review. Failure to do so may result in your application being removed from the selections process.   __________________________________________________________________________________________________________________    You must apply for this vacancy through the NEOGOV system; click on \"Apply\" in the job posting for instructions in submitting your electronic application. Your application for any position does not guarantee that you will be contacted by the Department for further consideration. Only those applicants interviewed will be notified of the results.    Civil Service Commission Rule 2-7 requires that all newly hired state employees submit to and pass a pre-employment drug test prior to their actual appointment. Due to the nature of work of the Department of State, criminal records will be checked. Any position offer will be conditional until results of the criminal background record checks indicate eligibility for employment. \n \n \n \n \n \n \n \n \n \n State employment also offers rewarding careers where you can help Michiganders enjoy better lives. Many State of Michigan jobs offer alternate work schedules and remote-work options that can help give the flexibility you need. In 2022,  Forbes  ranked the State of Michigan in the Top 10 of America\u2019s Best Employers For New Grads and as the #1 employer for new grads in government services. More details on benefits for our new hires are below: \n   Rewarding Work:  State of Michigan jobs allow you to serve Michiganders in many different ways depending on your interests and skills. Help preserve and protect our environment and the public health; enforce state laws and regulations; advocate for children, families, and victims of discrimination; support our state\u2019s military and veterans; rebuild our state\u2019s infrastructure; or support other state agencies through our fiscal, IT, and HR systems.     Insurance Benefits:  The State of Michigan offers health, mental health, dental, and vision insurance to eligible career employees, their spouses, and their children. The state also covers a life-insurance benefit of two times employees\u2019 annual salary (up to $200,000). The state also offers long-term-disability insurance that can provide continuing benefits if an injury or illness prevents employees from working. More information is available at www.mi.gov/employeebenefits.     Retirement Programs:  The State of Michigan offers 401(k) and 457 plans for new hires to save for retirement. The state will automatically contribute an amount equal to 4% of your pay to a 401(k) account. The state will also match up to 5% of your pay if you contribute to your 401(k) account. Your contributions vest immediately, and the state\u2019s contributions fully vest after just 4 years. More information is available at http://www.mi.gov/orsstatedc.     Vacation and Sick Leave:  Eligible full-time employees receive between  15 and 35 personal days  and  13 sick days  per year that may be rolled over to the following year if not used. Eligible employees also receive an additional day each year for community service or school functions.     Paid Parental Leave:  Eligible employees can take  12 weeks of paid leave  immediately after a birth or adoption to allow needed time together at home with a new child.     Paid Holidays:  Eligible employees receive 13 or 14 paid holidays each year including New Year\u2019s Eve and Day, Martin Luther King Jr. Day, Presidents\u2019 Day, Memorial Day, Juneteenth, the Fourth of July, Labor Day, Election Day, Veterans Day, Thanksgiving, Thanksgiving Friday, Christmas Eve and Day.     Bonus Programs:  Eligible employees with five years of service also receive annual longevity bonuses that grow as seniority increases. Some positions also may qualify for recruitment, retention, and performance bonuses or other special pay premiums.     Military Pay Differential:  Employees in the guard or reserves may also qualify for supplemental pay benefits if miliary pay during qualifying duty is less than normal state pay. Prior military service may also allow seniority credits to accelerate eligibility for longevity bonuses and additional personal leave accrual.     Tax-Advantaged Programs:  In addition to 401(k) and 457 retirement accounts, the state also offers flexible spending account (FSA), health savings account (HSA), and qualified transportation fringe benefit (QTFB) programs that can help you save money by reducing your taxable income.     Student Loan Forgiveness:  Working for the State of Michigan may allow you to participate in programs that forgive the balance of qualifying student loans. Information to help determine if you could qualify is available from the U.S. Department of Education.     Tuition Reduction:  Some colleges and universities offer savings to eligible employees and family members to further their education while working for the State of Michigan.     Professional Development:  To help develop your career, programs are available to apply for reimbursement of up to $2,000 a year for education and training for college course credits and non-degree programs.     Alternative and Remote Work Schedules:  Depending on the nature of their duties, many state jobs offer flexible work schedules and remote or hybrid telecommuting options that can help obtain the work-life balance that you seek.     Great Lakes and Great Times:  Michigan boasts four Great Lakes, 11,000 inland lakes, 36,000 miles of rivers and streams, 20 million acres of forests, 100 state and national parks and recreation areas, 1,300 miles of bike trails, 6,500 miles of snowmobile trails, the second-most ski areas in the nation, 650 public golf courses, 600 campgrounds, and an international dark-sky park\u2014just for starters. Our cities offer concerts and cultural events, storied sports teams, education hubs, vibrant downtowns, one-of-a-kind craft beverages, and renowned restaurants for every appetite. From urban centers to beach towns to the great outdoors, the opportunities are endless. With your state salary and benefits and Michigan\u2019s affordable cost of living, you can explore all that Michigan has to offer.    Updated: 11/14/2022", "cleaned_desc": "", "techs": ""}, "b7ae7aba84a75731": {"terms": ["data analyst"], "salary_min": 60069.0, "salary_max": 75000.0, "title": "Business Analyst", "company": "9th Way Insignia", "desc": "Company Introduction: \n  9th Way Insignia is a service-disabled, veteran-owned small business bringing transformative technology to our government customers so they can achieve their missions. Our specialties include cybersecurity, cloud modernization, software development, data analytics, enterprise architecture, enterprise IT, analytics, process automation, and artificial intelligence. Learn more about 9th Way Insignia at https://9thwayinsignia.com/\n  \n \n Team/Program Introduction: \n  Join a pioneering team of highly skilled professionals dedicated to helping 9th Way Insignia achieve their transformative technology, and digital transformation objectives. We are looking for a Business Analyst to join this team. The Business Analyst aligns to the Senior Consultant professional level within 9th Way Insignia\u2019s career families.\n  \n \n Professional Level Information: \n  As a Sr. Consultant you will complete tasks and projects of moderate scope and complexity. A Sr. Consultant exercises the best judgement and problem-solving skills within defined guidelines and practices to determine appropriate action to execute assignments. As a Sr. Consultant, you will also provide guidance and/or lead on tasks/projects. \n  \n \n Functional Job (LCAT) Information: \n  The Business Analyst is part of a high-performance team responsible for developing and implementing innovative solutions that will enable various teams and units to help them achieve their technology goals. The Business Analyst will work with a variety of stakeholders to solicit and elaborate functional requirements, develop innovative solutions, implement them, and support the end users of these solutions.\n  \n \n Responsibilities: \n \n Collaborate with a multidisciplinary team to gather requirements and create solutions help the VA staff critical medical positions and provide the VA\u2019s Office of Healthcare Transformation with analytic insight into all of their program initiatives. \n Assist with the development, maintenance, and optimization of dashboards and reports using Microsoft Power BI. \n Leverage Power Automate to streamline data processes and workflows. \n Assist in the entire application lifecycle, focusing on coding, debugging, and testing. \n Provide technical support and training to end-users, ensuring the seamless adoption of new technologies. \n Contribute to the creation of system documentation and user manuals. \n \n \n Requirements: \n \n Excellent verbal and written communication skills. \n End User story telling with accuracy. \n Strong data collection skills. \n Strong analytical and problem-solving skills. \n Ability to work collaboratively with a team and also execute projects independently. \n Passionate about the mission of serving our veterans and enhancing the VA's healthcare system. \n Knowledge of Power BI, Power Automate, Power Apps and cloud Dataverse ecosystem a plus. \n Must be authorized to work for any employer in the U.S. \n Must be able to obtain and maintain the required security clearance. \n \n \n Salary Range: \n  The salary range for this position is $60,069 \u2013 $75,000 per year.\n  \n \n 9th Way Insignia\u2019s range for this job level is a general guideline only and not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other law. \n \n \n Clearance, Background Investigation: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.\n  \n \n Work Location:  \n  Remote\n  \n \n Legal: \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law. hr@9th-way.com", "cleaned_desc": " Provide technical support and training to end-users, ensuring the seamless adoption of new technologies. \n Contribute to the creation of system documentation and user manuals. \n \n \n Requirements: \n \n Excellent verbal and written communication skills. \n End User story telling with accuracy. \n Strong data collection skills. \n Strong analytical and problem-solving skills. \n Ability to work collaboratively with a team and also execute projects independently. ", "techs": ["none"]}, "3307340bc4922426": {"terms": ["data analyst"], "salary_min": 65.0, "salary_max": 70.0, "title": "8664 \u2013 Retirement Conversion Business Analyst", "company": "Interactive Resources LLC", "desc": "Implementation-Conversion Analyst/Client Conversion Analyst/Implementation Analyst/Business Analyst/Retirement Business Analyst/OMNI Conversion Analyst \n Join our team today on this EXCITING contract-to-hire opportunity with a FANTASTIC Fortune 500 Banking/Finance industry client company! \n SUMMARY : Client Data Mapping and information collection in order to arrange for a smooth client conversion from one system to the other and may train on use of systems/support client during conversion. \n **FULL DETAILS will be provided over a phone call to discuss!** \n DETAILS: \n \n This position is FULLY remote, but MUST sit in the U.S. (Need work certain time zone work hours \u2013 prefer ET, but CT and MT would be ok) \n A completed Bachelor\u2019s Degree is required at minimum or a completed High School Diploma/GED equivalent with the equivalent in training, work experience, etc. \n This is a contract-to-hire job opportunity! \n Starting pay ranges from $65.00/hour- $70.00/hour based on experience level! \n \n REQUIREMENTS: \n \n A completed Bachelor\u2019s Degree is highly preferred. A completed High School Diploma/GED equivalent with the equivalent in training, work experience, etc. is required at MINIMUM. \n MUST have intermediate to advanced Excel skills, retirement and OMNI recordkeeping systems experience, reconciliations experience, and experience with AdminWeb! \n MUST have at least 1-2 years of Banking or Financial Services industry experience. \n MUST have self-starting abilities & a high level of resourcefulness. \n Previous experience in a client-facing position is required. (Professional relationship building, negotiations, etc. experience is needed) \n 1-2 years of Project Management/Coordination/Assistance experience is a big plus! \n MUST be able to translate client requirements into more technical verbiage in order to communicate to technical team. \n MUST be able to maintain professional working relationships both internally and externally. \n Microsoft Suite programs skills and full computer literacy are required. \n BIG PLUS if you have Project Assistance/Coordinating, Business Analysis, Technical Implementations work experience. \n MUST interview with a hiring manager in order to receive a job offer and MUST be willing/able to submit to background screening and drug screening if job offer is accepted! \n \n Interactive Resources (iR) was built to provide a personalized approach to solving client and candidate needs while building sustaining relationships. In a world where technology advances by the minute, relationships are the variable that cannot be substituted with software. \n Founded in 2006 in Jacksonville, Florida, iR has grown year over year expanding across the United States. iR was founded on the principles of Honesty, Trust, and Dedication. We take pride in the relationships we have built and continue to build, and we are dedicated to delivering the superior results that our clients and candidates come to expect and deserve. We love what we do! \n Relationships \u2013 Talent \u2013 Results \n Job Types: Contract, Full-time \n Pay: $65.00 - $70.00 per hour \n Schedule: \n \n Day shift \n Monday to Friday \n \n Education: \n \n Bachelor's (Required) \n \n Experience: \n \n Retirement Plan: 1 year (Required) \n Data Conversion: 1 year (Required) \n Banking or Finance industry: 1 year (Required) \n OMNI: 1 year (Required) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "de1f69845d4ad405": {"terms": ["data analyst", "data engineer"], "salary_min": 99900.0, "salary_max": 135120.0, "title": "Senior Analyst Data Engineer (Remote)", "company": "Vail Resorts", "desc": "As a leading mountain resort operator with over 40 resorts in sixteen states and four countries. We exist to create an  Experience of a Lifetime  for our employees, so they can, in turn, provide and  Experience of a Lifetime  for our guests. We are looking for leaders, innovators, creators, and ambitious professionals to join our talented team. If you\u2019re ready to pursue your fullest potential, we want to get to know you! \n  Many of our Corporate function teams can now live and work in any of the states in which Vail Resorts currently operates* \u2013 enabling flexible remote work alongside a commitment to building and maintaining strong culture both in person and virtually. If you\u2019re ready to pursue your fullest potential, we want to get to know you. Find your purpose with us at www.vailresortscareers.com. \n \n  Job Summary: \n  The Enterprise Data Engineering Team at Vail Resorts is on a journey to redefine how data is ingested, modeled, and surfaced to our key stakeholders across the enterprise. This team is at the forefront of creating a modern data estate on which the foundation of our core businesses will operate.  We are looking for a passionate and driven Senior Data Engineer to become an important part of our fast-paced, high-energy, and innovative culture. The ideal candidate will have experience in Azure, Databricks, ETL processes, Python, SQL, Jira and Github. In addition to these skills, the candidate should also have experience in data lake house architecture, data modeling and migration from on-premise enterprise data warehousing to data lake. \n  As a Senior Data Engineer, you will be responsible for designing and implementing data pipelines that are scalable, reliable, and efficient. You will work closely with analytics teams, data scientist and other stakeholders to understand their requirements and design solutions that meet their needs. \n \n  Job Specifications: \n \n  Outlet: Corporate \n  Expected Pay Range: $99,900 - $135,120 + annual bonus \n  Shift & Schedule Availability: Full Time / Year Round \n \n \n  Other Specifics: Remote \n \n \n  Job Responsibilities: \n \n  Design and implement data pipelines using Azure and Databricks. \n  Develop ETL/ELT processes to extract load data into Databricks Lakehouse using PySpark/Python/Scala and Delta Live Tables. \n  Experience orchestrating and monitoring workflows. \n  Work with data scientists/data analysts to understand their requirements and design solutions that meet their needs. \n  Develop and maintain Python scripts to automate data processing tasks. \n  Write complex SQL queries. \n  Optimize database performance by tuning queries and indexes. \n  Monitor database performance and troubleshoot issues as they arise. \n  Other duties as assigned \n \n \n  Job Requirements: \n \n  Bachelor\u2019s degree in Computer Science or a related field. \n  5+ years of experience in data engineering. \n  Experience with Azure and Databricks. \n  Strong knowledge of ETL processes. \n  Proficiency in Python, SQL, Jira and Github. \n  Experience with big data technologies such as Hadoop, Spark, or Kafka is a plus. \n  Experience with Jira and Github. \n  Experience in data lake house architecture. \n  Experience ingesting data from Event Hubs is a plus. \n  Experience in data modeling is a plus.  Experience in migration from on-premise enterprise data warehousing to data lake. \n  \n \n The expected Total Compensation for this role is $99,900 - $135,120 + annual bonus. Individual compensation decisions are based on a variety of factors. \n  The perks include a free ski pass, and a set of benefits including... \n \n  Medical, Dental, Vision insurance, and a 401(k) retirement plan \n  Hourly employees are generally eligible for accrued Paid Time Off (PTO) and Sick Time. Salaried employees are generally eligible for Flexible Time Off (FTO) \n  Paid Parental Leave for eligible mothers and fathers \n  Healthcare & Dependent Care Flexible Spending Accounts \n  Life, AD&D, and disability insurance \n \n \n  Reach Your Peak at Vail Resorts.  At Vail Resorts, our team is made whole by the brave, passionate individuals who ambitiously push boundaries and challenge the status quo. Whether you\u2019re looking for seasonal work or the career of a lifetime, join us today to reach your peak. \n \n   Remote work is currently permitted from British Columbia and the 16 U.S. states in which we currently operate. This includes: California, Colorado, Indiana, Michigan, Minnesota, Missouri, New Hampshire, New York, Nevada, Ohio, Pennsylvania, Utah, Vermont, Washington State, Wisconsin, and Wyoming. Please note that the ability to work remotely, and the particulars related to such work, are subject to change at any time; and, accordingly, the Company reserves the right to change its policies and/or require in-person/in-office work at any time in its sole discretion. \n \n \n  Vail Resorts is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability, protected veteran status or any other status protected by applicable law. \n \n  Requisition ID 498620   Reference Date: 10/18/2023   Job Code Function: Information Systems", "cleaned_desc": " \n \n  Other Specifics: Remote \n \n \n  Job Responsibilities: \n \n  Design and implement data pipelines using Azure and Databricks. \n  Develop ETL/ELT processes to extract load data into Databricks Lakehouse using PySpark/Python/Scala and Delta Live Tables. \n  Experience orchestrating and monitoring workflows. \n  Work with data scientists/data analysts to understand their requirements and design solutions that meet their needs. \n  Develop and maintain Python scripts to automate data processing tasks.    Write complex SQL queries. \n  Optimize database performance by tuning queries and indexes. \n  Monitor database performance and troubleshoot issues as they arise. \n  Other duties as assigned \n \n \n  Job Requirements: \n \n  Bachelor\u2019s degree in Computer Science or a related field. \n  5+ years of experience in data engineering. \n  Experience with Azure and Databricks. \n  Strong knowledge of ETL processes.    Proficiency in Python, SQL, Jira and Github. \n  Experience with big data technologies such as Hadoop, Spark, or Kafka is a plus. \n  Experience with Jira and Github. \n  Experience in data lake house architecture. \n  Experience ingesting data from Event Hubs is a plus. \n  Experience in data modeling is a plus.  Experience in migration from on-premise enterprise data warehousing to data lake. \n  \n \n The expected Total Compensation for this role is $99,900 - $135,120 + annual bonus. Individual compensation decisions are based on a variety of factors. \n  The perks include a free ski pass, and a set of benefits including... \n \n  Medical, Dental, Vision insurance, and a 401(k) retirement plan ", "techs": ["azure", "databricks", "pyspark", "python", "scala", "delta live tables", "sql", "jira", "github", "hadoop", "spark", "kafka"]}, "3bbe57130a9d3930": {"terms": ["data analyst"], "salary_min": 66300.0, "salary_max": 119850.0, "title": "Finance Analyst", "company": "Leidos", "desc": "Description   \n Leidos CIO Services is looking for a  Finance Analyst  to join our IT Business Management & Operations Management team. In this role, you will support the management of a multimillion-dollar portfolio of IT asset contracts (hardware, software, etc). This includes planning, monitoring, and recording IT assets (for example, order and renewal requests, change requests, and reporting) to ensure compliance with vendor contracts and industry mandates. You will assist in forming procurement strategies to optimize technology spend across the organization, as well as develop and implement procedures for tracking company assets to oversee quality control throughout their lifecycles. \n \n  Primary Responsibilities: \n \n  Responsible for managing the lifecycle of IT assets (hardware and software) from procurement to retirement and disposal \n  Complete ownership of procurement and receipt activities for IT assets \n  Effectively communicate both written or orally with peers, management, customers, and other stakeholders \n  Analyze purchasing effectiveness and resolve purchasing issues \n  Oversee contract renewals and vendor management activities with Procurement on behalf of CIO Services \n  Collaborate with System Lifecycle Managers to identify cost savings initiatives \n  Contribute to the development and implementation of enterprise-wide IT asset management policies and procedures to minimize compliance risk, enhance the program, and create process efficiencies \n  Ensure audit compliance for IT assets and manages vendor audit activities \n  Provide input into the design and execution of asset management policies, procedures, and processes. \n \n \n  Required Qualifications: \n \n  Bachelor\u2019s degree and 4-8 years of experience in IT Budget Management \n  Experience with ServiceNow, Apptio, Excel \n  Excellent communications skills, both written and orally \n  Ability to analyze data, summarize information, and make recommendations to management \n  Strong problem-solving skills: can identify a problem and formulate a corrective action plan \n  Excellent at multi-tasking, managing deliverables and established deadlines \n  High attention to detail \n  Experience performing accruals, journal entries, multi-year budgeting, budget variance analysis \n \n \n  Preferred Qualifications: \n \n  Experience generating reports and building dashboards in ServiceNow and Apptio \n  Experience with Costpoint \n \n \n  Pay Range:  Pay Range $66,300.00 - $119,850.00\n  \n  The Leidos pay range for this job level is a general guideline only and not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other law. \n  #Remote", "cleaned_desc": " \n \n  Required Qualifications: \n \n  Bachelor\u2019s degree and 4-8 years of experience in IT Budget Management \n  Experience with ServiceNow, Apptio, Excel \n  Excellent communications skills, both written and orally ", "techs": ["servicenow", "apptio", "excel"]}, "53734bc0d6129fb0": {"terms": ["data analyst"], "salary_min": 45700.0, "salary_max": 68500.0, "title": "Business Analyst", "company": "CNO Financial Group", "desc": "Remote \n \n \n Salary Range  : $45,700 - $68,500 Annual \n Job Details \n The stated pay range is based on a national-average location. Actual salary is determined by factors including relevant work experience, skills and location. This position is bonus eligible. \n CNO Financial Group is hiring a  Business Analyst  to be responsible for organizing, designing, and maintaining group insurance analysis in addition to KPI reporting. The Business Analyst will lead both ad-hoc and ongoing data analysis requests under direct supervision and will be responsible for turning data into user-friendly reports and visuals. The Business Analyst will also provide project and organizational support as needed. \n This is your opportunity to gain exposure to budgeting/forecast activities. \n As a Business Analyst,   your responsibilities will include: \n \n Analyzing and reporting done through Microsoft Excel, occasionally presenting more formal summaries in Microsoft Word or PowerPoint as needed \n Producing and participating in the requirements gathering, design, and implementation of analytical deliverables \n Vendor management support, specifically aiding in creating external vendor reporting, auditing monthly vendor invoices, and supporting management in budget and reforecasting exercise \n Maintaining and creating KPI reporting \n Summarizing lengthy reports for all lines of business monthly \n Initial review of complex analysis performed by other team members by serving as second set of eyes on high visibility projects \n Supporting senior team members in intensive technical analysis \n \n The Business Analyst position   is well-suited for you if you: \n \n Have advanced skills designing and maintaining reports in Excel \n Thrive in an agile environment \n Demonstrate a high level of professionalism \u2013 especially in verbal and written communication \n Collaborate well with peers and managers in order to perform initial analyses autonomously \n Are open to accepting additional direction and constructive feedback when work products are reviewed \n Demonstrate attention to detail, strong problem solving skills, and are a quick learner \n \n What you\u2019ll need: \n \n Bachelor\u2019s degree or 8 years of relevant experience as equivalent \n 3 years of related work experience \n Intermediate to Expert-level Excel skills \n \n What will set you apart: \n \n Operational knowledge of group insurance \n \n The Company offers the following benefits for this position, subject to applicable eligibility requirements: \n \n medical insurance \n dental insurance \n vision insurance \n 401(k) retirement plan with company match \n short-term & long-term disability insurance \n Paid time-off and corporate holidays, \n paid parental leave \n company paid life insurance \n \n Click on this link for additional information. \n CNO embraces flexibility and encourages you to work where you\u2019re most productive. Associates who live within a 60-mile radius of a corporate office (Birmingham, Carmel, Chicago, Orlando and Milwaukee) have access to come into that office. \n Associates who live outside of a 60-mile radius of a corporate office (Birmingham, Carmel, Chicago, Orlando and Milwaukee) may perform this role full-time work from home (WFH) from any US based location, as long as you are willing to work central or eastern time zone hours. \n All associates may be asked to travel to varying corporate offices periodically. Work cannot be performed from outside of the United States. \n CNO provides life and health insurance, annuities, financial services, and workforce benefits solutions through our family of brands and supported by our associates and agents. Our customers work hard to save for the future, and we help protect their health, income and retirement needs with 3.2 million policies and more than $35 billion in total assets. Our 3,400 associates, 8,600 exclusive agents and independent partner agents guide individuals, families and businesses through a lifetime of financial decisions. \n We are financially strong and well positioned for continued growth, and we are grounded in our core values of Diversity, Equity & Inclusion (DE&I); Integrity, Customer Focus, Excellence, and Teamwork. We have offices in more than 260 communities in the U.S., including our headquarters in Carmel, Indiana, and corporate offices in Birmingham, Chicago, Philadelphia, Orlando and Milwaukee. \n At CNO Financial Group, we\u2019re always looking forward\u2014to the security and stability we help create for our insurance brands\u2019 customers, and the growth we create within our own company. We're looking for ambitious people who want to do more. We'll provide you with opportunities to grow your skills through challenging professional experiences. \n If you're looking for a culture that encourages development, helps you reach your potential, and rewards you for your contribution, then CNO Financial Group is right for you. For more information, visit CNOinc.com. \n We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, sex, gender, gender expression, sexual orientation, age, marital status, veteran status, or disability status. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation. \n Compensation \n Pay Range: $45,700.00 - $68,500.00 Annual \n We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, sex, gender, gender expression, sexual orientation, age, marital status, veteran status, or disability status. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation. \n ReqID  : JR167659 \n Job Type  : Full time", "cleaned_desc": "", "techs": ""}, "e5fdd799d0102828": {"terms": ["data analyst"], "salary_min": 68238.09, "salary_max": 86404.64, "title": "HRIS Analyst", "company": "Agero", "desc": "About Agero: \n Wherever drivers go, we're leading the way. Agero's mission is to rethink the vehicle ownership experience through a powerful combination of passionate people and data-driven technology, strengthening our clients' relationships with their customers. As the #1 B2B, white-label provider of digital driver assistance services, we're pushing the industry in a new direction, taking manual processes, and redefining them as digital, transparent, and connected. This includes: an industry-leading dispatch management platform powered by Swoop; comprehensive accident management services; knowledgeable consumer affairs and connected vehicle capabilities; and a growing marketplace of services, discounts and support enabled by a robust partner ecosystem. The company has over 150 million vehicle coverage points in partnership with leading automobile manufacturers, insurance carriers and many others. Managing one of the largest national networks of service providers, Agero responds to approximately 12 million service events annually. Agero, a member company of The Cross Country Group, is headquartered in Medford, Mass., with operations throughout North America. To learn more, visit www.agero.com. \n \n  The HRIS Analyst will provide functional support for all HR applications. This individual will leverage their expertise to contribute to and support HR system implementations, upgrades, testing and other technical projects as assigned. This individual will serve as a technical point of contact and the subject matter expert ensuring operational effectiveness, data integrity and analyzing process improvement opportunities. \n  Key Outcomes \n \n Provides day to day technical and administration support to departmental and end users \n Serves as liaison between vendors and/or IT and HR end users to troubleshoot functional system issues, identify root causes and partner with stakeholders to fix errors so that problems are not repeated. Documents changes to system and processes. \n Assures system integration functionality and troubleshoots integration issues, including review of integration specifications and development and maintenance \n Reviews, writes, and updates system documentation, including process maps/workflows, standard operating procedures, and project plans for HRIS. \n Continuously develops advanced knowledge of HCM cloud by utilizing vendor websites, user groups and training to maximize system capabilities. \n Maintains working knowledge of other integrated applications and/or interfaces \n Identify opportunities to automate processes and modernize systems. \n Provide support to other business areas that use HR data in their systems and reporting. \n Identify root-cause errors and potential solutions to ensure that data quality targets are met. \n Ensure accuracy and integrity of all HRIS data. Perform group data updates, exports, imports, clean-ups, and troubleshoot any data discrepancies. \n Proactively recommends process improvements/solutions utilizing technology to solve business needs/problems while also enhancing the understanding and acceptance of systems and capabilities \n Analyzes data and designs and develops both standard and complex reports to support HR and business needs. \n Develops and maintains reports for HR using various database and reporting tools. \n With direction from HR Management team; \n \n Configures system to meet business process requirements; plans for and supports migrations, releases, upgrades and/or patches, including functionality and design review as well as end to end user testing; provides technical and administration support to end users. \n Consults with functional owners to translate operational needs into system requirements and effectively communicates system capabilities and limitations. Partners with the team to determine best options for design decisions based on documented requirements, current configuration, and downstream impacts. \n \n \n Qualifications \n \n Bachelor's degree or equivalent experience. \n 4+ years of experience as an analyst or administrator responsible for configuration, testing, and application support \n Experience supporting a major HRIS migration \n Proficient in HCM, Recruiting, Benefits, Performance and Compensation modules - UKG (UltiPro) required \n Experience interpreting data and presenting information and findings \n Ability to perform diagnostic, identify problems and provide solutions \n Superior analytical, critical thinking, problem solving and innovative skills \n Excellent working knowledge of HR systems, data structure and report generation \n Ability to prioritize work under time constraints to meet project deadlines \n \n \n \n  #LI-REMOTE \n \n  D, E & I Mission & Culture at Agero : \n  We are all Change Drivers at Agero. Each day, we speak to thousands of drivers and tow professionals across one of the most diverse countries in the world. Our mission to safeguard drivers on the road, strengthen our clients' relationships with their drivers, and support the communities we live and work in unites us together as one force driving positive change. \n  The road to positive change starts inside Agero. In celebrating each other's differences, we lift each other up and create space for innovation and community. Bringing our whole selves to work powers our commitment, drive, agility, and courage - ensuring we are not only changing the landscape of the driver services industry, we also are making a difference in the lives of our customers with each call, chat, and rescue. \n  THIS DESCRIPTION IS NOT INTENDED TO BE A COMPLETE STATEMENT OF JOB CONTENT, RATHER TO ACT AS A GUIDE TO THE ESSENTIAL FUNCTIONS PERFORMED. MANAGEMENT RETAINS THE DISCRETION TO ADD TO OR CHANGE THE DUTIES OF THE POSITION AT ANY TIME. \n  To review Agero's privacy policy click the link: https://www.agero.com/privacy. \n  ***Disclaimer:  Agero is committed to creating a diverse and inclusive environment and encourages applications from all qualified candidates. Accommodation is available. Additionally, we offer accommodation for applicants with disabilities in our recruitment processes. If you require accommodation during the recruitment process, please contact  recruiting@agero.com", "cleaned_desc": " Reviews, writes, and updates system documentation, including process maps/workflows, standard operating procedures, and project plans for HRIS. \n Continuously develops advanced knowledge of HCM cloud by utilizing vendor websites, user groups and training to maximize system capabilities. \n Maintains working knowledge of other integrated applications and/or interfaces \n Identify opportunities to automate processes and modernize systems. \n Provide support to other business areas that use HR data in their systems and reporting. \n Identify root-cause errors and potential solutions to ensure that data quality targets are met. \n Ensure accuracy and integrity of all HRIS data. Perform group data updates, exports, imports, clean-ups, and troubleshoot any data discrepancies. \n Proactively recommends process improvements/solutions utilizing technology to solve business needs/problems while also enhancing the understanding and acceptance of systems and capabilities \n Analyzes data and designs and develops both standard and complex reports to support HR and business needs.   Bachelor's degree or equivalent experience. \n 4+ years of experience as an analyst or administrator responsible for configuration, testing, and application support \n Experience supporting a major HRIS migration \n Proficient in HCM, Recruiting, Benefits, Performance and Compensation modules - UKG (UltiPro) required \n Experience interpreting data and presenting information and findings \n Ability to perform diagnostic, identify problems and provide solutions \n Superior analytical, critical thinking, problem solving and innovative skills \n Excellent working knowledge of HR systems, data structure and report generation \n Ability to prioritize work under time constraints to meet project deadlines ", "techs": ["reviews", "writes", "and updates system documentation", "process maps/workflows", "standard operating procedures", "and project plans for hris.\nutilizing vendor websites", "user groups", "and training to develop advanced knowledge of hcm cloud.\nmaintaining working knowledge of other integrated applications and/or interfaces.\nidentifying opportunities to automate processes and modernize systems.\nsupporting other business areas that use hr data in their systems and reporting.\nidentifying root-cause errors and potential solutions for data quality.\nperforming group data updates", "exports", "imports", "cleanups", "and troubleshooting data discrepancies.\nproactively recommending process improvements/solutions utilizing technology.\nanalyzing data and designing and developing standard and complex reports.\nbachelor's degree or equivalent experience.\n4+ years of experience as an analyst or administrator responsible for configuration", "testing", "and application support.\nexperience supporting a major hris migration.\nproficient in hcm", "recruiting", "benefits", "performance", "and compensation modules - ukg (ultipro) required.\nexperience interpreting data and presenting information and findings.\nability to perform diagnostic", "identify problems", "and provide solutions.\nsuperior analytical", "critical thinking", "problem-solving", "and innovative skills.\nexcellent working knowledge of hr systems", "data structure", "and report generation.\nability to prioritize work under time constraints to meet project deadlines."]}, "96e031fcb4345b59": {"terms": ["data analyst"], "salary_min": 112160.53, "salary_max": 142020.22, "title": "Compliance Analyst II, Data Protection & Privacy", "company": "HashiCorp", "desc": "Compliance Analyst II, Data Protection and Privacy \n  We're looking for an individual well versed in the cloud environment and associated technical controls to help continually develop and mature the data protection and privacy program. This role will be heavily focused on assisting with building out, automating, and managing data protection and privacy operations capabilities across HashiCorp. We're looking for a self-motivated individual who thrives in fast-paced environments, can seamlessly drive efforts with multiple stakeholders to accomplish large goals, has demonstrable experience in operational privacy and data protection and is comfortable working across the breadth and depth of a large program.Security at HashiCorp is a remote team. While prior experience working remotely isn't required, we are looking for team members who can perform well given a high level of independence and autonomy. \n  HashiCorp embraces diversity and equal opportunity. We are committed to building a team that represents a variety of backgrounds, perspectives, and skills. We believe the more inclusive we are, the better our company will be. \n  In this role, your responsibilities will include to: \n \n Lead multiple work streams and/or teams to execute against project plans \n Prioritize and manage completing competing efforts within the privacy and GRC function \n Drive maintaining awareness of data in our cloud products and corporate systems \n Document new or expanding processes and controls for data privacy and data management \n Manage risk registers and help track risk remediation \n Lead relevant internal controls testing and audit readiness preparation \n Help lead data protection efforts and program build out, including associated controls \n Manage external customer communications regarding privacy and the control environment \n Define, collect, and report on metrics for the privacy program \n Continually improve the privacy program, policies, and processes \n Help with common GRC activities as needed \n \n Must-Have Qualifications \n \n 4+ years of experience with security or privacy controls development/management \n Experience with controls in a cloud environment \n High-level understanding of privacy regulations and requirements, such as CCPA & GDPR \n Experience with creating and implementing technical controls for data privacy and/or information security requirements \n Strong risk management experience, including management of the risk lifecycle \n Comfortable working with both deeply technical and non-technical audiences \n Able to develop relationships in a highly cross functional environment \n Highly responsive and with a customer first mindset \n Flexibility in daily hours (i.e., willingness to work longer hours during end of quarter, peak periods and audits) \n Ability to prioritize and track multiple competing projects in parallel \n \n Desired Qualifications \n \n 5+ years of relevant experience, including enhancing a privacy program \n Understanding of evolving privacy landscape and introduction of new laws and regulations globally \n Previous experience at a technology or SaaS company in similar role \n Relevant certifications, including from ISACA (e.g., CISA, CISSP) or IAPP (e.g., CIPP/E, CIPM, CIPT) \n \n About the Application Process \n  Please note, as communication is a critical aspect of how we work, a cover letter is a great way to provide a sample of how you communicate. In your cover letter, describe why you're interested in working at HashiCorp, and what draws you to this role in particular. \n  HashiCorp embraces diversity and equal opportunity. We are committed to building a team that represents a variety of backgrounds, perspectives, and skills. We believe the more inclusive we are, the better our company will be. \n  #LI-AZ1 \n  #LI-REMOTE \n \n  Canada, Colorado, California, Washington and New York Applicants:  To view base salary ranges for this role in your location and to learn more about which roles are eligible for bonus pay or commissions, please visit our Pay Transparency Calculator below. Individual pay within the range will be determined based on job related-factors such as skills, experience, and education or training. Information on our benefits can be found via the link below. Intern ranges can be found below. \n \n Pay Transparency Calculator: https://bit.ly/3B7gwql \n Benefits: https://www.hashicorp.com/careers/benefits \n Intern Ranges: https://bit.ly/3H2soha", "cleaned_desc": " \n 4+ years of experience with security or privacy controls development/management \n Experience with controls in a cloud environment \n High-level understanding of privacy regulations and requirements, such as CCPA & GDPR \n Experience with creating and implementing technical controls for data privacy and/or information security requirements \n Strong risk management experience, including management of the risk lifecycle \n Comfortable working with both deeply technical and non-technical audiences \n Able to develop relationships in a highly cross functional environment \n Highly responsive and with a customer first mindset ", "techs": ["none"]}, "db5f99885eceba96": {"terms": ["data analyst"], "salary_min": 80000.0, "salary_max": 85000.0, "title": "Program/Communication Analyst", "company": "Decisive Point Consulting Group", "desc": "Currently seeking a Program/Communications Analyst to support the Department of Veterans Affairs. The Program Analyst will be responsible for the data call process and VA PARS compliance tracking for the Product Line. The environment is dynamic and client needs are often evolving; flexibility and forward-thinking views are important for success. This is a remote working opportunity. The individual is expected to have a proven track record of working remotely with minimal direction. \n Office hours are M-F 8am-5pm ET. \n Essential Functions: \n \n Manage data call responses for a VA IT Product Line. Analyze data call requests, identify recurring data call needs, and formulate responses with a minimum of leadership guidance, review data call requirements and formulate a recommended response to Product Line leadership. Manage and track data call progress; coordinate with cross-discipline stakeholders to ensure all parties are on track with meeting data call suspense \n Leverage excellent writing skills to translate complicated issues from multiple information sources into a clear point of view, and create a compelling, concise, and well-written narrative \n Develop or provide feedback on clear and concise communications products and materials for internal or external audiences \n Conduct research, analyze information needs, and perform analysis to support the delivery of relevant artifacts \n Develop, gather, and disseminate product information and documentation \n Track, forecast, and report on project progress including metrics and challenges \n Support the clients by applying creative problem-solving and an entrepreneurial approach. Be a self-starter without the need for guidance with every task. \n Providing meeting management support including scheduling, communicating to attendees and recording/capturing meeting minutes to sustain momentum for future, recurring meetings. \n Facilitate meetings as directed by Product Line leadership and maintain meeting pace without interfering with attendee reporting and discussion. \n Formulate responses for weekly executive reports and VA PARS compliance reports \n Proactively monitor VA artifact repositories to ensure compliance with and timeliness of content updates. \n Take ownership for formatting and content accuracy of Product Line and Product Team presentations. \n Obtain and maintain a detailed working knowledge of Product Line/Product Team goals, objectives, milestones, and Product Line\u2019s/Product Team\u2019s client-facing deliverables as a foundation for proactively updating, correcting, and formatting all Product Line/Product Team documents, presentations, lists, archives, and reporting dashboards for which you have ownership and create/update responsibility. \n Planning details for travel including transportation, accommodation, and airlines. \n Planning and logistics for large-scale events including conferences and retreats. \n \n Required Skills and Experience : \n \n Great interpersonal skills and ability to work independently with minimal guidance/supervision \n Solid experience with Microsoft and other collaborative tools including Teams, SharePoint, Jira, etc. \n Must be skilled in using MS Office applications particularly MS Teams and SharePoint to collaborate with team members \n Must be organized, detail oriented, and possess analytical skills \n Bachelor's Degree in Engineering or related scientific or technical discipline is required. \n A minimum of 10 years of experience required. An additional 8 years of experience may be substituted for education. \n \n Desired Qualifications: \n \n Well-versed in the VA project management methodology and other VA-related reporting methodologies. \n Prior support of a VA IT Product Line, especially within the Health Portfolio \n Strong communication skills (oral and written) to relay concise messaging and reporting to all stakeholders for both technical and non-technical subjects \n Analytical and investigation skills crafting solutions to challenging problems or issues \n Demonstrated experience in a remote work environment. Familiar with Product Line Maturity levels and requirements. \n Clearance Required: Public Trust \n \n EEO Minority/Disabled/Veteran/Female \n Job Type: Full-time \n Pay: $80,000.00 - $85,000.00 per year \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Employee assistance program \n Health insurance \n Paid time off \n Tuition reimbursement \n Vision insurance \n \n Schedule: \n \n Monday to Friday \n \n Application Question(s): \n \n Are you a US Citizen or Green Card Holder? (Y/N) \n Are you willing to go through the background check in order to receive a public trust clearance? (Y/N) \n Are you comfortable with the salary range posted? \n Is your Bachelor's Degree in an Engineering or related technical field? (Y/N) \n \n Education: \n \n Bachelor's (Required) \n \n Experience: \n \n Professional work: 10 years (Required) \n Jira: 2 years (Required) \n Previous VA (Veteran Affairs) Project Management Methodology: 2 years (Required) \n \n Work Location: Remote", "cleaned_desc": " Proactively monitor VA artifact repositories to ensure compliance with and timeliness of content updates. \n Take ownership for formatting and content accuracy of Product Line and Product Team presentations. \n Obtain and maintain a detailed working knowledge of Product Line/Product Team goals, objectives, milestones, and Product Line\u2019s/Product Team\u2019s client-facing deliverables as a foundation for proactively updating, correcting, and formatting all Product Line/Product Team documents, presentations, lists, archives, and reporting dashboards for which you have ownership and create/update responsibility. \n Planning details for travel including transportation, accommodation, and airlines. \n Planning and logistics for large-scale events including conferences and retreats. \n \n Required Skills and Experience : \n \n Great interpersonal skills and ability to work independently with minimal guidance/supervision \n Solid experience with Microsoft and other collaborative tools including Teams, SharePoint, Jira, etc. \n Must be skilled in using MS Office applications particularly MS Teams and SharePoint to collaborate with team members \n Must be organized, detail oriented, and possess analytical skills \n Bachelor's Degree in Engineering or related scientific or technical discipline is required. \n A minimum of 10 years of experience required. An additional 8 years of experience may be substituted for education. ", "techs": ["microsoft teams", "sharepoint", "jira"]}, "ba63f570b212e1d8": {"terms": ["data analyst"], "salary_min": 78801.086, "salary_max": 99779.74, "title": "Reports Business Analyst", "company": "SoftPro", "desc": "SoftPro  is the nation's leading provider of real estate closing and title insurance software. A division of Fidelity National Financial (NYSE: FNF), SoftPro\u2019s technology solutions are used in thousands of law firms and title companies throughout the country and are an essential part of residential and commercial Real Estate transactions. SoftPro\u2019s Headquarters is in Raleigh, North Carolina.\n   \n \n SoftPro  offers comprehensive health benefit offerings (medical, dental, vision, disability, etc), 401k and Employee Stock Purchase Plans with company matching, as well as generous paid vacation time and paid parental leave. We have positions that are eligible to be 100% remote. Employees who live near our Raleigh, NC Headquarters can choose to work a hybrid (office/home) schedule.\n   \n \n SoftPro  has received national recognition for our excellent customer service and products, and we were recently recognized as a \n   2023 Best Places to Work by the Triangle Business Journal!  SoftPro has won this prestigious award 11 times since 2012!\n   \n \n What are we looking for? \n  SoftPro is seeking to fill a \n   Business Analyst  position to join our Reports Team in the Raleigh, NC office, or as a hybrid or remote employee.\n   \n  The role of a Reports Team Business Analyst is to provide reporting solutions to our customers, allowing them to make educated business decisions with Production Reporting; stay in compliance with 1099 and Trust Account Reporting (including Checks); and generate professional looking and accurate closing statements.\n  \n \n \n  The Business Analyst in particular, is the face of the reports team. They communicate directly with customers, Support staff and Implementation Managers to understand exactly what the customer\u2019s end goal is in order to create a Specification Sheet (list of detailed instructions) for the Reports Developer. They are primarily responsible for managing their projects, timelines, coordinating delivery of completed reports, lead meetings, and the upkeep of documentation, both internal and external.\n   \n \n \n What will I do as a Business Analyst at SoftPro? \n  In this position, you will be responsible for working directly with customers, identifying requirements and translating into internal development requirements/standards. This position is also responsible for troubleshooting support related requests and maintaining high quality reports to support our customer needs.\n   \n \n What skills do I need to be a successful Business Analyst at SoftPro? \n \n \n 5+ years\u2019 experience in the real estate industry with a primary emphasis on the escrow/closing side is a must \n SoftPro Select experience is highly desired \n Must be an analytical thinker \n Project management experience managing multiple projects of varying levels of difficulty in an environment with constantly changing priorities \n Ability to learn new and complex concepts easily \n Technical aptitude \n Excellent customer service skills \n Exceptional attention to detail \n 5% US travel is required \n Must be a team player, flexible, and exhibit excellent communication skills \n Bachelor's degree or Associates degree, or one to two years related experience and/or training, or an equivalent combination of education and experience. \n \n \n \n Join us and live our Core Values \n  Deliver AMAZING Customer Service, Be an AWESOME Teammate, Adopt a Sense of Urgency, Innovate to be Efficient, Produce Quality Work, Take Initiative, Go the Extra Mile.\n   \n \n \n EQUAL OPPORTUNITY POLICY \n  FNF, its affiliates and subsidiaries, is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, disability, protected veteran status, national origin, sexual orientation, gender identity or expression (including transgender status), genetic information or any other characteristic protected by applicable law.", "cleaned_desc": " \n \n 5+ years\u2019 experience in the real estate industry with a primary emphasis on the escrow/closing side is a must \n SoftPro Select experience is highly desired \n Must be an analytical thinker \n Project management experience managing multiple projects of varying levels of difficulty in an environment with constantly changing priorities \n Ability to learn new and complex concepts easily \n Technical aptitude \n Excellent customer service skills ", "techs": ["softpro select", "project management", "technical aptitude"]}, "4efe34b0be5b16d7": {"terms": ["data analyst"], "salary_min": 110000.0, "salary_max": 120000.0, "title": "Data Visualization Specialist", "company": "Tantus Technologies, Inc", "desc": "Tantus Technologies, Inc. (Tantus) - recognized by the Washington Post as a Top Workplace - is seeking a qualified Data Visualization Specialist certified in Power BI to support a federal customer in Washington, DC. Qualified candidates must possess superior skills in identifying data sources and appropriate ways to analyse data. This candidate will also be well-versed in UX/UI skills and be able to use Power BI to present large amounts of information in ways that are easy to understand and used to make decisions, including Gantt charts. Candidates should be knowledgeable of different ETL design and development methodologies & have experience with Pentaho, ELK stack  OR  similar tools. Successful candidates will also have experience working on Agile software development teams and be familiar with Agile ceremonies and tools. \n *US Citizenship required. Must be able to obtain a Public Trust. \" \n What You'll Do \n \n Power BI development and administration \n Building Analysis Services reporting models \n Developing visual reports, dashboards and KPI scorecards using Power BI \n Implement data visualization best practices to deliver intuitive and actionable dashboards \n Manager Power BI production deliverables throughout the year \n Utilize Power BI to build interactive and visually appealing dashboards and reports \n Perform DAX queries and functions in Power BI \n Connecting to data sources, importing data, and transforming data for BI \n Assist in the design and implementation of business intelligence and data warehousing solutions \n Provide insight based on data sources and contributes to development of future data enhancements \n Collaborate with Business Analyst and act as a resource for their projects \n Participate in meetings / agile ceremonies and manage frequent communications with other members within the team and client organization \n Stay up to date with the latest Power BI features and advancements to continuously enhance the client's reporting capabilities \n Implement row-level security on data and apply security layer models in Power BI \n Provide training and support to end-users to maximize their utilization of Power BI \n \n Required Knowledge and Skills \n \n BS in Computer Science, Information Systems, or related field \n Microsoft Power BI Data Analyst certified \n Minimum of 3 years of experience with Power BI using DAX and M Query expressions to build reports and dashboards. \n Minimum of 5 years in database technologies and strong SQL query writing skills, preferrable SQL Server \n Knowledge of different ETL design and development methodologies. \n In-depth understanding of how multiple data sources can be consolidated together to produce BI Solutions \n Optimize query performance tuning by database refactoring (making code more efficient and maintainable), normalizing table objects \n Experience with Microsoft Azure, SQL data warehouse, Visual Studio \n Preference for candidates w/experience working in an Agile environment. \n \n Abilities \n \n Well-organized and self-directed individual; ability to balance and prioritize competing requirements \n Ability to work collaboratively as part of a larger, integrated team \n Ability to creatively problem-solve \n Ability to build strong trust-based working relationships with team and clients \n \n Nice to Haves \n \n Experience with Microsoft SQL Server Intergration Services \n Experience in Government contracting preferred \n \n Why Tantus? We Provide: \n \n Competitive total compensation package based on the work you do and the contributions you make \n An environment that supports balancing great work with a great life \n A learning organization that invests in you with $3000 annually for professional development opportunities \n Excellent healthcare programs available through United Healthcare \n Community engagement events where you will have ample opportunities to give back by volunteering \n Discretionary quarterly bonuses for above and beyond contributions and outstanding performance \n \n About Us \n Tantus is an IT development and management consulting firm helping federal programs become more successful, cost-effective and mission-focused through program management oversight and system development and implementation. Our people are committed to making our world better by delivering solutions to improve the effectiveness of government services and citizen experience. Tantus is Latin for \u201cso great\u201d or \u201cso much\u201d \u2013 we strive to put great things into everything we do. \n Tantus is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy, gender identity, and sexual orientation), national origin, age (40 or older), disability, military status or any other classification protected by federal, state or local law. \n If you are a qualified individual with a disability or a disabled veteran, and require an accommodation to navigate Tantus\u2019 careers website or apply for one of Tantus\u2019 job openings, please contact Human Resources at Hr@tantustech.comto request a reasonable accommodation. \n Know Your Rights: Workplace Discrimination is Illegal Pay Transparency Nondiscrimination Posters \n Job Type: Full-time \n Pay: $110,000.00 - $120,000.00 per year \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Flexible schedule \n Flexible spending account \n Health insurance \n Life insurance \n Paid time off \n Parental leave \n Professional development assistance \n Vision insurance \n \n Compensation package: \n \n Performance bonus \n Yearly pay \n \n Experience level: \n \n 5 years \n \n Schedule: \n \n Monday to Friday \n \n Application Question(s): \n \n The position requires to be US Citizen or Green Card Holder. Do you meet that requirement? \n Do you have strong SQL query writing skills, preferrable SQL Server? \n Do you have a minimum of 3 years of experience in Business Analytics tool developing Reporting and Dashboards? \n \n Experience: \n \n UX/UI: 1 year (Required) \n \n Work Location: Remote", "cleaned_desc": "Tantus Technologies, Inc. (Tantus) - recognized by the Washington Post as a Top Workplace - is seeking a qualified Data Visualization Specialist certified in Power BI to support a federal customer in Washington, DC. Qualified candidates must possess superior skills in identifying data sources and appropriate ways to analyse data. This candidate will also be well-versed in UX/UI skills and be able to use Power BI to present large amounts of information in ways that are easy to understand and used to make decisions, including Gantt charts. Candidates should be knowledgeable of different ETL design and development methodologies & have experience with Pentaho, ELK stack  OR  similar tools. Successful candidates will also have experience working on Agile software development teams and be familiar with Agile ceremonies and tools. \n *US Citizenship required. Must be able to obtain a Public Trust. \" \n What You'll Do \n \n Power BI development and administration \n Building Analysis Services reporting models \n Developing visual reports, dashboards and KPI scorecards using Power BI \n Implement data visualization best practices to deliver intuitive and actionable dashboards \n Manager Power BI production deliverables throughout the year \n Utilize Power BI to build interactive and visually appealing dashboards and reports \n Perform DAX queries and functions in Power BI \n Connecting to data sources, importing data, and transforming data for BI \n Assist in the design and implementation of business intelligence and data warehousing solutions \n Provide insight based on data sources and contributes to development of future data enhancements \n Collaborate with Business Analyst and act as a resource for their projects \n Participate in meetings / agile ceremonies and manage frequent communications with other members within the team and client organization \n Stay up to date with the latest Power BI features and advancements to continuously enhance the client's reporting capabilities \n Implement row-level security on data and apply security layer models in Power BI \n Provide training and support to end-users to maximize their utilization of Power BI   \n Required Knowledge and Skills \n \n BS in Computer Science, Information Systems, or related field \n Microsoft Power BI Data Analyst certified \n Minimum of 3 years of experience with Power BI using DAX and M Query expressions to build reports and dashboards. \n Minimum of 5 years in database technologies and strong SQL query writing skills, preferrable SQL Server \n Knowledge of different ETL design and development methodologies. \n In-depth understanding of how multiple data sources can be consolidated together to produce BI Solutions \n Optimize query performance tuning by database refactoring (making code more efficient and maintainable), normalizing table objects \n Experience with Microsoft Azure, SQL data warehouse, Visual Studio \n Preference for candidates w/experience working in an Agile environment. \n \n Abilities \n \n Well-organized and self-directed individual; ability to balance and prioritize competing requirements \n Ability to work collaboratively as part of a larger, integrated team \n Ability to creatively problem-solve \n Ability to build strong trust-based working relationships with team and clients ", "techs": ["tantus technologies", "inc.", "power bi", "gantt charts", "pentaho", "elk stack", "agile software development", "analysis services", "dax queries", "business intelligence", "data warehousing", "row-level security", "sql server", "microsoft azure", "visual studio"]}, "1b43f27aa3d9b14f": {"terms": ["data analyst"], "salary_min": 20.87, "salary_max": 47.31, "title": "Financial Analyst", "company": "Principal Financial Group", "desc": "What You'll Do: \n  \n   As a \n   Financial \n Analyst,  you'll have the opportunity to work on our Individual Disability team. In this role you will be working on individual disability insurance product development and pricing. We are looking for someone who thrives on solving problems with analytical skills and enjoys working with several internal partners and tools.\n  \n \n  Participate in the maintenance, preparation, analysis, and communication of financial information used in the product development and pricing processes. \n  Work with a variety of spreadsheets and the ALFA Pricing System to set rates for products, complete state insurance filings, analyze claims experience, query and summarize data from our systems, provide reinsurance support and much more. \n  Use your technical skills to do financial research and calculations as well as build new spreadsheets and enhance existing spreadsheets and calculation processes. \n  Provide actuarial support to business partners. \n \n \n   Operating at the intersection of financial services and technology, Principal builds financial tools that help our customers live better lives. We take pride in being a purpose-led firm, motivated by our mission to make financial security accessible to all. Our mission, integrity, and customer focus have made us a trusted leader for more than 140 years!\n   Who You Are: \n  \n Bachelor\u2019s Degree in Math, Actuarial Science, Statistics, Finance, Accounting, or related field (or equivalent experience) \n  Ability to use Excel or similar software \n  Ability to collect, organize, and analyze data \n  Strong problem-solving skills \n  Demonstrated ability to continuously grow through intellectual curiosity. Comfortable collaborating with all staff levels \n \n  Skills That Will Help You Stand Out  \n \n Previous internship or work experience in the financial services industry \n  Advanced Excel skills (VBA, Macros, etc\u2026) \n  Involvement in extracurricular activities or within the community \n  Salary Range Information: Salary ranges below reflect targeted base salaries. Non-sales positions have the opportunity to participate in a bonus program. Sales positions are eligible for sales incentives, and in some instances a bonus plan, whereby total compensation may far exceed base salary depending on individual performance. Actual compensation for all roles will be based upon geographic location, work experience, education, licensure requirements and/or skill level and will be finalized at the time of offer. Salary Range: $20.87 - $47.31 / hour Additional Information: \n  Job Level \n \n   We\u2019ll consider talent at the next level with the right experiences and skills.\n  \n  Work Environments \n \n   This role offers in-office, hybrid (blending at least three office days in a typical workweek), and remote work arrangements (only if residing more than 30 miles from Des Moines, IA, or Charlotte, NC). You\u2019ll work with your leader to figure out which option may align best based on several factors.\n  \n  Work Authorization/Sponsorship  \n \n  At this time, we're not considering applicants that need any type of immigration sponsorship (additional work authorization or permanent work authorization) now or in the future to work in the United States. This includes, but IS NOT LIMITED TO: F1-OPT, F1-CPT, H-1B, TN, L-1, J-1, etc. For additional information around work authorization needs please use the following links.\n  \n \n   Nonimmigrant Workers and Green Card for Employment-Based Immigrants\n  \n  Investment Code of Ethics  \n \n  For Principal Asset Management positions, you\u2019ll need to follow an Investment Code of Ethics related to personal and business conduct as well as personal trading activities for you and members of your household. These same requirements may also apply to other positions across the organization.\n  \n  Experience Principal  \n \n  At Principal, we value connecting on both a personal and professional level. Together, we\u2019re imagining a more purpose-led future for financial services \u2013 and that starts with you. Our success depends on the unique experiences, backgrounds, and talents of our employees. And we support our employees the same way we support our customers: with comprehensive, competitive benefit offerings crafted to protect their physical, financial, and social well-being. Check out our careers site to learn more about our purpose, values and benefits.\n  \n  Principal is an Equal Opportunity Employer  \n \n  All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.\n   Posting Window: We will be accepting applications for at least 3 days from when the job was originally posted, after which we may keep open or remove the posting based upon applications we receive. Please submit applications in a timely manner as there is no guarantee the posting will be available beyond 3 days of the original posting date. Date First Posted (TTF): 10/18/2023 \n  LinkedIn Remote Hashtag  : #LI-Remote", "cleaned_desc": "", "techs": ""}, "6f54e739a2694671": {"terms": ["data analyst"], "salary_min": 85000.0, "salary_max": 110000.0, "title": "International Strategy and Operations Analyst", "company": "Dealer Tire", "desc": "Who We Are\n  \n \n   We\u2019re Dealer Tire, a family-owned, international distributor of tires and parts established in 1918 in Cleveland, OH. We\u2019re laser focused on helping the world\u2019s largest and most trusted auto manufacturers grow their tire business\u2014in fact, we\u2019ve sold more than 60 million tires to date. We\u2019re a thriving company, and we\u2019re looking for driven individuals to join our team. That\u2019s where you come in!\n  \n \n \n   Title: International Strategy and Operations Analyst\n  \n \n \n \n   Reports To: Vice President, International Operations\n  \n \n \n   FLSA Status: Exempt\n  \n \n \n   Date Created: 10/09/2023\n  \n \n \n   As an International Strategy and Operations Analyst, your essential job functions will include the following:\n  \n \n  Provide reports and analysis that support the growth strategy for International Operations. \n  Assist with research to evaluate market entry into new geographies, products, and services, to include clear investment rationale, market potential, competitor and customer analysis, financial modeling, risk assessment, market and industry trends, and related forecasts. Analysis will include an evaluation of alternatives and recommendations to decision makers. \n  Work closely with functional groups to analyze data and ensure decisions involving new business practices or modifications to existing practices are appropriately assessed for impacts on operations. \n  Information gathering and consolidation, including alignment with different intracompany departments. \n  Compare and analyze data from different sources to draw conclusions. \n  Define goals of analysis and make actionable recommendations that are consistent with available facts, constraints, and consider down-stream impacts. \n  Develop frameworks for capital allocation and ROI-based decisions that inform the speed and substance of the Company\u2019s international growth strategy. \n  Create presentation materials for management for all key projects, including Board Meetings, Partner Meetings and customer engagements. \n  Assemble and distribute operational reports and performance metrics, provide leadership with interpretations of reports, and assist them in understanding underlying data. \n \n \n \n   Project Management\n  \n \n  For all assigned projects, analyze results, gain consensus among key stakeholders, present alternatives, and results to leadership. \n  Tracking of subprojects, milestones and tasks including deadlines \n  Conduct quality research and make effective recommendations on project assignments. \n  Complete assigned projects on time and according to the specified parameters. Ensure project sponsors are consistently kept up to date on project development status. \n  Manage external consulting or technology resources, as needed to facilitate project-based objectives. \n \n \n \n   Process Documentation & Analysis\n  \n \n  Document, update, and analyze business processes as assigned. Ensure documentation is updated routinely and appropriately represented. \n  Recommend process improvements, provide innovative suggestions and solutions, identify, and understand issues, problems, and opportunities. \n  In coordination with International Operations leadership and critical internal stakeholders, manage FCPA and OFAC requirements. \n \n \n \n   Other Duties as Assigned\n  \n \n \n   Position Requirements\n  \n \n  Bachelor\u2019s degree in analytics, finance, business, strategy or related fields and/or related equivalent work experience. Advanced degree preferred. \n  3-5 years of work experience as an operations or financial analyst. International experience preferred. \n  Able to work outside of regular business hours as needed. \n  Advanced knowledge in MS Office (Excel, Word, PowerPoint, PowerBI) and data management. \n  Financial modeling \u2013 create forecast, budget models, DCF models, three-statement models. \n  Strong analytical skills with the ability to define problems, collect data, draw valid conclusions, creativity, and communication. \n  Detail oriented, works with a sense of urgency, and able to multi-task. \n  Able to adapt to ongoing and continuous change, takes initiative, and works independently as well as in a team environment. \n  Strong presentation skills and the ability to speak at all levels of the organization. \n  Effective project management experience with proven results. \n \n \n \n   Competencies Required\n  \n \n  Strong Presentation skills (Powerpoint) \u2013 data visualization, storytelling, PowerPoint design \n \n \n  Results Orientation \n  Agility \n  Initiative \n  Critical Thinking \n  Innovation \n  Relationship Building \n  Ability to work effectively among different cultures and backgrounds \n  Willingness to learn foreign language(s) \n \n \n \n   Physical Job Requirements\n  \n \n  Sitting for long periods of time. \n  Continuous viewing from and inputting data to a computer screen. \n  Travel will be required (<25%). \n \n \n \n   Drug Policy\n  \n \n  Dealer Tire is a drug-free environment. All applicants being considered for employment must pass a pre-employment drug screening before beginning work. \n \n \n \n   Why Dealer Tire: An amazing opportunity to join a growing organization, built on the efforts of hard working, innovative, and team-oriented people. The compensation offered for this position will depend on qualifications, experience, and geographic location. The total compensation package may also include commission, bonus or profit sharing. We offer a competitive & comprehensive benefit package including: paid time off, medical, dental, vision, and 401k match (50% on the dollar up to 7% of employee contribution).\n  \n \n \n   Base Pay Range:\n   $85,000 - $110,000\n  \n \n   EOE Statement: Dealer Tire is an Equal Employment Opportunity (EEO) employer and does not discriminate on the basis of race, color, national origin, religion, gender, age, veteran status, political affiliation, sexual orientation, marital status or disability (in compliance with the Americans with Disabilities Act*), or any other legally protected status, with respect to employment opportunities.\n  \n \n \n ADA Disclosure: Any candidate who feels that they may need an accommodation to complete this application, or any portions of same, based on the impact of a disability should contact Dealer Tire\u2019s Human Resources Department to discuss your specific needs. Please feel free to contact us at ADAAAccommodation@dealertire.com or via phone at 833-483-8232.", "cleaned_desc": " \n \n   Process Documentation & Analysis\n  \n \n  Document, update, and analyze business processes as assigned. Ensure documentation is updated routinely and appropriately represented. \n  Recommend process improvements, provide innovative suggestions and solutions, identify, and understand issues, problems, and opportunities. \n  In coordination with International Operations leadership and critical internal stakeholders, manage FCPA and OFAC requirements. \n \n \n \n   Other Duties as Assigned\n  \n \n \n   Position Requirements\n  \n \n  Bachelor\u2019s degree in analytics, finance, business, strategy or related fields and/or related equivalent work experience. Advanced degree preferred. \n  3-5 years of work experience as an operations or financial analyst. International experience preferred. \n  Able to work outside of regular business hours as needed. \n  Advanced knowledge in MS Office (Excel, Word, PowerPoint, PowerBI) and data management. \n  Financial modeling \u2013 create forecast, budget models, DCF models, three-statement models. \n  Strong analytical skills with the ability to define problems, collect data, draw valid conclusions, creativity, and communication.    Detail oriented, works with a sense of urgency, and able to multi-task. \n  Able to adapt to ongoing and continuous change, takes initiative, and works independently as well as in a team environment. \n  Strong presentation skills and the ability to speak at all levels of the organization. \n  Effective project management experience with proven results. \n \n \n \n   Competencies Required\n  \n \n  Strong Presentation skills (Powerpoint) \u2013 data visualization, storytelling, PowerPoint design \n \n \n  Results Orientation \n  Agility \n  Initiative \n  Critical Thinking \n  Innovation \n  Relationship Building \n  Ability to work effectively among different cultures and backgrounds \n  Willingness to learn foreign language(s) \n \n \n ", "techs": ["ms office (excel", "word", "powerpoint", "powerbi)", "data management", "financial modeling", "powerpoint design"]}, "7f611ef386634d49": {"terms": ["data analyst"], "salary_min": 89942.65, "salary_max": 113887.43, "title": "Data Governance Analyst - (REMOTE OPPORTUNITY)", "company": "Regions", "desc": "Thank you for your interest in a career at Regions. At Regions, we believe associates deserve more than just a job. We believe in offering performance-driven individuals a place where they can build a career --- a place to expect more opportunities. If you are focused on results, dedicated to quality, strength and integrity, and possess the drive to succeed, then we are your employer of choice. \n \n  Regions is dedicated to taking appropriate steps to safeguard and protect private and personally identifiable information you submit. The information that you submit will be collected and reviewed by associates, consultants, and vendors of Regions in order to evaluate your qualifications and experience for job opportunities and will not be used for marketing purposes, sold, or shared outside of Regions unless required by law. Such information will be stored in accordance with regulatory requirements and in conjunction with Regions\u2019 Retention Schedule for a minimum of three years. You may review, modify, or update your information by visiting and logging into the careers section of the system. \n \n \n Job Description: \n  At Regions, the Data Governance Analyst serves as a key resource and important intermediary between the data owners and the data consumers of the bank. Maintains connections and competencies in both the technical operational, reporting functional and analytical modeling data needs of the bank data citizens, with minimal guidance. \n \n  Primary Responsibilities \n Measures and monitors data quality, designs, and executes remediation plans, maintains, and supports applicable data management standards \n Implements and supports data quality requirements as designed by the Data Owner, including the business rules and movement controls \n Performs user acceptance testing (with applicable consumers) and reviews results with Data Owner for approval \n Reviews data quality issues, perform analysis, recommend fixes, and/or report timely any breaches of thresholds to Data Owners, Data Consumers, and escalate as needed to Enterprise Data Management (EDM) \n Manages and resolves or remediates data issues identified by Data Owners and Data Consumers \n Manages, executes and tracks data quality remediation plans in coordination with all stakeholders \n Tracks and reports data quality statistics for data quality for stewarded application(s), warehouse or mart (including developing evidence of compliance with Data standards) \n Collects and updates business metadata and references data for the data they are assigned to \n Translates business rules into data quality rules and produces data controls (in conjunction with the Data Custodians) \n Ensures data for all Enterprise Critical Data Elements (ECDEs) is provisioned in an appropriate authoritative source (in conjunction with Data Custodians) \n Supports applications and platforms to enable effective sharing of data from authoritative data sources \n Provides training and data assistance as needed \n May act as a resource to associates with less experience \n \n  This position is exempt from timekeeping requirements under the Fair Labor Standards Act and is not eligible for overtime pay. \n \n  Requirements \n Bachelor\u2019s degree in Business Management, Information Systems, or related field and seven (7) years of Business Analysis, Systems Analysis, or related experience \n \n  Preferences \n Master\u2019s degree in Business, Science, or related field \n \n  Skills and Competencies \n Ability to learn additional systems as needed \n Ability to translate business needs into technical solutions \n Ability to work under limited guidance \n Administrative ability and experience with communications with multiple stakeholders. \n Advanced skills in Data Analytics, Data Engineering, and Data Modeling, \n Capacity for day-to-day, hands-on execution \n Demonstrated ability to lead a team including an Agile team. \n Demonstrated knowledge and understanding of the applicable tools (e.g., DG, DQ, Metadata tool) \n Experience as a Scrum Master or Product Owner. \n Familiarity with data quality issues and Exact, Transform, Load (ETL) processes \n Presentation ability with multiple visualization tools. \n Skilled with advanced data management techniques and tooling that can leverage Big Data environment. \n Solid written, verbal, interpersonal, analytical, and application development skills \n Strong ability to review and analyze data, and identify and resolve problems \n Strong Banking Data Domain expertise including hands on experience and analysis of lending, deposit, and investment data. \n Strong project management skills including leading projects and independent data related work streams. \n Strong research and problem determination and solution skills \n Strong skills in data analysis - developing macros, scripts, queries to calculate data quality \n Typically work across many data assets and is an operations or technology person who is responsible for a data asset as it flows through systems \n Understanding of data architecture practices \n \n  Position Type Full time \n \n  Compensation Details \n Pay ranges are job specific and are provided as a point-of-market reference for compensation decisions. Other factors which directly impact pay for individual associates include: experience, skills, knowledge, contribution, job location and, most importantly, performance in the job role. As these factors vary by individuals, pay will also vary among individual associates within the same job. \n \n  The target information listed below is based on the national range and level of the position. \n \n \n Job Range Target: \n \n Minimum:  $97,784.00 USD \n \n Median:  $141,960.00 USD \n \n Incentive Pay Plans:  This job is not incentive eligible. \n \n  Benefits Information \n Regions offers a benefits package that is flexible, comprehensive and recognizes that \"one size does not fit all\" for benefits-eligible associates. Listed below is a synopsis of the benefits offered by Regions for informational purposes, which is not intended to be a complete summary of plan terms and conditions. \n Paid Vacation/Sick Time \n 401K with Company Match \n Medical, Dental and Vision Benefits \n Disability Benefits \n Health Savings Account \n Flexible Spending Account \n Life Insurance \n Parental Leave \n Employee Assistance Program \n Associate Volunteer Program \n \n  Please note, benefits and plans may be changed, amended, or terminated with respect to all or any class of associate at any time. To learn more about Regions\u2019 benefits, please click or copy the link below to your browser. \n \n  https://www.regions.com/welcometour/benefits.rf \n \n  Location Details Riverchase Operations Center \n \n Location:  Hoover, Alabama \n \n  Bring Your Whole Self to Work \n \n  We have a passion for creating an inclusive environment that promotes and values diversity of race, color, national origin, religion, age, sexual orientation, gender identity, disability, veteran status, genetic information, sex, pregnancy, and many other primary and secondary dimensions that make each of us unique as individuals and provide valuable perspective that makes us a better company and employer. More importantly, we recognize that creating a workplace where everyone, regardless of background, can do their best work is the right thing to do. \n \n \n OFCCP Disclosure:  Equal Opportunity Employer/Disabled/Veterans", "cleaned_desc": "Thank you for your interest in a career at Regions. At Regions, we believe associates deserve more than just a job. We believe in offering performance-driven individuals a place where they can build a career --- a place to expect more opportunities. If you are focused on results, dedicated to quality, strength and integrity, and possess the drive to succeed, then we are your employer of choice. \n \n  Regions is dedicated to taking appropriate steps to safeguard and protect private and personally identifiable information you submit. The information that you submit will be collected and reviewed by associates, consultants, and vendors of Regions in order to evaluate your qualifications and experience for job opportunities and will not be used for marketing purposes, sold, or shared outside of Regions unless required by law. Such information will be stored in accordance with regulatory requirements and in conjunction with Regions\u2019 Retention Schedule for a minimum of three years. You may review, modify, or update your information by visiting and logging into the careers section of the system. \n \n \n Job Description: \n  At Regions, the Data Governance Analyst serves as a key resource and important intermediary between the data owners and the data consumers of the bank. Maintains connections and competencies in both the technical operational, reporting functional and analytical modeling data needs of the bank data citizens, with minimal guidance. \n \n  Primary Responsibilities \n Measures and monitors data quality, designs, and executes remediation plans, maintains, and supports applicable data management standards \n Implements and supports data quality requirements as designed by the Data Owner, including the business rules and movement controls \n Performs user acceptance testing (with applicable consumers) and reviews results with Data Owner for approval \n Reviews data quality issues, perform analysis, recommend fixes, and/or report timely any breaches of thresholds to Data Owners, Data Consumers, and escalate as needed to Enterprise Data Management (EDM) \n Manages and resolves or remediates data issues identified by Data Owners and Data Consumers \n Manages, executes and tracks data quality remediation plans in coordination with all stakeholders \n Tracks and reports data quality statistics for data quality for stewarded application(s), warehouse or mart (including developing evidence of compliance with Data standards) \n Collects and updates business metadata and references data for the data they are assigned to \n Translates business rules into data quality rules and produces data controls (in conjunction with the Data Custodians) \n Ensures data for all Enterprise Critical Data Elements (ECDEs) is provisioned in an appropriate authoritative source (in conjunction with Data Custodians)   Supports applications and platforms to enable effective sharing of data from authoritative data sources \n Provides training and data assistance as needed \n May act as a resource to associates with less experience \n \n  This position is exempt from timekeeping requirements under the Fair Labor Standards Act and is not eligible for overtime pay. \n \n  Requirements \n Bachelor\u2019s degree in Business Management, Information Systems, or related field and seven (7) years of Business Analysis, Systems Analysis, or related experience \n \n  Preferences \n Master\u2019s degree in Business, Science, or related field \n \n  Skills and Competencies \n Ability to learn additional systems as needed \n Ability to translate business needs into technical solutions \n Ability to work under limited guidance \n Administrative ability and experience with communications with multiple stakeholders. \n Advanced skills in Data Analytics, Data Engineering, and Data Modeling, \n Capacity for day-to-day, hands-on execution   Demonstrated ability to lead a team including an Agile team. \n Demonstrated knowledge and understanding of the applicable tools (e.g., DG, DQ, Metadata tool) \n Experience as a Scrum Master or Product Owner. \n Familiarity with data quality issues and Exact, Transform, Load (ETL) processes \n Presentation ability with multiple visualization tools. \n Skilled with advanced data management techniques and tooling that can leverage Big Data environment. \n Solid written, verbal, interpersonal, analytical, and application development skills \n Strong ability to review and analyze data, and identify and resolve problems \n Strong Banking Data Domain expertise including hands on experience and analysis of lending, deposit, and investment data. \n Strong project management skills including leading projects and independent data related work streams. \n Strong research and problem determination and solution skills \n Strong skills in data analysis - developing macros, scripts, queries to calculate data quality \n Typically work across many data assets and is an operations or technology person who is responsible for a data asset as it flows through systems \n Understanding of data architecture practices \n \n  Position Type Full time \n \n  Compensation Details \n Pay ranges are job specific and are provided as a point-of-market reference for compensation decisions. Other factors which directly impact pay for individual associates include: experience, skills, knowledge, contribution, job location and, most importantly, performance in the job role. As these factors vary by individuals, pay will also vary among individual associates within the same job. ", "techs": ["regions", "data governance analyst", "technical operational", "reporting functional", "analytical modeling", "data owner", "user acceptance testing", "data consumers", "enterprise data management", "data quality remediation plans", "business metadata", "data custodians", "enterprise critical data elements", "authoritative data sources", "training", "business analysis", "systems analysis", "master's degree", "data analytics", "data engineering", "data modeling", "agile team", "scrum master", "product owner", "exact", "transform", "load", "etl processes", "visualization tools", "big data environment", "written", "verbal", "interpersonal", "analytical", "application development skills", "banking data domain expertise", "project management skills", "research", "problem determination", "data analysis", "data architecture."]}, "7387457deca45da1": {"terms": ["data analyst"], "salary_min": 56000.0, "salary_max": 97000.0, "title": "Senior Business Analyst (Competitive Intelligence)", "company": "VSP Global", "desc": "Develop, research, test, and implement business process improvements, procedures, and system changes. Use independent judgement to gather and evaluate information to make recommendations for improvements to business processes or systems.\n  \n \n   Essential Functions\n  \n \n \n   Develop alternative views and future business needs to assist management in making business changes to stay ahead of the competition\n  \n \n \n   Research the external market and internal business to find and leverage patterns and best practices to improve business processes\n  \n \n \n   Apply advanced analysis skills in the development of business process models, procedures, and systems\n  \n \n \n   Lead teams to continually look at process improvement strategies for business processes and systems\n  \n \n \n   Evaluate business process changes to identify and document business impacts and benefits at a corporate level\n  \n \n \n   Act as subject matter expert to provide business requirements for process improvements and system enhancements\n  \n \n \n   Conduct effective interview/research to determine and document the stakeholders, business needs, and requirements\n  \n \n \n   Serve as a mentor for requirement methodology and analysis best practices\n  \n \n \n   Review technical design deliverables to ensure business objectives are reached\n  \n \n \n   Assist business stakeholders to design user acceptance testing, defect reporting, and resolution, with the ability to lead others in these activities\n  \n \n \n   Identification of training and development materials, communications of changes, manuals, etc.\n  \n \n \n   Provide post-implementation support, such as problem resolution, adjustments to new procedures, and change management\n  \n \n \n   Develop presentations of materials, models, findings, plans, and/or conclusions\n  \n \n \n   Job Specifications\n  \n \n \n  Typically has the following skills or abilities: \n \n \n \n   Bachelor\u2019s Degree in Business Administration or related field, or equivalent experience\n  \n \n \n   4+ years of experience in data gathering, research & analytics, problem identification, and presenting solution recommendations\n  \n \n \n   4+ years of experience with financial and risk analysis, making recommendations, and preparing business cases including cost-benefit analysis\n  \n \n \n   4+ years of in-depth knowledge of project planning techniques and methodologies\n  \n \n \n   4+ years of experience with business process analytics using Excel, flowcharting, activity diagrams, and workflow models\n  \n \n \n   Demonstrated ability to document, propose, negotiate, and present approaches and solutions\n  \n \n \n   Ability to visualize and create plans for future business outcomes and changes\n  \n \n \n   Thorough understanding of business implications, project interdependencies, and system interfaces\n  \n \n \n   Strong conflict management skills\n  \n \n \n   Proficient at facilitating meetings, and negotiating across all levels of the organization\n  \n \n \n   Ability to multi-task and work in a team environment\n  \n \n   Proven ability to effectively communicate information to a wide variety of technical and non-technical individuals or groups at all levels of the organization\n  \n \n \n   Regularly exercise discretion and independent judgment in the performance of job duties\n  \n \n \n   Preferred Skills\n  \n \n \n   Customer service oriented; experience working with or supporting sales teams\n  \n \n   Research experience (qualitative and/or quantitative) is a plus\n  \n \n   Strong analytic skills; using data analysis to back up competitive positioning\n  \n \n   Experience in Salesforce\n  \n \n   Growth mindset; a continuous learner with passion for helping VSP win in a competitive market\n  \n \n   Healthcare experience\n  \n \n \n   #LI-REMOTE\n  \n \n   #LI-VISIONCARE\n  \n \n \n   Compensation range for the role is listed below. Applicable salary ranges may differ across markets.\n     Actual pay will be determined based on experience and other job-related factors permitted by law. As a part of the compensation package, this role may include eligible bonuses, equity and commissions. For more information regarding VSP Vision benefits, please \n   \n   click here\n   .\n  \n  Salary Ranges: $56,000.00 - $97,000.00\n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                        VSP Vision is an equal opportunity employer and gives consideration for employment to qualified applicants without regard to age, gender, race, color, religion, sex, national origin, gender identity, sexual orientation, disability or protected veteran status. We maintain a drug-free workplace and perform pre-employment substance abuse testing.\n                       \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n   Notice to Candidates: Fraud Alert - Fake Job Opportunity Solicitations Used to Collect Fees/Personal Information.\n  \n \n  We have been made aware that fake job opportunities are being offered by individuals posing as VSP Vision and affiliate recruiters. \n   \n   Click here \n   to learn about our application process and what to watch for regarding false job opportunities.\n  \n \n \n   As a regular part of doing business, VSP Vision (\u201cVSP\u201d) collects many different types of personal information, including protected health information, about our audiences, including members, doctors, clients, brokers, business partners, and employees. VSP Vision employees will have access to this sensitive personal information and are subject to follow Information Security and Privacy Policies.", "cleaned_desc": " \n   Assist business stakeholders to design user acceptance testing, defect reporting, and resolution, with the ability to lead others in these activities\n  \n \n \n   Identification of training and development materials, communications of changes, manuals, etc.\n  \n \n \n   Provide post-implementation support, such as problem resolution, adjustments to new procedures, and change management\n  \n \n \n   Develop presentations of materials, models, findings, plans, and/or conclusions\n  \n \n \n   Job Specifications\n  \n \n \n  Typically has the following skills or abilities: \n \n \n \n   Bachelor\u2019s Degree in Business Administration or related field, or equivalent experience\n  \n \n \n   4+ years of experience in data gathering, research & analytics, problem identification, and presenting solution recommendations\n  \n \n \n   4+ years of experience with financial and risk analysis, making recommendations, and preparing business cases including cost-benefit analysis\n  \n \n \n   4+ years of in-depth knowledge of project planning techniques and methodologies\n  \n \n \n   4+ years of experience with business process analytics using Excel, flowcharting, activity diagrams, and workflow models   \n \n \n   Demonstrated ability to document, propose, negotiate, and present approaches and solutions\n  \n \n \n   Ability to visualize and create plans for future business outcomes and changes\n  \n \n \n   Thorough understanding of business implications, project interdependencies, and system interfaces\n  \n \n \n   Strong conflict management skills\n  \n \n \n   Proficient at facilitating meetings, and negotiating across all levels of the organization\n  \n \n \n   Ability to multi-task and work in a team environment\n  \n \n   Proven ability to effectively communicate information to a wide variety of technical and non-technical individuals or groups at all levels of the organization\n  \n \n \n   Regularly exercise discretion and independent judgment in the performance of job duties\n  \n \n \n   Preferred Skills\n  \n \n \n   Customer service oriented; experience working with or supporting sales teams\n  \n \n   Research experience (qualitative and/or quantitative) is a plus", "techs": ["user acceptance testing", "defect reporting", "resolution", "identification of training and development materials", "communications", "manuals", "post-implementation support", "problem resolution", "adjustments", "change management", "presentations", "materials", "models", "findings", "plans", "conclusions", "bachelor's degree in business administration", "data gathering", "research & analytics", "problem identification", "presenting solution recommendations", "financial analysis", "risk analysis", "making recommendations", "preparing business cases", "cost-benefit analysis", "project planning techniques", "methodologies", "business process analytics", "excel", "flowcharting", "activity diagrams", "workflow models", "documentation", "proposal", "negotiation", "visualization", "creating plans", "business outcomes", "changes", "business implications", "project interdependencies", "system interfaces", "conflict management", "facilitating meetings", "negotiation", "multi-task", "team environment", "communication", "discretion", "independent judgment", "customer service", "sales support", "research experience."]}, "795dd1338fefe849": {"terms": ["data analyst"], "salary_min": 80000.0, "salary_max": 90000.0, "title": "Business Analyst", "company": "One Gi Llc", "desc": "Job Summary:  The Business Analyst will collaborate with various departments and stakeholders to gather, document, and analyze business requirements, processes, and workflows. They will translate these requirements into functional specifications for teams and work closely with project managers, developers, and testers to ensure successful project delivery. The Business Analyst will also be involved in identifying areas for process improvement and recommending solutions to enhance operational efficiency and effectiveness.\n  \n \n \n  Supervisory Responsibility:  This position has no supervisory responsibilities.\n  \n \n \n  Key Responsibilities \n \n \n \n \n     Gather, review and analyze business and industry data, including KPIs, financial reports and other key metrics usingdata analytics tools\n    \n \n \n     Liaison between various departments and groups\n    \n \n \n     Write clear and well-structured business requirements and documentation\n    \n \n \n     Identify automation opportunities\n    \n \n \n     Create reports, dashboards and visualizations to help others understand business performance\n    \n \n \n     Develop and maintain reporting tools (Zuar, Snowflake and Tableau)\n    \n \n \n     Perform data discovery, analysis and modeling\n    \n \n \n     Work closely with business stakeholders to understand their needs, objectives, and challenges.\n    \n \n \n     Elicit, document, and analyze business requirements, processes, and workflows.\n    \n \n \n     Translate business requirements into clear and concise functional specifications for technical teams.\n    \n \n \n     Propose innovative and practical solutions to address business challenges.\n    \n \n \n     Ensure that proposed solutions align with the organization's strategic goals and technological capabilities.\n    \n \n \n     Serve as a liaison between business stakeholders and technology teams.\n    \n \n \n     Maintain accurate and up-to-date project documentation throughout the project lifecycle.\n    \n \n \n     Collaborate with project managers to define project scope, objectives, and deliverables.\n    \n \n \n     Assist in project planning, estimation, and resource allocation.\n    \n \n \n     Monitor project progress and identify potential risks or deviations from the plan.\n    \n \n \n     Identify areas for process optimization and efficiency enhancement.\n    \n \n \n     Recommend process improvements and assist in their implementation.\n    \n \n \n \n  Core Competencies \n \n \n \n \n     Flexible, Detail oriented, Customer focus, Team working, Initiative, Problem solving, Organized, Self-motivated\n    \n \n \n \n  General \n \n \n \n \n     Adopt the One GI culture of respect, integrity and accountability that contribute to an internal environment of teamwork and promote a positive brand image to our external customers.\n    \n \n \n     Incorporate a leadership mindset to your role.\n    \n \n \n     Comply with One GI procedures, policies, and regulations relevant to your role.\n    \n \n \n     Successfully completes all One GI training requirements (i.e. OSHA, HIPAA, HealthStream, compliance, etc.)\n    \n \n \n     Responsible for compliance with all regulatory requirements and/or guidelines. These requirements/guidelines include, but are not limited to: OSHA, HIPAA, Federal Fraud and Abuse laws.\n    \n \n \n     Computer skills good working knowledge of MS office.\n    \n \n \n     Ability to communicate effectively with others, both verbally and in writing.\n    \n \n \n     Proven ability to manage time, meet deadlines and prioritize.\n    \n \n \n     Able to maintain standards and professionalism during periods of fluctuating workloads.\n    \n \n \n     Provide professional service to direct customers of One GI in all interactions.\n    \n \n \n     Build effective working relationships with other team members.\n    \n \n \n     Manage daily tasks to ensure business needs are consistently met.\n    \n \n \n  Education and Qualifications \n \n \n \n \n     High School Diploma or equivalent required.\n    \n \n \n     A bachelor\u2019s degree in business or related field or an MBA required.\n    \n \n \n     Proficiency in requirement gathering techniques, process modeling, and documentation required.\n    \n \n \n     Familiarity with project management methodologies and software development lifecycle required.\n    \n \n \n     Advanced technical skills with SQL and database management required.\n    \n \n \n     Certification in Business Analysis (e.g., CBAP, CCBA) is advantageous.\n    \n \n \n \n  Physical Demands \n \n \n   The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. While performing the duties of this job, the employee is regularly required to speak and hear. \n  \n \n \n  Understand/comprehend English as well as read/follow written English instructions.\n  \n \n \n  To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed above are representative of the knowledge, skill and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. \n \n \n \n  Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice. \n \n \n \n  Accommodations \n \n \n  Reasonable accommodations will be made to enable a qualified individual with a disability to perform the non-essential or essential functions of this job. All accommodations will be investigated on an individual basis with the needs of the department and current staff resources considered. Accommodations will not be made that compromise the safety and health of any associate.", "cleaned_desc": "", "techs": ""}, "81ea478b64586516": {"terms": ["data analyst"], "salary_min": 40.0, "salary_max": 100.0, "title": "ServiceNow Business Analyst", "company": "Synovize", "desc": "Job Description: \n Synovize, a leading provider of enterprise digital transformation services, is seeking a talented ServiceNow Business Analyst to join our team. As a ServiceNow Business Analyst, you will be responsible for working with clients to understand their business requirements and translating them into technical solutions on the ServiceNow platform. \n Responsibilities: \n \n Work with clients to understand their business requirements and translate them into technical solutions on the ServiceNow platform \n Develop and maintain business requirements documentation \n Collaborate with developers to ensure that technical solutions meet business requirements \n Develop and deliver training to users on ServiceNow functionality \n Ensure that ServiceNow solutions are properly documented and supported \n Stay up to date with the latest developments in ServiceNow, ITIL, ITSM, ITOM, GRC, SPM, and CMDB, and share knowledge with the team \n \n Requirements: \n \n Bachelor's degree in Business, Computer Science, Information Technology, or related field \n Minimum of 2 years of experience as a ServiceNow Business Analyst \n Experience working with clients to understand their business requirements and translate them into technical solutions on the ServiceNow platform \n Strong understanding of ServiceNow architecture and development best practices \n Experience with ServiceNow modules such as Incident Management, Change Management, Service Catalog, CMDB, and Asset Management \n Strong analytical and problem-solving skills \n Excellent communication skills, both verbal and written \n Ability to work independently and as part of a team \n ServiceNow Certified System Administrator certification is a plus \n \n We are willing to consider candidates with fewer years of experience if they possess strong knowledge of ServiceNow and ITIL, ITSM, ITOM, GRC, SPM, and CMDB. \n If you are passionate about ServiceNow and want to work with a dynamic team of experts, we encourage you to apply today! \n Job Types:  Full-time, Part-time, Contract \n Salary:  $60.00 - $100.00 per hour \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Flexible schedule \n Health insurance \n Paid time off \n Vision insurance \n \n Compensation package: \n \n 1099 contract \n \n Schedule: \n \n 4 hour shift \n 8 hour shift \n Choose your own hours \n \n Work Location:  Remote \n Job Types: Contract, Permanent, Full-time \n Pay: $40.00 - $100.00 per hour \n Benefits: \n \n 401(k) \n 401(k) 4% Match \n 401(k) matching \n Dental insurance \n Flexible spending account \n Health insurance \n Health savings account \n Life insurance \n Vision insurance \n \n Compensation package: \n \n 1099 contract \n \n Experience level: \n \n 10 years \n 11+ years \n 1 year \n 2 years \n 3 years \n 4 years \n 5 years \n 6 years \n 7 years \n 8 years \n 9 years \n No experience needed \n Under 1 year \n \n Schedule: \n \n 4 hour shift \n 8 hour shift \n Choose your own hours \n \n Application Question(s): \n \n Do you have any ServiceNow Certifications? If so, were they paid out of pocket? \n \n Experience: \n \n ServiceNow: 1 year (Preferred) \n \n Security clearance: \n \n Secret (Preferred) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "bfb99ee056cd101b": {"terms": ["data analyst"], "salary_min": null, "salary_max": null, "title": "Data Visualization", "company": "JPMorgan Chase & Co", "desc": "JOB DESCRIPTION \n  DESCRIPTION: \n  Duties: Support lines of business or business units focused BI reporting and dashboards. Drive the set up and production of dashboards measuring KPIs for the business units. Work with engineers and data scientists to turn insights into self-service dashboards or data products. Build clean, actionable dashboards. Query Salesforce data and merge information from diverse data sources to create rich datasets that enable better decision-making. Evangelize the insights through storytelling. Create easy-to-consume media that inspires into action anyone from senior executives to fellow analysts. Drive automation of new and existing processes. Telecommuting is permitted up to 40% of the week. \n  QUALIFICATIONS: \n  Minimum education and experience required: Bachelor\u2019s degree in Electrical Engineering, Electronics Engineering, Computer Engineering, Computer Science, Information Systems, or related field of study plus 5 years of experience in the job offered or as Data Visualization, Data Analysts, Programmer, or related occupation. The employer will alternatively accept a Master\u2019s degree in Electrical Engineering, Electronics Engineering, Computer Engineering, Computer Science, Information Systems, or related field of study plus 3 years of experience in the job offered or as Data Visualization, Data Analysts, Programmer, or related occupation. \n  Skills Required: Requires experience in the following: SQL; Data Visualization such as Tableau or Power BI; ETL or Data Wrangling tool such as Alteryx; Database or Cloud systems such as MS Azure or SQL Server; Python; and Advanced Excel such as pivot table, lookup, or indexing. \n  Job Location: 8181 Communications Parkway, Plano, TX 75024. Telecommuting permitted up to 40% of the week. \n ABOUT US \n  Chase is a leading financial services firm, helping nearly half of America\u2019s households and small businesses achieve their financial goals through a broad range of financial products. Our mission is to create engaged, lifelong relationships and put our customers at the heart of everything we do. We also help small businesses, nonprofits and cities grow, delivering solutions to solve all their financial needs. \n  We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants\u2019 and employees\u2019 religious practices and beliefs, as well as any mental health or physical disability needs. \n  We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, discretionary incentive compensation which may be awarded in recognition of individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process. \n \n  Equal Opportunity Employer/Disability/Veterans \n \n \n \n ABOUT THE TEAM \n \n  Our Consumer & Community Banking division serves our Chase customers through a range of financial services, including personal banking, credit cards, mortgages, auto financing, investment advice, small business loans and payment processing. We\u2019re proud to lead the U.S. in credit card sales and deposit growth and have the most-used digital solutions \u2013 all while ranking first in customer satisfaction.", "cleaned_desc": "  QUALIFICATIONS: \n  Minimum education and experience required: Bachelor\u2019s degree in Electrical Engineering, Electronics Engineering, Computer Engineering, Computer Science, Information Systems, or related field of study plus 5 years of experience in the job offered or as Data Visualization, Data Analysts, Programmer, or related occupation. The employer will alternatively accept a Master\u2019s degree in Electrical Engineering, Electronics Engineering, Computer Engineering, Computer Science, Information Systems, or related field of study plus 3 years of experience in the job offered or as Data Visualization, Data Analysts, Programmer, or related occupation. \n  Skills Required: Requires experience in the following: SQL; Data Visualization such as Tableau or Power BI; ETL or Data Wrangling tool such as Alteryx; Database or Cloud systems such as MS Azure or SQL Server; Python; and Advanced Excel such as pivot table, lookup, or indexing. ", "techs": ["sql", "tableau", "power bi", "alteryx", "ms azure", "sql server", "python"]}, "ef460f32bcf6fc17": {"terms": ["data analyst"], "salary_min": 55.0, "salary_max": 60.0, "title": "Centura Business Analyst", "company": "ANB Sourcing LLC", "desc": "Centura Business Analyst \n 100% REMOTE Job \n Long term contract. \n Note : Need only visa independent W2 consultant. \n Skills and Experience Required: \n Required \n \n Excellent communication skills \u2013 written, spoken, presentation and listening with ability to explain and interpret complex issues clearly. \n Experience with Centura 6.2 or 7.2 \n Possess the ability to document and communicate complex process flows. \n Proven experience in understanding the scalability of a growing business and implementing changes to deliver award-winning customer support solutions in a dynamic high growth business. \n Able to clearly articulate and effectively write business requirements. \n Write use cases or specifications for changes. \n Able to document processes, road maps, and use cases. \n Define and create test conditions and plans. \n \n Desired: \n \n Experience with Gupta SQL \n \n Job Type: Contract \n Salary: $55.00 - $60.00 per hour \n Schedule: \n \n 8 hour shift \n \n Application Question(s): \n \n Current Location & Visa Status: \n \n Experience: \n \n Centura Business Analyst: 3 years (Required) \n \n Work Location: Remote", "cleaned_desc": " \n Excellent communication skills \u2013 written, spoken, presentation and listening with ability to explain and interpret complex issues clearly. \n Experience with Centura 6.2 or 7.2 \n Possess the ability to document and communicate complex process flows. \n Proven experience in understanding the scalability of a growing business and implementing changes to deliver award-winning customer support solutions in a dynamic high growth business. \n Able to clearly articulate and effectively write business requirements. ", "techs": ["centura 6.2", "centura 7.2"]}, "40bf4384b407f9b0": {"terms": ["data analyst"], "salary_min": 59900.637, "salary_max": 75847.555, "title": "Business Analyst - Remote", "company": "Sharecare", "desc": "Job Description:\n  \n \n   Sharecare is the digital health company that helps people manage all their health in one place. The Sharecare platform provides each person \u2013 no matter where they are in their health journey \u2013 with a comprehensive and personalized health profile, where they can dynamically and easily connect to the information, evidence-based programs and health professionals they need to live their healthiest, happiest and most productive life. With award-winning and innovative frictionless technologies, scientifically validated clinical protocols and best-in-class coaching tools, Sharecare helps providers, employers and health plans effectively scale outcomes-based health and wellness solutions across their entire populations. We are always looking for people that value the opportunity to work hard, have fun on the job, and make a difference in the lives of others through their work every day!\n  \n \n \n   Job Summary:\n  \n \n   The Business Analyst will be responsible for compiling, analyzing and visualizing market & competitive intelligence data across several data sources for a fast-growing health and wellness company. Additionally, the analyst will be responsible for creating reports, communicating results, developing sales strategies, and supporting the sales staff to execute on strategy.\n  \n \n   In addition to very strong technical skills, the ideal candidate has superb business process analysis and interpersonal skills. The ability to extract and analyze data, patterns, and related trends is needed, with the subsequent ability to synthesize the data and market intelligence research into clear concise reports for senior business decision-makers and stakeholders.\n  \n \n \n   Essential Job Functions:\n  \n \n Collect and analyze various sources of market & competitive intelligence data relevant to our industry \n Create models to estimate market opportunity for various products \n Analyze customer segments and develop go to market strategies \n Complete projects that require data mining, entry, organization, analysis, and presentation \n Prepare reports in both Excel and PowerPoint that clearly and succinctly summarize findings, key takeaways, and recommendations \n Develop dashboards and monthly and quarterly reports to enhance operational efficiency \n Support sales team with reporting, ad-hoc market analysis, and general meeting preparation \n \n \n \n   Specific Skills/ Attributes:\n  \n \n Strong proficiency in Excel and PowerPoint \n Working familiarity with data analytics tools such as Salesforce, Power BI, QLIK and other proprietary systems \n Self-starter who can be productive with minimal direction \n Ability to work in a fast-paced, technical, cross-functional environment \n Ability to focus on solutions, dive into projects, quickly identify data drivers and key strategic implications for the business \n Ability to quickly identify high-level takeaways from projects that have the most impact on strategic initiatives \n Excellent visual design sense regarding clear and accurate presentation of data. \n \n \n \n   Qualifications:\n  \n \n Bachelor\u2019s Degree in Business Administration, Economics or Finance is preferred \n Statistics, data analysis, data-driven computation are all relevant areas of study \n Minimum 2 years' experience in relevant work experience in a Corporate Finance, Marketing or Analytics role, particularly in Health Benefits, Wellness, Digital Media, or related field is preferred \n Established PC skills and demonstrated proficiency in the MS Office Suite products. \n \n \n \n   Sharecare and its subsidiaries are Equal Opportunity Employers and E-Verify users. Qualified applicants will receive consideration for employment without regard to race, color, sex, national origin, sexual orientation, gender identity, religion, age, equal pay, disability, genetic information, protected veteran status, or other status protected under applicable law.", "cleaned_desc": "   Specific Skills/ Attributes:\n  \n \n Strong proficiency in Excel and PowerPoint \n Working familiarity with data analytics tools such as Salesforce, Power BI, QLIK and other proprietary systems \n Self-starter who can be productive with minimal direction \n Ability to work in a fast-paced, technical, cross-functional environment \n Ability to focus on solutions, dive into projects, quickly identify data drivers and key strategic implications for the business \n Ability to quickly identify high-level takeaways from projects that have the most impact on strategic initiatives \n Excellent visual design sense regarding clear and accurate presentation of data. ", "techs": ["excel", "powerpoint", "salesforce", "power bi", "qlik"]}, "c17017680d8b8543": {"terms": ["data analyst"], "salary_min": 87359.27, "salary_max": 110616.305, "title": "Business Analyst (1099 Contractor)", "company": "BLOCKSKYE INC", "desc": "Description: \n   About Blockskye: \n  Blockskye provides next-generation inventory booking, payment, and dynamic expense solutions for the travel and entertainment industries using blockchain. We connect suppliers and corporate buyers with blockchain technology thereby achieving greater transparency, trust, and efficiency in transaction, inventory, and booking management. Our solution is governed by industry stakeholders with a focus on supplier and corporate buyer participation. This inclusive approach has enabled us to deploy blockchain fairly quickly within the industry. We believe in inter-enterprise, real-time accounting integrations as a foundation for distributed ledger technology, private, and public blockchains. \n  Job Summary: \n  We are seeking a motivated and detail-oriented Business Analyst to join our dynamic team. The Business Analyst will work closely with internal and external stakeholders to gather, analyze, and document business requirements, as well as assist in the implementation and monitoring of various business processes. The ideal candidate will possess strong analytical skills, excellent communication abilities, and a desire to learn and grow.  The position will last roughly 3 months, with the potential for more long-term employment. \n  Responsibilities: \n \n  Collaborate with the Product team to gather and document business requirements from stakeholders. \n  Conduct data analysis and perform research to support business decision-making processes. \n  Assist in the development and documentation of business processes, workflows, and system specifications. \n  Participate in process improvement initiatives, identifying areas for optimization and proposing solutions. \n  Help facilitate communication between different stakeholders, including business users, IT teams, and management. \n  Support the testing and implementation of new business systems or enhancements, ensuring they meet the specified requirements. \n  Prepare reports, presentations, and documentation for various stakeholders, summarizing findings and recommendations. \n  Assist Product team with research initiatives as needed. \n  Requirements: \n   Qualifications: \n \n  Bachelor's degree or equivalent experience. \n  Strong analytical skills with the ability to gather, interpret, and analyze complex data. \n  Excellent written and verbal communication skills, including the ability to effectively present information to both technical and non-technical audiences. \n  Proficiency in using Atlassian products (JIRA). \n  Detail-oriented with a strong focus on accuracy and quality of work. \n  Ability to work independently as well as collaboratively in a team environment. \n  Strong organizational and time management skills, with the ability to prioritize tasks effectively. \n \n  Bonus Qualifications: \n \n  SAFe (Scale Agile Framework) knowledge \n  Travel industry (airlines, hotels, rental-cars, etc) or related knowledge/experience \n  Payment / Blockchain services knowledge/experience \n  Working knowledge of APIs, web services, webhooks, system architecture and user management.", "cleaned_desc": "  Bachelor's degree or equivalent experience. \n  Strong analytical skills with the ability to gather, interpret, and analyze complex data. \n  Excellent written and verbal communication skills, including the ability to effectively present information to both technical and non-technical audiences. \n  Proficiency in using Atlassian products (JIRA). \n  Detail-oriented with a strong focus on accuracy and quality of work. \n  Ability to work independently as well as collaboratively in a team environment. ", "techs": ["atlassian products (jira)"]}, "24faa416a2416f21": {"terms": ["data analyst"], "salary_min": 65000.0, "salary_max": -1.0, "title": "Business Analyst III (VA)", "company": "MPIRE Technology Group, Inc.", "desc": "MPIRE Technology Group, Inc. is seeking a Business Analyst who is responsible for the completion of assigned technical projects within budgetary and scheduling guidelines, as well as instructing, directing, and checking the work of other project technical staff. \n Responsibilities will include: \n \n Able to write and review a broad range of technical documentation, especially technical specifications, and design documents. \n Leads a technical staff assigned for the duration of a project or may function as ongoing lead for technical staff associated with one or more technical areas. \n Review and improve customer acceptance test plans. \n Work with business users to analyze, document, and refine business processes. \n Produce detailed requirements, specifications, user-stories to hand off to developers. \n Organizing requirements/discovery work-sessions. \n Document use cases and scenarios. \n Performs all functional duties with assistance of senior personnel. \n \n Requirements \n \n A minimum of Five (5) years\u2019 experience in Business Analyst or related field, preferably in the area of software application /or related field. \n Experience analyzing system needs, systems development and system process analysis, design, and re-engineering. \n Knowledge of and experience in software development and testing, preferably using different methodologies and lifecycles (e.g. Waterfall, Agile, etc); \n Experience with project management methodologies/disciplines, especially in the areas of scope, cost, and schedule management. \n Experience leading small teams and/or technical projects in the successful completion of assigned goals/objectives. \n Perform all functional duties with the assistance of senior personnel. \n Experience training junior personnel. \n Excellent communication skills. \n Ability to obtain a Public Trust Clearance. \n \n Experience:  Intermediate Level (5+ years) \n Education:  BA/BS in Computer Science Software Engineering, Computer Science, or related discipline. \n About Us: \n MPIRE Technology Group Inc. (MTG) is Small Business that was founded in Virginia. The company offers information technology services consulting and systems integration. Our core offerings include: Software Development, IT/Engineering Support and Cyber Security. MPIRE Technology Group\u2019s technical staff has extensive experience managing and executing the full life cycle of IT infrastructure and development projects. Our teams work alongside their clients helping them to achieve their specific objectives. Our clients continue to use our services because of our high quality of work and our company values. \n Our Benefits: \n \n Health insurance \n Dental insurance \n Vision insurance \n Retirement plan \n Paid time off \n Professional development assistance \n \n MPIRE Technology Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status. \n We are not currently working with 3rdparties. \n We are not currently providing sponsorship. \n Please note all work is done on-site. \n . \n Job Type: Full-time \n Pay: From $65,000.00 per year \n Benefits: \n \n 401(k) \n Dental insurance \n Flexible schedule \n Health insurance \n Paid time off \n Vision insurance \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n Business analysis: 5 years (Preferred) \n IT project management: 1 year (Preferred) \n test plans: 1 year (Preferred) \n Business requirements: 1 year (Preferred) \n Technical writing: 1 year (Preferred) \n User acceptance testing: 1 year (Preferred) \n SDLC: 1 year (Preferred) \n \n License/Certification: \n \n Certified Scrum Master (Preferred) \n \n Work Location: Remote", "cleaned_desc": " A minimum of Five (5) years\u2019 experience in Business Analyst or related field, preferably in the area of software application /or related field. \n Experience analyzing system needs, systems development and system process analysis, design, and re-engineering. \n Knowledge of and experience in software development and testing, preferably using different methodologies and lifecycles (e.g. Waterfall, Agile, etc); \n Experience with project management methodologies/disciplines, especially in the areas of scope, cost, and schedule management. \n Experience leading small teams and/or technical projects in the successful completion of assigned goals/objectives. \n Perform all functional duties with the assistance of senior personnel. \n Experience training junior personnel. \n Excellent communication skills. \n Ability to obtain a Public Trust Clearance. \n \n Experience:  Intermediate Level (5+ years) \n Education:  BA/BS in Computer Science Software Engineering, Computer Science, or related discipline. \n About Us: \n MPIRE Technology Group Inc. (MTG) is Small Business that was founded in Virginia. The company offers information technology services consulting and systems integration. Our core offerings include: Software Development, IT/Engineering Support and Cyber Security. MPIRE Technology Group\u2019s technical staff has extensive experience managing and executing the full life cycle of IT infrastructure and development projects. Our teams work alongside their clients helping them to achieve their specific objectives. Our clients continue to use our services because of our high quality of work and our company values. ", "techs": ["business analyst", "software application", "systems development", "system process analysis", "design", "re-engineering", "software development", "testing", "methodologies", "lifecycles", "waterfall", "agile", "project management", "scope management", "cost management", "schedule management", "small teams", "technical projects", "training", "communication skills", "public trust clearance", "intermediate level", "computer science software engineering", "it/engineering support", "cyber security", "information technology services consulting", "systems integration."]}, "ef3b9dd71ed34f78": {"terms": ["data analyst"], "salary_min": null, "salary_max": null, "title": "Data Governance Analyst - II", "company": "Freedom Mortgage", "desc": "Key Responsibilities: \n \n  Collaborate with cross-functional teams to assess their data governance needs. \n  Develop and implement a federated data governance framework that aligns with organizational objectives. \n  Establish and enforce data governance policies and standards across different business units. \n  Organizes, coordinates and assists cross-functional teams in planning, development, and execution of Data Governance oriented business processes at the operational level. \n  Provide guidance and support to teams in implementing data governance best practices. \n  Monitor data quality, privacy, and security compliance across the organization. \n  Conduct regular audits and assessments to identify data governance issues and opportunities for improvement. \n  Develop and deliver training programs on data governance principles and procedures. \n  Serve as a subject matter expert on data governance matters, providing guidance to teams as needed. \n  Builds enterprise dashboards and reporting to ensure proper communicate of the Data Governance program performance. \n  Act as a liaison between teams to ensure consistent data governance practices. \n  Stay informed about industry trends and regulations related to data governance. \n \n \n  Qualifications: \n \n \n  Bachelor's degree in a related field (e.g., Data Management, Information Technology, Business, or a related discipline). \n  3-5 years of experience in a Data Governance, Data Management or data centric role. \n  Strong understanding of data governance principles, standards, and best practices. \n  Excellent communication and interpersonal skills to work effectively with various teams. \n  Strong problem-solving and analytical abilities. \n  Ability to perform root cause analysis and make recommendations for the remediation of data governance and quality issues. \n  Ability to adapt to changing environments and priorities. \n  Ability to extract and analyze data via SQL. \n  Self-motivated and able to work both independently and as part of a team. \n  Highly proficient in data profiling techniques and tools. \n  Experience in working with cross-functional teams in a large organization. \n  Certification in data management or data governance (e.g., CDMP, DGSP, CISM) is a plus. \n  Familiarity with data governance tools and software. \n  Project management skills. \n \n \n  Remote", "cleaned_desc": "  Strong understanding of data governance principles, standards, and best practices. \n  Excellent communication and interpersonal skills to work effectively with various teams. \n  Strong problem-solving and analytical abilities. \n  Ability to perform root cause analysis and make recommendations for the remediation of data governance and quality issues. \n  Ability to adapt to changing environments and priorities. \n  Ability to extract and analyze data via SQL. \n  Self-motivated and able to work both independently and as part of a team.    Highly proficient in data profiling techniques and tools. \n  Experience in working with cross-functional teams in a large organization. \n  Certification in data management or data governance (e.g., CDMP, DGSP, CISM) is a plus. \n  Familiarity with data governance tools and software. \n  Project management skills. \n \n ", "techs": ["sql", "data profiling techniques and tools", "data governance tools and software", "project management"]}, "24be6d678d0adcac": {"terms": ["data analyst"], "salary_min": 68640.0, "salary_max": 124800.0, "title": "Senior Qualitative Research and/or Evaluation Analyst", "company": "Elite Research, LLC", "desc": "JOB DESCRIPTION \n TITLE: Senior Qualitative Research and/or Evaluation Analyst LOCATION: Irving, Texas/Houston, Texas/Remote POSITION TYPE: Analyst ORGANIZATIONAL RELATIONSHIPS: Reports to Director of Qualitative MERL HOURS/SCHEDULE: Permanent, Full- or Part-Time SALARY DETAILS: Commensurate with experience; Levels I, II, III, IV; Senior Levels I, II, III, IV \n JOB SUMMARY \n The Research and Evaluation MERL team at Elite Research collaborates with government, community-based organizations, philanthropy, non-governmental organizations, and academic partners to conduct small, moderate, and large-scale research and evaluations of programs and services, leverage data for action, and support the development and improvement of community-based programs, initiatives, and services. With numerous distinct contracts and grants at any one time, the Senior Analyst works with a variety of internal and external collaborators, supports small to large evaluation projects and research studies, manages multiple tasks simultaneously, amid multiple shifting priorities. These projects range from evaluations of national programs to statewide surveys and academic research, to robust government-funded evaluation studies of public health interventions, to local program evaluations carried out in collaboration with community-based organizations. \n The Senior Qualitative Research/Evaluation Analyst is responsible for supporting qualitative research and evaluation projects under the direction of the Director of Qualitative MERL and the Consultants. The analyst works closely with the Director of Qualitative MERL, other team members, and subject matter experts (SMEs) using a variety of research techniques to assist clients in meeting their research objectives and uncovering actionable insights from both academic and nonacademic types of qualitative data. Though not directly leading projects, the Senior Analyst will work alongside Consultants in meeting clients and providing consultations relative to qualitative or evaluation needs. In doing so, the Senior Analyst acquires a thorough understanding project needs and produces highly effective actionable insights that make a real difference in client programs and organizations. The Senior Analyst moderates qualitative studies, manages projects, and prepares/reviews deliverables for qualitative research and evaluation projects, along with contributing to creative proposals. The Senior Analyst also trains team members (as needed) on qualitative research and evaluation methods, design, data coding and analysis, and setup and management of project activities. \n DUTIES & RESPONSIBILITIES \n Key Responsibilities (include, but are not limited to) \n \u25aa Advocate for and contribute to developing a learning and growth mindset within the team. \u25aa Deepen existing/future client/staff relationships to generate and create incremental business. \u25aa Design a qualitative research strategy from planning to execution that is supportive of our mission. \u25aa Develop insightful proposals with innovative qualitative solutions to client problems. \u25aa Understand and relay information that would be beneficial to client's business or programs via interpreting, analyzing and synthesizing research data into meaningful and insightful qualitative reports/presentations. \u25aa Collect and analyze data with rigor and integrity and curate insights that are concise and appropriately accessible to other audiences. \u25aa Coordinate and collaborate with global (internal and external) research teams during qualitative project execution (in-person or remote) to ensure quality of results and communication delivered to clients \u25aa Contribute to and develop proposals with qualitative or mixed methods solutions to client problems. \u25aa Demonstrate flexibility and creativity in working with clients and in addressing research challenges, including showing adaptability with regard to working with various personalities, changes to project schedules, budgets, project needs and objectives, participant recruitment, data collection, and results. \n \u25aa Design and conduct training on qualitative research and evaluation methods for staff and clients. \u25aa Design or review data collection instruments that align with project objectives. \u25aa Contribute to marketing communications (e.g., blog posts, articles, webinars, and conference papers) specific to qualitative research methodologies. \n \u25aa Maintain highest level of data security and client confidentiality. \u25aa Support Elite Research\u2019s goal of empowering researchers through education and communication by providing clients with clear and specific guidance and feedback. \u25aa Other responsibilities as may be assigned. \n EXPERIENCE & QUALIFICATIONS \n \u25aa Master\u2019s degree or Ph.D. in a relevant discipline (sociology, anthropology, political science, psychology, etc.). \u25aa 3 to 5 years of professional experience in a research or evaluation role with a qualitative focus, with at least \n 2 years of experience in a client service capacity. \u25aa Ability to analyze information, interpret, summarize data, communicate and present findings in ways easily understandable to decision-makers within the organization and externally. \u25aa Ability to work creatively and think commercially. Have a flexible, innovative and analytical working style. \u25aa Experience working with a variety of public, private, nonprofit and grassroots organizational structures, governing bodies, including boards of directors, advisory boards, etc. \u25aa Strong hands-on experience and working knowledge of managing the qualitative research cycle. \u25aa Knowledge and experience of program evaluation principles, theories, concepts and practices, research and evaluation methods and tools for observing and interpreting patterns. \u25aa Knowledge and experience of using evaluation and community-based research to inform program development, including Participatory Action Research and Cultural Competency. \u25aa Ability to remaining focused on goals and objectives, meet deadlines and be persistent. \u25aa Strong interpersonal skills and the ability to communicate clearly with others (verbal & written), including with internal team members and clients. \u25aa Solid project management of multiple projects, delegation and planning skills, high level of organization, attention to detail, self-starter. \u25aa Strong proficiency and understanding of various qualitative analysis tools (NVIVO, Dedoose, ATLAS.ti, etc.). \u25aa Strong proficiency with MS Word, Excel, and PowerPoint. \u25aa Excellent written and oral communication skills, and strong storytelling skills. \n PHYSICAL DEMANDS OF THE JOB \n The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. \n While performing the duties of this job, the employee is occasionally required to stand; walk; sit; use hands to finger, handle, or feel objects, tools, or controls; climb stairs; talk or hear. The employee must have the ability to operate a personal computer and occasionally lift and/or move up to 25 pounds. Specific vision abilities required by the job include ability to distinguish the nature of objects using the eye. \n WORK ENVIRONMENT \n Employees are responsible for performing their duties in an environment that is free from discrimination, intimidation, coercion, or harassment, including sexual harassment. Work is performed primarily indoors in an office. The noise level in the work environment is low to moderate. The employee may be required to travel. \n SAFETY \n Employees are responsible to assist in the creation of a culture of safety and environmental protection by performing work safely in accordance with departmental safety procedures as well as operate equipment safely and report any unsafe work conditions or practice to their supervisor. \n CONCLUSION \n This description is intended to convey information essential to understanding the scope of the position and it is not intended to be an exhaustive list of skills, efforts, duties, responsibilities, or working conditions associated with the position. The job description does not constitute an employment agreement between the employer and employee and is subject to change by the employer as the needs of the employer and the requirements of the job change. \n Job Types: Part-time, Full-time \n Pay: $68,640.00 - $124,800.00 per year \n Benefits: \n \n Dental insurance \n Flexible schedule \n Health insurance \n Life insurance \n Paid time off \n Retirement plan \n Vision insurance \n \n Work Location: Remote", "cleaned_desc": " Key Responsibilities (include, but are not limited to) \n \u25aa Advocate for and contribute to developing a learning and growth mindset within the team. \u25aa Deepen existing/future client/staff relationships to generate and create incremental business. \u25aa Design a qualitative research strategy from planning to execution that is supportive of our mission. \u25aa Develop insightful proposals with innovative qualitative solutions to client problems. \u25aa Understand and relay information that would be beneficial to client's business or programs via interpreting, analyzing and synthesizing research data into meaningful and insightful qualitative reports/presentations. \u25aa Collect and analyze data with rigor and integrity and curate insights that are concise and appropriately accessible to other audiences. \u25aa Coordinate and collaborate with global (internal and external) research teams during qualitative project execution (in-person or remote) to ensure quality of results and communication delivered to clients \u25aa Contribute to and develop proposals with qualitative or mixed methods solutions to client problems. \u25aa Demonstrate flexibility and creativity in working with clients and in addressing research challenges, including showing adaptability with regard to working with various personalities, changes to project schedules, budgets, project needs and objectives, participant recruitment, data collection, and results. \n \u25aa Design and conduct training on qualitative research and evaluation methods for staff and clients. \u25aa Design or review data collection instruments that align with project objectives. \u25aa Contribute to marketing communications (e.g., blog posts, articles, webinars, and conference papers) specific to qualitative research methodologies. \n \u25aa Maintain highest level of data security and client confidentiality. \u25aa Support Elite Research\u2019s goal of empowering researchers through education and communication by providing clients with clear and specific guidance and feedback. \u25aa Other responsibilities as may be assigned. \n EXPERIENCE & QUALIFICATIONS \n \u25aa Master\u2019s degree or Ph.D. in a relevant discipline (sociology, anthropology, political science, psychology, etc.). \u25aa 3 to 5 years of professional experience in a research or evaluation role with a qualitative focus, with at least   2 years of experience in a client service capacity. \u25aa Ability to analyze information, interpret, summarize data, communicate and present findings in ways easily understandable to decision-makers within the organization and externally. \u25aa Ability to work creatively and think commercially. Have a flexible, innovative and analytical working style. \u25aa Experience working with a variety of public, private, nonprofit and grassroots organizational structures, governing bodies, including boards of directors, advisory boards, etc. \u25aa Strong hands-on experience and working knowledge of managing the qualitative research cycle. \u25aa Knowledge and experience of program evaluation principles, theories, concepts and practices, research and evaluation methods and tools for observing and interpreting patterns. \u25aa Knowledge and experience of using evaluation and community-based research to inform program development, including Participatory Action Research and Cultural Competency. \u25aa Ability to remaining focused on goals and objectives, meet deadlines and be persistent. \u25aa Strong interpersonal skills and the ability to communicate clearly with others (verbal & written), including with internal team members and clients. \u25aa Solid project management of multiple projects, delegation and planning skills, high level of organization, attention to detail, self-starter. \u25aa Strong proficiency and understanding of various qualitative analysis tools (NVIVO, Dedoose, ATLAS.ti, etc.). \u25aa Strong proficiency with MS Word, Excel, and PowerPoint. \u25aa Excellent written and oral communication skills, and strong storytelling skills. \n PHYSICAL DEMANDS OF THE JOB \n The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. \n While performing the duties of this job, the employee is occasionally required to stand; walk; sit; use hands to finger, handle, or feel objects, tools, or controls; climb stairs; talk or hear. The employee must have the ability to operate a personal computer and occasionally lift and/or move up to 25 pounds. Specific vision abilities required by the job include ability to distinguish the nature of objects using the eye. \n WORK ENVIRONMENT \n Employees are responsible for performing their duties in an environment that is free from discrimination, intimidation, coercion, or harassment, including sexual harassment. Work is performed primarily indoors in an office. The noise level in the work environment is low to moderate. The employee may be required to travel. ", "techs": ["nvivo", "dedoose", "atlas.ti", "ms word", "excel", "powerpoint"]}, "f439e41d7e543174": {"terms": ["data analyst"], "salary_min": 82961.31, "salary_max": 105047.516, "title": "Technical Business Analyst", "company": "VXForward", "desc": "VXForward has a great opportunity for a Technical Business Analyst - 100% Remote with one of our clients.\n  \n \n Roles and Responsibilities: \n \n \n Experienced technical requirements BA needed to support reporting. \n Need the ability to take business KPIs and create tech requirements for developers. \n \n Required Skills: \n \n \n History in health claim data analytics \n SQL. \n Technical requirements gathering \n \n Desired Skills: \n \n \n Snowflake, \n ThoughtSpot \n PowerBI \n \n \n This is a remote position.", "cleaned_desc": "", "techs": ""}, "b8e36273e72201f4": {"terms": ["data analyst"], "salary_min": 70214.0, "salary_max": 105320.0, "title": "BUSINESS ANALYST - INNOVATION & IMPROVEMENT (REMOTE)", "company": "OCHIN", "desc": "Description: \n   MAKE A DIFFERENCE AT OCHIN \n  OCHIN is a rapidly growing national nonprofit health IT organization with two decades of experience transforming health care delivery to drive health equity. We are hiring for a number of new positions to meet increasing demand. When you choose to join OCHIN, you have the opportunity to continuously grow your skills and do meaningful work to help fulfill our mission. \n  OCHIN provides leading-edge technology, data analytics, research, and support services to nearly 1,000 community health care sites, reaching nearly 6 million patients nationally. We believe that every individual, no matter their race, ethnicity, background, or zip code, should have fair opportunity to achieve their full health potential. Our work addresses differences in health that are systemic, avoidable, and unjust. We partner, learn, innovate, and advocate, in order to close the gap in health for individuals and communities negatively impacted by racism or other structural inequities. \n  At OCHIN, we value the unique perspectives and experiences of every individual and work hard to maintain a culture of belonging. \n  Founded in Oregon in 2000, OCHIN employs a growing virtual workforce of more than 1,000 diverse professionals, working remotely across 48 states. We offer a generous compensation package and are committed to supporting our employees\u2019 entire well-being by fostering a healthy work-life balance and equitable opportunity for professional advancement. We are curious, collaborative learners who strive to live our values everyday: leadership, collaboration, excellence, innovation, inclusion, and stewardship. OCHIN is excited to support our continued national expansion and the increasing demand for our innovative tools and services by welcoming new talent to our growing team. \n  Position Overview \n  The  Business Analyst  in the Operational Excellence & Business Solutions department support OCHIN\u2019s mission by ensuring the efficient and successful delivery of integrated products and services from OCHIN\u2019s preferred technology partners to our member organizations. Business Analysts gather and analyze data to support potential integrations, identify opportunities to improve department operations, and assist with project management for selected projects. The Business Analyst will manage and drive coordination across interdisciplinary teams. They will intake new integration requests, collect business and technical requirements, and provide comparative assessments to ensure OCHIN selects and supports a best in-class list of preferred technology partners. Additionally, Business Analysts will provide project management and coordination for select projects and department initiatives. \n  Essential Duties \n \n  Collaborate with interdisciplinary internal and external stakeholders to understand the vision and business value for a project \n  Schedule, coordinate, and participate in project and product meetings \n  Create and maintain detailed documentation of projects, products, and meeting decisions \n  Capture business requirements and translate into functional requirements that project team(s) can rely upon \n  Provide weekly reports to the internal and external stakeholders, as appropriate, on status of implementations currently in flight and issues / trends involved with projects \n  Meet service level expectations for responsiveness and resolution of member requests and issues \n  Ensure that all issues and risks are properly escalated and mitigated \n  Participate in process improvement efforts \n  Evaluate technology platforms to understand existing functionality and the impact of potential changes on members clinical operation \n  Create executive summaries of insights gathered through comparative assessments to inform Preferred Technology Partner selection process \n  Where needed, work with OCHIN\u2019s Procurement Team and member to select and order necessary equipment / software for vendor product(s) \n  Partner with the Business Development team through the product discovery, assessment, contracting processes \n  Research, resolve, and respond to inquiries during the deployment and aid with hand-off to operations \n  Work with technical resources to resolve any technical issues involved with projects \n  Track the progress of implementation(s) and ensure all milestones and timelines get met, quickly identifying, and escalating any risks to meeting these milestones and timelines \n  Assist with small-scale project management for selected projects, under close supervision or direction from managers \n  Other duties, as assigned \n  Requirements: \n  \n Bachelor\u2019s Degree or equivalent experience required \n  Minimum of 3 years of experience in Healthcare, Healthcare IT, Project Coordinator, or Business Analyst role \n  May be required to travel up to 10% \n  Working knowledge of Epic applications and workflows preferred \n  Experience project managing including presenting/meetings, communications, and tracking progress from beginning to end \n  Ability to work with technical resources and customers to compile what is needed to build or configure a product \n  Intermediate proficiency in project tracking tool(s) \n  Experience creating and training workflows and communicating between teams and customers. \n  Ability to create documentation tools that are usable for audiences in support of a product \n  Superb attention to detail and a rigorous focus on delivering quality output by documenting findings \n  Excellent communication skills, including the ability to speak knowledgeably with members of both the business, technology, and leadership teams \n  Strong time management and organization skills \n  Strong analytical skills and ability to synthesize and clearly communicate findings of analysis into presentations \n  Strong teamwork, interpersonal, relationship, and collaboration skills \n  Adaptable and capable of working in fast-paced environments \n  Desire to take ownership, be creative with problem solving, and pro-actively secure the objectives of the business \n \n  Base Pay Overview \n  The typical offer range for this role is minimum to midpoint ,  ($70,214-$87,767) with the midpoint representing the average pay in a national market scope for this position.  Please keep in mind that this range represents the pay range for all positions in the job grade within which this position falls. The actual salary offer will consider a wide range of factors directly relevant to this position, including, but not limited to, skills, knowledge, training, responsibility, and experience, as well as internal equity and alignment with market data. \n  Work Location and Travel Requirements \n  OCHIN is a 100% remote organization with no physical corporate office location. Employees work remotely from home and many of our positions also support our member organizations on-site for new software installations. Nationwide travel is determined based on OCHIN business needs. Please inquire during the interview process about travel requirements for this position. \n  Work from home requirements are? \n \n  Ability to work independently and efficiently from a home office environment \n  High Speed Internet Service \n  It is a requirement that employees work in a distraction free workplace \n  Travel may be required to support our member organizations on-site based on business requirements for OCHIN \n \n  We offer a comprehensive range of benefits. See our website for details: https://ochin.org/employment-openings \n  COVID-19 Vaccination Requirement \n  To keep our colleagues, members, and communities safe, OCHIN requires all employees\u2014including remote employees, contractors, interns, and new hires\u2014to be vaccinated with a COVID-19 vaccine, as supported by state and federal public health officials, as a condition of employment. All new hires are required to provide proof of full vaccination or receive approval for a medical or religious exemption before their hire date. \n  Equal Opportunity Statement \n  OCHIN is proud to be an equal opportunity employer. We are committed to building a team that represents a variety of backgrounds, perspectives, and skills for the benefit of our staff, our mission, and the communities we serve. \n  As an Equal Opportunity and Affirmative Action employer, OCHIN, Inc. does not discriminate on the basis of race, ethnicity, sex, gender identity, sexual orientation, religion, marital or civil union status, age, disability status, veteran status, or any other protected characteristics. All aspects of employment are based on merit, performance, and business needs.", "cleaned_desc": "", "techs": ""}, "0f10a9c08760b2f3": {"terms": ["data analyst"], "salary_min": 50.0, "salary_max": 65.0, "title": "Business Analyst", "company": "Pinnacle Technical Resources", "desc": "BUSINESS ANALYST - (Business Analyst \u2013 Associate / Senior Associate Level) \n \n 100% Remote \n \n   \n \n Top Skill Sets & Experiences: \n \n - ADAS  experience preferred\n   \n \n Engineering/tech background would be a plus \n Experience with defining product strategy \n Customer centricity mindset \n Effectively articulate, define and document software products \n Collaborate with technical partners to build the right solution for the customer \n Have basic level of understanding of AEB (Automatic Emergency Braking) and the ability to describe what it does so relevant info can be bundled together. \n Basic analysis functions focusing on sales data, forecasting data, vehicle volume, analyzing business inputs & outputs, pricing \n Individual in this role will have access to volume, projections by brand/model/market. \n More junior level role (Associate or Senior Associate Level \u2013 2-5 years exp) \n \n Specific project or industry experience be required?  Yes, ADAS and AEB\n   \n \n Job Description \n  We are seeking a Business Analyst with ADAS knowledge (Advanced Driver Assistance System) assist in to deliver on the client's 2023 product roadmap. The goal is to increase the Product Management competency level of the organization by embedding experienced Product Management professionals within each team who will be responsible for specific Product deliverables. At a high-level, expectations can be summarized in this way: Looking for candidates who identify the customer need and the larger business objectives that a product or feature will fulfill, articulates what success looks like for a product, and rallies a team to turn that vision into a reality.\n   \n \n Your Impact / Qualifications \n  - ADAS experience preferred\n   \n \n Engineering/tech background would be a plus \n Experience with defining product strategy \n Customer centricity mindset \n Effectively articulate, define and document software products \n Collaborate with technical partners to build the right solution for the customer \n Have basic level of understanding of AEB (Automatic Emergency Braking) and the ability to describe what it does so relevant info can be bundled together. \n Basic analysis functions focusing on sales data, forecasting data, vehicle volume, analyzing business inputs & outputs, pricing \n Individual in this role will l have access to volume, projections by brand/model/market. \n \n \n Pay Rate: $50/hr. - $65/hr. \n \n The specific compensation for this position will be determined by a number of factors, including the scope, complexity and location of the role as well as the cost of labor in the market; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. Our full-time consultants have access to benefits including medical, dental, vision as well as 401K contributions. \n \n   \n \n #LI-GN1", "cleaned_desc": "", "techs": ""}, "2befd491fdcbf7f1": {"terms": ["data analyst"], "salary_min": 82778.23, "salary_max": 104815.68, "title": "Senior Data & Reporting Analyst", "company": "ICON", "desc": "As a SDTM Visualization Analyast you will be joining the world\u2019s largest & most comprehensive clinical research organisation, powered by healthcare intelligence.\n  \n \n  What you will be doing: \n \n  The main responsibilities for the Business Intelligence Developer role include; \n \n  Supporting the clinical-study team-members in definition of requirements for, understanding of and use of the newly developed analytics platform \n  Collaborating closely with key business stakeholders to analyse their requirements  \n Using your strong programming/developer skills to create interactive dashboards and data visualisations  \n Delivering metrics and reporting tools  \n Providing consultative industry leading solutions to our clients  \n Working on multiple cross functional projects with a large, diverse operational analytics team \n \n \n  You are: \n \n \n  A solutions orientated, analytical and customer focused individual with a global business mind set and a strong background in operational excellence! \n \n  Here at ICON we want our employees to succeed and ensure that they are set up for this success through constant training, development and support. To enable success in this position you will have: \n \n \n \n  A Bachelor\u2019s degree in Maths, Statistics or Computer Science  \n Previous clinical trials industry experience \n  Programming of CDISC SDTM  \n Experience with data visualisations using tools like Spotfire, Tableau, BI (or similar tools)  \n Ability to work analytically within a problem solving environment  \n Fluency in English \n \n \n  Why ICON? \n \n  Our focus is to provide you with a comprehensive and competitive total reward package that comprises, not only an excellent level of base pay, but also a wide range of variable pay and recognition programs. In addition, our best in class employee benefits, supportive policies and wellbeing initiatives are tailored to support you and your family at all stages of your career - both now, and into the future.\n   \n  Our success depends on the knowledge, capabilities and quality of our people. That\u2019s why we are committed to developing our employees in a continuous learning culture \u2013 one where we challenge you with engaging work and where every experience adds to your professional development.\n   \n  ICON, including subsidiaries, is an equal opportunity and inclusive employer and is committed to providing a workplace free of discrimination and harassment. All qualified applicants will receive equal consideration for employment without regard to race, colour, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.\n   \n  If, because of a medical condition or disability, you need a reasonable accommodation for any part of the application process, or in order to perform the essential functions of a position, please let us know.\n   \n  Interested in the role, but unsure if you meet all of the requirements? We would encourage you to apply regardless \u2013 there\u2019s every chance you\u2019re exactly what we\u2019re looking for here at ICON whether it is for this or other roles.", "cleaned_desc": "  A Bachelor\u2019s degree in Maths, Statistics or Computer Science  \n Previous clinical trials industry experience \n  Programming of CDISC SDTM  \n Experience with data visualisations using tools like Spotfire, Tableau, BI (or similar tools)  \n Ability to work analytically within a problem solving environment  \n Fluency in English \n \n ", "techs": ["cdisc sdtm", "spotfire", "tableau", "bi"]}, "3199071c70ed947b": {"terms": ["data analyst"], "salary_min": null, "salary_max": null, "title": "Business Analyst - Continuous Improvement", "company": "Stoneridge Software", "desc": "Stoneridge Software began with an idea: How can Microsoft implementations be done better? After considering the idea and continually seeing the need for a business partner who could successfully deliver software implementations, Eric Newell, Becky Newell and Cody Marshall founded Stoneridge Software. As a 2023 Inc. Best Workplaces Honoree, member of the Microsoft Inner Circle, and award winning Microsoft Solutions Partner for Business Applications and Modern Work, we\u2019ve developed a proven process for project delivery, a laser focus on long-term support to empower our clients\u2019 success and a way to enjoy our work with a high degree of integrity. We know how to use tenacity to get the work done but we also know how important it is to balance work with the rest of our lives. Stoneridge Software has cultivated a flexible working environment, flexible vacation time, paid parental leave, continuous learning and development, and social wellness initiatives that bring a sense of belonging to all.\n   \n \n \n \n    Our team is dedicated to helping customers get it right when it comes to software implementation and technology. We play as hard as we work, we embrace every opportunity to learn and share our success. What are you waiting for? Join us!\n   \n \n \n  Stoneridge Software seeks a highly motivated Business Analyst to contribute to our evolving culture of continuous improvement. This individual will work closely with key stakeholders and other internal enablement functions to analyze current processes, define requirements, and create collaborative solutions in prioritized, high-impact areas of Stoneridge\u2019s business. The person in this role will use their passion and skills for requirement elicitation through thoughtful, end user-focused methods, critical thinking and problem solving, and facilitating actionable collaboration and solutioning to support Stoneridge in bringing its continuous improvement ideas to life.\n   \n \n \n  We are seeking someone with formal training and experience in business analysis, with transferable skills in change management and process improvement, who can blend and flex those skills to fit the varying needs an internal project carries. The Business Analyst will work with the Program Manager \u2013 Continuous Improvement and other CI team members to balance the strategic and tactical sides of continuous improvement at Stoneridge, and may be responsible for one or more aspects of internal projects. This could include solution requirement elicitation and documentation, business process analysis and diagramming, identifying and documenting process improvement opportunities, facilitating collaborative working sessions with internal teams, defining and documenting future state designs, and guiding the functional side of testing, training, and validating continuous improvement efforts.\n   \n \n \n  The candidate must be extremely detail-oriented, able to multitask within a fast-paced environment, an excellent communicator, and a compassionate collaborator who can work across a variety of perspectives and quickly navigate any situation to reach desired goals.\n   \n \n \n \n \n \n  A Day in the Life \n \n \n  Collaborate within the CI team to support a portfolio of continuous improvement initiatives, leading business analysis efforts on assigned priority projects based on Stoneridge\u2019s strategic plan \n  Partner within the Internal Operations team and with other Stoneridge stakeholders and subject matter experts to facilitate discovery and create improved processes, assets, and solutions relevant to Stoneridge Software\u2019s delivery methodology (Proven Process) and internal operating processes \n  Work with the broader Stoneridge teams to turn proposed changes and ideas into reality, and support the definition of project scope, goals, and deliverables as part of the requirements gathering process \n  Write end user documentation and create training plans for continuous improvement initiatives \n  Facilitate strategic envisioning and other types of discovery and/or design thinking activities for assigned continuous improvement initiatives \n  Communicate in formal and informal presentation settings, including small to large-sized groups, internal project teams, all-company meetings and events; and develop written communications to address varied styles and information needs \n  Track and report progress against project plans while working with management to remove roadblocks \n  Develop productive working relationships and establish credibility with internal team members in a way that aligns with Stoneridge culture and contributes to a positive and healthy workplace environment \n  Participate in the After Action Review (AAR) framework and contribute to tactical execution of a backlog of improvement items from AARs, in collaboration with others in the CI Team and Stoneridge business process owners / subject matter experts \n  Consider and embed change management techniques in all aspects of the CI team\u2019s approach to business analysis for internal continuous improvement purposes \n  Continuously document and reflect on lessons learned, and collaborate with others to solidify a continuous improvement culture across Stoneridge \n \n \n \n \n \n \n \n \n  Preferred Qualifications \n \n \n  3-5+ years of experience as a Business Analyst or similar role \n  Knowledge and/or certifications in Business Analysis methodologies \n  Experience conducting requirements gathering and Fit-Gap analysis, documenting requirements, and creating business process diagrams \n  Familiarity with Microsoft business applications and the Microsoft consulting space \n  Ability to translate requirements into a solution that meets business needs \n  Transferable experience or skills in change management and/or process improvement \n  Strong critical thinking and problem-solving skills \n  Excellent communication skills, including active listening, written, and verbal \n  Facilitation skills and practice working with small and large groups across a wide array of perspectives \n  Strong interpersonal skills and ability to establish and maintain productive, professional, and values-driven working relationships \n  Self-motivated and capable of operating in a fast-paced, ever-evolving environment \n  Willingness to lean into difficult conversations, and courageous in navigating conflict \n  Qualities of a lifelong learner, reflecting an eagerness to ask questions, stay curious, question preconceived notions, and grow through challenge \n  Ability to work independently and collaboratively for the best interests of the business and team \n \n \n  Work Location:  This position is available on a \n       REMOTE  basis in the United States or \n       REMOTE  in Canada (Alberta, British Columbia, Manitoba, New Brunswick, Newfoundland, Nova Scotia, Ontario, Prince Edward Island, Saskatchewan).\n      \n \n \n \n \n \n \n \n \n  Health and Wellness \n \n \n  Medical Insurance (premiums for employees paid for by the company) \n  Dental Insurance \n  Vision insurance \n  401(k) contribution program (US) or RRSP Benefits (Canada) \n  Life insurance \n  Disability Benefits \n  Paid parental leave \n  Paid flexible time off \n  Paid sick time (US) or floater days (Canada) \n  Paid holidays \n  Flexible work schedules \n  Mobile/internet reimbursement \n  Employee and family assistance program \n  Learning and development allowance \n  Employer charitable contribution \n  Social wellness clubs \n  Professional coaching \n  Paid business mileage \n  Home office and wellness allowance (US Only) \n  HSA contribution (US Only) \n \n \n \n \n \n \n \n \n    We live and breathe our core values: \n   \n \n   Integrity | Technical Excellence | Tenacity | Client Centric | Enjoy Our Work\n   \n \n \n \n    They are the fabric of our company and a reflection of our organizational culture. Our values are a part of our talent acquisition process, how we operate our company and how we partner with our clients. We enjoy our work by exhibiting our technical excellence and tenacity while being inherently client-centric with integrity toward every customer engagement.\n   \n \n \n \n    Stoneridge Software is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, veteran status and all the other fascinating characteristics that make us unique. Growing the best team is at the center of our strategic plan. To be successful in this, we strive to create an inclusive environment and build a sense of belonging by celebrating our differences and ensuring fair and equitable treatment for all our team members.\n   \n \n \n  We will comply with local guidelines regarding infectious diseases and vaccine requirements. Team members who are required to travel to client sites, conferences and events that are not in Stoneridge Software offices, must comply with the client's COVID-19 policies and procedures or have an approved exemption.", "cleaned_desc": "  Knowledge and/or certifications in Business Analysis methodologies \n  Experience conducting requirements gathering and Fit-Gap analysis, documenting requirements, and creating business process diagrams \n  Familiarity with Microsoft business applications and the Microsoft consulting space \n  Ability to translate requirements into a solution that meets business needs \n  Transferable experience or skills in change management and/or process improvement \n  Strong critical thinking and problem-solving skills \n  Excellent communication skills, including active listening, written, and verbal \n  Facilitation skills and practice working with small and large groups across a wide array of perspectives \n  Strong interpersonal skills and ability to establish and maintain productive, professional, and values-driven working relationships \n  Self-motivated and capable of operating in a fast-paced, ever-evolving environment \n  Willingness to lean into difficult conversations, and courageous in navigating conflict \n  Qualities of a lifelong learner, reflecting an eagerness to ask questions, stay curious, question preconceived notions, and grow through challenge \n  Ability to work independently and collaboratively for the best interests of the business and team \n \n \n  Work Location:  This position is available on a \n       REMOTE  basis in the United States or \n       REMOTE  in Canada (Alberta, British Columbia, Manitoba, New Brunswick, Newfoundland, Nova Scotia, Ontario, Prince Edward Island, Saskatchewan).\n      \n \n \n \n \n \n ", "techs": ["business analysis methodologies", "microsoft business applications", "microsoft consulting space", "change management", "process improvement", "critical thinking", "problem-solving", "communication skills", "facilitation skills", "small and large group facilitation", "interpersonal skills", "productive working relationships", "self-motivation", "fast-paced environment", "conflict navigation", "lifelong learner", "independent work", "collaborative work", "remote work", "united states", "canada", "alberta", "british columbia", "manitoba", "new brunswick", "newfoundland", "nova scotia", "ontario", "prince edward island", "saskatchewan"]}, "5d998f26a01521c4": {"terms": ["data analyst"], "salary_min": 73875.17, "salary_max": 93542.44, "title": "Business Intelligence Analyst", "company": "EquipmentShare", "desc": "EquipmentShare is Hiring a Business Intelligence Analyst \n  EquipmentShare is searching for a Business Intelligence Analyst for our corporate office in Columbia, MO, to support our Business Analytics team as the department continues to grow.  This new team member may be based anywhere in the United States and offers a remote/hybrid work option, but must be able to meet with management in person at least quarterly. \n  EquipmentShare is seeking a  Business Intelligence Analyst.  As a BI Analyst, you will use your data expertise to help departments throughout the company with analytics needs. These projects are wide ranging and could include anything from finance and collections to telematics and fleet data. \n  Primary Responsibilities \n \n Become a technical data and reporting expert in a variety of areas to refine and troubleshoot reporting requirements working across teams and domains \n Build complex queries and data models based on reporting requirements with minimal errors \n Produce and support dashboards and reports used across the organization \n Use your strong development and analytical skills to ideate and solve business problems \n \n Why We're a Better Place to Work \n \n Competitive salary \n Health insurance and medical coverage benefits \n 401(k) and company match \n Unlimited paid time off \n Stocked breakroom and full kitchen, chef prepared meals daily (Corporate HQ) \n State of the art onsite gym (Corporate HQ)/Gym stipend for remote employees \n Volunteering and local charity initiatives that help you nurture and grow the communities you call home \n Opportunities for career and professional development with conferences, events, seminars and continued education. \n \n About You \n  Our mission to change an entire industry is not easily achieved, so we only hire people who are inspired by the goal and up for the challenge. In turn, our employees have every opportunity to grow with us, achieve personal and professional success and enjoy making a tangible difference in an industry that's long been resistant to change. \n  Skills & Qualifications \n \n Must be qualified to work in the United States - we are not sponsoring any candidates at this time. \n At least 2 years of experience programming in SQL \n At least 2 years of experience designing business intelligence reports (e.g. Looker, PowerBI, Tableau, Qlik, etc.) \n Strong attention to detail and quality assurance process \n Knowledge of an analytical language like Python or R is a plus \n Proven ability to independently approach complex problems with curiosity and an analytical mindset \n Ability to adapt quickly, manage competing projects and challenge the status quo \n A keen understanding of data interpretation and the ability to swiftly extract key insights \n \n About EquipmentShare \n  EquipmentShare is dedicated to creating a  connected jobsite for the modern contractor . We deliver user-friendly technology solutions that help contractors maximize their equipment uptime, reduce risk exposure and increase productivity. EquipmentShare's product offerings include an improved equipment rental experience, fleet tracking and asset management software, hardware security solutions and predictive service and maintenance applications. \n  EquipmentShare is the fastest-growing, independently owned construction equipment rental company in the country. We serve dozens of markets across the U.S. and are on track to create a national footprint in every major market in the country by the end of 2023. \n  Since our founding in 2014 and incorporation in 2015, we've had nationwide growth \u2014 and we're not stopping anytime soon. Ready to support our mission, invest in yourself and discover your potential? Then we'd love to meet you. Apply today. \n  EquipmentShare is committed to a diverse and inclusive workplace. EquipmentShare is an equal opportunity   employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation,   protected veteran status, disability, age, or other legally protected status. \n \n \n  #LI-Remote", "cleaned_desc": " \n Must be qualified to work in the United States - we are not sponsoring any candidates at this time. \n At least 2 years of experience programming in SQL \n At least 2 years of experience designing business intelligence reports (e.g. Looker, PowerBI, Tableau, Qlik, etc.) \n Strong attention to detail and quality assurance process \n Knowledge of an analytical language like Python or R is a plus \n Proven ability to independently approach complex problems with curiosity and an analytical mindset \n Ability to adapt quickly, manage competing projects and challenge the status quo ", "techs": ["looker", "powerbi", "tableau", "qlik", "python", "r"]}, "ae4eac27680ef50d": {"terms": ["data analyst"], "salary_min": 77235.0, "salary_max": 96544.0, "title": "HEALTH CARE BUSINESS INTELLIGENCE ANALYST (REMOTE)", "company": "OCHIN", "desc": "Description: \n   Make a difference at OCHIN \n  OCHIN is a rapidly growing national nonprofit health IT organization with two decades of experience transforming health care delivery to drive health equity. We are hiring for a number of new positions to meet increasing demand. When you choose to join OCHIN, you have the opportunity to continuously grow your skills and do meaningful work to help fulfill our mission. \n  OCHIN provides leading-edge technology, data analytics, research, and support services to nearly 1,000 community health care sites, reaching nearly 6 million patients nationally. We believe that every individual, no matter their race, ethnicity, background, or zip code, should have fair opportunity to achieve their full health potential. Our work addresses differences in health that are systemic, avoidable, and unjust. We partner, learn, innovate, and advocate, in order to close the gap in health for individuals and communities negatively impacted by racism or other structural inequities. \n  At OCHIN, we value the unique perspectives and experiences of every individual and work hard to maintain a culture of belonging. \n  Founded in Oregon in 2000, OCHIN employs a growing virtual workforce of more than 1000+ diverse professionals, working remotely across 49 states. We offer a generous compensation package and are committed to supporting our employees\u2019 entire well-being by fostering a healthy work-life balance and equitable opportunity for professional advancement. We are curious, collaborative learners who strive to live our values everyday: leadership, collaboration, excellence, innovation, inclusion, and stewardship. OCHIN is excited to support our continued national expansion and the increasing demand for our innovative tools and services by welcoming new talent to our growing team. \n  Position Overview \n  The  Business Intelligence Analyst  supports the mission of OCHIN by designing, developing, testing, documenting, maintaining, and troubleshooting reports across a broad platform of business intelligence tools. As a member of OCHIN\u2019s Population Health/Reporting Analytics department, the  Business Intelligence Analyst  role supports the full lifecycle of projects particularly the requirements definitions, quality assurance testing and user acceptance testing phases of projects. This role requires an above-average ability and desire to communicate in email, via JIRA tickets, and over the phone, as well as to effectively balance multiple competing priorities. \n  Essential Duties \n \n  Participate in requirement gathering, defining scope and objectives of business requirements, including documentation of requirements (i.e. use cases) and relevant translation into system requirement specifications. \n  Serve as a subject matter expert in assigned reporting system, internally and with members or external customers. \n  Responsible for the execution of full reporting lifecycle from design, development, testing, documentation, maintenance, and troubleshooting. \n  Develop and update technical documentation for reporting systems \n  Perform other duties as assigned \n  Requirements: \n  \n Bachelor\u2019s degree or 4 years of equivalent work experience preferred \n  A minimum of 2 years of professional experience, preferably in a Healthcare, Information Technology, or related field, required. Experience in a Healthcare setting, Ambulatory or Acute Care settings \n  Experience with Caboodle database highly desired \n  Experience with SlicerDicer highly desired \n  Display knowledge of the underlying language of the assigned data system and business intelligence toolset (SQL, Epic Cogito, Business Objects, Crystal Reports, Tableau). \n  Experience in working with others to identify, define and analyze end user requirements and timelines designed to meet business needs \n  At least one current Epic certification in area of focus (Cogito or Clarity) preferred \n \n  COVID-19 Vaccination Requirement \n  To keep our colleagues, members, and communities safe, OCHIN requires all employees\u2014including remote employees, contractors, interns, and new hires\u2014to be vaccinated with a COVID-19 vaccine, as supported by state and federal public health officials, as a condition of employment. All new hires are required to provide proof of full vaccination or receive approval for a medical or religious exemption before their hire date. \n  Work Location and Travel Requirements \n \n  OCHIN is 100% remote organization with no physical corporate office location. Employees work remotely from home and many of our positions also support our member organizations on-site for new software installations. Nationwide travel is determined based on OCHIN business needs. Please inquire during the interview process about travel requirements for the position. \n  Work from home requirements are: \n \n Ability to work independently and efficiently from a home office environment. \n High Speed Internet Service \n It is a requirement that employees work in a distraction free workplace. \n \n  We offer a comprehensive range of benefits. See our website for details: https://ochin.org/employment-openings \n  OCHIN is proud to be an equal opportunity employer. We are committed to building a team that represents a variety of backgrounds, perspectives, and skills for the benefit of our staff, our mission, and the communities we serve. \n  As an Equal Opportunity and Affirmative Action employer, OCHIN, Inc. does not discriminate on the basis of race, ethnicity, sex, gender identity, sexual orientation, religion, marital or civil union status, age, disability status, veteran status, or any other protected characteristics. All aspects of employment are based on merit, performance, and business needs. \n  Base Pay Overview \n  The typical offer range for this role is minimum to midpoint, with the midpoint representing the average pay in a national market scope for this position. Please keep in mind that this range represents the pay range for all positions in the job grade within which this position falls. The actual salary offer will consider a wide range of factors directly relevant to this position, including, but not limited to, skills, knowledge, training, responsibility, and experience, as well as internal equity and alignment with market data. \n  #LI-Remote \n  #Caboodle \n  #Clarity \n  #Cogito \n  #Ambulatory \n  #Acutecare", "cleaned_desc": "", "techs": ""}, "a03557a23890c446": {"terms": ["data analyst"], "salary_min": 83147.36, "salary_max": 105283.08, "title": "Business Analyst", "company": "KeenLogic", "desc": "KeenLogic is seeking to hire a Software Requirements Analyst (BA) on a large IT project providing application operations and maintenance, COTS integration and software development services and business solutions for more than 100 websites and applications in the Federal Government. The candidate will be responsible for eliciting, documenting and managing the system requirements for assigned application(s) within the portfolio, ensuring that the requirements are understood by stakeholders, are detailed for implementation by the development teams and are testable by the QA teams, all within an Agile process. In addition, the successful candidate will be responsible for contributing to a wide array of software documentation. This is a full-time position offering benefits, PTO, 401k, and Life Insurance. \n  *Must have Active Secret Clearance* \n  Education: \n  BS degree or equivalent experience \n  General roles & responsibilities: \n \n  Become an expert in your supported application(s) understanding its features and functionality so that you can assist in the definition of new improvements, enhancements and processes. \n  Interview and collaborate with stakeholders at multiple management levels to obtain requirements. \n  Document and manage software requirements in story form. \n  Maintain and groom application backlogs and conduct sprint planning. \n  Provide support for Developers, Test Team and client Stakeholders in the creation and implementation of requirement stories. \n  Assist in the testing and validation of software implementations. \n  Develop and update software Documentation, such as Users Guides or sites, Design Documents and security documentation. \n  Maintain requirements in the form of stories within Azure DevOps. \n  Support sprint planning and execution in an Agile environment. \n  Develop software release notes. \n  Develop process analysis and standard operating procedures. \n  Provide process and system diagrams using available tools. \n \n  Required Skills: \n \n  At least three years of experience in software requirements analysis and documentation of which at least one year was in an Agile process environment. \n  Ability to work with all levels of client from end users to Sr. managers to obtain detailed system requirements. \n  Excellent communication skills, the ability to facilitate working meetings, ask probing questions to elicit requirements and ability to understand the feedback to comprehend client responses to translate into documentable requirements. \n  Ability to perform business process analysis and process improvement. \n  Excellent writing skills to clearly document and communicate stakeholder requirements at various levels from high level to detailed. \n  Experience in creating system and user documentation is also required. \n \n  Tools: \n \n  Experience with Microsoft Azure DevOps for requirements/story management and sprint planning is a plus. \n  Experience with modeling tools such as Visio and requirements management tools such as Jira is a plus. \n \n   \n   \n aXhSRGM78o", "cleaned_desc": "", "techs": ""}, "f037a792d9816b8c": {"terms": ["data analyst"], "salary_min": 62600.0, "salary_max": 94000.0, "title": "Revenue Operations Analyst, Strategy and Analytics", "company": "Articulate", "desc": "The Revenue Operations Analyst is a critical role responsible for leveraging data to drive strategic business outcomes. This position involves performing in-depth data analysis and generating actionable insights for key stakeholders, including Sales, Success, Channel, Marketing, and Finance leaders. Additionally, the role focuses on streamlining RevOps reporting and models, enhancing automation, and ensuring clear documentation of team processes. \n  The ideal candidate possesses 2-4 years of experience in revenue operations or a similar data-oriented role, a bachelor's degree, and proficiency in tools like Google Sheets, Excel, and Salesforce. They should be analytical, adaptable, and an excellent communicator, capable of working both independently and collaboratively in a remote environment. \n  What you'll do: \n \n Perform data analysis and create actionable insights based on interpretation of the results. \n Create highly visual dashboards and reports to communicate insights to stakeholders, which includes Sales, Success, Channel, Marketing, and Finance leaders. \n Solicit and collaborate with business stakeholders to understand what data and cascading information is most helpful in aiding strategic business outcomes. \n Support strategic initiatives by evaluating the impact of revenue-driving programs and advising stakeholders accordingly. \n Drive automation and efficiency of RevOps\u2019 reporting and models by identifying bottlenecks and streamlining data collection. \n Document RevOps team processes and procedures, ensuring clarity and consistency.   \n \n What you should have: \n \n Minimum 2-4 years experience in revenue operations, sales operations reporting and analysis, or a similar data-oriented position \n A four-year college degree or equivalent experience is required \n A team player who is comfortable in a human-centered organization \n Proficiency with Google Sheets or Excel to perform complex data analysis and reporting \n Demonstrated skill in using data to identify trends, draw conclusions, and make strategic recommendations. \n Knowledge and experience in the use of Salesforce.com for revenue-generating teams, as well as building reports in Salesforce.com \n An analytical mind with the ability to tie business needs and desired outcomes to the data \n Self-starter motivated by intellectual curiosity, eager to learn and adapt to new tools and processes \n Excellent organizational and time management skills \n Self-motivated in a remote environment with the ability to work independently while also functioning and contributing as part of a team \n Skilled in building strong relationships across an organization and communicating complex information both written and verbally \n \n You're the ideal candidate if: \n \n Experience working for a SaaS organization, understanding PLG business models and best practices \n Experience with data visualization tools (Looker, Tableau) \n \n The pay range for this position is $62,600 to $94,000 for all US locations. Articulate takes into consideration a wide range of factors that are utilized in making compensation decisions including, but not limited to, skill sets, experience and training, licensure and certifications, qualifications and education, and other business and organizational needs. This position is also bonus eligible. Articulate also offers a robust suite of benefits, check out the website for a full list. \n  About us \n \n  Articulate Global, LLC, is the leading SaaS provider of creator platforms for online workplace training. Founded by Adam Schwartz in 2002, Articulate provides creator tools and services that make it simple for enterprises and SMBs to develop, deliver, and analyze online workplace training that\u2019s engaging and effective.\n  \n \n \n  Increasingly, organizations must reskill employees for ever-changing remote and hybrid work environments, create learning cultures that attract and retain employees in a tight labor market, and use training to build more equitable, empowering, and engaging workplaces. Articulate helps organizations address these critical business needs with its creator platform for workplace training. Articulate 360\u2014a suite of creator tools for online courses\u2014was named the 7th most-loved product in the world by TrustRadius in 2021. And Rise\u2014an all-in-one online training system that makes online training easy to create, enjoyable to take, and simple to manage\u2014is the first creator platform for SMBs and departments within the enterprise. Articulate has more than 118,000 customers in 170 countries and counts all 100 of the Fortune 100 companies as customers.\n  \n \n \n  Named one of Inc. Magazine\u2019s Best Workplaces 2022 and a leader in building a human-centered organization, Articulate is guided by a commitment to provide the best value to customers, do right by employees, and create an equitable, empowering workplace for all. As a human-centered organization, we honor people\u2019s humanity knowing that each person\u2019s unique history, vulnerabilities, and social location inform how we show up with one another. We embrace our connectedness, aware that what we do and say impacts others. We give each other grace because we are all works in progress, learning and evolving every day. And we take responsibility for ourselves and are serious about our accountability to each other. In all we do, we strive to create an equitable, sustainable, and empowering workplace while we drive results for the business and make a positive impact in the world. Read more about our values here.\n  \n \n \n  Articulate welcomes different voices and viewpoints and does not discriminate on the basis of race, religion, color, national origin, ancestry, physical and/or mental disability, medical condition, native language, pregnancy status, physical size, genetic information, marital status, sex, gender, gender identity, gender expression, transgender status, age, sexual orientation, and military or veteran status, or any other basis protected by law. We are an equal opportunity employer and invite applicants to voluntarily disclose their race and gender on our application form to help us create a diverse company. This voluntarily disclosed information will not be shared with any hiring manager and will be kept in confidence by the Articulate human resources department and executives who are not hiring for this position.\n  \n \n \n (For information about Articulate's privacy practices, please view our  Privacy Notice\n   )", "cleaned_desc": " \n What you should have: \n \n Minimum 2-4 years experience in revenue operations, sales operations reporting and analysis, or a similar data-oriented position \n A four-year college degree or equivalent experience is required \n A team player who is comfortable in a human-centered organization \n Proficiency with Google Sheets or Excel to perform complex data analysis and reporting \n Demonstrated skill in using data to identify trends, draw conclusions, and make strategic recommendations. \n Knowledge and experience in the use of Salesforce.com for revenue-generating teams, as well as building reports in Salesforce.com \n An analytical mind with the ability to tie business needs and desired outcomes to the data   Self-starter motivated by intellectual curiosity, eager to learn and adapt to new tools and processes \n Excellent organizational and time management skills \n Self-motivated in a remote environment with the ability to work independently while also functioning and contributing as part of a team \n Skilled in building strong relationships across an organization and communicating complex information both written and verbally \n \n You're the ideal candidate if: \n \n Experience working for a SaaS organization, understanding PLG business models and best practices \n Experience with data visualization tools (Looker, Tableau) \n ", "techs": ["google sheets", "excel", "salesforce.com", "looker", "tableau"]}, "b68e2ee2ac58cb5f": {"terms": ["data analyst"], "salary_min": 56893.332, "salary_max": 72039.63, "title": "Data Visualization PowerPoint Specialist", "company": "Luminas", "desc": "Position \n  Data Visualization PowerPoint Specialist \n  We\u2019re looking for a talented and passionate visualization professional to join our virtual, growing team in the US as a Data Visualization PowerPoint Specialist. \n \n  Who we are: \n  Luminas, LLC is a full-service insights and market research company that helps to drive brands forward. We were founded in 2018 by a team of forward-thinking consultants. At Luminas, we pride ourselves on being a company where employee development, creativity, and kindness matter. Other benefits of joining our small and agile company include:  \n \n The opportunity to help influence and shape the company \n Access to company leadership \n A supportive close-knit culture \n \n \n \n  What we offer: \n \n Comprehensive benefits program (including medical, dental, and vision coverage) \n 401k program \n Unlimited vacation policy \n Company bonus program \n Full time remote working \n \n \n \n  Who we are looking for: \n \n  This position is responsible for transforming our Team\u2019s PowerPoint reports into impactful and visually engaging business presentations. We are seeking someone with a passion for visual design, attention to detail, and an eye for attractive and appealing layouts. Our growing Visualization Team has been recognized by our clients for their sleek and thoughtful designs. \n \n  Experience: \n \n \n \n Experience in designing PowerPoint presentations, preferably in a market research, analytics, or consulting firm \n Expert skill level designing and formatting charts in PowerPoint (along with basic knowledge of Excel)  \n Worked with videos (editing video, incorporating into PowerPoint) \n Skills in illustration with a working knowledge of Illustrator and Photoshop  \n Experience in animation, including 3D animation would be a plus  \n Excellent communication skills able to communicate complex ideas clearly and concisely \n Logically organize information and content \n High standards in terms of quality products and client service \n The ability to work proactively in a fast-paced virtual environment \n Enthusiastic, creative, proactive, and collaborative attitude \n \n \n \n   Job Responsibilities: \n \n \n \n  Responsible for designing, producing and updating PowerPoint presentations based on company style guidelines \n Produce client ready documents with minimal guidance. Includes interpretation of comments providing the right designs or layouts that ensure communication of messages  \n Transform and present data into charts and graphs \n Develop infographics \n Graphically streamline complex concepts \n Quality check documents thoroughly to ensure there are no errors in client deliverables \n Manage time effectively to meet deadlines  \n Accept feedback and make changes, updates, and improvements if required \n \n \n Contact :  To apply, submit your resume to JoinOurTeam@LuminasLLC.com \n \n \n  Luminas LLC is committed to diversity, equity, and inclusion and is an equal-opportunity employer. Applicants will be considered for employment, and all employment decisions will be made without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran, or disability status. Employment at Luminas is based solely on business needs, job requirements, and individual qualifications. We prohibit discrimination and harassment of any kind, live or virtual, in our workplace. This policy applies to all terms, conditions and privileges of employment, including recruitment, hiring, placement, compensation, promotion, discipline and termination.", "cleaned_desc": "", "techs": ""}, "c4269f0388a381af": {"terms": ["data analyst"], "salary_min": 110000.0, "salary_max": 125000.0, "title": "ServiceNow Business Analyst", "company": "RCR Consulting Group", "desc": "LEIDIT is seeking a Business Analyst to be part of a growing team doing ServiceNow implementations and application development for a Federal Agency customer in the DC Metropolitan area. Contract provides enterprise support and requires working extensively with multiple stakeholders in support of growing customer requirements. \n Skills shall include the following: \n \u00b7 Experience with software development lifecycles (SDLCs), including DevOps, Agile, Lean, Iterative, or Waterfall. \n \u00b7 Strong technical foundation and knowledge of the ServiceNow platform. \n \u00b7 Proficient analysis skill and capability to identify downstream implications. \n \u00b7 Exceptional communication skills. \n \u00b7 The ability to develop and forge strong relationships and build consensus among competing stakeholders \n \u00b7 Experience leading and facilitating business process review efforts, including evaluating business processes, anticipating requirements, and uncovering areas for improvement. \n \u00b7 Excellent planning, organizational, and time management skills. \n \u00b7 Exceptional requirements elicitation and facilitation skills. \n \u00b7 Exceptional analytical and conceptual thinking skills. \n \u00b7 In-depth understanding of requirements traceability. \n Ability to: \n \u00b7 Gather critical information from meetings with various stakeholders and produce useful reports. \n \u00b7 Document the results of business process reviews, develop, and communicate optimization strategies to team members and Management. \n \u00b7 Effectively conduct meetings and presentations to share ideas and findings. \n \u00b7 Work closely with business clients, technical staff, and management. \n \u00b7 Ensure solutions meet business needs and requirements. \n Responsibilities may include the following: \n \u00b7 Represents project stakeholders throughout planning, development, and release processes. \n \u00b7 Owns the relationship with project stakeholders to identify, model, and document business, process, and data requirements. \n \u00b7 Works with Platform Support Team to develop release estimates. \n \u00b7 Supports Platform Support Team in understanding business and test requirements. \n \u00b7 Translates technical complexities to project stakeholders, ensuring understanding of design decisions. \n Preferred Skills/Certifications: \n \n Degree in Business or Business Administration \n ServiceNow Administrator, Developer and/or ServiceNow CIS Certifications \n \n Clearance: \n Public Trust \n Job Type: Full-time \n Pay: $110,000.00 - $125,000.00 per year \n Benefits: \n \n 401(k) \n Health insurance \n Paid time off \n Professional development assistance \n \n Schedule: \n \n Monday to Friday \n \n Application Question(s): \n \n Will you be able to reliably commute or relocate to Washington, DC 20005 for this job? \n How many years of ServiceNow experience do you have? \n Do you have an active security clearance? \n Do you hold any ServiceNow certifications including Certified System Administrator and Certified Application Developer? \n \n Education: \n \n Bachelor's (Required) \n \n Experience: \n \n SQL: 1 year (Preferred) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "e4e22f988d0eea26": {"terms": ["data analyst"], "salary_min": 57000.0, "salary_max": 115100.0, "title": "Business Analyst, Supply Chain (Remote)", "company": "Stryker", "desc": "Why supply chain at Stryker? \n  As a member of our Supply Chain team, you will make a daily impact on the lives of others. Apply today and you will get a chance to work with high-functioning, driven people who all have the same mission of making healthcare better. \n  We are proud to be named one of the World\u2019s Best Workplaces and a Best Workplace for Diversity by Fortune Magazine! Learn more about our award-winning organization by visiting  stryker.com \n  Who we want- \n \n  Analytical problem solvers:  People who go beyond just fixing to identify root causes, evaluate optimal solutions, and recommend comprehensive upgrades to prevent future issues \n  Collaborative networkers  who proactively collaborate with business leaders, internal partners, and external contacts to build powerful relationships that lead to successful business outcomes \n  Competitive achievers  who are persistent, results-driven individuals who thrive in a fast-paced environment and will stop at nothing to ensure a project is complete and meets regulations and expectations \n \n \n  What you will do-  The Supply Chain Business Analyst will oversee new requests for inventory placements. In this role, you will build relationships with customers and maximize inventory assets to grow the business. The Supply Chain Business Analyst will partner with Field Offices to ensure customer service levels and satisfaction are met while meeting the overall objective to create a leaner and more profitable supply chain. This role will be the primary contact for Branch Operations with regard to standard kit allocations and new product rollouts. This role will also provide data to the Joint Replacement Sales and BOM teams on inventory placements and sales opportunities. \n \n  Essential Duties and Responsibilities \n \n  Analyze data to determine correct placements of new product launch kits and EPS (early product surveillance) sets \n  Collaborate with manufacturing partners on long term new product development plans designed to improve NPDP allocation process \n  Partner with Demand Planning and Marketing on new product launch forecasts \n  Play a role in Field budget creation for standard instrument kits and non-NPDP consumable items \n  Analyze and schedule order management activities to support forecasts, target inventories, and multiple supply chain activities \n  Deliver forecasts that will be used during monthly IBP meetings and attend weekly manufacturing and kitting conference calls \n  Schedule and lead bi-monthly meetings with field SME's to discuss and gain feedback on resource allocation process \n  Review weekly instrument budgets and approve instrument asset orders when quarterly budget is exceeded \n \n  What you need- \n \n  Bachelor\u2019s degree or 6 years of relevant experience in lieu of degree -required \n  2+ years of relevant experience in addition to Bachelor\u2019s degree or 6 years of relevant experience -required \n  Experience with Salesforce.com, WebOps, Oracle, and PowerBI -highly preferred \n  Salesforce Business Admin Certificate or equivalent experience -highly preferred \n \n \n  $57,000.00-$115,100.00 salary plus bonus eligible + benefits. Actual minimum and maximum may vary based on location. Individual pay is based on skills, experience, and other relevant factors. \n  About Stryker \n  Our benefits:   \n \n 12 paid holidays annually   \n Health benefits include: Medical and prescription drug insurance, dental insurance, vision insurance, critical illness insurance, accident insurance, hospital indemnity insurance, personalized healthcare support, wellbeing program and tobacco cessation program.   \n Financial benefits include Health Savings Account (HSA), Flexible Spending Accounts (FSAs), 401(k) plan, Employee Stock Purchase Plan (ESPP), basic life and AD&D insurance, and short-term disability insurance.   \n \n For a more detailed overview of our benefits or time off, please follow this link to learn more: US Stryker employee benefits     About Stryker  Stryker is one of the world\u2019s leading medical technology companies and, together with its customers, is driven to make healthcare better. The company offers innovative products and services in Medical and Surgical, Neurotechnology, Orthopaedics and Spine that help improve patient and healthcare outcomes. Alongside its customers around the world, Stryker impacts more than 130 million patients annually. More information is available at stryker.com.     Know someone at Stryker?  Be sure to have them submit you as a referral prior to applying for this position. Learn more about our employee referral program on our referral page    Stryker is driven to work together with our customers to make healthcare better. Employees and new hires in sales and field roles that require access to customer accounts as a function of the job may be required, depending on customer requirements, to obtain various vaccinations as an essential function of their role.", "cleaned_desc": "", "techs": ""}, "6c2d165c1b93c073": {"terms": ["data analyst"], "salary_min": 65966.09, "salary_max": 83527.78, "title": "Business Analyst, Billing Strategy", "company": "Natera", "desc": "POSITION SUMMARY: \n  The Business Analyst is responsible for analyzing internal billing and payment data to identify trends in reimbursement at national, regional and territory level. The position is responsible for various analysis required on a regular basis from other teams in the organization. \n  PRIMARY RESPONSIBILITIES: \n \n Supports Finance, Billing, Market Access, Product and Marketing teams on projects by preparing ad-hoc analysis and presentations as required. \n Performs a wide range of analytics functions in a fast-paced team environment using tools such as Excel and other business intelligence tools. \n Analyzes payer contract compliance and trends. \n Identifies opportunities for process improvements. \n Designs and executes improvement projects. \n Conducts complex data analysis and data interpretation \n Meets established deadlines timely, accurately, and with a sense of urgency. \n Performs other duties as assigned. \n This role works with PHI on a regular basis both in paper and electronic form and have an access to various technologies to access PHI (paper and electronic) in order to perform the job. \n Employees must complete training relating to HIPAA/PHI privacy, General Policies and Procedure Compliance training and security training as soon as possible but not later than the first 30 days of hire. \n Must maintain a current status on Natera training requirements. \n \n \n \n  QUALIFICATIONS: \n \n Bachelor's Degree in business, economics, related field, or equivalent required. \n Minimum of 2 years of experience working in business administration, information systems, health sciences, insurance company or healthcare billing organization. \n \n \n \n  KNOWLEDGE, SKILLS, AND ABILITIES: \n \n Advanced proficiency with quantitative software programs (Microsoft Excel, Google Sheets). \n Basic SQL knowledge is required. \n Billing systems experience a plus. \n Experience with BI tools, such as Business Objects or Hyperion preferred. \n Ability to define problems, collect and reconcile data, validate data against source information. \n Motivated, shows initiative, and ability to work in a fast paced environment. \n Drive for Results (Service, Quality, and Continuous Improvement). \n Commitment to the successful achievement of team and organizational goals. \n Demonstrate a focus on listening to and understanding client/customer needs and then delighting the client/customer by exceeding service and quality expectations. \n \n \n \n  #LI-REMOTE \n \n \n    The pay range is listed and actual compensation packages are based on a wide array of factors unique to each candidate, including but not limited to skill set, years & depth of experience, certifications and specific office location. This may differ in other locations due to cost of labor considerations.\n   \n  Remote USA \n \n    $66,700\u2014$83,400 USD\n   \n \n \n  OUR OPPORTUNITY \n  Natera\u2122 is a global leader in cell-free DNA (cfDNA) testing, dedicated to oncology, women's health, and organ health. Our aim is to make personalized genetic testing and diagnostics part of the standard of care to protect health and enable earlier and more targeted interventions that lead to longer, healthier lives. \n  The Natera team consists of highly dedicated statisticians, geneticists, doctors, laboratory scientists, business professionals, software engineers and many other professionals from world-class institutions, who care deeply for our work and each other. When you join Natera, you'll work hard and grow quickly. Working alongside the elite of the industry, you'll be stretched and challenged, and take pride in being part of a company that is changing the landscape of genetic disease management. \n  WHAT WE OFFER \n  Competitive Benefits - Employee benefits include comprehensive medical, dental, vision, life and disability plans for eligible employees and their dependents. Additionally, Natera employees and their immediate families receive free testing in addition to fertility care benefits. Other benefits include pregnancy and baby bonding leave, 401k benefits, commuter benefits and much more. We also offer a generous employee referral program! \n  For more information, visit www.natera.com. \n  Natera is proud to be an Equal Opportunity Employer. We are committed to ensuring a diverse and inclusive workplace environment, and welcome people of different backgrounds, experiences, abilities and perspectives. Inclusive collaboration benefits our employees, our community and our patients, and is critical to our mission of changing the management of disease worldwide. \n  All qualified applicants are encouraged to apply, and will be considered without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, age, veteran status, disability or any other legally protected status. We also consider qualified applicants regardless of criminal histories, consistent with applicable laws. \n  If you are based in California, we encourage you to read this important information for California residents. \n  Link: https://www.natera.com/notice-of-data-collection-california-residents/ \n  Please be advised that Natera will reach out to candidates with a @natera.com email domain ONLY. Email communications from all other domain names are not from Natera or its employees and are fraudulent. Natera does not request interviews via text messages and does not ask for personal information until a candidate has engaged with the company and has spoken to a recruiter and the hiring team. Natera takes cyber crimes seriously, and will collaborate with law enforcement authorities to prosecute any related cyber crimes. \n \n    For more information:\n    \n \n BBB announcement on job scams \n FBI Cyber Crime resource page", "cleaned_desc": " \n Advanced proficiency with quantitative software programs (Microsoft Excel, Google Sheets). \n Basic SQL knowledge is required. \n Billing systems experience a plus. \n Experience with BI tools, such as Business Objects or Hyperion preferred. \n Ability to define problems, collect and reconcile data, validate data against source information. \n Motivated, shows initiative, and ability to work in a fast paced environment. \n Drive for Results (Service, Quality, and Continuous Improvement). \n Commitment to the successful achievement of team and organizational goals. \n Demonstrate a focus on listening to and understanding client/customer needs and then delighting the client/customer by exceeding service and quality expectations. \n \n \n ", "techs": ["microsoft excel", "google sheets", "sql", "business objects", "hyperion"]}, "5076ed4c35b22dac": {"terms": ["data analyst"], "salary_min": 50.0, "salary_max": 55.0, "title": "WMS BA(Manhattan)", "company": "Lakarya", "desc": "The WMS Business Analyst is responsible for gathering, analyzing, and documenting business requirements related to warehouse operations and translating them into technical solutions utilizing Warehouse Management Systems (WMS). This role collaborates closely with various stakeholders, including warehouse managers, IT teams, and end-users, to ensure efficient and effective warehouse processes. \n WMS Business Analyst Chesapeake ,VA(Remote) Long Term Contact \n DESCRIPTION \n Understand scope of Data-Lake solution and work on identifying the data model Participate in design and architecture of ETL processes for the defined mapping to Data-Lake solution Conduct meetings with Client Support teams to gather the data mapping requirements for various WMS Conduct meetings with internal stakeholders to understand and perform the analysis between various WMS Understand business problems, provide analysis and insights from the client\u2019s data Conduct scheduled progress reviews on all workstreams and interact with the teams daily Create detailed functional specifications for modifications, defect corrections, enhancements identifying, mapping changes impacting Data-Lake solution Perform process and data modeling \n SKILLS \n Bachelor\u2019s degree in Engineering or related technical fields 4 years of experience in Supply Chain and logistics or related industry Expertise and experience in at least one of the following business disciplines: supply chain management, warehousing, transportation or distribution Strong project and time management skills with ability to multitask and prioritize workload Solid expertise with MS Excel, SQL, any visualization tools like Tableau/PowerBI, any ETL tools for data analysis, extraction, troubleshooting and reporting Hands on experience of working with Big data sets (Data sets with millions of records) Good to have hands on experience with any reporting tool Good to have any working experience in any Cloud ecosystem Good to have any knowledge of formal systems development methodologies \n Job Type: Contract \n Salary: $50.00 - $55.00 per hour \n Experience level: \n \n 4 years \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Application Question(s): \n \n Are you willing to working on W2 or 1099 ? \n \n Experience: \n \n Manhattan: 5 years (Preferred) \n Business analysis: 4 years (Preferred) \n Omni Channel: 3 years (Preferred) \n \n Work Location: Remote", "cleaned_desc": " Bachelor\u2019s degree in Engineering or related technical fields 4 years of experience in Supply Chain and logistics or related industry Expertise and experience in at least one of the following business disciplines: supply chain management, warehousing, transportation or distribution Strong project and time management skills with ability to multitask and prioritize workload Solid expertise with MS Excel, SQL, any visualization tools like Tableau/PowerBI, any ETL tools for data analysis, extraction, troubleshooting and reporting Hands on experience of working with Big data sets (Data sets with millions of records) Good to have hands on experience with any reporting tool Good to have any working experience in any Cloud ecosystem Good to have any knowledge of formal systems development methodologies \n Job Type: Contract \n Salary: $50.00 - $55.00 per hour \n Experience level: \n ", "techs": ["ms excel", "sql", "tableau/powerbi", "etl tools", "big data sets", "reporting tool", "cloud ecosystem", "formal systems development methodologies"]}, "2d1c359b3439d3c3": {"terms": ["data analyst"], "salary_min": 62600.0, "salary_max": 94000.0, "title": "Revenue Operations Analyst, Strategy and Analytics", "company": "Articulate", "desc": "The Revenue Operations Analyst is a critical role responsible for leveraging data to drive strategic business outcomes. This position involves performing in-depth data analysis and generating actionable insights for key stakeholders, including Sales, Success, Channel, Marketing, and Finance leaders. Additionally, the role focuses on streamlining RevOps reporting and models, enhancing automation, and ensuring clear documentation of team processes. \n  The ideal candidate possesses 2-4 years of experience in revenue operations or a similar data-oriented role, a bachelor's degree, and proficiency in tools like Google Sheets, Excel, and Salesforce. They should be analytical, adaptable, and an excellent communicator, capable of working both independently and collaboratively in a remote environment. \n  What you'll do: \n \n Perform data analysis and create actionable insights based on interpretation of the results. \n Create highly visual dashboards and reports to communicate insights to stakeholders, which includes Sales, Success, Channel, Marketing, and Finance leaders. \n Solicit and collaborate with business stakeholders to understand what data and cascading information is most helpful in aiding strategic business outcomes. \n Support strategic initiatives by evaluating the impact of revenue-driving programs and advising stakeholders accordingly. \n Drive automation and efficiency of RevOps' reporting and models by identifying bottlenecks and streamlining data collection. \n Document RevOps team processes and procedures, ensuring clarity and consistency.   \n \n What you should have: \n \n Minimum 2-4 years experience in revenue operations, sales operations reporting and analysis, or a similar data-oriented position \n A four-year college degree or equivalent experience is required \n A team player who is comfortable in a human-centered organization \n Proficiency with Google Sheets or Excel to perform complex data analysis and reporting \n Demonstrated skill in using data to identify trends, draw conclusions, and make strategic recommendations. \n Knowledge and experience in the use of Salesforce.com for revenue-generating teams, as well as building reports in Salesforce.com \n An analytical mind with the ability to tie business needs and desired outcomes to the data \n Self-starter motivated by intellectual curiosity, eager to learn and adapt to new tools and processes \n Excellent organizational and time management skills \n Self-motivated in a remote environment with the ability to work independently while also functioning and contributing as part of a team \n Skilled in building strong relationships across an organization and communicating complex information both written and verbally \n \n You're the ideal candidate if: \n \n Experience working for a SaaS organization, understanding PLG business models and best practices \n Experience with data visualization tools (Looker, Tableau) \n \n The pay range for this position is $62,600 to $94,000 for all US locations. Articulate takes into consideration a wide range of factors that are utilized in making compensation decisions including, but not limited to, skill sets, experience and training, licensure and certifications, qualifications and education, and other business and organizational needs. This position is also bonus eligible. Articulate also offers a robust suite of benefits, check out the website for a full list. \n  About us \n \n  Articulate Global, LLC, is the leading SaaS provider of creator platforms for online workplace training. Founded by Adam Schwartz in 2002, Articulate provides creator tools and services that make it simple for enterprises and SMBs to develop, deliver, and analyze online workplace training that's engaging and effective.\n  \n \n \n  Increasingly, organizations must reskill employees for ever-changing remote and hybrid work environments, create learning cultures that attract and retain employees in a tight labor market, and use training to build more equitable, empowering, and engaging workplaces. Articulate helps organizations address these critical business needs with its creator platform for workplace training. Articulate 360\u2014a suite of creator tools for online courses\u2014was named the 7th most-loved product in the world by TrustRadius in 2021. And Rise\u2014an all-in-one online training system that makes online training easy to create, enjoyable to take, and simple to manage\u2014is the first creator platform for SMBs and departments within the enterprise. Articulate has more than 118,000 customers in 170 countries and counts all 100 of the Fortune 100 companies as customers.\n  \n \n \n  Named one of Inc. Magazine's Best Workplaces 2022 and a leader in building a human-centered organization, Articulate is guided by a commitment to provide the best value to customers, do right by employees, and create an equitable, empowering workplace for all. As a human-centered organization, we honor people's humanity knowing that each person's unique history, vulnerabilities, and social location inform how we show up with one another. We embrace our connectedness, aware that what we do and say impacts others. We give each other grace because we are all works in progress, learning and evolving every day. And we take responsibility for ourselves and are serious about our accountability to each other. In all we do, we strive to create an equitable, sustainable, and empowering workplace while we drive results for the business and make a positive impact in the world. Read more about our values here.\n  \n \n \n  Articulate welcomes different voices and viewpoints and does not discriminate on the basis of race, religion, color, national origin, ancestry, physical and/or mental disability, medical condition, native language, pregnancy status, physical size, genetic information, marital status, sex, gender, gender identity, gender expression, transgender status, age, sexual orientation, and military or veteran status, or any other basis protected by law. We are an equal opportunity employer and invite applicants to voluntarily disclose their race and gender on our application form to help us create a diverse company. This voluntarily disclosed information will not be shared with any hiring manager and will be kept in confidence by the Articulate human resources department and executives who are not hiring for this position.\n  \n \n \n (For information about Articulate's privacy practices, please view our  Privacy Notice\n   )", "cleaned_desc": " \n What you should have: \n \n Minimum 2-4 years experience in revenue operations, sales operations reporting and analysis, or a similar data-oriented position \n A four-year college degree or equivalent experience is required \n A team player who is comfortable in a human-centered organization \n Proficiency with Google Sheets or Excel to perform complex data analysis and reporting \n Demonstrated skill in using data to identify trends, draw conclusions, and make strategic recommendations. \n Knowledge and experience in the use of Salesforce.com for revenue-generating teams, as well as building reports in Salesforce.com \n An analytical mind with the ability to tie business needs and desired outcomes to the data   Self-starter motivated by intellectual curiosity, eager to learn and adapt to new tools and processes \n Excellent organizational and time management skills \n Self-motivated in a remote environment with the ability to work independently while also functioning and contributing as part of a team \n Skilled in building strong relationships across an organization and communicating complex information both written and verbally \n \n You're the ideal candidate if: \n \n Experience working for a SaaS organization, understanding PLG business models and best practices \n Experience with data visualization tools (Looker, Tableau) \n ", "techs": ["google sheets", "excel", "salesforce.com", "looker", "tableau"]}, "e4a8c2ae37d71186": {"terms": ["data analyst"], "salary_min": 84949.9, "salary_max": 107565.49, "title": "Senior Analyst, Business Intelligence", "company": "The Hershey Company", "desc": "Job Title: Senior Analyst, Business Intelligence \n Job Location: Hershey, PA \n \n \n \n This position is open to 100% remote. \n \n \n Summary \n \n \n Responsible for providing critical analytical support to help inform the direction of the Salty Snacks business by leveraging data across the retail landscape. This position is responsible for supporting the Business Intelligence Manager and will serve as a key input into commercial planning by providing forecasting projections, data analysis, as well as a strong cross-functional partner to identify the greatest areas of value creation. \n \n \n \n Responsibilities \n \n \n \n Own retail insights to fuel and inform the commercial plan for the overall business. \n Analyze, understand, and share out key drivers of our own brand and key competitors\u2019 performance, as well as macro trend insights. \n Provide weekly retail reporting and business insights across the Salty Category and distribute to Salty business team members and leadership. \n Engage with Commercial team to enhance planning, forecasting, and reconciliation processes by leveraging consistent use of data and insights. \n Support Business Intelligence Manager in creation and execution of quarterly executive committee (including the President of Salty and CEO) reviews of the Salty Snacks business; build confidence in the business direction as well as prioritize key areas of future focus. \n Liaise and support the Hershey Organization efforts around data integration, processes, and synergies, including third-party partnerships for database management. \n \n \n \n \n Qualifications \n \n \n \n Bachelor\u2019s Degree required. \n 3-5 years experience in the Consumer Packaged Goods (CPG) industry (manufacturer, retailer, vendor, etc). \n Strong interpersonal skills demonstrating the ability to work independently and with a cross functional team. \n Ability to communicate effectively and manage relationships with cross-functional teams. \n Analytical and project management skills with the ability to manage multiple assignments simultaneously. \n Excellent technical and analytical/statistical skills. \n Detail oriented, logical, and methodical approach to problem solving. \n Self-starter/learner, and ability to adapt to fast-paced and changing environment. \n \n \n \n \n Preferred Experience : \n \n \n \n Experience building dashboards in Power BI, Tableau or similar. \n Experience using analytical automation tools (e.g. Alteryx, VBA macros) \n 2+ years analytical experience in category management, sales, consulting, finance, or marketing, including experience in retail databases (e.g., Nielsen or Circana) \n \n \n   \n #LI-MB1 \n #LI-Remote \n  The Hershey Company is an Equal Opportunity Employer. The policy of The Hershey Company is to extend opportunities to qualified applicants and employees on an equal basis regardless of an individual's race, color, gender, age, national origin, religion, citizenship status, marital status, sexual orientation, gender identity, transgender status, physical or mental disability, protected veteran status, genetic information, pregnancy, or any other categories protected by applicable federal, state or local laws. \n \n \n The Hershey Company is an Equal Opportunity Employer - Minority/Female/Disabled/Protected Veterans \n If you require a reasonable accommodation as part of the application process, please contact the HR Service Center (askhr@hersheys.com).", "cleaned_desc": " Liaise and support the Hershey Organization efforts around data integration, processes, and synergies, including third-party partnerships for database management. \n \n \n \n \n Qualifications \n \n \n \n Bachelor\u2019s Degree required. \n 3-5 years experience in the Consumer Packaged Goods (CPG) industry (manufacturer, retailer, vendor, etc). \n Strong interpersonal skills demonstrating the ability to work independently and with a cross functional team.   Ability to communicate effectively and manage relationships with cross-functional teams. \n Analytical and project management skills with the ability to manage multiple assignments simultaneously. \n Excellent technical and analytical/statistical skills. \n Detail oriented, logical, and methodical approach to problem solving. \n Self-starter/learner, and ability to adapt to fast-paced and changing environment. \n \n \n \n \n Preferred Experience : \n \n ", "techs": ["database management"]}, "4781c8645953a0cb": {"terms": ["data analyst"], "salary_min": 69831.15, "salary_max": 88421.79, "title": "Business Analyst", "company": "CSG", "desc": "Hi, I'm \n   \n   Juhi Banerjee\n   , your Recruiter and guide to joining CSG. At CSG, you're more than your resume. We want your diverse perspective and unique background to help us enrich the work we do together. We believe that by channeling the power of all, we make ordinary customer and employee experiences extraordinary. Channel the power of YOU and begin the journey to becoming a CSGer.\n  \n \n \n   What you'll do\n  \n \n  You will report to the Senior Manager of Software Development to contribute toward the successful transformation of a client\u2019s legacy data to the target system \n  Perform as a subject matter expert in data specifications/requirements gathering, processing parameters (UDF/CTD/9XX), CSG Voice Backoffice, CSG Provisioning Database, and test output review \n  Creation of data mapping specifications to include transformation rules to be used \n  Act as a liaison between the client and CSG development and management personnel throughout the transformation process \n  Responsible for tracking, communicating, and documenting (both internally and externally) critical requirements, details, and issues/resolutions \n  Support complex projects, update and develop team tools, and evaluate new processes \n  Perform data mining and analysis to identify data cleansing opportunities \n \n \n \n   You should have\n  \n \n   Research shows that candidates from underrepresented backgrounds often don't apply for roles if they don't meet all the criteria. Remember, you are not solely your resume. Give your transferable skills the chance to tell the full story. Channel the power of YOU and apply to explore the possibility we're the perfect fit.\n  \n \n  Bachelor's degree in Computer Science, Business or equivalent experience required \n  Proficiency in English in a business environment \n  Experience with formulating, writing, and executing TSQL, SQL, or Oracle is required \n  Experience with T-SQL to support project work is required \n  3+ years of Business Analyst experience \n  1+ years of experience in a data transformation environment is a plus \n  Experience in data mining and analysis in a relational database is a plus \n  Ability to work non-standard hours as required \n  Basic knowledge of office software including Word and Excel required \n  Expert technical writing/editing skills required \n  Excellent organizational skills, including ability to consistently adhere to multiple deadlines and frequently changing workload \n  Able to work independently, delivering accurate documentation under deadline pressure \n  Ability to work effectively in a team environment \n  Potential travel as required by business needs \n \n \n   Who will love this job\n  \n \n  A trusted team player \u2013 you know how to connect and communicate with your audience(s) around the world and create safe environments to voice diverse opinions, foster diversity and belonging and above all treat people with respect \n  A growth driver \u2013 you have a mindset that anticipates and adapts to changing needs and can bring partners together to contribute and work toward a shared vision \n  A game changer \u2013 you dream big and push the limits of what's possible to improve for yourself and others \n  A leader \u2013 you excel leading your own projects and produce impactful outcomes while dedicating time to mentor those around you to help them grow \n  A strategist \u2013 you're curious and find inventive ways to implement ideas that lead to business simplification outcomes and solutions \n \n \n \n   Perks & Benefits\n  \n \n  Work from Home, in-office, or hybrid \n  Flexible Paid Vacation, 2 days of Volunteer Time Off per Year, and Holiday Time Off \n  Immediately vested 5.5% 401(k) match \n  And so much more! \n \n \n \n \n  If you would like to be considered for employment opportunities with CSG and need special assistance due to a disability or accommodation for a disability throughout any aspect of the application process, please call us at 1 (402) 431-7440 or email us at accommodations@csgi.com. CSG provides accommodations for persons with disabilities in employment, including during the hiring process and any interview and/or testing processes. \n \n \n \n   Our Story\n  \n \n \n    CSG\n    empowers companies to build unforgettable experiences, making it easier for people and businesses to connect with, use and pay for the services they value most. For over 40 years, our technologies and people have helped some of the world's most recognizable brands solve their toughest business challenges and evolve to meet the demands of today's digital economy.\n  \n \n \n   By channeling the power of all, we make ordinary customer and employee experiences extraordinary. Our people [CSGers] are good people who are committed to doing good work. We're high on respect and low on ego, making us an easy company to do business with and a best place to work. We cultivate a culture based on integrity, innovation and impact across all our \n   \n   locations\n   , so our people show up as the most authentic version of themselves and can work together to build a more future-ready world. \n   \n Learn more \n \n \n \n \n   #LI-Remote\n  \n \n \n   Position Pay Range:\n  \n \n  This range represents the low and high end of the salary range for this position. Actual salaries will vary based on factors including but not limited to geographical location and experience. \n  $57,877.28-$92,602.83\n  \n \n   This role is eligible for a bonus opportunity.\n  \n \n \n   Location(s):\n   United States RemoteCanada Remote", "cleaned_desc": "   You should have\n  \n \n   Research shows that candidates from underrepresented backgrounds often don't apply for roles if they don't meet all the criteria. Remember, you are not solely your resume. Give your transferable skills the chance to tell the full story. Channel the power of YOU and apply to explore the possibility we're the perfect fit.\n  \n \n  Bachelor's degree in Computer Science, Business or equivalent experience required \n  Proficiency in English in a business environment \n  Experience with formulating, writing, and executing TSQL, SQL, or Oracle is required \n  Experience with T-SQL to support project work is required \n  3+ years of Business Analyst experience \n  1+ years of experience in a data transformation environment is a plus \n  Experience in data mining and analysis in a relational database is a plus \n  Ability to work non-standard hours as required \n  Basic knowledge of office software including Word and Excel required \n  Expert technical writing/editing skills required \n  Excellent organizational skills, including ability to consistently adhere to multiple deadlines and frequently changing workload \n  Able to work independently, delivering accurate documentation under deadline pressure \n  Ability to work effectively in a team environment \n  Potential travel as required by business needs ", "techs": ["tsql", "sql", "oracle"]}, "d61554d86942d6d1": {"terms": ["data analyst"], "salary_min": 94400.0, "salary_max": 141600.0, "title": "Compensation Analyst", "company": "HubSpot", "desc": "Do you have an analytical mindset and like to think creatively? Do you have a passion for people and enjoy working with an energetic and supportive team? Would working alongside our managers, directors, and VPs globally to create competitive compensation programs and packages challenge your intellect? HubSpot continues to grow rapidly, and we are seeking a highly autonomous individual to help us grow and scale our Compensation team within the People Operations department. \n  As a Compensation Analyst, you will be a vital part of the team by supporting the design, implementation and day-to-day administration of HubSpot's global compensation programs. In this role, you will be responsible for compensation analysis and administration. \n  What you'll do: \n \n Support the compensation team with the implementation and ongoing administration of innovative compensation programs and policies, making sure everything runs smoothly \n Consult, advise and provide data analysis to the Compensation team, HR Business Partners, and leadership on compensation decisions, design and planning \n Research, analyze, and administer global compensation programs and processes \n Participate in the annual compensation and equity planning processes \n Help us scale, improve and add efficiency to our current programs and processes \n Participate in salary surveys by gathering and analyzing HubSpot compensation data \n Perform job analysis and participate in annual competitive market analysis \n Maintain and audit compensation data in Workday HRIS \n Partner with Finance and Legal teams as it relates to budgets, payroll and equity administration \n Ensure compliance with local labor laws and regulations such as FLSA, statutory country requirements and pay study filings \n Maintain knowledge of latest market trends \n Lead other compensation related activities and projects \n \n We are looking for someone with: \n \n A desire to be part of a high-growth company that leads with HEART (Humble, Empathetic, Adaptable, Remarkable, Transparent) \n 3+ years relevant experience within a global compensation function with knowledge of compensation practices and theory; including experience in compensation program design and project management \n Strong Excel skills with ability to analyze data and see beyond the numbers to help guide decision making \n Experience creating a salary structure and salary ranges for more than one country \n Excellent organizational and analytical skills \n Strong attention to detail and accuracy \n Experience with Workday or other HRIS \n Flexible and consultative approach with ability to balance the data and needs of the business \n Ability to exercise discretion and confidentiality as it pertains to compensation and HR related matters \n Ability to organize and accomplish objectives autonomously and proactively navigate within a growing organization \n \n \n Cash compensation range:  94400-141600 USD Annually    This resource will help guide how we recommend thinking about the range you see. Learn more about HubSpot's compensation philosophy from Katie Burke, HubSpot's Chief People Officer.     The cash compensation above includes base salary, on-target commission for employees in eligible roles, and annual bonus targets under HubSpot's bonus plan for eligible roles. In addition to cash compensation, all HubSpotters are eligible to participate in HubSpot's equity plan to receive restricted stock units (RSUs). Some roles may also be eligible for overtime pay. Individual compensation packages are based on a few different factors unique to each candidate, including their skills, experience, qualifications and other job-related reasons.     We know that benefits are also an important piece of your total compensation package. To learn more about what's included in total compensation, check out some of the benefits and perks HubSpot offers to help employees grow better.     At HubSpot, fair compensation practices isn't just about checking off the box for legal compliance. It's about living out our value of transparency with our employees, candidates, and community. \n \n \n  We know the  confidence gap  and  imposter syndrome  can get in the way of meeting spectacular candidates, so please don't hesitate to apply \u2014 we'd love to hear from you. \n \n \n  If you need assistance or an accommodation due to a disability, please email us at  interviewaccommodation@hubspot.com .  This information will be treated as confidential and used only for the purpose of determining an appropriate accommodation for the interview process. \n \n \n  Germany Applicants:  (m/f/d) - link to HubSpot's Career Diversity page  here . \n \n \n \n About HubSpot \n  HubSpot (NYSE: HUBS) is a leading customer relationship management (CRM) platform that provides software and support to help businesses grow better. We build marketing, sales, service, and website management products that start free and scale to meet our customers' needs at any stage of growth. We're also building a company culture that empowers people to do their best work. If that sounds like something you'd like to be part of, we'd love to hear from you. \n  You can find out more about our company culture in the HubSpot Culture Code, which has more than 5M views, and learn about our commitment to creating a diverse and inclusive workplace, too. Thanks to the work of every employee globally, HubSpot was named the #2 Best Place to Work on Glassdoor in 2022, and has been recognized for award-winning culture by Great Place to Work, Comparably, Fortune, Entrepreneur, Inc., and more. \n  Headquartered in Cambridge, Massachusetts, HubSpot was founded in 2006. Today, thousands of employees work across the globe in HubSpot offices and remotely. Visit our careers website to learn more about culture and opportunities at HubSpot. \n \n By submitting your application, you agree that HubSpot may collect your personal data for recruiting, global organization planning, and related purposes. HubSpot's  Privacy Notice  explains what personal information we may process, where we may process your personal information, our purposes for processing your personal information, and the rights you can exercise over HubSpot's use of your personal information.", "cleaned_desc": " \n A desire to be part of a high-growth company that leads with HEART (Humble, Empathetic, Adaptable, Remarkable, Transparent) \n 3+ years relevant experience within a global compensation function with knowledge of compensation practices and theory; including experience in compensation program design and project management \n Strong Excel skills with ability to analyze data and see beyond the numbers to help guide decision making \n Experience creating a salary structure and salary ranges for more than one country \n Excellent organizational and analytical skills \n Strong attention to detail and accuracy \n Experience with Workday or other HRIS \n Flexible and consultative approach with ability to balance the data and needs of the business ", "techs": ["excel", "workday", "hris"]}, "26486a54b52404d0": {"terms": ["data analyst"], "salary_min": 24.0, "salary_max": 26.0, "title": "Logistics Analyst - Remote", "company": "Stefanini, Inc", "desc": "Stefanini Group is hiring! \n \n \n  Stefanini is looking for Operations Analyst/Logistics Analyst for Deerfield, IL - Remote Location \n \n \n  For quick Apply, please reach out to Bhavishya Yagnik - call: (248) 263-5623 / email: bhavishya.yagnik@stefanini.com \n \n \n \n  Work Hours:  M-F (40 hours)\n  \n \n  Work Location : Deerfield, IL - Remote\n  \n \n  Shift:  1st Shift\n  \n \n \n  Job Description: \n \n \n   Logistics Analyst (Systems and Support)\n  \n \n   Responsible for support of business owned systems and processes throughout the Deployment, Logistics, and Global Transportation organization including:\n  \n \n \n  The development and management of departmental/internal SharePoint sites, setup and maintenance of intercompany export software systems, and support of process documentation. Function also includes support activities such as data analysis, report generation, system testing and special projects. \n \n \n \n \n  Essential Duties and Responsibilities: \n \n \n  Maintain internal SharePoint sites/functions (including interactive lists) \n  Assist in the management of TR ONE SOURCE (global trade management system) setup requests. \n  Assists in the development of policies and procedures \n  Examine effectiveness of strategies and processes, research and provide alternative possibilities. \n  Support continuous improvement initiatives. \n  Participate in, embrace, and promote the EMS culture. \n  Summarizes data for use in reports to business units \n  Analyzes data to provide support for special projects \n  Continuously audits internal systems to ensure compliance \n  Assemble information, analyze, verify, and make recommendations on corrective actions, as necessary. \n \n \n \n \n \n Job Requirement: \n \n \n  BS in Operations/Logistics or similar degree; 0 - 3 years related experience \n  Ability to operate in the complex, international matrixed environment. \n  Requires strong leadership and teamwork skills \n  Project management experience and strong organizational skills \n  Excellent problem solving and analytical skills. \n  Excellent written and oral communication skills. \n  Strong PC computer skills (Word, Excel, etc.). \n \n \n \n  ***Listed salary ranges may vary based on experience, qualifications, and local market. Also, some positions may include bonuses or other incentives*** \n \n \n \n  Stefanini takes pride in hiring top talent and developing relationships with our future employees. Our talent acquisition teams will never make an offer of employment without having a phone conversation with you. Those face-to-face conversations will involve a description of the job for which you have applied. We also speak with you about the process including interviews and job offers.\n  \n \n \n  About Stefanini Group \n \n \n   The Stefanini Group is a global provider of offshore, onshore, and near shore outsourcing, IT digital consulting, systems integration, application, and strategic staffing services to Fortune 1000 enterprises around the world. Our presence is in countries like the Americas, Europe, Africa, and Asia, and more than four hundred clients across a broad spectrum of markets, including financial services, manufacturing, telecommunications, chemical services, technology, public sector, and utilities. Stefanini is a CMM level 5, IT consulting company with a global presence. We are CMM Level 5 company.", "cleaned_desc": "", "techs": ""}, "9dab4e7b014ee17d": {"terms": ["data analyst"], "salary_min": 80000.0, "salary_max": 130000.0, "title": "Business Analyst-Oracle inventory, Supply Chai and BPMN2.0", "company": "GrayAcumen Inc.", "desc": "Business Analyst-Oracle inventory, Supply Chai and BPMN2.0 \n Position-1 \n Location-Remote(Onsite) \n Exp-8-10 years \n JD: \n \n Good understanding of Oracle Supply Chain (Inventory and Shipping Module) \n \n \n Knowledge of the BPMN2.0 standard should be able to develop flows using BPMN2.0. \n \n \n Ability to mine data from Oracle, Snowflake, and Salesforce \n \n \n Ability to recognize patterns and trends in large data sets. \n \n \n Exceptional presentation, research, and verbal and written communication. \n \n \n Ability to summarize and explain complex information to other \n \n Job Type: Full-time \n Salary: $80,000.00 - $130,000.00 per year \n Compensation package: \n \n Bonus opportunities \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n BPMN2.0: 5 years (Preferred) \n Oracle inventory, Supply Chain: 5 years (Preferred) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "d8b2eaeba9633c2b": {"terms": ["data analyst"], "salary_min": 49800.0, "salary_max": 102000.0, "title": "Project Control Analyst, Mid", "company": "Booz Allen Hamilton", "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Chantilly,VA,US \n         \n \n \n \n         Remote Work: \n         \n \n         Hybrid \n         \n \n \n \n         Job Number: \n         \n \n         R0181074\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Project Control Analyst, Mid\n           The Opportunity:  \n The right mixture of great ideas and funding can create change. In a complex organization, allocating funding to where it can be most effective can be challenging. That\u2019s why we need you, a financial analyst who can navigate the requirements, policies, and regulations that govern funding, to make sure Space and Intel resources can make the most impact. \n \n  As a financial analyst on our team, you\u2019ll will be responsible for a wide variety of detailed financial and administrative activities for moderate-to-large sized programs, organizations, or proposals. You\u2019ll perform detailed financial and program control activities, including budgeting, reporting, estimating, and analysis for full contract life cycle support. You\u2019ll prepare budgets, authorize budget expenditures, provide work leadership to junior employees, participate in budget preparation, monitor expenses, perform cost and schedule variance analysis, and provide resulting recommendations. You\u2019ll prepare the cost-to-complete, including supporting estimates and contract deliverables, respond to contract and program data calls, and participate in contract terms and conditions and statement of work reviews. You\u2019ll also prepare detailed financial program management reviews, provide a status of key performance metrics for the firm, anticipate and respond to customer needs, and serve as a primary point of contact for customers. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  Experience with financial modeling, including funding analyses, and cost and revenue projections \n  Knowledge of Microsoft Excel, including using formulas and functions in calculation and analysis \n  Ability to identify, research, discuss, and resolve administrative and financial issues independently and as part of a team, set priorities that balance service and control, and manage and track multiple initiatives \n  Ability to be a team player, work in a dynamic and fast-paced environment, and adapt to changing requirements \n  Ability to think analytically and conduct trend analysis \n  Ability to accomplish financial forecasts based on bottoms-up analysis and historical trends \n  Ability to identify program risks, assist with associated mitigation plans, and assist with identifying and prioritizing requirements \n  Ability to collect and analyze data from multiple sources, summarize it, and read and interpret contractual requirements appropriately \n  Active TS/SCI clearance; willingness to take a polygraph exam \n  HS diploma or GED and 6+ years of experience with financial management or in a financial program control environment, Associate\u2019s degree and 4+ years of experience with financial management or in a financial program control environment, or Bachelor\u2019s degree and 2+ years of experience with financial management or in a financial program control environment \n \n \n  Nice If You Have:  \n \n Possession of excellent verbal and written communication skills \n  Possession of excellent organizational, analytical, and problem-solving skills \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance is required. \n \n  Create Your Career: \n \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll build your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $49,800.00 to $102,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.", "cleaned_desc": "", "techs": ""}, "43d22759ea8d7751": {"terms": ["data analyst"], "salary_min": 79340.0, "salary_max": 126940.0, "title": "Lead Rebate Business Analyst- REMOTE", "company": "Prime Therapeutics", "desc": "Our work matters. We help people get the medicine they need to feel better and live well. We do not lose sight of that. It fuels our passion and drives every decision we make.\n  \n \n \n   Job Posting Title\n  \n  Lead Rebate Business Analyst- REMOTE\n  \n \n   Job Description Summary\n  \n  Serves as liaison between departmental team business owners, end users, IT, Claims and Clinical departments. Responds to ad hoc requests for support, reports and analysis. Supports departmental management team by providing trending and performance data. Supports special projects. Maintains and monitors reporting queues and requests (if appropriate), and internal share point sites. May participate in full life cycle development by performing requirements analysis, process development and design, and testing using development methodology. Collaborates with functional teams, as well as with IT business analysts and programmers to develop detailed design specifications according to standards.\n  \n \n   Job Description\n  \n \n  Develops and documents workflow, systems requirements, system impact analysis, systems design, process analysis and testing (including reasonableness checks) using software development methodology to provide efficient, cost-effective solutions as directed. \n  Identifies impact of solutions on existing and future systems. \n  May perform operational activities. \n  Creates and maintains standard related reports to support operational and development needs. \n  Manages reporting and requests for ad hoc reports to support sales, implementation, new product development, specials. \n  Queries data warehouse and internal databases and prepares user friendly reports according to requestors' requirements. \n  Creates and maintains internal management tools and databases to support CQI, rates, workflow business rules and system configuration, reimbursement and document management requirements. \n  Develops and maintains project plans. \n  Manages small to medium sized projects, system enhancements impacting data management. \n  Conducts root cause analyses, gathering data to pinpoint problem areas on which to focus, validating that the analysis is data driven, recommending and implementing solutions and evaluating those results, and implementing controls to monitor consistent use of the solution. \n  Participates in design plans for implementation, produces user documentation and training materials. \n  Responsible for keeping up with latest software trends. \n  May conduct end user training. \n  Provides status reports that give a detailed description of the current project's progress and indicates time devoted to each task of the project; leads status meetings, creating agendas and documenting meeting minutes as needed. \n  Identifies reporting needs based on system configuration and workflows and documents reporting requirements and testing of new reports in development prior to implementation to Production. \n  Participates in initiatives or projects that support process improvements, leveraging new system capabilities or the integration of data/other applications into existing systems. \n  Performs other duties as assigned. \n \n \n \n   Responsibilities\n  \n \n  Minimum of 4 years of systems analysis experience in appropriate technical environment. \n \n \n  7+ years of directly related experience. \n  Related professional experience in the managed care, healthcare, or insurance industries. \n  Analytical/problem solving skills, excellent verbal and written communication skills, strong PC background, efficient in using standard software. \n  Knowledge of system process analysis and/or program management, estimating IT system development and testing. \n  For positions supporting Medicare, requires 5+ years of experience working in Medicare Operations. \n \n \n \n   Work Experience\n  \n \n   Work Experience - Required:\n   Business Analysis\n  \n \n   Work Experience - Preferred:\n  \n \n \n   Education\n  \n \n   Education - Required:\n   A Combination of Education and Work Experience May Be Considered., Bachelors\n  \n \n   Education - Preferred:\n  \n \n \n   Certifications\n  \n \n   Certifications - Required:\n  \n \n \n   Certifications - Preferred:\n  \n  Potential pay for this position ranges from $79,340.00 - $126,940.00 based on experience and skills. Pay range may vary by 8% depending on applicant location.\n  \n \n  Prime Therapeutics LLC is an Equal Opportunity Employer. We encourage diverse candidates to apply and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy), sexual orientation, gender identity or expression, genetic information, marital status, family status, national origin, age, disability, veteran status, or any other legally protected class under federal, state, or local law.", "cleaned_desc": " \n \n \n   Responsibilities\n  \n \n  Minimum of 4 years of systems analysis experience in appropriate technical environment. \n \n \n  7+ years of directly related experience. \n  Related professional experience in the managed care, healthcare, or insurance industries. \n  Analytical/problem solving skills, excellent verbal and written communication skills, strong PC background, efficient in using standard software. \n  Knowledge of system process analysis and/or program management, estimating IT system development and testing. \n  For positions supporting Medicare, requires 5+ years of experience working in Medicare Operations. \n \n \n ", "techs": ["none"]}, "a1416c041c4a8f36": {"terms": ["data analyst"], "salary_min": null, "salary_max": null, "title": "Senior Data Governance Analyst", "company": "Freedom Mortgage", "desc": "Roles and Responsibilities \n \n  Engage data owners and data stewards, business users, and the data management teams to ensure Data Governance and Quality processes are implemented and managed, including updating and maintaining documentation, identifying, and documenting critical data elements, preparing, and managing business and technical metadata, defining data quality thresholds, and the identifying and triaging data integrity issues. \n  Develop, enhance, and enforce data governance policies, standards, and procedures, driving best practices in data management. \n  Responsible for the administration of data governance and quality software, maintaining a corporate data dictionary, ensuring data quality standards are met. \n  Organizes, coordinates, and assists cross-functional teams in planning, development, and promote Data Stewardship practices throughout the Organization. \n  Measure progress against data definition and quality performance targets, following up with business representatives, as necessary. \n  Builds enterprise dashboards and reporting to ensure proper communicate of the Data Governance program performance. \n  Act as a change agent with a capacity to successfully measure progress by providing training and guidance to staff, fostering a culture of data accountability and awareness of data governance principles. \n \n \n  Qualifications \n \n  5+ years of experience in a Data Governance, Data Management, or data centric role. \n  Ability to design and recommend Data Governance structures and control frameworks for the ongoing management of data. \n  Strong communication and interpersonal skills. \n  Ability to work effectively in a team environment and translate business needs into functional and/or technical requirements to meet the needs of the enterprise. \n  Strong knowledge and understanding of data governance and data quality and how they affect business decisions. \n  Ability to perform root cause analysis and make recommendations for the remediation of data governance and quality issues. \n  Knowledge of industry leading data quality and data management practices and tools. \n  Ability to extract and analyze data via SQL. \n  Experience with business intelligence tools such as (but not limited to) Tableau, Qlik or Power BI. \n  Highly proficient in data profiling techniques and tools. \n  Proven skills with Microsoft Office suite, especially Excel required \n  Personal initiative to find opportunities, lead change, improve processes and solve problems \n  Proven ability to collaborate with business data SME\u2019s throughout the organization. \n  Proven track record of meeting commitments with the highest standards of ethics and integrity \n  Must be self-directed and have excellent initiative and organization skills. \n  Experience in banking or mortgage industry is preferred. \n \n \n \n  Remote", "cleaned_desc": "Roles and Responsibilities \n \n  Engage data owners and data stewards, business users, and the data management teams to ensure Data Governance and Quality processes are implemented and managed, including updating and maintaining documentation, identifying, and documenting critical data elements, preparing, and managing business and technical metadata, defining data quality thresholds, and the identifying and triaging data integrity issues. \n  Develop, enhance, and enforce data governance policies, standards, and procedures, driving best practices in data management. \n  Responsible for the administration of data governance and quality software, maintaining a corporate data dictionary, ensuring data quality standards are met. \n  Organizes, coordinates, and assists cross-functional teams in planning, development, and promote Data Stewardship practices throughout the Organization.   \n  5+ years of experience in a Data Governance, Data Management, or data centric role. \n  Ability to design and recommend Data Governance structures and control frameworks for the ongoing management of data. \n  Strong communication and interpersonal skills. \n  Ability to work effectively in a team environment and translate business needs into functional and/or technical requirements to meet the needs of the enterprise. \n  Strong knowledge and understanding of data governance and data quality and how they affect business decisions.    Ability to perform root cause analysis and make recommendations for the remediation of data governance and quality issues. \n  Knowledge of industry leading data quality and data management practices and tools. \n  Ability to extract and analyze data via SQL. \n  Experience with business intelligence tools such as (but not limited to) Tableau, Qlik or Power BI. \n  Highly proficient in data profiling techniques and tools. \n  Proven skills with Microsoft Office suite, especially Excel required ", "techs": ["tableau", "qlik", "power bi", "sql", "microsoft office suite"]}, "d3422d27f93fa801": {"terms": ["data analyst"], "salary_min": 70.0, "salary_max": -1.0, "title": "Business Analyst for CRM (Dynamics 365)/AMS - Part-time contract (urgent)", "company": "AMS", "desc": "Part time opportunity for Business Analyst for an AMS/CRM project - \n At least six years of experience as a BA \n - Part time - approximately 20 hours/week \n - Knowledge of Microsoft Dynamics 365 CRM \n - Experience in association industry will be preferred \n - Experience in Protech, Cobalt or any other AMS will be a plus \n - Liaison between the technical team and business users \n - Strong communication and documentation skills \n - Experienced in the Agile methodology \n - Basic to intermediate-level SQL experience; ability to work data will be a plus \n - Experience in CRM/AMS implementation projects will be preferred \n Provide your resume and hourly rate. \n Job Types: Contract, Full-time \n Pay: From $70.00 per hour \n Experience level: \n \n 6 years \n \n Schedule: \n \n Day shift \n \n Experience: \n \n Dynamics 365 CRM: 2 years (Required) \n Association: 1 year (Preferred) \n BA: 6 years (Required) \n \n Work Location: Remote", "cleaned_desc": " - Experience in Protech, Cobalt or any other AMS will be a plus \n - Liaison between the technical team and business users \n - Strong communication and documentation skills \n - Experienced in the Agile methodology \n - Basic to intermediate-level SQL experience; ability to work data will be a plus ", "techs": ["protech", "cobalt", "ams", "agile methodology", "sql"]}, "e9af6b6801736f80": {"terms": ["data analyst"], "salary_min": 88439.63, "salary_max": 111984.27, "title": "Sr. Business Analyst", "company": "Index Analytics LLC", "desc": "Company Overview \n Index Analytics LLC is a rapidly growing Baltimore-based small business providing health related consulting services to the federal government. At the center of our company culture is a commitment to providing a dynamic and employee-friendly place to work. We place a priority on promoting a supportive and collegial team environment and enhancing staff\u2019s experience through career development and educational opportunities. \n Position Overview \n Index Analytics is seeking a Senior Business Process Analyst to support Government clients in the Baltimore and Washington D.C. Metro Area. The Senior Business Process Analyst will collaborate with our customers to define product requirements, develop a product understanding, and communicate effectively to both business and technical audiences to deliver solutions. \n Responsibilities \n \n Identify and validate clients\u2019 business needs and Salesforce application requirements \n Support project managers with managing the client relationship and deliverables \n Work with stakeholders to define product vision and Salesforce application requirements \n Attend requirements gathering meetings with the client to identify business needs, functional and system requirements \n Collaborate with the development and testing team to ensure implementation of the needed business, functional and system requirements \n Provide regular and open communication across the program and stakeholders for transparency and awareness of progress and impediments \n Understand, visualize, and manage upstream/downstream dependencies \n Drive delivery and continuous improvement by utilizing feedback and metrics to identify areas of opportunity \n Communicate requirements to developers, testers, and stakeholders \n Demonstrate product functionality to stakeholders \n \n Responsibilities \n \n US citizen, or lived in the US for 3 of the last 5 years with an ability to obtain Public Trust level clearance \n Previous experience with Salesforce preferred \n Bachelor\u2019s degree with 6 years of overall work experience including at least 4 years of experience managing requirements and backlog. \n Prior experience with Center for Medicare Medicaid Services or other Govt agencies is a plus \n Agile certifications preferred \n Demonstrated ability to break down complex requirements into actionable work items \n Knowledge and experience of Agile software development methodology \n Demonstrated ability to work with engineering and analytics teams to discuss technical concepts, make tradeoffs to remove roadblocks, and evaluate new ideas \n Ability to demonstrate excellent written and oral communication required \n Understanding of system and document 508 requirements strongly preferred \n \n Index Analytics provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. \n Job Type: Full-time \n Benefits: \n \n 401(k) \n 401(k) 3% Match \n AD&D insurance \n Dental insurance \n Flexible spending account \n Health insurance \n Health savings account \n Life insurance \n Paid time off \n Vision insurance \n Work from home \n \n Experience level: \n \n 6 years \n \n Schedule: \n \n 8 hour shift \n \n Work Location: Remote", "cleaned_desc": " Previous experience with Salesforce preferred \n Bachelor\u2019s degree with 6 years of overall work experience including at least 4 years of experience managing requirements and backlog. \n Prior experience with Center for Medicare Medicaid Services or other Govt agencies is a plus \n Agile certifications preferred \n Demonstrated ability to break down complex requirements into actionable work items \n Knowledge and experience of Agile software development methodology \n Demonstrated ability to work with engineering and analytics teams to discuss technical concepts, make tradeoffs to remove roadblocks, and evaluate new ideas \n Ability to demonstrate excellent written and oral communication required \n Understanding of system and document 508 requirements strongly preferred \n ", "techs": ["salesforce", "center for medicare medicaid services", "agile certifications", "agile software development methodology", "engineering", "analytics", "system and document 508 requirements"]}, "567ce152d7871aac": {"terms": ["data analyst"], "salary_min": 84474.914, "salary_max": 106964.07, "title": "Technical Business Analyst", "company": "RSA Conference", "desc": "Technical Business Analyst \n \n  RSA Conference\u2122 is the premier series of global events and year-round learning for the cybersecurity community. RSAC is where the security industry converges to discuss current and future concerns and have access to the experts, unbiased content and ideas that help enable individuals and companies advance their cybersecurity posture and build stronger and smarter teams. Both in-person and online, RSAC brings the cybersecurity industry together and empowers the collective \u201cwe\u201d to stand against cyberthreats around the world. RSAC is the ultimate marketplace for the latest technologies and hands-on educational opportunities that help industry professionals discover how to make their companies more secure while showcasing the most enterprising, influential and thought-provoking thinkers and leaders in cybersecurity today.  \n We are looking for a Technical Business Analyst to join our technology team and help us deliver innovative and effective website properties. The technical business analyst will be responsible for working with the marketing team and other teams to define business needs and translate them into functional specifications. The technical business analyst will also collaborate with the development team and other stakeholders to ensure the delivery of the solutions that meet the business requirements and expectations. \n  In This Role, You Will \n \n  Work with the technology and marketing teams to understand the business goals, challenges, and opportunities of the RSAC website and related projects. \n  Facilitate market research, competitor analysis, customer feedback, and data analysis to identify the business needs and opportunities. \n  Define and document the business needs and requirements using various techniques such as user stories, use cases, personas, etc. \n  Translate the business needs and requirements into functional specifications. \n  Communicate and collaborate with the development team, marketing team, and other stakeholders to ensure the alignment of the functional specifications with the technical feasibility and capabilities. \n  Review and validate the solutions delivered by the development team and provide feedback and suggestions for improvement. \n  Conduct user acceptance testing and quality assurance testing to ensure the solutions meet the business needs and requirements. \n  Create and manage processes and workflows to facilitate communication between Marketing and Technology teams. \n  Utilize Jira and Confluence as part of the Agile process. \n \n  Your Profile \n \n  Bachelor\u2019s degree in marketing, business, information systems, or related field. \n  Minimum 5 years of experience in technical business analysis or related roles in digital marketing domain. \n  Proven experience in defining and translating business needs and requirements into functional specifications for digital marketing solutions. \n  Strong knowledge of digital marketing concepts, strategies, channels, tools, and best practices. \n  Worked in the Agile framework and utilized tools such as Jira and Confluence. \n  Experience in market research, competitor analysis, product research, and customer feedback. \n  Experience in wireframes, mockups, prototypes, or other functional specification techniques. \n  Experience working with content management systems, preferably Sitecore  \n Experience in user stories, use cases, and personas is a plus. \n  Excellent communication, analytical, and problem-solving skills. \n  Ability to work independently and as part of a team. \n \n  Benefits \n  RSAC believes in investing in our people. We offer: \n \n  Competitive salary, benefits, and perks for all full-time employees \n  Employer-subsidized medical, dental and vision insurance \n  401K retirement employer match \n  Home office equipment stipend and monthly technology stipend \n  Thirteen paid holidays per calendar year \n  Unlimited personal time off \n  Annual employee bonus dependent upon overall company and personal performance \n  Annual company-wide offsite \n \n  Our Culture \n  We believe that our differences make us stronger, and we are committed to fostering a culture of respect, empathy, and understanding. \n \n  We are a fully remote team operating across the United States, giving our employees the flexibility to work from wherever they choose. \n  Our team is passionate and results-oriented, striving to achieve excellence in everything we do. \n  We strongly believe in creating an inclusive environment that values diversity and encourages our team members to share their unique perspectives. \n  We recognize that by collaborating and working together, we can achieve our goals faster and more effectively. \n \n \n  Why RSAC? \n  The RSAC team takes great pride in helping shape the future of cybersecurity and being part of an expansive global community! We're always looking for imaginative and visionary individuals who share our passion for providing cutting-edge programs that equip cybersecurity practitioners worldwide with the intel and knowledge they need to thrive and safeguard organizations against cyberthreats. \n  Our Values \n \n  Adaptability:  In our ever-changing world, we innovate through determination, creativity and resourcefulness. \n  Community:  We bring people together and build trust by embracing the unique thoughts and perspectives of others with kindness and respect. \n  Excellence:  Because we are where the world talks security, we have the highest expectations of ourselves and our partners. \n \n   \n   \n DFivOOuaj9", "cleaned_desc": "", "techs": ""}, "a42f565c469df763": {"terms": ["data analyst"], "salary_min": 50.0, "salary_max": 60.0, "title": "Data Extraction Analyst from SAP HANA to Snowflake or Talend", "company": "Formac Inc", "desc": "Data Extractors  Talend/Snowflake and SAP S/4 HANA Engineers \n REMOTE \n Long TERM \n 60 per HR All inclusive (Open to discuss for Sr Resources) \n We are looking for 4 resources who worked mainly on Data Extraction on Fallowing areas \n \n Need resource who has expertise on Data extraction from SAP S4 HANA to Snowflake \u2013 2 Profiles \n Need resource who has expertise on Data extraction from SAP S4 HANA to Talend \u2013 2 Profiles \n \n Thanks \n Jay \n 628-215-2224 \n Job Types: Full-time, Contract \n Pay: $50.00 - $60.00 per hour \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n \n Experience level: \n \n 5 years \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Application Question(s): \n \n best number and time to connect \n \n Education: \n \n Bachelor's (Preferred) \n \n Experience: \n \n data extraction: 4 years (Required) \n SAP HANA: 1 year (Required) \n sap Hana to snowflake: 1 year (Preferred) \n sap hana to talend: 1 year (Preferred) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "f4f73bed9988c864": {"terms": ["data analyst"], "salary_min": 87264.0, "salary_max": 130896.0, "title": "Bus Info Analyst Sr (US)", "company": "Elevance Health", "desc": "Job Family: Data Warehousing and Business Information  \n Type: Full time \n Date Posted: Oct 18, 2023  \n Req #: JR91828 \n \n \n \n Description \n The  Business Information Analyst Sr  is responsible for analyzing, reporting and developing recommendations on data related to complex and varied business metrics and providing guidance to other data analysts. The  Provider Insights  team within  Health Economics  is looking for high-performing, high-potential Business Information Analyst Sr. who is ready to use technology to tell stories and positively impact healthcare. The Provider Insights team works closely with our users to create the reports they need, as well as educate and assist them with using the reports. Members of our team have the technical expertise to produce relevant, actionable information for our stakeholders. But we also communicate and collaborate with our users, to engage them and to add value to their experience. Our team works with diverse departments within Elevance Health to generate Tableau dashboard reports that identify cost of care opportunities, business trends and context. We write code to pull together data from a wide array of data sources within the company and then build user friendly dashboards for business users and other analysts. We are looking for someone who can work well with both non-technical and technical stakeholders on every phase of a project from requirement specifications, to data build, to dashboard design, to training and support. Business areas supported include Contracting (Professional, Facility, and Network Analytics), Collaboration (Value-Based Payment and Population Health Management), Government Business Division (Medicare and Medicaid), and Customer (Employer groups).  \n Primary duties may include, but are not limited to:  \n \n Creates and maintains databases to track business performance.  \n Analyzes data and summarizes performance using summary statistical procedures.  \n Develops and analyzes business performance reports (e.g. for claims data, provider data, utilization data) and provides notations of performance deviations and anomalies.  \n Creates and publishes periodic reports, as well as any necessary ad hoc reports.  \n May require taking business issue and devising best way to develop appropriate diagnostic and/or tracking data that will translate business requirements into usable decision support tools.  \n May make recommendations based upon data analysis.  \n Provides analytic consultation to other business areas, leadership or external customers.  \n Uses SQL/SAS/Snowflake to create, maintain and manipulate databases to track business performance.  \n \n Minimum Qualifications  \n Requires a BS/BA degree in related field and a minimum of 3 years data analysis or related experience; or any combination of education and experience which would provide an equivalent background.  \n Preferred Skills, Capabilities, and Experiences:  \n \n Experience with relational databases and knowledge of query tools and statistical software is strongly preferred.  \n Ability to manipulate large sets of data strongly preferred.  \n Strong analytical, organizational, presentation, and problem solving skills strongly preferred.  \n SQL, Tableau, SAS and Snowflake strongly preferred.  \n Healthcare and Value Based background preferred.  \n \n For candidates working in person or remotely in the below locations, the salary* range for this specific position is $87,264 to $130,896.  \n Locations: California; Colorado; Nevada; New York; Washington State; Jersey City, NJ  \n In addition to your salary, Elevance Health offers benefits such as, a comprehensive benefits package, incentive and recognition programs, equity stock purchase and 401k contribution (all benefits are subject to eligibility requirements). The salary offered for this specific position is based on a number of legitimate, non-discriminatory factors set by the company. The company is fully committed to ensuring equal pay opportunities for equal work regardless of gender, race, or any other category protected by federal, state, and local pay equity laws  .  \n \n The salary range is the range Elevance Health in good faith believes is the range of possible compensation for this role at the time of this posting. This range may be modified in the future and actual compensation may vary from posting based on geographic location, work experience, education and/or skill level. Even within the range, the actual compensation will vary depending on the above factors as well as market/business considerations. No amount is considered to be wages or compensation until such amount is earned, vested, and determinable under the terms and conditions of the applicable policies and plans. The amount and availability of any bonus, commission, benefits, or any other form of compensation and benefits that are allocable to a particular employee remains in the Company's sole discretion unless and until paid and may be modified at the Company\u2019s sole discretion, consistent with the law.   \n \n \n Please be advised that Elevance Health only accepts resumes from agencies that have a signed agreement with Elevance Health. Accordingly, Elevance Health is not obligated to pay referral fees to any agency that is not a party to an agreement with Elevance Health. Thus, any unsolicited resumes, including those submitted to hiring managers, are deemed to be the property of Elevance Health. \n  Be part of an Extraordinary Team \n  Elevance Health is a health company dedicated to improving lives and communities \u2013 and making healthcare simpler. A Fortune 20 company with a longstanding history in the healthcare industry, we are looking for leaders at all levels of the organization who are passionate about making an impact on our members and the communities we serve. You will thrive in a complex and collaborative environment where you take action and ownership to solve problems and lead change. Do you want to be part of a larger purpose and an evolving, high-performance culture that empowers you to make an impact? \n  We offer a range of market-competitive total rewards that include merit increases, paid holidays, Paid Time Off, and incentive bonus programs (unless covered by a collective bargaining agreement), medical, dental, vision, short and long term disability benefits, 401(k) +match, stock purchase plan, life insurance, wellness programs and financial education resources, to name a few. \n  Elevance Health operates in a Hybrid Workforce Strategy, providing various levels of flexibility while also ensuring that associates have opportunities to connect in-person. Unless in a designated virtual-eligible role and specified as primarily virtual by the hiring manager, associates are required to work at an Elevance Health location at least once per week, and potentially several times per week. Specific requirements and expectations for time onsite will be discussed as part of the hiring process. Candidates must reside within 50 miles or 1-hour commute each way of a relevant Elevance Health location. \n  The health of our associates and communities is a top priority for Elevance Health. We require all new candidates in certain patient/member-facing roles to become vaccinated against COVID-19. If you are not vaccinated, your offer will be rescinded unless you provide \u2013 and Elevance Health approves \u2013 a valid religious or medical explanation as to why you are not able to get vaccinated that Elevance Health is able to reasonably accommodate. Elevance Health will also follow all relevant federal, state and local laws. \n  Elevance Health has been named as a Fortune Great Place To Work in 2022, has been ranked for five years running as one of the 2023 World\u2019s Most Admired Companies by Fortune magazine, and is a growing Top 20 Fortune 500 Company. To learn more about our company and apply, please visit us at careers.ElevanceHealth.com. Elevance Health is an Equal Employment Opportunity employer and all qualified applicants will receive consideration for employment without regard to age, citizenship status, color, creed, disability, ethnicity, genetic information, gender (including gender identity and gender expression), marital status, national origin, race, religion, sex, sexual orientation, veteran status or any other status or condition protected by applicable federal, state, or local laws. Applicants who require accommodation to participate in the job application process may contact ability@icareerhelp.com for assistance.", "cleaned_desc": " Experience with relational databases and knowledge of query tools and statistical software is strongly preferred.  \n Ability to manipulate large sets of data strongly preferred.  \n Strong analytical, organizational, presentation, and problem solving skills strongly preferred.  \n SQL, Tableau, SAS and Snowflake strongly preferred.  \n Healthcare and Value Based background preferred.  \n \n For candidates working in person or remotely in the below locations, the salary* range for this specific position is $87,264 to $130,896.  \n Locations: California; Colorado; Nevada; New York; Washington State; Jersey City, NJ  ", "techs": ["sql", "tableau", "sas", "snowflake"]}, "be426dcc9e028088": {"terms": ["data analyst"], "salary_min": 82201.29, "salary_max": 104085.15, "title": "Business Analyst IV - IT - Contract (REMOTE)", "company": "Co-op Solutions", "desc": "Job Description\n   \n \n \n \n \n \n  The Opportunity \n  We are seeking a talented and experienced  Business  Analyst IV  whose role is to utilize their consultative abilities to make recommendations on tasks and techniques used to work as a liaison between technology and business side stakeholders with the goal of driving the delivery of new and enhanced processes, products, and services on time and within budget. \n \n  Day in the Life \n \n  Create, refine, and maintain the User Stories/Requirements for a project, map the user stories to features, develop epics and features, define the acceptance criteria, and lead story estimations. \n  Maintain, manage, and refine a prioritized backlog in partnership with the Product Owner \n  Advise the team members on Agile (Scrum or Kanban, as applicable) best practices and analysis techniques & tools. \n  Apply knowledge of project planning concepts and project management techniques to assist in small projects and/or group initiatives. \n  Utilizes advanced techniques to encourage cross functional team collaboration and creates an environment of open and honest communication to help the team embrace changes, manage complexities, and meet deliverables and deadlines on medium to large projects.  \n Facilitates high-level meetings with stakeholders and executives to discuss overall project and business strategies and roadmaps.  \n Foundational understanding of API technologies and data flows to translate technical jargon between the Product Owner, QA analysts, developers and the stakeholders of the business so that all partners are working towards a common goal.  \n Utilizes advanced emotional intelligence skills and active listening skills when communicating and building relationships with multiple stakeholders and vendor partners  \n Develops and delivers multi-mode communications that convey a clear understanding of the unique needs of different audiences, asks good questions, and gives appropriate context and details when speaking. \n  Utilizes advanced critical/analytical thinking skills to identify process gaps and potential project risks, then takes a consultative approach to brainstorming solutions with the team.  \n Ensure compliance with all the audit requirements of the company. \n  Collect, compile, and analyze data from various sources to identify trends, patterns, and insights that can inform decision-making, then has the ability to present these findings to leadership teams. \n  Create complex SQL queries and help map the data elements as needed, collaborate with multiple stakeholders to elicit requirements and lead story estimation for data or application development projects. \n \n \n  Experience \n \n  4-year degree and 10+ years\u2019 of experience \n  5+ years\u2019 writing SQL queries \n  5+ years\u2019 experience in modeling / mapping business processes. \n  5+ years\u2019 experience planning and facilitating UAT for projects and enhancements. \n  Knowledge of financial domain a plus. \n  Experience with Azure Development Ops (ADO) or JIRA is a plus.", "cleaned_desc": "  Create, refine, and maintain the User Stories/Requirements for a project, map the user stories to features, develop epics and features, define the acceptance criteria, and lead story estimations. \n  Maintain, manage, and refine a prioritized backlog in partnership with the Product Owner \n  Advise the team members on Agile (Scrum or Kanban, as applicable) best practices and analysis techniques & tools. \n  Apply knowledge of project planning concepts and project management techniques to assist in small projects and/or group initiatives. \n  Utilizes advanced techniques to encourage cross functional team collaboration and creates an environment of open and honest communication to help the team embrace changes, manage complexities, and meet deliverables and deadlines on medium to large projects.  \n Facilitates high-level meetings with stakeholders and executives to discuss overall project and business strategies and roadmaps.     Create complex SQL queries and help map the data elements as needed, collaborate with multiple stakeholders to elicit requirements and lead story estimation for data or application development projects. \n \n \n  Experience \n \n  4-year degree and 10+ years\u2019 of experience ", "techs": ["user stories/requirements", "epics", "features", "acceptance criteria", "story estimations", "prioritized backlog", "agile (scrum or kanban)", "project planning", "project management", "small projects", "group initiatives", "cross-functional team collaboration", "communication", "stakeholder meetings", "sql queries", "data elements", "stakeholders", "application development."]}, "7c873f4c2876beb8": {"terms": ["data analyst"], "salary_min": 91059.34, "salary_max": 115301.42, "title": "Centura Business Analyst", "company": "GalaxE.Solutions", "desc": "What You Will Do: \n  \n Gather business requirements and solutions from the design stage to delivery. \n  Manage multiple projects and effectively communicate status updates with Project Managers \n  Detail and explain methodology used in analyses as requested by Project Managers \n  Write Use Cases and specifications for changes. \n  Develop test plans and be involved in testing implemented changes. \n  Skills and Experience You Will Need: \n  \n   Required\n  \n \n  Excellent communication skills \u2013 written, spoken, presentation and listening with ability to explain and interpret complex issues clearly. \n  Experience with Centura 6.2 or 7.2 \n  Possess the ability to document and communicate complex process flows. \n  Proven experience in understanding the scalability of a growing business and implementing changes to deliver award-winning customer support solutions in a dynamic high growth business. \n  Able to clearly articulate and effectively write business requirements. \n  Write use cases or specifications for changes. \n  Able to document processes, road maps, and use cases. \n  Define and create test conditions and plans. \n \n  Desired: \n \n  Experience with Gupta SQL \n  Who We Are: \n   GalaxE.Solutions \n \n   GalaxE is a professional IT services firm that specializes in platform-driven solutions and the use of automation to achieve enterprise business transformation and mission-critical change for some of the largest companies in the world. Using our proprietary solution set, \n   GxFource\u00ae,  we apply machine learning techniques and predictive analytics tools as part of a broad artificial intelligence strategy that provides effective impact and data-driven business transformation.\n  \n \n \n \n \n  Since its founding, GalaxE has been dedicated to advancing the benefits of technology. As we continue that legacy and look to the future, a focus on business enablement through agile, cost-efficient, and effective integration of people, process, and technology anchors our success. We revolutionize change in the costs of doing business that transform companies and their ability to leap beyond the competition.\n  \n \n \n  At GalaxE we value people and are committed to diversity and inclusion where our employees are made to feel comfortable and are encouraged to be authentic. We focus on cultivating both traditional IT and non-traditional, new collar, workers through our \n   Outsource to America\u00ae,  program.\n  \n \n   We are always looking for passionate, entrepreneurial-minded innovators and disrupters; game-changers that take ownership of the work they produce and bring it each and every day. Working with like-minded team members you will get a chance to discover, develop, and use cutting-edge technologies to transform the way we deliver creative business solutions.\n  \n \n \n  Sound like you? Join us and find out for yourself what it means for you, and your career, to be part of the GalaxE team. Let\u2019s build something, together. \n   #WeAreGalaxE \n \n \n \n  Equal Opportunity Employer/Veterans/Disabled \n \n \n \n  Physical Requirements: \n \n \n  Prolonged periods of remaining stationary at a desk and working on a computer \n  Must be able to lift to 15 lbs., as needed \n  Must be able to work on-site (corporate/client offices), as needed (not applicable for 100% remote roles) \n  Occasionally required to bend, kneel, crouch, and reach overhead. \n  Hand-eye coordination necessary to operate computers and various pieces of office equipment.  \n Specific vision abilities required include close vision, the ability to tolerate fluorescent lighting, and the ability to adjust focus. \n \n \n   Employees must be able to perform the physical requirements of the position satisfactorily and, if requested, reasonable accommodations will be made to enable employees requiring accommodations to perform the essential functions of their jobs, absent undue hardship.\n  \n \n \n  For more information, please visit https://www.galaxe.com/", "cleaned_desc": "What You Will Do: \n  \n Gather business requirements and solutions from the design stage to delivery. \n  Manage multiple projects and effectively communicate status updates with Project Managers \n  Detail and explain methodology used in analyses as requested by Project Managers \n  Write Use Cases and specifications for changes. \n  Develop test plans and be involved in testing implemented changes. \n  Skills and Experience You Will Need: \n  \n   Required\n  \n \n  Excellent communication skills \u2013 written, spoken, presentation and listening with ability to explain and interpret complex issues clearly. \n  Experience with Centura 6.2 or 7.2    Possess the ability to document and communicate complex process flows. \n  Proven experience in understanding the scalability of a growing business and implementing changes to deliver award-winning customer support solutions in a dynamic high growth business. \n  Able to clearly articulate and effectively write business requirements. \n  Write use cases or specifications for changes. \n  Able to document processes, road maps, and use cases. \n  Define and create test conditions and plans. \n \n  Desired: \n \n  Experience with Gupta SQL \n  Who We Are: \n   GalaxE.Solutions \n \n   GalaxE is a professional IT services firm that specializes in platform-driven solutions and the use of automation to achieve enterprise business transformation and mission-critical change for some of the largest companies in the world. Using our proprietary solution set, ", "techs": ["centura 6.2 or 7.2", "gupta sql"]}, "424d3b6344ecdd2b": {"terms": ["data analyst"], "salary_min": 38145.0, "salary_max": 70625.0, "title": "Senior Business Analyst", "company": "Tista Science and Technology Corporation", "desc": "Overview: \n  \n   Are you a \n   Senior Business Analyst  who would like to have a positive impact for millions of people? If so, we may have an opportunity for you!\n  \n \n \n  TISTA  associates enjoy above Industry Healthcare Benefits, Remote Working Options, Paid Time Off, Training/Certification opportunities, Healthcare Savings Account & Flexible Savings Account, Paid Life Insurance, Short-term & Long-term Disability, 401K Match, Tuition Reimbursement, Employee Assistance Program, Paid Holidays, Military Leave, and much more!\n   Responsibilities: \n  \n Responsible for completing CMDB Onboarding activities related to VA Service operationalization \n  Conduct Training and coaching, and act as liaisons for SCM Program in order for customers \n  Leverage CIs for ticketing and request process activities \n  Manage the attributes of CI records they own \n  Track lifecycle and status of their of CIs via ITSM tool workspaces \n  Advise the appropriate people on the implications of existing IT systems that can be applied to a problem \n  Develop or assists in the development of work plans, specifications, task sequencing, and the extent to which tasks may be performed concurrently \n  Responsible for working follow-on activities with Discovery and Service Mapping teams for operationalization of Services \n  Attend scrum meetings to report status of onboarding tasks related to operationalization of Services, which includes reporting for Objectives and Key Results (OKRs) measuring progress of CMDB Operationalization project \n  Collaborate with users and stakeholders on any additional needs to achieve operationalization of the Services and CIs owned by customers, which is identified by specific Operationalization criteria met by each Service onboarded by the SCM Onboarding teams \n  Ensure Services onboarded are properly prioritized and onboarding is completed \n  Qualifications: \n  \n Experience in working with customers on identification and processing of technology, identified as Configuration Items (CIs), meeting the criteria for Onboarding into the CMDB \n  Experience in using IT Service Management Tools \u2013 e.g., ServiceNow or equivalent \n  Preferred: Familiar with IT Infrastructure Library (ITIL) methodology and concepts, and ITIL Foundations certified \n  Preferred: Familiar with Government Change, Release, and Service Configuration Management processes \n  Ability to communicate ideas and problem solutions \n  Ability to effectively work with people in other departments and/or outside of the enterprise \n  Must be customer service oriented \n \n \n  Education: \n \n \n  Bachelor's Degree In Operations Research, Mathematics, Computer Science, Cost Accounting or related scientific or technical discipline and 5+ years work experience \n  Eight (8) years of additional relevant experience may be substituted for education (13 years total) \n \n \n \n  Clearance: \n \n \n  Moderate: Tier 2S (Standard MBI) \n \n \n \n  Location: \n \n \n  100% Remote, USA \n  Monday - Friday (8:00 AM - 4:30 PM EST Time) \n \n \n  Pay Range: \n \n \n  The pay for this position ranges from$38,145 to $70,625 \n  The actual salary offer will carefully consider a wide range of factors, including your skills, qualifications, experience, and location \n  Also, certain positions are eligible for additional forms of compensation, such as bonuses \n  TISTA associates are eligible to participate in our comprehensive benefits plan! More information can be found here: https://tistatech.com/working-at-tista/", "cleaned_desc": "  Experience in using IT Service Management Tools \u2013 e.g., ServiceNow or equivalent \n  Preferred: Familiar with IT Infrastructure Library (ITIL) methodology and concepts, and ITIL Foundations certified \n  Preferred: Familiar with Government Change, Release, and Service Configuration Management processes \n  Ability to communicate ideas and problem solutions \n  Ability to effectively work with people in other departments and/or outside of the enterprise \n  Must be customer service oriented \n \n \n  Education: \n \n \n  Bachelor's Degree In Operations Research, Mathematics, Computer Science, Cost Accounting or related scientific or technical discipline and 5+ years work experience ", "techs": ["servicenow", "it infrastructure library (itil)", "itil foundations", "government change", "release", "and service configuration management", "operations research", "mathematics", "computer science", "cost accounting"]}, "1478bd80101e681a": {"terms": ["data analyst"], "salary_min": 78320.0, "salary_max": 99170.58, "title": "IT Business Analyst, Salesforce", "company": "Pure Insurance", "desc": "About the role.\n  \n \n   The IT Business Analyst will be part of the IT Product Management team, responsible for managing PURE\u2019s core systems. The IT Business Analyst will take the lead identifying business and system requirements for PURE\u2019s Salesforce Platform as well as other integrated systems. We are looking for a highly self-motivated individual to interface with our end users, elicit and document requirements, perform analysis, and support the execution of our backlog consisting of small enhancements and projects. A career in business analysis creates a rewarding opportunity to drive deep impact for our business.\n   \n  As part of the team you impact this organization by:\n  \n \n  Take the lead in identifying, eliciting, and evaluating business and system requirements for PURE\u2019s Salesforce System as well as other integrated systems \n  Define and document clear and concise requirements that describe business scenarios and processes in language understandable to both technical and domain stakeholders \n  Own the requirements through their full lifecycle. Ensure that requirements are clearly documented; reviewed and approved by the business community; managed and updated under change control; and developed, tested and implemented to meet the true business needs \n  Prepare user acceptance test (UAT) plans, scenarios, and test cases where applicable. Ensure the UAT plans, roles and responsibilities are well documented and communicated. Follow through with UAT testing resources to ensure timely completion and resolve issues found during UAT \n  Work closely with our internal IT team to assist in the analysis and resolution of production support issues, document them in our project management system, Rally, and provide timely follow-up to questions from the Agile team. \n  \u201cBe in the moment\u201d with our clients to help them identify unforeseen areas for improvement, whether a process improvement or a system enhancement \n \n \n \n   This career is for you if you have:\n  \n \n  A Bachelor\u2019s degree (required) \n  A Salesforce Business Analyst certificate, Salesforce Consultant certificate, or Salesforce Administrator certificate (required) \n  Knowledge of property and casualty insurance (strongly preferred) \n  Experience with Salesforce Service Cloud, Sales Cloud, or Financial Services Cloud (strongly preferred) \n  Experience in Agile / Scrum methodologies (strongly preferred) \n  Experience working with platforms such as Marketo or Five9 (preferred) \n  A good understanding of emerging technology to improve customer satisfaction and reduce friction (preferred) \n  The ability to be productive given only general instruction on work; can walk into a problem and analyze the underlying issue, use judgment, creativity, and sound knowledge to develop and recommend solutions \n  The ability to influence internal customers to balance their requirements against what\u2019s most appropriate for a world-class organization, and find the right compromise \n  Strong consensus building skills and ability to convey technical concepts in a clear, understandable way \n \n \n \n   This role may occasionally be required to work a few hours on a weekend and/or late night in support of scheduled system releases.\n  \n \n \n   We are seeking bright individuals with ambitions as high as our own. Come join us. PURE is an Equal Opportunity Employer.", "cleaned_desc": "  A Salesforce Business Analyst certificate, Salesforce Consultant certificate, or Salesforce Administrator certificate (required) \n  Knowledge of property and casualty insurance (strongly preferred) \n  Experience with Salesforce Service Cloud, Sales Cloud, or Financial Services Cloud (strongly preferred) \n  Experience in Agile / Scrum methodologies (strongly preferred) \n  Experience working with platforms such as Marketo or Five9 (preferred) \n  A good understanding of emerging technology to improve customer satisfaction and reduce friction (preferred) \n  The ability to be productive given only general instruction on work; can walk into a problem and analyze the underlying issue, use judgment, creativity, and sound knowledge to develop and recommend solutions ", "techs": ["salesforce business analyst certificate", "salesforce consultant certificate", "salesforce administrator certificate", "knowledge of property and casualty insurance", "experience with salesforce service cloud", "sales cloud", "financial services cloud", "experience in agile / scrum methodologies", "experience working with platforms such as marketo or five9", "a good understanding of emerging technology to improve customer satisfaction and reduce friction", "the ability to be productive given only general instruction on work"]}, "8c2772600c9d3dbf": {"terms": ["data analyst"], "salary_min": 50.0, "salary_max": 55.0, "title": "PI Analyst", "company": "1 Point System", "desc": "Role: PI Analyst / Developer \n Location: San Fran Bay Area (Hybrid) \n Contract: 6+ Months \n Visa: USC / GC \n Note: ****On Call Required (1 time every 2 months and potentially late-night triage calls 1 time per week)**** \n Job Title: PI Data Analyst/Developer \n Project Scope/  Job Responsibilities: \n Looking for a PI Data Analyst to support PI Systems. This person will be helping to lead the security team, delegate work and handle a lot of PI triaging. PI System knowledge is required to help debug code in production. .Net/C# experience is required, although this person may not be doing much development from scratch as he/she will be doing more bug fixing. \n This is 90% Data Analysis and 10% Development. Must have heavy SQL, SSIS/SSRS or other reporting tools. \n Required Skills: \n Top Required Skills: (5+ years\u2019 experience) \n OSISoft PI Systems / PI WebAPI experience \n SQL within Oracle \n Organizational leadership experience   Other Skills: \n \n OSIsoft PI System knowledge/PI WebAPIMaintaining applications in portfolio, triaging, talking to other teams in the company to problem solve, helping clients use product (mainly PI WebAPI, analytics and security area) \n Windows File System/NAS \n Systems Analysis \n SQL DML/MS SQL Server Administration \n Network/Infrastructure (\u201cClient\u201d specific)Former \u201cClient\u201d experience is nice to have as their network/infrastructure isn\u2019t setup in the most common way so would be helpful to understand how theirs is set up. \n Security/Vulnerabilities managementAs it relates to PI systems and working with the patching team. This person may not do the patching themselves but should be able to talk to the team and communicate what needs to happen. \n Windows/OS level troubleshooting/Patching \n Powershell/Batch processing/Automation \n NERC CIP experience \n \n Job Type: Contract \n Salary: $50.00 - $55.00 per hour \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n Vision insurance \n \n Experience level: \n \n 8 years \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n PI Analyst / Developer: 7 years (Preferred) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "258c0682f9a2a500": {"terms": ["data analyst"], "salary_min": 38145.0, "salary_max": 70625.0, "title": "Senior Business Analyst", "company": "Tista Science and Technology Corporation", "desc": "Overview: \n  \n   Are you a \n   Senior Business Analyst  who would like to have a positive impact for millions of people? If so, we may have an opportunity for you!\n  \n \n \n  TISTA  associates enjoy above Industry Healthcare Benefits, Remote Working Options, Paid Time Off, Training/Certification opportunities, Healthcare Savings Account & Flexible Savings Account, Paid Life Insurance, Short-term & Long-term Disability, 401K Match, Tuition Reimbursement, Employee Assistance Program, Paid Holidays, Military Leave, and much more!\n   Responsibilities: \n  \n Develop, deliver, and maintain technical documentation in written and/or electronic format to include SOPs, installation guides, process flows, illustrations, diagrams, and reports \n  Prepare documents/presentations utilizing Microsoft Office suite of products and Adobe Acrobat Pro  \n Research and prepare statistical and analytical reports from various sources including the timekeeping system and the ticketing system \n  Research data call and requested information, organize, evaluate, and compile results \n  Prepare detailed summaries, track progress on projects and action items \n  Maintain the contents of the SharePoint site \n  Publish meeting agendas, notes, key schedules, and other document repositories as assigned \n  Act as librarian of all application related documents by creating and maintaining key documents in the appropriate SharePoint sites \n  Qualifications: \n  \n Experience maintaining technical documentation in written and electronic format \n  Must have excellent written and verbal communication \n  Ability to Define, design, develop and deliver flexible/user friendly reports \n  Must have experience keeping meeting minutes and schedules \n  Must have experience preparing documents and presentations utilizing Microsoft Office suite \n  Must have experience with Adobe Acrobat Pro \n  Experience preparing statistical and analytical reports \n  Experience with ServiceNow or similar ticketing system \n  Experience evaluating data calls and compiling reports \n  Experience with SharePoint and maintaining site content \n \n \n  Education: \n \n \n  Bachelor's Degree In Operations Research, Mathematics, Computer Science, Cost Accounting or related scientific or technical discipline and 5+ years work experience \n  Eight (8) years of additional relevant experience may be substituted for education (13 years total) \n \n \n \n  Clearance: \n \n \n  Moderate: Tier 2S (Standard MBI) \n \n \n \n  Location: \n \n \n  100% Remote, USA \n  Monday - Friday (8:00 AM - 4:30 PM EST Time) \n \n \n  Pay Range: \n \n \n  The pay for this position ranges from$38,145 to $70,625 \n  The actual salary offer will carefully consider a wide range of factors, including your skills, qualifications, experience, and location \n  Also, certain positions are eligible for additional forms of compensation, such as bonuses \n  TISTA associates are eligible to participate in our comprehensive benefits plan! More information can be found here: https://tistatech.com/working-at-tista/", "cleaned_desc": "  Must have experience preparing documents and presentations utilizing Microsoft Office suite \n  Must have experience with Adobe Acrobat Pro \n  Experience preparing statistical and analytical reports \n  Experience with ServiceNow or similar ticketing system \n  Experience evaluating data calls and compiling reports \n  Experience with SharePoint and maintaining site content \n \n \n  Education: \n \n \n  Bachelor's Degree In Operations Research, Mathematics, Computer Science, Cost Accounting or related scientific or technical discipline and 5+ years work experience ", "techs": ["microsoft office suite", "adobe acrobat pro", "servicenow", "sharepoint"]}, "875e7278529a743c": {"terms": ["data analyst"], "salary_min": null, "salary_max": null, "title": "QA Analyst (Remote)", "company": "Patterson Technology Center", "desc": "The Quality Assurance (QA) Analyst writes test plans, performs test execution, and tracks defects using the defined QA tools, processes, and methodology. The QA Analyst applies proven analytical and problem-solving skills for validating processes and handles moderately complex issues and problems in order to maximize product quality and value delivery in a product or project area. \n \n  ESSENTIAL FUNCTIONS \n  To perform this job successfully, an employee must be able to perform each essential function satisfactorily, with or without reasonable accommodation. To request a reasonable accommodation, notify Human Resources or the manager who oversees the position.\n   \n \n Adhere to established Patterson QA standards for Quality Assurance Process and Methodology. \n Collaborate with team members, including Software Engineers and Product Owners, regarding feature design. \n Analyze design documents to create test plan documentation that can be reviewed and utilized by other QA Analysts. \n Create and execute test plans and scripts that will determine optimal application performance according to specifications. \n Execute test scenarios using existing documentation. \n Collaborate with software/systems personnel in application testing, such as but not limited to system, unit, regression, load, and acceptance testing methods. \n Test any new software to ensure integration into company systems meets functional and non-functional requirements, system compliance, and technical specifications. \n Perform issue tracking, reporting and resolution of issues found during testing. \n Define and track quality assurance metrics. \n Collect and analyze data for software process evaluation and improvements and integrate them into business processes to address the needs of the business. \n Provide regular status as directed throughout the release cycle to appropriate leadership and development team members. \n For regulated products, follows regulatory requirements for software development/testing and provide needed documentation. \n Provide support for escalated incident tickets from end users to resolve application and software issues. \n \n \n \n \n  ADDITIONAL FUNCTIONS \n  In addition to the essential functions listed above, the incumbent may perform the following additional functions.\n   \n \n May provide leadership, coaching, and/or mentoring to Associate QA Analysts. \n Participate in regulatory and compliance activities. \n \n \n  REQUIRED QUALIFICATIONS \n \n \n Associate degree with emphasis on Computer Science, IT or related QA field or equivalent software experience \n 2+ years\u2019 experience in quality assurance and testing applications \n Knowledge of software QA best practices, methodologies, tools, and processes \n Experience with desktop, web, cloud, and mobile applications \n Ability to conduct research into software-related issues and products \n Highly self-motivated and directed, with keen attention to detail and ability to prioritize \n Experience with SQL scripting practices \n \n \n \n  PREFERRED QUALIFICATIONS \n \n \n Bachelor\u2019s degree with emphasis on Computer Science, IT or related QA field or equivalent software experience \n Experience working in an Agile/Scrum environment that is team-oriented and collaborative \n Knowledge of Patterson products and offerings. \n Experience with application lifecycle management tools such as Azure DevOps \n \n \n \n Travel to corporate sites is periodically required (Quarterly or so) \n \n \n \n Periodic on call rotations and available outside of normal business hours on evenings and weekends during critical production release or issue escalation periods", "cleaned_desc": " \n Associate degree with emphasis on Computer Science, IT or related QA field or equivalent software experience \n 2+ years\u2019 experience in quality assurance and testing applications \n Knowledge of software QA best practices, methodologies, tools, and processes \n Experience with desktop, web, cloud, and mobile applications \n Ability to conduct research into software-related issues and products \n Highly self-motivated and directed, with keen attention to detail and ability to prioritize \n Experience with SQL scripting practices \n \n \n    PREFERRED QUALIFICATIONS \n \n \n Bachelor\u2019s degree with emphasis on Computer Science, IT or related QA field or equivalent software experience \n Experience working in an Agile/Scrum environment that is team-oriented and collaborative \n Knowledge of Patterson products and offerings. \n Experience with application lifecycle management tools such as Azure DevOps \n \n \n \n Travel to corporate sites is periodically required (Quarterly or so) ", "techs": ["associate degree with emphasis on computer science", "it or related qa field or equivalent software experience", "2+ years\u2019 experience in quality assurance and testing applications", "knowledge of software qa best practices", "methodologies", "tools", "and processes", "experience with desktop", "web", "cloud", "and mobile applications", "ability to conduct research into software-related issues and products", "highly self-motivated and directed", "with keen attention to detail and ability to prioritize", "experience with sql scripting practices", "bachelor\u2019s degree with emphasis on computer science", "it or related qa field or equivalent software experience", "experience working in an agile/scrum environment that is team-oriented and collaborative", "knowledge of patterson products and offerings", "experience with application lifecycle management tools such as azure devops"]}, "bc644fb7e1d65e15": {"terms": ["data analyst"], "salary_min": 77597.37, "salary_max": 98255.555, "title": "Lead Supply Chain Process Analyst", "company": "PROKIDNEY LLC", "desc": "Description:\n  \n  As the Lead Supply Chain Process Analyst, you will play a crucial role in ensuring the efficiency, compliance, and transformation of our supply chain processes. You will work closely with cross-functional teams to analyze data, identify areas for optimization, and implement process improvements. Your role will require knowledge of GMP guidelines, process improvement methodologies, and digital technologies in supply chain. \n \n Analyze supply chain process adhere to GMP guidelines and identify gaps. \n Support the assessment and optimization of supply chain processes to enhance efficiency and reduce operational risks. \n Develop and implement process improvement strategies, focusing on GMP best practices. \n Develop and collaborate with cross-functional teams and implement strategies to enhance process efficiency, reduce costs, and improve overall performance to ensure alignment with strategic goals. \n Develop and maintain process documentation, including flowcharts, standard operating procedures (SOPs), process maps, work instructions. \n Facilitate change management initiatives to ensure successful adoption of process improvements. \n Provide training and support to team members to ensure they understand and can effectively implement new processes and technologies. \n Stay updated on industry best practices and emerging trends in supply chain management. \n Continuously seek opportunities for optimization and cost reduction within the supply chain. \n  Requirements: \n  \n Bachelor's degree in Supply Chain Management, Business, Engineering, or a related field required \n  Minimum of 5 years of experience in supply chain management, GMP compliance, process improvement, or related roles in a regulated environment. \n  Strong understanding of GMP guidelines and regulations, as well as experience. \n  Expertise in process improvement methodologies is preferred. \n  Ability to read and comprehend GMP documents (i.e., SOPs, Work Instructions). \n  Proficiency in digital technologies relevant to supply chain management, including ERP, MRP, Planning. \n  Knowledge of Chain of Identity/Chain of Custody would be a plus. \n  Strong analytical skills with proficiency in process and data analysis tools (e.g., Visio, Excel, data visualization tools).", "cleaned_desc": "", "techs": ""}, "b672cf1f28431952": {"terms": ["data analyst"], "salary_min": 49800.0, "salary_max": 75000.0, "title": "Technical Business Analyst II", "company": "Jack Henry and Associates, Inc.", "desc": "At Jack Henry, we deliver technology solutions that are digitally transforming and empowering community banks and credit unions to provide enhanced and streamlined user experiences to their customers and members. Our best-in-class products are just the start as we lay the groundwork for the future of digital banking and payments. We hope you\u2019ll join us. We can\u2019t do it without you.\n  \n \n \n  We are seeking a Technical Business Analyst to join our team within our Loan Modernization group at Jack Henry. In this role, you will be responsible for analyzing information derived from various sources to assist multiple development teams in enhancing the Loan Modernization product. You will have the exciting opportunity to work on modernization efforts which carry cross collaboration with several teams on the Lending side. The ideal candidate is familiar with Scaled Agile Framework (SAFe) and has substantial experience within lending and mortgage financial industry. They have excellent attention to details and can effectively communicate and collaborate with various teams.\n  \n \n \n  This position will be filled to work Remotely within the U.S.\n  \n \n \n \n  The target salary range for this position is $49,800 \u2013 $75,000, based on location and experience.\n   \n \n \n  If you are interested in this position, please apply on or before October 25, 2023.\n   \n \n \n  What you\u2019ll be responsible for: \n \n \n \n \n \n  Work with Product Management to understand the features to be developed and prioritization. \n  Share development team needs with Product Management (time constraints, technology needs, dependencies, etc.). \n  Work with scrum master to maintain & work a prioritized backlog. \n  Create issues in Jira with a description of the feature and acceptance criteria. \n  Lead and participate in planning, retrospectives, & demos. \n  Create functional specifications and system documentation, as well as contributing to end-user and project management documentation. \n  Work with quality assurance and programming teams to ensure changes are migrated into production correctly. \n  Evaluate third-party vendor changes and documenting integration enhancement needs. \n  Interact with technical teams to convey functional requirements. \n  May perform other job duties as assigned. \n \n \n \n  What you\u2019ll need to have: \n \n \n \n \n \n  A minimum of 2 years of experience writing requirements, YAML/Swagger, JSON, XML, and API design. \n  Strong knowledge of the financial industry. \n  Strong project management skills. \n  Strong communication (written and verbal) and customer interaction skills. \n  Excellent attention to details. \n  Ability to travel up to 5% to attend JH meetings, trainings, and/or professional conferences. \n \n \n \n  What would be nice for you to have: \n \n \n \n \n \n  Bachelor\u2019s degree in IT or Business. \n  Experience with Scaled Agile Framework (SAFe). \n  Previous experience as a Business Analyst or an Analyst in a bank or FinTech environment. \n  Previous experience in lending (consumer and/or commercial) or experience with lending software (analysis, testing, or reporting). \n  Experience with Atlassian Jira or Confluence products. \n  Ability to define system and functional requirements. \n  Ability to interact with and communicate well with other technical associates. \n  Experience with microservices, Rest APIs, Domain Driven Design, Behavior Driven Development, SOAP and Postman. \n \n \n \n \n   If you got this far, we hope you're feeling excited about this opportunity. Even if you don't feel you meet every single requirement on this posting, we still encourage you to apply. We're eager to meet motivated people who align with Jack Henry\u2019s mission and can contribute to our company in a variety of ways.\n   \n \n \n \n \n Why Jack Henry? \n \n \n \n  At Jack Henry, we pride ourselves through our motto of, \"Do the right thing, do whatever it takes, and have fun.\" We recognize the value of our associates and believe much of our company\u2019s strength and success depends on their well-being.\n   \n \n \n \n \n  We demonstrate our commitment by offering outstanding benefit programs to ensure the physical, mental & financial wellbeing of our people is always met.\n  \n \n \n \n \n  Culture of Commitment \n \n \n \n \n \n   Ask our associates why they love Jack Henry, and many will tell you it is because our culture is exceptional. We do great things together. Rising to meet challenges and seeking opportunities is part of who we are as an organization. Our culture has helped us stay strong through challenging times and we credit our dedicated associates for our success. Visit our Corporate Responsibility site to learn more about our culture and commitment to our people, customers, community, environment, and shareholders.\n   \n \n \n \n \n Equal Employment Opportunity \n \n \n \n \n \n   At Jack Henry, we know we are better together. We value, respect, and protect the uniqueness each of us brings. Innovation flourishes by including all voices and makes our business\u2014and our society\u2014stronger. Jack Henry is an equal opportunity employer and we are committed to providing equal opportunity in all of our employment practices, including selection, hiring, performance management, promotion, transfer, compensation, benefits, education, training, social, and recreational activities to all persons regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, genetic information, pregnancy, marital status, sex, gender, gender identity, gender expression, age, sexual orientation, and military and veteran status, or any other protected status protected by local, state or federal law.\n  \n \n \n \n \n   No one will be subject to, and Jack Henry prohibits, any form of discipline, reprisal, intimidation, or retaliation for good faith reports or complaints of incidents of discrimination of any kind, pursuing any discrimination claim, or cooperating in related investigations.\n  \n \n \n \n \n  Requests for full corporate job description may be requested through the interview process at any time.", "cleaned_desc": " \n \n  Work with Product Management to understand the features to be developed and prioritization. \n  Share development team needs with Product Management (time constraints, technology needs, dependencies, etc.). \n  Work with scrum master to maintain & work a prioritized backlog. \n  Create issues in Jira with a description of the feature and acceptance criteria. \n  Lead and participate in planning, retrospectives, & demos. \n  Create functional specifications and system documentation, as well as contributing to end-user and project management documentation. \n  Work with quality assurance and programming teams to ensure changes are migrated into production correctly. \n  Evaluate third-party vendor changes and documenting integration enhancement needs. \n  Interact with technical teams to convey functional requirements. \n  May perform other job duties as assigned. \n \n \n \n  What you\u2019ll need to have: \n \n \n \n \n \n  A minimum of 2 years of experience writing requirements, YAML/Swagger, JSON, XML, and API design. \n  Strong knowledge of the financial industry. \n  Strong project management skills. \n  Strong communication (written and verbal) and customer interaction skills. ", "techs": ["jira", "yaml/swagger", "json", "xml", "api design"]}, "c688c7697c781374": {"terms": ["data analyst"], "salary_min": 40.0, "salary_max": 100.0, "title": "ServiceNow IT Service Management (ITSM) Analyst", "company": "Synovize", "desc": "Synovize is a leading technology consulting firm that specializes in providing innovative solutions to businesses across various industries. With a team of experienced professionals, we aim to deliver exceptional services to our clients and help them achieve their digital transformation goals. As a remote-first company, we offer flexible work opportunities to talented individuals across the United States. \n Overview: \n We are currently seeking a skilled and experienced ServiceNow IT Service Management (ITSM) Analyst to join our team. As a ServiceNow ITSM Analyst, you will be responsible for analyzing, designing, and implementing IT service management solutions using the ServiceNow platform. This is a full-time, permanent or contract position with the flexibility of remote work. \n Responsibilities: \n \n Collaborate with clients and stakeholders to understand their IT service management needs and translate them into ServiceNow configurations. \n Analyze existing IT service management processes and workflows, identifying areas for improvement and optimization. \n Design and configure ServiceNow ITSM modules, including incident management, problem management, change management, and service catalog. \n Customize ServiceNow functionalities using JavaScript, Angular, and other web technologies to meet specific client requirements. \n Integrate ServiceNow with external systems through REST API, SOAP API, and other integration methods. \n Develop and maintain the Configuration Management Database (CMDB) to ensure accurate and up-to-date data. \n Conduct testing and quality assurance activities to ensure the stability and reliability of the implemented ITSM solutions. \n Provide end-user training and support during and after the implementation process. \n Collaborate with cross-functional teams to ensure successful project delivery within agreed timelines and budgets. \n Stay updated with the latest ServiceNow features and enhancements, recommending and implementing improvements to optimize IT service management processes. \n \n Requirements: \n \n Proven experience as a ServiceNow ITSM Analyst, working on IT service management projects and configuring the ServiceNow platform. \n Strong knowledge of IT service management processes and frameworks, such as ITIL. \n Proficiency in JavaScript, Angular, and web technologies for customization and enhancement purposes. \n Experience with integrating ServiceNow with external systems using REST API, SOAP API, and other methods. \n Familiarity with the Configuration Management Database (CMDB) and data management best practices. \n Strong problem-solving and analytical skills, with the ability to translate complex business requirements into technical solutions. \n Effective communication and collaboration skills to work with clients and cross-functional teams. \n \n Preferred Skills: \n \n ServiceNow certifications such as Certified Implementation Specialist or Certified Application Developer. \n Knowledge of ITIL best practices and their application in ServiceNow. \n Experience with other ServiceNow modules such as GRC, HAM, SAM, APM, and SPM. \n Familiarity with NoSQL databases and their usage in ServiceNow. \n Experience with ITOM, SCCM, JAMF, or other related tools and technologies. \n \n To apply for the position of ServiceNow IT Service Management (ITSM) Analyst at Synovize, please submit your resume and any relevant certifications. We are excited to hear from talented individuals who are passionate about leveraging the power of ServiceNow to drive efficient IT service delivery. Join us in shaping the future of technology consulting! \n Job Types: Contract, Permanent, Full-time \n Pay: $40.00 - $100.00 per hour \n Benefits: \n \n 401(k) matching \n Dental insurance \n Disability insurance \n Flexible schedule \n Flexible spending account \n Health insurance \n Health savings account \n Life insurance \n Parental leave \n Vision insurance \n \n Compensation package: \n \n 1099 contract \n \n Experience level: \n \n 10 years \n 11+ years \n 1 year \n 2 years \n 3 years \n 4 years \n 5 years \n 6 years \n 7 years \n 8 years \n 9 years \n No experience needed \n Under 1 year \n \n Schedule: \n \n 10 hour shift \n 8 hour shift \n Day shift \n Monday to Friday \n Night shift \n Overtime \n \n Application Question(s): \n \n Do you have any ServiceNow Certifications? If so, were they paid out of pocket? \n \n Experience: \n \n ServiceNow: 2 years (Preferred) \n \n Security clearance: \n \n Secret (Preferred) \n \n Work Location: Remote", "cleaned_desc": " Proven experience as a ServiceNow ITSM Analyst, working on IT service management projects and configuring the ServiceNow platform. \n Strong knowledge of IT service management processes and frameworks, such as ITIL. \n Proficiency in JavaScript, Angular, and web technologies for customization and enhancement purposes. \n Experience with integrating ServiceNow with external systems using REST API, SOAP API, and other methods. \n Familiarity with the Configuration Management Database (CMDB) and data management best practices. \n Strong problem-solving and analytical skills, with the ability to translate complex business requirements into technical solutions. \n Effective communication and collaboration skills to work with clients and cross-functional teams. \n \n Preferred Skills: \n \n ServiceNow certifications such as Certified Implementation Specialist or Certified Application Developer. \n Knowledge of ITIL best practices and their application in ServiceNow. \n Experience with other ServiceNow modules such as GRC, HAM, SAM, APM, and SPM. \n Familiarity with NoSQL databases and their usage in ServiceNow. \n Experience with ITOM, SCCM, JAMF, or other related tools and technologies. \n \n To apply for the position of ServiceNow IT Service Management (ITSM) Analyst at Synovize, please submit your resume and any relevant certifications. We are excited to hear from talented individuals who are passionate about leveraging the power of ServiceNow to drive efficient IT service delivery. Join us in shaping the future of technology consulting! \n Job Types: Contract, Permanent, Full-time ", "techs": ["servicenow itsm analyst", "servicenow platform", "itil", "javascript", "angular", "rest api", "soap api", "configuration management database (cmdb)", "certified implementation specialist", "certified application developer", "grc", "ham", "sam", "apm", "spm", "nosql databases", "itom", "sccm", "jamf"]}, "7c21309fe6b75e73": {"terms": ["data analyst"], "salary_min": 117394.305, "salary_max": 148647.34, "title": "Data Analytics Lead", "company": "Cyberjin", "desc": "Hybrid/Remote role \n  Locations in multiple States \n  The Data Analytics Lead at Company has/is: \n \n  3 - 8 years experience in a data analytics role , preferably at a high-growth startup, CPG, loyalty, retail, or mobile gaming company \n  Entrepreneurial mindset with a  \u2018self-start\u2019 mentality ; Excels at finding answers. Customer centric. Comfortable with a workday and schedule that isn\u2019t always highly structured or predictable \n  Experience with  BI & data visualization tools  (e.g., Tableau, PowerBI).  Strong experience with SQL  and at  least   one  programming language (e.g., Python, R). Experience with  ETL tools  (Tableau Prep, Alteryx, Knime or similar). Proven experience in the cloud (Snowflake/AWS/GCP/Azure), Experience with  mobile products and analytics tools (Amplitude or similar) \n  A leader and a team player : ability to work and make decisions autonomously with appropriate levels of collaboration and engagement with the team to ensure alignment. \n \n  Additional: \n \n  Ability to handle multiple tasks simultaneously, maintain focus, and adapt to a variety of challenges in a  fast-paced agile environment \n  5 Location / ability to relocate to: Chicago (highly preferred) or San Diego \n \n   \n zbe2F1TdlX", "cleaned_desc": "  Experience with  BI & data visualization tools  (e.g., Tableau, PowerBI).  Strong experience with SQL  and at  least   one  programming language (e.g., Python, R). Experience with  ETL tools  (Tableau Prep, Alteryx, Knime or similar). Proven experience in the cloud (Snowflake/AWS/GCP/Azure), Experience with  mobile products and analytics tools (Amplitude or similar) \n  A leader and a team player : ability to work and make decisions autonomously with appropriate levels of collaboration and engagement with the team to ensure alignment. \n ", "techs": ["tableau", "powerbi", "sql", "python", "r", "tableau prep", "alteryx", "knime", "snowflake", "aws", "gcp", "azure", "amplitude"]}, "5c1d14f7d08fd821": {"terms": ["data analyst"], "salary_min": null, "salary_max": null, "title": "IT Business Analyst/Scrum Master", "company": "Acuity INC", "desc": "Overview: \n  \n   As a Business Analyst, you will serve as a dedicated team member who has primary responsibility to support their self-organizing, self-managing team successfully achieve their daily, iteration, and release goals and delivery objectives. They do so by effectively applying, implementing and enforcing Scrum principles and practices. The Business Analyst will also help protect the team from outside influences, which could otherwise interfere with the team's ability to deliver value in a short time-box (iteration). The Business Analyst will help to mentor the empowerment teams and assist the team in its transition to the new method, continuously facilitate a team dynamic intended to maximize performance of the team, and by continuously improving agile practices.\n   Responsibilities: \n  \n   Skills: \n  \n \n SCM \n  General understanding of RPA, AI and ML \n  UiPath customer engagement and follow-up \n  Minor SharePoint site content updates \n  Ability to maintain and track MOU/MOA and other process documents. \n \n \n   DevSecOps\n  \n \n  Support multiple service and support.\n    \n  Application Security understanding \n  Manage Application Engineering, patching and vulnerability mitigation  \n \n Schedule and orchestrate daily stand-up meetings. \n  Schedule and guide sprint planning and reviews. \n  Prepare and publish sprint reports. \n  Follow through with team members on task and board updates. \n  Facilitate technical discussions with team members and external stakeholders. \n  Qualifications: \n  \n Bachelor's Degree or equivalent with experience in a related Information Technology field \n  Communicate and collaborate with project manages and cross-national teams. \n  Maintain documentation regarding various projects, processes and operations. \n  Make recommendations for improvements. \n  Ability to liaise between groups and numerous organization units. \n  Ability to communicate effectively. \n  Review and analyze key business metrics and compliance. \n  Ability to operate independently and accommodate an international audience. \n  Schedule, plan and lead requirements gathering and review meetings. \n  Serve as BA in support of AI/ML projects. \n  Excellent knowledge of agile methodology, techniques and frameworks \n  Ability to lead daily stand-up scrum meetings. \n  Knowledge of kanban, back logs and project tracking \n \n \n  Clearance Requirement \n \n \n  Must have active Top Secret government clearance \n \n \n \n \n \n About Acuity Inc: \n \n \n   Acuity is a leading management and technology consulting firm that specializes in serving the federal government. Our innovative, collaborative and rewarding work environment has earned repeat honors from the Washington Business Journal\u2019s Best Places to Work and SmartCEO Corporate Culture awards.\n  \n \n \n  We are an equal employment opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, national origin, disability status, protected veteran status or any other characteristic protected by law.", "cleaned_desc": "", "techs": ""}, "54804d8334b20f7c": {"terms": ["data analyst"], "salary_min": 54922.0, "salary_max": 107098.0, "title": "Sr Analyst - HEDIS Analytics (Remote in NE)", "company": "Molina Healthcare", "desc": "JOB DESCRIPTION \n \n  Job Summary \n \n  Molina's Quality Improvement function oversees, plans, and implements new and existing healthcare quality improvement initiatives and education programs; ensures maintenance of programs for members in accordance with prescribed quality standards; conducts data collection, reporting and monitoring for key performance measurement activities; and provides direction and implementation of NCQA accreditation surveys and federal/state QI compliance activities. \n \n  KNOWLEDGE/SKILLS/ABILITIES \n \n  In collaboration with Quality Improvement (QI) management, the Senior Analyst, HEDIS/Quality Reporting develops and provides reports and cost-benefit analysis tools to meet QI requirements and uses automated software tools and processes to help streamline activities and improve data/analytics for the quality team. \n \n  Acts as a lead analyst to provide project-, program-, and / or initiative-related direction and guidance for other analysts within the department and/or collaboratively with other departments. \n \n  Develops, codes, runs, and/or prepares formatted reports to support critical Quality Improvement functions (e.g., reporting for key performance measurement activities, including HEDIS, state-based measure reporting and medical record review). \n \n  Collaborates and / or assists in performing quality assurance checks on reports prior to completion \n \n  Works with Director and / or Manager to establish and / or document quality assurance process checks to be utilized by all staff to ensure the integrity, completeness and validity of external and internal reports \n \n  Understands how to prioritize reports according to business need, regulatory requirements, urgency and / or other key business factors \n \n  Collaborates with department leads and other partnering departments to understand and / or document business requirements and / or implement required reporting. \n \n  Writes and / or produces accurate reports and conducts analyses according to set timelines and project plans. \n \n  Collaborates with other department staff to convert HEDIS data sources for use in HEDIS reporting as needed. \n \n  Coordinates data and analyses from MHI and / or Health Plans as needed. \n \n  Assists with generation of State-specific performance measurement requirements. \n \n  Assists program managers with research regarding performance measurement outliers when asked. \n \n  Uses industry standard techniques determined by the department to reduce report writing errors. \n \n  Modifies reports in response to error identification and / or approved change requests; understand the balance between responsiveness to business requests for enhancements versus department needs to complete work efficiently and timely. \n \n  JOB QUALIFICATIONS \n \n  Required Education \n \n  Bachelor's Degree or equivalent combination of education and work experience. \n \n  Required Experience \n \n  3 years of experience in healthcare, or equivalent experience in a non-financial regulated industry. \n \n  1 year experience in managed healthcare, or equivalent \n \n  Technical experience in reporting and/or programming. \n \n  Proficiency with Excel and Visio (flow chart equivalent) and demonstrated ability to learn new information systems and software programs. \n \n  Proficiency with data manipulation and interpretation. \n \n  Knowledge of basic statistics. \n \n  Preferred Education \n \n  Master's Degree or higher in a clinical field, IT, Public Health or Healthcare. \n \n  Preferred Experience \n \n  HEDIS reporting or collection experience. \n \n  CAHPS improvement experience. \n \n  1+ years in managed healthcare non-financial reporting. \n \n  1+ years health care information systems experience or in a role as an IS liaison/contact for QI projects. \n \n  State QI experience. \n \n  Supervisory experience. \n \n  Project management and team building experience. \n \n  Experience developing performance measures that support business objectives. \n \n  Experience using multiple programming languages, including but not limited to, SQL / SSRS. \n \n  Preferred License, Certification, Association \n \n  Microsoft Certification(s) \n \n \n Pay Range:  $54,922 - $107,098 \n \n \n \n Actual compensation may vary from posting based on geographic location, work experience, education and/or skill level. \n \n To all current Molina employees:  If you are interested in applying for this position, please apply through the intranet job listing. \n \n  Molina Healthcare offers a competitive benefits and compensation package. Molina Healthcare is an Equal Opportunity Employer (EOE) M/F/D/V.", "cleaned_desc": "", "techs": ""}, "305c5f690050796b": {"terms": ["data analyst"], "salary_min": 45000.0, "salary_max": 45000.0, "title": "Business Development Data Analyst - Remote Work", "company": "BairesDev", "desc": "Who We are \n  BairesDev is proud to be the fastest-growing company in America. With people in five continents and world-class clients, we are only as strong as the multicultural teams at the heart of our business. To consistently deliver the highest quality solutions to our clients, we only hire the Top 1% of the best talents and nurture their professional growth on exciting projects.  \n Business Development Data Analyst at BairesDev \n  We are looking for a Business Development Data Analyst to join our Team and identify and implement new business development initiatives. \n  What You Will Do: \n \n Identify opportunities to use data analytics tools to monitor, extract, and evaluate data. \n Work closely and collaboratively to improve, develop and implement new processes \n Work collaboratively with the A&E and R&D teams to develop the initiatives of the business development team. \n Proactively work with the team to identify, plan, and implement new business development opportunities. \n \n  Here\u2019s what we are looking for: \n \n 2+ years of experience as Data Analyst. \n Technical and business knowledge with a background in process improvement. \n Advanced methodical skills, attention to detail, and deadline-driven. \n Knowledge of Google Sheets, Tableau, and SQL is desirable. \n Advanced English level. \n \n  How we do make your work (and your life) easier: \n \n 100% remote work. \n Hardware setup for you to work from home. \n  - Flexible hours - make your schedule.\n  \n \n Paid parental leave, vacation & holidays. \n Diverse and multicultural work environment. \n An innovative environment with the structure and resources of a leading multinational. \n Excellent compensation \u2014 well above the market average. \n Here you can grow at the speed of your learning curve. \n \n Our people work remotely but with a consistent and robust culture that promotes diversity and teamwork. To continue being the leading software development company in Latin America, we want to ensure that every BairesDev member gets the best growth and professional development opportunities in a diverse, welcoming, and innovative environment.   Every BairesDev team member brings something unique to our company.  We want to hear your story. Apply now!", "cleaned_desc": "", "techs": ""}, "10b13f6090621c54": {"terms": ["data analyst"], "salary_min": 74752.33, "salary_max": 94653.11, "title": "Data Quality Analyst - ( German/ French) - Remote", "company": "Cystems Logic Inc", "desc": "Job Description\n  \n  Hi, \n \n  We have contract job opening, If you are interested, Please send your updated resume. \n \n  Job Title: Data Quality Analyst \n \n  Work location: Remote, USA \n \n  Duration: Longtetrm Contract \n \n  Comments: Customer is fine to have resource with 3-5 yrs of experience \n \n  Data Quality Analyst (French) \u2013 1st position \n \n \n  Perform regular audits and analysis of labeled data in French, and deliver metrics and insights to project management in English. \n \n \n \n  Calibrate with human labeling teams around project guidelines to identify market specific pain points and ensure quality improvements. \n \n \n \n  Assist in the revision of project guidelines according to investigated areas of weakness or lack of clarity. \n \n \n  Data Quality Analyst (German)- 2nd position \n \n \n  Perform regular audits and analysis of labeled data in German, and deliver metrics and insights to project management in English. \n \n \n \n  Calibrate with human labeling teams around project guidelines to identify market specific pain points and ensure quality improvements. \n \n \n \n  Assist in the revision of project guidelines according to investigated areas of weakness or lack of clarity. \n \n \n  Best Regards \n  Girish \n  Cystems Logic Inc, \n \n \n \n Additional Information\n   All your information will be kept confidential according to EEO guidelines.", "cleaned_desc": "", "techs": ""}, "186602b8bdbb6e18": {"terms": ["data analyst"], "salary_min": null, "salary_max": null, "title": "Business Analyst (Senior)- Remote - Eastern Time Zone Only", "company": "WellSpan Health", "desc": "Job Description: \n Under general supervision, the Business Analyst (Senior) is responsible for retrieving, interpreting, and analyzing data to drive key business decisions and actions, measure program efficacy and contribute to strategic direction. Helps drive the success of the business by providing business analyses and analytical solutions to guide management and operational decision-making. The individual will work on projects and products dealing with key performance metrics tracking, financial and business assessments of potential strategic initiatives and other ad hoc requests. The solutions could range from dashboards in advanced BI content to exploratory analysis and impact assessments that leads to strategic recommendations. This position will work collaboratively with associates across different levels, functions, business units and regions to support all data and analytical products. Working with other teams across the Analytics Center of Excellence (ACoE), participates as a catalyst for maintaining the product life cycle, focusing on system strategic goals and objectives, assist business stakeholders with formulating appropriate data and analytics questions that will lead to analyses which will reveal relevant insights. Assists stakeholders with interpreting results, at times applying visualization techniques (e.g., Microsoft Power BI). Collaborates with developers and end users to ensure technical requirements and specifications reflect appropriate business logic. In this role, the Business Analyst (Senior) engages with various groups within WellSpan to gather business requirements while ensuring that these requirements align to the various analytics products existing or currently underway. There will be opportunities to enhance business processes and the requirement to build test cases and support functional testing and UAT. This position will leverage the analytics spectrum to tell a story with the data, working with senior level analysts to ensure the application of the most appropriate approach for each business need. This position requires the soft skill of story-telling through data, by turning technical information into easy-to-understand non-technical action items. Confidence in presentation of findings and excellent communication skills are desired. This position will develop the ability to view business problems from varying perspectives and continuously display curiosity. \n \n Duties and Responsibilities \n \n \n Works with partners across the WellSpan business domains to gather detailed business requirements. Be point person for collation of requirements and subsequent sharing and obtaining of sign offs. Defines testing approach and strategy and help execute this strategy during test phases of project. \n \n \n Works with engineering and development team members to define the functional and technical design to support business processing requirements for data and analytics products. \n \n \n Works with the Product Manager and Product Owners to ensure delivery throughout the lifecycle of the product. Tracks and communicates status to wider team and management as needed. \n \n \n Collaborates with the development team on test plan development, design test strategy and manage the UAT process. \n \n \n Assists customers with formulating appropriate data questions to meet business and strategic needs. \n \n \n Able to take a business question or need and turn it into a data question for the purpose of transforming and analyzing the data to extract an answer to that question. \n \n \n Supports the ACoE data and analytics strategy, processes, technical architecture, and design of subject areas. \n \n \n Collaborates with developers and end users to ensure technical requirements and specifications reflect appropriate business logic. \n \n \n Supports system wide data integrity, quality control and standardization as identified by system leaders and/or system level teams. \n \n \n Mentors other business analysts and work with leadership in establishing and adopting best practices within business analysis, product owner and scrum master responsibilities \n \n \n Qualifications \n \n Minimum Experience: \n     \n 7 Years of experience as a Business Analyst \n Experience in Market Analytics \n \n \n \n \n Min Field of Expertise: Healthcare operations or Data and Analytics related experience \n \n \n   \n \n Minimum Education: \n     \n Bachelor's Degree \n \n \n \n \n Skills: \n     \n Business Analysis, Business Requirements Documents, Project Management \n Experience in Agile methodologies, writing User Stories, Using Jira \n Strong teamwork/communication/customer service skills. \n \n \n \n # Remote (Eastern time zone only) \n \n  Location: WellSpan Health \u00b7 Analytics Ctr of Excellence\n   Schedule: Full Time, Day", "cleaned_desc": "Job Description: \n Under general supervision, the Business Analyst (Senior) is responsible for retrieving, interpreting, and analyzing data to drive key business decisions and actions, measure program efficacy and contribute to strategic direction. Helps drive the success of the business by providing business analyses and analytical solutions to guide management and operational decision-making. The individual will work on projects and products dealing with key performance metrics tracking, financial and business assessments of potential strategic initiatives and other ad hoc requests. The solutions could range from dashboards in advanced BI content to exploratory analysis and impact assessments that leads to strategic recommendations. This position will work collaboratively with associates across different levels, functions, business units and regions to support all data and analytical products. Working with other teams across the Analytics Center of Excellence (ACoE), participates as a catalyst for maintaining the product life cycle, focusing on system strategic goals and objectives, assist business stakeholders with formulating appropriate data and analytics questions that will lead to analyses which will reveal relevant insights. Assists stakeholders with interpreting results, at times applying visualization techniques (e.g., Microsoft Power BI). Collaborates with developers and end users to ensure technical requirements and specifications reflect appropriate business logic. In this role, the Business Analyst (Senior) engages with various groups within WellSpan to gather business requirements while ensuring that these requirements align to the various analytics products existing or currently underway. There will be opportunities to enhance business processes and the requirement to build test cases and support functional testing and UAT. This position will leverage the analytics spectrum to tell a story with the data, working with senior level analysts to ensure the application of the most appropriate approach for each business need. This position requires the soft skill of story-telling through data, by turning technical information into easy-to-understand non-technical action items. Confidence in presentation of findings and excellent communication skills are desired. This position will develop the ability to view business problems from varying perspectives and continuously display curiosity. \n \n Duties and Responsibilities \n \n \n Works with partners across the WellSpan business domains to gather detailed business requirements. Be point person for collation of requirements and subsequent sharing and obtaining of sign offs. Defines testing approach and strategy and help execute this strategy during test phases of project. \n \n \n Works with engineering and development team members to define the functional and technical design to support business processing requirements for data and analytics products. \n \n \n Works with the Product Manager and Product Owners to ensure delivery throughout the lifecycle of the product. Tracks and communicates status to wider team and management as needed. ", "techs": ["microsoft power bi"]}, "7fab8477e3c7b0ac": {"terms": ["data analyst"], "salary_min": null, "salary_max": null, "title": "Program Analyst (FT)", "company": "Jamison Professional Services Inc", "desc": "Program Manager - Remote \n \n  Jamison Professional Services, Inc. (\u201cJPS\u201d) is currently seeking a qualified and motivated candidate for the position of Program Analyst.\n   \n \n \n  Labor Category:  Program Analyst - Remote\n   \n \n \n   Successful performance of a Program Analyst under this requirement requires a wide variety of associated duties including research, analysis, systems thinking, data entry, writing, document preparation, editing, scanning, document management, copying, phone calls, faxing, filing, and other activities as necessary to complete the tasks assigned. Contractor Personnel are required to provide data input/extraction and ongoing support of the data systems for VHA Procurement Regional Procurement Offices (RPOs) and Network/Program Contracting Activity. Program Analysts may also be expected to analyze a wide variety of data from conceptualization through presentation of the data to the RPO Program Analyst team.\n   \n \n \n  Responsibilities: \n \n \n  Assists in designing, coordinating, developing, and documenting proposed organization designs, and/or changes in business/programmatic processes, procedures, and/or products. \n  Performs initial reviews of existing processes, procedures, and/or products. \n  Gathers and compiles data for reports to develop comprehensive studies for decision-making purposes and ensures information is provided within necessary time frames. \n  Organizes and analyzes data from all applicable sources, using statistical methods to ensure the validity of results. \n  Assists in the development of recommendations for changes to improve systems, applications, processes, or products. \n  Provides data and trend analysis during exploratory and informative stages. \n  Briefs RPO Program Analysts on problem areas, corrective action to be taken, and the monitoring of those actions once implemented. \n  Responds to all customer inquiries and concerns and recommends alternate approaches when customers' request cannot be met. \n \n \n  Qualifications: \n \n \n  Work Experience:  A minimum of four (4) recent years of relevant experience in conducting comprehensive program analyst services.\n   \n \n Education:  Program Analysts shall have, at a minimum, a relevant bachelor\u2019s degree from an accredited college or university.\n   \n \n \n  Additional Knowledge and Skills:  In addition to the experience and educational requirements described above, Program Analysts shall clearly possess the following knowledge and skills:\n  \n \n  Working knowledge of PC software packages, such as Microsoft Power BI, Power Automate, Excel, Access, SharePoint, various Microsoft programs, and other Business Intelligence software. \n  Experience with established program analysis principles, theories, and practices, including knowledge of various analytical techniques (audits, databases, spreadsheet/graphics analysis) \n  Working knowledge of qualitative and/or quantitative data analytic methods for the assessment and suggested improvements of program effectiveness. \n \n \n \n  Place of Performance: \n \n \n   This requirement requires contractor personnel to work off-site (remote). Travel to the nearest VA Medical Center is required for onboarding (fingerprinting, PIV picture, PIV card, and GFE). Contractor personnel are usually required to physically access the nearest VA facility when receiving GFE.\n   \n \n Electronic Media: \n  All contractor employees shall be knowledgeable and proficient in the use of Microsoft Office basic tools and software: Word, Excel, Outlook, and SharePoint. It is mandatory that all contract employees be proficient with modern computing equipment.\n   \n \n English Language Requirement: \n  The Contractor shall ensure all personnel are able to read, write, and speak English well enough to effectively communicate.\n   \n \n U.S. Citizenship:  \n  All contractor personnel performing under this contract shall be U.S. citizens. \n  \n \n Jamison Corporate Overview: \n \n \n \n   Jamison Professional Services, Inc. (Jamison) is a Service-Disabled, Veteran-Owned Small Business (SDVOSB), certified Minority Business Enterprise (MBE) headquartered in metropolitan Atlanta, Georgia. We specialize in providing professional management, administrative, healthcare, court reporters and transcriptionist experts, and document/ record and telehealth operational support solutions to U.S. Government, State, and commercial clients. Jamison is a nationwide professional staff augmentation company, that helps commercial clients and government agencies expand their talent acquisition reach by sourcing, assessing, developing, and managing the talent that enables them to be successful.\n   \n \n \n   Jamison offers a wide range of employment opportunities in the commercial and government sectors. We seek employees who share our values of service excellence, integrity, and professionalism.\n   \n \n \n   Jamison affords equal employment opportunity to all individuals, regardless of race, creed, color, religion, gender, national origin, ancestry, age, marital status, veteran status, disability, medical condition, gender identity, or sexual orientation. Our employees, as well as applicants and others with whom we do business, will not be subjected to sexual, racial, religious, ethnic, or any other form of unlawful harassment and/or discrimination. In addition, JPS adheres to the equal employment opportunity requirements of all states and localities in which it does business.\n   \n \n \n   Jamison\u2019s commitment to equal opportunity is applied through every aspect of the employment relationship, including, but not limited to, recruitment, selection, placement, training, compensation, promotion, transfer, termination, and all other matters of employment.\n   \n \n \n   Applicants may be required to successfully complete an online assessment to determine qualifications for positions requiring specific skills.\n   \n \n \n   All applications must be submitted through our application system at: https://www.jps-online.com/apply-now/\n  \n \n \n About Jamison Professional Services Inc: \n \n \n Jamison Professional Services, Inc. (Jamison) is a Service-Disabled, Veteran-Owned Small Business (SDVOSB), certified Minority Business Enterprise (MBE) headquartered in metropolitan Atlanta, Georgia, founded in 1993. As a nationwide professional staff augmentation company, we help commercial clients and government agencies expand their talent acquisition reach by sourcing, assessing, developing, and managing the talent that enables them to be successful. We have provided talent solutions and operational solutions in the areas of program management, financial management, acquisition support, and strategic planning/consulting to over 30 U.S. Government agencies, including all four branches of the military.", "cleaned_desc": "", "techs": ""}, "fae725f033d9ad81": {"terms": ["data analyst"], "salary_min": null, "salary_max": null, "title": "Business Analyst (Senior)- Remote - Eastern Time Zone Only", "company": "WellSpan Health", "desc": "Summary   \n \n Job Description: \n Under general supervision, the Business Analyst (Senior) is responsible for retrieving, interpreting, and analyzing data to drive key business decisions and actions, measure program efficacy and contribute to strategic direction. Helps drive the success of the business by providing business analyses and analytical solutions to guide management and operational decision-making. The individual will work on projects and products dealing with key performance metrics tracking, financial and business assessments of potential strategic initiatives and other ad hoc requests. The solutions could range from dashboards in advanced BI content to exploratory analysis and impact assessments that leads to strategic recommendations. This position will work collaboratively with associates across different levels, functions, business units and regions to support all data and analytical products. Working with other teams across the Analytics Center of Excellence (ACoE), participates as a catalyst for maintaining the product life cycle, focusing on system strategic goals and objectives, assist business stakeholders with formulating appropriate data and analytics questions that will lead to analyses which will reveal relevant insights. Assists stakeholders with interpreting results, at times applying visualization techniques (e.g., Microsoft Power BI). Collaborates with developers and end users to ensure technical requirements and specifications reflect appropriate business logic. In this role, the Business Analyst (Senior) engages with various groups within WellSpan to gather business requirements while ensuring that these requirements align to the various analytics products existing or currently underway. There will be opportunities to enhance business processes and the requirement to build test cases and support functional testing and UAT. This position will leverage the analytics spectrum to tell a story with the data, working with senior level analysts to ensure the application of the most appropriate approach for each business need. This position requires the soft skill of story-telling through data, by turning technical information into easy-to-understand non-technical action items. Confidence in presentation of findings and excellent communication skills are desired. This position will develop the ability to view business problems from varying perspectives and continuously display curiosity. \n Duties and Responsibilities \n \n \n Works with partners across the WellSpan business domains to gather detailed business requirements. Be point person for collation of requirements and subsequent sharing and obtaining of sign offs. Defines testing approach and strategy and help execute this strategy during test phases of project. \n \n \n Works with engineering and development team members to define the functional and technical design to support business processing requirements for data and analytics products. \n \n \n Works with the Product Manager and Product Owners to ensure delivery throughout the lifecycle of the product. Tracks and communicates status to wider team and management as needed. \n \n \n Collaborates with the development team on test plan development, design test strategy and manage the UAT process. \n \n \n Assists customers with formulating appropriate data questions to meet business and strategic needs. \n \n \n Able to take a business question or need and turn it into a data question for the purpose of transforming and analyzing the data to extract an answer to that question. \n \n \n Supports the ACoE data and analytics strategy, processes, technical architecture, and design of subject areas. \n \n \n Collaborates with developers and end users to ensure technical requirements and specifications reflect appropriate business logic. \n \n \n Supports system wide data integrity, quality control and standardization as identified by system leaders and/or system level teams. \n \n \n Mentors other business analysts and work with leadership in establishing and adopting best practices within business analysis, product owner and scrum master responsibilities \n \n \n Qualifications \n \n Minimum Experience: \n    \n 7 Years of experience as a Business Analyst \n Experience in Market Analytics \n \n \n \n \n Min Field of Expertise: Healthcare operations or Data and Analytics related experience \n \n \n \n \n Minimum Education: \n    \n Bachelor's Degree \n \n \n \n \n Skills: \n    \n Business Analysis, Business Requirements Documents, Project Management \n Experience in Agile methodologies, writing User Stories, Using Jira \n Strong teamwork/communication/customer service skills. \n \n \n \n # Remote (Eastern time zone only)", "cleaned_desc": "", "techs": ""}, "32e4c6782f5c8c86": {"terms": ["data analyst"], "salary_min": 109080.0, "salary_max": 109080.0, "title": "Business Information Analyst Senior - CarelonRx", "company": "Elevance Health", "desc": "Job Family: Data Warehousing and Business Information  \n Type: Full time \n Date Posted: Oct 19, 2023  \n Req #: JR92826 \n \n \n \n Description \n Business Information Analyst Senior - CarelonRx  \n Location:  The primary location of this role is in St. Louis, MO, with additional locations in Atlanta, GA; Chicago, IL; Mason, OH; Norfolk, VA; Miami, FL; and New York City, NY. This position is part of Elevance Health hybrid work model (remote and office). Ideal candidate will live within 50 miles of one of our PulsePoint Locations.  \n The  Business Information Analyst Senior - CarelonRx is  responsible for analyzing, reporting and developing recommendations on data related to complex and varied business metrics. Typically provides technical assistance to lower-level staff.  \n How you will make an impact:  \n \n Creates and maintains databases to track business performance.  \n Analyzes data and summarizes performance using summary statistical procedures.  \n Develops and analyzes business performance reports (e.g. for claims data, provider data, utilization data) and provides notations of performance deviations and anomalies.  \n Creates and publishes periodic reports, as well as any necessary ad hoc reports.  \n May require taking business issue and devising best way to develop appropriate diagnostic and/or tracking data that will translate business requirements into usable decision support tools.  \n May make recommendations based upon data analysis.  \n \n Minimum Requirements:  \n \n Requires a BS/BA degree in related field and a minimum of 3 years data analysis or related experience; or any combination of education and experience which would provide an equivalent background.  \n Minimum 3 years' experience with relational databases and knowledge of query tools and statistical software.  \n \n Preferred Skills, Capabilities and Experiences:  \n \n Pharmacy or Healthcare experience strongly preferred.  \n Minimum 1 year experience with Tableau preferred.  \n Ability to manipulate large sets of data is strongly preferred.  \n Knowledge of SLQ and BI Tools  \n Strong analytical, organizational and problem solving skills are strongly preferred.  \n \n For candidates working in person or remotely in the below locations, the salary* range for this specific position is $109,080.00 to $130,896.00.  \n Location: New York City, NY  \n In addition to your salary, Elevance Health offers benefits such as, a comprehensive benefits package, incentive and recognition programs, equity stock purchase and 401k contribution (all benefits are subject to eligibility requirements). The salary offered for this specific position is based on a number of legitimate, non-discriminatory factors set by the company. The company is fully committed to ensuring equal pay opportunities for equal work regardless of gender, race, or any other category protected by federal, state, and local pay equity laws  .  \n \n The salary range is the range Elevance Health in good faith believes is the range of possible compensation for this role at the time of this posting. This range may be modified in the future and actual compensation may vary from posting based on geographic location, work experience, education and/or skill level. Even within the range, the actual compensation will vary depending on the above factors as well as market/business considerations. No amount is considered to be wages or compensation until such amount is earned, vested, and determinable under the terms and conditions of the applicable policies and plans. The amount and availability of any bonus, commission, benefits, or any other form of compensation and benefits that are allocable to a particular employee remains in the Company's sole discretion unless and until paid and may be modified at the Company\u2019s sole discretion, consistent with the law.   \n \n \n Please be advised that Elevance Health only accepts resumes from agencies that have a signed agreement with Elevance Health. Accordingly, Elevance Health is not obligated to pay referral fees to any agency that is not a party to an agreement with Elevance Health. Thus, any unsolicited resumes, including those submitted to hiring managers, are deemed to be the property of Elevance Health. \n  Be part of an Extraordinary Team \n  Elevance Health is a health company dedicated to improving lives and communities \u2013 and making healthcare simpler. A Fortune 20 company with a longstanding history in the healthcare industry, we are looking for leaders at all levels of the organization who are passionate about making an impact on our members and the communities we serve. You will thrive in a complex and collaborative environment where you take action and ownership to solve problems and lead change. Do you want to be part of a larger purpose and an evolving, high-performance culture that empowers you to make an impact? \n  We offer a range of market-competitive total rewards that include merit increases, paid holidays, Paid Time Off, and incentive bonus programs (unless covered by a collective bargaining agreement), medical, dental, vision, short and long term disability benefits, 401(k) +match, stock purchase plan, life insurance, wellness programs and financial education resources, to name a few. \n  Elevance Health operates in a Hybrid Workforce Strategy, providing various levels of flexibility while also ensuring that associates have opportunities to connect in-person. Unless in a designated virtual-eligible role and specified as primarily virtual by the hiring manager, associates are required to work at an Elevance Health location at least once per week, and potentially several times per week. Specific requirements and expectations for time onsite will be discussed as part of the hiring process. Candidates must reside within 50 miles or 1-hour commute each way of a relevant Elevance Health location. \n  The health of our associates and communities is a top priority for Elevance Health. We require all new candidates in certain patient/member-facing roles to become vaccinated against COVID-19. If you are not vaccinated, your offer will be rescinded unless you provide \u2013 and Elevance Health approves \u2013 a valid religious or medical explanation as to why you are not able to get vaccinated that Elevance Health is able to reasonably accommodate. Elevance Health will also follow all relevant federal, state and local laws. \n  Elevance Health has been named as a Fortune Great Place To Work in 2022, has been ranked for five years running as one of the 2023 World\u2019s Most Admired Companies by Fortune magazine, and is a growing Top 20 Fortune 500 Company. To learn more about our company and apply, please visit us at careers.ElevanceHealth.com. Elevance Health is an Equal Employment Opportunity employer and all qualified applicants will receive consideration for employment without regard to age, citizenship status, color, creed, disability, ethnicity, genetic information, gender (including gender identity and gender expression), marital status, national origin, race, religion, sex, sexual orientation, veteran status or any other status or condition protected by applicable federal, state, or local laws. Applicants who require accommodation to participate in the job application process may contact ability@icareerhelp.com for assistance.", "cleaned_desc": " May make recommendations based upon data analysis.  \n \n Minimum Requirements:  \n \n Requires a BS/BA degree in related field and a minimum of 3 years data analysis or related experience; or any combination of education and experience which would provide an equivalent background.  \n Minimum 3 years' experience with relational databases and knowledge of query tools and statistical software.  \n \n Preferred Skills, Capabilities and Experiences:  \n ", "techs": ["relational databases", "query tools", "statistical software"]}, "bdbbc9f02e51f0f4": {"terms": ["data analyst"], "salary_min": 73500.0, "salary_max": 150000.0, "title": "Sr. IAM Controls Testing Analyst", "company": "CVS Health", "desc": "Bring your heart to CVS Health. Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand \u2014 with heart at its center \u2014 our purpose sends a personal message that how we deliver our services is just as important as what we deliver.    Our Heart At Work Behaviors\u2122 support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable. \n \n  Position Summary \n \n   Key focus on testing the Identity Access Management (IAM) control standards. This will include helping to build out the testing program and execute to that program.\n   \n \n may include participation in all Controls & Governance activities including: \n  o Development and Interpretation of Control Standards, Procedures\n    o Development and measurement of Key Risk Indicators\n    o Conducting Risk Control Self Assessments\n    o Execution of IAM controls including Periodic Access Review\n    o Issue identification and management\n    o Liaison with other oversight organizations such as audit teams\n   \n \n Advisory on process changes impacting IAM workflows to ensure compliance with firm standards \n Participate in developing IAM solutions \u2013 representing the GRC needs \n Communicate and educate business and IT colleagues on IAM GRC topics \n \n \n  Required Qualifications \n \n \n Experience conducting audit/assessment type control testing \n knowledge and experience with legal, privacy, and regulatory compliance \n Familiarity with standards such NIST 800, ISO 27000 \n Familiarity with SOX, SOC, PCI Audits \n 3+ years of experience working in IT Audit (preferred), Controls & Governance, Risk, and/or compliance function \n \n  Preferred Qualifications \n \n Ability to handle multiple competing priorities. \n Self-starter, ability to work across organizations, drive projects to closure \u2013 result and relationship focused. \n Ability to identify problems, analyze data, and present conclusions convincingly \n Strong verbal, written, and presentations skills \n Experience with compliance or regulatory issues preferred \n Strong verbal, written, and presentations skills \n Exposure to IAM technology, solutions and concepts \u2013 Authentication, Authorization etc. \n \n  Education \n  Bachelors degree or eq \n \n  Pay Range \n  The typical pay range for this role is: \n  $73,500.00 - $150,000.00\n  \n  This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above.    In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company\u2019s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (\u201cPTO\u201d) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies.    For more detailed information on available benefits, please visit jobs.CVSHealth.com/benefits \n \n  CVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated. \n \n  You are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work. \n \n  CVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health can provide a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services through ColleagueRelations@CVSHealth.com If you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.", "cleaned_desc": "  Preferred Qualifications \n \n Ability to handle multiple competing priorities. \n Self-starter, ability to work across organizations, drive projects to closure \u2013 result and relationship focused. \n Ability to identify problems, analyze data, and present conclusions convincingly \n Strong verbal, written, and presentations skills \n Experience with compliance or regulatory issues preferred \n Strong verbal, written, and presentations skills \n Exposure to IAM technology, solutions and concepts \u2013 Authentication, Authorization etc. \n ", "techs": ["iam technology"]}, "efadf840d8745f30": {"terms": ["data analyst"], "salary_min": 95000.0, "salary_max": 110000.0, "title": "Sr Business Analyst - Remote", "company": "Universal Technical Institute", "desc": "Overview: \n  \n   The Senior Business Analyst conducts detailed analysis, defines business requirements, and acts as a liaison between the business owners and Information Technology development Scrum teams, in a customer-centric environment. This position supports other members of the BA team by providing training. They contribute and improve processes across business units and Scrum teams.\n  \n \n \n  The Senior Business Analyst is considered Competent or Proficient in all areas of Business Analysis practice, having good or in-depth knowledge of all related skill areas. The position is important to Learning Technologies team to assist with courseware updates, Blackboard course maintenance and working with all campuses to ensure that the content changes and grading policies are aligned. \n  Responsibilities: \n  \n Partners with assigned business areas to understand and prioritize information needs, and translate business requirements into system solutions \n  Captures customer requirements through iterative structured interviews with subject matter experts \n  Develops current / future state user stories, process flows, and CRC models from customer interviews \n  Collaborates with business areas to define business processes \n  Educates IT on the direction of the business \n  Responsible for developing acceptance criteria and requirements from user stories, customer interviews, process flows, and CRC models \n  Responsible for the quality and accuracy of each requirements specification \n  Responsible for understanding all aspects of each solution \n  Traces requirements from scope through design, development, and testing \n  Collaborates with Developers and Report Writers to ensure accurate design and implementation of business/system requirements \n  Collaborates with Quality Assurance Analyst to ensure comprehensive requirements based testing is achieved \n  Collaborates with Scrum Master to ensure team objectives are met \n  Participates in solution design \n  Participates in buy versus build discussions \n  Provide teaching, coaching and mentoring to IT staff \n  Assist in the development of UTI processes \n  Other duties as assigned \n  Qualifications: \n  \n   Education / Experience\n  \n \n  Bachelor\u2019s or Master\u2019s degree in a business or IT discipline, or equivalent work experience \n  Requires 7 \u2013 10 years of relevant work experience and growth; typically within IT or working in relevant positions within business units \n  Prefer 4+ years experience as Business Analyst \n  Prefer Certified Business Analysis Professional (CBAP) certification \n  Prefer experience in Learning Technologies like Blackboard or Canvas \n  Requires technical and business knowledge in multiple disciplines / processes \n  Possesses an understanding of IT\u2019s systems and capabilities. \n  Varied experience over different companies, projects, and / or applications \n  Familiar with gathering use cases or user stories through interviews, observations, and interpretation of policies and procedures \n  Significant experience turning use cases into functional requirements \n  Advanced knowledge and demonstrated use of personal computer software applications including Microsoft Office Products (Word, Excel, PowerPoint, and Visio) \n \n \n \n  Skills\n  \n \n  Ability to perform all duties of Business Analyst \n  Ability to analyze business partner\u2019s operations to understand their strengths and weaknesses to determine opportunities to automate processes and functions. \n  Ability to assist the business process redesign and documentation as needed for new technology. \n  Ability to work in a matrixed environment as part of both Business Analysis and Scrum teams \n  Ability to comply with UTI\u2019s Agile, Scrum, and other software development lifecycle practices and standards \n  Excellent verbal and written communication skills \n  Ability to control, lead, and coordinate with multiple levels of staff and project management in both the business and technical areas while keeping discussions at the appropriate level of abstraction \n  Ability to reconcile competing ideas or problems to a mutually beneficial conclusion \n  Ability to collaborate in a non-confrontational manner \n  Ability to contribute and adhere to process \n  Ability to work in a fast-paced environment where deadlines are essential \n  Ability to maintain professional image and work environment \n  Ability to work under minimal direction from management \n  Ability to organize, plan, prioritize and follow through on work \n  Ability to work with all levels of employees and consultants \n  Ability to build & maintain strong relationships \n  Ability to turn ambiguous information into meaningful requirements \n  Ability to facilitate a discussion about business processes with diverse participants \n  Ability to build consensus using a consultative approach \n  Strong logical, analytical, and problem solving skills \n \n \n \n  Abilities\n  \n \n  Must be able to lift, carry, push, or pull up to 5 pounds or less 5% of the workday \n  Must be able stoop, kneel, crouch, or crawl 5% or less of the workday \n  Must be able to talk, see, hear, concentrate, think, learn and reason for all of the workday \n  Must be able to sit and walk or otherwise move around for prolonged periods of time throughout the workday. \n  Must be able to use a keyboard and do manual tasks for prolonged periods of time throughout the workday. \n  May require overnight travel. \n \n \n \n  Work Environment\n  \n \n  Work is performed indoors in a climate controlled environment. \n \n \n   Pay and Benefits\n  \n \n  Salary range $95,000/yr - $110,000/yr depending on experience \n  Medical, dental, vision \n  Company paid LTD & STD \n  401K with Company match \n \n  #LI-PW1", "cleaned_desc": "  Varied experience over different companies, projects, and / or applications \n  Familiar with gathering use cases or user stories through interviews, observations, and interpretation of policies and procedures \n  Significant experience turning use cases into functional requirements \n  Advanced knowledge and demonstrated use of personal computer software applications including Microsoft Office Products (Word, Excel, PowerPoint, and Visio) \n \n \n \n  Skills\n  \n \n  Ability to perform all duties of Business Analyst \n  Ability to analyze business partner\u2019s operations to understand their strengths and weaknesses to determine opportunities to automate processes and functions. \n  Ability to assist the business process redesign and documentation as needed for new technology. \n  Ability to work in a matrixed environment as part of both Business Analysis and Scrum teams \n  Ability to comply with UTI\u2019s Agile, Scrum, and other software development lifecycle practices and standards \n  Excellent verbal and written communication skills \n  Ability to control, lead, and coordinate with multiple levels of staff and project management in both the business and technical areas while keeping discussions at the appropriate level of abstraction \n  Ability to reconcile competing ideas or problems to a mutually beneficial conclusion \n  Ability to collaborate in a non-confrontational manner ", "techs": ["microsoft office products (word", "excel", "powerpoint", "visio)"]}, "a50749afcdf1c93e": {"terms": ["data analyst"], "salary_min": null, "salary_max": null, "title": "Business Analyst (Senior)/CTO", "company": "Precise Software Solutions, Inc.", "desc": "The Senior Business Analyst/Scrum Master is responsible for gathering and documenting system/business requirements in the form of user stories and use cases, perform requirement analysis and systems analysis, facilitating design and development of software solutions, assisting with the testing process, and helping quality assurance process. \n  While this position is remote, successful applicants ideally reside within a 2-3 hour drive to the D.C./Maryland/Northern Virginia metropolitan area. \n  Successful candidates must be able to complete a Public Trust background check, requiring U.S. residency for 3 of the past 5 years. \n  Responsibilities   \n Responsible for stakeholder management, requirement elicitation, preparing estimations for business analysis tasks and deliverables, systems analysis, preparing functional specifications using user stories, acceptance criteria and use case narration. Responsible for ensuring unique business needs are properly translated to functional specifications and provide a system solution, assisting with the maintenance of project schedules and developing various status reports.  \n Job Requirements   \n \n Plan out business analysis efforts, including stakeholder analysis, communication planning, and elicitation techniques. \n  Facilitate requirements meetings, interview sessions, brainstorming, documentation analysis, and other techniques as necessary. \n  Support customer meetings to understand current client business practices and business needs supporting requirements analysis. \n  Ensure that requirement statements are complete, consistent, concise, comprehensible, traceable, feasible, unambiguous, and verifiable, and that they conform to standards. \n  Validate requirements with business stakeholders and team members. \n  Collaborate with stakeholders and team members regarding requirements development and translation into software specifications. \n  Support traceability efforts from high-level business needs through functional validation. \n  Participate in requirements prioritization and backlog grooming sessions. \n  Write detailed descriptions of user needs, program functions and dependencies required to develop or modify applications. \n  Manage changes to baselined requirements through effective application of change control processes and tools. \n  Works closely with developers and testers to ensure all requirements are understood and have corresponding test scripts. \n \n  Required Skills   \n \n Six plus years of work experience in Information Technology as a Business Analyst and Tester in an Agile environment. \n  Facilitates meetings with business owners, technical leads, and other stakeholders. \n  Works as the Scrum Master for technical team coordination.  \n Captures business needs and develops corresponding functional solutions. \n  Facilitates development of technical requirements, user stories, and mockups to address business needs and work with developers and testers to ensure prototype solutions meet expectations.  \n Develops Weekly Status presentations.  \n Estimates testing levels of effort for requirements.  \n Determines testing approach for break/fix and enhancement requests.  \n Supports UAT prep efforts in conjunction with business owners/ users. \n  Proficient in Microsoft Office tools \n  MS Word, Excel, Project, PowerPoint \n  Proficient in formal software development life cycle processes \n  Proficient with JIRA and/or Microsoft DevOps \n  Demonstrated abilities as a driven, self-starter and quick study \n  Story Creation \n  Customization \n  Report Generation \n \n  Desired Skills   \n \n Experience in a government environment \n  Agile development practices \n  MS Visio \n \n  EDUCATION AND CERTIFICATIONS   \n BS Degree from an accredited college in Information Systems, Business Administration or related discipline required. MS preferred.  Pluses:  Certified Analytics Professional (CAP); Certified Scrum Master (CSM) \n  ABOUT US \n  Precise Software Solutions, Inc., an SBA 8(a) program participant, is an innovative small business with a proven record of success delivering quality services and solutions to government organizations. A CMMI Level 3 company, Precise serves as a trusted advisor to senior technology executives and helps government agencies enhance and expand their information technology capabilities. Precise helps their customers capitalize on the efficiencies offered by technological advancements and ensures the integrity of their IT systems and programs so they can perform their public mission more effectively. The company is known for delivering agile and innovative solutions and specializes in strategic consulting, system modernization and integration, digital transformation and experience, infrastructure and cloud implementation, and data management and analytics. \n  BENEFITS AND PERKS: \n \n  Comprehensive Health Benefits (Medical, Dental and Vision) including High Deductible Health plan where company pays 100% of the deductible for your family. \n  Flexible Spending Accounts (FSA) & Health Savings Account (HSA) \n  Retirement Plan with 4% match and discretionary match at year end \n  Paid Time Off (PTO): 15 days of PTO accrued per year; 7 holidays+ 3 Floating holidays; 2 Innovation days (paid training days) \n  Short Term and Long-Term Disability \n  Paid Parental Leave \n  Paid Jury Duty leave \n  Life and AD&D Insurance \n  Critical Illness Insurance \n  Training and Development \n  Wellness Incentives & Discount programs \n  Employee Referral Program \n  Annual Charity Donation Match \n  Awards and Recognition \n \n  Our Equal Employment Opportunity Policy \n  Precise is an equal opportunity employer. The company shall not discriminate against any employee or applicant because of race, color, religion, creed, sex, sexual orientation, gender or gender identity (except where gender is a bona fide occupational qualification), national origin, age, disability, military/veteran status, marital status, genetic information or any other factor protected by law. We are committed to equal employment opportunity in all decisions related to employment, promotion, wages, benefits and all other privileges, terms and conditions of employment. The company is dedicated to seeking all qualified applicants. \n   \n vaFu83VDQN", "cleaned_desc": "", "techs": ""}, "016f15efafef55f0": {"terms": ["data analyst"], "salary_min": 89399.25, "salary_max": 113199.375, "title": "Senior Business Analyst - Health (HYBRID)", "company": "Inclusively", "desc": "Inclusively is partnering with a multinational financial services company to hire a Senior Business Analyst - Health (HYBRID). \n ABOUT INCLUSIVELY: \n Inclusively is a digital tech platform that connects candidates with disabilities, who may benefit from workplace accommodations, to inclusive employers. This includes all disabilities under the ADA, including mental health conditions (e.g. anxiety, depression, PTSD), chronic illnesses (e.g. diabetes, Long COVID), and neurodivergence (e.g. autism, ADHD).  Applicants with one or more of these conditions are encouraged to apply; Inclusively does not require applicants to disclose their specific disability. \n The Expertise and Skills You Bring \n \n Bachelor\u2019s degree or equivalent years of experience required \n 5+ years software Development Business Analyst experience, ideally working in an Agile Scrum environment, with demonstrable ability to work across multiple multi-functional teams or Master\u2019s degree in related filed with solid software product development skills. \n Solid understanding industry experience in health care and/or benefits administration and/or product development preferred. \n Shown expertise in various business analysis methodologies and techniques, including data analysis, use case development, story writing, user acceptance testing, and product documentation. \n Solid grasp of the architecture and deployment needed to support web development \n Interact closely with Subject Matter Experts and stakeholders across Health Benefits domain to elicit Product requirements \n Work with UXD teams to support prototyping \n Skilled in MS Word, Excel, PowerPoint, Visio; Experience with JIRA or similar agile backlog management and testing tool \n Certified Business Analysis Professional\u00ae (CBAP\u00ae) certification or Certified Scrum Product Owner certification is a plus \n Skilled at translating business vision into defined and prioritized user stories for team\u2019s backlog \n Ability to understand complex customer needs, translate them into user stories with concrete acceptance criteria, and drive solution formulation with a multi-functional team \n Customer-obsessed and have demonstrated a commitment to delivering frequent, high business value features \n Look for opportunities to innovate and take thoughtful risks to get work done better and faster \n Excellent listening, communication (verbal and written), and presentation skills \n You effectively and regularly lead, facilitate, and drive individuals and group meetings to common goals \n You are highly organized and have a strong ability to prioritize and work under tight deadlines \n Skilled at building relationships, fostering strong teams, and influencing others \n You are a self-motivated, great teammate with the ability to plan and complete work independently, and partner effectively to handle dependencies \n Strong desire to learn and develop additional skills and expertise over time, as well as drive process improvement \n You have excellent business judgement and maintain confidentiality of all data \n Providing consulting, support, and guidance to leadership, squad members, and other relevant partners to influence culture and behaviors \n \n The Value You Deliver \n \n Working in a Scrum Agile environment to deliver software products \n Leading and conducting business analyses to formulate and make recommendations \n Identifying and defining solutions to business problems, through creation and documentation of systems and process specifications \n Creating, documenting, and leading scrum team backlog (writing user stories / acceptance criteria, supporting prioritization, running refinement sessions, etc.) \n Collaborate closely with business partners, development teams, external vendors, and QA on plans, project management, requirements, design, testing, and implementation of solutions throughout the development lifecycle \n Supporting deployment, business readiness, and solution enablement, e.g., defining and documenting enablement tasks, supporting user procedure documentation, creation and delivery of solution training to internal teams, and communication \n Prioritize multiple initiatives and business analysis tasks at the same time \n \n Job Type: Full-time \n Schedule: \n \n Monday to Friday \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "5eb960d5ac7757a6": {"terms": ["data analyst"], "salary_min": 85741.09, "salary_max": 108567.33, "title": "Senior Knowledge Enablement Technical Business Analyst", "company": "Jack Henry and Associates, Inc.", "desc": "Do you have strong analytical skills? Do you have specialized knowledge in Jack Henry Banking core software? Do you like collaborating with development? Do you like educating on technology? If so, this may be the job for you. The Knowledge Enablement (KE) organization has a current opening for Technical Business Analyst Position with our Strategic Partnerships department.  \n This Technical Business Analysts position must have subject matter expertise in one or more of the Jack Henry Banking core software programs (CIF 20/20, Core Director, SilverLake).  The analyst is responsible for attending development meetings as an operational subject matter expert, gathering, and synthesizing technical information for the purpose of educating customers and associates on new products, features and releases. They will partner with other Knowledge Enablement groups to ensure all documentation and educational offerings are updated appropriately within expected timeframes, and other associates are cross-trained. \n \n    At Jack Henry, we deliver technology solutions that are digitally transforming and empowering community banks and credit unions to provide enhanced and streamlined user experiences to their customers and members. Our best-in-class products are just the start as we lay the groundwork for the future of digital banking and payments. We hope you\u2019ll join us. We can\u2019t do it without you.\n   \n \n  About Our Team  \n The Knowledge Enablement Team is a collaborative group of fun and innovative individuals who work together to deliver documentation and education to JH clients and associates. The Technical Business Analyst position is integral in ensuring alignment between KE and JH\u2019s research and development areas. \n \n \n \n  What you\u2019ll be responsible for:  \n \n \n \n Liaison with research and development teams to gather and inform KE on new products, features, and releases. \n  Responsible for creating business requirements, system documentation, and release overview training. \n  Responsible for cross-training Knowledge Enablement associates on new releases. \n  Ensures enhancements are migrated into necessary environments; may perform application, system, and regression testing. \n  Serves as a resource and/or participant in business process re-design activities. \n  May assist less experienced peers. May act as a team lead. \n  May perform other job duties as assigned. \n \n \n \n \n  What you\u2019ll need to have: \n \n \n \n  Minimum of 10 years' experience with Jack Henry Banking Software. \n \n \n \n \n  What would be nice for you to have:  \n \n \n \n Associate or bachelor's degree preferred. \n  Strong written and verbal communication skills. \n  Exceptional professional expertise. Works on complex projects with no supervision. Exercises judgment within defined procedures and practices. \n  General knowledge in the following areas: \n \n  Financial/banking or related industry. \n  JH products, equivalent competitor products, and understanding of application functions. \n  General knowledge of applications including Microsoft Suite products. \n  General knowledge in banking business operations and procedures including concepts, structures, etc. \n \n  Able to: \n \n  Analyze/convert customer information and processes for setup in JH system. Analyze business information and processes. \n  Train others to use JH software. \n  Work with all levels of personnel and communicate complex information in user-friendly terms. \n \n \n \n \n \n  If you got this far, we hope you're feeling excited about this opportunity. Even if you don't feel you meet every single requirement on this posting, we still encourage you to apply. We're eager to meet motivated people who align with Jack Henry\u2019s mission and can contribute to our company in a variety of ways.\n   \n \n \n \n \n Why Jack Henry? \n \n \n \n  At Jack Henry, we pride ourselves through our motto of, \"Do the right thing, do whatever it takes, and have fun.\" We recognize the value of our associates and believe much of our company\u2019s strength and success depends on their well-being.\n   \n \n \n \n \n  We demonstrate our commitment by offering outstanding benefit programs to ensure the physical, mental & financial wellbeing of our people is always met.\n  \n \n \n \n \n  Culture of Commitment \n \n \n \n \n \n   Ask our associates why they love Jack Henry, and many will tell you it is because our culture is exceptional. We do great things together. Rising to meet challenges and seeking opportunities is part of who we are as an organization. Our culture has helped us stay strong through challenging times and we credit our dedicated associates for our success. Visit our Corporate Responsibility site to learn more about our culture and commitment to our people, customers, community, environment, and shareholders.\n   \n \n \n \n \n Equal Employment Opportunity \n \n \n \n \n \n   At Jack Henry, we know we are better together. We value, respect, and protect the uniqueness each of us brings. Innovation flourishes by including all voices and makes our business\u2014and our society\u2014stronger. Jack Henry is an equal opportunity employer and we are committed to providing equal opportunity in all of our employment practices, including selection, hiring, performance management, promotion, transfer, compensation, benefits, education, training, social, and recreational activities to all persons regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, genetic information, pregnancy, marital status, sex, gender, gender identity, gender expression, age, sexual orientation, and military and veteran status, or any other protected status protected by local, state or federal law.\n  \n \n \n \n \n   No one will be subject to, and Jack Henry prohibits, any form of discipline, reprisal, intimidation, or retaliation for good faith reports or complaints of incidents of discrimination of any kind, pursuing any discrimination claim, or cooperating in related investigations.\n  \n \n \n \n \n  Requests for full corporate job description may be requested through the interview process at any time.", "cleaned_desc": "", "techs": ""}, "6690fadf23d9c8ec": {"terms": ["data analyst"], "salary_min": 75000.0, "salary_max": 85000.0, "title": "Business Technical Analyst", "company": "Ascendion", "desc": "Description \n About Ascendion \n  Ascendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next. \n  Ascendion | Engineering to elevate life | www.ascendion.com \n  We have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us: \n \n Build the coolest tech for the world\u2019s leading brands \n Solve complex problems \u2013 and learn new skills \n Experience the power of transforming digital engineering for Fortune 500 clients \n Master your craft with leading training programs and hands-on experience \n \n Experience a community of change-makers!  Join a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion. \n  About the Role: \n  Location:  Remote work \n  Description: \n \n We are looking for a Business Technical Analyst/Developer to support a large healthcare organization in Tampa, FL. \n This group will be working with the risk adjustment team to help reconcile healthcare datasets. \n They are building out dashboards, reports, and visualizations in Power BI related to Medicare and Medicaid datasets. \n \n Must Haves: \n \n 4+ years of experience with SAS and SQL. \n 4+ years of experience with Power BI for building out complex dashboards. \n Strong experience working with large database sets and dealing with database management. \n Healthcare experience with Medicaid and Medicare specifically. \n \n Salary Range : The salary for this position is between $75k - $85k annually. Factors that may affect pay within this range may include geography/market, skills, education, experience, and other qualifications of the successful candidate. \n  Benefits : The company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [5 personal days accrued each calendar year. The Paid time off benefits meet the paid sick and safe time laws that pertain to the City/ State] [10-15 days of paid vacation time] [6 paid holidays and 1 floating holiday per calendar year] [Ascendion Learning Management System] \n  Want to change the world? Let us know.  Tell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let\u2019s talk! \n Preferred Skills: \n \n SAS \n  SQL \n  Power BI \n  Reporting \n  Dashboarding \n  Visualization \n  Large Datasets \n \n Job details \n \n \n Job ID \n \n \n   328894\n   \n \n \n \n Job Requirements \n \n \n   Business Technical Analyst\n   \n \n \n \n \n Location \n \n \n   Tampa, Florida, US\n   \n \n \n \n \n Recruiter \n \n \n   Harshita\n   \n \n \n \n Email \n \n \n   harshita.sahu@ascendion.com\n   \n \n \n \n Phone \n \n \n   7042475818", "cleaned_desc": "", "techs": ""}, "247560a5d70ea4ab": {"terms": ["data analyst"], "salary_min": 88816.07, "salary_max": 112460.93, "title": "Salesforce Business Analyst", "company": "REI Systems", "desc": "Overview: \n  \n   REI Systems provides reliable, effective, and innovative technology solutions that advance federal, state, local, and nonprofit missions. Our technologists and consultants are passionate about solving complex challenges that impact millions of lives. We take a Mindful Modernization approach in delivering our application modernization, grants management systems, government data analytics, and advisory services. Mindful Modernization is the REI Way of delivering mission impact by aligning our government customers\u2019 strategic objectives to measurable outcomes through people, processes, and technology. Learn more at REIsystems.com.\n  \n \n \n  Employees voted REI Systems a Washington Post Top Workplace in 2015, 2016, 2018, 2020, 2021 and 2022!\n   Responsibilities: \n  \n  Position Overview: \n \n \n  Hands-on experience with Salesforce (Classic and  Lightning ) \n  Exposure to various Salesforce products (e.g., Sales Cloud, Service Cloud, Salesforce Community Portal, Partner Portal experience, Data Loader) \n  Data Analytics and Migration \n  Strong documentation expertise \n  Gathering requirements \n  Agile methodology \n  Build and support Salesforce applications and customizations \n  Configure and develop custom objects/apps using Salesforce.com \n  Facilitate the testing and release of software solutions  \n Provide support to the user community \n  Regularly communicate complex technical issues to non-technical business leaders and technical project stakeholders by providing timely generation and distribution of communication \n  Monitors progress of technical issue resolution and negotiate solutions as necessary \n  Qualifications: \n  \n  Required Qualifications: \n \n \n  3 plus years of Salesforce experience as a Business Analyst \n  Agile/Scrum experience \n  2 years with Sales Clouds \n  SFDC Admin Certified/ Sales Cloud Certified \n \n \n  Education Qualifications: \n \n \n   Bachelors degree in Computer Science or any related field\n  \n \n \n  Location:  Hybrid\n  \n \n  Clearance Requirements:  General Public Trust/ability to gain public trust clearance\n  \n \n \n  Covid Policy Disclosure:  \n Should the essential functions of this position require that the employee performing this role work on-site at REI\u2019s Sterling location the following requirements will apply: the individual holding this position must be fully vaccinated, as defined in CDC guidance, as a condition of continued employment. REI will consider requests to be excused from this policy whenever necessary to comply with legal requirements and will consider any requests for reasonable accommodations due to a disability, religion, or other exemptions on an individual basis in accordance with applicable legal requirements. Employees and applicants requesting accommodations should request the accommodation in writing and should explain in detail the reasons why they are seeking an accommodation. REI will request additional information or documentation it deems necessary to inform its decision on an employee\u2019s or applicant\u2019s accommodation request. \n \n \n  EEO Statement:   REI Systems is an Equal Opportunity Employer (Minority/Female/Disability/Vet)", "cleaned_desc": "", "techs": ""}, "e4c3895de6c076ce": {"terms": ["data analyst"], "salary_min": 70.0, "salary_max": 75.0, "title": "Senior Business Analyst (W2)", "company": "TekValue IT Solutions", "desc": "Required Skills: \n Full Software Development Lifecycle experience from a business analysis experience Financial Services experience (Fixed Income Capital Markets) \n Create a Business Requirements Document (BRD) for building a data lake that will house Fixed Income line of business data with a BI/Analytics layer on top to drive more insights into the business. \n Bachelor's degree with a minimum of atleast 7-10 years of industry experience in financial services (Fixed Income Capital Markets). \n Preferably has attained FINRA Series 7 certification NOTES from Hiring IT VP: strongly prefer candidates local to one of these three location in order of preferance (Jersey City, NJ, St, Pete, FL, Memphis, Tenn.) for potential hybrid model \n Need some basic SQL knowledge to query RDBMS, also need strong experience in writing/executing BRD's this area of IT for this group is within the Capital Markets space at RJF role has a chance to extend based on performance and future project work \n Job Type: Contract \n Salary: $70.00 - $75.00 per hour \n Experience level: \n \n 9 years \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n Business analysis: 8 years (Required) \n Financial services: 7 years (Required) \n Fixed Income: 6 years (Required) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "a666da5a2555667f": {"terms": ["data analyst"], "salary_min": 72126.29, "salary_max": 91327.945, "title": "Federal Business Analyst", "company": "Red Carrot", "desc": "Red Carrot is seeking a dedicated and detail-oriented Business Analyst to join our PMO team contracting for a federal client. This Business Analyst will play a crucial role in reviewing requirements, analyzing system development plans, documenting processes, and actively participating in the implementation of system changes. This position requires a proactive and analytical mindset to bridge the gap between business needs and technical solutions. The expected organizational structure is that this Business Analyst will report to the Project Manager and will not have any reporting colleagues. While this is a remote role, an ideal candidate will be located in the DMV area (DC, Maryland, Virginia). \n  KEY RESPONSIBILITIES: \n  Requirements Analysis: \n \n  Collaborate with stakeholders to gather, document, and analyze business requirements. \n  Ensure that requirements are clear, complete, and aligned with business objectives. \n  Identify and communicate any potential issues or discrepancies. \n \n  System Development Analysis: \n \n  Review system development plans, project timelines, and technical specifications. \n  Assess the feasibility and impact of proposed system changes or enhancements. \n  Identify potential risks and propose mitigation strategies. \n \n  Documentation: \n \n  Create detailed business requirement documents (BRDs) and system specifications. \n  Develop process flowcharts, use cases, and user stories to illustrate system functionality. \n  Maintain accurate and up-to-date documentation throughout the project lifecycle. \n \n  Implementation Support: \n \n  Actively participate in the implementation of system changes, working closely with development teams. \n  Verify that implemented solutions meet specified requirements and align with business goals. \n  Provide support and guidance during testing, user acceptance, and post-implementation phases. \n \n  Stakeholder Communication: \n \n  Facilitate communication between business stakeholders and technical teams. \n  Regularly update stakeholders on project progress and seek feedback for continuous improvement. \n \n  Data Analysis: \n \n  Analyze data to identify trends, patterns, and insights that can inform decision-making and improvements. \n  Assist in data-related projects to enhance business operations. \n \n  QUALIFICATIONS: \n  Must Haves: \n \n  Bachelor's degree in business, Information Technology, or a related field. \n  3+ years as a Business Analyst or a directly related role, with a strong focus on requirements analysis and system development. \n  Proficiency with business analysis tools and techniques. \n  Proficient in Microsoft Office 365 \n  Ability to meet requirements to obtain a Public Trust Clearance or an existing Public Trust or Security Clearance \n  Exceptional written and verbal communication skills. \n  Strong organizational and project management abilities. \n  Ability to handle sensitive and confidential information with discretion. \n  Experience using at least 5 of the common business analysis programs and tools; \n \n  Microsoft Office Suite, Microsoft Visio, Microsoft SharePoint, Lucidchart, Tableau, JIRA, Confluence, Trello, IBM SPSS, SAS, Google Workspace, IBM Rational RequisitePro, Axure RP, Balsamiq, Zoho Analytics, MS Project, MindManager, Draw.io, Adobe Acrobat Pro, SQL and database management tools \n \n \n  Nice to Haves: \n \n  Knowledge of federal agency operations and policies \n  Federal government experience \n  Experience with Public Trust or Security Clearance processes \n  Well-organized with a keen eye for detail \n \n \n  BENEFITS AND WHY TO CHOOSE RED CARROT: \n  At Red Carrot, we empower you to be a leader. We attract and develop talent from all backgrounds because we believe there\u2019s strength in diversity, offering different perspectives and skills. Together, we can solve our client\u2019s biggest challenges. We offer a competitive compensation and benefits package. \n \n  Training and Development  \u2013 All team members have a training budget and are eligible for tuition reimbursement after their first year of employment. \n  Healthcare  \u2013 Red Carrot provides paid top-tier medical, dental, vision, and long-term disability coverage. \n  401(k) Plan  \u2013 Team members can enroll in a 401(k) retirement plan with company matching and no vesting period. \n  Profit Sharing  \u2013 Red Carrot provides a discretionary profit-sharing plan to all eligible employees after one year of employment. \n  Virtual Work  \u2013 Red Carrot provides up to 100% telework opportunities. \n  Paid Time Off  \u2013 Red Carrot provides flexible work hours, paid time off and 11 federal holidays. \n \n \n  More about us at Red Carrot: \n  Red Carrot is both a trusted and award-winning agency with extensive experience providing clients with innovative solutions. We create inspiring team stories, conduct actionable research, and excel at recruiting and managing team talent. Our track record for organizing and hosting memorable conferences and events indeed speaks for itself. \n  Learn even more at : Join the Team - Red Carrot (theredcarrot.com) \n   \n SHc87leHrb", "cleaned_desc": " \n  Data Analysis: \n \n  Analyze data to identify trends, patterns, and insights that can inform decision-making and improvements. \n  Assist in data-related projects to enhance business operations. \n \n  QUALIFICATIONS: \n  Must Haves: \n \n  Bachelor's degree in business, Information Technology, or a related field. \n  3+ years as a Business Analyst or a directly related role, with a strong focus on requirements analysis and system development. \n  Proficiency with business analysis tools and techniques. \n  Proficient in Microsoft Office 365 \n  Ability to meet requirements to obtain a Public Trust Clearance or an existing Public Trust or Security Clearance \n  Exceptional written and verbal communication skills.    Strong organizational and project management abilities. \n  Ability to handle sensitive and confidential information with discretion. \n  Experience using at least 5 of the common business analysis programs and tools; \n \n  Microsoft Office Suite, Microsoft Visio, Microsoft SharePoint, Lucidchart, Tableau, JIRA, Confluence, Trello, IBM SPSS, SAS, Google Workspace, IBM Rational RequisitePro, Axure RP, Balsamiq, Zoho Analytics, MS Project, MindManager, Draw.io, Adobe Acrobat Pro, SQL and database management tools \n \n \n  Nice to Haves: \n \n  Knowledge of federal agency operations and policies \n  Federal government experience \n  Experience with Public Trust or Security Clearance processes \n  Well-organized with a keen eye for detail \n \n ", "techs": ["microsoft office suite", "microsoft visio", "microsoft sharepoint", "lucidchart", "tableau", "jira", "confluence", "trello", "ibm spss", "sas", "google workspace", "ibm rational requisitepro", "axure rp", "balsamiq", "zoho analytics", "ms project", "mindmanager", "draw.io", "adobe acrobat pro", "sql"]}, "5a92885521f44263": {"terms": ["data analyst"], "salary_min": 115000.0, "salary_max": 150000.0, "title": "Data Insights Analyst III", "company": "Care.com", "desc": "About Care.com \n  Care.com is a consumer tech company with heart. We're on a mission to solve a human challenge we all face: finding great care for the ones we love. We're moms and dads and pet parents. We have parents and grandparents, so we understand that everyone, at some point in their lives, could use a helping hand. Our culture and our products reflect that. \n  Here, entrepreneurs, self-starters, team players, and big thinkers unite behind a common cause. Here, we're applying data analytics, AI, and the latest technologies to solve universal problems and connect people in new ways. If you like having autonomy, if you thrive on collaboration and building new things, and if you're all about using your talent for good, Care.com is the place for you. \n  Position Overview: \n \n Care.com is looking for a Data Insights Analyst III to join the Analytics & Data Insights team to support the core consumer business. This analyst will be passionate about learning the business while using data, technology, and analytics to provide valuable insights to drive the company's critical business decisions. \n \n Office Locations: (This position may require you to work 2 days a week in-office near an office location listed below) \n \n 555 W 18th Street,  NY, NY  10011 \n 1501 S MoPac Expy #340,  Austin, TX  78746 \n 2 Armstrong Road  Shelton, CT  06484 \n \n What You'll Do: \n \n Partner with product managers, marketing leaders, and other internal teams to address complex business questions and provide insightful analysis and strategic recommendations through strong storytelling capabilities to both technical and non-technical stakeholders \n Turn data-based observations and insights into hypotheses through analytical rigor, leading to A/B tests that will confirm or deny those hypotheses and ultimately improve the performance of our sites \n Take ownership, from definition to reporting, of metrics related to the functional area that you support \n Monitor engagement and conversion trends across the Care.com platform, identify breaks in trends, understand underlying drivers, and surface opportunities and threats \n Develop advanced metrics and visuals, by collecting and integrating data from various sources, including web analytics tools and internal databases \n Be a Care data guru - be the point of contact for all data questions and insights \n \n Who You Are: \n \n At least 3+ years of professional experience in a business intelligence analyst and/or data analyst position \n Take initiative in solving business questions that data could potentially answer by producing top-down data driven solutions to address them \n Strong product development mindset and focus on actionable analytics: e.g., Ability to surface signals in our data and work with Product/Engineering to transform these into concrete tests \n Experience using relational databases and big data via writing performant queries in SQL against large datasets in various environments \n Understanding of Clickstream data and ability to extract and analyze event data \n Be a creative, global thinker & team player \n Strong SQL skills are required (MSSL, BQ, Hive, Presto) \n Big Data Cloud experience a plus (Snowflake, Hadoop, etc) \n Strong skills in Tableau, R, or Python for data analysis, structuring, transforming, and visualization \n Experience with Amplitude a plus \n Statistical knowledge and modeling a plus \n Ability to work independently with high-level direction \n Willingness to proactively engage with partners across many disciplines \n Proficiency in analyzing and interpreting data to while also acting as a mentor to other analysts from other internal teams \n Consistent ability to produce quality, accurate and highly detailed work products \n Inquisitive and curious minds only need to apply. \n \n For a list of our Perks + Benefits, click   here ! \n  Care.com supports diverse families and communities and seeks employees who are just as diverse. As an equal opportunity employer, Care.com recognizes the power of a diverse and inclusive workforce and encourages applications from individuals with varied experiences, perspectives, and backgrounds. Care.com is committed to providing reasonable accommodations for qualified individuals with disabilities. If you need assistance or accommodation, please reach out to talent@care.com. \n  Company Overview: \n  Available in more than 20 countries, Care.com is the world's leading platform for finding and managing high-quality family care. Care.com is designed to meet the evolving needs of today's families and caregivers, offering everything from household tax and payroll services and customized corporate benefits packages covering the care needs of working families, to innovating new ways for caregivers to be paid and obtain professional benefits. Since 2007, families have relied on Care.com's industry-leading products\u2014from child and elder care to pet care and home care. Care.com is an IAC company (NASDAQ: IAC). \n  Salary Range:  $115,000 to $150,000.  \n The base salary range above represents the anticipated low and high end of the national salary range for this position.  Actual salaries may vary and may be above or below the range based on various factors including but not limited to work location, experience, and performance.  The range listed is just one component of Care.com's total compensation package for employees. Other rewards may include annual bonuses and short- and long-term incentives. In addition, Care.com provides a variety of benefits to employees, including health insurance coverage, life, and disability insurance, a generous 401K employer matching program, paid holidays, and paid time off (PTO).", "cleaned_desc": " Monitor engagement and conversion trends across the Care.com platform, identify breaks in trends, understand underlying drivers, and surface opportunities and threats \n Develop advanced metrics and visuals, by collecting and integrating data from various sources, including web analytics tools and internal databases \n Be a Care data guru - be the point of contact for all data questions and insights \n \n Who You Are: \n \n At least 3+ years of professional experience in a business intelligence analyst and/or data analyst position \n Take initiative in solving business questions that data could potentially answer by producing top-down data driven solutions to address them \n Strong product development mindset and focus on actionable analytics: e.g., Ability to surface signals in our data and work with Product/Engineering to transform these into concrete tests   Experience using relational databases and big data via writing performant queries in SQL against large datasets in various environments \n Understanding of Clickstream data and ability to extract and analyze event data \n Be a creative, global thinker & team player \n Strong SQL skills are required (MSSL, BQ, Hive, Presto) \n Big Data Cloud experience a plus (Snowflake, Hadoop, etc) \n Strong skills in Tableau, R, or Python for data analysis, structuring, transforming, and visualization \n Experience with Amplitude a plus \n Statistical knowledge and modeling a plus \n Ability to work independently with high-level direction ", "techs": ["tableau", "r", "python", "sql (mssl", "bq", "hive", "presto)", "snowflake", "hadoop", "amplitude"]}, "9c1fe131ecbccec2": {"terms": ["data analyst"], "salary_min": 122147.62, "salary_max": 154666.1, "title": "Business Intelligence Lead", "company": "Pacific Life", "desc": "Job Description: \n  Pacific Life is investing in bright, agile and diverse talent to contribute to our mission of innovating our business and creating a superior customer experience. \n \n  We\u2019re actively seeking a talented Business Intelligence Lead to join our new Workforce Benefits division. This role can be fully remote or hybrid and based in Newport Beach, CA. \n \n  As a Business Intelligence Lead , you\u2019ll play a key role within the Workforce Benefits division to advance our reporting and visualization efforts. You will ensure that we remain agile and will be responsible for leveraging Tableau to develop robust reporting mechanisms to present data in a clear, actionable format to stakeholders across departments. You will report to the Head of Analytics, Workforce Benefits and contribute to driving the Business Intelligence aspects of the overall Analytics strategy. \n \n \n How you will make an impact: \n  Data Visualization & Reporting \n Craft and refine Tableau dashboards that display complex data streams in comprehensible visual formats. Regularly update and adapt reports in line with changing business needs and objectives. \n Stakeholder Collaboration \n Engage regularly with department leads to ascertain their data requirements. Conduct workshops and feedback sessions to refine BI offerings. \n Data Integrity Assurance \n Establish protocols to ensure report accuracy and consistency. Identify and rectify any discrepancies or anomalies in datasets. Collaborate closely with the Data Engineering team \n Training & Capability Building \n Roll out Tableau training sessions for internal stakeholders, ensuring optimal utilization. Develop BI best practices and guidelines for the broader team. \n Performance & Scalability \n Ensure rapid dashboard responsiveness and efficient report generation. Strategize on BI infrastructure scalability to support growing datasets. \n Ad hoc reporting needs \n Generates ad hoc reports and regular datasets or report information for end-users using system tools and database or data warehouse queries and scripts. \n \n \n The experience you will bring: \n  Passion for fostering a data-driven culture. \n Bachelor's degree in Technology , Computer Science, or a related field. \n 6+ years of experience in business intelligence, data analysis, or a similar role. \n Proven expertise in Tableau (certification preferred). \n Proficiency in SQL and understanding of relational databases. \n Strong analytical and problem-solving skills. \n Excellent communication skills, with the ability to present complex information in a clear and concise manner. \n \n \n What will make you stand out: \n  MS and/or MBA degree \n Workforce Benefits, Insurance or Financial Services \n Familiarity with other BI tools is a plus \n Knowledge of Salesforce objects and data structures \n \n  #LI-JA1 \n \n  You belong at Pacific Life \n At Pacific Life we are committed to a culture of belonging, a space where all employees are empowered to be authentic. One way we cultivate an inclusive culture is through our employee connection groups. The purpose of these employee-led groups is to offer a place to build community, connection, camaraderie, and a sense of belonging. Each group can be active in education, advocacy, recruitment, and community building throughout our organization. Learn more about our employee connection groups at www.pacificlife.com. \n \n  Want to learn more about life at Pacific Life? Take an inside look at our company culture: Instagram.com/lifeatpacificlife. \n \n \n Base Pay Range: \n  The base pay range noted provides a basis to determine the appropriate offer dependent upon several factors including but not limited to geographic location, experience, skills, education and pay equity. Also, most employees are eligible for additional incentive pay. \n \n  Your Benefits Start Day 1 \n \n  Your wellbeing is important to Pacific Life, and we\u2019re committed to providing you with flexible benefits that you can tailor to meet your needs. Whether you are focusing on your physical, financial, emotional, or social wellbeing, we\u2019ve got you covered. \n \n  Prioritization of your health and well-being including Medical, Dental, Vision, and Wellbeing Reimbursement Account that can be used on yourself or your eligible dependents \n \n \n Generous paid time off options including:  Paid Time Off, Holiday Schedules, and Financial Planning Time Off \n \n  Paid Parental Leave as well as an Adoption Assistance Program \n \n  Competitive 401k savings plan with company match and an additional contribution regardless of participation \n \n \n EEO Statement: \n  Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.", "cleaned_desc": " Data Integrity Assurance \n Establish protocols to ensure report accuracy and consistency. Identify and rectify any discrepancies or anomalies in datasets. Collaborate closely with the Data Engineering team \n Training & Capability Building \n Roll out Tableau training sessions for internal stakeholders, ensuring optimal utilization. Develop BI best practices and guidelines for the broader team. \n Performance & Scalability \n Ensure rapid dashboard responsiveness and efficient report generation. Strategize on BI infrastructure scalability to support growing datasets. \n Ad hoc reporting needs \n Generates ad hoc reports and regular datasets or report information for end-users using system tools and database or data warehouse queries and scripts. \n \n \n The experience you will bring: \n  Passion for fostering a data-driven culture. \n Bachelor's degree in Technology , Computer Science, or a related field.   6+ years of experience in business intelligence, data analysis, or a similar role. \n Proven expertise in Tableau (certification preferred). \n Proficiency in SQL and understanding of relational databases. \n Strong analytical and problem-solving skills. \n Excellent communication skills, with the ability to present complex information in a clear and concise manner. \n \n \n What will make you stand out: \n  MS and/or MBA degree \n Workforce Benefits, Insurance or Financial Services \n Familiarity with other BI tools is a plus \n Knowledge of Salesforce objects and data structures \n ", "techs": ["data integrity assurance", "tableau", "bi infrastructure", "sql", "relational databases", "tableau certification", "ms and/or mba degree", "salesforce objects and data structures"]}, "0f35818882a3cbbc": {"terms": ["data analyst"], "salary_min": 96050.21, "salary_max": 121620.98, "title": "Senior Analyst, Data Strategy and Governance (HYBRID)", "company": "Inclusively", "desc": "Inclusively is partnering with a multinational financial services company to hire a Senior Analyst, Data Strategy and Governance. \n ABOUT INCLUSIVELY: \n Inclusively is a digital tech platform that connects candidates with disabilities, who may benefit from workplace accommodations, to inclusive employers. This includes all disabilities under the ADA, including mental health conditions (e.g. anxiety, depression, PTSD), chronic illnesses (e.g. diabetes, Long COVID), and neurodivergence (e.g. autism, ADHD).  Applicants with one or more of these conditions are encouraged to apply; Inclusively does not require applicants to disclose their specific disability. \n The Team \n The Asset Management Data Office (AMDO), established in 2021, was formed as a centralized team within Asset Management (AM) to drive a \u201cData First\u201d mindset, given the increasing importance of building data strategy into initiatives across all aspects of the organization. The team embraces a spirit of entrepreneurship, collaboration, and innovation as we work together to navigate the data challenges of emerging businesses (Alternative Investing, Digital Assets, ESG) as well as the modernization of traditional investment and data distribution platforms and methodologies. \n AMDO provides strategic thought leadership, data fluency education, data governance oversight, data quality expertise, data request prioritization and a variety of other utilities to AM. We aim to help simplify engagement, accelerate delivery, integrate business perspective, and improve the quality of all things data. Working closely with leaders across Asset Management and other key business groups, we drive a \u201cOne-AM\u201d approach to data investment and priorities for the AM business. \n The Role \n As a Senior Analyst on the team, you will be responsible for supporting key initiatives in close partnership with our stakeholders and business partners. This highly collaborative role will expose you to a diverse population of IT and business associates across Equity, Fixed Income, Quantitative Research, High Income, and others across the organization. \n Your expertise across project management, data lineage, and financial acumen will be crucial in supporting our investment decision-making processes and driving innovation in our data-driven strategies. \n Program Management \n \n Collaborate with stakeholders to define project goals, deliverables, timelines, and resource requirements. \n Monitor project progress, manage risks, and communicate updates to key partners, ensuring successful and timely project delivery. \n \n Data Strategy \n \n Work alongside senior leadership to develop and execute the data strategy for the Company, focusing on data needs specific to the investment management process. \n Oversee the collection, integration, and quality assurance of diverse data sources, including proprietary data sets, market data, research data, and alternative data. \n Collaborate with portfolio managers, research analysts, and data scientists to identify data driven opportunities and drive innovation in investment strategies. \u2022 Develop frameworks and methodologies for integrating and normalizing diverse data sets, ensuring consistency and accuracy \n Collaborate with cross-functional teams to define data governance policies, data standards, and data architecture frameworks. \n \n Risk Management \n \n Proactively identify areas of potential risk for AM in close coordination with our business partners and data vendors. \n Conduct thoughtful transition of ongoing projects into established processes, architecting the procedures, clearly defining roles and responsibilities, and implementing key controls in partnership with Corporate Risk. \n \n The Expertise and Skills You Bring \n \n Bachelor\u2019s degree with at least six years of experience supporting the asset management industry. \n Solid understanding of financial markets, investment strategies, and portfolio management concepts. \n Experience working with investment data related to fund accounting (ex. Portfolio Reference, Security Master, Tax Lots, Transactions, Trial Balance, etc.). \u2022 Knowledge of data governance, data quality, and data management standard processes. \n Exceptional analytical, conceptual, and problem-solving abilities. \n Strong communication and presentation skills, with the ability to effectively communicate complex data insights to both technical and non-technical stakeholders. \n Independent and strategic problem solver; accountable for and skilled in exercising sound judgment. \n Validated attention to detail as well as effective time management abilities \u2022 Passion for continuous learning \u2013 Keeps abreast of the challenges facing the industry and the approaches to address them. \n Familiarity with analytic and visualization technologies a plus (e.g. Tableau, Power BI, Python, SQL, etc.), but not required. \n Rich history of project management experience required. Experience with Agile methodology a plus. \n \n At the Company, our goal is for most people to work flexibly in a way that balances both personal and business needs with time onsite and offsite through what we\u2019re calling \u201cDynamic Working\u201d. Most associates will have a hybrid schedule with a requirement to work onsite at a Company work location for at least one week, 5 consecutive days, every four weeks. These requirements are subject to change \n At the Company, we are passionate about making our financial expertise broadly accessible and effective in helping people live the lives they want! We are a privately held company that places a high degree of value in creating and nurturing a work environment that attracts the best talent and reflects our commitment to our associates. We are proud of our diverse and inclusive workplace where we respect and value our associate for their unique perspectives and experiences. For information about working at the Company, The Company is an equal opportunity employer. \n The Company will reasonably accommodate applicants with disabilities who need adjustments in order to complete the application or interview process. \n Certifications: \n Company Overview \n The Company is a privately held company with a mission  to strengthen the financial well-being of our clients.  We help people invest and plan for their future. We assist companies and non-profit organizations in delivering benefits to their employees. And we provide institutions and independent advisors with investment and technology solutions to help invest their own clients\u2019 money. \n Join Us \n At the Company, you\u2019ll find endless opportunities to build a meaningful career that positively impacts peoples\u2019 lives, including yours. You can take advantage of flexible benefits that support you through every stage of your career, empowering you to thrive at work and at home. Honored with a Glassdoor Employees\u2019 Choice Award, we have been recognized by our employees as a Best Place to Work in 2023. And you don\u2019t need a finance background to succeed at the Company\u2014we offer a range of opportunities for learning so you can build the career you\u2019ve always imagined. \n At the Company, our goal is for most people to work flexibly in a way that balances both personal and business needs with time onsite and offsite through what we\u2019re calling \u201cDynamic Working\u201d. Most associates will have a hybrid schedule with a requirement to work onsite at a Company work location for at least one week, 5 consecutive days, every four weeks. These requirements are subject to change. \n The Company is an equal opportunity employer. We believe that the most effective way to attract, develop and retain a diverse workforce is to build an enduring culture of inclusion and belonging. \n The Company will reasonably accommodate applicants with disabilities who need adjustments to participate in the application or interview process. To initiate a request for an accommodation, contact the HR Accommodation Team. \n At the Company, we value honesty, integrity, and the safety of our associates and customers within a heavily regulated industry . Certain roles may require candidates to go through a preliminary credit check during the screening process. Candidates who are presented with a Company offer will need to go through a background investigation and may be asked to provide additional documentation as requested. This investigation includes but is not limited to a criminal, civil litigations and regulatory review, employment, education, and credit review (role dependent). These investigations will account for 7 years or more of history, depending on the role. Where permitted by federal or state law, The Company will also conduct a pre-employment drug screen, which will review for the following substances: Amphetamines, THC (marijuana), cocaine, opiates, phencyclidine. \n Job Type: Full-time \n Schedule: \n \n Monday to Friday \n \n Work Location: Remote", "cleaned_desc": " Collaborate with stakeholders to define project goals, deliverables, timelines, and resource requirements. \n Monitor project progress, manage risks, and communicate updates to key partners, ensuring successful and timely project delivery. \n \n Data Strategy \n \n Work alongside senior leadership to develop and execute the data strategy for the Company, focusing on data needs specific to the investment management process. \n Oversee the collection, integration, and quality assurance of diverse data sources, including proprietary data sets, market data, research data, and alternative data. \n Collaborate with portfolio managers, research analysts, and data scientists to identify data driven opportunities and drive innovation in investment strategies. \u2022 Develop frameworks and methodologies for integrating and normalizing diverse data sets, ensuring consistency and accuracy \n Collaborate with cross-functional teams to define data governance policies, data standards, and data architecture frameworks. \n \n Risk Management   \n Proactively identify areas of potential risk for AM in close coordination with our business partners and data vendors. \n Conduct thoughtful transition of ongoing projects into established processes, architecting the procedures, clearly defining roles and responsibilities, and implementing key controls in partnership with Corporate Risk. \n \n The Expertise and Skills You Bring \n \n Bachelor\u2019s degree with at least six years of experience supporting the asset management industry. \n Solid understanding of financial markets, investment strategies, and portfolio management concepts. \n Experience working with investment data related to fund accounting (ex. Portfolio Reference, Security Master, Tax Lots, Transactions, Trial Balance, etc.). \u2022 Knowledge of data governance, data quality, and data management standard processes. \n Exceptional analytical, conceptual, and problem-solving abilities. \n Strong communication and presentation skills, with the ability to effectively communicate complex data insights to both technical and non-technical stakeholders. ", "techs": ["collaborate with stakeholders", "monitor project progress", "manage risks", "communicate updates", "data strategy", "oversee the collection", "integration", "and quality assurance of diverse data sources", "collaborate with portfolio managers", "research analysts", "and data scientists", "develop frameworks and methodologies for integrating and normalizing diverse data sets", "collaborate with cross-functional teams", "define data governance policies", "data standards", "and data architecture frameworks", "risk management", "proactively identify areas of potential risk", "conduct thoughtful transition of ongoing projects", "architecting the procedures", "clearly defining roles and responsibilities", "implementing key controls", "bachelor\u2019s degree", "at least six years of experience supporting the asset management industry", "solid understanding of financial markets", "investment strategies", "and portfolio management concepts", "experience working with investment data related to fund accounting", "knowledge of data governance", "data quality", "and data management standard processes", "exceptional analytical", "conceptual", "and problem-solving abilities", "strong communication and presentation skills"]}, "3729b645f2ae57f3": {"terms": ["data analyst"], "salary_min": 80000.0, "salary_max": 130000.0, "title": "Business Analyst-Oracle Order management and BPMN2.0", "company": "GrayAcumen Inc.", "desc": "B usiness Analyst-Oracle Order management and BPMN2.0 \n Position-1 \n Location-Remote(Onsite) \n Exp-8-10 years \n JD: \n \n Good understanding of Oracle Supply Chain (Order Management, Inventory, and Shipping Module) \n \n \n Knowledge of the BPMN2.0 standard should be able to develop flows using BPMN2.0. \n \n \n Ability to mine data from Oracle, Snowflake, and Salesforce \n \n \n Ability to recognize patterns and trends in large data sets. \n \n \n Exceptional presentation, research, and verbal and written communication. \n \n \n Ability to summarize and explain complex information to other \n \n Job Type: Full-time \n Salary: $80,000.00 - $130,000.00 per year \n Compensation package: \n \n Bonus opportunities \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n BPMN2.0: 5 years (Preferred) \n Oracle Order management: 5 years (Preferred) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "cba5dbb5664ffbc5": {"terms": ["data analyst"], "salary_min": 92650.0, "salary_max": 119900.0, "title": "Software Development Tester/Analyst Interest Rate Derivatives", "company": "U.S. Bank National Association", "desc": "At U.S. Bank, we\u2019re on a journey to do our best. Helping the customers and businesses we serve to make better and smarter financial decisions and enabling the communities we support to grow and succeed. We believe it takes all of us to bring our shared ambition to life, and each person is unique in their potential. A career with U.S. Bank gives you a wide, ever-growing range of opportunities to discover what makes you thrive at every stage of your career. Try new things, learn new skills and discover what you excel at\u2014all from Day One. \n \n  Job Description \n  SUMMARY \n  U.S. Bank is seeking a highly effective and dynamic individual to perform testing and project support for our Derivatives business in the Capital Market space. This position will help support the delivery of business needs via the Calypso Product suite and will collaborate with internal partners to ensure efficiencies and value-added solution are properly and thoroughly tested and validated prior to any production release. Success will be measured through effective and proactive risk mitigations efforts, strong partnered approach to drive business satisfaction and effectiveness. \n    RESPONSIBILITIES  Provides project and testing support for the Calypso product suite. Performs research, analysis, review, development, implementations, and testing of new and/or revised products/services. Acts as a liaison with other departments testing interfaces or processes. Compiles and analyzes information for an assigned project making recommendations based on findings. Responsible for managing assigned regression test cases including those that have been automated. \n \n  REQUIRED \n \n Eight to ten years of experience in project management activities \n Bachelor's degree, or equivalent work experience \n \n \n  PREFERRED \n \n Experience with/working knowledge of interest rate derivatives \n Experience with the trading processing platform, Calypso \n Considerable knowledge of assigned business line or functional area  \n Strong organizational and analytical skills  \n Thorough knowledge of project management  \n Ability to identify and resolve exceptions and to analyze data  \n Demonstrated leadership skills  \n Master's degree \n \n \n  This position is remote, i.e., anywhere in the United States. \n \n  #USBOps \n  #OpsTE \n \n  If there\u2019s anything we can do to accommodate a disability during any portion of the application or hiring process, please refer to our disability accommodations for applicants. \n \n  Benefits: \n  Our approach to benefits and total rewards considers our team members\u2019 whole selves and what may be needed to thrive in and outside work. That's why our benefits are designed to help you and your family boost your health, protect your financial security and give you peace of mind. Our benefits include the following (some may vary based on role, location or hours): \n \n  Healthcare (medical, dental, vision) \n  Basic term and optional term life insurance \n  Short-term and long-term disability \n  Pregnancy disability and parental leave \n  401(k) and employer-funded retirement plan \n  Paid vacation (from two to five weeks depending on salary grade and tenure) \n  Up to 11 paid holiday opportunities \n  Adoption assistance \n  Sick and Safe Leave accruals of one hour for every 30 worked, up to 80 hours per calendar year unless otherwise provided by law \n \n \n  EEO is the Law \n  U.S. Bank is an equal opportunity employer committed to creating a diverse workforce. We consider all qualified applicants without regard to race, religion, color, sex, national origin, age, sexual orientation, gender identity, disability or veteran status, among other factors. \n \n  E-Verify \n  U.S. Bank participates in the U.S. Department of Homeland Security E-Verify program in all facilities located in the United States and certain U.S. territories. The E-Verify program is an Internet-based employment eligibility verification system operated by the U.S. Citizenship and Immigration Services. \n  The salary range reflects figures based on the primary location, which is listed first. The actual range for the role may differ based on the location of the role. In addition to salary, US Bank offers a comprehensive benefits package, including incentive and recognition programs, equity stock purchase 401k contribution and pension (all benefits are subject to eligibility requirements). Pay Range: $92,650.00 - $109,000.00 - $119,900.00\n   U.S. Bank will consider qualified applicants with criminal histories in a manner consistent with the San Francisco Fair Chance Ordinance.", "cleaned_desc": " Bachelor's degree, or equivalent work experience \n \n \n  PREFERRED \n \n Experience with/working knowledge of interest rate derivatives \n Experience with the trading processing platform, Calypso \n Considerable knowledge of assigned business line or functional area  \n Strong organizational and analytical skills  \n Thorough knowledge of project management  ", "techs": ["bachelor's degree", "interest rate derivatives", "trading processing platform (calypso)", "project management"]}, "20453719b65f0639": {"terms": ["data analyst"], "salary_min": 65000.0, "salary_max": 75000.0, "title": "Board Certified Behavior Analyst", "company": "Autism Center of Sauk Valley", "desc": "About us \n We are data-driven, supportive, collaborative and our goal is to empower children to reach new heights. \n Our work environment includes: \n \n Remote work \n Growth opportunities \n Flexible working hours \n Relaxed atmosphere \n \n Company Description \n The Autism Center of Sauk Valley provides comprehensive Applied Behavior Analysis (ABA) therapy across Sterling, Rock Falls, Dixon, and surrounding areas including direct, one-to-one therapy services, in-depth caregiver training, and consultation services. ABA therapy is a data-driven, evidence-based treatment that is effective in improving social, communication, and adaptive skills while reducing problem behaviors. We are dedicated to providing support and empowering families in helping their children reach new heights. \n Role Description \n This is a full-time remote role for a Board Certified Behavior Analyst. The BCBA will be responsible for providing in-person and telehealth services to clients in addition to collaborating with the interdisciplinary team members, family members, and caregivers. The BCBA will also provide ongoing training for the Registered Behavior Technicians, and gather and analyze data to create and adjust the Individualized Treatment Plan. \n Qualifications \n \n Expertise in parent education and support \n Master's degree in Psychology, Behavior Analysis, or related field \n Board Certification in Behavior Analysis (BCBA) \n Experience in developing and monitoring Behavioral Intervention Plans \n Excellent written and verbal communication skills \n Collaborative approach and ability to work effectively in a team environment \n Experience in ABA-based autism treatment preferred \n Ability to supervise Registered Behavior Technicians \n \n Note: This job description is not intended to be all-inclusive. The employee may be required to perform other duties as assigned. \n Job Type: Full-time \n Pay: $65,000.00 - $75,000.00 per year \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Employee assistance program \n Flexible schedule \n Flexible spending account \n Health insurance \n Paid time off \n Parental leave \n Professional development assistance \n Relocation assistance \n Retirement plan \n Tuition reimbursement \n Vision insurance \n \n Compensation package: \n \n Bonus opportunities \n \n Schedule: \n \n Choose your own hours \n \n Experience: \n \n ABA: 1 year (Preferred) \n \n License/Certification: \n \n BCBA (Preferred) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "a5702b075fac0639": {"terms": ["data analyst"], "salary_min": 73000.0, "salary_max": 166000.0, "title": "IT Business Analyst", "company": "Booz Allen Hamilton", "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Stennis Space Center,MS,US \n         \n \n \n \n         Remote Work: \n         \n \n         Yes \n         \n \n \n \n         Job Number: \n         \n \n         R0178930\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         IT Business Analyst\n          \n  The Opportunity: \n  You know that true progress is made at the intersection of business and tech, and as an IT Business Analyst, you can develop your skills in both. Here, you\u2019ll have the chance to work with an Agile team as they develop digital products to support your clients\u2019 most pressing missions. We\u2019re looking for someone like you to help propel business analytics and processes forward, as well as delve into technology trends to deliver user-friendly client experiences. \n \n  As an IT business analyst, you\u2019ll work to develop and manage leading-edge systems, applications, and processes. Working with IT architects, developers, testers, business analysts, DevSecOps engineers, data scientists, AI/ML engineers and alongside subject matter experts, specialists, digital strategists, you\u2019ll identify clients\u2019 business needs, gather user requirements, and map strategies to ensure project success. You\u2019ll understand the overall direction and nuanced user needs clearly, and you\u2019ll guide your team as they fulfill these needs by creating deployable features. Together, you\u2019ll deliver high business value products to our clients and the warfighter. \n \n  Work with us to make an impact by helping design, manage, and maintain IT programs that keep warfighters safe and enhance national security. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  4+ years experience with communicating directly with stakeholders to capture key requirements for delivery and execution of complex goals, projects, or programs \n  Experience with utilizing project and requirements management tools, including Jira, Confluence, Trello, Microsoft Project, or Excel \n  Knowledge of project management fundamentals, including risk mitigation \n  Secret clearance  \n Bachelors degree in Computer Science or Business administration \n  Ability to obtain an Security+ Certification within 90 days of hire date \n \n \n  Nice If You Have: \n \n  Experience in Agile Project Management Framework-related processes, including Scrum or Kanban \n  Top Secret clearance \n  PMP certification \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. \n  Create Your Career: \n \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll build your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $73,000.00 to $166,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.", "cleaned_desc": "", "techs": ""}, "b35f5ffb6fb35f13": {"terms": ["data analyst"], "salary_min": 91945.195, "salary_max": 116423.1, "title": "Senior Business Analyst - Health (HYBRID)", "company": "Inclusively", "desc": "Inclusively is partnering with a multinational financial services company to hire a Senior Business Analyst - Health (HYBRID). \n ABOUT INCLUSIVELY: \n Inclusively is a digital tech platform that connects candidates with disabilities, who may benefit from workplace accommodations, to inclusive employers. This includes all disabilities under the ADA, including mental health conditions (e.g. anxiety, depression, PTSD), chronic illnesses (e.g. diabetes, Long COVID), and neurodivergence (e.g. autism, ADHD).  Applicants with one or more of these conditions are encouraged to apply; Inclusively does not require applicants to disclose their specific disability. \n The Expertise and Skills You Bring \n \n Bachelor\u2019s degree or equivalent years of experience required \n 5+ years software Development Business Analyst experience, ideally working in an Agile Scrum environment, with demonstrable ability to work across multiple multi-functional teams or Master\u2019s degree in related filed with solid software product development skills. \n Solid understanding industry experience in health care and/or benefits administration and/or product development preferred. \n Shown expertise in various business analysis methodologies and techniques, including data analysis, use case development, story writing, user acceptance testing, and product documentation. \n Solid grasp of the architecture and deployment needed to support web development \n Interact closely with Subject Matter Experts and stakeholders across Health Benefits domain to elicit Product requirements \n Work with UXD teams to support prototyping \n Skilled in MS Word, Excel, PowerPoint, Visio; Experience with JIRA or similar agile backlog management and testing tool \n Certified Business Analysis Professional\u00ae (CBAP\u00ae) certification or Certified Scrum Product Owner certification is a plus \n Skilled at translating business vision into defined and prioritized user stories for team\u2019s backlog \n Ability to understand complex customer needs, translate them into user stories with concrete acceptance criteria, and drive solution formulation with a multi-functional team \n Customer-obsessed and have demonstrated a commitment to delivering frequent, high business value features \n Look for opportunities to innovate and take thoughtful risks to get work done better and faster \n Excellent listening, communication (verbal and written), and presentation skills \n You effectively and regularly lead, facilitate, and drive individuals and group meetings to common goals \n You are highly organized and have a strong ability to prioritize and work under tight deadlines \n Skilled at building relationships, fostering strong teams, and influencing others \n You are a self-motivated, great teammate with the ability to plan and complete work independently, and partner effectively to handle dependencies \n Strong desire to learn and develop additional skills and expertise over time, as well as drive process improvement \n You have excellent business judgement and maintain confidentiality of all data \n Providing consulting, support, and guidance to leadership, squad members, and other relevant partners to influence culture and behaviors \n \n The Value You Deliver \n \n Working in a Scrum Agile environment to deliver software products \n Leading and conducting business analyses to formulate and make recommendations \n Identifying and defining solutions to business problems, through creation and documentation of systems and process specifications \n Creating, documenting, and leading scrum team backlog (writing user stories / acceptance criteria, supporting prioritization, running refinement sessions, etc.) \n Collaborate closely with business partners, development teams, external vendors, and QA on plans, project management, requirements, design, testing, and implementation of solutions throughout the development lifecycle \n Supporting deployment, business readiness, and solution enablement, e.g., defining and documenting enablement tasks, supporting user procedure documentation, creation and delivery of solution training to internal teams, and communication \n Prioritize multiple initiatives and business analysis tasks at the same time \n \n Job Type: Full-time \n Schedule: \n \n Monday to Friday \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "68dd6fabfec2d650": {"terms": ["data analyst"], "salary_min": 74081.984, "salary_max": 93804.3, "title": "Federal Business Analyst", "company": "Red Carrot", "desc": "Red Carrot is seeking a dedicated and detail-oriented Business Analyst to join our PMO team contracting for a federal client. This Business Analyst will play a crucial role in reviewing requirements, analyzing system development plans, documenting processes, and actively participating in the implementation of system changes. This position requires a proactive and analytical mindset to bridge the gap between business needs and technical solutions. The expected organizational structure is that this Business Analyst will report to the Project Manager and will not have any reporting colleagues. While this is a remote role, an ideal candidate will be located in the DMV area (DC, Maryland, Virginia). \n  KEY RESPONSIBILITIES: \n  Requirements Analysis: \n \n  Collaborate with stakeholders to gather, document, and analyze business requirements. \n  Ensure that requirements are clear, complete, and aligned with business objectives. \n  Identify and communicate any potential issues or discrepancies. \n \n  System Development Analysis: \n \n  Review system development plans, project timelines, and technical specifications. \n  Assess the feasibility and impact of proposed system changes or enhancements. \n  Identify potential risks and propose mitigation strategies. \n \n  Documentation: \n \n  Create detailed business requirement documents (BRDs) and system specifications. \n  Develop process flowcharts, use cases, and user stories to illustrate system functionality. \n  Maintain accurate and up-to-date documentation throughout the project lifecycle. \n \n  Implementation Support: \n \n  Actively participate in the implementation of system changes, working closely with development teams. \n  Verify that implemented solutions meet specified requirements and align with business goals. \n  Provide support and guidance during testing, user acceptance, and post-implementation phases. \n \n  Stakeholder Communication: \n \n  Facilitate communication between business stakeholders and technical teams. \n  Regularly update stakeholders on project progress and seek feedback for continuous improvement. \n \n  Data Analysis: \n \n  Analyze data to identify trends, patterns, and insights that can inform decision-making and improvements. \n  Assist in data-related projects to enhance business operations. \n \n  QUALIFICATIONS: \n  Must Haves: \n \n  Bachelor's degree in business, Information Technology, or a related field. \n  3+ years as a Business Analyst or a directly related role, with a strong focus on requirements analysis and system development. \n  Proficiency with business analysis tools and techniques. \n  Proficient in Microsoft Office 365 \n  Ability to meet requirements to obtain a Public Trust Clearance or an existing Public Trust or Security Clearance \n  Exceptional written and verbal communication skills. \n  Strong organizational and project management abilities. \n  Ability to handle sensitive and confidential information with discretion. \n  Experience using at least 5 of the common business analysis programs and tools; \n \n  Microsoft Office Suite, Microsoft Visio, Microsoft SharePoint, Lucidchart, Tableau, JIRA, Confluence, Trello, IBM SPSS, SAS, Google Workspace, IBM Rational RequisitePro, Axure RP, Balsamiq, Zoho Analytics, MS Project, MindManager, Draw.io, Adobe Acrobat Pro, SQL and database management tools \n \n \n  Nice to Haves: \n \n  Knowledge of federal agency operations and policies \n  Federal government experience \n  Experience with Public Trust or Security Clearance processes \n  Well-organized with a keen eye for detail \n \n \n  BENEFITS AND WHY TO CHOOSE RED CARROT: \n  At Red Carrot, we empower you to be a leader. We attract and develop talent from all backgrounds because we believe there\u2019s strength in diversity, offering different perspectives and skills. Together, we can solve our client\u2019s biggest challenges. We offer a competitive compensation and benefits package. \n \n  Training and Development  \u2013 All team members have a training budget and are eligible for tuition reimbursement after their first year of employment. \n  Healthcare  \u2013 Red Carrot provides paid top-tier medical, dental, vision, and long-term disability coverage. \n  401(k) Plan  \u2013 Team members can enroll in a 401(k) retirement plan with company matching and no vesting period. \n  Profit Sharing  \u2013 Red Carrot provides a discretionary profit-sharing plan to all eligible employees after one year of employment. \n  Virtual Work  \u2013 Red Carrot provides up to 100% telework opportunities. \n  Paid Time Off  \u2013 Red Carrot provides flexible work hours, paid time off and 11 federal holidays. \n \n \n  More about us at Red Carrot: \n  Red Carrot is both a trusted and award-winning agency with extensive experience providing clients with innovative solutions. We create inspiring team stories, conduct actionable research, and excel at recruiting and managing team talent. Our track record for organizing and hosting memorable conferences and events indeed speaks for itself. \n  Learn even more at : Join the Team - Red Carrot (theredcarrot.com) \n   \n vUlZWz8CZS", "cleaned_desc": " \n  Data Analysis: \n \n  Analyze data to identify trends, patterns, and insights that can inform decision-making and improvements. \n  Assist in data-related projects to enhance business operations. \n \n  QUALIFICATIONS: \n  Must Haves: \n \n  Bachelor's degree in business, Information Technology, or a related field. \n  3+ years as a Business Analyst or a directly related role, with a strong focus on requirements analysis and system development. \n  Proficiency with business analysis tools and techniques. \n  Proficient in Microsoft Office 365 \n  Ability to meet requirements to obtain a Public Trust Clearance or an existing Public Trust or Security Clearance \n  Exceptional written and verbal communication skills.    Strong organizational and project management abilities. \n  Ability to handle sensitive and confidential information with discretion. \n  Experience using at least 5 of the common business analysis programs and tools; \n \n  Microsoft Office Suite, Microsoft Visio, Microsoft SharePoint, Lucidchart, Tableau, JIRA, Confluence, Trello, IBM SPSS, SAS, Google Workspace, IBM Rational RequisitePro, Axure RP, Balsamiq, Zoho Analytics, MS Project, MindManager, Draw.io, Adobe Acrobat Pro, SQL and database management tools \n \n \n  Nice to Haves: \n \n  Knowledge of federal agency operations and policies \n  Federal government experience \n  Experience with Public Trust or Security Clearance processes \n  Well-organized with a keen eye for detail \n \n ", "techs": ["microsoft office suite", "microsoft visio", "microsoft sharepoint", "lucidchart", "tableau", "jira", "confluence", "trello", "ibm spss", "sas", "google workspace", "ibm rational requisitepro", "axure rp", "balsamiq", "zoho analytics", "ms project", "mindmanager", "draw.io", "adobe acrobat pro", "sql"]}, "d2d7e0022de3d671": {"terms": ["data analyst"], "salary_min": 30.0, "salary_max": 35.0, "title": "Data Analyst - Remote (EST ONLY)", "company": "Radiant Systems", "desc": "\"#INDEED_B\" \n Remote (EST ONLY) \n Position Summary - \n This remote work-from-home position plays a supporting role on the Real Estate Services team for the client. The portfolio analyst shall be responsible for research and data analysis specific to real estate across more than 950 sites and over 9 million square feet. client owns, leases and has donated facilities of office, industrial and retail properties. This position is well suited for an analytical, detail oriented and experienced professional in corporate real estate. The ideal candidate must have experience in corporate real estate databases with an emphasis on Lease Administration. This position will play a key role in analysis providing key data points for delivery to several Real Estate related systems. \n Key Duties: \n \n Responsible for real estate data analysis and delivery \n Review of lease-related critical dates for distribution \n Create and validate renewal projects \n Administer and respond to Real Estate Team Email Box \n Assist with lease administration tasks \n Performs other duties as assigned \n \n Qualifications: \n \n 3-5 years relevant work experience, with at least 3 years in commercial/corporate real estate/lease administration \n Bachelor\u2019s degree from a four-year college or university with Accounting, Finance or Real Estate emphasis. Equivalent work experience may be sufficient \n Advanced Excel skills \n Knowledge of CoStar Real Estate Manager (portfolio and projects modules) a plus \n Flexibility \n \n Job Types: Temporary, Contract, Full-time \n Salary: $30.00 - $35.00 per hour \n Expected hours: 40 per week \n Benefits: \n \n 401(k) \n Health insurance \n Paid sick time \n \n Experience level: \n \n 3 years \n 4 years \n 5 years \n 6 years \n 7 years \n 8 years \n \n Schedule: \n \n 8 hour shift \n Day shift \n Monday to Friday \n \n Experience: \n \n Microsoft Excel: 3 years (Required) \n Real estate: 3 years (Required) \n lease administration: 3 years (Required) \n CoStar: 1 year (Required) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "55bd7f9da1b0556a": {"terms": ["data analyst"], "salary_min": 95664.92, "salary_max": 121133.11, "title": "Senior Business Analyst - Health (HYBRID)", "company": "Inclusively", "desc": "Inclusively is partnering with a multinational financial services company to hire a Senior Business Analyst - Health (HYBRID). \n ABOUT INCLUSIVELY: \n Inclusively is a digital tech platform that connects candidates with disabilities, who may benefit from workplace accommodations, to inclusive employers. This includes all disabilities under the ADA, including mental health conditions (e.g. anxiety, depression, PTSD), chronic illnesses (e.g. diabetes, Long COVID), and neurodivergence (e.g. autism, ADHD).  Applicants with one or more of these conditions are encouraged to apply; Inclusively does not require applicants to disclose their specific disability. \n The Expertise and Skills You Bring \n \n Bachelor\u2019s degree or equivalent years of experience required \n 5+ years software Development Business Analyst experience, ideally working in an Agile Scrum environment, with demonstrable ability to work across multiple multi-functional teams or Master\u2019s degree in related filed with solid software product development skills. \n Solid understanding industry experience in health care and/or benefits administration and/or product development preferred. \n Shown expertise in various business analysis methodologies and techniques, including data analysis, use case development, story writing, user acceptance testing, and product documentation. \n Solid grasp of the architecture and deployment needed to support web development \n Interact closely with Subject Matter Experts and stakeholders across Health Benefits domain to elicit Product requirements \n Work with UXD teams to support prototyping \n Skilled in MS Word, Excel, PowerPoint, Visio; Experience with JIRA or similar agile backlog management and testing tool \n Certified Business Analysis Professional\u00ae (CBAP\u00ae) certification or Certified Scrum Product Owner certification is a plus \n Skilled at translating business vision into defined and prioritized user stories for team\u2019s backlog \n Ability to understand complex customer needs, translate them into user stories with concrete acceptance criteria, and drive solution formulation with a multi-functional team \n Customer-obsessed and have demonstrated a commitment to delivering frequent, high business value features \n Look for opportunities to innovate and take thoughtful risks to get work done better and faster \n Excellent listening, communication (verbal and written), and presentation skills \n You effectively and regularly lead, facilitate, and drive individuals and group meetings to common goals \n You are highly organized and have a strong ability to prioritize and work under tight deadlines \n Skilled at building relationships, fostering strong teams, and influencing others \n You are a self-motivated, great teammate with the ability to plan and complete work independently, and partner effectively to handle dependencies \n Strong desire to learn and develop additional skills and expertise over time, as well as drive process improvement \n You have excellent business judgement and maintain confidentiality of all data \n Providing consulting, support, and guidance to leadership, squad members, and other relevant partners to influence culture and behaviors \n \n The Value You Deliver \n \n Working in a Scrum Agile environment to deliver software products \n Leading and conducting business analyses to formulate and make recommendations \n Identifying and defining solutions to business problems, through creation and documentation of systems and process specifications \n Creating, documenting, and leading scrum team backlog (writing user stories / acceptance criteria, supporting prioritization, running refinement sessions, etc.) \n Collaborate closely with business partners, development teams, external vendors, and QA on plans, project management, requirements, design, testing, and implementation of solutions throughout the development lifecycle \n Supporting deployment, business readiness, and solution enablement, e.g., defining and documenting enablement tasks, supporting user procedure documentation, creation and delivery of solution training to internal teams, and communication \n Prioritize multiple initiatives and business analysis tasks at the same time \n \n Job Type: Full-time \n Schedule: \n \n Monday to Friday \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "78d568efc70c9cf5": {"terms": ["data analyst"], "salary_min": 82805.68, "salary_max": 104850.445, "title": "Senior Technical Business Analyst\u2013 CPS iSeries", "company": "Jack Henry and Associates, Inc.", "desc": "At Jack Henry, we deliver technology solutions that are digitally transforming and empowering community banks and credit unions to provide enhanced and streamlined user experiences to their customers and members. Our best-in-class products are just the start as we lay the groundwork for the future of digital banking and payments. We hope you\u2019ll join us. We can\u2019t do it without you. \n  Acting independently, this position contributes to the software development process by ensuring complete and accurate documentation of system requirements. This role serves as a liaison between customers and development departments and will participate as a multi-talented contributor in all phases of the development cycle: concept, requirements definition, technical design, prototype, code development, testing, release to QA and implementation. This role will support the processing platforms for EFT transaction routing and settlements from debit and regional networks, ATM terminal driving and monitoring, fraud management solutions, card management, award programs, etc. \n  Position may be hired for a lower level depending upon experience level and skill set. \n  What you\u2019ll be responsible for: \n \n Interacts with customers to gather system requirements. \n Defines the system and functional requirements of the product. \n Prepares business requirements and functional specifications. \n Serves as a resource and/or participant in business process re-design activities. Assists the customer in determining if and how system enhancements may improve process flow and business function. \n May perform application, system and regression tests. \n Responsible for creating business requirements and system documentation, as well as contributing to end-user and project management documentation. \n Works with quality assurance and programming teams to ensure changes are migrated into production correctly. \n Interacts with technical teams to convey business requirements. \n Works with industry research groups to prepare for product trends. \n May assist less experienced peers. May act as a team lead. \n Educate users on existing functionality and enhancements. \n Facilitate and drive issue resolution for customer challenges. \n Lead collaboration efforts to build strong and positive relationships across the organization and with third party vendors. \n Lead continuous process improvements initiatives. \n Works on highly complex and diverse projects. Works on significant and unique issues where analysis of situations or data requires an evaluation of intangibles. Exercises independent judgment in selecting methods, techniques and evaluation criteria for obtaining solutions. \n May perform other job duties as assigned \n \n  What you\u2019ll need to have: \n \n Bachelor\u2019s degree, advanced degree desirable, or equivalent combination of education and work experience sufficient to successfully perform the essential functions of the job \n iSeries, Silverlake, CIF20/20, or CPS iSeries experience  \n Minimum of 6 years of experience in business analysis, software engineering, or related field \n Superior knowledge and experience with requirements gathering and documentation, defining use cases, authoring functional and/or technical specifications \n Superior communication and customer interaction skills with the ability to communicate across all levels of the organization: operations, technical teams, executive level, etc. \n Able to independently drive multiple work efforts simultaneously to meet aggressive deadlines. \n \n  What would be nice for you to have: \n \n iSeries, Silverlake, CIF20/20, or CPS Host experience highly desired \n Has broad expertise or unique knowledge and contributes to company objectives as a subject matter expert (SME). \n Superior knowledge of the financial industry. \n Superior knowledge and experience in the payment processing industry \n Superior knowledge and experience with waterfall and agile development methodologies \n Superior knowledge in debit and credit issuer processing. \n Superior ability to define system and functional requirements \n Superior grammar and writing skills. \n Project management skills. \n Experience in the EFT transaction messaging domain (ISO 8583 message specification, EFT transaction switching and routing, high speed transaction processing, ATM messaging, etc) \n Superior knowledge of Microsoft Office applications. \n Superior technical expertise in the following domains: \n \n ISO8583 message specification \n EFT transaction messaging \n EFT transaction switching and routing \n High speed transaction processing challenges and constraints \n ATM messaging, fraud strategies, dispute processing, EFT billing and settlement \n Core banking domain and/or core CU domain \n Security and compliance (PCI, PII, etc.) \n \n Experience in one or more of the following technical domains: \n \n Java and .net based applications \n Distributed applications \n Mainframe applications \n Micro services API \n Data ETL and Analytic Solutions \n Business Process Model \n \n Experience with Fintech. \n Experience with ISO 20022. \n Experience with Cloud based technologies. \n \n  If you got this far, we hope you're feeling excited about this opportunity. Even if you don't feel you meet every single requirement on this posting, we still encourage you to apply. We're eager to meet motivated people who align with Jack Henry\u2019s mission and can contribute to our company in a variety of ways. \n  Why Jack Henry? \n  At Jack Henry, we pride ourselves through our motto of, \"Do the right thing, do whatever it takes, and have fun.\" We recognize the value of our associates and believe much of our company\u2019s strength and success depends on their well-being. We demonstrate our commitment by offering outstanding benefit programs to ensure the physical, mental & financial wellbeing of our people is always met. \n  Culture of Commitment \n  Ask our associates why they love Jack Henry, and many will tell you it is because our culture is exceptional. We do great things together. Rising to meet challenges and seeking opportunities is part of who we are as an organization. Our culture has helped us stay strong through challenging times and we credit our dedicated associates for our success. Visit our Corporate Responsibility site to learn more about our culture and commitment to our people, customers, community, environment, and shareholders. \n  Equal Employment Opportunity \n  At Jack Henry, we know we are better together. We value, respect, and protect the uniqueness each of us brings. Innovation flourishes by including all voices and makes our business\u2014and our society\u2014stronger. Jack Henry is an equal opportunity employer and we are committed to providing equal opportunity in all of our employment practices, including selection, hiring, performance management, promotion, transfer, compensation, benefits, education, training, social, and recreational activities to all persons regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, genetic information, pregnancy, marital status, sex, gender, gender identity, gender expression, age, sexual orientation, and military and veteran status, or any other protected status protected by local, state or federal law. \n  No one will be subject to, and Jack Henry prohibits, any form of discipline, reprisal, intimidation, or retaliation for good faith reports or complaints of incidents of discrimination of any kind, pursuing any discrimination claim, or cooperating in related investigations. \n  Requests for full corporate job description may be requested through the interview process at any time.", "cleaned_desc": " Educate users on existing functionality and enhancements. \n Facilitate and drive issue resolution for customer challenges. \n Lead collaboration efforts to build strong and positive relationships across the organization and with third party vendors. \n Lead continuous process improvements initiatives. \n Works on highly complex and diverse projects. Works on significant and unique issues where analysis of situations or data requires an evaluation of intangibles. Exercises independent judgment in selecting methods, techniques and evaluation criteria for obtaining solutions. \n May perform other job duties as assigned \n \n  What you\u2019ll need to have: \n \n Bachelor\u2019s degree, advanced degree desirable, or equivalent combination of education and work experience sufficient to successfully perform the essential functions of the job \n iSeries, Silverlake, CIF20/20, or CPS iSeries experience  \n Minimum of 6 years of experience in business analysis, software engineering, or related field \n Superior knowledge and experience with requirements gathering and documentation, defining use cases, authoring functional and/or technical specifications \n Superior communication and customer interaction skills with the ability to communicate across all levels of the organization: operations, technical teams, executive level, etc. \n Able to independently drive multiple work efforts simultaneously to meet aggressive deadlines.   \n  What would be nice for you to have: \n \n iSeries, Silverlake, CIF20/20, or CPS Host experience highly desired \n Has broad expertise or unique knowledge and contributes to company objectives as a subject matter expert (SME). \n Superior knowledge of the financial industry. \n Superior knowledge and experience in the payment processing industry \n Superior knowledge and experience with waterfall and agile development methodologies \n Superior knowledge in debit and credit issuer processing. \n Superior ability to define system and functional requirements \n Superior grammar and writing skills. \n Project management skills. \n Experience in the EFT transaction messaging domain (ISO 8583 message specification, EFT transaction switching and routing, high speed transaction processing, ATM messaging, etc) \n Superior knowledge of Microsoft Office applications. \n Superior technical expertise in the following domains: ", "techs": ["iseries", "silverlake", "cif20/20", "cps iseries", "business analysis", "software engineering", "requirements gathering", "use cases", "functional specifications", "technical specifications", "communication skills", "customer interaction skills", "aggressive deadlines", "iseries", "silverlake", "cif20/20", "cps host", "subject matter expert", "financial industry", "payment processing industry", "waterfall development methodologies", "agile development methodologies", "debit and credit issuer processing", "system requirements", "functional requirements", "grammar and writing skills", "project management skills", "eft transaction messaging domain", "iso 8583 message specification", "eft transaction switching and routing", "high speed transaction processing", "atm messaging", "microsoft office applications."]}, "8af95d31989ebae6": {"terms": ["data analyst"], "salary_min": 45.0, "salary_max": 55.0, "title": "Senior Program Analyst", "company": "RCS Corporation", "desc": "RCS Corporation has an immediate need for various  Senior Program ,  Portfolio and Project Analysts (PPP Analysts)  in  Washington, D.C.  This is a  full-time, long-term contract, hybrid  assignment with our client. This position offers a competitive package including benefits, vacation, and holidays offered. \n Overview of YOUR role as a Senior PPP Analyst In this role, you will assist program managers in their execution of programs within the RDT&E process. The process includes various development, testing, risk management, mitigation, and quality control variations. \n As a Senior PPP Analyst YOU will: \n \n Define requirements and provide input on various projects. \n Monitor and maintain project baselines. \n Prepare presentations and other materials to support the project. \n Draft documents and quality check details as needed. \n \n YOU are the ideal Senior PPP Analyst candidate if you: \n \n An active secret security clearance \n Bachelor\u2019s degree and at least 7 years of relevant experience \n Previous government DHS, Security Affairs, or related experience \n Program and/or project management experience \n \n It\u2019s a BONUS if you: \n \n Master\u2019s degree \n Active PMP or Certified Scrum Master \n \n About Our CLIENT Our client delivers strategic and professional services spanning cities, transportation, buildings, water, new energy, and the environment. They create a sustainable infrastructure for the future with planners, designers, engineers, program managers, consultants, and construction managers. Working throughout the project lifecycle, their team is driven by a common purpose to deliver a better world. \n Job Types: Contract, Full-time \n Pay: $45.00 - $55.00 per hour \n Benefits: \n \n Dental insurance \n Health insurance \n Paid time off \n Vision insurance \n \n Experience level: \n \n 7 years \n \n Application Question(s): \n \n Are you willing to come on site as needed? (Approximately quarterly to Washington, DC) \n \n Education: \n \n Bachelor's (Preferred) \n \n Security clearance: \n \n Secret (Required) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "afe6ee282a7d7388": {"terms": ["data analyst"], "salary_min": 80000.0, "salary_max": 100000.0, "title": "Data Analyst", "company": "Liberty Personnel Services", "desc": "Data Analyst \n My client has a full time opening for a Data Analyst. This is a hybrid role and offers 2-3 days WFH. Position will involve the following: \n \n SQL \n Power BI \n ETL \n Transform raw data into data structures \n Building reports \n Development of database systems \n Data Modeling \n Creation of interactive visualizations \n Experience with Tableau and Cloud is a plus \n \n Please reach out for more info...and feel free to add me on Linked in. \n Tim Campbell \n  Liberty Personnel Services Inc. \n  610-941-6300 ext 121 direct: 484-567-2089 \n  tc@libertyjobs.com www.libertyjobs.com \n  www.linkedin.com/pub/tim-campbell/0/a9b/616 \n #midsenior", "cleaned_desc": "", "techs": ""}, "d1321985983d731d": {"terms": ["data analyst"], "salary_min": 43.0, "salary_max": 45.0, "title": "component content management system (CCMS)-BUSINESS ANALYST", "company": "TAJ Technologies Inc", "desc": "TECHNICAL BUSINESS ANALYSt \n Location: Remote \n 1 years contract \n must have CMS/CCMS, Agile, Azure DevOps, and DITA XML experience \n component content management system  ( CCMS ) & content management system (cms) \n Ability to build and maintain strong working relationships at multiple levels of the organization. Effective (or Strong) communicator (written & verbal) with active listening skills. Ability to facilitate small group/team discussions. Professional and reflects Mayo Clinic values and beliefs. Strong planning & organizational skills. Proactive and able to navigate conflict and help find resolution. Problem solver and ability to maintain a keen attention to detail and manage multiple initiatives. \n Education: \n Bachelor's Degree (business, communications, advertising, marketing, statistics, engineering, technology, health care) 2+ years of relevant business and/or technical experience. \n Job Type: Contract \n Pay: $43.00 - $45.00 per hour \n Expected hours: 40 per week \n Benefits: \n \n Health insurance \n \n Experience level: \n \n 2 years \n \n Schedule: \n \n 8 hour shift \n Day shift \n Monday to Friday \n \n Application Question(s): \n \n KIndly share your valid Email address ! \n \n Experience: \n \n Component content management system CCMS & CCM: 2 years (Required) \n Agile, Azure DevOps, and DITA XML (ALL need ): 2 years (Required) \n Recent Healthcare/ Hospital Employer: 1 year (Required) \n \n License/Certification: \n \n 100 % Only W2 Tax ( others Dont Apply ) (Required) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "22e5c9f876d2c5ea": {"terms": ["data analyst"], "salary_min": 81001.97, "salary_max": 102566.55, "title": "Lead EDI Analyst", "company": "Treehouse Foods", "desc": "About Us: \n TreeHouse Foods (NYSE: THS) is a leading manufacturer of private label packaged foods and beverages, operating a network of production facilities across the United States and Canada. At TreeHouse Foods, our commitment to excellence extends beyond our products and revolves around our people. We are investing in talent and creating a performance-based culture where employees can do their best work, directly impacting our mission to make high quality, affordable food for our customers, communities and families. We hope you will consider joining the team and being part of our future. \n What You Gain: \n \u00b7 Competitive compensation and benefits program \n \u00b7 Enrollment in our wellness and employee assistance programs \n \u00b7 Paid holidays, vacation, and other competitive paid time off opportunities \n \u00b7 An inclusive working environment where you can build meaningful work relationships with a diverse group of people \n \u00b7 Leaders who are invested in supporting your career growth \n \u00b7 Opportunities to be recognized for outstanding contributions to your team through our employee recognition programs \n About the Role: \n The Lead EDI Analyst role is critical to the success of the organization and impacts functions such as Sales, Purchasing, Accounts Receivable, Logistics, and more! You\u2019ll add value to this role by performing various functions including but not limited to: \n \u00b7 Establishing and setting up new trading relationships with our partners \n \u00b7 Monitoring the system for potential issues \n \u00b7 Coordinating a support team in responding to requests and issues as they arise \n \u00b7 Establishing and maintaining standards and procedures for the EDI support team \n \u00b7 Ensuring proper data transformation to and from X12 and EDIFACT standards \n \u00b7 Creating and maintaining certificates as they expire \n Important Details: \n This is a full-time role that will generally operate during normal business hours but may require occasional nighttime and weekend hours to address critical system issues or maintenance responsibilities. \n About You: \n You\u2019ll fit right in if you have: \n \u00b7 8+ years of related experience \n \u00b7 Excellent communication and organizational skills \n \u00b7 In-depth knowledge of IBM\u2019s Sterling Integrator including Business Processes, Mapping Tool and Rules, BPML, SSH Mailboxes, Workflow, Service Configurations, and System Schedules \n \u00b7 Ability to setup AS/2 Profiles and create supporting CA, exchange, and signing certificates \n \u00b7 Ability to setup remote SFTP/FTPS profiles and create supporting SSL, host, and SSH authorization key pairs \n \u00b7 A basic understanding of DB2 SQL and the SQL query tools in Sterling Integrator \n \u00b7 SAP experience is preferred, but not required \n \u00b7 Education preference: Bachelor\u2019s Degree in Information Technology, Computer Science, or related field \n Job Type: Full-time \n Benefits: \n \n 401(k) matching \n Dental insurance \n Health insurance \n Vision insurance \n Work from home \n \n Compensation package: \n \n Yearly bonus \n Yearly pay \n \n Experience level: \n \n 5 years \n \n Schedule: \n \n Monday to Friday \n On call \n Weekends as needed \n \n Experience: \n \n Sterling Integrator: 4 years (Preferred) \n \n Work Location: Remote", "cleaned_desc": " \u00b7 Excellent communication and organizational skills \n \u00b7 In-depth knowledge of IBM\u2019s Sterling Integrator including Business Processes, Mapping Tool and Rules, BPML, SSH Mailboxes, Workflow, Service Configurations, and System Schedules \n \u00b7 Ability to setup AS/2 Profiles and create supporting CA, exchange, and signing certificates \n \u00b7 Ability to setup remote SFTP/FTPS profiles and create supporting SSL, host, and SSH authorization key pairs \n \u00b7 A basic understanding of DB2 SQL and the SQL query tools in Sterling Integrator \n \u00b7 SAP experience is preferred, but not required \n \u00b7 Education preference: Bachelor\u2019s Degree in Information Technology, Computer Science, or related field \n Job Type: Full-time \n Benefits: \n \n 401(k) matching ", "techs": ["ibm's sterling integrator", "as/2 profiles", "remote sftp/ftps profiles", "db2 sql", "sql query tools", "sap", "401(k) matching"]}, "5581f8a1bea3816b": {"terms": ["data engineer"], "salary_min": 131243.38, "salary_max": 158056.53, "title": "Senior Data Engineer", "company": "IBR (Imagine Believe Realize)", "desc": "The Senior Data Engineer must be able to meet the key criteria below: \n \n Location:  100% telework \n Years' Experience:  10+ years \n Education:  Bachelor\u2019s in IT related field \n Security Clearance:  IBR is a federal contractor. Applicants must be able to meet the requirements to obtain an Public Trust security clearance. NOTE: United States Citizenship is required. \n Work Authorization:  Must show that applicant is legally permitted to work in the United States. \n Employment Type:  Full-Time, W-2 \n Key Skills: \n 10+ years of IT experience focusing on enterprise data architecture and management \n Experience with Databricks required \n 8+ years experience in Conceptual/Logical/Physical Data Modeling & expertise in Relational and Dimensional Data Modeling \n Experience with ETL and ELT tools such as SSIS, Pentaho, and/or Data Migration Services \n Advanced level SQL experience (Joins, Aggregation, Windowing functions, Common Table Expressions, RDBMS schema design, Postgres performance optimization) \n Experience with AWS environment, CI/CD pipelines, and Python (Python 3) a bonus \n \n Overview \n Do you want to help build a portfolio of next-generation mobile-enabled data collection systems and enterprise portals? As a Data Engineer at IBR, you will support the Agile based engineering of a robust, secure, and scalable enterprise web portal solutions hosted in AWS. This position will work closely with the solutions delivery team to supporting the operations team performing Deployment, Systems Integration Testing, and Operations & Maintenance activities. \n Responsibilities \n \n Plan, create, and maintain data architectures, ensuring alignment with business requirements \n Obtain data, formulate dataset processes, and store optimized data \n Identify problems and inefficiencies and apply solutions \n Determine tasks where manual participation can be eliminated with automation. \n Identify and optimize data bottlenecks, leveraging automation where possible \n Create and manage data lifecycle policies (retention, backups/restore, etc) \n Create, maintain, and manage ETL/ELT pipelines \n Create, maintain, and manage data transformations \n Maintain/update documentation \n Create, maintain, and manage data pipeline schedules \n Monitor data pipelines \n Create, maintain, and manage data quality gates (Great Expectations) to ensure high data quality \n Support AI/ML teams with optimizing feature engineering code \n Spark updates \n Create, maintain, and manage Spark Structured Steaming jobs, including using the newer Delta Live Tables and/or DBT \n Research existing data in the data lake to determine best sources for data \n Create, manage, and maintain ksqlDB and Kafka Streams queries/code \n Maintain and update Python-based data processing scripts executed on AWS Lambdas \n Unit tests for all the Spark, Python data processing and Lambda codes \n Maintain PCIS Reporting Database data lake with optimizations and maintenance (performance tuning, etc) \n \n Qualifications \n \n 10+ years of IT experience focusing on enterprise data architecture and management \n Experience in Conceptual/Logical/Physical Data Modeling & expertise in Relational and Dimensional Data Modeling \n Experience with Databricks, Structured Streaming, Delta Lake concepts, and Delta Live Tables required \n Additional experience with Spark, Spark SQL, Spark DataFrames and DataSets, and PySpark \n Data Lake concepts such as time travel and schema evolution and optimization \n Structured Streaming and Delta Live Tables with Databricks a bonus \n Experience leading and architecting enterprise-wide initiatives specifically system integration, data migration, transformation, data warehouse build, data mart build, and data lakes implementation / support \n Advanced level understanding of streaming data pipelines and how they differ from batch systems \n Formalize concepts of how to handle late data, defining windows, and data freshness \n Advanced understanding of ETL and ELT and ETL/ELT tools such as SSIS, Pentaho, Data Migration Service etc \n Understanding of concepts and implementation strategies for different incremental data loads such as tumbling window, sliding window, high watermark, etc. \n Familiarity and/or expertise with Great Expectations or other data quality/data validation frameworks a bonus \n Understanding of streaming data pipelines and batch systems \n Familiarity with concepts such as late data, defining windows, and how window definitions impact data freshness \n Advanced level SQL experience (Joins, Aggregation, Windowing functions, Common Table Expressions, RDBMS schema design, Postgres performance optimization) \n Indexing and partitioning strategy experience \n Debug, troubleshoot, design and implement solutions to complex technical issues \n Experience with large-scale, high-performance enterprise big data application deployment and solution \n Understanding how to create DAGs to define workflows \n Familiarity with CI/CD pipelines, containerization, and pipeline orchestration tools such as Airflow, Prefect, etc a bonus but not required \n Architecture experience in AWS environment a bonus \n Familiarity working with Kinesis and/or Lambda specifically with how to push and pull data, how to use AWS tools to view data in Kinesis streams, and for processing massive data at scale (UNICORN) a bonus \n Experience with Docker, Jenkins, and CloudWatch \n Ability to write and maintain Jenkinsfiles for supporting CI/CD pipelines \n Experience working with AWS Lambdas for configuration and optimization \n Experience working with DynamoDB to query and write data \n Experience with S3 \n Knowledge of Python (Python 3 desired) for CI/CD pipelines a bonus \n Familiarity with Pytest and Unittest a bonus \n Experience working with JSON and defining JSON Schemas a bonus \n Experience setting up and management Confluent/Kafka topics and ensuring performance using Kafka a bonus \n Familiarity with Schema Registry, message formats such as Avro, ORC, etc. \n Understanding how to manage ksqlDB SQL files and migrations and Kafka Streams \n Ability to thrive in a team-based environment \n Experience briefing the benefits and constraints of technology solutions to technology partners, stakeholders, team members, and senior level of management \n \n Physical Demands \n Position consists of sitting for long periods of time, bending, stooping, crouching, and lifting up to 20 pounds. Frequently uses hands/fingers for manipulation of keyboard and mouse. \n Work Environment \n Work is performed primarily indoors in a well-lit office environment. The environment is normally air conditioned, but conditions may change dependent upon circumstances. Work may need to be performed in a fast-paced environment requiring quick thinking and rapid judgements. Employee will be exposed to a wide variety of clients in differing functions, personalities, and abilities. \n About IBR Imagine Believe Realize, LLC (IBR) is an emerging small business focused on delivering software and systems engineering solutions to government and commercial clients. Our talent acquisition strategy is tailored to career seeking candidates who embrace continuous learning and desire to grow as a professional in the software/systems engineering industry. We strive to enhance our team members ability to thrive in the workplace by creating a proper work/life balance and first-class benefits package that includes: \n \n Nationwide medical, dental, and vision insurance \n 3 weeks of Paid Time Off and 11 Paid Federal Holidays \n 401k matching \n Life Insurance, Short-Term Disability, and Long-Term Disability at no cost to our employees \n Flexible spending accounts and Dependent Care spending accounts \n Wellness incentives \n Reimbursement for professional development and certifications \n Training assistance opportunities \n \n Upon hire and in compliance with federal law, all persons hired are required to verify identity and eligibility to work in the United States, and to complete the required employment eligibility verification and background check. IBR is a Federal Contractor. \n Imagine Believe Realize, LLC is proud to be an Equal Opportunity and Affirmative Action Employer. We do not discriminate based upon race, age, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.\u201d Learn more at  http://www.teamibr.com \n If alternative methods of assistance are needed with the application process, additional contact information has been provided below: \n info@teamibr.com \u200b\u200b\u200b\u200b\u200b\u200b\u200b407.459.1830 \n Job Type: Full-time \n Pay: $131,243.38 - $158,056.53 per year \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Employee assistance program \n Flexible spending account \n Health insurance \n Health savings account \n Life insurance \n Paid time off \n Professional development assistance \n Referral program \n Vision insurance \n \n Experience level: \n \n 10 years \n \n Schedule: \n \n Monday to Friday \n \n Work Location: Remote", "cleaned_desc": "The Senior Data Engineer must be able to meet the key criteria below: \n \n Location:  100% telework \n Years' Experience:  10+ years \n Education:  Bachelor\u2019s in IT related field \n Security Clearance:  IBR is a federal contractor. Applicants must be able to meet the requirements to obtain an Public Trust security clearance. NOTE: United States Citizenship is required. \n Work Authorization:  Must show that applicant is legally permitted to work in the United States. \n Employment Type:  Full-Time, W-2 \n Key Skills: \n 10+ years of IT experience focusing on enterprise data architecture and management \n Experience with Databricks required \n 8+ years experience in Conceptual/Logical/Physical Data Modeling & expertise in Relational and Dimensional Data Modeling \n Experience with ETL and ELT tools such as SSIS, Pentaho, and/or Data Migration Services \n Advanced level SQL experience (Joins, Aggregation, Windowing functions, Common Table Expressions, RDBMS schema design, Postgres performance optimization) \n Experience with AWS environment, CI/CD pipelines, and Python (Python 3) a bonus \n \n Overview \n Do you want to help build a portfolio of next-generation mobile-enabled data collection systems and enterprise portals? As a Data Engineer at IBR, you will support the Agile based engineering of a robust, secure, and scalable enterprise web portal solutions hosted in AWS. This position will work closely with the solutions delivery team to supporting the operations team performing Deployment, Systems Integration Testing, and Operations & Maintenance activities. \n Responsibilities \n \n Plan, create, and maintain data architectures, ensuring alignment with business requirements \n Obtain data, formulate dataset processes, and store optimized data \n Identify problems and inefficiencies and apply solutions \n Determine tasks where manual participation can be eliminated with automation.   Identify and optimize data bottlenecks, leveraging automation where possible \n Create and manage data lifecycle policies (retention, backups/restore, etc) \n Create, maintain, and manage ETL/ELT pipelines \n Create, maintain, and manage data transformations \n Maintain/update documentation \n Create, maintain, and manage data pipeline schedules \n Monitor data pipelines \n Create, maintain, and manage data quality gates (Great Expectations) to ensure high data quality \n Support AI/ML teams with optimizing feature engineering code \n Spark updates \n Create, maintain, and manage Spark Structured Steaming jobs, including using the newer Delta Live Tables and/or DBT \n Research existing data in the data lake to determine best sources for data \n Create, manage, and maintain ksqlDB and Kafka Streams queries/code \n Maintain and update Python-based data processing scripts executed on AWS Lambdas \n Unit tests for all the Spark, Python data processing and Lambda codes \n Maintain PCIS Reporting Database data lake with optimizations and maintenance (performance tuning, etc) \n \n Qualifications \n \n 10+ years of IT experience focusing on enterprise data architecture and management \n Experience in Conceptual/Logical/Physical Data Modeling & expertise in Relational and Dimensional Data Modeling \n Experience with Databricks, Structured Streaming, Delta Lake concepts, and Delta Live Tables required \n Additional experience with Spark, Spark SQL, Spark DataFrames and DataSets, and PySpark \n Data Lake concepts such as time travel and schema evolution and optimization   Structured Streaming and Delta Live Tables with Databricks a bonus \n Experience leading and architecting enterprise-wide initiatives specifically system integration, data migration, transformation, data warehouse build, data mart build, and data lakes implementation / support \n Advanced level understanding of streaming data pipelines and how they differ from batch systems \n Formalize concepts of how to handle late data, defining windows, and data freshness \n Advanced understanding of ETL and ELT and ETL/ELT tools such as SSIS, Pentaho, Data Migration Service etc \n Understanding of concepts and implementation strategies for different incremental data loads such as tumbling window, sliding window, high watermark, etc. \n Familiarity and/or expertise with Great Expectations or other data quality/data validation frameworks a bonus \n Understanding of streaming data pipelines and batch systems \n Familiarity with concepts such as late data, defining windows, and how window definitions impact data freshness \n Advanced level SQL experience (Joins, Aggregation, Windowing functions, Common Table Expressions, RDBMS schema design, Postgres performance optimization) \n Indexing and partitioning strategy experience \n Debug, troubleshoot, design and implement solutions to complex technical issues \n Experience with large-scale, high-performance enterprise big data application deployment and solution \n Understanding how to create DAGs to define workflows \n Familiarity with CI/CD pipelines, containerization, and pipeline orchestration tools such as Airflow, Prefect, etc a bonus but not required \n Architecture experience in AWS environment a bonus \n Familiarity working with Kinesis and/or Lambda specifically with how to push and pull data, how to use AWS tools to view data in Kinesis streams, and for processing massive data at scale (UNICORN) a bonus \n Experience with Docker, Jenkins, and CloudWatch \n Ability to write and maintain Jenkinsfiles for supporting CI/CD pipelines \n Experience working with AWS Lambdas for configuration and optimization \n Experience working with DynamoDB to query and write data \n Experience with S3 \n Knowledge of Python (Python 3 desired) for CI/CD pipelines a bonus \n Familiarity with Pytest and Unittest a bonus ", "techs": ["databricks", "ssis", "pentaho", "data migration services", "aws", "python", "spark", "spark sql", "spark dataframes", "spark datasets", "pyspark", "structured streaming", "delta lake", "ksqldb", "kafka streams", "great expectations", "pcis reporting database", "pytest", "unittest", "docker", "jenkins", "cloudwatch", "aws lambdas", "dynamodb", "s3"]}, "7dd9208ec61a79ed": {"terms": ["data engineer", "machine learning engineer"], "salary_min": 87225.445, "salary_max": 110446.85, "title": "Cerner Data Engineer", "company": "USA Health", "desc": "Overview: \n  USA Health is Transforming Medicine along the Gulf Coast to care for the unique needs of our community. \n \n  USA Health is changing how medical care, education and research impact the health of people who live in Mobile and the surrounding area. Our team of doctors, advanced care providers, nurses, therapists and researchers provide the region's most advanced medicine at multiple facilities, campuses, clinics and classrooms. We offer patients convenient access to innovative treatments and advancements that improve the health and overall wellbeing of our community. \n \n \n Responsibilities: \n  The Cerner Data Engineer will build and maintain data systems and construct datasets that are used to analyze and support USA Health Data and Analytics; implement methods to improve data reliability, quality, and efficiency - ensuring that data is collected accurately and consistently, y using standardized data practices; identify and correct any errors or inconsistencies in the data and ensure that the data is complete, accurate, and relevant to the intended use; conducts regular audits of data collection procedures; participate in data governance process by helping to establish policies and procedures for managing data, including data ownership, access, and security ensuring that data is used in a consistent and ethical manner; analyzing and organize raw data, removing any errors or inconsistencies, applying data standardization; combine data from multiple sources to provide a more complete picture of Health System practices; helping end users to identify trends and practices and improving the overall accuracy of the data; develop and maintain datasets by identifying the data that is needed, ensuring that it is cleaned and organized, and establishing a process for ensuring that the data will be refreshed periodically and monitored for accuracy; build data systems and pipelines by creating and managing the infrastructure that is used to collect, store, process, and analyze data and then establishing the processes that moves data from one place to another; build algorithms and prototypes by working with end users to help determine the problem that needs to be solved and for complex issues breaking it down into smaller, more manageable problems, and addressing those problems; then developing the appropriate algorithms or prototypes using programming languages, software development frameworks, and machine learning libraries as is applicable; develop and test architectures that enable data extraction and transformation to prepare data for prescriptive and predictive modeling; identify all of the data sources that will be used for the modeling project; this could include data from internal systems, external databases, or third-party APIs; ensure the data is cleaned and remove any errors or inconsistencies, and formatting the data in a way that is compatible with the modeling tools that will be used; develop an extraction and transformation (ETL) pipeline; develop and test the models and then deploy; develop analytical tools and programs by working with ream members and end users to define the problem, determine or design the appropriate solution as needed and then build the solution using a coding solution to a data visualization tool or machine learning library, then test and deploy the solution; collaborate with end users, team members, and vendors on assigned projects; works the assigned schedule as defined and overtime as required; completes all mandatory education requirements; attends meetings as required including administrative, committee, and staff meetings; cooperates with department staff to achieve objectives and maintain good interdepartmental relationships; abides by and enforces all compliance requirements; performs these responsibilities in an ethical manner consistent with the organization's values; adheres to USA Health policies including confidentiality; accepts and completes all duties positively and without conflict; cooperates, helps others, and improves the performance of the department; completes all mandatory department education and USA Health requirements; regular and prompt attendance; ability to work schedule as defined and overtime as required; related duties as required. \n \n \n Qualifications: \n  The Bachelor\u2019s degree from an accredited institution as approved and accepted by the University of South Alabama and four years of experience in IT HER programs, clinical applications and/or coding/programming with two years of experience specific to Cerner Plus.", "cleaned_desc": " Responsibilities: \n  The Cerner Data Engineer will build and maintain data systems and construct datasets that are used to analyze and support USA Health Data and Analytics; implement methods to improve data reliability, quality, and efficiency - ensuring that data is collected accurately and consistently, y using standardized data practices; identify and correct any errors or inconsistencies in the data and ensure that the data is complete, accurate, and relevant to the intended use; conducts regular audits of data collection procedures; participate in data governance process by helping to establish policies and procedures for managing data, including data ownership, access, and security ensuring that data is used in a consistent and ethical manner; analyzing and organize raw data, removing any errors or inconsistencies, applying data standardization; combine data from multiple sources to provide a more complete picture of Health System practices; helping end users to identify trends and practices and improving the overall accuracy of the data; develop and maintain datasets by identifying the data that is needed, ensuring that it is cleaned and organized, and establishing a process for ensuring that the data will be refreshed periodically and monitored for accuracy; build data systems and pipelines by creating and managing the infrastructure that is used to collect, store, process, and analyze data and then establishing the processes that moves data from one place to another; build algorithms and prototypes by working with end users to help determine the problem that needs to be solved and for complex issues breaking it down into smaller, more manageable problems, and addressing those problems; then developing the appropriate algorithms or prototypes using programming languages, software development frameworks, and machine learning libraries as is applicable; develop and test architectures that enable data extraction and transformation to prepare data for prescriptive and predictive modeling; identify all of the data sources that will be used for the modeling project; this could include data from internal systems, external databases, or third-party APIs; ensure the data is cleaned and remove any errors or inconsistencies, and formatting the data in a way that is compatible with the modeling tools that will be used; develop an extraction and transformation (ETL) pipeline; develop and test the models and then deploy; develop analytical tools and programs by working with ream members and end users to define the problem, determine or design the appropriate solution as needed and then build the solution using a coding solution to a data visualization tool or machine learning library, then test and deploy the solution; collaborate with end users, team members, and vendors on assigned projects; works the assigned schedule as defined and overtime as required; completes all mandatory education requirements; attends meetings as required including administrative, committee, and staff meetings; cooperates with department staff to achieve objectives and maintain good interdepartmental relationships; abides by and enforces all compliance requirements; performs these responsibilities in an ethical manner consistent with the organization's values; adheres to USA Health policies including confidentiality; accepts and completes all duties positively and without conflict; cooperates, helps others, and improves the performance of the department; completes all mandatory department education and USA Health requirements; regular and prompt attendance; ability to work schedule as defined and overtime as required; related duties as required. ", "techs": ["cerner data engineer", "data systems", "datasets", "usa health data and analytics", "standardized data practices", "data collection procedures", "data governance process", "data ownership", "data access", "data security", "data standardization", "data sources", "data cleaning", "data organization", "data refresh", "data accuracy", "data systems", "data pipelines", "infrastructure", "data collection", "data storage", "data processing", "data analysis", "algorithms", "prototypes", "programming languages", "software development frameworks", "machine learning libraries", "data extraction", "data transformation", "prescriptive modeling", "predictive modeling", "etl pipeline", "analytical tools", "data visualization", "collaboration", "mandatory education requirements", "meetings", "compliance requirements", "ethics", "confidentiality", "department duties", "attendance", "overtime."]}, "7f7a185825ef7e9f": {"terms": ["data engineer"], "salary_min": 60.0, "salary_max": 80.0, "title": "Data Migration Engineer", "company": "MetroSys", "desc": "Responsibilities: \n \n  Collaborate with stakeholders to understand data migration requirements, including scope, timelines, and specific data sets. \n  Design and develop a comprehensive data migration plan, considering factors such as data volume, complexity, and business continuity. \n  Utilize Komprise data management software to perform assessments, identify target data, and orchestrate the migration process. \n  Configure and optimize Komprise settings to align with migration goals, ensuring efficient and secure data transfer. \n  Conduct pre-migration validation tests to ensure data integrity and accuracy before the actual migration process. \n  Monitor the data migration process in real-time, addressing any issues or discrepancies as they arise. \n  Implement data validation and reconciliation procedures to verify the successful completion of the migration. \n  Collaborate with cross-functional teams, including storage administrators and system engineers, to ensure seamless integration with the NetApp environment. \n  Document the entire migration process, including configurations, settings, and any custom scripts or workflows used. \n  Provide knowledge transfer and training to internal teams for ongoing management and maintenance of the migrated data. \n \n  Requirements: \n \n  Bachelor's degree in Information Technology, Computer Science, or a related field (preferred) or equivalent work experience. \n  Proven work experience as a Data Migration Engineer with specific expertise in migrating data from Isilon to NetApp using Komprise. \n  Strong proficiency in Komprise data management software and related tools. \n  In-depth knowledge of Isilon and NetApp storage platforms, including file systems, protocols, and administration. \n  Experience with scripting languages (e.g., Python, PowerShell) for automation and customization of migration processes. \n  Excellent problem-solving and analytical skills, with the ability to diagnose and resolve complex data migration issues. \n  Strong communication and interpersonal skills, with the ability to collaborate effectively with technical and non-technical stakeholders. \n \n   \n T7ZuUtppMf", "cleaned_desc": "  Implement data validation and reconciliation procedures to verify the successful completion of the migration. \n  Collaborate with cross-functional teams, including storage administrators and system engineers, to ensure seamless integration with the NetApp environment. \n  Document the entire migration process, including configurations, settings, and any custom scripts or workflows used. \n  Provide knowledge transfer and training to internal teams for ongoing management and maintenance of the migrated data.    Proven work experience as a Data Migration Engineer with specific expertise in migrating data from Isilon to NetApp using Komprise. \n  Strong proficiency in Komprise data management software and related tools. \n  In-depth knowledge of Isilon and NetApp storage platforms, including file systems, protocols, and administration. \n  Experience with scripting languages (e.g., Python, PowerShell) for automation and customization of migration processes.    Excellent problem-solving and analytical skills, with the ability to diagnose and resolve complex data migration issues. \n  Strong communication and interpersonal skills, with the ability to collaborate effectively with technical and non-technical stakeholders. \n \n   ", "techs": ["data validation", "reconciliation procedures", "migration", "collaboration", "integration", "netapp environment", "documentation", "configurations", "settings", "custom scripts", "workflows", "knowledge transfer", "training", "data migration engineer", "isilon", "netapp", "komprise", "komprise data management software", "isilon storage platform", "netapp storage platform", "file systems", "protocols", "administration", "scripting languages", "python", "powershell", "automation", "customization", "problem-solving", "analytical skills", "data migration issues", "communication skills", "interpersonal skills"]}, "3b61441b9b1ff9fa": {"terms": ["data engineer"], "salary_min": 140000.0, "salary_max": 140000.0, "title": "Senior Data Warehouse Engineer", "company": "Twin Health", "desc": "Twin Health \n  At Twin Health, we empower people to reverse, prevent and improve chronic metabolic diseases. Twin Health invented The Whole Body Digital Twin\u2122 , a dynamic representation of each individual's unique metabolism, built from thousands of data points collected daily via non-invasive sensors and self-reported preferences. The Whole Body Digital Twin delivers a new standard of care, empowering physicians and patients to make personalized data-driven decisions. \n  Working here \n  Our team is passionate, talented, and driven by our purpose to improve the health and happiness of our members. Our culture empowers each Twin to do what's needed to create value for our customers and our company, and enjoy their experience at work. Twin Health was awarded Innovator of the Year by Employer Health Innovation Roundtable (EHIR) (out of 358 companies), named to the 2021 CB Insights Digital Health 150, and recognized by Built In's 2022 Best Places To Work Awards. In October 2021, Twin Health announced its Series C funding round of $155M, led by ICONIQ Growth, enabling us to scale services in the U.S. and globally, helping to solve the global chronic metabolic disease health crisis. We have recently announced broad and growing partnerships with premier employers, such as Blackstone and Berkshire Hathaway. We are building the company you always wished you worked for. Join us in revolutionizing healthcare and building the most impactful digital health company in the world! \n  Excited to join us and do your part in improving people's health and happiness? \n \n  Opportunity \n  Twin Heath is expanding rapidly across health providers nationwide in the US as well as India. We are seeking an experienced Data Warehouse Engineer to join our growing team to own the entire process of building a data warehouse from scratch and managing ETL pipelines, working collaboratively with internal business stakeholders and customers. We are looking for candidates physically located in PST. \n  Responsibilities \n \n Drive analysis, architecture, design, and development of Cloud based data warehouse and business intelligence solutions. \n  Design and develop data flows and models for data warehousing and self-serve reporting. \n  Design and build extensible data acquisition and integration solutions to meet business reporting and analytics needs. \n  Implement a comprehensive framework to support logging, profile and audit high volume high frequency file processing supporting multiple formats. \n  Automate and optimize existing data processing workloads to integrate with the enterprise data warehouse. \n  Understand and translate business needs into data models to support long-term, scalable, and reliable solutions. \n  Create data models for self-serve reporting. \n  Build data pipelines from systems such as CRM, ERP and internal applications with the emphasis on scalability and reliability. \n  Partner with business users, senior architects, and infrastructure engineers to form complete end-to end-solutions. \n  Drive data quality across the organization; develop best practices for standard naming conventions and coding practices to ensure consistency of data models and tracking. \n  Prepare to respond to ad hoc reporting needs of business functions. \n  Work in a fast-paced environment and perform effectively in a sprint based agile development environment. \n  Collaborate with developers and analysts on technical and functional designs. \n  Analyze query performance and perform query tuning to assist development engineers in designing and optimizing queries. \n Applicants must be authorized to work for any employer in the U.S. We are unable to sponsor or take over sponsorship of an employment Visa at this time. \n This remote opportunity is available to US based persons \n \n Qualifications \n \n Bachelor's degree in computers Ince or related field. \n  At least 8 year of overall experience building data warehouse solutions with solid data modeling skills. \n  At least 3 years of hands-on experience in building Data Warehouses in Snowflake or Redshift \n  At least 4 years of experience in developing data pipelines using Python, PySpark or Scala. \n  Experience with API design and development using RESTful and/or SOAP protocols. \n  At least 2 years of experience creating DBT models and in a cloud, data Warehouses platform. \n  Knowledge of advanced SQL scripting and ability to write complex queries. \n  Experience using Rivery or new age ELT tools like Fivetran, Matillion etc. \n  Understanding of agile methodologies such as CI/CD, Applicant Resiliency, and Security \n  Experience working with various file formats at scale. \n  Experience with AWS. Familiarity with AWS Athena, Glue, Data Pipeline is a plus. \n  At least 2 years of experience with Salesforce Health Cloud, Marketing Cloud and NetSuite Schemas. \n  Experience designing highly scalable ETL/ELT processes with complex data transformations, data formats including error handling and monitoring. \n  Excellent analytical, problem solving, and troubleshooting skills, and solid communication skills. \n \n Compensation and Benefits \n  The compensation range for this position is $140,000 annually. \n  In addition, Twin has an ambitious vision to empower people to live healthier and happier lives, and to achieve this purpose, we need the very best people to enhance our cutting-edge technology and medical science, deliver the best possible care, and turn our passion into value for our members, partners and investors. We are committed to delivering an outstanding culture and experience for every Twin employee through a company based on the values of passion, talent, and trust. We offer comprehensive benefits and perks in line with these principles, as well as a high level of flexibility for every Twin \n \n A competitive compensation package in line with leading technology companies \n As a remote friendly company we are committed to providing opportunities for all who join to further build relationships, increase cross-functional collaboration, and celebrate our accomplishments. \n Opportunity for equity participation \n Unlimited vacation with manager approval \n 16 weeks of 100% paid parental leave for delivering parents; 8 weeks of 100% paid parental leave for non-delivering parents \n 100% Employer sponsored healthcare, dental, and vision for you, and 80% coverage for your family; Health Savings Account and Flexible Spending Account options \n 401k retirement savings plan \n \n \n \n   Salary range for US jobs\n   \n  US Salary Range \n \n    $140,000\u2014$140,000 USD", "cleaned_desc": "  Design and build extensible data acquisition and integration solutions to meet business reporting and analytics needs. \n  Implement a comprehensive framework to support logging, profile and audit high volume high frequency file processing supporting multiple formats. \n  Automate and optimize existing data processing workloads to integrate with the enterprise data warehouse. \n  Understand and translate business needs into data models to support long-term, scalable, and reliable solutions. \n  Create data models for self-serve reporting. \n  Build data pipelines from systems such as CRM, ERP and internal applications with the emphasis on scalability and reliability. \n  Partner with business users, senior architects, and infrastructure engineers to form complete end-to end-solutions. \n  Drive data quality across the organization; develop best practices for standard naming conventions and coding practices to ensure consistency of data models and tracking. \n  Prepare to respond to ad hoc reporting needs of business functions. \n  Work in a fast-paced environment and perform effectively in a sprint based agile development environment. \n  Collaborate with developers and analysts on technical and functional designs. \n  Analyze query performance and perform query tuning to assist development engineers in designing and optimizing queries.   Applicants must be authorized to work for any employer in the U.S. We are unable to sponsor or take over sponsorship of an employment Visa at this time. \n This remote opportunity is available to US based persons \n \n Qualifications \n \n Bachelor's degree in computers Ince or related field. \n  At least 8 year of overall experience building data warehouse solutions with solid data modeling skills. \n  At least 3 years of hands-on experience in building Data Warehouses in Snowflake or Redshift \n  At least 4 years of experience in developing data pipelines using Python, PySpark or Scala. \n  Experience with API design and development using RESTful and/or SOAP protocols. \n  At least 2 years of experience creating DBT models and in a cloud, data Warehouses platform. \n  Knowledge of advanced SQL scripting and ability to write complex queries.    Experience using Rivery or new age ELT tools like Fivetran, Matillion etc. \n  Understanding of agile methodologies such as CI/CD, Applicant Resiliency, and Security \n  Experience working with various file formats at scale. \n  Experience with AWS. Familiarity with AWS Athena, Glue, Data Pipeline is a plus. \n  At least 2 years of experience with Salesforce Health Cloud, Marketing Cloud and NetSuite Schemas. \n  Experience designing highly scalable ETL/ELT processes with complex data transformations, data formats including error handling and monitoring. \n  Excellent analytical, problem solving, and troubleshooting skills, and solid communication skills. \n \n Compensation and Benefits \n  The compensation range for this position is $140,000 annually. \n  In addition, Twin has an ambitious vision to empower people to live healthier and happier lives, and to achieve this purpose, we need the very best people to enhance our cutting-edge technology and medical science, deliver the best possible care, and turn our passion into value for our members, partners and investors. We are committed to delivering an outstanding culture and experience for every Twin employee through a company based on the values of passion, talent, and trust. We offer comprehensive benefits and perks in line with these principles, as well as a high level of flexibility for every Twin \n ", "techs": ["extensible data acquisition", "integration solutions", "comprehensive framework", "high volume high frequency file processing", "multiple formats", "automating and optimizing data processing workloads", "enterprise data warehouse", "data models", "self-serve reporting", "data pipelines", "crm", "erp", "internal applications", "scalability", "reliability", "end-to-end solutions", "data quality", "naming conventions", "coding practices", "ad hoc reporting", "sprint-based agile development", "technical and functional designs", "query performance", "query tuning", "data warehouse solutions", "data modeling", "snowflake", "redshift", "data pipelines using python", "pyspark", "scala", "api design", "restful", "soap protocols", "dbt models", "cloud data warehouses", "advanced sql scripting", "rivery", "elt tools", "agile methodologies", "ci/cd", "applicant resiliency", "security", "file formats at scale", "aws", "aws athena", "aws glue", "aws data pipeline", "salesforce health cloud", "marketing cloud", "netsuite schemas", "etl/elt processes", "data transformations", "error handling", "monitoring", "analytical skills", "problem-solving skills", "troubleshooting skills"]}, "afa1c3c5c9790b59": {"terms": ["data engineer"], "salary_min": 130000.0, "salary_max": 145000.0, "title": "Senior Data and Analytics Engineer", "company": "MJH Life Sciences", "desc": "At MJH Life Sciences our success is measured by your success! If you set your standards high and want to contribute to a winning team, we\u2019ll provide you with every opportunity to help grow our company and your career. Our associates come from all backgrounds, sharing one key quality: determination to succeed. We value being Service Focused, having a Passion for Winning, Innovation, Respect, Integrity, and Teamwork. Nothing means more to us than hiring people with these attributes. If you believe you\u2019re right for the job, this is the place to prove it! \n Job Title: Senior Data & Analytics Engineer \n Reports to: Data Analytics Manager \n As a Senior Data & Analytics Engineer at MJH, you will model data and work closely with data architects, data analysts, data product managers, data scientists, and other analytics engineers to provide clean, accurate datasets for use by the team and business stakeholders. You will spend your time transforming, testing, deploying, and documenting data. You will be the bridge between the raw data our Data Integrations team lands in the data lake and our analytical and business stakeholders. As the person most directly responsible for materializing critical data for end users, you will apply software engineering best practices, including version control and continuous integration to the analytics code base. \n Job Responsibilities \n \n Assist the Data Analytics Manager in developing a highly scalable data warehouse and analytics platform that will assist with improved business outcomes. \n Assist with defining and developing the enterprise data architecture and best practices around processes, standards, methodologies, and data modeling. \n Collaborate with stakeholders to understand user needs and use cases to develop clear and compelling data models that support interactive and dynamic visualizations. \n Use dbt and Snowflake to iteratively deliver usable data models that enable analyst workflows and reverse ETL processes. \n Implement test-driven processes to ensure data accuracy. \n Assist project management in developing requirements and delivery expectations. \n When necessary, provide documentation and training to stakeholders to foster increased understanding and utilization of the delivered functionality. \n Become a subject matter expert on core business rules and systems. \n Be a champion of data privacy and quality. \n Perform other duties as assigned. \n \n Desired Skills and Experience \n \n 8+ years of experience as an analytics engineer, data engineer, data analyst, or ETL developer. \n 3 + years of experience in Snowflake with exposure to administration \n 2 + years of experience in DBT with advanced level like using jinja templates and creating macros. \n 3+ years of experience in GitHub implementing CICD pipelines for data engineering. \n Experience with any reporting tool like Tableau. \n Advanced proficiency in SQL and data modeling strategies. \n Previous experience with ETL/ELT principles and data warehousing concepts. \n Great team player with the ability to interact and communicate with all levels of management. \n Excellent organizational, prioritization, and independent decision-making skills. \n Communicate clearly using excellent written and verbal skills. \n Experience with Segment, Fivetran, and Tableau is a plus. \n Familiarity with modeling strategies such as snowflake, star, OBT, and relational is preferred. \n Experience working in an Agile environment is preferred. \n dbt certification would be strongly preferred. \n Continuous learning mindset. \n Bachelor\u2019s degree required. \n \n Job Type: Full-time \n COVID-19 considerations: Team is working remotely while we evaluate return to work scenarios. \n #LI-REMOTE \n MJH Life Sciences provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. All employees of MJH Life Sciences are employed \u201cAt Will.\u201d This means that either the employee or the Company is free to end the employment relationship at any time, for any reason, with or without cause and with or without notice. \n Job Type: Full-time \n Pay: $130,000.00 - $145,000.00 per year \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Employee assistance program \n Flexible spending account \n Health insurance \n Health savings account \n Life insurance \n Paid time off \n Referral program \n Vision insurance \n \n Compensation package: \n \n Bonus opportunities \n Yearly bonus \n \n Experience level: \n \n 6 years \n \n Schedule: \n \n 8 hour shift \n Day shift \n Monday to Friday \n \n Education: \n \n Bachelor's (Required) \n \n Work Location: Remote", "cleaned_desc": "At MJH Life Sciences our success is measured by your success! If you set your standards high and want to contribute to a winning team, we\u2019ll provide you with every opportunity to help grow our company and your career. Our associates come from all backgrounds, sharing one key quality: determination to succeed. We value being Service Focused, having a Passion for Winning, Innovation, Respect, Integrity, and Teamwork. Nothing means more to us than hiring people with these attributes. If you believe you\u2019re right for the job, this is the place to prove it! \n Job Title: Senior Data & Analytics Engineer \n Reports to: Data Analytics Manager \n As a Senior Data & Analytics Engineer at MJH, you will model data and work closely with data architects, data analysts, data product managers, data scientists, and other analytics engineers to provide clean, accurate datasets for use by the team and business stakeholders. You will spend your time transforming, testing, deploying, and documenting data. You will be the bridge between the raw data our Data Integrations team lands in the data lake and our analytical and business stakeholders. As the person most directly responsible for materializing critical data for end users, you will apply software engineering best practices, including version control and continuous integration to the analytics code base. \n Job Responsibilities \n \n Assist the Data Analytics Manager in developing a highly scalable data warehouse and analytics platform that will assist with improved business outcomes. \n Assist with defining and developing the enterprise data architecture and best practices around processes, standards, methodologies, and data modeling. \n Collaborate with stakeholders to understand user needs and use cases to develop clear and compelling data models that support interactive and dynamic visualizations. \n Use dbt and Snowflake to iteratively deliver usable data models that enable analyst workflows and reverse ETL processes. \n Implement test-driven processes to ensure data accuracy. \n Assist project management in developing requirements and delivery expectations. \n When necessary, provide documentation and training to stakeholders to foster increased understanding and utilization of the delivered functionality. \n Become a subject matter expert on core business rules and systems. \n Be a champion of data privacy and quality.   Perform other duties as assigned. \n \n Desired Skills and Experience \n \n 8+ years of experience as an analytics engineer, data engineer, data analyst, or ETL developer. \n 3 + years of experience in Snowflake with exposure to administration \n 2 + years of experience in DBT with advanced level like using jinja templates and creating macros. \n 3+ years of experience in GitHub implementing CICD pipelines for data engineering. \n Experience with any reporting tool like Tableau. \n Advanced proficiency in SQL and data modeling strategies. \n Previous experience with ETL/ELT principles and data warehousing concepts. \n Great team player with the ability to interact and communicate with all levels of management. \n Excellent organizational, prioritization, and independent decision-making skills. \n Communicate clearly using excellent written and verbal skills. \n Experience with Segment, Fivetran, and Tableau is a plus. ", "techs": ["snowflake", "dbt", "github", "tableau"]}, "6b0246ca2a37effe": {"terms": ["data engineer"], "salary_min": 55000.0, "salary_max": 140000.0, "title": "Data Engineer (AWS/ETL)", "company": "Aflac, Incorporated", "desc": "Salary Range:  $55,000 - $140,000 \n \n  We\u2019ve Got You Under Our Wing \n  We are the duck. We develop and empower our people, cultivate relationships, give back to our community, and celebrate every success along the way. We do it all\u2026 The Aflac Way . \n \n  Aflac, a Fortune 500 company, is an industry leader in voluntary insurance products that pay cash directly to policyholders and one of America's best-known brands. Aflac has been recognized as Fortune\u2019s 50 Best Workplaces for Diversity and as one of World\u2019s Most Ethical Companies by Ethisphere.com. \n   \n Our business is about being there for people in need. So, ask yourself, are you the duck? If so, there\u2019s a home, and a flourishing career for you at Aflac. \n \n  Work Designation.  Depending on your location within the continental US, this role may be  hybrid  or  remote.  \n \n If you live  within 50 miles  of the Aflac offices located in Columbus, GA or Columbia, SC, this role will be  hybrid.   This means you will be expected to work in the office for at least 60% of the work week. You will work from your home (within the continental US) for the remaining portion of the work week. Details of this schedule will be discussed with your leadership. \n  If you live  more than 50 miles  from the Aflac offices located in Columbus, GA or Columbia, SC, this role will be  remote.  This means you will be expected to work from your home, within the continental US. If the role is remote, there may be occasions that you are requested to come to the office based on business need. Any requests to come to the office would be communicated with you in advance. \n \n \n  What does it take to be successful at Aflac? \n \n  Acting with Integrity \n  Communicating Effectively \n  Pursuing Self-Development \n  Serving Customers \n  Supporting Change \n  Supporting Organizational Goals \n  Working with Diverse Populations \n \n \n  What does it take to be successful in this role? \n \n AWS Data Platform - Cloud infrastructure, Datalake/Cloud Formation, Automation, CI/CD  \n Amazon Cloud Data Storage \u2013 S3, RedShift, DynamoDB, NoSQL  \n ETL Tools \u2013 AWS Glue, Informatica Suite, SSIS, Infoworks  \n SQL & Relational Databases \u2013 SQL Server, Teradata, MS Access, HIVE, HBase  \n XML  \n XSLT  \n .NET Framework  \n C#  \n Java  \n JavaScript  \n jQuery  \n LINQ  \n MVC Framework  \n ASPX  \n Angular.js  \n Bootstrap  \n Knockout  \n Business Intelligence  \n ETL Techniques  \n Data Modeling  \n Data Warehousing/Business Intelligence  \n Meta Data Repository  \n MS SQL Server \n \n \n  Education & Experience Required \n \n  Bachelor's Degree In Programming/systems or computer science, or related field \n  Four or more years of programming experience \n  Experience and understanding of multiple programming languages and applicable applications including SQL and ETL \n  Experienced in Cloud data storage and consumption models such as S3 Buckets, Lake Formation, RedShift, Dynamo DB \n  Experienced in working with compute engines such as Spark, EMR, Data bricks, Snowflake etc. \n \n  Or an equivalent combination of education and experience \n \n  Principal Duties & Responsibilities \n \n Works under minimum supervisor to exercise independent decision making; Creates processes which initiate the ETL or Batch cycle; develops streaming processes for extracted data loading to destination database, including on-the-fly processing where extract and transformation phase to no go to persistent storage; Performs data profiling of source data in order to identify data quality issues and anomalies, business knowledge embedded in data; natural keys, and meta data information \n \n   \n \n Build repeatable, automated and sustainable Extract, Transform and Load (ETL) processes leveraging platforms such as AWS cloud native \u2013 AWS Glue, DMS, Informatica, Infoworks, Hadoop, Spark processing Engines \n \n   \n \n Creates data validation rule on source data to confirm the data has correct and/or expected values; Writes alternate workflow steps or reports back to the source for further analysis and correction of incorrect record(s) when validation rules are not passed \n \n   \n \n Develops processes to be applied to extracted source data to move to target state; Writes data cleansing functions to get data to proper prunes data set to include only fields needed; translates source code values to target value; Standardizes free form values to codes; Derives new values through calculations on existing fields; Merges data from multiple in order to generate on consolidated source for the target \n \n   \n \n Sorts and Aggregates records into rollup where multiple records are represented; Creates surrogate-key values to use in place of multiple natural keys; Turns multiple columns into multiple rows or vice\u2013versa (Transposing or Pivoting); Splits multi-valued column data into multiple columns; Disaggregates repeating columns into separate detail table(s); Creates lookup tables; Looks up and validates reference information as part of data validation \n \n   \n \n Creates and applies data validation step process in order to perform partial, full or no record\u2019s rejection; Writes processes which handle exceptions and/or move records exceptions to alternate Transform step(s) \n \n   \n \n Develops processes which load the transformed data into end target systems (database, file, application, etc.); may apply different techniques based on business needs including inserting new data into target; Over write existing data with cumulative information; Updates existing data at some frequency; Creates data validation steps in this layer to ensure loaded data \n \n   \n \n Creates process cleanup after complex ETL processes which release resources used to run ETL; Creates processes to archive data \n \n   \n \n Participates in project collaboration meeting with clients, business analysts, and team members in order to analyze and clarify business requirements; Translates business requirements into detailed technical specifications \n \n   \n \n Works with project teams to define and design scope for each project; Creates unit test cases to ensure the application meets the needs of the business \n \n   \n \n Ensures proper configuration management and change controls are implemented; Provides technical assistance and cross training to other team members \n \n   \n \n Designs and implements technology best practices, guidelines and repeatable processes; Prepares and presents status updates on various projects \n \n   \n \n Performs other duties as required \n \n \n  Total Rewards \n  This compensation range is specific to the job level and takes into account the wide range of factors that are considered in making compensation decisions including, but not limited to: education, experience, licensure, certifications, geographic location, and internal equity. The range has been created in good faith based on information known to Aflac at the time of the posting. Compensation decisions are dependent on the circumstances of each case. This salary range does not include any potential incentive pay or benefits, however, such information will be provided separately when appropriate. The salary range for this position is $55,000 to $140,000. \n \n  In addition to the base salary, we offer an array of benefits to meet your needs including medical, dental, and vision coverage, prescription drug coverage, health care flexible spending, dependent care flexible spending, Aflac supplemental policies (Accident, Cancer, Critical Illness and Hospital Indemnity offered at no costs to employee), 401(k) plans, annual bonuses, and an opportunity to purchase company stock. On an annual basis, you\u2019ll also be offered 11 paid holidays, up to 20 days PTO to be used for any reason, and, if eligible, state mandated sick leave (Washington employees accrue 1 hour sick leave for every 40 hours worked) and other leaves of absence, if eligible, when needed to support your physical, financial, and emotional well-being. Aflac complies with all applicable leave laws, including, but not limited to sick and safe leave, and adoption and parental leave, in all states and localities.", "cleaned_desc": "  Working with Diverse Populations \n \n \n  What does it take to be successful in this role? \n \n AWS Data Platform - Cloud infrastructure, Datalake/Cloud Formation, Automation, CI/CD  \n Amazon Cloud Data Storage \u2013 S3, RedShift, DynamoDB, NoSQL  \n ETL Tools \u2013 AWS Glue, Informatica Suite, SSIS, Infoworks  \n SQL & Relational Databases \u2013 SQL Server, Teradata, MS Access, HIVE, HBase  \n XML  \n XSLT  \n .NET Framework  \n C#  \n Java  \n JavaScript  \n jQuery  \n LINQ  \n MVC Framework  \n ASPX  \n Angular.js  \n Bootstrap  \n Knockout  \n Business Intelligence    ETL Techniques  \n Data Modeling  \n Data Warehousing/Business Intelligence  \n Meta Data Repository  \n MS SQL Server \n \n \n  Education & Experience Required \n \n  Bachelor's Degree In Programming/systems or computer science, or related field \n  Four or more years of programming experience \n  Experience and understanding of multiple programming languages and applicable applications including SQL and ETL \n  Experienced in Cloud data storage and consumption models such as S3 Buckets, Lake Formation, RedShift, Dynamo DB \n  Experienced in working with compute engines such as Spark, EMR, Data bricks, Snowflake etc. \n \n  Or an equivalent combination of education and experience \n \n  Principal Duties & Responsibilities \n \n Works under minimum supervisor to exercise independent decision making; Creates processes which initiate the ETL or Batch cycle; develops streaming processes for extracted data loading to destination database, including on-the-fly processing where extract and transformation phase to no go to persistent storage; Performs data profiling of source data in order to identify data quality issues and anomalies, business knowledge embedded in data; natural keys, and meta data information \n \n   \n   Build repeatable, automated and sustainable Extract, Transform and Load (ETL) processes leveraging platforms such as AWS cloud native \u2013 AWS Glue, DMS, Informatica, Infoworks, Hadoop, Spark processing Engines \n \n   \n \n Creates data validation rule on source data to confirm the data has correct and/or expected values; Writes alternate workflow steps or reports back to the source for further analysis and correction of incorrect record(s) when validation rules are not passed \n \n   \n \n Develops processes to be applied to extracted source data to move to target state; Writes data cleansing functions to get data to proper prunes data set to include only fields needed; translates source code values to target value; Standardizes free form values to codes; Derives new values through calculations on existing fields; Merges data from multiple in order to generate on consolidated source for the target \n \n   \n \n Sorts and Aggregates records into rollup where multiple records are represented; Creates surrogate-key values to use in place of multiple natural keys; Turns multiple columns into multiple rows or vice\u2013versa (Transposing or Pivoting); Splits multi-valued column data into multiple columns; Disaggregates repeating columns into separate detail table(s); Creates lookup tables; Looks up and validates reference information as part of data validation \n \n   \n \n Creates and applies data validation step process in order to perform partial, full or no record\u2019s rejection; Writes processes which handle exceptions and/or move records exceptions to alternate Transform step(s) \n \n   \n \n Develops processes which load the transformed data into end target systems (database, file, application, etc.); may apply different techniques based on business needs including inserting new data into target; Over write existing data with cumulative information; Updates existing data at some frequency; Creates data validation steps in this layer to ensure loaded data \n \n   ", "techs": ["aws data platform", "cloud infrastructure", "datalake/cloud formation", "automation", "ci/cd", "amazon cloud data storage", "s3", "redshift", "dynamodb", "nosql", "etl tools", "aws glue", "informatica suite", "ssis", "infoworks", "sql", "relational databases", "sql server", "teradata", "ms access", "hive", "hbase", "xml", "xslt", ".net framework", "c#", "java", "javascript", "jquery", "linq", "mvc framework", "aspx", "angular.js", "bootstrap", "knockout", "business intelligence", "etl techniques", "data modeling", "data warehousing/business intelligence", "meta data repository", "ms sql server", "aws glue", "dms", "hadoop", "spark processing engines"]}, "45a231ffe43c577a": {"terms": ["data engineer"], "salary_min": 48.0, "salary_max": 52.0, "title": "Jr Data Engineer - Secret Cleared", "company": "Gridiron IT", "desc": "Seeking a Junior Data Engineer on a remote basis.  Secret clearance is required.  \n Overview:  We are looking to immediately fill a Junior Data Engineer on our team. The ADE is one of the major pillars of MyNavy HR Transformation and serves as an enterprise-wide centralized repository that provides seamless and secure data access. This pilot\u2019s objective is to support defining a comprehensive future-state ADE data model by informing the total number of unique data elements and to assess the ability to accelerate the data integration process using new data tools available following the Authority to Operate (ATO). \n Minimum Qualifications: \n \n 2+ years of experience with scalable ETL workflows/development, extract, cleanse, and process disparate data sources \n Secret Clearance is required. \n HS Diploma required (Bachelor's preferred) \n Experience with cleaning and transforming data utilizing Python and/or SQL, specifically complex SQL queries \n Familiarity with acquiring data from disparate data sources using APIs and SQL \n Ability to develop scripts and programs for converting various types of data into usable formats and support project team to scale, monitor, and operate data platforms \n \n Job Type: Full-time \n Pay: $48.00 - $52.00 per hour \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Health insurance \n Vision insurance \n \n Schedule: \n \n 8 hour shift \n \n Work Location: Remote", "cleaned_desc": " Secret Clearance is required. \n HS Diploma required (Bachelor's preferred) \n Experience with cleaning and transforming data utilizing Python and/or SQL, specifically complex SQL queries \n Familiarity with acquiring data from disparate data sources using APIs and SQL \n Ability to develop scripts and programs for converting various types of data into usable formats and support project team to scale, monitor, and operate data platforms ", "techs": ["python", "sql", "apis"]}, "c323d27b302a6ce8": {"terms": ["data engineer"], "salary_min": 65.0, "salary_max": 70.0, "title": "Lead Data Engineer", "company": "eCom Solutions Inc", "desc": "Job Title: Sr. Lead Data Engineer \n Location: Remote \n Duration: Long Term \n Pay Rate: BOE \n Job Description Summary : \n Recognized subject matter expert. Apply advanced statistical data modeling techniques to large data sets to create actionable business insights- Use statistical analysis software packages (SAS, SPSS, etc.-) and business intelligence and analytics platforms to create dashboards and reporting capabilities- Design, develop and deploy algorithms through statistical programming that: support complex business decision making, manage large amounts of data and create visualization and insights. Manage major/complex large projects and coaches, review and delegate work to entry/intermediate profession. \n MUST HAVE's: \n \u200b Over all 12-15 years of experience as a Data Engineer. \n TOP 3 Skills: \n 1. Snowflake \n 2. SQL \n 3. Data Modelling \n Expertise in ETL tools (SAP BODS, Informatica or similar tools) \n MAJOR JOB DUTIES AND RESPONSIBILITIES \n o Collaborate with the Analytical team to prototype and prove the viability of data solutions \n o Design of all aspects of data solutions including modeling, developing, technical documentation, data diagrams and data dictionaries. \n o Lead development and execution of data solutions involving domain specific analytics. \n o Provide expertise in the development of standards, architectural governance, design patterns, and practices, evaluate best applicable solutions for different use cases \n o Work cross-functionally with product owners, business stakeholders, and management. \n o Direct people management and leadership experience (budget management, interview, hire, performance management, promotion, etc.) \n o Suggest how to design and optimize data architecture for consumption, utilization, and analytics on the Data Warehouse \n o Analyze data patterns and optimize data processing. Suggest best practice, technology, and process improvements \n o Comfortable with rapid prototyping and disciplined software development processes. \n o Realize and communicate trends related to Data technologies \n o Create centralized and streamlined Datawarehouse support processes. Provide effective training to team members \n o Performs other duties as assigned \n QUALIFICATIONS  (Education/Training, Experience and Certifications) \n o Bachelor\u2019s Degree in Engineering (computer science or other equivalent majors). Prefer advanced degree \n o 12+ years of architecture or engineering experience in building data pipelines, ETLs, data platforms, data products, distributed data systems or AI/ML, Master Data, \n Data Quality, Cloud Technologies, etc. \n o 12+ year of experience with SQL, shell is a plus \n o 3+ plus years of job-related experience in programming languages such as Scala, Python, or similar \n KNOWLEDGE SKILLS AND ABILITIES  (Those necessary to perform the job competently) \n o Expertise in Cloud Data technologies (Snowflake, AWS or GCP) \n o Expertise in ETL tools (SAP BODS, Informatica or similar tools) \n o SAP functional domain knowledge is big plus (Supply Chain, Finance etc.) \n o Experience in data governance, data security, data compliance etc. \n o Large scale projects, process and industry experience is big plus \n o Strong organizational skills \n o Proven team motivator who can develop talent \n o Able to coach team members. \n o Ability to provide technical direction to data and analytics teams \n o Excellent communication skills both verbal and written \n Job Type: Contract \n Pay: $65.00 - $70.00 per hour \n Benefits: \n \n Dental insurance \n Health insurance \n Life insurance \n Vision insurance \n \n Experience level: \n \n 11+ years \n \n Schedule: \n \n Day shift \n Monday to Friday \n \n Experience: \n \n Cloud Data technologies (Snowflake, AWS or GCP): 4 years (Preferred) \n ETL tools (SAP BODS, Informatica: 4 years (Preferred) \n SAP functional domain knowledge: 1 year (Preferred) \n \n Work Location: Remote", "cleaned_desc": "Job Title: Sr. Lead Data Engineer \n Location: Remote \n Duration: Long Term \n Pay Rate: BOE \n Job Description Summary : \n Recognized subject matter expert. Apply advanced statistical data modeling techniques to large data sets to create actionable business insights- Use statistical analysis software packages (SAS, SPSS, etc.-) and business intelligence and analytics platforms to create dashboards and reporting capabilities- Design, develop and deploy algorithms through statistical programming that: support complex business decision making, manage large amounts of data and create visualization and insights. Manage major/complex large projects and coaches, review and delegate work to entry/intermediate profession. \n MUST HAVE's: \n \u200b Over all 12-15 years of experience as a Data Engineer. \n TOP 3 Skills: \n 1. Snowflake \n 2. SQL \n 3. Data Modelling \n Expertise in ETL tools (SAP BODS, Informatica or similar tools)   MAJOR JOB DUTIES AND RESPONSIBILITIES \n o Collaborate with the Analytical team to prototype and prove the viability of data solutions \n o Design of all aspects of data solutions including modeling, developing, technical documentation, data diagrams and data dictionaries. \n o Lead development and execution of data solutions involving domain specific analytics. \n o Provide expertise in the development of standards, architectural governance, design patterns, and practices, evaluate best applicable solutions for different use cases \n o Work cross-functionally with product owners, business stakeholders, and management. \n o Direct people management and leadership experience (budget management, interview, hire, performance management, promotion, etc.) \n o Suggest how to design and optimize data architecture for consumption, utilization, and analytics on the Data Warehouse \n o Analyze data patterns and optimize data processing. Suggest best practice, technology, and process improvements \n o Comfortable with rapid prototyping and disciplined software development processes. \n o Realize and communicate trends related to Data technologies \n o Create centralized and streamlined Datawarehouse support processes. Provide effective training to team members \n o Performs other duties as assigned   QUALIFICATIONS  (Education/Training, Experience and Certifications) \n o Bachelor\u2019s Degree in Engineering (computer science or other equivalent majors). Prefer advanced degree \n o 12+ years of architecture or engineering experience in building data pipelines, ETLs, data platforms, data products, distributed data systems or AI/ML, Master Data, \n Data Quality, Cloud Technologies, etc. \n o 12+ year of experience with SQL, shell is a plus \n o 3+ plus years of job-related experience in programming languages such as Scala, Python, or similar \n KNOWLEDGE SKILLS AND ABILITIES  (Those necessary to perform the job competently) \n o Expertise in Cloud Data technologies (Snowflake, AWS or GCP) \n o Expertise in ETL tools (SAP BODS, Informatica or similar tools) \n o SAP functional domain knowledge is big plus (Supply Chain, Finance etc.) \n o Experience in data governance, data security, data compliance etc. \n o Large scale projects, process and industry experience is big plus \n o Strong organizational skills ", "techs": ["snowflake", "sql", "data modelling", "sap bods", "informatica", "scala", "python", "snowflake", "aws", "gcp", "sap bods", "informatica"]}, "a4031cd344d4043a": {"terms": ["data engineer"], "salary_min": 145000.0, "salary_max": 185000.0, "title": "Data Engineer", "company": "CyberCoders", "desc": "Data Engineer \n  \n Job Title:  Senior Data Engineer\n   \n Remote:  Yes, 100% Remote\n   \n Job Type:  Direct Hire\n   \n Hours:  Full-Time\n   \n Base Salary Range:  $140-185k (base) / year\n   \n \n Given the clients work with government contracts, you must be an active US Citizen to apply. You will need to obtain a security clearance after hire, but do not need to have one currently. US CITIZENSHIP REQUIRED is for all Government Clearance. Thank you. \n \n  Our team is looking for an experienced Senior Data Engineer to join us in working on top secret DOD cleared projects. Ideally someone with experience in time series and sensor data collecting with the ability to program in Python or R. We are building out a new data engineering team and this role would support our existing 4 data scientists in their efforts by building data pipelines, shaping data, etl, etc.\n  \n  What You Need for this Position \n \n Data Engineering / Cloud Engineering / Database Management Experience \n Incredible SQL Skills (MySQL / SQLite / Oracle) \n Programming experience (Python or R) \n \n \n  Bonus Point For: \n \n \n Sensor Data / Imaging Data / Time Series Data \n IOT  \n Azure Gov / AWS \n Government Clearance \n \n  What's In It for You \n \n Generous Base Salary \n 401k (+match) \n Flexible Remote Schedule \n Health / Dental / Vision \n Vacation / PTO \n 14 Paid holidays + Holiday break around new year / end of year \n \n \n   So, if you are a Data Engineer with experience, please apply today!\n  \n \n   Colorado employees will receive paid sick leave. For additional information about available benefits, please contact Hanna Frauen\n  \n \n Applicants must be authorized to work in the U.S. \n  CyberCoders is proud to be an Equal Opportunity Employer \n \n  All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.\n  \n \n Your Right to Work  \u2013 In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.", "cleaned_desc": " Incredible SQL Skills (MySQL / SQLite / Oracle) \n Programming experience (Python or R) \n \n \n  Bonus Point For: \n \n \n Sensor Data / Imaging Data / Time Series Data \n IOT  \n Azure Gov / AWS ", "techs": ["mysql", "sqlite", "oracle", "python", "r", "sensor data", "imaging data", "time series data", "iot", "azure gov", "aws"]}, "647e801f97a01cca": {"terms": ["data engineer"], "salary_min": 110000.0, "salary_max": 120000.0, "title": "Azure Data Engineer", "company": "GTECH LLC", "desc": "Job Title : Azure Data Engineer \n Job Location: Remote \n Responsibilities \n \n Understand business requirements. \n Understand source systems, source data and source data formats that are available on-prem / cloud. \n Design and build data ingestion pipeline. \n Design and build complex data processing pipelines. \n Work with relevant stakeholders to assist with data-related technical issues and support their data needs. \n Build programs for data quality checks. \n Provide operational support. \n Work with data architecture, data governance and data analytics. teams to ensure pipelines adhere to enterprise standards, usability, and performance. \n Involve in System Testing, UAT, code deployment activities. \n Coordinate with offshore team on regular basis \n \n Primary Skills \n \n Azure Databricks \n PySpark, \n Scala \n Snowflake (at least for 1 resource) \n \n Secondary Skills \n \n ADF \n CICD \n Airflow \n SQL \n Cloud Databases \n Understanding of Agile methodologies \n \n Job Type: Full-time \n Salary: $110,000.00 - $120,000.00 per year \n Experience level: \n \n 5 years \n \n Schedule: \n \n 8 hour shift \n \n Work Location: Remote", "cleaned_desc": " Work with relevant stakeholders to assist with data-related technical issues and support their data needs. \n Build programs for data quality checks. \n Provide operational support. \n Work with data architecture, data governance and data analytics. teams to ensure pipelines adhere to enterprise standards, usability, and performance. \n Involve in System Testing, UAT, code deployment activities. \n Coordinate with offshore team on regular basis \n \n Primary Skills ", "techs": ["none"]}, "420fe670f9676abc": {"terms": ["data engineer"], "salary_min": 55000.0, "salary_max": 140000.0, "title": "Data Engineer (AWS/ETL)", "company": "Aflac", "desc": "The Company: Aflac Columbus \n     \n \n \n \n \n \n \n \n     The Location: Remote, US, 31999 GA, US, 31999 \n     \n \n \n \n \n \n \n \n     The Division: Digital Services \n     \n \n \n \n \n \n \n \n     Job Id: 5463 \n     \n \n \n \n \n \n \n \n \n Salary Range:  $55,000 - $140,000 \n \n \n We\u2019ve Got You Under Our Wing \n We are the duck. We develop and empower our people, cultivate relationships, give back to our community, and celebrate every success along the way. We do it all\u2026 The Aflac Way . \n \n \n Aflac, a Fortune 500 company, is an industry leader in voluntary insurance products that pay cash directly to policyholders and one of America's best-known brands. Aflac has been recognized as Fortune\u2019s 50 Best Workplaces for Diversity and as one of World\u2019s Most Ethical Companies by Ethisphere.com. \n \n \n Our business is about being there for people in need. So, ask yourself, are you the duck? If so, there\u2019s a home, and a flourishing career for you at Aflac. \n \n \n Work Designation.  Depending on your location within the continental US, this role may be  hybrid  or  remote.  \n \n If you live  within 50 miles  of the Aflac offices located in Columbus, GA or Columbia, SC, this role will be  hybrid.   This means you will be expected to work in the office for at least 60% of the work week. You will work from your home (within the continental US) for the remaining portion of the work week. Details of this schedule will be discussed with your leadership. \n If you live  more than 50 miles  from the Aflac offices located in Columbus, GA or Columbia, SC, this role will be  remote.  This means you will be expected to work from your home, within the continental US. If the role is remote, there may be occasions that you are requested to come to the office based on business need. Any requests to come to the office would be communicated with you in advance. \n \n \n   \n What does it take to be successful at Aflac? \n \n Acting with Integrity \n Communicating Effectively \n Pursuing Self-Development \n Serving Customers \n Supporting Change \n Supporting Organizational Goals \n Working with Diverse Populations \n \n \n   \n What does it take to be successful in this role? \n \n AWS Data Platform - Cloud infrastructure, Datalake/Cloud Formation, Automation, CI/CD  \n \n \n Amazon Cloud Data Storage \u2013 S3, RedShift, DynamoDB, NoSQL  \n \n \n ETL Tools \u2013 AWS Glue, Informatica Suite, SSIS, Infoworks  \n \n \n SQL & Relational Databases \u2013 SQL Server, Teradata, MS Access, HIVE, HBase  \n \n \n XML  \n \n \n XSLT  \n \n \n .NET Framework  \n \n \n C#  \n \n \n Java  \n \n \n JavaScript  \n \n \n jQuery  \n \n \n LINQ  \n \n \n MVC Framework  \n \n \n ASPX  \n \n \n Angular.js  \n \n \n Bootstrap  \n \n \n Knockout  \n \n \n Business Intelligence  \n \n \n ETL Techniques  \n \n \n Data Modeling  \n \n \n Data Warehousing/Business Intelligence  \n \n \n Meta Data Repository  \n \n \n MS SQL Server \n \n \n \n Education & Experience Required \n \n Bachelor's Degree In Programming/systems or computer science, or related field \n Four or more years of programming experience \n Experience and understanding of multiple programming languages and applicable applications including SQL and ETL \n Experienced in Cloud data storage and consumption models such as S3 Buckets, Lake Formation, RedShift, Dynamo DB \n Experienced in working with compute engines such as Spark, EMR, Data bricks, Snowflake etc. \n \n Or an equivalent combination of education and experience \n \n \n Principal Duties & Responsibilities \n \n Works under minimum supervisor to exercise independent decision making; Creates processes which initiate the ETL or Batch cycle; develops streaming processes for extracted data loading to destination database, including on-the-fly processing where extract and transformation phase to no go to persistent storage; Performs data profiling of source data in order to identify data quality issues and anomalies, business knowledge embedded in data; natural keys, and meta data information \n \n \n \n \n Build repeatable, automated and sustainable Extract, Transform and Load (ETL) processes leveraging platforms such as AWS cloud native \u2013 AWS Glue, DMS, Informatica, Infoworks, Hadoop, Spark processing Engines \n \n \n \n \n Creates data validation rule on source data to confirm the data has correct and/or expected values; Writes alternate workflow steps or reports back to the source for further analysis and correction of incorrect record(s) when validation rules are not passed \n \n \n \n \n Develops processes to be applied to extracted source data to move to target state; Writes data cleansing functions to get data to proper prunes data set to include only fields needed; translates source code values to target value; Standardizes free form values to codes; Derives new values through calculations on existing fields; Merges data from multiple in order to generate on consolidated source for the target \n \n \n \n \n Sorts and Aggregates records into rollup where multiple records are represented; Creates surrogate-key values to use in place of multiple natural keys; Turns multiple columns into multiple rows or vice\u2013versa (Transposing or Pivoting); Splits multi-valued column data into multiple columns; Disaggregates repeating columns into separate detail table(s); Creates lookup tables; Looks up and validates reference information as part of data validation \n \n \n \n \n Creates and applies data validation step process in order to perform partial, full or no record\u2019s rejection; Writes processes which handle exceptions and/or move records exceptions to alternate Transform step(s) \n \n \n \n \n Develops processes which load the transformed data into end target systems (database, file, application, etc.); may apply different techniques based on business needs including inserting new data into target; Over write existing data with cumulative information; Updates existing data at some frequency; Creates data validation steps in this layer to ensure loaded data \n \n \n \n \n Creates process cleanup after complex ETL processes which release resources used to run ETL; Creates processes to archive data \n \n \n \n \n Participates in project collaboration meeting with clients, business analysts, and team members in order to analyze and clarify business requirements; Translates business requirements into detailed technical specifications \n \n \n \n \n Works with project teams to define and design scope for each project; Creates unit test cases to ensure the application meets the needs of the business \n \n \n \n \n Ensures proper configuration management and change controls are implemented; Provides technical assistance and cross training to other team members \n \n \n \n \n Designs and implements technology best practices, guidelines and repeatable processes; Prepares and presents status updates on various projects \n \n \n \n \n Performs other duties as required \n \n \n \n Total Rewards \n This compensation range is specific to the job level and takes into account the wide range of factors that are considered in making compensation decisions including, but not limited to: education, experience, licensure, certifications, geographic location, and internal equity. The range has been created in good faith based on information known to Aflac at the time of the posting. Compensation decisions are dependent on the circumstances of each case. This salary range does not include any potential incentive pay or benefits, however, such information will be provided separately when appropriate. The salary range for this position is $55,000 to $140,000. \n \n \n In addition to the base salary, we offer an array of benefits to meet your needs including medical, dental, and vision coverage, prescription drug coverage, health care flexible spending, dependent care flexible spending, Aflac supplemental policies (Accident, Cancer, Critical Illness and Hospital Indemnity offered at no costs to employee), 401(k) plans, annual bonuses, and an opportunity to purchase company stock. On an annual basis, you\u2019ll also be offered 11 paid holidays, up to 20 days PTO to be used for any reason, and, if eligible, state mandated sick leave (Washington employees accrue 1 hour sick leave for every 40 hours worked) and other leaves of absence, if eligible, when needed to support your physical, financial, and emotional well-being. Aflac complies with all applicable leave laws, including, but not limited to sick and safe leave, and adoption and parental leave, in all states and localities. \n \n \n \n \n \n \n   Nearest Major Market:  Columbus GA  \n \n \n  Apply Now \u00bb", "cleaned_desc": " \n \n \n Education & Experience Required \n \n Bachelor's Degree In Programming/systems or computer science, or related field \n Four or more years of programming experience \n Experience and understanding of multiple programming languages and applicable applications including SQL and ETL \n Experienced in Cloud data storage and consumption models such as S3 Buckets, Lake Formation, RedShift, Dynamo DB \n Experienced in working with compute engines such as Spark, EMR, Data bricks, Snowflake etc. \n \n Or an equivalent combination of education and experience \n \n \n Principal Duties & Responsibilities \n \n Works under minimum supervisor to exercise independent decision making; Creates processes which initiate the ETL or Batch cycle; develops streaming processes for extracted data loading to destination database, including on-the-fly processing where extract and transformation phase to no go to persistent storage; Performs data profiling of source data in order to identify data quality issues and anomalies, business knowledge embedded in data; natural keys, and meta data information \n \n \n \n \n Build repeatable, automated and sustainable Extract, Transform and Load (ETL) processes leveraging platforms such as AWS cloud native \u2013 AWS Glue, DMS, Informatica, Infoworks, Hadoop, Spark processing Engines \n \n \n \n \n Creates data validation rule on source data to confirm the data has correct and/or expected values; Writes alternate workflow steps or reports back to the source for further analysis and correction of incorrect record(s) when validation rules are not passed \n \n \n \n \n Develops processes to be applied to extracted source data to move to target state; Writes data cleansing functions to get data to proper prunes data set to include only fields needed; translates source code values to target value; Standardizes free form values to codes; Derives new values through calculations on existing fields; Merges data from multiple in order to generate on consolidated source for the target \n \n \n \n \n Sorts and Aggregates records into rollup where multiple records are represented; Creates surrogate-key values to use in place of multiple natural keys; Turns multiple columns into multiple rows or vice\u2013versa (Transposing or Pivoting); Splits multi-valued column data into multiple columns; Disaggregates repeating columns into separate detail table(s); Creates lookup tables; Looks up and validates reference information as part of data validation \n \n \n \n \n Creates and applies data validation step process in order to perform partial, full or no record\u2019s rejection; Writes processes which handle exceptions and/or move records exceptions to alternate Transform step(s) \n \n \n \n ", "techs": ["sql", "etl", "s3 buckets", "lake formation", "redshift", "dynamo db", "spark", "emr", "data bricks", "snowflake", "aws glue", "dms", "informatica", "infoworks", "hadoop"]}, "8a6fc1cf4a3aad4e": {"terms": ["data engineer"], "salary_min": 130524.87, "salary_max": 165273.56, "title": "Lead Data Engineer - Data Interoperability", "company": "b.well Connected Health", "desc": "Lead Data Engineer - Data Interoperability Team \n \n  As a Lead Data Engineer, you will be a critical member of the Data Interoperability team responsible for building and maintaining data pipelines and data infrastructure that connects to thousands of data sources around the country to bring together a person\u2019s health record in one place.\n   \n  b.well Connected Health has the largest set of connected health data for any person in the United States. By bringing a person\u2019s health data into one place, we are able to help everyone get convenient and affordable health care.\n   \n \n This position is available for fully remote work .\n   \n \n What You'll Do: \n \n \n Design, build, and maintain b.well\u2019s data pipeline infrastructure using Python, Spark, Prefect, Kubernetes and other modern technologies \n Lead a team of data engineers to build data pipelines and infrastructure that connects to thousands of data sources around the country including health providers, insurance companies, pharmacies and labs. \n Launch new projects from ideation to completion \n Help lead other developers to improve their career development and coding abilities \n You will safeguard sensitive data by following policies and training concerning your security and privacy responsibilities \n \n \n Job Requirements: \n \n \n 7+ years of professional programming experience (must include Python) \n 2+ years building microservices in Python \n Exceptional and demonstrable data engineering experience \n Experience in loading, validating, cleaning, and manipulating data files \n Strong experience with unit testing and test-driven development \n Strong experience with relational and/or NoSQL databases \n Strong experience with cloud-based infrastructure \n Comfort with Linux/Unix command line \n \n \n Great to Have: \n \n \n 7+ years of Advance Python experience \n 5+ years of data pipeline engineering experience \n 1+ years of experience with Spark \n Experience with Airflow or Prefect \n Experience with Docker \n Experience with streaming data \n Experience scaling technology solutions to hundreds of thousands active users \n Experience mentoring other developers \n Deep understanding of common API methodologies \n Startup experience \n \n \n Blow Us Away: \n \n \n Experience working with third-party healthcare APIs, HL7, data streams, and/or flat files \n Experience in cybersecurity \n Experience with HIPAA, HITECH, and HITRUST \n An active GitHub profile or other public code portfolio \n Active Stack Overflow profile \n Documented work on open source projects \n \n \n \n   Data shows that women, people of color, and other underrepresented groups may be less likely to apply for jobs unless they believe they are a perfect match. But b.well holds diversity amongst its key values, and we have a strong commitment to building our workforce and products through that lens.\n   \n \n \n \n   You don't have to check every box in this job description to be a great fit for the role! If you're excited about this position and the prospect of working for b.well, please apply. If it turns out this role isn't for you, there may be other openings that could align with your experience and expertise!\n   \n \n \n \n  We are committed to an inclusive and diverse b.well. We are an equal opportunity employer. We do not discriminate based on race, ethnicity, color, ancestry, national origin, religion, sex, sexual orientation, gender identity, age, disability, veteran, genetic information, marital status or any other legally protected status.", "cleaned_desc": " Lead a team of data engineers to build data pipelines and infrastructure that connects to thousands of data sources around the country including health providers, insurance companies, pharmacies and labs. \n Launch new projects from ideation to completion \n Help lead other developers to improve their career development and coding abilities \n You will safeguard sensitive data by following policies and training concerning your security and privacy responsibilities \n \n \n Job Requirements: \n \n \n 7+ years of professional programming experience (must include Python) \n 2+ years building microservices in Python \n Exceptional and demonstrable data engineering experience \n Experience in loading, validating, cleaning, and manipulating data files \n Strong experience with unit testing and test-driven development   Strong experience with relational and/or NoSQL databases \n Strong experience with cloud-based infrastructure \n Comfort with Linux/Unix command line \n \n \n Great to Have: \n \n \n 7+ years of Advance Python experience \n 5+ years of data pipeline engineering experience \n 1+ years of experience with Spark \n Experience with Airflow or Prefect \n Experience with Docker \n Experience with streaming data   Experience scaling technology solutions to hundreds of thousands active users \n Experience mentoring other developers \n Deep understanding of common API methodologies \n Startup experience \n \n \n Blow Us Away: \n \n \n Experience working with third-party healthcare APIs, HL7, data streams, and/or flat files \n Experience in cybersecurity \n Experience with HIPAA, HITECH, and HITRUST \n An active GitHub profile or other public code portfolio \n Active Stack Overflow profile ", "techs": ["data pipelines", "microservices", "python", "data engineering", "unit testing", "test-driven development", "relational databases", "nosql databases", "cloud-based infrastructure", "linux/unix command line", "spark", "airflow", "prefect", "docker", "streaming data", "scaling technology solutions", "mentoring", "common api methodologies", "third-party healthcare apis", "hl7", "data streams", "flat files", "cybersecurity", "hipaa", "hitech", "hitrust", "github", "stack overflow"]}, "6d6399c51c6d5573": {"terms": ["data engineer"], "salary_min": 127700.0, "salary_max": 191500.0, "title": "Staff Data Engineer", "company": "Western Governors University", "desc": "The salary range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs.\n  \n \n \n   At WGU, it is not typical for an individual to be hired at or near the top of the range for their role, and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is:\n  \n  Pay Range: $127,700.00 - $191,500.00\n  \n  If you\u2019re passionate about building a better future for individuals, communities, and our country\u2014and you\u2019re committed to working hard to play your part in building that future\u2014consider WGU as the next step in your career.\n  \n \n \n   Driven by a mission to expand access to higher education through online, competency-based degree programs, WGU is also committed to being a great place to work for a diverse workforce of student-focused professionals. The university has pioneered a new way to learn in the 21st century, one that has received praise from academic, industry, government, and media leaders. Whatever your role, working for WGU gives you a part to play in helping students graduate, creating a better tomorrow for themselves and their families.\n  \n \n   Current WGU employees should submit an internal application before 10/27/2023 to be considered.\n  \n \n \n   The Staff Data Engineer should be agnostic to tools and should be able to supervise, design, architect and code using Apache Spark and other cloud technologies. The position will supervise and design how data will flow through hybrid data environments comprised of open-source big data platforms and traditional database systems. The core responsibility for this position includes supervision of data engineering technical aspects, design of data and system architecture for the Data Lake and data warehouse, supervision of the technical aspects of a data engineering team and projects encompassing dimensional and normalized data modeling. The Staff Data Engineer will improve technical standards in the environment ensuring optimal use of data warehouse and other data stores to solve business problems. They will serve as the lead engineer and go to person for all aspects of the data engineer team including solution architecture of data systems.\n  \n \n \n   Essential Functions and Responsibilities:\n  \n \n \n \n     Supervise work on cloud technologies and architect scalable and performant Data Lake systems.\n    \n \n \n     Establish design and methodology for database build processes.\n    \n \n \n     Supervise the architecture and design of complete data model solutions.\n    \n \n \n     Supervise necessary data protection and security processes.\n    \n \n \n     Create and design extract processes for data access layer.\n    \n \n \n     Translate business problems/information requirements accurately to logical/physical data models aligning with customers\u2019 data architecture standards.\n    \n \n \n     Supervise and perform research and analysis to find solutions for complex business problems.\n    \n \n \n     Monitor job performance and fine tune Spark SQL queries as appropriate on a regular basis.\n    \n \n \n     Supervise the profiling of data, the publishing of data profiles and corrective actions if required to ensure data quality.\n    \n \n \n     Supervise and perform documentation / reverse engineering / analysis of data mapping using data integration code/tools.\n    \n \n \n     Work with APIs for data wrangling and integrations with other systems data in the EDW.\n    \n \n \n     Perform impact analysis using Data Integration/Data Virtualization tool repositories, DB data dictionary, UNIX scripts and frontend code on versioning systems.\n    \n \n \n     Analyze / research data on multiple platforms as wells as multiple heterogeneous databases including custom developed databases.\n    \n \n \n     Positively impact projects by completing tasks assigned on time.\n    \n \n \n     Communicate technical and domain knowledge as it relates to work, to both technical and non-technical audiences.\n    \n \n \n     Ingest and transform structured, semi-structured, and unstructured data from sources including relational databases, NoSQL, external APIs, JSON, XML, delimited files, and more.\n    \n \n \n     Support business and functional requirements and translate these requirements into robust, scalable, solutions.\n    \n \n \n     Collaborate with engineers to help adopt best practices in data system creation, data integrity, test design, analysis, validation, and documentation.\n    \n \n \n     Help continually improve ongoing reporting and analysis processes, automate, or simplify self-service modelling and production support for customers.\n    \n \n \n     Performs other related duties as assigned.\n    \n \n \n \n   Knowledge, Skill and Abilities:\n  \n \n \n \n     Expertise with analytical reporting tools, preferably Cognos and Tableau.\n    \n \n \n     Mastery in code based ETL/ ELT tools for importing and exporting data across disparate systems.\n    \n \n \n     Expertise in analytic skills related to working with unstructured datasets.\n    \n \n \n     Use of industry best practices for code development, testing, implementation and documentation.\n    \n \n \n     Ability to evaluate and prioritize work based on the organization\u2019s needs.\n    \n \n \n     Ability to supervise cross team projects to accomplish data integrations and pipelines.\n    \n \n \n     Supervisory abilities for data engineering team with respect to technical design and architecture.\n    \n \n \n     Excellent verbal & written communication, along with technical documentation\n    \n \n \n     Ability to work and deliver in a team environment\n    \n \n \n     Ability to manage the use of tools like Jira, Confluence, GitHub\n    \n \n \n     Architect and Develop processes for audit of Data Integrity\n    \n \n \n     Ability to mentor Associate/Senior/Data Engineer in data pipeline architecture and coding standards\n    \n \n \n     Supervise Validation and testing to analyze and debug issues\n    \n \n \n     Mastery of AWS cloud technologies, REST API, and HTML5\n    \n \n \n     Mastery of relational SQL and NoSQL databases\n    \n \n \n     Mastery with object-oriented/object function scripting languages: Python, Java, Scala\n    \n \n \n     Mastery of big data tools: Hadoop, Spark, Kafka, Databricks, etc.\n    \n \n \n \n   Competencies:\n  \n \n   Organizational or Student Impact:\n  \n \n \n \n     Recommends and implements changes in technical/business processes; identifies areas for improvement.\n    \n \n \n     Helps lead/coordinate extremely complex technical projects and programs and leads development and implementation of innovative solutions for specialized technical issues.\n    \n \n \n     Works proactively; identifies and helps prevent/ solve problems that may cross disciplines.\n    \n \n \n     Fully understands and quantifies project risks with impact. Identifies, generates, and implements innovative solutions.\n    \n \n \n   Problem Solving & Decision Making:\n  \n \n \n \n     This individual accomplishes goals and objectives independently.\n    \n \n \n     Builds and leads teams, influencing decisions and results.\n    \n \n \n     Uses discretion to fully scope, design, and implement solutions to complex technical problems.\n    \n \n \n     The individual provides regular technical advice and direction to technical teams and management.\n    \n \n \n     Models and helps set high standards for effective interactions with internal and external individuals.\n    \n \n \n   Communication & Influence:\n  \n \n \n \n     Communicates with parties within and outside of their job function and typically has responsibilities for communicating with parties external to the organization.\n    \n \n \n     Works to influence others to accept and understand new concepts, practices, and approaches. Requires ability to communicate with executive leadership regarding matters of significant importance to the organization.\n    \n \n \n     This individual may conduct briefings with senior leaders within the technical function.\n    \n \n \n   Leadership:\n  \n \n \n \n     Frequently responsible for providing guidance, coaching, and training to other employees across the Company within the area of expertise.\n    \n \n \n     Responsible for managing large, complex project initiatives or strategically important solutions to the organization, involving large cross-functional teams.\n    \n \n \n     May have direct reports but generally fewer than three.\n    \n \n \n \n   Job Qualifications:\n  \n \n \n \n     M. S. in Business, Management Information Systems, Computer Science, or a related field, or an equivalent combination of experience and training.\n    \n \n \n     Seven or more years of experience as a Data Engineer, Data Integration, Big Data, or Business Intelligence Engineer with a background as a Software Engineer.\n    \n \n \n \n   Preferred Qualifications:\n  \n \n \n \n     Strong experience with distance education and distance learning students is preferred.\n    \n \n \n     Higher Education domain knowledge\n    \n \n \n     Experience as a Lead or Staff Data Engineer\n    \n \n \n \n   #LI-REMOTE\n  \n \n   #LI-ZARD\n  \n \n  As an equal opportunity employer, WGU recognizes that our strength lies in our people. We are committed to diversity.", "cleaned_desc": "The salary range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs.\n  \n \n \n   At WGU, it is not typical for an individual to be hired at or near the top of the range for their role, and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is:\n  \n  Pay Range: $127,700.00 - $191,500.00\n  \n  If you\u2019re passionate about building a better future for individuals, communities, and our country\u2014and you\u2019re committed to working hard to play your part in building that future\u2014consider WGU as the next step in your career.\n  \n \n \n   Driven by a mission to expand access to higher education through online, competency-based degree programs, WGU is also committed to being a great place to work for a diverse workforce of student-focused professionals. The university has pioneered a new way to learn in the 21st century, one that has received praise from academic, industry, government, and media leaders. Whatever your role, working for WGU gives you a part to play in helping students graduate, creating a better tomorrow for themselves and their families.\n  \n \n   Current WGU employees should submit an internal application before 10/27/2023 to be considered.\n  \n \n \n   The Staff Data Engineer should be agnostic to tools and should be able to supervise, design, architect and code using Apache Spark and other cloud technologies. The position will supervise and design how data will flow through hybrid data environments comprised of open-source big data platforms and traditional database systems. The core responsibility for this position includes supervision of data engineering technical aspects, design of data and system architecture for the Data Lake and data warehouse, supervision of the technical aspects of a data engineering team and projects encompassing dimensional and normalized data modeling. The Staff Data Engineer will improve technical standards in the environment ensuring optimal use of data warehouse and other data stores to solve business problems. They will serve as the lead engineer and go to person for all aspects of the data engineer team including solution architecture of data systems.\n  \n \n \n   Essential Functions and Responsibilities:\n  \n \n \n \n     Supervise work on cloud technologies and architect scalable and performant Data Lake systems.\n    \n \n \n     Establish design and methodology for database build processes.\n    \n \n \n     Supervise the architecture and design of complete data model solutions.\n    \n \n \n     Supervise necessary data protection and security processes.\n    \n \n \n     Create and design extract processes for data access layer.\n    \n \n \n     Translate business problems/information requirements accurately to logical/physical data models aligning with customers\u2019 data architecture standards.\n    \n \n \n     Supervise and perform research and analysis to find solutions for complex business problems.\n    \n \n \n     Monitor job performance and fine tune Spark SQL queries as appropriate on a regular basis.\n    \n \n \n     Supervise the profiling of data, the publishing of data profiles and corrective actions if required to ensure data quality.     \n \n \n     Supervise and perform documentation / reverse engineering / analysis of data mapping using data integration code/tools.\n    \n \n \n     Work with APIs for data wrangling and integrations with other systems data in the EDW.\n    \n \n \n     Perform impact analysis using Data Integration/Data Virtualization tool repositories, DB data dictionary, UNIX scripts and frontend code on versioning systems.\n    \n \n \n     Analyze / research data on multiple platforms as wells as multiple heterogeneous databases including custom developed databases.\n    \n \n \n     Positively impact projects by completing tasks assigned on time.\n    \n \n \n     Communicate technical and domain knowledge as it relates to work, to both technical and non-technical audiences.\n    \n \n \n     Ingest and transform structured, semi-structured, and unstructured data from sources including relational databases, NoSQL, external APIs, JSON, XML, delimited files, and more.\n    \n \n \n     Support business and functional requirements and translate these requirements into robust, scalable, solutions.\n    \n \n \n     Collaborate with engineers to help adopt best practices in data system creation, data integrity, test design, analysis, validation, and documentation.\n    \n \n \n     Help continually improve ongoing reporting and analysis processes, automate, or simplify self-service modelling and production support for customers.\n    \n \n \n     Performs other related duties as assigned.\n    \n \n \n \n   Knowledge, Skill and Abilities:\n  \n \n \n \n     Expertise with analytical reporting tools, preferably Cognos and Tableau.\n    \n \n \n     Mastery in code based ETL/ ELT tools for importing and exporting data across disparate systems.\n    \n \n       Expertise in analytic skills related to working with unstructured datasets.\n    \n \n \n     Use of industry best practices for code development, testing, implementation and documentation.\n    \n \n \n     Ability to evaluate and prioritize work based on the organization\u2019s needs.\n    \n \n \n     Ability to supervise cross team projects to accomplish data integrations and pipelines.\n    \n \n \n     Supervisory abilities for data engineering team with respect to technical design and architecture.\n    \n \n \n     Excellent verbal & written communication, along with technical documentation\n    \n \n \n     Ability to work and deliver in a team environment\n    \n \n \n     Ability to manage the use of tools like Jira, Confluence, GitHub\n    \n \n \n     Architect and Develop processes for audit of Data Integrity\n    \n \n \n     Ability to mentor Associate/Senior/Data Engineer in data pipeline architecture and coding standards\n    \n \n \n     Supervise Validation and testing to analyze and debug issues\n    \n \n \n     Mastery of AWS cloud technologies, REST API, and HTML5\n    \n \n \n     Mastery of relational SQL and NoSQL databases\n    \n \n \n     Mastery with object-oriented/object function scripting languages: Python, Java, Scala\n    \n \n \n     Mastery of big data tools: Hadoop, Spark, Kafka, Databricks, etc.\n    \n \n \n     Competencies:\n  \n \n   Organizational or Student Impact:\n  \n \n \n \n     Recommends and implements changes in technical/business processes; identifies areas for improvement.\n    \n \n \n     Helps lead/coordinate extremely complex technical projects and programs and leads development and implementation of innovative solutions for specialized technical issues.\n    \n \n \n     Works proactively; identifies and helps prevent/ solve problems that may cross disciplines.\n    \n \n \n     Fully understands and quantifies project risks with impact. Identifies, generates, and implements innovative solutions.\n    \n \n \n   Problem Solving & Decision Making:\n  \n \n \n \n     This individual accomplishes goals and objectives independently.\n    \n \n \n     Builds and leads teams, influencing decisions and results.\n    \n \n \n     Uses discretion to fully scope, design, and implement solutions to complex technical problems.\n    \n \n \n     The individual provides regular technical advice and direction to technical teams and management.\n    \n \n \n     Models and helps set high standards for effective interactions with internal and external individuals.\n    \n \n \n   Communication & Influence:\n  \n \n \n \n     Communicates with parties within and outside of their job function and typically has responsibilities for communicating with parties external to the organization.\n    \n \n \n     Works to influence others to accept and understand new concepts, practices, and approaches. Requires ability to communicate with executive leadership regarding matters of significant importance to the organization.\n    \n ", "techs": ["apache spark", "cognos", "tableau", "hadoop", "spark", "kafka", "databricks", "python", "java", "scala", "aws", "rest api", "html5"]}, "e6c5d0d5fcc570e0": {"terms": ["data engineer"], "salary_min": 78365.22, "salary_max": 99227.83, "title": "Data Center Network Engineer", "company": "Black Box", "desc": "Qualified candidate for the Data Center Network Engineer needs to understand networking. Why is just as important as how. Given the freedom to innovate, you seek new and better ways of doing things. You love to mentor others because you know a stronger team means everybody wins. If you are looking for an opportunity to make a difference and build a team, talk to us. Provide post-sales deployment engineering expertise and hands-on support inclusive of architectural, design, integration and support the initial implementation, installation, configuration, and ongoing change support for network solutions across various BBOX product and service offerings. Come be a part of a team working and supporting data centers and remote offices within one of the world's largest financial networks. You need to have a desire to learn why as much as how. Attention to detail sets you apart from others. You have not reached your peak but are on your way. You love to mentor others because you know a stronger team means everybody wins. If you are looking for an opportunity to make a difference and build a team, talk to us. \n You will be responsible to provide post-sales deployment engineering expertise and hands-on support inclusive of architectural, design, integration and support the initial implementation, installation, configuration, and ongoing change support for network solutions across various BBOX product and service offerings. \n Primary Roles & Responsibilities: \n \n Provide post-sales engineering implementation services for network solutions across various BBOX product and service offerings such as requirement definitions and implementation plans, end to end system designs, equipment staging, configuration creation and testing, and solution deployment of varying types of software and/or hardware network solution deployments spanning geographical separation. \n Proactively assess solution specifications in light of changing customer requirements, and recommend solution changes that optimize value for both the client and BBOX organization. \n Prepare documentation for internal and external clients detailing system designs and configuration of deployed solutions. \n Ability to coordinate remotely with Smart Hands and Project Managers to complete the activity with clear communication and coordination \n Develop and maintain professional and productive relationships with clients, infrastructure vendors such as ISPs and Carrier Services, software & hardware vendors and related key contributors to ensure stable and quality product & service delivery consistent with company objectives and client expectations. \n Provide a technical overview of product architecture, functionality, system data requirements, service delivery and integration with enterprise applications. \n Continuously expand, research and leverage knowledge of market and industry trends and benchmarking to identify, recommend and implement best practices, methodologies and relevant analytics. \n Continuously develop and enhance knowledge, skills and abilities through various learning channels to expand technical and non-technical capabilities. Ensure further expansion of skill-set in the operating systems, networking infrastructure and products & services that BBOX supports. \n Meet all financial performance objectives for area of responsibility and take corrective action as needed. \n Implement and make recommendations to improve methodologies, core competencies and processes for deployment engineering to ensure stable and quality product & service delivery consistent with company objectives and client expectations. \n Maintain and enhance a strong client service-oriented environment focused on problem prediction, detection and resolution. Proactively identify and remove barriers to meeting client expectations. Provide timely documentation of issues, action plan and outcome. Achieve all client satisfaction objectives and internal and external SLAs. \n Actively and consistently recommend and support all efforts to improve, simplify, automate and enhance day to day service delivery operations and the client experience. \n Foster and contribute toward collaborative working relationships within operations and across all levels and departments of the organization to execute deployment engineering functions and company priorities. \n Utilize escalation and exception paths, processes and systems to report current performance and make recommendations for improvement of performance. \n Achieve performance targets established by leadership for applicable Key Performance Indicators. \n Perform other duties as assigned by management. \n \n Knowledge, Skills, Abilities \n Accountability - Demonstrates an understanding of the link between one\u2019s own job responsibilities and overall organizational goals and needs, and performs one\u2019s job with the broader goals in mind. Looks beyond the requirements of one\u2019s own job to offer suggestions for improvements of overall organization operations. Takes personal ownership in the organization\u2019s success. \n Customer Focus - Demonstrates concern for meeting internal and external customers\u2019 needs in a manner that provides satisfaction for the customer. Considers the impact on the external customer when taking action, setting policies or carrying out one\u2019s own job tasks. Looks for external trends that are likely to shape the wants and needs of customers in the near future. Looks for creative approaches to providing or improving services that may increase efficiency and decrease cost. \n \u00b7Business Acumen - Interprets situations and events from a business standpoint in order to make decisions that are consistent and congruent with the organization's strategic direction and goals. Demonstrates the ability to use technology to enhance decision making, and provide cost-effective organizational and management tools. Aligns policies for a consistent and united business approach. Increases cooperation and communications between departments. \n Decision Making - Makes good decisions using a combination of analysis, knowledge, experience, and judgment. Analyzes and distinguishes core problems by looking at the symptoms. Resolves key issues behind major problems in the short term while developing and executing long term solutions. Has a strong record for making decisions that are correct and accurate. Applies strategies to implement effective decision making during crises. \n Results Focused - Demonstrates concern for achieving or surpassing results against an internal or external standard of excellence, shows a passion for improving the delivery of services with a commitment to continuous improvement. Sets and maintains high performance standards for self and others that support the organization\u2019s strategic plan. \n Education / Experience Requirements \n \n Bachelor\u2019s Degree in Engineering, Management Information Systems, Information Technology, Computer Science or related field, or equivalent, relevant experience. \n Minimum of 5 years with engineering deployment responsibilities involving complex client requirements assessments, solutions designs and implementation within the technology services industry. \n Ability to work within Change Management process/procedures and the ability to understand the requirements to compile documents with existing standards. The ability to gather requirements from the end user. Merge with existing standards within specified timeframes. \n Previous post-sales engineering experience with network solutions including requirement definitions and implementation plans, end-to-end system designs, equipment staging, configuration creation and testing, and solution deployment of varying types of software and/or hardware network solution deployments spanning geographical separation. \n Cisco Certified Network Professional (CCNP), Cisco Certified Network Associate (CCNA), Arista ACE or related certifications preferred. \n Working within a production Data Center environment including experience directly managing routers, switches, firewalls, global and local load balancing, DMZ and a good understanding of DDI. \n A proficient networking skillset within industry-standard networking technologies and infrastructures including cabling, LAN and WAN. Extensive routing experience with routing protocols including but not limited to a thorough understanding of BGP, OSPF, EIGRP, route subnetting and route aggregation techniques. Demonstrable switching experience and knowledge with datacenter switching, including but not limited to Nexus product line, Spine and leaf architecture, Cisco ACI, Arista CLOS. \n End-to-end process thinker, with proven experience in business processes and workflow design. \n Excellent problem solving and systems analysis skills with demonstrated success in root cause analysis, effectiveness measurements and related documentation. \n Demonstrated experience of continuously expanding and leveraging knowledge of technology, market and industry trends with success in identifying, recommending and implementing best practices and methodologies. \n Ability to work effectively across all functional groups to optimize product & service offerings, fostering a seamless internal and external client experience and track record of timely and accurate issue resolution. \n Proficient in MS Office (Word, Excel, PowerPoint), Outlook, SharePoint, ERP, service delivery management tools and related cloud based technology systems. \n \n Job Type: Full-time \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Health insurance \n Health savings account \n Paid time off \n Parental leave \n Referral program \n Vision insurance \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n Computer networking: 5 years (Preferred) \n LAN: 2 years (Preferred) \n \n Security clearance: \n \n Confidential (Preferred) \n \n Work Location: Remote", "cleaned_desc": "Qualified candidate for the Data Center Network Engineer needs to understand networking. Why is just as important as how. Given the freedom to innovate, you seek new and better ways of doing things. You love to mentor others because you know a stronger team means everybody wins. If you are looking for an opportunity to make a difference and build a team, talk to us. Provide post-sales deployment engineering expertise and hands-on support inclusive of architectural, design, integration and support the initial implementation, installation, configuration, and ongoing change support for network solutions across various BBOX product and service offerings. Come be a part of a team working and supporting data centers and remote offices within one of the world's largest financial networks. You need to have a desire to learn why as much as how. Attention to detail sets you apart from others. You have not reached your peak but are on your way. You love to mentor others because you know a stronger team means everybody wins. If you are looking for an opportunity to make a difference and build a team, talk to us. \n You will be responsible to provide post-sales deployment engineering expertise and hands-on support inclusive of architectural, design, integration and support the initial implementation, installation, configuration, and ongoing change support for network solutions across various BBOX product and service offerings. \n Primary Roles & Responsibilities: \n \n Provide post-sales engineering implementation services for network solutions across various BBOX product and service offerings such as requirement definitions and implementation plans, end to end system designs, equipment staging, configuration creation and testing, and solution deployment of varying types of software and/or hardware network solution deployments spanning geographical separation. \n Proactively assess solution specifications in light of changing customer requirements, and recommend solution changes that optimize value for both the client and BBOX organization. \n Prepare documentation for internal and external clients detailing system designs and configuration of deployed solutions. \n Ability to coordinate remotely with Smart Hands and Project Managers to complete the activity with clear communication and coordination \n Develop and maintain professional and productive relationships with clients, infrastructure vendors such as ISPs and Carrier Services, software & hardware vendors and related key contributors to ensure stable and quality product & service delivery consistent with company objectives and client expectations. \n Provide a technical overview of product architecture, functionality, system data requirements, service delivery and integration with enterprise applications. \n Continuously expand, research and leverage knowledge of market and industry trends and benchmarking to identify, recommend and implement best practices, methodologies and relevant analytics. \n Continuously develop and enhance knowledge, skills and abilities through various learning channels to expand technical and non-technical capabilities. Ensure further expansion of skill-set in the operating systems, networking infrastructure and products & services that BBOX supports. \n Meet all financial performance objectives for area of responsibility and take corrective action as needed.   Results Focused - Demonstrates concern for achieving or surpassing results against an internal or external standard of excellence, shows a passion for improving the delivery of services with a commitment to continuous improvement. Sets and maintains high performance standards for self and others that support the organization\u2019s strategic plan. \n Education / Experience Requirements \n \n Bachelor\u2019s Degree in Engineering, Management Information Systems, Information Technology, Computer Science or related field, or equivalent, relevant experience. \n Minimum of 5 years with engineering deployment responsibilities involving complex client requirements assessments, solutions designs and implementation within the technology services industry. \n Ability to work within Change Management process/procedures and the ability to understand the requirements to compile documents with existing standards. The ability to gather requirements from the end user. Merge with existing standards within specified timeframes. \n Previous post-sales engineering experience with network solutions including requirement definitions and implementation plans, end-to-end system designs, equipment staging, configuration creation and testing, and solution deployment of varying types of software and/or hardware network solution deployments spanning geographical separation. \n Cisco Certified Network Professional (CCNP), Cisco Certified Network Associate (CCNA), Arista ACE or related certifications preferred. \n Working within a production Data Center environment including experience directly managing routers, switches, firewalls, global and local load balancing, DMZ and a good understanding of DDI. \n A proficient networking skillset within industry-standard networking technologies and infrastructures including cabling, LAN and WAN. Extensive routing experience with routing protocols including but not limited to a thorough understanding of BGP, OSPF, EIGRP, route subnetting and route aggregation techniques. Demonstrable switching experience and knowledge with datacenter switching, including but not limited to Nexus product line, Spine and leaf architecture, Cisco ACI, Arista CLOS. \n End-to-end process thinker, with proven experience in business processes and workflow design. \n Excellent problem solving and systems analysis skills with demonstrated success in root cause analysis, effectiveness measurements and related documentation. \n Demonstrated experience of continuously expanding and leveraging knowledge of technology, market and industry trends with success in identifying, recommending and implementing best practices and methodologies. ", "techs": ["networking", "mentorship", "post-sales deployment", "architecture", "design", "integration", "implementation", "installation", "configuration", "change support", "bbox product", "bbox service", "documentation", "coordination", "smart hands", "project managers", "client relationships", "infrastructure vendors", "isps", "carrier services", "software vendors", "hardware vendors", "product architecture", "system data requirements", "service delivery", "integration", "enterprise applications", "market trends", "industry trends", "analytics", "learning channels", "operating systems", "networking infrastructure", "financial performance", "engineering", "management information systems", "information technology", "computer science", "complex client requirements assessments", "solutions designs", "change management", "requirements gathering", "standards compilation", "post-sales engineering", "cisco certified network professional", "cisco certified network associate", "arista ace", "data center", "routers", "switches", "firewalls", "load balancing", "dmz", "ddi", "networking technologies", "cabling", "lan", "wan", "routing protocols", "bgp", "ospf", "eigrp", "route subnetting", "route aggregation", "switching", "nexus product line", "spine and leaf architecture", "cisco aci", "arista clos", "business processes", "workflow design", "problem solving", "systems analysis", "root cause analysis", "effectiveness measurements", "technology trends", "market trends", "best practices", "methodologies."]}, "350077b572417b1d": {"terms": ["data engineer"], "salary_min": 35.34, "salary_max": 35.34, "title": "Azure Data Engineer (W2 only)", "company": "Elite Quests LLC", "desc": "Required Qualifications \n \u00b7 Bachelor\u2019s degree in a related field or relevant work experience. \n \u00b7 Minimum 3 years of experience using Azure Data Lake, Data Factory and/or Data Bricks. \n \u00b7 Minimum 3 years of experience working with SAP technologies such as Hana or BW. \n \u00b7 Minimum 3 years of experience working in an IT environment independently and in teams. \n \u00b7 Solid understanding and application of business concepts, procedures and practices. \n Preferred Qualifications \n \u00b7 Experience with DevOps Version Control and Storyboarding. \n \u00b7 Experience with data and reporting using data from ERP systems such as SAP. \n \u00b7 Experience with regulatory tools for document archiving and document control. \n \u00b7 Ability to perform in a regulated and/or validated environment. \n \u00b7 General knowledge of a variety of alternatives and their impact on business. \n \u00b7 Experience with other reporting tools such as Snowflake, BOBJ, Tableau \n Job Type: Contract \n Pay: $35.34 per hour \n Experience level: \n \n 3 years \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n Informatica: 1 year (Preferred) \n Data lake: 3 years (Required) \n Azure Data Lake: 3 years (Required) \n \n Work Location: Remote", "cleaned_desc": "Required Qualifications \n \u00b7 Bachelor\u2019s degree in a related field or relevant work experience. \n \u00b7 Minimum 3 years of experience using Azure Data Lake, Data Factory and/or Data Bricks. \n \u00b7 Minimum 3 years of experience working with SAP technologies such as Hana or BW. \n \u00b7 Minimum 3 years of experience working in an IT environment independently and in teams.   \u00b7 Solid understanding and application of business concepts, procedures and practices. \n Preferred Qualifications \n \u00b7 Experience with DevOps Version Control and Storyboarding. \n \u00b7 Experience with data and reporting using data from ERP systems such as SAP. \n \u00b7 Experience with regulatory tools for document archiving and document control. ", "techs": ["azure data lake", "data factory", "data bricks", "sap hana", "sap bw", "devops version control."]}, "f5777b4056e4e7e0": {"terms": ["data engineer"], "salary_min": 50.0, "salary_max": 58.0, "title": "Data Engineer (Only W2)", "company": "OTSI", "desc": "OTSI (Object Technology Solutions, Inc)  has an immediate opening  Senior Data Engineer  at  Overland Park, KS (Remote)  and it\u2019s a  Long Term Contract  position. \n This would be W2 position and consultant should go for F2F interview in Overland Park, KS location. (so please apply who are ready to work on W2 and go for a F2F interview) \n Job Description: \n \u00b7 7+ Year of experience as a Data Engineer with below skills \n \u00b7 Big Data, \n \u00b7 Spark, \n \u00b7 HIVE \n \u00b7 AWS \n \u00b7 Kubernetes \n \u00b7 Data Bricks \n About us: \n OTSI is a leading global technology company offering solutions, consulting, and managed services for businesses worldwide since 1999. OTSI serves clients from its 15 offices across 6 countries around the globe with a \u201cFollow-the-Sun\u201d model. Headquartered in Overland Park, Kansas, we have a strong presence in North America, Central America, and Asia-Pacific with a Global Delivery Center based in India. These strategic locations offer our customers the competitive advantages of onshore, nearshore, and offshore engagement and delivery options, with 24/7 support. OTSI works with 100+ enterprise customers, of which many are Fortune ranked, OTSI focuses on industry segments such as Banking, Financial Services & Insurance, Healthcare & Life Sciences, Energy & Utilities, Communications & Media Entertainment, Engineering & Telecom, Retail & Consumer Services, Hi-tech, Manufacturing, Engineering, transport logistics, Government, Defense & PSUs. \n Our Center of Excellence: \n \u00b7 Data & Analytics \n \u00b7 Digital Transformation \n \u00b7 QA & Automation \n \u00b7 Enterprise Applications \n \u00b7 Disruptive Technologies \n Job Type: Contract \n Pay: $50.00 - $58.00 per hour \n Experience level: \n \n 7 years \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Experience: \n \n Data Engineer: 7 years (Preferred) \n Spark: 5 years (Preferred) \n AWS: 5 years (Preferred) \n DATA BRICKS: 5 years (Preferred) \n Kubernetes: 5 years (Preferred) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "0f792dda1b295e27": {"terms": ["data engineer"], "salary_min": 129985.65, "salary_max": 164590.8, "title": "Senior Data Engineer (Remote) (12 Month Contract)", "company": "Lucayan Technology Solutions", "desc": "Description \n  A minimum of 10 years experience in Data Engineering.\n   A minimum of 4 years in Azure.\n   Must have excellent communication skills.\n   We are looking for a talented and experienced Azure Data Engineer with expertise in Azure Databricks, Azure Synapse Analytics, Azure Data Factory, RDBMS, and NoSQL databases. The ideal candidate will play a crucial role in designing, implementing, and optimizing data solutions on the Azure platform to support our data-driven initiatives.\n  \n \n Key Responsibilities: \n  Data Pipeline Development: Design, develop, and maintain data pipelines using Azure Data Factory and Azure Databricks/Spark to efficiently extract, transform, and load (ETL) data from various sources into data lakes and data warehouses.\n   Data Modeling: Create and manage data models and schemas within Azure Synapse Analytics, NoSQL (Cosmos, MongoDB) to ensure data accuracy, performance, and scalability.\n   Data Integration: Collaborate with cross-functional teams to integrate data from diverse sources, including RDBMS (e.g., Oracle, SQL Server) and NoSQL databases (e.g., MongoDB, Cosmos DB).\n   Data Migration : Lead data migration projects, including data extraction, transformation, and loading (ETL), from on-premises systems and other cloud platforms to Azure. Ensure data quality, accuracy, and consistency throughout the migration process.\n   Data Quality and Profiling: Implement data quality checks, Data Profiling and Cleansing to maintain data integrity, security, and compliance with industry standards and regulations.\n  \n \n Qualifications: \n  Bachelor's degree in Computer Science, Information Technology, or a related field. Master's degree preferred.\n   Proven experience as a data engineer with a strong focus on Azure data services.\n   Proficiency in Azure Databricks/Spark, Azure Synapse Analytics, Azure Data Factory, and other Azure data-related tools.\n   Strong SQL skills and experience with data modeling in both RDBMS and NoSQL databases.\n   Familiarity with data warehousing concepts and best practices.\n   Knowledge of data governance, security, and compliance standards.\n   Programming skills in languages such as Python and Microservices (Python) is desired.\n   Excellent problem-solving and communication skills.\n   Strong Databricks experience in AWS/GCP experience can also be considered.\n   Ability to work independently and collaboratively within a team environment. \n  \n  Education:  Bachelors Degree", "cleaned_desc": "Description \n  A minimum of 10 years experience in Data Engineering.\n   A minimum of 4 years in Azure.\n   Must have excellent communication skills.\n   We are looking for a talented and experienced Azure Data Engineer with expertise in Azure Databricks, Azure Synapse Analytics, Azure Data Factory, RDBMS, and NoSQL databases. The ideal candidate will play a crucial role in designing, implementing, and optimizing data solutions on the Azure platform to support our data-driven initiatives.   \n \n Key Responsibilities: \n  Data Pipeline Development: Design, develop, and maintain data pipelines using Azure Data Factory and Azure Databricks/Spark to efficiently extract, transform, and load (ETL) data from various sources into data lakes and data warehouses.\n   Data Modeling: Create and manage data models and schemas within Azure Synapse Analytics, NoSQL (Cosmos, MongoDB) to ensure data accuracy, performance, and scalability.    Data Integration: Collaborate with cross-functional teams to integrate data from diverse sources, including RDBMS (e.g., Oracle, SQL Server) and NoSQL databases (e.g., MongoDB, Cosmos DB).\n   Data Migration : Lead data migration projects, including data extraction, transformation, and loading (ETL), from on-premises systems and other cloud platforms to Azure. Ensure data quality, accuracy, and consistency throughout the migration process.\n   Data Quality and Profiling: Implement data quality checks, Data Profiling and Cleansing to maintain data integrity, security, and compliance with industry standards and regulations.\n  \n   Qualifications: \n  Bachelor's degree in Computer Science, Information Technology, or a related field. Master's degree preferred.\n   Proven experience as a data engineer with a strong focus on Azure data services.\n   Proficiency in Azure Databricks/Spark, Azure Synapse Analytics, Azure Data Factory, and other Azure data-related tools.\n   Strong SQL skills and experience with data modeling in both RDBMS and NoSQL databases.    Familiarity with data warehousing concepts and best practices.\n   Knowledge of data governance, security, and compliance standards.\n   Programming skills in languages such as Python and Microservices (Python) is desired.\n   Excellent problem-solving and communication skills.\n   Strong Databricks experience in AWS/GCP experience can also be considered.", "techs": ["azure data factory", "azure databricks", "azure synapse analytics", "rdbms", "nosql databases", "oracle", "sql server", "mongodb", "cosmos db", "data profiling", "data cleansing", "python", "microservices"]}, "34d9149b4a61c486": {"terms": ["data engineer"], "salary_min": 55.0, "salary_max": 60.0, "title": "Sr Data Engineer - Only W2", "company": "MST Solutions", "desc": "Role/Responsibilities \n \n Support transition of media data from RAPP (current vendor) \n Hands on technical role working with data and providing expertise on how best to transition data \n ETL, Python, AWS, SQL \n \n Top 3-5 Skills \n ETL \n AWS \u2013 Apache Airflow, Kafka, Streaming Data, etc. \n Python \n SQL \u2013 Validate data policy checks \n Modeling experience is a plus \n Job Requirements: \n Desired soft skills \n \n Hands on \n Flexible, must be able to attend meetings \n Good verbal and written communication as they will have to give their recommendations on data transfer to leadership team \n This will be a high visibility role \n \n Job Type: Contract \n Salary: $55.00 - $60.00 per hour \n Experience: \n \n ETL: 1 year (Preferred) \n AWS: 1 year (Preferred) \n Redshift: 1 year (Preferred) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "226571fd23411b51": {"terms": ["data engineer"], "salary_min": 184700.0, "salary_max": 323300.0, "title": "Senior Staff Data and Services Software Engineer", "company": "ServiceNow", "desc": "Company Description \n  At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can\u2019t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you. \n With more than 7,700+ customers, we serve approximately 85% of the Fortune 500\u00ae, and we're proud to be one of FORTUNE 100 Best Companies to Work For\u00ae and World's Most Admired Companies\u2122. \n Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow. \n Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates. \n  Job Description \n  As a Senior Staff Data and Software Engineer, you will be responsible for developing and implementing cutting-edge technical solutions that align with our organization's business objectives. You will work closely with stakeholders to understand their needs, assess existing systems and infrastructure, and design robust and scalable data and mircroservices solutions that drive innovation and efficiency. Your role will require a combination of technical expertise, strategic thinking, and effective communication to bridge the gap between business and technology. \n \n  Key Responsibilities: \n \n  Solution Design:  Collaborate with business leaders, project managers, and technical teams to understand requirements and design holistic technical solutions that address current and future needs. \n  Architecture Planning:  Develop and maintain technology roadmaps, ensuring alignment with organizational goals and industry best practices. \n  Technical Leadership:  Provide technical leadership and guidance to development teams, ensuring adherence to architectural standards and best practices. \n  Risk Assessment:  Identify and evaluate technical risks and propose mitigation strategies to ensure project success and data security. \n  Documentation:  Create and maintain comprehensive architecture documentation, including diagrams, guidelines, and standards for development teams to follow. \n  Vendor Evaluation:  Assess and recommend third-party tools, products, and services that can enhance our technical solutions. \n  Prototyping:  Develop proof-of-concept and prototype solutions to validate architectural decisions and demonstrate feasibility. \n  Performance Optimization:  Continuously monitor and analyze system performance, identifying areas for improvement and optimizing existing solutions. \n  Security and Compliance:  Ensure that solutions comply with industry regulations and security standards, and proactively address security vulnerabilities. \n  Collaboration:  Foster collaboration and effective communication between cross-functional teams, promoting a culture of innovation and excellence. \n \n \n  Qualifications \n  Qualifications: \n \n  Bachelor's degree in Computer Science, Information Technology, or related field (Master's degree preferred). \n  Proven experience as a Lead Engineer and Solution Architect or a similar role. \n  Strong knowledge of enterprise architecture principles and best practices. \n  Proficiency in designing and implementing solutions using various technologies and platforms. \n  Excellent problem-solving and analytical skills. \n  Outstanding communication and interpersonal abilities. \n  Project management skills and experience in managing complex technical projects. \n  Certification in relevant technologies or architecture frameworks (e.g., TOGAF, AWS Certified Solutions Architect, Microsoft Certified: Azure Solutions Architect Expert) is a plus. \n \n  Preferred Skills: \n \n  Cloud computing expertise (e.g., AWS, Azure, Google Cloud Platform). \n  Knowledge of DevOps practices and tools. \n  Familiarity with microservices architecture, expertise a plus. \n  Familiarity with graph databases, expertise a plus. \n  Experience with containerization and orchestration technologies (e.g., Docker, Kubernetes). \n  Strong understanding of data architecture and database technologies. \n  Knowledge of cybersecurity best practices. \n  Excellent presentation and facilitation skills. \n \n  #DTjobs \n  For positions in the Bay Area, we offer a base pay of $184,700 - $323,300, plus equity (when applicable), variable/incentive compensation and benefits. Sales positions generally offer a competitive On Target Earnings (OTE) incentive compensation structure. Please note that the base pay shown is a guideline, and individual total compensation will vary based on factors such as qualifications, skill level, competencies and work location. We also offer health plans, including flexible spending accounts, a 401(k) Plan with company match, ESPP, matching donations, a flexible time away plan and family leave programs (subject to eligibility requirements). Compensation is based on the geographic location in which the role is located, and is subject to change based on work location. \n  Additional Information \n  ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law. \n At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office. \n If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance. \n For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government. \n Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site. \n   \n From Fortune. \u00a9 2022 Fortune Media IP Limited All rights reserved. Used under license. \n Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.", "cleaned_desc": "  Qualifications \n  Qualifications: \n \n  Bachelor's degree in Computer Science, Information Technology, or related field (Master's degree preferred). \n  Proven experience as a Lead Engineer and Solution Architect or a similar role. \n  Strong knowledge of enterprise architecture principles and best practices. \n  Proficiency in designing and implementing solutions using various technologies and platforms. \n  Excellent problem-solving and analytical skills. \n  Outstanding communication and interpersonal abilities. \n  Project management skills and experience in managing complex technical projects. \n  Certification in relevant technologies or architecture frameworks (e.g., TOGAF, AWS Certified Solutions Architect, Microsoft Certified: Azure Solutions Architect Expert) is a plus.   \n  Preferred Skills: \n \n  Cloud computing expertise (e.g., AWS, Azure, Google Cloud Platform). \n  Knowledge of DevOps practices and tools. \n  Familiarity with microservices architecture, expertise a plus. \n  Familiarity with graph databases, expertise a plus. \n  Experience with containerization and orchestration technologies (e.g., Docker, Kubernetes). \n  Strong understanding of data architecture and database technologies. \n  Knowledge of cybersecurity best practices. \n  Excellent presentation and facilitation skills. ", "techs": ["aws", "azure", "google cloud platform", "devops practices and tools", "microservices architecture", "graph databases", "docker", "kubernetes", "data architecture and database technologies", "cybersecurity best practices"]}, "227119efc149cadc": {"terms": ["data engineer"], "salary_min": 105408.0, "salary_max": 209352.0, "title": "Lead Data Engineer (Remote)", "company": "CareFirst BlueCross BlueShield", "desc": "Resp & Qualifications   \n PURPOSE:   The Lead Data Engineer is responsible for orchestrating, deploying, maintaining and scaling cloud OR on-premise infrastructure targeting big data and platform data management (Relational and NoSQL, distributed and converged) with emphasis on reliability, automation and performance. This role will focus on leading the development of solutions and helping transform the company's platforms deliver data-driven, meaningful insights and value to company.     ESSENTIAL FUNCTIONS: \n \n  Lead the team to design, configure, implement, monitor, and manage all aspects of Data Integration Framework. Defines and develop the Data Integration best practices for the data management environment of optimal performance and reliability. \n  Develops and maintains infrastructure systems (e.g., data warehouses, data lakes) including data access APIs. Prepares and manipulates data using Informatica, Snowflake, and Azure SQL. \n  Provides detailed guidance and performs work related to Modeling Data Warehouse solutions in the cloud OR on-premise. Understands Dimensional Modeling, De-normalized Data Structures, OLAP, and Data Warehousing concepts. \n  Oversees the delivery of engineering data initiatives and projects. Supports long term data initiatives as well as Ad-Hoc analysis and ELT/ETL activities. Creates data collection frameworks for structured and unstructured data. Applies data extraction, transformation and loading techniques in order to connect large data sets from a variety of sources. \n  Enforces the implementation of best practices for data auditing, scalability, reliability and application performance. Develop and apply data extraction, transformation and loading techniques in order to connect large data sets from a variety of sources. \n  Interprets data, analyzes results using statistical techniques, and provides ongoing reports. Executes quantitative analyses that translate data into actionable insights. Provides analytical and data-driven decision-making support for key projects. Designs, manages, and conducts quality control procedures for data sets using data from multiple systems. \n  Improves data delivery engineering job knowledge by attending educational workshops; reviewing professional publications; establishing personal networks; benchmarking state-of-the-art practices; participating in professional societies. \n \n  SUPERVISORY RESPONSIBILITY:  Position does not have direct reports but is expected to assist in guiding and mentoring less experienced staff. May lead a team of matrixed resources.     QUALIFICATIONS:     Education Level:  Bachelor's Degree in Computer Science, Information Technology or Engineering or related field OR in lieu of a Bachelor's degree, an additional 4 years of relevant work experience is required in addition to the required work experience.     Experience:  8 years Experience in leading data engineering and cross functional team to implement scalable and fine tuned ETL/ELT solutions for optimal performance. Experience developing and updating ETL/ELT scripts. Hands-on experience with application development, relational database layout, development, data modeling.     Knowledge, Skills and Abilities (KSAs) \n \n  Knowledge and understanding of Informatica including Cloud version (IICS). \n  Knowledge and understanding of Cloud Platforms (ie. Azure). \n  Knowledge and understanding of Cloud Databases (ie. Snowflake, Azure SQL). \n  Knowledge and understanding of at least one programming language (i.e., SQL, NoSQL, Python). \n  Knowledge and understanding of database design and implementation concepts. \n  Knowledge and understanding of data exchange formats. \n  Knowledge and understanding of data movement concepts. \n  Strong technical and analytical and problem solving skills to troubleshoot to solve a variety of problems. \n  Requires strong organizational and communication skills, written and verbal, with the ability to handle multiple priorities. \n  Able to effectively provide direction to and lead technical teams.  Must be able to meet established deadlines and handle multiple customer service demands from internal and external customers, within set expectations for service excellence. Must be able to effectively communicate and provide positive customer service to every internal and external customer, including customers who may be demanding or otherwise challenging. \n  \n   Salary Range:  $105,408 - $209,352   \n Salary Range Disclaimer   \n The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the work is being performed. This compensation range is specific and considers factors such as (but not limited to) the scope and responsibilites of the position, the candidate's work experience, education/training, internal peer equity, and market and business consideration. It is not typical for an individual to be hired at the top of the range, as compensation decisions depend on each case's facts and circumstances, including but not limited to experience, internal equity, and location. In addition to your compensation, CareFirst offers a comprehensive benefits package, various incentive programs/plans, and 401k contribution programs/plans (all benefits/incentives are subject to eligibility requirements). \n  Department   \n Department:  ODS/ETL Members \n  Equal Employment Opportunity   \n CareFirst BlueCross BlueShield is an Equal Opportunity (EEO) employer. It is the policy of the Company to provide equal employment opportunities to all qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, protected veteran or disabled status, or genetic information. \n  Where To Apply   \n Please visit our website to apply: www.carefirst.com/careers \n  Federal Disc/Physical Demand   \n Note: The incumbent is required to immediately disclose any debarment, exclusion, or other event that makes him/her ineligible to perform work directly or indirectly on Federal health care programs. \n  PHYSICAL DEMANDS: \n  The associate is primarily seated while performing the duties of the position. Occasional walking or standing is required. The hands are regularly used to write, type, key and handle or feel small controls and objects. The associate must frequently talk and hear. Weights up to 25 pounds are occasionally lifted. \n  Sponsorship in US   \n Must be eligible to work in the U.S. without Sponsorship \n  #LI-LD1", "cleaned_desc": "Resp & Qualifications   \n PURPOSE:   The Lead Data Engineer is responsible for orchestrating, deploying, maintaining and scaling cloud OR on-premise infrastructure targeting big data and platform data management (Relational and NoSQL, distributed and converged) with emphasis on reliability, automation and performance. This role will focus on leading the development of solutions and helping transform the company's platforms deliver data-driven, meaningful insights and value to company.     ESSENTIAL FUNCTIONS: \n \n  Lead the team to design, configure, implement, monitor, and manage all aspects of Data Integration Framework. Defines and develop the Data Integration best practices for the data management environment of optimal performance and reliability. \n  Develops and maintains infrastructure systems (e.g., data warehouses, data lakes) including data access APIs. Prepares and manipulates data using Informatica, Snowflake, and Azure SQL. \n  Provides detailed guidance and performs work related to Modeling Data Warehouse solutions in the cloud OR on-premise. Understands Dimensional Modeling, De-normalized Data Structures, OLAP, and Data Warehousing concepts. \n  Oversees the delivery of engineering data initiatives and projects. Supports long term data initiatives as well as Ad-Hoc analysis and ELT/ETL activities. Creates data collection frameworks for structured and unstructured data. Applies data extraction, transformation and loading techniques in order to connect large data sets from a variety of sources.    Enforces the implementation of best practices for data auditing, scalability, reliability and application performance. Develop and apply data extraction, transformation and loading techniques in order to connect large data sets from a variety of sources. \n  Interprets data, analyzes results using statistical techniques, and provides ongoing reports. Executes quantitative analyses that translate data into actionable insights. Provides analytical and data-driven decision-making support for key projects. Designs, manages, and conducts quality control procedures for data sets using data from multiple systems. \n  Improves data delivery engineering job knowledge by attending educational workshops; reviewing professional publications; establishing personal networks; benchmarking state-of-the-art practices; participating in professional societies. \n \n  SUPERVISORY RESPONSIBILITY:  Position does not have direct reports but is expected to assist in guiding and mentoring less experienced staff. May lead a team of matrixed resources.     QUALIFICATIONS:     Education Level:  Bachelor's Degree in Computer Science, Information Technology or Engineering or related field OR in lieu of a Bachelor's degree, an additional 4 years of relevant work experience is required in addition to the required work experience.     Experience:  8 years Experience in leading data engineering and cross functional team to implement scalable and fine tuned ETL/ELT solutions for optimal performance. Experience developing and updating ETL/ELT scripts. Hands-on experience with application development, relational database layout, development, data modeling.     Knowledge, Skills and Abilities (KSAs) \n \n  Knowledge and understanding of Informatica including Cloud version (IICS).    Knowledge and understanding of Cloud Platforms (ie. Azure). \n  Knowledge and understanding of Cloud Databases (ie. Snowflake, Azure SQL). \n  Knowledge and understanding of at least one programming language (i.e., SQL, NoSQL, Python). \n  Knowledge and understanding of database design and implementation concepts. \n  Knowledge and understanding of data exchange formats. \n  Knowledge and understanding of data movement concepts. \n  Strong technical and analytical and problem solving skills to troubleshoot to solve a variety of problems. ", "techs": ["informatica", "snowflake", "azure sql", "sql", "nosql", "python"]}, "53f6056d9cfd3d9f": {"terms": ["data engineer"], "salary_min": 168898.58, "salary_max": 213863.23, "title": "Principal Engineer - Master Data Management", "company": "Verizon", "desc": "When you join Verizon \n  Verizon is one of the world\u2019s leading providers of technology and communications services, transforming the way we connect around the world. We\u2019re a human network that reaches across the globe and works behind the scenes. We anticipate, lead, and believe that listening is where learning begins. In crisis and in celebration, we come together\u2014lifting up our communities and striving to make an impact to move the world forward. If you\u2019re fueled by purpose, and powered by persistence, explore a career with us. Here, you\u2019ll discover the rigor it takes to make a difference and the fulfillment that comes with living the #NetworkLife. \n \n  What you\u2019ll be doing... \n \n  Are you ready for the challenge of driving transformation at the scale of a $130B+ Fortune 50 company through an industry leading technology stack? \n \n  In this role, you will be responsible for Technical Product Management for Verizon\u2019s Corporate end to end master data management capabilities, focused on building a robust human centered experience spanning across the Supply Chain, Finance, and HR data domains. Trusted data starts with complete, accurate and valid master data. Your work will focus on shaping human centered end to end processes from identification of the need for new master data, through to its request and eventual creation / maintenance including full accountability for product vision & strategy, roadmap and backlogs around key mission objectives, delivering features from concept to launch through agile delivery methodologies, ensuring value realization, run governance and support that delivers outstanding business results / user experience. Partnership is essential in this role, as we focus on shaping a federated data strategy that requires the definition of data standards in partnership with various GPOs within the Finance, Supply Chain and HR domains, collaboration in the establishment of data catalogs that enable end users to leverage plain business language to query their data, and connectivity with owners of commercial and other non-corporate data to which the corporate functions will subscribe. \n \n  The ideal candidate for this role will be equal parts technical and functional leader to be successful, with the ability to set rigorous technical / architectural standards whilst speaking the language of our business partners to influence the strategic direction, master data and governance capabilities. Focusing on driving the innovation agenda, this leader will work with internal & external industry leaders to shape world-class capabilities and enable continuous improvement. \n \n  This Principal Engineer will drive the MDM strategy with other MDM SME\u2019s, Analysts and 3rd party partners, as well as influence Global Process Owners to deliver transformative solutions. \n \n  Responsibilities   \n \n Collaborating with cross-functional teams to define and enforce data governance policies, standards, and best practices within Oracle EDMCS and SAP MDG. \n  Utilizing your deep knowledge of Oracle EDMCS and SAP MDG to configure and maintain workflows, and validation rules. \n  Being proficient in Google Cloud Platform (GCP) services and tools, including BigQuery, Dataflow, Dataproc, and Pub/Sub. \n  Working closely with IT and Business teams to ensure seamless data integration between Oracle EDMCS, SAP MDG, and other enterprise systems. \n  Developing and maintaining data mapping and transformation rules to ensure data consistency and compliance. \n  Collaborating with data stewards and business users to resolve data-related issues and support data maintenance activities as well as own function design fo the end to end master data lifecycle mgmt \n  Creating and maintaining comprehensive documentation for data management processes, configurations, and standard operating procedures. \n \n \n  What we\u2019re looking for...    You\u2019ll need to have: \n \n  Bachelor\u2019s degree or four or more years of work experience. \n  Six or more years of relevant work experience \n  Experience with Oracle EDMCS/DRM and SAP MDG. \n  Experience in managing or executing data cleansing, data mapping, and data governance areas, preferably in an SAP environment as well as integration across complex ERP landscapes. \n  Experience of interfacing SAP with legacy and modern data ecosystems. \n  Experience in data modeling, data mapping, and data transformation. \n  Experience in data governance, data quality management, and MDM concepts. \n \n \n  Even better if you have one or more of the following: \n \n  SAP MDG or Oracle EDMCS certification is a plus. \n  Working knowledge of SAP finance modules. \n  Experience with Collibra workflows and master data modules. \n  Experience in successful delivery of scaled agile. \n  Scripting and programming skills in languages like Python, Java, or Scala. \n  Experience as a Data Engineer or similar role with a focus on GCP. Strong knowledge of cloud-based data storage solutions, such as Cloud Storage, Cloud SQL, and Bigtable. \n  Knowledge of data privacy regulations and compliance standards (e.g., GDPR, CCPA). \n \n \n  If Verizon and this role sound like a fit for you, we encourage you to apply even if you don\u2019t meet every \u201ceven better\u201d qualification listed above.    This role may be considered as part of the Department of Defense SkillBridge Program. \n \n \n \n \n \n \n \n \n  Where you\u2019ll be working \n \n \n \n \n \n \n  In this hybrid role, you'll have a defined work location that includes work from home and assigned office days set by your manager.\n  \n  Scheduled Weekly Hours  40\n  \n  Equal Employment Opportunity \n  We\u2019re proud to be an equal opportunity employer - and celebrate our employees\u2019 differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. At Verizon, we know that diversity makes us stronger. We are committed to a collaborative, inclusive environment that encourages authenticity and fosters a sense of belonging. We strive for everyone to feel valued, connected, and empowered to reach their potential and contribute their best. Check out our diversity and inclusion page to learn more.", "cleaned_desc": "  Responsibilities   \n \n Collaborating with cross-functional teams to define and enforce data governance policies, standards, and best practices within Oracle EDMCS and SAP MDG. \n  Utilizing your deep knowledge of Oracle EDMCS and SAP MDG to configure and maintain workflows, and validation rules. \n  Being proficient in Google Cloud Platform (GCP) services and tools, including BigQuery, Dataflow, Dataproc, and Pub/Sub. \n  Working closely with IT and Business teams to ensure seamless data integration between Oracle EDMCS, SAP MDG, and other enterprise systems. \n  Developing and maintaining data mapping and transformation rules to ensure data consistency and compliance. \n  Collaborating with data stewards and business users to resolve data-related issues and support data maintenance activities as well as own function design fo the end to end master data lifecycle mgmt \n  Creating and maintaining comprehensive documentation for data management processes, configurations, and standard operating procedures. \n \n \n  What we\u2019re looking for...    You\u2019ll need to have: \n    Bachelor\u2019s degree or four or more years of work experience. \n  Six or more years of relevant work experience \n  Experience with Oracle EDMCS/DRM and SAP MDG. \n  Experience in managing or executing data cleansing, data mapping, and data governance areas, preferably in an SAP environment as well as integration across complex ERP landscapes. \n  Experience of interfacing SAP with legacy and modern data ecosystems. \n  Experience in data modeling, data mapping, and data transformation. \n  Experience in data governance, data quality management, and MDM concepts. \n \n \n  Even better if you have one or more of the following: \n \n  SAP MDG or Oracle EDMCS certification is a plus. \n  Working knowledge of SAP finance modules.    Experience with Collibra workflows and master data modules. \n  Experience in successful delivery of scaled agile. \n  Scripting and programming skills in languages like Python, Java, or Scala. \n  Experience as a Data Engineer or similar role with a focus on GCP. Strong knowledge of cloud-based data storage solutions, such as Cloud Storage, Cloud SQL, and Bigtable. \n  Knowledge of data privacy regulations and compliance standards (e.g., GDPR, CCPA). \n \n \n  If Verizon and this role sound like a fit for you, we encourage you to apply even if you don\u2019t meet every \u201ceven better\u201d qualification listed above.    This role may be considered as part of the Department of Defense SkillBridge Program. \n \n \n \n \n ", "techs": ["oracle edmcs", "sap mdg", "google cloud platform (gcp)", "bigquery", "dataflow", "dataproc", "pub/sub", "collibra", "python", "java", "scala", "cloud storage", "cloud sql", "bigtable"]}, "bcb3fa3a95822e7e": {"terms": ["data engineer"], "salary_min": 93300.0, "salary_max": 212000.0, "title": "Azure Data Engineer, Lead", "company": "Booz Allen Hamilton", "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Springfield,VA,US \n         \n \n \n \n         Remote Work: \n         \n \n         Yes \n         \n \n \n \n         Job Number: \n         \n \n         R0182529\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Azure Data Engineer, Lead\n           The Opportunity: \n  The DHS Cube program is seeking an experienced Data Engineer for its data management, data integration, and business intelligence program. This high-visibility mission support data program is managed within Headquarters for the DHS and our numerous client stakeholders. Over the next year and beyond, this program will be looking to take on new challenges, including modernizing their business intelligence technologies through a move to cloud services, improving the data quality through the development of confidence scorecards, and development of a data governance or data standards prototype. \n \n  As part of this role, our Azure ETL Engineer will be responsible for moving ETL pipelines from one framework to a new framework. The role will also perform ETL testing and troubleshooting, including testing the unit data models, system performance testing, uploading, downloading, or querying speed tests, and data flow validations. In this role, you will also be building repeatable documentation assets to enable implementation teams to take advantage of pre-built assets, identifying data storage requirements, determining the storage needs of the customer, and ongoing development of a repository of ETL knowledge and utilizing that to enhance the quality, speed, and productivity of the team. As a senior member of the team, you\u2019ll also be supporting more mid-level engineers with the testing and QA of their code along with an expectation of enhanced code velocity, design thinking, and the ability to work independently and provide feedback to the Data Architect on required design updates throughout the process. \n \n  Join us. The world can\u2019t wait. \n \n  You Have:  \n \n 8+ years of experience in a role encompassing industry standard ETL development techniques \n  8+ years of experience with data integration, and database technologies, including Oracle, Postgres, Cosmos, or SQL \n  3+ years of experience with Azure Cloud SaaS solutions and managed services serverless technologies, including Azure Data Factory, Synapse Analytics, Logic Apps, or ADLS \n  Experience with scripting and basic programming, including JavaScript, shell script, or Python \n  Experience with data analysis and profiling of source data while developing or building robust ETL processes \n  Knowledge of disparate data sources and targets \n  Knowledge of data validation, cleansing, transformation, consolidation, de-duplication, aggregation, de-aggregation, and enrichment \n  Knowledge of API development and testing \n  DHS Suitability \n  Bachelor\u2019s degree \n \n \n  Nice If You Have: \n \n  Experience with Agile and Scrum methodologies \n  Experience with Azure Platform CI/CD or DevOps \n  Experience with reporting tools, including Tableau or Power BI \n  Experience with industry standard ETL tools such as SQL, scripting languages, data modelling techniques, or relational and NoSQL database engineering and configuration, including document store, Azure Cosmos, or AWS DynamoDB \n  Knowledge of data transactional requirements, business logic pertaining to commit and rollback cycles, and how to implement to preserve the integrity of related data elements in government, financial and similar systems \n  Ability to build ETL processes that apply to data migration and data integration scenarios to know their key differences \n  Ability to adapt to a rapidly changing product and respond strategically to client needs \n  Ability to balance multiple efforts simultaneously and meet strict deadlines \n  Ability to have a desire for learning and development, and a passion for exploratory analysis or exploratory learning \n \n \n  Vetting:  \n Applicants selected will be subject to a government investigation and may need to meet eligibility requirements of the U.S. government client; DHS suitability is required. \n \n  Create Your Career: \n \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll develop your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $93,300.00 to $212,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.", "cleaned_desc": " \n \n \n \n \n \n         Azure Data Engineer, Lead\n           The Opportunity: \n  The DHS Cube program is seeking an experienced Data Engineer for its data management, data integration, and business intelligence program. This high-visibility mission support data program is managed within Headquarters for the DHS and our numerous client stakeholders. Over the next year and beyond, this program will be looking to take on new challenges, including modernizing their business intelligence technologies through a move to cloud services, improving the data quality through the development of confidence scorecards, and development of a data governance or data standards prototype. \n \n  As part of this role, our Azure ETL Engineer will be responsible for moving ETL pipelines from one framework to a new framework. The role will also perform ETL testing and troubleshooting, including testing the unit data models, system performance testing, uploading, downloading, or querying speed tests, and data flow validations. In this role, you will also be building repeatable documentation assets to enable implementation teams to take advantage of pre-built assets, identifying data storage requirements, determining the storage needs of the customer, and ongoing development of a repository of ETL knowledge and utilizing that to enhance the quality, speed, and productivity of the team. As a senior member of the team, you\u2019ll also be supporting more mid-level engineers with the testing and QA of their code along with an expectation of enhanced code velocity, design thinking, and the ability to work independently and provide feedback to the Data Architect on required design updates throughout the process. \n \n  Join us. The world can\u2019t wait. \n \n  You Have:  \n \n 8+ years of experience in a role encompassing industry standard ETL development techniques \n  8+ years of experience with data integration, and database technologies, including Oracle, Postgres, Cosmos, or SQL \n  3+ years of experience with Azure Cloud SaaS solutions and managed services serverless technologies, including Azure Data Factory, Synapse Analytics, Logic Apps, or ADLS \n  Experience with scripting and basic programming, including JavaScript, shell script, or Python \n  Experience with data analysis and profiling of source data while developing or building robust ETL processes \n  Knowledge of disparate data sources and targets    Knowledge of data validation, cleansing, transformation, consolidation, de-duplication, aggregation, de-aggregation, and enrichment \n  Knowledge of API development and testing \n  DHS Suitability \n  Bachelor\u2019s degree \n \n \n  Nice If You Have: \n \n  Experience with Agile and Scrum methodologies \n  Experience with Azure Platform CI/CD or DevOps \n  Experience with reporting tools, including Tableau or Power BI \n  Experience with industry standard ETL tools such as SQL, scripting languages, data modelling techniques, or relational and NoSQL database engineering and configuration, including document store, Azure Cosmos, or AWS DynamoDB \n  Knowledge of data transactional requirements, business logic pertaining to commit and rollback cycles, and how to implement to preserve the integrity of related data elements in government, financial and similar systems \n  Ability to build ETL processes that apply to data migration and data integration scenarios to know their key differences \n  Ability to adapt to a rapidly changing product and respond strategically to client needs \n  Ability to balance multiple efforts simultaneously and meet strict deadlines \n  Ability to have a desire for learning and development, and a passion for exploratory analysis or exploratory learning \n \n \n  Vetting:  \n Applicants selected will be subject to a government investigation and may need to meet eligibility requirements of the U.S. government client; DHS suitability is required. \n ", "techs": ["azure data factory", "synapse analytics", "logic apps", "adls", "javascript", "shell script", "python", "tableau", "power bi", "sql", "azure cosmos", "aws dynamodb"]}, "0d55a4ef42556841": {"terms": ["data engineer", "machine learning engineer"], "salary_min": 105789.85, "salary_max": 133953.53, "title": "TSS Data Engineer", "company": "General Dynamics Information Technology", "desc": "TSS Data Engineer \n \n  GDIT is seeking a Data Engineer to support its Technology Shared Services (TSS) Data and Analytics organization. Deliver insights to help our clients turn data into action as a Data Engineer at GDIT. Your work will provide transformative solutions to our clients' big-data obstacles and help advance the mission. Here, you can make a meaningful impact on our clients' mission and on your career.\n  \n  GDIT is your place. You make it your own. Bring your creativity to help us find simple solutions to complex problems. By owning your opportunity at GDIT, you'll play an essential part in preparing our nation for the future. At GDIT, our employees are driven, resourceful, and unwavering.\n  \n \n HOW A DATA ENGINEER WILL MAKE AN IMPACT \n \n \n  Responsible for data migrations, data modeling, and creating schema. \n  Provides expert-level design and development of relational databases. \n  Designs, implements, and maintains data pipelines to perform extract, transform, and load (ETL) data from sources to destinations. \n  Builds and manages cloud-native data architectures in AWS and Azure. \n  Identifies and directs information needs and elements, data relationships and attributes, data flow and storage requirements, and data output and reporting capabilities. \n  Leads new data development ensuring consistency and integration with existing data warehouse structure. \n  Reviews business requests for data and data usage, researches data sources for new and better data feeds. \n  Maintains comprehensive documentation on data processes, pipelines, and architecture for knowledge sharing and collaboration. \n  Leads continuous improvement efforts in enhancing performance and providing increased functionality, including performing proactive maintenance such as ensuring continued space availability, monitoring activity, and documenting problems, changes, and solutions. \n  Assignments may include design of data dictionaries, database structure and layout, installing, upgrading, and managing database applications. \n  Presents insights to both technical and non-technical team members and stakeholders, assisting in making informed, data-driven decisions. \n  Collaborates with different teams to understand their data needs and create solutions that solve problems and streamline workflows. \n \n \n  GDIT is committed to fostering economic growth and prosperity in Louisiana, with established operations in multiple locations throughout the state, including facilities in New Orleans, Natchitoches, and our Integrated Technology Center in Bossier City, LA. This position offers the flexibility to work 100% remotely from anywhere within the state of Louisiana.  \n \n \n WHAT YOU'LL NEED TO SUCCEED \n \n Education:  \n \n \n BA/BS (or equivalent years of experience) \n \n \n  Required Experience :\n  \n \n  2+ years of relevant experience \n \n \n  Required Skills and Abilities: \n \n \n  Experienced in AWS and Azure cloud environments. \n  Proficient in Python to perform data analysis and engineering tasks. \n  Experienced in working in AWS with AWS data and analytics services, such as RDS, DynamoDB, Redshift, Aurora, S3, and Database Migration Service (DMS). \n  Proficient in database administration and Structured Query Language (SQL). \n  Experienced in data modeling and data normalization techniques. \n  Experienced in different data structures, including relational databases, semi-structured, and object stores. \n  Experienced in database migrations, including homogenous and heterogenous and on-prem and cloud. \n  Excellent communication and presentation skills with the ability to present complex data insights to both technical and non-technical audiences. \n  Good team player, able to manage multiple assignments, and adapt to changing client needs. \n  Skilled in programming languages like Python, R, SQL, and experience in working with data visualization tools like Tableau and Power BI. \n \n \n  Preferred Skills and Abilities: \n \n \n  AWS Certified Solutions Architect Associate \n  Azure Fundamentals \n  Azure Data Fundamentals \n  Secret clearance or ability to obtain \n  Knowledge of ITIL framework \n  Knowledge of Agile methodology \n  Demonstrated experience consulting with internal and external customers to understand business needs and make recommendations. \n  Previous experience in the defense or government sector \n  Familiarity with cloud services: AWS, Google Cloud, Microsoft Azure, etc.) and big data tools is plus. \n  Experience in optimization algorithms and natural language processing is a plus. \n  Data science and cloud certifications are a plus (Certified Data Scientist (CDS), AWS Certified Machine Learning - Specialty, Microsoft Certified: Azure Data Scientist Associate, IBM Data Science Professional) \n \n  GDIT IS YOUR PLACE:\n  \n \n Full-flex work week to own your priorities at work and at home** (remove if not eligible)** \n 401K with company match \n Comprehensive health and wellness packages \n Internal mobility team dedicated to helping you own your career \n Professional growth opportunities including paid education and certifications \n Cutting-edge technology you can learn from \n Rest and recharge with paid vacation and holidays **(remove if not eligible)** \n \n  Work Requirements\n  \n  .cls-1{fill:none;stroke:#5b6670;stroke-miterlimit:10;stroke-width:2px;} \n   Years of Experience \n   2 + years of related experience\n  \n \n \n may vary based on technical training, certification(s),  or  degree \n \n  .cls-1,.cls-2{fill:none;stroke:#5b6670;stroke-miterlimit:10;}.cls-1{stroke-width:1.77px;}.cls-2{stroke-width:2px;} \n   Certification\n  \n  .cls-1{fill:none;stroke:#5b6670;stroke-miterlimit:10;stroke-width:2px;} \n   Travel Required \n   10-25%\n  \n  About Our Work\n  \n  We are GDIT. A global technology and professional services company that delivers consulting, technology and mission services to every major agency across the U.S. government, defense and intelligence community. Our 30,000 experts extract the power of technology to create immediate value and deliver solutions at the edge of innovation. We operate across 30 countries worldwide, offering leading capabilities in digital modernization, AI/ML, Cloud, Cyber and application development. Together with our clients, we strive to create a safer, smarter world by harnessing the power of deep expertise and advanced technology. \n  \n  GDIT is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status, or any other protected class.", "cleaned_desc": "TSS Data Engineer \n \n  GDIT is seeking a Data Engineer to support its Technology Shared Services (TSS) Data and Analytics organization. Deliver insights to help our clients turn data into action as a Data Engineer at GDIT. Your work will provide transformative solutions to our clients' big-data obstacles and help advance the mission. Here, you can make a meaningful impact on our clients' mission and on your career.\n  \n  GDIT is your place. You make it your own. Bring your creativity to help us find simple solutions to complex problems. By owning your opportunity at GDIT, you'll play an essential part in preparing our nation for the future. At GDIT, our employees are driven, resourceful, and unwavering.\n  \n \n HOW A DATA ENGINEER WILL MAKE AN IMPACT \n \n \n  Responsible for data migrations, data modeling, and creating schema. \n  Provides expert-level design and development of relational databases. \n  Designs, implements, and maintains data pipelines to perform extract, transform, and load (ETL) data from sources to destinations. \n  Builds and manages cloud-native data architectures in AWS and Azure. \n  Identifies and directs information needs and elements, data relationships and attributes, data flow and storage requirements, and data output and reporting capabilities. \n  Leads new data development ensuring consistency and integration with existing data warehouse structure. \n  Reviews business requests for data and data usage, researches data sources for new and better data feeds. \n  Maintains comprehensive documentation on data processes, pipelines, and architecture for knowledge sharing and collaboration. \n  Leads continuous improvement efforts in enhancing performance and providing increased functionality, including performing proactive maintenance such as ensuring continued space availability, monitoring activity, and documenting problems, changes, and solutions. \n  Assignments may include design of data dictionaries, database structure and layout, installing, upgrading, and managing database applications.   \n  Required Skills and Abilities: \n \n \n  Experienced in AWS and Azure cloud environments. \n  Proficient in Python to perform data analysis and engineering tasks. \n  Experienced in working in AWS with AWS data and analytics services, such as RDS, DynamoDB, Redshift, Aurora, S3, and Database Migration Service (DMS). \n  Proficient in database administration and Structured Query Language (SQL). \n  Experienced in data modeling and data normalization techniques. \n  Experienced in different data structures, including relational databases, semi-structured, and object stores. \n  Experienced in database migrations, including homogenous and heterogenous and on-prem and cloud. \n  Excellent communication and presentation skills with the ability to present complex data insights to both technical and non-technical audiences. \n  Good team player, able to manage multiple assignments, and adapt to changing client needs. \n  Skilled in programming languages like Python, R, SQL, and experience in working with data visualization tools like Tableau and Power BI. \n \n \n  Preferred Skills and Abilities: \n \n \n  AWS Certified Solutions Architect Associate    Azure Fundamentals \n  Azure Data Fundamentals \n  Secret clearance or ability to obtain \n  Knowledge of ITIL framework \n  Knowledge of Agile methodology \n  Demonstrated experience consulting with internal and external customers to understand business needs and make recommendations. \n  Previous experience in the defense or government sector \n  Familiarity with cloud services: AWS, Google Cloud, Microsoft Azure, etc.) and big data tools is plus. \n  Experience in optimization algorithms and natural language processing is a plus. \n  Data science and cloud certifications are a plus (Certified Data Scientist (CDS), AWS Certified Machine Learning - Specialty, Microsoft Certified: Azure Data Scientist Associate, IBM Data Science Professional) \n \n  GDIT IS YOUR PLACE:\n  \n \n Full-flex work week to own your priorities at work and at home** (remove if not eligible)** \n 401K with company match \n Comprehensive health and wellness packages \n Internal mobility team dedicated to helping you own your career \n Professional growth opportunities including paid education and certifications \n Cutting-edge technology you can learn from ", "techs": ["tss data engineer", "aws", "azure", "python", "r", "sql", "tableau", "power bi", "aws certified solutions architect associate", "azure fundamentals", "azure data fundamentals", "itil framework", "agile methodology", "aws certified machine learning - specialty", "microsoft certified: azure data scientist associate", "ibm data science professional"]}, "63a3e9e2d048a495": {"terms": ["data engineer"], "salary_min": 138400.0, "salary_max": 173000.0, "title": "Senior Software Engineer, Data Solutions", "company": "Invitae", "desc": "Invitae (NYSE: NVTA) is a leading medical genetics company trusted by millions of patients and their providers to deliver timely genetic information using digital technology. We aim to provide accurate and actionable answers to strengthen medical decision-making for individuals and their families. Invitae's genetics experts apply a rigorous approach to data and research, serving as the foundation of their mission to bring comprehensive genetic information into mainstream medicine to improve healthcare for billions of people. \n \n  By joining Invitae, you'll work alongside some of the world's experts in genetics and healthcare at the forefront of genetic medicine. We've crafted a culture that empowers our teams and our teammates to have the biggest impact and to explore their interests and capabilities. We prize freedom with accountability and offer significant flexibility, along with excellent benefits and competitive compensation in a fast-growing organization! \n  We are looking for a reliable and motivated  Senior Software Engineer  to join our Data Solutions Team in developing the data ingestion pipelines and data platform architecture that supports the analytical and reporting needs of data scientists, our bio informatics team, customers, and internal stakeholders. \n  What you'll do: \n \n Support and collaborate with multiple teams to gather requirements, design software, and implement features that support multiple teams and use cases across Data Science, Bioinformatics, and Finance. \n Design and implement reliable, scalable and efficient data framework, data driven products and software solutions for external and internal customers \n Create a secure, flexible and powerful world-class Health Data Platform for medical research and treatment \n Enhance existing systems to automate and use latest technologies and tools \n Ability and passion for data to become the Subject Matter Expert working with users on databases, tables, schemas and meta-data \n Follow and contribute to agile best practices within the organization, looking for ways to streamline, automate and reduce redundancy and costs \n Support and respond to teammate and user questions in a fast-paced, collaborative environment in a timely manner \n \n What you bring: \n \n Minimum of 4 years of related experience with a Bachelor's degree, 2 years and a Master's degree or beyond. \n Skilled in one or more high-level programming languages, including Scala, Python and a willingness to learn \n Hands-on experience with trouble-shooting, debugging, log collection, and alerting systems. \n Proficient in AWS, Azure, or Google Cloud Platform (AWS preferred) including databases, monitoring, security, provisioning, and scalability. \n Experience with relational and columnar databases including Snowflake and RDS. Proven experience in writing, debugging and modifying SQL queries. \n Experience with one or more containerization tools, especially Docker and Kubernetes \n Experience with messaging/queuing or stream processing systems (Kafka preferred) \n Laser focus on high quality code and process, including automated testing, documentation and coding best practices \n Demonstrated track record of working with cross functional teams to deliver value and features across the organization \n \n Additional Preferred but not Required Skills: \n \n Hands-on experience working with large datasets, ETL pipelines, and modern warehouse technologies. \n Hands-on functional programming in Scala or other language \n Hands-on parallel programming in Spark or other platforms \n Experience with dbt or similar tools for data transformation, with Debezium or similar tools for change data capture, and Kafka for streaming data applications \n Experience with maintaining and administering Kubernetes clusters \n Experience with build automation and CI/CD pipelines (e.g. GitHub Actions) \n Experience with one or more data visualization tools (Looker preferred) \n \n Nice to have: \n \n Demonstrated experience with data modeling/dimensional modeling \n Demonstrated experience with database performance tuning \n Familiarity with data lineage/data governance \n Demonstrated understanding of security principals including OAuth, Role-Based Access Control and encryption. Experience with Snowflake Security a plus and Data Governance a plus \n \n #LI-Remote \n  This salary range is an estimate, and the actual salary may vary based on a wide range of factors, including your skills, qualifications, experience and location. This position is eligible for benefits including but not limited to medical, dental, vision, life insurance, disability coverage, flexible paid time off, Spring Health, Carrot Fertility, participation in a 401k with company match, ESPP, and many other additional voluntary benefits. Invitae also offers generous paid leave programs so you can spend time with your new child, recover from your own illness or care for a sick family member. \n  USA National Pay Range \n  $138,400\u2014$173,000 USD    Join Us! \n \n \n    This salary range is an estimate, and the actual salary may vary based on a wide range of factors, including your skills, qualifications, experience and location. This position is eligible for benefits including but not limited to medical, dental, vision, life insurance, disability coverage, flexible paid time off, Spring Health, Carrot Fertility, participation in a 401k with company match, ESPP, and many other additional voluntary benefits. Invitae also offers generous paid leave programs so you can spend time with your new child, recover from your own illness or care for a sick family member.\n   \n  California Pay Range \n \n    $138,400\u2014$173,000 USD\n   \n \n \n  Please apply even if you don't meet all of the \"What you bring\" requirements noted. It's rare that someone checks every single item, it's ok, we encourage you to apply anyways. \n  Join us! \n  At Invitae, we value diversity and provide equal employment opportunities (EEO) to all employees and applicants without regard to race, color, religion, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. We will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance.     We truly believe a diverse workplace is crucial to our company's success and to better serve our diverse patients. Your input is especially valuable. We'd greatly appreciate it if you can take a quick moment to make your selection(s) below. Submissions will be anonymous. \n  You can find a detailed explanation of our privacy practices here.", "cleaned_desc": "Invitae (NYSE: NVTA) is a leading medical genetics company trusted by millions of patients and their providers to deliver timely genetic information using digital technology. We aim to provide accurate and actionable answers to strengthen medical decision-making for individuals and their families. Invitae's genetics experts apply a rigorous approach to data and research, serving as the foundation of their mission to bring comprehensive genetic information into mainstream medicine to improve healthcare for billions of people. \n \n  By joining Invitae, you'll work alongside some of the world's experts in genetics and healthcare at the forefront of genetic medicine. We've crafted a culture that empowers our teams and our teammates to have the biggest impact and to explore their interests and capabilities. We prize freedom with accountability and offer significant flexibility, along with excellent benefits and competitive compensation in a fast-growing organization! \n  We are looking for a reliable and motivated  Senior Software Engineer  to join our Data Solutions Team in developing the data ingestion pipelines and data platform architecture that supports the analytical and reporting needs of data scientists, our bio informatics team, customers, and internal stakeholders. \n  What you'll do: \n \n Support and collaborate with multiple teams to gather requirements, design software, and implement features that support multiple teams and use cases across Data Science, Bioinformatics, and Finance. \n Design and implement reliable, scalable and efficient data framework, data driven products and software solutions for external and internal customers \n Create a secure, flexible and powerful world-class Health Data Platform for medical research and treatment \n Enhance existing systems to automate and use latest technologies and tools \n Ability and passion for data to become the Subject Matter Expert working with users on databases, tables, schemas and meta-data \n Follow and contribute to agile best practices within the organization, looking for ways to streamline, automate and reduce redundancy and costs   Support and respond to teammate and user questions in a fast-paced, collaborative environment in a timely manner \n \n What you bring: \n \n Minimum of 4 years of related experience with a Bachelor's degree, 2 years and a Master's degree or beyond. \n Skilled in one or more high-level programming languages, including Scala, Python and a willingness to learn \n Hands-on experience with trouble-shooting, debugging, log collection, and alerting systems. \n Proficient in AWS, Azure, or Google Cloud Platform (AWS preferred) including databases, monitoring, security, provisioning, and scalability. \n Experience with relational and columnar databases including Snowflake and RDS. Proven experience in writing, debugging and modifying SQL queries. \n Experience with one or more containerization tools, especially Docker and Kubernetes \n Experience with messaging/queuing or stream processing systems (Kafka preferred) \n Laser focus on high quality code and process, including automated testing, documentation and coding best practices   Demonstrated track record of working with cross functional teams to deliver value and features across the organization \n \n Additional Preferred but not Required Skills: \n \n Hands-on experience working with large datasets, ETL pipelines, and modern warehouse technologies. \n Hands-on functional programming in Scala or other language \n Hands-on parallel programming in Spark or other platforms \n Experience with dbt or similar tools for data transformation, with Debezium or similar tools for change data capture, and Kafka for streaming data applications \n Experience with maintaining and administering Kubernetes clusters \n Experience with build automation and CI/CD pipelines (e.g. GitHub Actions) \n Experience with one or more data visualization tools (Looker preferred) \n ", "techs": ["invitae", "nyse", "nvta", "digital technology", "genetics", "data ingestion pipelines", "data platform architecture", "data scientists", "bioinformatics team", "data driven products", "software solutions", "health data platform", "programming languages", "scala", "python", "aws", "azure", "google cloud platform", "databases", "monitoring", "security", "snowflake", "rds", "sql queries", "containerization tools", "docker", "kubernetes", "messaging/queuing", "stream processing systems", "kafka", "automated testing", "documentation", "etl pipelines", "warehouse technologies", "functional programming", "spark", "dbt", "debezium", "kubernetes clusters", "build automation", "ci/cd pipelines", "github actions", "data visualization tools", "looker."]}, "8b1b5f4e9d03f613": {"terms": ["data engineer"], "salary_min": 112000.0, "salary_max": 179000.0, "title": "Big Data Cloud Senior Software Engineer", "company": "Peraton", "desc": "Peraton Overview \n  Peraton drives missions of consequence spanning the globe and extending to the farthest reaches of the galaxy. As the world's leading mission capability integrator and transformative enterprise IT provider, we deliver trusted and highly differentiated national security solutions and technologies that keep people safe and secure. Peraton serves as a valued partner to essential government agencies across the intelligence, space, cyber, defense, civilian, health, and state and local markets. Every day, our employees do the can't be done, solving the most daunting challenges facing our customers.\n  \n Responsibilities \n \n  Peraton is looking for a \n  Big Data Cloud Senior Software Engineer.  The qualified candidate will join our highly performing team supporting the Securities and Exchange Commission (SEC), Office of Data Science (ODS) Data Engineering Program. This is a telework position. \n  \n \n What you will do:  \n \n \n Provide support across data life cycle and including but not limited to the planning, design, development, implementation, and operational support of the data models, ETL, Data Sourcing processes and related software programs.  \n The SEC ODS will require support in the adoption of cloud-based technologies such as Spark/PySpark, Databricks, Scala, AWS Glue and S3.  \n The position will require cooperation with a wide range of stakeholders such as end users, SMEs, and technical staff from data vendors such as FINRA and other SEC divisions such as Office of Information Technology (OIT).  \n Design, development and tuning of ETL/ELT processes involving massive data (order of TB).  \n Migration of datasets from on-prem databases to AWS.  \n \n \n Qualifications \n \n \n Required Qualifications:  \n \n \n Bachelor's Degree and a minimum of 12 years of experience.  \n Development of complex Python scripts.  \n Experience in development and support activities in cloud-based environments using big data technologies and programming languages and tools such as Scala, Spark, PySpark, Presto, Ranger, Hadoop, and Hive etc. (at least 3 years of experience).  \n Experience working in Amazon Cloud environment (AWS) utilizing tools such as S3, EMR, Databricks, Data Lakes, AWS Glue, Amazon StageMaker, Amazon Redshift etc.  \n Design, development and tuning of complex ETL/ELT processes involving massive data (order of TB).  \n Design, development and support of Web Services (RESTful/SOAP) & Web Scraping (HTTP, CSS and HTML) ETL/ELT processes.  \n Experience working with complex file formats of structured, unstructured and semi-structured data including JSON, XML, CSV, Avro, Parquet etc.  \n Data modelling using RDBMS such as Amazon Relation Database Services (RDS), and PostgreSQL, etc.  \n Development of clear and concise technical documentation including data models, architecture and data workflow diagrams, design documents, and deployment documents.  \n Experience working with Git, and GitLab.  \n Ability to create technical guidance documents with data maps and conditions.  \n Ability to work independently with Stakeholders and Industry to approve technical guidance.  \n Experience/Knowledge in AWS cloud tools and Redshift data warehouse service  \n Industry XML data exchange message formats, required modifications, or extensions knowledge.  \n Must be a US Citizen without Dual Citizenship  \n Must be able to obtain and maintain the required agency clearance (SEC Public Trust)  \n AWS Solutions Architect or Developer Certification  \n \n \n Preferred Qualifications:  \n \n \n Current or previous knowledge and experience working with financial capital markets data is a plus.  \n \n \n Benefits:  \n \n  At Peraton, our benefits are designed to help keep you at your best beyond the work you do with us daily. We're fully committed to the growth of our employees. From fully comprehensive medical plans to tuition reimbursement, tuition assistance, and fertility treatment, we are there to support you all the way. \n  \n \n Target Salary Range \n \n  $112,000 - $179,000. This represents the typical salary range for this position based on experience and other factors.\n  \n \n SCA / Union / Intern Rate or Range \n \n \n EEO \n  An Equal Opportunity Employer including Disability/Veteran.\n  \n \n Our Values \n \n \n Benefits \n  At Peraton, our benefits are designed to help keep you at your best beyond the work you do with us daily. We're fully committed to the growth of our employees. From fully comprehensive medical plans to tuition reimbursement, tuition assistance, and fertility treatment, we are there to support you all the way.\n  \n \n  Paid Time-Off and Holidays \n  Retirement \n  Life & Disability Insurance \n  Career Development \n  Tuition Assistance and Student Loan Financing \n  Paid Parental Leave \n  Additional Benefits \n  Medical, Dental, & Vision Care", "cleaned_desc": " Migration of datasets from on-prem databases to AWS.  \n \n \n Qualifications \n \n \n Required Qualifications:  \n \n \n Bachelor's Degree and a minimum of 12 years of experience.  \n Development of complex Python scripts.  \n Experience in development and support activities in cloud-based environments using big data technologies and programming languages and tools such as Scala, Spark, PySpark, Presto, Ranger, Hadoop, and Hive etc. (at least 3 years of experience).  \n Experience working in Amazon Cloud environment (AWS) utilizing tools such as S3, EMR, Databricks, Data Lakes, AWS Glue, Amazon StageMaker, Amazon Redshift etc.  \n Design, development and tuning of complex ETL/ELT processes involving massive data (order of TB).  \n Design, development and support of Web Services (RESTful/SOAP) & Web Scraping (HTTP, CSS and HTML) ETL/ELT processes.  \n Experience working with complex file formats of structured, unstructured and semi-structured data including JSON, XML, CSV, Avro, Parquet etc.    Data modelling using RDBMS such as Amazon Relation Database Services (RDS), and PostgreSQL, etc.  \n Development of clear and concise technical documentation including data models, architecture and data workflow diagrams, design documents, and deployment documents.  \n Experience working with Git, and GitLab.  \n Ability to create technical guidance documents with data maps and conditions.  \n Ability to work independently with Stakeholders and Industry to approve technical guidance.  \n Experience/Knowledge in AWS cloud tools and Redshift data warehouse service  \n Industry XML data exchange message formats, required modifications, or extensions knowledge.  \n Must be a US Citizen without Dual Citizenship  \n Must be able to obtain and maintain the required agency clearance (SEC Public Trust)  \n AWS Solutions Architect or Developer Certification  \n \n \n Preferred Qualifications:  \n \n \n Current or previous knowledge and experience working with financial capital markets data is a plus.  ", "techs": ["on-prem databases", "aws", "python", "scala", "spark", "pyspark", "presto", "ranger", "hadoop", "hive", "s3", "emr", "databricks", "data lakes", "aws glue", "amazon sagemaker", "amazon redshift", "etl/elt", "web services", "restful", "soap", "web scraping", "json", "xml", "csv", "avro", "parquet", "rdbms", "amazon rds", "postgresql", "git", "gitlab", "data maps", "conditions", "stakeholders", "industry", "aws cloud tools", "redshift data warehouse", "xml data exchange", "sec public trust", "aws solutions architect", "developer certification"]}, "5129c67eff35d9e9": {"terms": ["data engineer"], "salary_min": 138176.34, "salary_max": 174962.03, "title": "Distributed Systems Engineer (L5) - Data Platform", "company": "Netflix", "desc": "Remote, United States\n      \n \n \n \n \n \n \n         Data Platform\n        \n \n \n \n \n \n \n \n     At Netflix, we want to entertain the world and are constantly innovating on how entertainment is imagined, created and delivered to a global audience. We currently stream content in more than 30 languages in 190 countries, topping over 220 million paid subscribers and are expanding into new forms of entertainment such as gaming.\n    \n \n \n  The data infrastructure teams at Netflix enable us to leverage data to bring joy to our members in many different ways. We provide centralized data platforms and tools for various business functions at Netflix, so they can utilize our data to make critical data-driven decisions. We do all the heavy lifting to make it easy for our business partners to work with data efficiently, securely, and responsibly. We aspire to lead the industry standard in building a world-class data infrastructure, as Netflix leads the way to be the most popular and pervasive destination for global internet entertainment.\n    \n \n \n  We are looking for distributed systems engineers to help evolve and innovate our infrastructure as we work towards our ambitious goal of 500 million members worldwide. We are committed to building a diverse and inclusive team to bring new perspectives as we solve the next set of challenges. In addition, we are open to remote candidates. We value what you can do, from anywhere in the U.S.\n    \n \n \n  Spotlight on Data Infrastructure Teams:\n    \n \n \n  Database Access Platform |Learn More\n    \n \n     The Database Access Platform team builds and operates a flexible query gateway that facilitates data abstractions to operate at sub-millisecond latencies while allowing Netflix microservices to more easily store, consume, and manage their data. This team holds a substantial responsibility in enabling Netflix microservices to satisfy their ever-growing and evolving data needs.\n    \n \n     This team is passionate about distributed data systems technology. We are active in the open-source community and believe in operating what we own. We are a small team responsible for business-critical systems and are committed to a culture of feedback and engineering\n     \n \n \n \n \n \n This would be your dream job if you enjoy: \n \n  Solving real business needs at large scale by applying your software engineering and analytical problem solving skills. \n  Architecting and building a robust, scalable, and highly available distributed infrastructure. \n  Leading cross-functional initiatives and collaborating with engineers, product managers, and TPM across teams. \n  Sharing our experiences with the open source communities and contributing to Netflix OSS.  \n \n \n \n About you: \n \n  You have 5+ years of experience in building large-scale distributed systems or applications. \n  You are proficient in design and development of RESTful web services. \n  Experienced building and operating scalable, fault-tolerant, distributed systems \n  You are an expert in Java or other object-oriented programming languages. Python or Scala expertise is a plus. \n  Multi-threading is a challenge that you are comfortable tackling. \n  You have a BS in Computer Science or related field. \n \n \n \n     A few more things about us:\n    \n \n \n  As a team, we come from many different countries and our fields of education range from the humanities to engineering to computer science. Our team includes product managers, program managers, designers, full-stack developers, distributed systems engineers, and data scientists. Folks have the opportunity to wear different hats, should they choose to. We strongly believe this diversity has helped us build an inclusive and empathetic environment and look forward to adding your perspective to the mix!\n    \n \n \n  At Netflix, we carefully consider a wide range of compensation factors to determine your personal top of market. We rely on market indicators to determine compensation and consider your specific job family, background, skills, and experience to get it right. These considerations can cause your compensation to vary and will also be dependent on your location.\n    \n \n \n  The overall market range for roles in this area of Netflix is typically $100,000 - $700,000\n    \n \n \n  This market range is based on total compensation (vs. only base salary), which is in line with our compensation philosophy. Our culture is unique, and we tend to live by our values, so it\u2019s worth learning more about Netflix here.", "cleaned_desc": "  Solving real business needs at large scale by applying your software engineering and analytical problem solving skills. \n  Architecting and building a robust, scalable, and highly available distributed infrastructure. \n  Leading cross-functional initiatives and collaborating with engineers, product managers, and TPM across teams. \n  Sharing our experiences with the open source communities and contributing to Netflix OSS.  \n \n \n \n About you: \n \n  You have 5+ years of experience in building large-scale distributed systems or applications. \n  You are proficient in design and development of RESTful web services. \n  Experienced building and operating scalable, fault-tolerant, distributed systems \n  You are an expert in Java or other object-oriented programming languages. Python or Scala expertise is a plus. \n  Multi-threading is a challenge that you are comfortable tackling. \n  You have a BS in Computer Science or related field. \n ", "techs": ["restful web services", "java", "python", "scala", "multi-threading"]}, "faec18680fbfd1d2": {"terms": ["machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Design Release Engineer", "company": "Capgemini", "desc": "Duration : 12+ months \n \n  Job Description: \n \n \n \n  BCM (Body Control Module) Design release engineer. \n  8-10+ years of experience with relevance of 3+ years with automotive, electrical development experience. \n  Responsibilities Includes, \n  Overall project timeline setup and tracking \n  Participate in project and committee forums relevant to BCM development in different centers across the globe. \n  Vendor coordination for A, B, C Samples \n  Vendor coordination for series samples \n  Sample delivery and documentation for each sample \n  Defect tracking and analysis (KPM) \n  Quality issues tracking and analysis \n \n \n  Critical Skills: \n \n  Overall project timeline setup and tracking \n  Experience with Infotainment /Body Control Module components of vehicle system. \n  Software Issue Management - Open issues list management and dispositioning \n  Software Issue Triage - First level triage to determine appropriate issue owner \n  Ability to communicate status of issues from triage to issue closure. \n  Experience prioritizing multiple complex solutions \n  High level of problem solving and analytical skills \n  Strong leadership skills (prepared to lead and work directly with a supplier/vendor team) \n  Experience with tools, including, KPM, JIRA, PowerPoint, Confluence, etc \n  Knowledge of automotive architectures and communication protocols (as CAN, LIN, MOST and Ethernet) . \n \n \n  The Capgemini Freelancer Gateway is enabled by a cutting-edge software platform that leads the contingent labor world for technology innovation. The software platform leverages Machine Learning and Artificial Intelligence to make sure the right people end up in the right job. \n \n  A global leader in consulting, technology services and digital transformation, Capgemini is at the forefront of innovation to address the entire breadth of clients\u2019 opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50 year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. It is a multicultural company of over 200,000 team members in more than 40 countries. The Group reported 2018 global revenues of EUR 13.2 billion.", "cleaned_desc": "  Ability to communicate status of issues from triage to issue closure. \n  Experience prioritizing multiple complex solutions \n  High level of problem solving and analytical skills \n  Strong leadership skills (prepared to lead and work directly with a supplier/vendor team) \n  Experience with tools, including, KPM, JIRA, PowerPoint, Confluence, etc \n  Knowledge of automotive architectures and communication protocols (as CAN, LIN, MOST and Ethernet) . ", "techs": ["kpm", "jira", "powerpoint", "confluence", "can", "lin", "most", "ethernet"]}, "a44650fa088049da": {"terms": ["machine learning engineer"], "salary_min": 130000.0, "salary_max": 175000.0, "title": "Sr. Software Engineer I", "company": "Apartment List", "desc": "At Apartment List, we're on a mission to find every renter a home they love at the value they deserve. Finding the right place to live is one of the most important, time-consuming and expensive decisions that all of us make. Getting it right matters. We've helped over 1 million families find a home they love, and we're just getting started. \n \n  Reporting to the Data Platform Engineering Manager, you will primarily be responsible for owning the data platform, building scalable data pipelines, and partnering with analysts, data scientists, and other engineers to unlock value of data across the organization. You will also have the opportunity to grow your career by building high-availability services that deliver performance, scalability, security, and productivity that serve as a foundation for all engineering efforts at Apartment List. As a Sr. Software Engineer, you will influence the broader engineering organization through engineering best practices and collaborate with other technical specialists to improve developer experience. \n  Here's what you'll do as part of the team: \n \n Maintain and improve our data platform that is used by dozens of analysts and engineers. \n Scale our eventing and data pipelining systems, with a penchant for delivering near real time insights capabilities to our users. \n Use the right tool for the job. Our data platform is powered by BigQuery, Airflow, dbt, and GCP Pub/Sub. We are always open to new ideas on how to make us more productive. \n Build and support machine learning services that deliver value for our users. \n Work in a small team of like-minded software engineers. We expect you to be great, and we expect you to make us all better. \n \n Here are the skills and experience you'll need to be successful: \n \n You have at least 3 years of experience in organizations with a solid engineering process and an emphasis on delivering highly scalable and highly performant services. \n You have incredible attention to detail and are able to implement creative and technically sound solutions to product challenges. \n You have strong database experience (PostgreSQL, Redshift, Snowflake, BigQuery, etc) \n You have experience designing and implementing RESTful APIs \n You tackle problems at all levels of software development, including feature implementation, software build and delivery processes, and developer productivity and velocity improvements. \n You are a constant learner, always on the lookout for learning and trying new technologies. \n You have experience with Python, Go, or Typescript programming languages \u2013 or a willingness to learn. \n \n Here's the Pay Range: \n  At Apartment List, we carefully consider a variety of factors to determine compensation for each position, including the role, level, and work. The US base salary range for this position is $130,000 -$175,000 + bonus + equity, which reflects the compensation target for new hire salaries for the position across all US locations. Please note, the compensation details provided do not include benefits and perks that we offer. \n  We also rely on market indicators along with considering your work location, job related skills, experience and relevant education and training, to determine compensation that is fair and competitive for you. Apartment List will consider paying compensation near the higher of the range in exceptional circumstances, where candidates have the experience, credentials or expertise that would warrant such consideration. It is always our goal to hire exceptional talent and we would be happy to share more about compensation during the hiring process. \n \n  Here's what's in it for you (full-time employees only): \n \n Competitive Compensation: Including annual salary, pre-IPO stock options, and other financial compensation (if applicable) \n Medical, Dental, and Vision Coverage: 100% of premiums covered for you AND all of your dependents \n Unlimited Flexible Time Off: Unlimited FTO in addition to 11 company holidays per year, quarterly \"recharge\" days, and a week-long holiday break \n Home Office Reimbursement: To cover home office furniture and supplies, monthly home internet, and monthly cell phone (if applicable) \n Health & Wellness Reimbursement: To cover monthly gym membership or other qualifying expenses \n Parental Support: Generous parental and family leave, fertility benefits, and employer-sponsored stipends towards family forming services \n 401k Plan: To support you in your individual retirement goals \n Team Events: Frequent team-building events, fun team off-sites, and bi-annual company meetups \n Commitment to DEI: To prioritize Diversity, Equity, and Inclusion within our workplace and to stay true to our values and mission \n Mentorship and Training: To get you onboard quickly, learn new professional skills, and invest in your career development \n Impact and Visibility: To expose you to and provide the opportunity to work on highly strategic initiatives that will transform the business \n Encouragement and Empowerment: To explore and adopt new technologies and drive meaningful decisions and outcomes \n \n At Apartment List we believe that everyone deserves a home they love AND a career they love. We strive to build a diverse team that is a reflection of the people we serve; this is made possible through our commitment to fostering a culture of diversity, inclusion, equity, and connectedness. \n  As a proud equal opportunity employer, we celebrate the collection of individual differences, life experiences, ideas, perspectives, knowledge, and talent. We hire candidates of any race, color, ancestry, religion, sex, national origin, sexual orientation, gender identity, age, marital or family status, disability, Veteran status, and any other status. \n  #LI-Remote", "cleaned_desc": "", "techs": ""}, "df686e4cbc3fc810": {"terms": ["machine learning engineer"], "salary_min": 110000.0, "salary_max": -1.0, "title": "Bioinformatics Engineer", "company": "Ginkgo Bioworks", "desc": "Our mission is to make biology easier to engineer. Ginkgo is constructing, editing, and redesigning the living world in order to answer the globe\u2019s growing challenges in health, energy, food, materials, and more. Our bioengineers make use of an in-house automated foundry for designing and building new organisms. \n \n \n \n \n Ginkgo Bioworks is a publicly traded (NYSE: $DNA), high-growth biotechnology company based in Boston\u2019s Seaport District, that is redesigning the living world to solve some of the globe\u2019s growing challenges in health, energy, food, material, and more. Our mission to \u201cmake biology easier to engineer\u201d is poised to disrupt multiple industries by leveraging our innovative data, automation, and scale capabilities in biological engineering. \n  Ginkgo believes that if we are to grow a thriving, sustainable bioeconomy, we must also grow a new market in biosecurity. Our biosecurity and public health initiative, Concentric by Ginkgo, launched a nationwide emergency response to the COVID-19 pandemic, providing end-to-end pathogen monitoring services to schools, communities, and travelers. As we continue to scale Concentric, our work is also evolving into new and exciting directions, from global expansion to the integration of new technologies and capabilities, including our Traveler-Based Genomic Surveillance Plan with the CDC. \n  We are seeking a motivated Bioinformatics Engineer/Test Engineer 2/3 to join our growing Biosecurity Team and be a part of implementing innovative biosecurity solutions. Your responsibilities will include engineering pipelines, analyzing sequencing data, and supporting the development of long-term biosecurity initiatives. In this role you will interface with key teams in the Ginkgo Bioworks Foundry and Biosecurity Divisions to ensure program success through high quality deliverables and innovative offerings. You bring subject matter expertise in bioinformatics, pipeline development, and high performance computing to help the Biosecurity Division\u2019s growing bioinformatics programs; you are a cross-functional team player, bringing diverse perspectives to our interdisciplinary team, and poised to develop the future of biosecurity. \n  Responsibilities \n \n Support Ginkgo\u2019s Biosecurity Teams with your technical expertise in bioinformatics \n Design, build, test, deploy, and maintain bioinformatics pipelines \n Interface with software engineers to create and implement NGS data analysis pipelines for production use \n Collaborate cross-functionally with wet and dry-lab operators on experimental design and analysis to optimize new analytic approaches using NGS technologies \n Effectively communicate scientific results to technical and non-technical audiences \n Assist with shaping Ginkgo and Concentric\u2019s overall direction as a company and support its evolving needs, as necessary \n \n Minimum Requirements \n \n BS with 4+years OR MS with 2+ years OR PhD with 1+ year of experience \n 2 years of relevant industry experience is required \n Proficient in at least one software programming language (Python) \n Proficient in workflow management software (Nextflow, Docker) \n Proficient in pipeline development on AWS infrastructure \n Proficient in best practices for collaborative software development (GitHub, version control systems, CI/CD, test-driven development, and good documentation habits) \n First-hand technical experience in at least two of the following disciplines: bioinformatics, computer science, mathematics, genome assembly & annotation, statistics, probabilistic modeling, machine learning, or quantitative modeling of biological systems \n Demonstrated ability to meet the demands of multiple concurrent projects, and work efficiently in a fast-paced, high-growth environment \n Ability to adapt to changing priorities and pivot as needed in a fast-paced environment \n Superb communication skills, with the ability to effectively convey project plans and complex technical details to a wide range of internal teams, executive leadership, and external customers \n Strong curiosity for, and comfort working in, areas of biology & biosecurity previously unknown to you (and, at times, unknown to your peers) \n \n Preferred Capabilities and Experience \n \n Experience analyzing and benchmarking outputs from multiple sequencing technologies: Illumina, Oxford Nanopore, PacBio, Hi-C \n Direct sequencing and bioinformatics experience with varied pathogen types (e.g. viral, bacterial, fungal) or engineered organisms \n Experience with many or all of the following: Python, bash/unix scripting, Snakemake, Nextflow, airflow, CWL, relational databases (SQL), GraphQL, distributed computing (AWS/Google Cloud), Docker, software version control (git) \n Data and Database Management: SQL, AWS, Snowflake \n Technical program management skills, JIRA, SCRUM, and agile methodologies \n \n \n Total compensation for this role is market driven, with a starting salary of $ 110k+ , as well as company stock awards. Base pay is ultimately determined based on a candidate's skills, expertise, and experience. We also offer a comprehensive benefits package including medical, dental & vision coverage, health spending accounts, voluntary benefits, leave of absence policies, Employee Assistance Program, 401(k) program with employer contribution, 8 paid holidays in addition to a full-week winter shutdown and unlimited Paid Time Off policy. \n \n \n \n   To learn more about Ginkgo, visit www.ginkgobioworks.com/press/ or check out some curated press below:\n   \n \n What is it really like to take your company public via a SPAC? One Boston biotech shares its journey (Fortune) \n Ginkgo Bioworks resizes the definition of going big in biotech, raising $2.5B in a record SPAC deal that weighs in with a whopping $15B-plus valuation (Endpoints News) \n Ginkgo Bioworks CEO on scaling up Covid-19 testing: \u2018If we try, we can win\u2019 (CNBC) \n Ginkgo raises $70 million to ramp up COVID-19 testing for employers, universities (Boston Globe) \n Ginkgo Bioworks Redirects Its Biotech Platform to Coronavirus (Wall Street Journal) \n Ginkgo Bioworks Provides Support on Process Optimization to Moderna for COVID-19 Response (PRNewswire) \n The Life Factory: Synthetic Organisms From This $1.4 Billion Startup Will Revolutionize Manufacturing (Forbes) \n Synthetic Bio Pioneer Ginkgo Raises $290 Million in New Funding (Bloomberg) \n Ginkgo Bioworks raises $350 million fund for biotech spinouts (Reuters) \n Can This Company Convince You to Love GMOs? (The Atlantic) \n \n \n \n   We also feel that it\u2019s important to point out the obvious here \u2013 there\u2019s a serious lack of diversity in our industry, and that needs to change. Our goal is to help drive that change. Ginkgo is deeply committed to diversity, equity, and inclusion in all of its practices, especially when it comes to growing our team. Our culture promotes inclusion and embraces how rewarding it is to work with people from all walks of life.\n   \n \n \n   We\u2019re developing a powerful biological engineering platform, so we must remain mindful of the many ways our technology can \u2013 and will \u2013 impact people around the world. We care about how our platform is used, and having a diverse team to build it gives us the best chance that it\u2019s something we\u2019ll be proud of as it continues to grow. Therefore, it\u2019s critical that we incorporate the diverse voices and visions of all those who play a role in the future of biology.\n   \n \n \n   It is the policy of Ginkgo Bioworks to provide equal employment opportunities to all employees, employment applicants, and EOE disability/vet.\n   \n \n \n Privacy Notice \n \n \n   I understand that I am applying for employment with Ginkgo Bioworks and am being asked to provide information in connection with my application. I further understand that Ginkgo gathers this information through a third-party service provider and that Ginkgo may also use other service providers to assist in the application process. Ginkgo may share my information with such third-party service providers in connection with my application and for the start of employment. Ginkgo will treat my information in accordance with Ginkgo's Privacy Policy. By submitting this job application, I am acknowledging that I have reviewed and agree to Ginkgo's Privacy Policy as well as the privacy policies of the third-party service providers used by Ginkgo's associated with the application process.", "cleaned_desc": " Assist with shaping Ginkgo and Concentric\u2019s overall direction as a company and support its evolving needs, as necessary \n \n Minimum Requirements \n \n BS with 4+years OR MS with 2+ years OR PhD with 1+ year of experience \n 2 years of relevant industry experience is required \n Proficient in at least one software programming language (Python) \n Proficient in workflow management software (Nextflow, Docker) \n Proficient in pipeline development on AWS infrastructure \n Proficient in best practices for collaborative software development (GitHub, version control systems, CI/CD, test-driven development, and good documentation habits) \n First-hand technical experience in at least two of the following disciplines: bioinformatics, computer science, mathematics, genome assembly & annotation, statistics, probabilistic modeling, machine learning, or quantitative modeling of biological systems \n Demonstrated ability to meet the demands of multiple concurrent projects, and work efficiently in a fast-paced, high-growth environment \n Ability to adapt to changing priorities and pivot as needed in a fast-paced environment \n Superb communication skills, with the ability to effectively convey project plans and complex technical details to a wide range of internal teams, executive leadership, and external customers \n Strong curiosity for, and comfort working in, areas of biology & biosecurity previously unknown to you (and, at times, unknown to your peers) ", "techs": ["nextflow", "docker", "aws infrastructure", "github", "version control systems", "ci/cd", "test-driven development", "python"]}, "a9f6b6c90c2c2d1f": {"terms": ["machine learning engineer"], "salary_min": 116002.0, "salary_max": 168000.0, "title": "Software Engineer, iOS - Monetization", "company": "Meta", "desc": "From making valuable connections between people and businesses to building premium services that deliver high-value experiences, the monetization organization at Meta empowers people and businesses to succeed in the global economy. As Meta focuses on building the next evolution of social experiences, the monetization team plays a crucial role in shaping the communication pathways and financial tools that all sized businesses, especially small to medium ones, need to thrive in the new digital economic environment. And we achieve that from end-to-end product and technology innovation.As an iOS Engineer on the monetization team at Meta, you can help build cutting-edge full-stack technologies that will transform the way people and businesses connect and communicate. You\u2019ll help develop industry-leading solutions that power next-generation, large-scale platforms and AI services to help connect billions of people around the world.\n  \n \n \n Software Engineer, iOS - Monetization Responsibilities:    \n \n Work closely with our product and design teams to build new and innovative application experiences for the iOS platform \n  Implement custom native user interfaces using the latest iOS programming techniques \n  Build reusable iOS software components for interfacing with our back-end platforms \n  Analyze and optimize UI and infrastructure application code for quality, efficiency, and performance \n \n \n \n \n Minimum Qualifications:   \n \n  2+ years of object-oriented software development experience \n  Currently has, or is in the process of obtaining a Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience. Degree must be completed prior to joining Meta. \n  1+ years experience building complex applications for the iPhone or iPad using Objective-C/C++/Swift with the iOS SDK and other frameworks \n  Experience building maintainable and testable code bases, including API design and unit testing techniques \n  Experience with multithreading programming and mobile memory management \n \n \n \n \n \n \n About Meta:    Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today\u2014beyond the constraints of screens, the limits of distance, and even the rules of physics.\n  \n \n \n \n  Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment. \n   \n  Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.", "cleaned_desc": " Work closely with our product and design teams to build new and innovative application experiences for the iOS platform \n  Implement custom native user interfaces using the latest iOS programming techniques \n  Build reusable iOS software components for interfacing with our back-end platforms \n  Analyze and optimize UI and infrastructure application code for quality, efficiency, and performance \n \n    1+ years experience building complex applications for the iPhone or iPad using Objective-C/C++/Swift with the iOS SDK and other frameworks \n  Experience building maintainable and testable code bases, including API design and unit testing techniques \n  Experience with multithreading programming and mobile memory management \n \n \n ", "techs": ["ios platform", "ios programming techniques", "back-end platforms", "objective-c/c++", "swift", "ios sdk", "frameworks", "maintainable code bases", "testable code bases", "api design", "unit testing techniques", "multithreading programming", "mobile memory management"]}, "7791bffa27fac703": {"terms": ["machine learning engineer"], "salary_min": 55.0, "salary_max": 65.0, "title": "Software Engineer", "company": "Global IT Resources", "desc": "Duties: \n Software Engineer to design and build back-end services that support our portfolio of data-centric clinical and analytic applications. These applications leverage cloud computing, big data, mobile, data science, data warehousing, machine learning using state of the art software development applications and frameworks. Our Software Engineers ensures that these cloud-based micro-services adhere to uptime and accuracy targets, are resilient, and scale as data volumes and traffic increase. They work closely with the data engineering, platform, and solutions teams to develop applications as required to benefit our practice and patients. Works closely with the Product Owners, Product Managers, Architects to translate requirements into code. Developing services around data warehousing, big data, cloud computing, business intelligence, analytics and machine learning. Participate in DevOps, Agile, continuous development and integration frameworks. Programming in high-level languages such as Go, Python, Java etc. Work on deployment automation/configuration management with tools including but not limited to ADO, Puppet, Chef or Ansible or Azure Pipelines, CloudFormation, Terraform following a DevOps model. Ensure all appropriate documentation of processes and source code is created and maintained. Communicate effectively with peers, leaders, and customers throughout the organization. Participate in expert level troubleshooting and resolve problems through root cause analysis, data and system investigation. Continues to build knowledge of the organization, processes and customers. Performs a range of mainly straightforward assignments. Uses prescribed guidelines or policies to analyze and resolve problems. Receives a moderate level of guidance and direction. \n Required skills: \n \n 2+ years of professional front-end experience developing Web applications \n Experience with front-end technologies (such as React/React Native, JavaScript, jQuery, HTML, CSS) \n Experience with Cloud based infrastructure (preferably, Azure or Google Cloud Platform) \n \n Preferred skills: \n \n Experience consuming APIs \n Experience with Figma, Sketch, or other design tools \n Experience with 3rd party UI libraries \n Experience in the healthcare industry \n \n Education: \n Bachelor's degree  \n Note: This is not an exhaustive list of responsibilities and skills. Other duties may be assigned based on business needs. \n If you are a talented Software Engineer looking for an exciting opportunity to work on cutting-edge projects in a collaborative environment, we want to hear from you! Apply now to join our team. \n Job Types: Temporary, Contract, Full-time \n Pay: $55.00 - $65.00 per hour \n Expected hours: 40 per week \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n Vision insurance \n \n Education: \n \n Bachelor's (Required) \n \n Experience: \n \n Front-end development: 2 years (Required) \n Web Applications: 2 years (Preferred) \n React Native: 2 years (Required) \n JavaScript: 2 years (Required) \n APIs: 2 years (Required) \n 3rd Party UI libraries: 2 years (Required) \n Healthcare: 2 years (Required) \n \n Work Location: Remote", "cleaned_desc": "Duties: \n Software Engineer to design and build back-end services that support our portfolio of data-centric clinical and analytic applications. These applications leverage cloud computing, big data, mobile, data science, data warehousing, machine learning using state of the art software development applications and frameworks. Our Software Engineers ensures that these cloud-based micro-services adhere to uptime and accuracy targets, are resilient, and scale as data volumes and traffic increase. They work closely with the data engineering, platform, and solutions teams to develop applications as required to benefit our practice and patients. Works closely with the Product Owners, Product Managers, Architects to translate requirements into code. Developing services around data warehousing, big data, cloud computing, business intelligence, analytics and machine learning. Participate in DevOps, Agile, continuous development and integration frameworks. Programming in high-level languages such as Go, Python, Java etc. Work on deployment automation/configuration management with tools including but not limited to ADO, Puppet, Chef or Ansible or Azure Pipelines, CloudFormation, Terraform following a DevOps model. Ensure all appropriate documentation of processes and source code is created and maintained. Communicate effectively with peers, leaders, and customers throughout the organization. Participate in expert level troubleshooting and resolve problems through root cause analysis, data and system investigation. Continues to build knowledge of the organization, processes and customers. Performs a range of mainly straightforward assignments. Uses prescribed guidelines or policies to analyze and resolve problems. Receives a moderate level of guidance and direction. \n Required skills: \n \n 2+ years of professional front-end experience developing Web applications \n Experience with front-end technologies (such as React/React Native, JavaScript, jQuery, HTML, CSS) \n Experience with Cloud based infrastructure (preferably, Azure or Google Cloud Platform) \n   Preferred skills: \n \n Experience consuming APIs \n Experience with Figma, Sketch, or other design tools \n Experience with 3rd party UI libraries \n Experience in the healthcare industry \n \n Education: ", "techs": ["react/react native", "javascript", "jquery", "html", "css", "azure", "google cloud platform", "figma", "sketch"]}, "df418b7d48f48859": {"terms": ["machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Product Manager", "company": "webAI", "desc": "Title: Product Manager \n  Company:  webAI \n  Location : Grand Rapids, Michigan; Austin, Texas; Remote \n  Type:  Full-Time, Salaried Exempt \n  Experience: 3+ years \n  Education:  Bachelor's Degree, minimum \n  About Us: \n  Just as the web connected the world, webAI is here to connect and empower by redefining the artificial intelligence stack. From novel architectures such as DeepDetection and LBRA, to Navigator's state-of-the-art development platform, webAI designs and develops solutions for many of AI's most significant challenges. If you are passionate about building a new kind of AI ecosystem that is efficient, safe, and accessible to all, we'd love to hear from you! \n  As a Product Manager - Developer platform, you will be at the intersection of technology, design, and AI. Your primary mission will be to understand our users' needs deeply and articulate a product strategy that results in delightful and impactful products. You'll spearhead initiatives that drive our product's growth and evolution, collaborating with a cross-functional team to turn visionary ideas into real-world solutions. \n  We at webAI are committed to living out the  core values  we have put in place as the foundation on which we operate as a team. We seek individuals who exemplify the following: \n \n Loyalty  - We support each other as individuals and come together to execute boldly once decisions are made. \n Mastery  - We commit to high performance as our standard and genius as our goal. \n Fortitude  - We demonstrate grit in the face of obstacles to best support the team. \n Humility  - We display grace in victory, compassion in our setbacks and goodwill to all. \n Truth  - We embrace discomfort in the new or unknown in the constant pursuit of objectivity. \n \n Responsibilities: \n \n Define Product Strategy & Vision: Define and communicate product strategy for our AI development platform based on market research, competitive analysis, technology roadmaps, and customer/user interaction \n Product Lifecycle Management: Lead the full product cycle: from ideation, research, and prototyping, through to design, execution, launch, and post-launch optimization \n Cross-Functional Collaboration: Partner with engineering, design, marketing, sales, and other teams to develop a cohesive product vision and execute effectively \n Customer Engagement: Interface with customers and users and gather feedback to inform product refinements and ongoing development \n Requirements Gathering: Work closely with customers, stakeholders, and users to understand and document requirements \n Performance Metrics: Monitor and measure launched products and feed learnings back into the product development process \n Stakeholder Management: Clearly communicate product benefits to our users and internal stakeholders, ranging from engineers to C-level executives \n \n Requirements and Skills: \n \n Bachelor's degree in Computer Science, Engineering, Business, or related field \n 3+ years of experience in product management, preferably in the tech or SaaS sector \n Demonstrated experience in Machine Learning tools and processes \n Strong understanding of the software development lifecycle \n Exceptional communication and presentation skills. \n Proactive and innovative mindset, with the ability to work in a fast-paced environment \n \n Benefits: \n \n Competitive salary and performance-based incentives. \n Comprehensive health, dental, and vision benefits package. \n $200/mos Health and Wellness Stipend \n $400/year Continuing Education Credit \n Flexible work week \n Free parking, for in-office employees \n Unlimited PTO \n Parental, Bereavement Leave \n \n \n \n  webAI is an Equal Opportunity Employer and does not discriminate against any employee or applicant on the basis of age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We adhere to these principles in all aspects of employment, including recruitment, hiring, training, compensation, promotion, benefits, social and recreational programs, and discipline. In addition, it is the policy of webAI to provide reasonable accommodation to qualified employees who have protected disabilities to the extent required by applicable laws, regulations and ordinances where a particular employee works.", "cleaned_desc": " Requirements and Skills: \n \n Bachelor's degree in Computer Science, Engineering, Business, or related field \n 3+ years of experience in product management, preferably in the tech or SaaS sector \n Demonstrated experience in Machine Learning tools and processes \n Strong understanding of the software development lifecycle \n Exceptional communication and presentation skills. \n Proactive and innovative mindset, with the ability to work in a fast-paced environment \n ", "techs": ["machine learning tools and processes"]}, "158db9e45276283f": {"terms": ["machine learning engineer"], "salary_min": 172994.0, "salary_max": 241000.0, "title": "Graphics Software Engineer, Rendering - Reality Labs", "company": "Meta", "desc": "Reality Labs at Meta is building products that make it easier for people to connect with the ones they love most, enjoy top-notch, wire-free VR, and push the future of computing platforms. We are a team of world-class experts developing and shipping products at the intersection of hardware, software and content.As a Graphics Software Engineer on the Reality Labs team at Meta, you can help build new, innovative hardware and software that radically redefine the way people work, play and connect. What we build today could one day be the norm. So to be here today is to truly be at the heart of change and the frontier of what's to come. We're the people helping to define the metaverse. We may not have all the answers. But together, we're getting closer.\n  \n \n \n Graphics Software Engineer, Rendering - Reality Labs Responsibilities:    \n \n Develop innovative graphics frameworks, algorithms, and tools to maximize graphics quality and performance \n  Partner closely with various infra and product teams across Meta, on camera, graphics, upcoming hardware, media enhancements, and more to create real-time rendering architecture \n  Building tools and pipelines for generating very realistic synthetic images \n  Enable high fidelity experiences through remote compute solutions on smaller devices with limited battery \n  Building rendering subsystems for platforms such as Spark AR and Horizon \n  Build a platform for cloud streamed games \n  Document and support graphics features \n  Write high-quality, performant, and maintainable code \n  Collaborate with cross-functional engineering teams to deliver innovation into AR/VR products \n \n \n \n \n Minimum Qualifications:   \n \n  Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience. \n  6+ years of graphics software engineering experience or 2+ years of graphics software engineering experience with PhD \n  6+ years of experience with C/C++ programming \n  6+ years of object-oriented and component-based design experience \n  Problem-solving and communication skills \n \n \n \n \n Preferred Qualifications:   \n \n  Experience delivering AAA Games, working on Graphics subsystems or the Game Engine AR/VR experience \n  Knowledge of ray tracing, rasterization and linear algebra \n  Experience with low level performance profiling and optimization \n  Experience implementing 3D graphics features such as lighting, effects, shaders and other low-level systems \n  Experience with tools such as Maya, Houdini, Blender, 3Ds Max, Arnold, RenderMan, or Cycles \n  Experience with either DirectX/Vulkan/OpenGL/Metal \n \n \n \n \n About Meta:    Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today\u2014beyond the constraints of screens, the limits of distance, and even the rules of physics.\n  \n \n \n \n  Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment. \n   \n  Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.", "cleaned_desc": "  Enable high fidelity experiences through remote compute solutions on smaller devices with limited battery \n  Building rendering subsystems for platforms such as Spark AR and Horizon \n  Build a platform for cloud streamed games \n  Document and support graphics features \n  Write high-quality, performant, and maintainable code \n  Collaborate with cross-functional engineering teams to deliver innovation into AR/VR products \n \n \n   \n Minimum Qualifications:   \n \n  Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience. \n  6+ years of graphics software engineering experience or 2+ years of graphics software engineering experience with PhD \n  6+ years of experience with C/C++ programming \n  6+ years of object-oriented and component-based design experience \n  Problem-solving and communication skills \n   \n \n \n Preferred Qualifications:   \n \n  Experience delivering AAA Games, working on Graphics subsystems or the Game Engine AR/VR experience \n  Knowledge of ray tracing, rasterization and linear algebra \n  Experience with low level performance profiling and optimization \n  Experience implementing 3D graphics features such as lighting, effects, shaders and other low-level systems ", "techs": ["spark ar", "horizon", "cloud streamed games", "graphics features", "ar/vr products", "c/c++ programming", "ray tracing", "rasterization", "linear algebra", "low level performance profiling", "optimization", "3d graphics features"]}, "5fd66233b759165a": {"terms": ["machine learning engineer"], "salary_min": 125000.0, "salary_max": 175000.0, "title": "Senior Software Engineer (Backend, Rust)", "company": "Second Spectrum", "desc": "Senior Software Engineer (Backend, Rust)  at Second Spectrum \n  \n  Remote - United States\n  \n \n \n \n Second Spectrum is a Sports Emmy-winning data & tech company  that is building the next way of seeing sports - by capturing and producing the highest quality data and innovative content for many of the world\u2019s largest leagues and media partners, such as the NFL, NBA, English Premier League, ESPN, Amazon, and CBS Sports. \n  We are pushing the boundaries of deep tech - machine learning, computer vision, big data, augmented and virtual reality. Our passion for cutting-edge design and decades of experience playing college and professional sports is an equal part of the magic that brings unique and innovative products to life. These products have helped Second Spectrum partners to multiple NBA championships, to win matches on football pitches around the world, to entertain and educate millions of fans on TV and digital. In 2021, Second Spectrum was acquired by Genius Sports, bringing together a unique combination of technological, operational and commercial capabilities. \n  We believe that technology will revolutionize the way that sports are played, coached, and experienced. We're just getting started turning our joint vision of transformative sports technologies into reality. \n  Second Spectrum is the place to be if you\u2019re interested in working on cutting edge technology in sports, alongside incredibly driven and ambitious teammates. Our innovative and dynamic environment emphasizes opportunities for motivated individuals to maximize their growth and impact. \n \n \n  The Role - Senior Software Engineer (Backend, Rust) \n  Second Spectrum is building a comprehensive system responsible for producing and distributing its highest quality and lowest latency tracking, skeletal pose, eventing, and video streams to date. You will design and develop the services required to execute all parts of this process for thousands of basketball and soccer games every year. Specifically, you can expect to: \n \n Develop our run management system that ensures we generate all data streams on time with minimal human input. \n Develop our storage and distribution layer responsible for making all of our data available to consumers at low latency. \n Integrate low-latency algorithms in collaboration with the computer vision, artificial intelligence, and augmentation teams in order to produce our data streams. \n Develop performant code targeting cutting edge devices both in the cloud and on-premise. \n Build highly autonomous systems to scale our technology and minimize the need for manual intervention. \n Collaborate on tools and frameworks that support the developer experience and velocity across the engineering organization. \n \n What You Have: \n \n Proficiency with Rust or other statically typed languages like Go or TypeScript \n Experience building distributed systems \n Experience with database design \n Team-first mindset \n Ability to excel in a fast-paced environment \n Care for your craft \n Desire to learn and teach others \n \n What Sets You Apart: \n \n Experience with architecting and benchmarking high-performance, real-time systems \n Experience with streaming technology like Pulsar or Kafka \n Experience with Docker and Kubernetes \n Experience with AWS (S3, RDS, EC2, ECR) \n Experience building products for live events \n \n Our Work Environment and What You Will Benefit From: \n \n Cutting-edge products to work on for major professional sports leagues and teams. \n Team-oriented engineering habits and software engineering best practices (readable, maintainable, and efficient code). \n Flat hierarchy and collaborative management led by experienced and strong technical leads. \n Innovative and dynamic environment, which encourages self-development and opportunities to make an impact. \n Multicultural team with employees based across several countries (e.g., Switzerland, Denmark, France, United States). \n Potential for Equity/Bonus, Flexible working hours, Competitive salary, Medical and dental benefits, 401k match \n \n What\u2019s in it for you? \n  As well as a competitive salary and annual leave allowance, our benefits include health insurance, skills training and much more, depending on the location. We also offer a host of softer benefits, including many social events throughout the year such as summer and winter holiday parties, monthly team building events, sports tournaments, charity days and wellbeing activities. \n  The base salary range for this role is $125,000 \u2013 $175,000. There are a number of factors which affect what the specific pay offer would be for this role, including location, seniority, and relevant educational and working experience. This is base salary only \u2013 all full-time roles will also be eligible to take part in Second Spectrum benefits and equity plan, and some roles may be eligible to take part in a bonus plan. For more details on the compensation and benefits package, please get in touch with our Talent team. \n  How we work: \n  We have adapted a forward-thinking \u2018Ways of Working\u2019 framework, which sets out (amongst other things) the opportunities for Second Spectrum to work flexibly, remotely and on working holidays. It affects different teams and locations differently, so please ask for further information on how it would work with this role. \n  Our employees are empowered to stretch the boundaries of what\u2019s achievable, always reaching further and pushing the edges to see what gives. We collaborate, we innovate, and we celebrate. We will continue to grow as an organization and continue to invest in our highly talented and diverse team. \n  Second Spectrum, part of Genius Sports Group, is proud to be an equal opportunities employer. We recognize and celebrate the benefits that a diverse and inclusive workforce bring to our business, our customers and our staff. We welcome and will consider all applications regardless of age, different abilities or disability, gender identity or re-assignment, marriage, pregnancy, maternity, race or nationality, religion or belief, sex and sexual orientation (and any other applicable status). Please let us know when you apply if you need any assistance during the recruiting process due to a disability.", "cleaned_desc": " What Sets You Apart: \n \n Experience with architecting and benchmarking high-performance, real-time systems \n Experience with streaming technology like Pulsar or Kafka \n Experience with Docker and Kubernetes \n Experience with AWS (S3, RDS, EC2, ECR) \n Experience building products for live events \n \n Our Work Environment and What You Will Benefit From: \n \n Cutting-edge products to work on for major professional sports leagues and teams. ", "techs": ["pulsar", "kafka", "docker", "kubernetes", "aws (s3", "rds", "ec2", "ecr)"]}, "7e6c7c3fba186e7b": {"terms": ["machine learning engineer"], "salary_min": 196000.0, "salary_max": 269000.0, "title": "Display Imaging Pipeline Engineer", "company": "Meta", "desc": "At Meta Reality Labs, we\u2019re developing the future of virtual reality (VR) and augmented reality (AR). The APIX team is looking for an Imaging Pipeline Engineer who can bring together the disparate simulation models of the component parts of our image chain, and employ this end-to-end pipeline in a continuous feedback loop to optimize product requirements against Display system constraints.\n  \n \n \n Display Imaging Pipeline Engineer Responsibilities:    \n \n Work cross-functionally with silicon, graphics, perception and display teams to implement pipeline models and simulate end-to-end performance of our image pipeline using those models \n  Implement system simulations of pipeline components and algorithms using a mixture of MATLAB and Python \n  Use simulation results to propose and verify improvements to aspects of the pipeline via modeling and human factors testing \n  Perform tradeoff analyses against visual quality metrics \n  Bring up novel display subsystems \n \n \n \n \n Minimum Qualifications:   \n \n  Bachelors in image processing or equivalent experience \n  8+ years of experience in research, advanced optics development, or equivalent experience \n  Experience in taking image-based (e.g. camera, printer, display) products to market \n  Experience with MATLAB \n  Understanding of Color spaces (HDR workflows, LED constraints, Display Calibration & Characterization) \n  Understanding of Imaging Standards such as SMPTE, MPEG & compressions schemes \n  Understanding of frame rates perception and hardware-software interactions \n  image processing algorithms and SW/HW implementation through the entire pipeline \n  Experience in managing production-level tradeoffs in typical image pipelines \n  Experience in working as part of a cross-functional team and familiarity with typical software/hardware design processes \n  Hands on working experience with displays and camera pipelines \n \n \n \n \n Preferred Qualifications:   \n \n  15+ years of experience in research, advanced optics development, or equivalent experience \n  PhD in Image Processing or related field \n  Knowledge of the human visual system, color science and imaging architectures \n  Experience in human factors testing and psychometric testing paradigms \n  Experience in bringing up real-world display technologies or optical systems, especially AR/VR \n  Experience with C/C++, C#, and/or Python and/or Matlab \n \n \n \n \n About Meta:    Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today\u2014beyond the constraints of screens, the limits of distance, and even the rules of physics.\n  \n \n \n \n  Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment. \n   \n  Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.", "cleaned_desc": "  Experience with MATLAB \n  Understanding of Color spaces (HDR workflows, LED constraints, Display Calibration & Characterization) \n  Understanding of Imaging Standards such as SMPTE, MPEG & compressions schemes \n  Understanding of frame rates perception and hardware-software interactions \n  image processing algorithms and SW/HW implementation through the entire pipeline \n  Experience in managing production-level tradeoffs in typical image pipelines \n  Experience in working as part of a cross-functional team and familiarity with typical software/hardware design processes \n  Hands on working experience with displays and camera pipelines \n \n   \n \n Preferred Qualifications:   \n \n  15+ years of experience in research, advanced optics development, or equivalent experience \n  PhD in Image Processing or related field \n  Knowledge of the human visual system, color science and imaging architectures \n  Experience in human factors testing and psychometric testing paradigms \n  Experience in bringing up real-world display technologies or optical systems, especially AR/VR \n  Experience with C/C++, C#, and/or Python and/or Matlab ", "techs": ["matlab", "color spaces (hdr workflows", "led constraints", "display calibration & characterization)", "imaging standards (smpte", "mpeg", "compressions schemes)", "frame rates perception", "image processing algorithms", "sw/hw implementation", "production-level tradeoffs", "cross-functional team", "software/hardware design processes", "displays", "camera pipelines", "research", "advanced optics development", "phd in image processing or related field", "human visual system", "color science", "imaging architectures", "human factors testing", "psychometric testing paradigms", "real-world display technologies", "optical systems", "ar/vr", "c/c++", "c#", "python"]}, "93c88aa9adaceccf": {"terms": ["machine learning engineer"], "salary_min": 123300.0, "salary_max": 145000.0, "title": "Software Development Engineer in Test - Python III", "company": "OpenX", "desc": "Company at a Glance \n \n \n   OpenX is focused on unleashing the full economic potential of digital media companies. We do this by making digital advertising markets and technologies that are designed to deliver optimal value to publishers and advertisers on every ad served across all screens.\n  \n \n \n  At OpenX, we have built a team that is uniquely experienced in designing and operating high-scale ad marketplaces, and we are constantly on the lookout for thoughtful, creative executors who are as fascinated as we are about finding new ways to apply a blend of market design, technical innovation, operational excellence, and empathetic partner service to the frontiers of digital advertising.\n  \n \n \n  OpenX is looking for talented, communicative, and curious engineers to join our team. Currently, we\u2019re looking for a Software Developer in Test (Python) to join our full-stack team.\n  \n \n \n  You will have a chance to work in aspects of agile application development, including our highly efficient and available serving platform Your influence will be considered in phases of product development, starting from requirements to validation and deployment. You will assist other engineers to ensure that our processes are defined, documented, tested, and easy to use.\n  \n \n \n  You will have the opportunity to work closely with other SDETs focusing on different domains (both frontend and backend), as well as be a part of the QA Guilds focusing on making impactful changes to our tools and processes.\n  \n Key Responsibilities \n \n  Test large-scale programmatic advertising platform \n  Involved in all phases of product development, starting from requirements to validation and deployment \n  Analyze and improve the efficiency, scalability, and stability of applications \n  Work in a focused and agile team that collaborates on common problems across products and across focus areas \n  Own components, processes, and workflows that demand professionalism, excellent communication, teamwork, and documentation skills \n  Create, maintain, and improve automation test suites/frameworks \n  Monitor and maintain QA CI pipelines, collaborate on CD enablement \n  Conduct root cause analysis of issues and provide solutions for better coverage and maintainability \n  Effectively communicate and work as a crucial member of both the platform teams and the QA organization \n  Be exposed to a broader set of problems, which allows for fast career growth and proximity to abundant technical problems \n \n  Required Qualifications \n \n  5+ years of test automation experience \n  Proficiency in Python and ability to improve, debug, modify, and maintain an automation framework codebase \n  Experience in using test design techniques \n  Experience using CI/CD tools like Jenkins or Spinnaker \n  Excellent troubleshooting skills to triage complex issues \n  Experience operating in an agile environment \n  Bachelor\u2019s degree in Computer Science or equivalent degree/work experience \n \n  Nice to Have \n \n  Experience with Google Cloud Platform, Kubernetes, and Docker \n  Experience in UI/UX testing \n  Experience in API testing \n  Experience with the Pytest framework \n  Familiarity with advertising technologies and the advertising ecosystem \n  Experience with machine learning, particularly with Tensorflow, TFX, and Kubeflow \n \n \n   Pursuant to the San Francisco Fair Chance Ordinance, Los Angeles Fair Chance Initiative for Hiring Ordinance, New York Fair Chance Act, and any other state or local hiring regulations, we will consider for employment any qualified applicant, including those with arrest and conviction records, in a manner consistent with the applicable regulation.\n  \n \n \n  OpenX is committed to fair and equitable compensation practices. For applicants in New York, New Jersey, California, and Colorado, the salary range is $123,300 - $145,000 per year + bonus + equity + benefits. A candidate\u2019s salary is determined by various factors including, but not limited to, relevant work experience, skills, and certifications. The salary range may differ in other states.\n  \n \n \n  A summary of our benefits, which include medical, dental, vision, 401k, equity and more, can be viewed here: https://www.openx.com/company/careers/ A candidate\u2019s salary is determined by various factors including, but not limited to, relevant work experience, skills, and certifications.\n  \n \n  OpenX VALUES \n \n \n   Our five company values form a solid bedrock serving to define us as a group and guide the company. Our values remind us that how we do things often matters as much as what we do.\n  \n \n \n  WE ARE ONE \n \n \n   We are one team. There are no exceptions. We are a group of strong and diverse individuals unified by a shared mission. We embrace challenges and win together as a team. We respect and care about our colleagues and cultivate an inclusive culture\n  \n \n \n  WE ARE CUSTOMER CENTRIC \n \n \n   We innovate on behalf of our customers. We understand, respect, and listen carefully to our customers. We build great products to solve our customers\u2019 problems. We manage our customers\u2019 expectations clearly and honestly. We are a trusted partner to all of our customers - we act with integrity at all times. We care.\n  \n \n \n  OPENX IS OURS \n \n \n   We innovate on behalf of our customers. We understand, respect, and listen carefully to our customers. We build great products to solve our customers\u2019 problems. We manage our customers\u2019 expectations clearly and honestly. We are a trusted partner to all of our customers - we act with integrity at all times. We care.\n  \n \n \n  WE ARE AN OPEN BOOK \n \n \n   We understand and respect what each of us does. We are eager to teach and share what we know with others, both internally and externally. We are eager to learn from others and we ask questions internally and externally.\n  \n \n \n  WE EVOLVE FAST \n \n \n   We take responsible risks and own and learn from our mistakes. We recognize and repeat success. We actively seek out and provide constructive feedback. We adapt quickly and embrace change. We tackle growth and learning with real urgency. We are endlessly curious.\n   \n \n \n \n \n OpenX is committed to equal employment opportunities.  \n \n \n  It is a fundamental principle at OpenX not to discriminate against employees or applicants for employment on any legally-recognized basis including, but not limited to: age, race, creed, color, religion, national origin, sexual orientation, sex, disability, predisposing genetic characteristics, genetic information, military or veteran status, marital status, gender identity/transgender status, pregnancy, childbirth or related medical condition, and other protected characteristic as established by law.\n  \n \n \n  OpenX Applicant Privacy Policy \n \n \n   Applicants can review our Applicant Privacy Policy at any time by visiting the following link: https://www.openx.com/privacy-center/applicant-privacy-policy/.\n  \n \n \n  Effective Date: March 1, 2022", "cleaned_desc": "  Involved in all phases of product development, starting from requirements to validation and deployment \n  Analyze and improve the efficiency, scalability, and stability of applications \n  Work in a focused and agile team that collaborates on common problems across products and across focus areas \n  Own components, processes, and workflows that demand professionalism, excellent communication, teamwork, and documentation skills \n  Create, maintain, and improve automation test suites/frameworks \n  Monitor and maintain QA CI pipelines, collaborate on CD enablement \n  Conduct root cause analysis of issues and provide solutions for better coverage and maintainability \n  Effectively communicate and work as a crucial member of both the platform teams and the QA organization \n  Be exposed to a broader set of problems, which allows for fast career growth and proximity to abundant technical problems \n \n  Required Qualifications \n \n  5+ years of test automation experience \n  Proficiency in Python and ability to improve, debug, modify, and maintain an automation framework codebase \n  Experience in using test design techniques \n  Experience using CI/CD tools like Jenkins or Spinnaker \n  Excellent troubleshooting skills to triage complex issues \n  Experience operating in an agile environment \n  Bachelor\u2019s degree in Computer Science or equivalent degree/work experience \n \n  Nice to Have \n \n  Experience with Google Cloud Platform, Kubernetes, and Docker \n  Experience in UI/UX testing ", "techs": ["requirements to validation and deployment", "efficiency", "scalability", "and stability of applications", "focused and agile team", "components", "processes", "and workflows", "automation test suites/frameworks", "qa ci pipelines", "root cause analysis", "python", "automation framework codebase", "test design techniques", "ci/cd tools like jenkins or spinnaker", "troubleshooting skills", "agile environment", "google cloud platform", "kubernetes", "docker", "ui/ux testing"]}, "bd8e278a0a2b5947": {"terms": ["machine learning engineer"], "salary_min": 60.0, "salary_max": 70.0, "title": "Sr. Software Engineer", "company": "Global IT Resources", "desc": "Duties: \n We are seeking a Senior Software Engineer to design and build back-end services that support our portfolio of data-centric clinical and analytic applications. These applications leverage cloud computing, big data, mobile, data science, data warehousing, machine learning using state of the art software development applications and frameworks. Our Software Engineers ensures that these cloud-based micro-services adhere to uptime and accuracy targets, are resilient, and scale as data volumes and traffic increase. They work closely with the data engineering, platform, and solutions teams to develop applications as required to benefit our practice and patients. Works closely with the Product Owners, Product Managers, Architects to translate requirements into code. Developing services around data warehousing, big data, cloud computing, business intelligence, analytics and machine learning. Participate in DevOps, Agile, continuous development, and integration frameworks. Programming in high-level languages such as Go, Python, Java etc. Ensure all appropriate documentation of processes and source code is created and maintained. Communicate effectively with peers, leaders, and customers throughout the organization. Participate in expert level troubleshooting and resolve problems through root cause analysis, data and system investigation. Contributes to design and architecture discussions with Principals and Architects. Leads targeted cross-functional improvement efforts and mentors more junior software engineers. Solves complex problems; takes a new perspective on existing solutions. Work independently with minimal guidance. You may lead projects or project steps within a broader project or have accountability for ongoing activities or objectives. Act as a resource for colleagues with less experience. \n Skills: \n Preferred qualifications for this position include: Master\u2019s degree in computer science/engineering or related field. Ability to use a wide variety of open-source technologies and cloud-based services. Experience writing software for the cloud (GCP, AWS, Azure). Experience in databases, analytics, big data systems or business intelligence products. Experience building high-performance, highly available and scalable distributed systems. Experience developing software for healthcare related industries. \n Required skills: \n \n 5+ years of professional experience developing Web applications. \n Demonstrated proficiency with the Microsoft Technology stack (C#, .NET) \n Experience with relational databases (preferably, Microsoft SQL Server) \n Experience creating RESTful APIs \n Experience with front-end technologies (such as React, JavaScript, and jQuery) \n Experience with Cloud based infrastructure (preferably, Azure or Google Cloud Platform) \n \n Preferred skills: \n \n Experience with GraphQL \n Experience with microservices architectural pattern \n Experience with Adobe Experience Manager \n Experience in the healthcare industry \n \n Education: \n Bachelor's Degree in Computer Science/Engineering or related field with 5 years of experience as noted below; OR an Associate's degree in Computer/Science/Engineering or related field with 7 years of experience. \n Note: This is a senior-level position that requires extensive experience in software development. \n Job Types: Temporary, Contract, Full-time \n Pay: $60.00 - $70.00 per hour \n Expected hours: 40 per week \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n Vision insurance \n \n Schedule: \n \n Day shift \n Monday to Friday \n \n Education: \n \n Bachelor's (Required) \n \n Experience: \n \n EPIC ACCESS Web: 1 year (Required) \n GCP: 5 years (Required) \n AWS: 5 years (Required) \n AZURE: 5 years (Required) \n Web applications: 5 years (Required) \n Microsoft Technology stack: 3 years (Required) \n RESTful API: 3 years (Required) \n Healthcare: 3 years (Required) \n \n Work Location: Remote", "cleaned_desc": "Duties: \n We are seeking a Senior Software Engineer to design and build back-end services that support our portfolio of data-centric clinical and analytic applications. These applications leverage cloud computing, big data, mobile, data science, data warehousing, machine learning using state of the art software development applications and frameworks. Our Software Engineers ensures that these cloud-based micro-services adhere to uptime and accuracy targets, are resilient, and scale as data volumes and traffic increase. They work closely with the data engineering, platform, and solutions teams to develop applications as required to benefit our practice and patients. Works closely with the Product Owners, Product Managers, Architects to translate requirements into code. Developing services around data warehousing, big data, cloud computing, business intelligence, analytics and machine learning. Participate in DevOps, Agile, continuous development, and integration frameworks. Programming in high-level languages such as Go, Python, Java etc. Ensure all appropriate documentation of processes and source code is created and maintained. Communicate effectively with peers, leaders, and customers throughout the organization. Participate in expert level troubleshooting and resolve problems through root cause analysis, data and system investigation. Contributes to design and architecture discussions with Principals and Architects. Leads targeted cross-functional improvement efforts and mentors more junior software engineers. Solves complex problems; takes a new perspective on existing solutions. Work independently with minimal guidance. You may lead projects or project steps within a broader project or have accountability for ongoing activities or objectives. Act as a resource for colleagues with less experience. \n Skills: \n Preferred qualifications for this position include: Master\u2019s degree in computer science/engineering or related field. Ability to use a wide variety of open-source technologies and cloud-based services. Experience writing software for the cloud (GCP, AWS, Azure). Experience in databases, analytics, big data systems or business intelligence products. Experience building high-performance, highly available and scalable distributed systems. Experience developing software for healthcare related industries. \n Required skills: \n \n 5+ years of professional experience developing Web applications. \n Demonstrated proficiency with the Microsoft Technology stack (C#, .NET) \n Experience with relational databases (preferably, Microsoft SQL Server) \n Experience creating RESTful APIs   Experience with front-end technologies (such as React, JavaScript, and jQuery) \n Experience with Cloud based infrastructure (preferably, Azure or Google Cloud Platform) \n \n Preferred skills: \n \n Experience with GraphQL \n Experience with microservices architectural pattern \n Experience with Adobe Experience Manager \n Experience in the healthcare industry \n ", "techs": ["cloud computing", "big data", "mobile", "data science", "data warehousing", "machine learning", "software development applications", "frameworks", "micro-services", "data engineering", "platform", "solutions teams", "data warehousing", "business intelligence", "analytics", "devops", "agile", "continuous development", "integration frameworks", "go", "python", "java", "documentation", "troubleshooting", "root cause analysis", "design and architecture discussions", "cross-functional improvement efforts", "mentoring", "open-source technologies", "cloud-based services", "gcp", "aws", "azure", "databases", "microsoft sql server", "restful apis", "react", "javascript", "jquery", "azure", "google cloud platform", "graphql", "microservices architectural pattern", "adobe experience manager"]}, "d002b1aed9483b48": {"terms": ["machine learning engineer"], "salary_min": 90107.0, "salary_max": 95174.0, "title": "Developer", "company": "American Unit Inc", "desc": "About us \n We are professional and agile. \n Our work environment includes: \n \n Modern office setting \n Food provided \n Work-from-home days \n Growth opportunities \n \n AU FTE Please share h1b transfer profiles only. \n Generative AI Developer \n Location: Remote \n Salary: based on market ( negotiate) \n No of Positions: 3 \n The ideal candidate will possess a blend of data engineering expertise hands-on development experience and a deep understanding of Generative AI technologies. \n Technical Skills: Gernerative AI \n Technical Skills: Azure Databricks, Azure Synapse and Python \n Proven experience as a Data Engineer or in a similar role with significant hands-on development experience \n We are seeking an innovative Generative AI Machine Learning Developer to join a brand new team focused on designing, developing and implementing cutting-edge generative AI models and solutions that can be entrenched into prevailing applications or the new application \n Strong proficiency in  Python and  exposure to other similar programming languages \n Python Expertise: Strong expertise in Python, which is commonly used for machine learning and AI development \n Solid understanding of system architecture with a focus on building solutions for scalability and performance \n Deep knowledge of Generative AI/LLM technologies, including but not limited to  GPT-3 and Transformers \n Generative AI and LLMs: Generative AI models and Large Language Models (LLMs) like BERT, GPT,  and others. \n Familiarity with  Linux operating systems and basic programming concepts \n Hands-on development experience with at least one  public cloud provider (AWS, Azure, GCP, etc.) \n Responsibilities \n This role is instrumental in developing and deploying state-of-the-art  Generative AI solutions that drive critical business functions \n Design, develop, and deploy solutions using OpenAI API and other LLM-related technologies to cater to critical business functions \n Preferred Qualifications: \n Research publications or contributions in the  fields of NLP, NLU and Generative AI \n Experience with C onversational AI, Chatbots (Kore.ai, Botpress, Nuance  etc.,) \n Job Type: Full-time \n Salary: $90,107.00 - $95,174.00 per year \n Benefits: \n \n Health insurance \n \n Schedule: \n \n 8 hour shift \n \n Supplemental pay types: \n \n Bonus opportunities \n \n Work Location: Remote", "cleaned_desc": " We are seeking an innovative Generative AI Machine Learning Developer to join a brand new team focused on designing, developing and implementing cutting-edge generative AI models and solutions that can be entrenched into prevailing applications or the new application \n Strong proficiency in  Python and  exposure to other similar programming languages \n Python Expertise: Strong expertise in Python, which is commonly used for machine learning and AI development \n Solid understanding of system architecture with a focus on building solutions for scalability and performance \n Deep knowledge of Generative AI/LLM technologies, including but not limited to  GPT-3 and Transformers \n Generative AI and LLMs: Generative AI models and Large Language Models (LLMs) like BERT, GPT,  and others. \n Familiarity with  Linux operating systems and basic programming concepts \n Hands-on development experience with at least one  public cloud provider (AWS, Azure, GCP, etc.) \n Responsibilities ", "techs": ["generative ai", "machine learning", "python", "programming languages", "system architecture", "scalability", "performance", "gpt-3", "transformers", "bert", "gpt", "linux operating systems", "programming concepts", "public cloud provider", "aws", "azure", "gcp."]}, "d8f24508b2e7c1b0": {"terms": ["machine learning engineer", "mlops"], "salary_min": 100000.0, "salary_max": 180000.0, "title": "Senior Computer Vision Engineer", "company": "Kibsi", "desc": "We\u2019re Kibsi and we\u2019re unleashing the future of vision-enabled applications. Our cloud-native, low-code platform democratizes computer vision, allowing customers to focus on their business needs, not the complexity. \n  We're currently looking for a Senior Computer Vision Engineer to help us design and build Kibsi. You\u2019ll be working with a team of designers, engineers, and CV experts responsible for creating our fully integrated environment designed for building computer vision applications.     \n What you bring to the table: \n \n Expertise with Python development and relevant machine learning and analytical libraries \n Experience with popular deep machine learning frameworks, such as TensorFlow, PyTorch, or ONNX Runtime \n Industry experience working with and deploying computer vision models for object detection, tracking, key point detection, segmentation, and classification \n Experience with video streaming technologies, including at the edge and in the cloud \n Experience with real-time video processing and model execution \n Experience with MLOps tools and workflows \n Experience designing and implementing traditional machine learning and neural network classifiers \n Experience setting up and managing (non-production) Linux systems for CV use cases \n 2-3 years of professional work experience creating and deploying computer vision models \n Great written and verbal communication skills \n Motivated and a self-starter with the ability to work autonomously and collaboratively within a team \n An analytical and thoughtful mind with the desire to help shape the requirements of a quickly evolving product \n Passionate to learn new things, whether it's a language, framework or brand-new concept \n \n What you'll get: \n \n Competitive pay:  We provide a highly competitive salary and bonus, and generous equity packages. \n Awesome benefits:  We offer top-notch health, dental, and vision coverage with market-leading employer contributions for you and your dependents, an FSA, a 401k with a match, and a generous parental leave policy to help take care of you and the ones you love. \n Unlimited vacation:  We provide unlimited time off, so you can take that much-needed vacation or random day whenever you need it. \n Flexible environment:  We give you the freedom to work wherever you want and are flexible about when you work. We even pay a phone and home office stipend. \n Fun atmosphere:  We like to bond and have fun outside of the office too, that\u2019s why we throw regular happy hours, team buildings and outings, & more! \n Tools for the job:  We let you choose your own equipment and get access to the materials, training, and the certifications you need to help us build the future. \n Random perks:  We want you to feel loved. That\u2019s why we offer random free lunches, goodies, lots of surprise swag delivered to your door & more!", "cleaned_desc": " Experience with popular deep machine learning frameworks, such as TensorFlow, PyTorch, or ONNX Runtime \n Industry experience working with and deploying computer vision models for object detection, tracking, key point detection, segmentation, and classification \n Experience with video streaming technologies, including at the edge and in the cloud \n Experience with real-time video processing and model execution \n Experience with MLOps tools and workflows   Experience designing and implementing traditional machine learning and neural network classifiers \n Experience setting up and managing (non-production) Linux systems for CV use cases \n 2-3 years of professional work experience creating and deploying computer vision models \n Great written and verbal communication skills \n Motivated and a self-starter with the ability to work autonomously and collaboratively within a team ", "techs": ["tensorflow", "pytorch", "onnx runtime", "mlops tools", "linux systems"]}, "f03987704c6b6cc2": {"terms": ["machine learning engineer"], "salary_min": 184300.0, "salary_max": 255000.0, "title": "Principal Software Engineer", "company": "Upstart Network, Inc.", "desc": "About Upstart \n  Upstart is a leading AI lending marketplace partnering with banks and credit unions to expand access to affordable credit. By leveraging Upstart's AI marketplace, Upstart-powered banks and credit unions can have higher approval rates and lower loss rates across races, ages, and genders, while simultaneously delivering the exceptional digital-first lending experience their customers demand. More than two-thirds of Upstart loans are approved instantly and are fully automated. \n  Upstart is a digital-first company, which means that most Upstarters can live and work anywhere in the U.S. We also have offices in San Mateo, California; Columbus, Ohio; and Austin, Texas. \n  Most Upstarters join us because they connect with our mission of enabling access to effortless credit based on true risk. If you are energized by the impact you can make at Upstart, we\u2019d love to hear from you! \n \n The Team \n  Upstart\u2019s Machine Learning team has a direct impact on our company's success. The team consists of full-stack applied science generalists as well as specialists in research, data science, statistical modeling and machine learning. The fundamental goal of the Machine Learning team is to explore new models and new data sets that can improve the accuracy of our models. With this goal comes near-limitless challenges to tackle, and that is one of the reasons why Upstart is such a unique opportunity. \n  As  Principal Software Engineer  at Upstart, you will be at the forefront of a team of top-notch specialists, using your C++ skills to optimize cutting-edge machine learning frameworks, employing GPU-accelerated computing, and mastering cloud and Linux infrastructure. \n  Position location  This role is available in the following locations: Remote \n  Time zone requirements  The team operates on the East/West coast time zones. \n  Travel requirements  As a digital first company, the majority of your work can be accomplished remotely. The majority of our employees can live and work anywhere in the U.S but are encouraged to to still spend high quality time in-person collaborating via regular onsites. The in-person sessions\u2019 cadence varies depending on the team and role; most teams meet once or twice per quarter for 2-4 consecutive days at a time. \n \n  How you\u2019ll make an impact: \n \n Deep Optimization : Dive into the C++ code which powers these ML models. You will use your expertise to push the boundaries of these models and extract their maximum potential. \n GPU and CUDA : Harness the raw power of GPUs using CUDA to supercharge your machine learning models, creating solutions that are not just efficient, but also blazing fast. \n Cloud and Linux : Leverage your solid understanding of cloud infrastructures and Linux to build robust, scalable, and highly available machine learning solutions \n Data Formats : Look into the finer details of data formats. Your work will ensure the accuracy, efficiency, and quality of the data that feeds into our machine learning models. \n \n Minimum Qualifications \n \n Strong software skills in C++, and multiple languages such as Java, Kotlin, Python. \n Profound knowledge of the entire tech stack, inclusive of computer science fundamentals and in-depth understanding of various operating systems and hardware configurations. \n High degree of cross-functional expertise, with the ability to navigate between various roles within the tech stack. \n Bachelor's or Master's degree in Computer Science or a related field, or equivalent practical experience. \n \n Preferred Qualifications \n \n Deep systems C++ expertise. \n Experience with machine learning frameworks such as TensorFlow, PyTorch, etc. \n Deep knowledge in using GPUs for computation, including a strong understanding of CUDA. \n Extensive experience with cloud and Linux infrastructures \n \n What you'll love: \n \n Competitive Compensation (base + bonus & equity) \n Comprehensive medical, dental, and vision coverage with Health Savings Account contributions from Upstart \n 401(k) with 100% company match up to $4,500 and immediate vesting and after-tax savings \n Employee Stock Purchase Plan (ESPP) \n Life and disability insurance \n Generous holiday, vacation, sick and safety leave \n Supportive parental, family care, and military leave programs \n Annual wellness, technology & ergonomic reimbursement programs \n Social activities including team events and onsites, all-company updates, employee resource groups (ERGs), and other interest groups such as book clubs, fitness, investing, and volunteering \n Catered lunches + snacks & drinks when working in offices \n \n #LI-REMOTE  \n #LI-MidSenior \n \n \n \n At Upstart, your base pay is one part of your total compensation package. The anticipated base salary for this position is expected to be within the below range. Your actual base pay will depend on your geographic location\u2013with our \u201cdigital first\u201d philosophy, Upstart uses compensation regions that vary depending on location. Individual pay is also determined by job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process. \n  In addition, Upstart provides employees with target bonuses, equity compensation, and generous benefits packages (including medical, dental, vision, and 401k). \n \n \n     United States | Remote - Anticipated Base Salary Range\n    \n \n     $184,300\u2014$255,000 USD\n    \n \n \n \n Upstart is a proud Equal Opportunity Employer. We are dedicated to ensuring that underrepresented classes receive better access to affordable credit, and are just as committed to embracing diversity and inclusion in our hiring practices. We celebrate all cultures, backgrounds, perspectives, and experiences, and know that we can only become better together. \n  If you require reasonable accommodation in completing an application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please email  candidate_accommodations@upstart.com \n  https://www.upstart.com/candidate_privacy_policy", "cleaned_desc": " \n Deep Optimization : Dive into the C++ code which powers these ML models. You will use your expertise to push the boundaries of these models and extract their maximum potential. \n GPU and CUDA : Harness the raw power of GPUs using CUDA to supercharge your machine learning models, creating solutions that are not just efficient, but also blazing fast. \n Cloud and Linux : Leverage your solid understanding of cloud infrastructures and Linux to build robust, scalable, and highly available machine learning solutions \n Data Formats : Look into the finer details of data formats. Your work will ensure the accuracy, efficiency, and quality of the data that feeds into our machine learning models. \n \n Minimum Qualifications \n \n Strong software skills in C++, and multiple languages such as Java, Kotlin, Python. \n Profound knowledge of the entire tech stack, inclusive of computer science fundamentals and in-depth understanding of various operating systems and hardware configurations. \n High degree of cross-functional expertise, with the ability to navigate between various roles within the tech stack. \n Bachelor's or Master's degree in Computer Science or a related field, or equivalent practical experience. \n ", "techs": ["deep optimization", "gpu", "cuda", "cloud", "linux", "data formats", "c++", "java", "kotlin", "python", "operating systems", "hardware configurations", "computer science"]}, "af990f05ca000c7e": {"terms": ["machine learning engineer"], "salary_min": 110000.0, "salary_max": 125000.0, "title": "Director of Software Development", "company": "Vectrona", "desc": "Position/Title: Director of Software Development \n Status:  Full-Time, Exempt \n Location:  Remote or Virginia Beach, VA \n Start date:  Immediate Hire \n Travel:  10-20% CONUS travel may be required \n Background:  Vectrona is developing cutting-edge AI/ML-based modeling & simulation systems, serious games, and 3D data visualization solutions to help warfighters train and operate. We require a seasoned Director of Software Development with 12 years of software/game development and at least 7 years of leadership experience to support development, deployment, and operation of our simulation systems. The Director of Software Development will lead the creation of multiple XR projects and serve as the interface between Subject Matter Experts and the software development team to ensure program objectives are accomplished. They will also play a key role in the development of Mixed Reality data visualization solutions that incorporate IoT and real-time sensor data. \n Day-to-Day Responsibilities: \n \n Define the technical architecture and manage the development of multiple XR projects \n Mentor junior members of the engineering team \n Manage multiple external contractors to ensure on-time, high quality delivery of work products \n Author and contribute to product artifacts (design documentation, user manuals, promotional material) \n Participate in technical strategy development, solution design, and proposal writing \n Support budget development and management \n Stay current with innovations in the XR and software engineering spaces \n \n Preferred Education/Degree:  BS in computer science, computer engineering, modeling and simulation engineering or 12+ years equivalent practical experience \n Preferred Experience: \n \n Experience leading XR projects from inception to completion \n Experience leading multidisciplinary teams in hybrid remote/onsite settings (artists, instructional designers, engineers, data scientists) \n Experience working on both production and research focused efforts (SBIRs, STTRs) \n Experience with Mixed and Virtual Reality development (HoloLens, Oculus, etc.) \n Experience working with analysis of sensor data highly desired (eye tracking, biometric, accelerometer, etc.) \n Experience with UI/UX Frameworks and Design \n Experience with speech recognition engines (including defining recognition grammars) \n Experience with version control platforms (Git, SVN, Perforce) \n Experience with Azure cloud services including data storage, data retrieval, authentication of users, and machine learning services \n Familiarity with CI/CD and Test-Driven Development (TDD) desired \n \n Preferred Knowledge and Skills: \n \n Outstanding verbal and written communication skills with the ability to tailor communications across all levels of stakeholders \n Ability to succeed in dynamic and demanding environment \n Creative approach to problem-solving with the ability to focus on details while maintaining the \u201cbig picture\u201d view \n Strong understanding of project management principles from initiation through planning, executing, and quality control to prioritize work and shift priorities as needed to meet aggressive milestones \n \n Security Clearance:  Clearance not required but candidates must be eligible for a Secret security clearance. Failure to obtain and/or maintain the required level of clearance may result in the withdrawal of a position offer or removal. If you possess a security clearance, please indicate the level and termination date in your resume. \n VECTRONA IS AN EQUAL OPPORTUNITY EMPLOYER AND A DRUG-FREE WORKPLACE. \n The above information has been designed to indicate the general nature and level of work performed by employees within this classification. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities, and qualifications required of employees assigned to this position. \n All Vectrona employment is contingent upon the individual providing legal proof of identity and authorization to work in the United States and satisfactory background check results. \n Employment with Vectrona is \u201cat will\u201d in accordance with Federal/State laws. \n Vectrona provides equal employment opportunities (EEO) to all employees and applications for employment. In addition to federal law requirements, Vectrona complies with applicable state and local laws governing nondiscrimination in employment. \n Job Type: Full-time \n Pay: $110,000.00 - $125,000.00 per year \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Flexible spending account \n Health insurance \n Health savings account \n Life insurance \n Paid time off \n Retirement plan \n Vision insurance \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Experience: \n \n software development: 10 years (Preferred) \n \n Willingness to travel: \n \n 25% (Required) \n \n Work Location: Remote", "cleaned_desc": " Stay current with innovations in the XR and software engineering spaces \n \n Preferred Education/Degree:  BS in computer science, computer engineering, modeling and simulation engineering or 12+ years equivalent practical experience \n Preferred Experience: \n \n Experience leading XR projects from inception to completion \n Experience leading multidisciplinary teams in hybrid remote/onsite settings (artists, instructional designers, engineers, data scientists) \n Experience working on both production and research focused efforts (SBIRs, STTRs) \n Experience with Mixed and Virtual Reality development (HoloLens, Oculus, etc.) \n Experience working with analysis of sensor data highly desired (eye tracking, biometric, accelerometer, etc.) \n Experience with UI/UX Frameworks and Design \n Experience with speech recognition engines (including defining recognition grammars) \n Experience with version control platforms (Git, SVN, Perforce) \n Experience with Azure cloud services including data storage, data retrieval, authentication of users, and machine learning services ", "techs": ["xr projects", "computer science", "computer engineering", "modeling and simulation engineering", "hybrid remote/onsite settings", "artists", "instructional designers", "engineers", "data scientists", "production", "research", "sbirs", "sttrs", "mixed reality development", "virtual reality development", "hololens", "oculus", "analysis of sensor data", "eye tracking", "biometric data", "accelerometer data", "ui/ux frameworks", "design", "speech recognition engines", "version control platforms", "git", "svn", "perforce", "azure cloud services", "data storage", "data retrieval", "authentication of users", "machine learning services"]}, "c14c089eba0f276d": {"terms": ["machine learning engineer"], "salary_min": 58400.0, "salary_max": 133000.0, "title": "Full Stack Software Engineer", "company": "Booz Allen Hamilton", "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Bethesda,MD,US \n         \n \n \n \n         Remote Work: \n         \n \n         Hybrid \n         \n \n \n \n         Job Number: \n         \n \n         R0182566\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Full Stack Software Engineer\n           The Opportunity: \n  Are you looking for an opportunity to combine your technical skills with big picture thinking to make an impact in healthcare? You understand your customer\u2019s environment and how to develop the right systems for their mission. Your ability to translate real-world needs into technical specifications makes you an integral part of delivering a customer focused engineering solution. \n \n  As a software engineer on our team, you have the chance to design systems in support of a federal client's healthcare initiatives. Your technical expertise will be vital as you evaluate and modernize legacy systems. You\u2019ll develop your skills in cloud technologies while gaining experience in healthcare. Join our team and help turn requirements into accomplishments that drive change. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  3+ years of experience with architecting, integrating, and developing software systems in Java, J2EE, Scala, or Python \n  Experience with ElasticSearch or Hibernate \n  Experience in interacting with Cloud infrastructure providers, including AWS \n  Experience with DevOps methods and tools, including Jenkins, Git, SVN, Jira, Cucumber, Docker, or Kubernetes \n  Experience with all phases of the software development life cycle (SDLC) using Agile methods \n  Knowledge of Microservices development and designing and implementing RESTful Web services \n  Knowledge of JavaScript frameworks, including Angular or React \n  Knowledge of object-oriented programming (OOP) and designing, developing, and communicating complex software solutions \n  Ability to obtain and maintain a Public Trust or Suitability/Fitness determination based on client requirements \n  Bachelor's degree \n \n \n  Nice If You Have: \n \n  Experience with MongoDB, MySQL, Airflow, Apache Spark, or PySpark \n  Experience with large-scale, distributed systems design and development \n  Experience with machine and deep learning concepts and algorithms \n  Knowledge of scripting languages, including Python, Node, or Bash \n  Knowledge of scaling, performance, and scheduling \n  Knowledge of system architecture, including process, memory, storage, and networking management \n  Possession of excellent analytical and problem-solving skills \n  Master's degree in Computer Science or a related field \n \n \n  Vetting: \n  Applicants selected will be subject to a government investigation and may need to meet eligibility requirements of the U.S. government client. \n \n  Create Your Career: \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll build your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $58,400.00 to $133,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.", "cleaned_desc": " \n \n \n \n \n \n         Full Stack Software Engineer\n           The Opportunity: \n  Are you looking for an opportunity to combine your technical skills with big picture thinking to make an impact in healthcare? You understand your customer\u2019s environment and how to develop the right systems for their mission. Your ability to translate real-world needs into technical specifications makes you an integral part of delivering a customer focused engineering solution. \n \n  As a software engineer on our team, you have the chance to design systems in support of a federal client's healthcare initiatives. Your technical expertise will be vital as you evaluate and modernize legacy systems. You\u2019ll develop your skills in cloud technologies while gaining experience in healthcare. Join our team and help turn requirements into accomplishments that drive change. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  3+ years of experience with architecting, integrating, and developing software systems in Java, J2EE, Scala, or Python \n  Experience with ElasticSearch or Hibernate \n  Experience in interacting with Cloud infrastructure providers, including AWS \n  Experience with DevOps methods and tools, including Jenkins, Git, SVN, Jira, Cucumber, Docker, or Kubernetes \n  Experience with all phases of the software development life cycle (SDLC) using Agile methods \n  Knowledge of Microservices development and designing and implementing RESTful Web services    Knowledge of JavaScript frameworks, including Angular or React \n  Knowledge of object-oriented programming (OOP) and designing, developing, and communicating complex software solutions \n  Ability to obtain and maintain a Public Trust or Suitability/Fitness determination based on client requirements \n  Bachelor's degree \n \n \n  Nice If You Have: \n \n  Experience with MongoDB, MySQL, Airflow, Apache Spark, or PySpark \n  Experience with large-scale, distributed systems design and development \n  Experience with machine and deep learning concepts and algorithms \n  Knowledge of scripting languages, including Python, Node, or Bash \n  Knowledge of scaling, performance, and scheduling \n  Knowledge of system architecture, including process, memory, storage, and networking management \n  Possession of excellent analytical and problem-solving skills \n  Master's degree in Computer Science or a related field \n \n \n  Vetting: \n  Applicants selected will be subject to a government investigation and may need to meet eligibility requirements of the U.S. government client. \n \n  Create Your Career: ", "techs": ["java", "j2ee", "scala", "python", "elasticsearch", "hibernate", "aws", "jenkins", "git", "svn", "jira", "cucumber", "docker", "kubernetes", "microservices", "restful web services", "angular", "react", "mongodb", "mysql", "airflow", "apache spark", "pyspark", "python", "node", "bash", "machine learning", "deep learning", "system architecture"]}, "4e4151dd6576d550": {"terms": ["machine learning engineer"], "salary_min": 78000.0, "salary_max": 141000.0, "title": "Unified Communications and Collaboration (UCC) Engineer", "company": "Leidos", "desc": "Description   \n Looking for an opportunity to make an impact?  \n \n At Leidos, we deliver innovative solutions through the efforts of our diverse and talented people who are dedicated to our customers\u2019 success. We empower our teams, contribute to our communities, and operate sustainable. Everything we do is built on a commitment to do the right thing for our customers, our people, and our community. Our Mission, Vision, and Values guide the way we do business. \n \n  If this sounds like a mission you want to be a part of, keep reading! \n \n  Civilian Health Solutions  uses a wide range of capabilities in Digital Modernization, Mission Software Systems, and enabling technologies like Artificial Intelligence and Machine Learning to support our customers\u2019 mission in advancing biomedical research and protecting public health. Our team\u2019s focus is ensuring our health customers have the right solutions to keep pace with an ever-evolving public health landscape and prevent the next public health crisis. To explore and learn more, click here! \n \n  Your greatest work is ahead! \n \n  Job Description \n  Leidos\u2019 Civilian Health Solutions Operation is seeking a dynamic, mission-centric hands-on seasoned  Unified Communications and Collaboration (UCC) Engineer  with a focus on Microsoft Teams. This position would support a federal agency\u2019s large, mission-critical enterprise in conjunction with the networks security team. The ideal candidate will leverage extensive knowledge in UCC platforms, Microsoft Teams, to facilitate seamless communication and collaboration supporting users internal and external to customers\u2019 network. The UCC Engineer will support the UCC infrastructure, ensuring seamless communication and collaboration through voice, video streaming, conferencing, messaging, and other advanced UCC technologies. This role demands a mix of technical expertise, user training, system integration and work with third-party vendors to ensure uninterrupted, top-tier communication services. The candidate must possess strong communications skills and the demonstrated ability to convey technical concepts to non-technical audiences. \n \n  Primary Responsibilities \n \n  Engineer, design, and provide operational support for the UCC infrastructure. \n  Provide 24x7x365 engineering and operational support services. \n  Ensure critical infrastructure protection, vulnerability remediation, and information assurance. \n  Manage and maintain UCC systems, performing routine patch management and security updates. \n  Document technical architecture, configurations, alert thresholds, and operational parameters. \n  Oversee software and hardware installation, configuration, support, maintenance, and troubleshooting. \n  Implement and maintain monitoring, logging, and alerting for UCC infrastructure using agencies\u2019 standard tools. \n  Deliver training materials, user guides, and online instructional material. \n  Provide consultation, guidance, and direct support to users. \n  Work in close coordination with software and hardware vendors for technical support and troubleshooting. \n  Conduct research, development, and testing on next-generation UCC technologies. \n  Stay updated with and support a range of technical tools as required by the federal agency. \n  Work collaboratively with other departments, ensuring seamless UCC services integration. \n  Collaborate with fellow team members, networking, and infrastructure teams to support an environment comprising of the tools listed below, but not limited to:\n    \n  Microsoft: Skype for Business Server 2015 (System) \n  Microsoft Skype for Business Client 2016 (Endpoint) \n  Microsoft Unified Messaging 2010, 2013 & O365 (System) \n  ServiceNow IT Service Management \n  Polycom: VVX600 (Endpoint) \n  Cisco: Telepresence Video Communication Server (VCS) Control, WebEx \n  Adobe: Adobe Connect \n  CA: SiteMinder (SSO) \n  AMX: Audio-Visual & Control Products \n  SMART Technologies: Interactive Whiteboards \n \n  Provide Software support on:\n    \n  Video streaming solutions \n  Live/VOD/Mobile player adoption and integration \n  Digital Rapids encoding system and Adobe AMS streaming solution \n  Video-rich Flash websites \n  Browser technologies including HTML/DHTML, JavaScript, JSP, Ajax, and web servers \n  Adobe Flex or Microsoft .NET (C++, C#) \n  N-tier web applications using Microsoft. Net, Java, Action Script, and JavaScript \n  Integration and tuning of third-party components (e.g., codec, streaming, monitoring, and hosting video files) \n  AMX programming in high-level programming languages, such as C, C++, or Java \n \n \n \n  Required Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, IT, Telecommunications, or a related field. \n  Minimum of  5 years of experience  in Unified Communications, with at least 3 years focused on Microsoft Teams. \n  Strong understanding of VoIP, video conferencing, and collaboration tools. \n  Familiarity with integrating Microsoft Teams in hybrid environments. \n  ITIL Foundations certification (or the ability to obtain it within 3 months after starting) \n \n \n  Preferred Qualifications: \n \n  Microsoft 365 Certified: Teams Administrator Associate or equivalent certification. \n  Experience with other UCC platforms like Cisco Webex, Zoom, Slack and Zabber. \n  Knowledge in scripting or programming for automation and integration tasks. \n \n \n  Pay Range:  Pay Range $78,000.00 - $141,000.00\n  \n  The Leidos pay range for this job level is a general guideline only and not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other law. \n  #Remote", "cleaned_desc": "  Live/VOD/Mobile player adoption and integration \n  Digital Rapids encoding system and Adobe AMS streaming solution \n  Video-rich Flash websites \n  Browser technologies including HTML/DHTML, JavaScript, JSP, Ajax, and web servers \n  Adobe Flex or Microsoft .NET (C++, C#) \n  N-tier web applications using Microsoft. Net, Java, Action Script, and JavaScript \n  Integration and tuning of third-party components (e.g., codec, streaming, monitoring, and hosting video files) \n  AMX programming in high-level programming languages, such as C, C++, or Java \n \n \n \n  Required Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, IT, Telecommunications, or a related field. \n  Minimum of  5 years of experience  in Unified Communications, with at least 3 years focused on Microsoft Teams. ", "techs": ["live/vod/mobile player adoption and integration", "\ndigital rapids encoding system and adobe ams streaming solution", "\nvideo-rich flash websites", "\nbrowser technologies including html/dhtml", "javascript", "jsp", "ajax", "and web servers", "\nadobe flex or microsoft .net (c++", "c#)", "\nn-tier web applications using microsoft. net", "java", "action script", "and javascript", "\nintegration and tuning of third-party components (e.g.", "codec", "streaming", "monitoring", "and hosting video files)", "\namx programming in high-level programming languages", "such as c", "c++", "or java"]}, "bee143924d9ca215": {"terms": ["machine learning engineer", "mlops"], "salary_min": 162496.6, "salary_max": 205756.9, "title": "Lead Product Security Engineer - US Remote", "company": "Weights & Biases", "desc": "At Weights & Biases, our mission is to build the best developer tools for machine learning. Weights & Biases is a series C company with $250 million in funding and a rapidly growing user base. Our platform is an essential piece of the daily work for machine learning engineers, from academic research institutions like FAIR and UC Berkeley to massive enterprise teams including iRobot, OpenAI, Toyota Research Institute, Samsung, NVIDIA, Salesforce, Blue Cross Blue Shield, Lyft, and more.\n  \n \n \n  Reporting to the CISO, the Lead Product Security Engineer will directly contribute to securing the Weights & Biases platform that powers our customer's MLOps workflows. Providing both tools and guidance, the Lead Product Security Engineer will enable engineers to deliver our product securely. You will also be the technical leader of our security team responsible for mentoring and growing the team.\n  \n Responsibilities: \n \n  Build security into each stage of the software development lifecycle through the use of automated tools and processes \n  Collaborate with product and engineering on design reviews and threat models \n  Review code for implementation misconfigurations, vulnerabilities, and business logic flaws \n  Triage and respond to reports from our bug bounty and vulnerability disclosure program \n  Collaborate with our compliance team to mitigate risks related to security \n  Mentor and grow the security team  \n \n Requirements: \n \n  Deep understanding of modern security principles including encryption, authn/authz, vulnerability management, etc. \n  Experience building security controls into a CI/CD environment \n  Solid understanding of threat modeling techniques such as RTMP, PASTA, STRIDE, etc. \n  Experience reviewing security scans and remediating vulnerabilities \n  Experience writing software in a production setting, ideally with TypeScript, Go, and/or Python \n  Effective written and verbal communication skills \n  Experience with multiple clouds. We're primarily on GCP but also deploy into AWS and Azure \n  Willingness to both teach others and learn new techniques \n \n \n   We encourage you to apply even if your experience doesn't perfectly align with the job description as we seek out diverse and creative perspectives. Team members who love to learn and collaborate in an inclusive environment will flourish with us. We are an equal opportunity employer and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. If you need additional accommodations to feel comfortable during your interview process, reach out at careers@wandb.com.\n  \n \n \n  #LI-Remote", "cleaned_desc": "  Experience building security controls into a CI/CD environment \n  Solid understanding of threat modeling techniques such as RTMP, PASTA, STRIDE, etc. \n  Experience reviewing security scans and remediating vulnerabilities \n  Experience writing software in a production setting, ideally with TypeScript, Go, and/or Python \n  Effective written and verbal communication skills \n  Experience with multiple clouds. We're primarily on GCP but also deploy into AWS and Azure ", "techs": ["ci/cd environment", "rtmp", "pasta", "stride", "typescript", "go", "python", "gcp", "aws", "azure"]}, "e21ee349a0f6e782": {"terms": ["machine learning engineer"], "salary_min": 83500.0, "salary_max": 122000.0, "title": "Scientific Image Processing Development Engineer", "company": "Kodak Alaris", "desc": "Kodak Alaris is a global technology company that\u2019s delivering future value through customer solutions. Our advanced, patented intellectual property combines breakthrough technologies, digital transformation, and human know-how to unlock the power of images and information. We make businesses run faster, governments run smarter and provide consumers innovative solutions to preserve and enjoy their most cherished memories. Our future is powered by our employees\u2019 creativity. Expect a lot from Kodak Alaris and know that we expect a lot of ourselves and the performance of the company. \n \n  Kodak Moments \n \n  Kodak Moments is a leading global provider of photo products and services to retailers, consumers, and entertainment properties. We inspire consumers to bring their memories to life--delivering innovative, high-quality photo products and experiences they find truly meaningful. Powered by over 100,000 consumer touchpoints across 30 countries globally, it's our mission to be the brand consumers choose to celebrate and preserve life's memories, from the big events to the everyday moments that matter. \n \n \n Job Summary: \n  We are looking for an individual with image processing, image science, and machine learning experience. This position will be the beginning or continuation of a career to commercialize imaging algorithms that will be used to create customized image products. The ideal candidate should have both the desire and ability to become an expert in digital image processing, digital and analog image science, and machine learning that will be applied to digital imaging. The candidate will work with senior Kodak Alaris experts in these areas to become an expert themselves in the use and application of digital image processing for the Kodak Moments business. \n The candidate\u2019s job duties will focus primarily on the development and implementation of image processing and machine learning algorithms to support Kodak Alaris products and services, as well as the analysis and resolution of issues found. \n \n \n Responsibilities: \n \n \n Work in all phases of the development lifecycle, including requirements definition, software/systems design, implementation, testing, integration, and system support. \n Integrate new image processing capabilities into our imaging system, supported by AI/ML or classic image processing. \n Identify and implement fixes for image processing failures and system performance, either in AI/ML or classical image processing spaces. \n Identify patentable ideas and work with the patent coordinator to write and file patents. \n Assist image product teams in the definition, design, development or purchase of imaging technology to meet product goals. \n Lead, maintain and improve our existing in-house algorithms and models, including continuous evaluation, gap analysis, re-training and fine tuning. \n Work collaboratively with software engineers, quality assurance engineers, image scientists, and product owners/managers on product delivery. \n Align support from the product, business, and customer engagement teams to identify technical challenges, propose technical approaches, and demonstrate innovative technical capabilities. \n \n Required Qualifications: \n \n \n Minimum of a Bachelor of Science in any of the following fields: Computer Science/Engineering, Mathematics, Physics, Image Science or related Science or Engineering discipline. \n Strong physics and mathematical background including Calculus, Linear Algebra, first order optics, classical algebra, trigonometry, probability and statistics. \n Strong programming and development skills (C, C++, Python) that utilizes software development best practices to solve scientific and engineering problems for production use. \n Excellent problem-solving skills, including the ability to debug/profile the code. \n Proficiency with fundamental computer vision algorithms such as object detection, classification, and segmentation. \n Hands on experience working with large imagery data sets including image normalization, image augmentation, raster/vector visualization, etc. \n Ability to work collaboratively with other software engineers, quality assurance engineers, image scientists, AI/ML experts and product owners/managers. \n Proficiency with OpenCV. \n \n Desired Qualifications: \n \n \n Cloud Experience (AWS, GCP, Azure). \n Familiarity with Docker and Kubernetes. \n Additional mathematics background, including but not limited to: 2D and 3D graphics processing and visualization. \n Additional physics backgrounds, higher level optics, digital and/or analog photography. \n Digital image processing, including but not limited to: brightness/contrast enhancement, sharpening, ICC color profiles, resampling and anti-aliasing, image compression and file formats (e.g., JPEG, TIFF, PNG, HEIC, SVG), video compression and file formats (e.g., MP4, H.264, H.265), open source software libraries (e.g., OpenCV, GraphicsMagick, FFMpeg). \n Digital and analog Image science, including but not limited to: color and sharpness targets, generation of ICC profiles for devices such as color printers, image quality assessment metrics and techniques, color spaces. \n Machine learning/artificial intelligence as applied to digital imaging, including but not limited to: face detection, facial feature finding, smile detection, head pose determination, image quality score, subject/background detection and replacement. \n C# language programming skills: ability to read, understand, and modify existing code. \n Software configuration management skills (e.g., git, ClearCase). \n \n \u201cNotice:  This job may require completion of a simulated work assessment as part of the hiring process. Kodak Alaris utilizes a third-party provider called Woven Teams, Inc. (\u201cWoven\u201d) to administer simulated work assessments on its behalf. By submitting an application for this position, you consent to us providing your email address to Woven solely for the purpose of allowing them to contact you with details regarding completion of a simulated work assessment. Access to and use of Woven applications and web pages is subject to any third-party terms made available by Woven at the time of access.\u201d \n Visa Sponsorship not available. \n $83,500 - $122,000 annually based on experience. \n \n Link to NY Labor Law Posters:  https://dol.ny.gov/posting-requirements-0 \n \n  Kodak Alaris provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. \n As a member of the Kodak Alaris team you will be eligible to participate in our flexible benefits program which include paid flexible time off, health, dental and vision coverage, paid sick leave, paid parental leave, 401(k) plan with company match, short-term and long term disability coverage and life insurance.", "cleaned_desc": " \n Responsibilities: \n \n \n Work in all phases of the development lifecycle, including requirements definition, software/systems design, implementation, testing, integration, and system support. \n Integrate new image processing capabilities into our imaging system, supported by AI/ML or classic image processing. \n Identify and implement fixes for image processing failures and system performance, either in AI/ML or classical image processing spaces. \n Identify patentable ideas and work with the patent coordinator to write and file patents. \n Assist image product teams in the definition, design, development or purchase of imaging technology to meet product goals. \n Lead, maintain and improve our existing in-house algorithms and models, including continuous evaluation, gap analysis, re-training and fine tuning. \n Work collaboratively with software engineers, quality assurance engineers, image scientists, and product owners/managers on product delivery.   Align support from the product, business, and customer engagement teams to identify technical challenges, propose technical approaches, and demonstrate innovative technical capabilities. \n \n Required Qualifications: \n \n \n Minimum of a Bachelor of Science in any of the following fields: Computer Science/Engineering, Mathematics, Physics, Image Science or related Science or Engineering discipline. \n Strong physics and mathematical background including Calculus, Linear Algebra, first order optics, classical algebra, trigonometry, probability and statistics. \n Strong programming and development skills (C, C++, Python) that utilizes software development best practices to solve scientific and engineering problems for production use. \n Excellent problem-solving skills, including the ability to debug/profile the code. \n Proficiency with fundamental computer vision algorithms such as object detection, classification, and segmentation. \n Hands on experience working with large imagery data sets including image normalization, image augmentation, raster/vector visualization, etc.   Ability to work collaboratively with other software engineers, quality assurance engineers, image scientists, AI/ML experts and product owners/managers. \n Proficiency with OpenCV. \n \n Desired Qualifications: \n \n \n Cloud Experience (AWS, GCP, Azure). \n Familiarity with Docker and Kubernetes. \n Additional mathematics background, including but not limited to: 2D and 3D graphics processing and visualization. \n Additional physics backgrounds, higher level optics, digital and/or analog photography. \n Digital image processing, including but not limited to: brightness/contrast enhancement, sharpening, ICC color profiles, resampling and anti-aliasing, image compression and file formats (e.g., JPEG, TIFF, PNG, HEIC, SVG), video compression and file formats (e.g., MP4, H.264, H.265), open source software libraries (e.g., OpenCV, GraphicsMagick, FFMpeg). ", "techs": ["opencv", "aws", "gcp", "azure", "docker", "kubernetes", "opencv", "graphicsmagick", "ffmpeg"]}, "33e2fb122e93fc87": {"terms": ["machine learning engineer"], "salary_min": 121282.83, "salary_max": 153571.08, "title": "Founding Engineer (Full Stack Software)", "company": "Cyberjin", "desc": "Hybrid/Remote role \n  Locations in multiple States \n  Our client is looking for a Founding Engineer (Full Stack Software) to join our team! You will lead the development of our Core Product: a soil carbon measurement, reporting, and verification (MRV) platform. As the first technical hire, you will work directly with the founders and own the entire technology stack, including making product decisions. You will set the technical roadmap and have the opportunity to build out a world-class technical team and culture as you see best. \n  Ideal candidate traits \n  5+ years of experience building and owning a complete end-to-end technology stack (Frontend + Backend + Cloud + CI/CD) \n  A track record of shipping and going through the full product development cycle right from writing the first line of code to product in the hands of users and iterating quickly on feedback \n  Experience with setting up the technology stack and development infrastructure from Day 1 and scaling it with growth \n \n Ability to develop infrastructure/pipelines to support Machine Learning / Remote Sensing workflows \n \n  Proactive and collaborative self-starter with a strong ability to attract other top technical talent and lead them effectively \n \n \ufe0f Past experience working in climate/agriculture is not a requirement, but a passion for climate is a plus! \n \ufe0f Past multidisciplinary teamwork (i.e. e.g. working on software in healthcare) is a huge plus, as you will be working with an interdisciplinary team with expertise in AI, Remote Sensing, Carbon Markets, Soil Carbon Modeling, Sustainable Finance \n \n  Machine Learning and Remote Sensing experience is not required, but understanding how to support these workflows (e.g. setting up data pipelines, setting up infrastructure to parallelize model runs, automating the deployment of models to integrate with the core MRV product) is a huge bonus! \n  You care deeply about climate change and feel a strong moral responsibility to act now. This extends into all facets of your life: both personal and professional. No action is too small and no goal is too big. Whether you have turned vegan or swear by public transport, we are big believers in embracing sustainability as a mindset and would love to learn what this means for you! \n   \n SE44bPSPU5", "cleaned_desc": "  Experience with setting up the technology stack and development infrastructure from Day 1 and scaling it with growth \n \n Ability to develop infrastructure/pipelines to support Machine Learning / Remote Sensing workflows ", "techs": ["technology stack", "development infrastructure", "machine learning", "remote sensing workflows"]}, "f6cbee269e6447fb": {"terms": ["machine learning engineer"], "salary_min": 160000.0, "salary_max": 190000.0, "title": "Senior Software Engineer", "company": "Q Bio", "desc": "Q Bio is building technology for the Physical of the Future that measures more, faster and cheaper about the human body, to enable proactive primary care for all. We're revolutionizing primary care with the first clinical digital twin platform, powered by breakthrough whole-body scanning technology, that highlights the most important changes in a person\u2019s physiology for sharing with physicians and specialists anywhere in the world.\n  \n \n \n  Join us! \n \n \n \n  Q Bio\u2019s clinical digital twin platform, Gemini, is the first to capture and monitor comprehensive baseline patient health in a scalable virtual model. The Gemini Dashboard highlights the most important chemical and anatomical changes in an individual weighted by an individual\u2019s lifestyle, genetic and medical history, that can be securely shared with physicians and specialists all over the world.\n  \n \n \n  Gemini is powered by the fastest, most accessible, whole body scanner developed: the Mark I. Self-driving and optimized for primary care, the Mark I can complete a whole-body scan in 15 minutes or less in an open space, without radiation, breath holds, or claustrophobia. Patient comfort is maximized with the option to sit, stand, or lie down, and real-time telemetry is displayed throughout.\n  \n \n \n  Why should you consider a career with Q Bio? \n \n \n \n  We dream big. Our team is aligned and excited about the opportunity to save lives and understand the human body like never before. We know how critical empowering and supportive leadership is, both to our excellence as a company, and for our team experience as a whole, and our leadership team will empower and support career growth. We\u2019re a team of engineers, scientists, and operators who come from a diverse background of disciplines and experiences. We value teamwork, growth, determination and persistence, commitment to collaboration, and a reliance on staying nimble while keeping the big picture in mind.\n  \n \n \n  Team Structure \n \n \n   The Radiomics Engineering Team is divided into four smaller teams: Image Acquisition/Pulse Sequence Design, Image Reconstruction, Image Post-processing, and Hardware Engineering. While each team functions independently, we value cross-pollination of ideas, open discussion, and sharing of knowledge. As a company, we all work towards the primary goal of developing a reproducible, non-invasive, and high-speed whole body exam.\n  \n \n \n  Role:  If you are passionate about writing innovative, high performance software, come join our engineering team! As a key player bringing advanced experience in software development, you will work alongside Image Processing Engineers and Machine Learning Scientists to deliver the future generations of our technology:\n  \n \n   - Cloud-based algorithmic pipelines for image processing\n  \n \n   - Tooling for ML: data management, model training, validation and deployment \n  \n Responsibilities \n \n  Design, implement, document, validate, release and maintain algorithmic software components \n  Improve infrastructure and tooling: machine learning toolkits, test frameworks and CI/CD pipelines \n  Design and deploy cloud-based infrastructure and services \n  Participate in cross-functional efforts such as clinical validations and releases of the software \n  Mentor other engineers and continuously improve our engineering practices and culture \n \n  Qualifications: \n \n  Minimum Bachelor\u2019s degree in Computer Science or related is required; advanced degree preferred \n  5+ year(s) of relevant industry experience in a software company \n  Expert proficiency in Python \n  Experience with cloud computing platforms such as AWS \n  Experience with source control and code reviews \n  Ability to read low level documentation and architect solutions \n  Familiarity with DevOps methodologies, CI/CD pipelines and containerization technologies such as Docker \n  Exceptionally clear communication with software engineers and scientists \n  Ability to work independently and as part of a team in a fast-paced startup environment \n \n  Nice to have: \n \n  Apache Airflow for data pipelines \n  Experience with infrastructure as code (IaC) tools such as CloudFormation \n  Knowledge of machine learning workflows at scale: from training to deploying models; Deep learning frameworks: Pytorch, TensorFlow \n  Experience with database design and management systems such as PostgreSQL \n  Strong understanding of networking \n  Knowledge of security best practices and compliance requirements, such as HIPAA. \n \n  Benefits offered by Q Bio include: \n \n  Competitive salary and equity in a well-funded, early stage startup \n  Healthcare, vision, and dental coverage for you and your dependents \n  Progressive paid family leave and sick leave plans \n  Complimentary annual Q Exam \n  Personalized catered meals every day \n  Opportunity to work on a highly interdisciplinary team and at the cutting edge of digital health tech \n \n \n   In the San Francisco Bay Area, the standard pay range for this role is $160,000-$190,000 annualized. This pay range is for the San Francisco Bay Area and is not applicable to locations outside of this location or for remote roles. Actual amounts will vary depending on experience, performance, and work location. In addition to a competitive base salary, we offer significant equity and an employee-friendly stock option plan. Employees will also be eligible to participate in benefits plans available to other similarly situated employees subject to any eligibility requirements imposed by such plans.\n  \n \n \n  Q Bio was founded in 2015 by serial entrepreneur Jeffrey Kaditz, Dr. Michael Snyder, Chair of Genetics and Director of Personalized Medicine at Stanford University, and Dr. Garry Choy, physician, radiologist, and former Chief Medical Information Officer at Mass General Hospital. Q Bio has raised over $80M from world class investors including Andreessen Horowitz, Kaiser Foundation Hospitals, Khosla Ventures, Founders Fund, SciFi VC, and many more.\n  \n \n \n  Q Bio is an Equal Opportunity Employer and we value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.", "cleaned_desc": "   - Cloud-based algorithmic pipelines for image processing\n  \n \n   - Tooling for ML: data management, model training, validation and deployment \n  \n Responsibilities \n \n  Design, implement, document, validate, release and maintain algorithmic software components \n  Improve infrastructure and tooling: machine learning toolkits, test frameworks and CI/CD pipelines \n  Design and deploy cloud-based infrastructure and services \n  Participate in cross-functional efforts such as clinical validations and releases of the software \n  Mentor other engineers and continuously improve our engineering practices and culture \n \n  Qualifications: \n \n  Minimum Bachelor\u2019s degree in Computer Science or related is required; advanced degree preferred \n  5+ year(s) of relevant industry experience in a software company    Expert proficiency in Python \n  Experience with cloud computing platforms such as AWS \n  Experience with source control and code reviews \n  Ability to read low level documentation and architect solutions \n  Familiarity with DevOps methodologies, CI/CD pipelines and containerization technologies such as Docker \n  Exceptionally clear communication with software engineers and scientists \n  Ability to work independently and as part of a team in a fast-paced startup environment \n \n  Nice to have: \n \n  Apache Airflow for data pipelines \n  Experience with infrastructure as code (IaC) tools such as CloudFormation \n  Knowledge of machine learning workflows at scale: from training to deploying models; Deep learning frameworks: Pytorch, TensorFlow \n  Experience with database design and management systems such as PostgreSQL \n  Strong understanding of networking \n  Knowledge of security best practices and compliance requirements, such as HIPAA. \n ", "techs": ["cloud-based algorithmic pipelines for image processing", "tooling for ml: data management", "model training", "validation and deployment", "python", "aws", "docker", "apache airflow", "cloudformation", "pytorch", "tensorflow", "postgresql"]}, "c7cd8d496fcb1f74": {"terms": ["machine learning engineer"], "salary_min": 21000.0, "salary_max": 21000.0, "title": "Senior Systems Engineer", "company": "G2 Ops, Inc.", "desc": "Number of Roles Open:  3 Full Time \n  Location:  San Diego, CA (in office  and   at customer site location) \n  Salary Range:  $120,000 - $180,000 + benefits \n  Start Date:  ASAP \n  Clearance Requirements:  Active DoD Secret required, Top Secret preferred. \n  Experience Requirements Role #1:  Qualified candidates must have clear NAVWAR C4I   systems   experience   and familiarity on  VLF or general RF/radio  knowledge. \n  Experience Requirements Role #2:  Qualified candidates must have clear  NAVWAR C4I  systems experience. \n  Experience Requirements Role #3:  Qualified candidates must have clear NAVWAR C4I   network hosting  experience. \n  What makes someone choose one company over another?  Pay, Benefits, Training, Work Satisfaction, Culture? What if you can have it all! At G2 Ops we have extremely competitive pay and benefits and that is not even the best part. Our culture is what sets us apart from other companies. Here, you will not be another payroll number or a cog in the machine. We provide great value to our customers by working as a team and ensuring every member is set up for success. Our team approach allows for each member to not only provide value with their expertise but also gives them the opportunity to cross train in other areas they have interest in. \n  Let's talk salary.  The salary range for these positions is  $120,000 - $180,000  based on what we are asking you to do, and your qualifications. We also offer a competitive benefits package and have fringe benefits offered throughout the year. The benefits have an estimated value of  $21,000  annually. With company standard annual performance reviews in place, plus on the spot awards for recognition, your performance will be rewarded and recognized, we promise! \n  So, you want to work from home?  Let's be honest, remote work is not always all it's cut out to be. At G2 Ops, we offer a flexible schedule to meet the needs of our employees and customers.  Due to the classification level of the projects we support, we are not able to offer fully remote opportunities at this time.  As a Defense Contractor, we are frequently working with sensitive material, and therefore, we need to ensure where you access your work is secure. You will have a shiny desk at the G2 Ops office, and certain positions  will be required to work   at a military site  directly with our customers (this is a good thing!). We do allow teleworking with prior approvals, but here's the thing, we have worked very hard to create an awesome culture where our employees get to come to a collaborative, exciting office environment. We want you to join the fun! \n  Still not convinced?  Allow us to elaborate. For these opportunities, we are seeking highly motivated, technology-focused, team-oriented  Systems Engineers  to join our team. These are critical roles for our company and the candidate would be required to interface with multiple services and stakeholders up to Flag level. This subject matter expert would be responsible for brief development, process development, technical/organizational problem solving, scheduling test and integration events, and implementing system engineering principles, as required.  \n What does this mean to you?  This is an exciting time to be part of a team that\u2019s impacting how engineering is being performed on a day-to-day basis. We\u2019re looking for  engineering experts  to lead our teams as we take on tough problems and build complex, highly sophisticated systems. Our ideal candidate will have a  Bachelor of Science Degree in engineering, computer science, or related  plus demonstrable  years of industry experience  (DoD military systems, C4I, Surface-, Undersea-, Air-, and Mine-warfare on military programs, etc.) Our desired candidate will be skilled in operational analysis and use case definition, plus requirements management and analysis. \n  We require a  bachelor\u2019s degree  from an accredited college or university (a technical degree in Computer Science, System Engineering, Information Systems is preferred) or additional applicable years of experience to be considered.  \n To be successful in this role,  you must be able to communicate clearly with stakeholders and engineering leadership teams to ensure requirements are clearly defined and Customer expectations are being met. The ability to analyze new and complex program-related problems and create innovative solutions that integrate schedule, technology, methodology, tools, and financial aspects are also critical components to this position.  \n Lastly, as we are working for the DoD, we are beholden to some requirements. These positions  require an  active DoD Secret Clearance , or higher, to be considered. \n  Congratulations , you made it all the way to the end of this job posting! We look forward to learning more about you! \n  Quick Note:  We are seeking full-time employees; the continuation of outside employment shall not constitute a conflict with the Company\u2019s interest, including performing work for a customer or competitor. \n  Benefits \n \n 100% company-paid insurance for medical, dental, and vision for eligible employees and family members \n 100% company-paid insurance for life, short-term (STD) and long-term disability (LTD) for eligible employees  \n 401(K) Plan with discretionary employer matching \n 10 paid holidays \n Paid time off (PTO) \n Educational assistance \n Work/life balance \n Family-oriented culture \n Competitive salaries \n \n About G2 Ops, Inc. \n G2 Ops, Inc. is a small business with big capabilities in cyber security architectural analysis, model-based systems engineering (MBSE), and strategic consulting in support of both government and commercial clients across the globe. As a trusted and reliable government contractor, we deliver cyber security & systems engineering support for integrated DoD weapons, communications, intelligence, and other mission-critical systems. In the commercial space, we provide business solutions analysis, strategic planning, and training and development services to a variety of public and private sector businesses and organizations. Through innovative solutions, exceptional employees, top-tier analytical capabilities, and a customer-centered focus, G2 Ops has established a reputation for service excellence and innovation. \n G2 Ops, Inc. is an Equal Opportunity Employer \n   \n KPJxQegc2J", "cleaned_desc": "", "techs": ""}, "9f4aa9e85825bc5a": {"terms": ["machine learning engineer"], "salary_min": 129000.0, "salary_max": 196000.0, "title": "Electrical Engineer, Analog/Power Systems", "company": "Meta", "desc": "Meta Reality Labs is building products that make it easier for people to connect with the ones they love most. We are a team of world-class experts developing and shipping products at the intersection of hardware, software, and content. Our team has the responsibility for taking breakthrough concepts and delivering them to market at scale. We are looking for a self-starter and a team player who can thrive in a dynamic environment. This candidate will own the analog/power design, integration, and validation of overall system-level solutions that push the boundaries of technology. Strong communications and organizational skill and the ability to multitask across various disciplines and tasks are a must.\n  \n \n \n Electrical Engineer, Analog/Power Systems Responsibilities:    \n \n Responsible for creating power models to estimate battery day of use, power circuit design, simulation, validation, and characterization across multiple products ensuring their successful delivery. \n  Generate design documentation, perform schematic capture and power delivery network simulation both pre and post board layout, prototype bring-up and design validation. \n  Characterize power consumption, battery run time, battery charging/discharging curve at each NPI build. Collect power measurements for weekly SW builds and drive power consumption optimization cross-functionally. \n  Root-cause and solve technical issues during new product development and support in field escalations. \n  Collaborate closely with cross-functional teams such as industrial design, architecture, product design, NPI, and supply chain. \n  Work closely with CM/JDM resources to leverage their engineers and maximize the focus of internal resources on adding value to and differentiating our product. \n  Evaluate and enable innovative solutions for cost, size, efficiency, safety, and reliability. \n \n \n \n \n Minimum Qualifications:   \n \n  BS or MS in Electrical Engineering or equivalent industry experience \n  4+ years of experience of low power design and delivery in consumer electronics or related fields \n  Knowledge of the characteristics of power conversion such as linear and switching regulators \n  Working experience in battery management system, mobile SoC and PMIC \n  Experience and knowledge of printed circuit board (PCB) technologies, such as rigid, flex, hybrid, HDI, etc. \n  Experience leading technical teams, cross-functional groups and vendors against plans \n \n \n \n \n Preferred Qualifications:   \n \n  Demonstrated experience in bringing new technologies to product \n  Experience performing bench level power measurements to validate battery life \n  Experience running PDN and PI simulations such as Sigrity or Hyperlynx \n  5+ years of experience of low voltage power design in consumer electronics or related fields \n  MS in Electrical Engineering or equivalent experience \n  System integration experience involving coex between PMICs and wireless sub-systems \n  Knowledge of the relationship between physical layout and electrical performance \n \n \n \n \n About Meta:    Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today\u2014beyond the constraints of screens, the limits of distance, and even the rules of physics.\n  \n \n \n \n  Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment. \n   \n  Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.", "cleaned_desc": " \n  BS or MS in Electrical Engineering or equivalent industry experience \n  4+ years of experience of low power design and delivery in consumer electronics or related fields \n  Knowledge of the characteristics of power conversion such as linear and switching regulators \n  Working experience in battery management system, mobile SoC and PMIC \n  Experience and knowledge of printed circuit board (PCB) technologies, such as rigid, flex, hybrid, HDI, etc. \n  Experience leading technical teams, cross-functional groups and vendors against plans \n \n   \n \n Preferred Qualifications:   \n \n  Demonstrated experience in bringing new technologies to product \n  Experience performing bench level power measurements to validate battery life \n  Experience running PDN and PI simulations such as Sigrity or Hyperlynx \n  5+ years of experience of low voltage power design in consumer electronics or related fields \n  MS in Electrical Engineering or equivalent experience ", "techs": ["bs or ms in electrical engineering", "low power design", "consumer electronics", "power conversion", "linear regulators", "switching regulators", "battery management system", "mobile soc", "pmic", "printed circuit board technologies", "rigid", "flex", "hybrid", "hdi", "technical teams", "cross-functional groups", "vendors", "new technologies", "product", "bench level power measurements", "battery life", "pdn simulations", "pi simulations", "sigrity", "hyperlynx", "low voltage power design"]}, "d10cd67a49ab968d": {"terms": ["machine learning engineer"], "salary_min": 160000.0, "salary_max": 190000.0, "title": "Senior Software Engineer", "company": "Q Bio", "desc": "Q Bio is building technology for the Physical of the Future that measures more, faster and cheaper about the human body, to enable proactive primary care for all. We're revolutionizing primary care with the first clinical digital twin platform, powered by breakthrough whole-body scanning technology, that highlights the most important changes in a person\u2019s physiology for sharing with physicians and specialists anywhere in the world.\n   \n \n \n  Join us! \n \n \n \n  Q Bio\u2019s clinical digital twin platform, Gemini, is the first to capture and monitor comprehensive baseline patient health in a scalable virtual model. The Gemini Dashboard highlights the most important chemical and anatomical changes in an individual weighted by an individual\u2019s lifestyle, genetic and medical history, that can be securely shared with physicians and specialists all over the world.\n   \n \n \n  Gemini is powered by the fastest, most accessible, whole body scanner developed: the Mark I. Self-driving and optimized for primary care, the Mark I can complete a whole-body scan in 15 minutes or less in an open space, without radiation, breath holds, or claustrophobia. Patient comfort is maximized with the option to sit, stand, or lie down, and real-time telemetry is displayed throughout.\n   \n \n \n  Why should you consider a career with Q Bio? \n \n \n \n  We dream big. Our team is aligned and excited about the opportunity to save lives and understand the human body like never before. We know how critical empowering and supportive leadership is, both to our excellence as a company, and for our team experience as a whole, and our leadership team will empower and support career growth. We\u2019re a team of engineers, scientists, and operators who come from a diverse background of disciplines and experiences. We value teamwork, growth, determination and persistence, commitment to collaboration, and a reliance on staying nimble while keeping the big picture in mind.\n   \n \n \n  Team Structure \n \n \n    The Radiomics Engineering Team is divided into four smaller teams: Image Acquisition/Pulse Sequence Design, Image Reconstruction, Image Post-processing, and Hardware Engineering. While each team functions independently, we value cross-pollination of ideas, open discussion, and sharing of knowledge. As a company, we all work towards the primary goal of developing a reproducible, non-invasive, and high-speed whole body exam.\n   \n \n \n  Role:  If you are passionate about writing innovative, high performance software, come join our engineering team! As a key player bringing advanced experience in software development, you will work alongside Image Processing Engineers and Machine Learning Scientists to deliver the future generations of our technology:\n   \n \n    - Cloud-based algorithmic pipelines for image processing\n   \n \n    - Tooling for ML: data management, model training, validation and deployment \n   \n \n \n \n Responsibilities \n \n \n  Design, implement, document, validate, release and maintain algorithmic software components \n  Improve infrastructure and tooling: machine learning toolkits, test frameworks and CI/CD pipelines \n  Design and deploy cloud-based infrastructure and services \n  Participate in cross-functional efforts such as clinical validations and releases of the software \n  Mentor other engineers and continuously improve our engineering practices and culture \n \n \n \n \n \n \n Qualifications: \n \n \n  Minimum Bachelor\u2019s degree in Computer Science or related is required; advanced degree preferred \n  5+ year(s) of relevant industry experience in a software company \n  Expert proficiency in Python \n  Experience with cloud computing platforms such as AWS \n  Experience with source control and code reviews \n  Ability to read low level documentation and architect solutions \n  Familiarity with DevOps methodologies, CI/CD pipelines and containerization technologies such as Docker \n  Exceptionally clear communication with software engineers and scientists \n  Ability to work independently and as part of a team in a fast-paced startup environment \n \n \n \n \n \n \n Nice to have: \n \n \n  Apache Airflow for data pipelines \n  Experience with infrastructure as code (IaC) tools such as CloudFormation \n  Knowledge of machine learning workflows at scale: from training to deploying models; Deep learning frameworks: Pytorch, TensorFlow \n  Experience with database design and management systems such as PostgreSQL \n  Strong understanding of networking \n  Knowledge of security best practices and compliance requirements, such as HIPAA. \n \n \n \n \n \n \n Benefits offered by Q Bio include: \n \n \n  Competitive salary and equity in a well-funded, early stage startup \n  Healthcare, vision, and dental coverage for you and your dependents \n  Progressive paid family leave and sick leave plans \n  Complimentary annual Q Exam \n  Personalized catered meals every day \n  Opportunity to work on a highly interdisciplinary team and at the cutting edge of digital health tech \n \n \n \n \n \n \n   In the San Francisco Bay Area, the standard pay range for this role is $160,000-$190,000 annualized. This pay range is for the San Francisco Bay Area and is not applicable to locations outside of this location or for remote roles. Actual amounts will vary depending on experience, performance, and work location. In addition to a competitive base salary, we offer significant equity and an employee-friendly stock option plan. Employees will also be eligible to participate in benefits plans available to other similarly situated employees subject to any eligibility requirements imposed by such plans.\n   \n \n \n  Q Bio was founded in 2015 by serial entrepreneur Jeffrey Kaditz, Dr. Michael Snyder, Chair of Genetics and Director of Personalized Medicine at Stanford University, and Dr. Garry Choy, physician, radiologist, and former Chief Medical Information Officer at Mass General Hospital. Q Bio has raised over $80M from world class investors including Andreessen Horowitz, Kaiser Foundation Hospitals, Khosla Ventures, Founders Fund, SciFi VC, and many more.\n   \n \n \n  Q Bio is an Equal Opportunity Employer and we value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.", "cleaned_desc": " \n  Design, implement, document, validate, release and maintain algorithmic software components \n  Improve infrastructure and tooling: machine learning toolkits, test frameworks and CI/CD pipelines \n  Design and deploy cloud-based infrastructure and services \n  Participate in cross-functional efforts such as clinical validations and releases of the software \n  Mentor other engineers and continuously improve our engineering practices and culture \n \n \n \n \n \n \n Qualifications: \n \n \n  Minimum Bachelor\u2019s degree in Computer Science or related is required; advanced degree preferred \n  5+ year(s) of relevant industry experience in a software company \n  Expert proficiency in Python \n  Experience with cloud computing platforms such as AWS \n  Experience with source control and code reviews \n  Ability to read low level documentation and architect solutions \n  Familiarity with DevOps methodologies, CI/CD pipelines and containerization technologies such as Docker    Exceptionally clear communication with software engineers and scientists \n  Ability to work independently and as part of a team in a fast-paced startup environment \n \n \n \n \n \n \n Nice to have: \n \n \n  Apache Airflow for data pipelines \n  Experience with infrastructure as code (IaC) tools such as CloudFormation \n  Knowledge of machine learning workflows at scale: from training to deploying models; Deep learning frameworks: Pytorch, TensorFlow \n  Experience with database design and management systems such as PostgreSQL \n  Strong understanding of networking \n  Knowledge of security best practices and compliance requirements, such as HIPAA. \n \n \n \n \n ", "techs": ["algorithmic software components", "machine learning toolkits", "test frameworks", "ci/cd pipelines", "cloud-based infrastructure", "cloud computing platforms (aws)", "source control", "code reviews", "python", "devops methodologies", "docker", "apache airflow", "infrastructure as code (iac) tools (cloudformation)", "machine learning workflows at scale", "deep learning frameworks (pytorch", "tensorflow)", "database design and management systems (postgresql)", "networking", "security best practices", "hipaa compliance."]}, "2de4ccad60043914": {"terms": ["machine learning engineer"], "salary_min": 151443.33, "salary_max": 191761.02, "title": "Staff Software Engineer", "company": "webAI", "desc": "Title:  Staff Software Engineer \n  Company:  WebAI \n  Location : Grand Rapids, MI; Austin, TX; or Remote \n  Type:  Full-Time, Salaried Exempt \n  Experience:  5+ years \n  Education:  Bachelor's Degree, minimum \n \n \n  About the Company: \n  WebAI is a leading technology company specializing in advanced artificial intelligence solutions. We are currently seeking an experienced Staff Software Engineer to join our team, where you'll play a critical role in shaping the architecture of our various systems and services. \n  Responsibilities: \n \n Design and architect scalable, robust, and secure system infrastructure to support WebAI's various product offerings. \n Collaborate with cross-functional teams, including software engineers, data scientists, and product managers, to ensure system design aligns with company objectives. \n Create and maintain documentation of system architecture, including diagrams and technical specifications. \n Evaluate new technologies and frameworks to improve performance, reliability, and scalability. \n Serve as the technical point of contact for architecture-related discussions and decisions. \n \n \n \n  Qualifications: \n \n Bachelor's or Master's degree in Computer Science, Information Systems, or related field. \n Minimum of 5 years of experience in system architecture or software engineering. \n Strong understanding of cloud computing, distributed systems, and microservices architecture. \n Expertise in programming languages such as Python, Java, or C++. \n Familiarity with data storage solutions, both SQL and NoSQL databases. \n Experience with Distributed Systems and FPGAs. \n Excellent communication skills, both written and verbal. \n \n \n Ability to work collaboratively in a team environment. \n Strong problem-solving skills and attention to detail. \n Demonstrated ability to manage multiple projects and meet deadlines. \n \n Nice To Have: \n \n Previous experience in a startup or fast-paced environment. \n Production experience developing services with Rust. \n Knowledge of machine learning and artificial intelligence. \n Experience with containerization technologies like Docker and Kubernetes. \n Certifications in cloud platforms like AWS, Azure, or Google Cloud. \n In-depth knowledge of FPGAs for hardware acceleration and parallel computing. \n \n Personality Traits: \n \n Confidence: Willingness to take ownership of projects and make informed decisions. \n Detail-Oriented: Thorough in reviewing and refining code to ensure accuracy and functionality. \n Mature: Professional demeanor and ability to handle challenges with composure. \n Organized: Efficiently manage tasks, projects, and priorities in a fast-paced environment. \n Team Player: Collaborate effectively with cross-functional teams to achieve common goals. \n Creative Thinker: Bring innovative ideas to the table for enhancing user experiences. \n \n Benefits: \n \n Competitive salary and performance-based incentives. \n Comprehensive health, dental, and vision benefits package. \n Flexible work week \n Free parking, for in-office employees \n Unlimited PTO \n Parental, Bereavement Leave \n \n If you're a self-driven Staff Software Engineer seeking an opportunity to make a significant impact within a forward-thinking company, we encourage you to apply. \n \n \n  WebAI is an Equal Opportunity Employer and does not discriminate against any employee or applicant on the basis of age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We adhere to these principles in all aspects of employment, including recruitment, hiring, training, compensation, promotion, benefits, social and recreational programs, and discipline. In addition, it is the policy of WebAI to provide reasonable accommodation to qualified employees who have protected disabilities to the extent required by applicable laws, regulations and ordinances where a particular employee works.", "cleaned_desc": " Collaborate with cross-functional teams, including software engineers, data scientists, and product managers, to ensure system design aligns with company objectives. \n Create and maintain documentation of system architecture, including diagrams and technical specifications. \n Evaluate new technologies and frameworks to improve performance, reliability, and scalability. \n Serve as the technical point of contact for architecture-related discussions and decisions. \n \n \n \n  Qualifications: \n \n Bachelor's or Master's degree in Computer Science, Information Systems, or related field. \n Minimum of 5 years of experience in system architecture or software engineering. \n Strong understanding of cloud computing, distributed systems, and microservices architecture. \n Expertise in programming languages such as Python, Java, or C++.   Familiarity with data storage solutions, both SQL and NoSQL databases. \n Experience with Distributed Systems and FPGAs. \n Excellent communication skills, both written and verbal. \n \n \n Ability to work collaboratively in a team environment. \n Strong problem-solving skills and attention to detail. \n Demonstrated ability to manage multiple projects and meet deadlines. \n \n Nice To Have: \n \n Previous experience in a startup or fast-paced environment. \n Production experience developing services with Rust.   Knowledge of machine learning and artificial intelligence. \n Experience with containerization technologies like Docker and Kubernetes. \n Certifications in cloud platforms like AWS, Azure, or Google Cloud. \n In-depth knowledge of FPGAs for hardware acceleration and parallel computing. \n \n Personality Traits: \n \n Confidence: Willingness to take ownership of projects and make informed decisions. \n Detail-Oriented: Thorough in reviewing and refining code to ensure accuracy and functionality. \n Mature: Professional demeanor and ability to handle challenges with composure. \n Organized: Efficiently manage tasks, projects, and priorities in a fast-paced environment. \n Team Player: Collaborate effectively with cross-functional teams to achieve common goals. \n Creative Thinker: Bring innovative ideas to the table for enhancing user experiences. ", "techs": ["collaboration", "software engineers", "data scientists", "product managers", "system design", "documentation", "diagrams", "technical specifications", "new technologies", "frameworks", "performance", "reliability", "scalability", "cloud computing", "distributed systems", "microservices architecture", "programming languages", "python", "java", "c++", "data storage solutions", "sql", "nosql databases", "distributed systems", "fpgas", "communication skills", "team environment", "problem-solving skills", "deadlines", "startup", "fast-paced environment", "rust", "machine learning", "artificial intelligence", "containerization technologies", "docker", "kubernetes", "certifications", "cloud platforms", "aws", "azure", "google cloud", "fpgas", "hardware acceleration", "parallel computing", "confidence", "detail-oriented", "mature", "organized", "team player", "creative thinker"]}, "2e5ed4dc2eacbdad": {"terms": ["machine learning engineer", "mlops"], "salary_min": 150074.3, "salary_max": 190027.48, "title": "Staff Engineer, DevOps", "company": "Valo Health", "desc": "About Us \n  Valo Health is a technology company that is integrating human-centric data and AI-powered technology to accelerate the creation of life-changing drugs for more patients faster. Valo was created with the belief that the drug discovery and development process can and should be faster and less expensive, with a much higher probability of success. We are using models early to fail less often, executing clinical trials to add valuation to the company, and generating fit-for-purpose data to feed back into Valo's Opal Computational Platform\u2122 as we reinvent drug discovery and development from the ground up. Disease doesn't wait, so neither can we. \n  We are a multi-disciplinary team of experts in science, technology, and pharmaceuticals united in our mission to achieve better drugs for patients faster. Valo is committed to hiring diverse talent, prioritizing growth and development, fostering an inclusive environment, and creating opportunities to bring together a group of different experiences, backgrounds, and voices to work together. We achieve the widest-ranging impact when we leverage our broad backgrounds and perspectives to accelerate a new frontier in health. Valo seeks to become the catalyst for the pharmaceutical industry and drive the digital transformation of the industry. Are you ready to join us? \n  About the Role \n  We are looking for DevOps engineers to help manage the AWS Cloud infrastructure for our Data Science and Machine Learning environments. A successful candidate should be equally adept in handling day-to-day problems encountered by our users, as well as able to see the larger picture and change our infrastructure to lower our overall operational costs and improve user experience. \n  What You'll Do\u2026 \n \n Handle a ticket duty to resolve user problems in an AWS Cloud Environment. \n Able to extract the general shapes of problems based on ad hoc tasks and find a technical path to automate away repetitive tasks and/or create tools and processes to allow self-service by users to decrease user burden. \n \n What You Bring... \n \n Proficient in Python, and shell scripting \n Proficient in administering AWS environments: Linux EC2 instances, EKS clusters, and general networking and security best practices. \n Comfortable with Software Engineering best practices such as the use of source control systems (specifically Git), code review, automated testing, and CI/CD pipelines \n Experience with GitLab, including the deployment and administration of a self-managed GitLab server (with GitLab CI) \n Familiar with automation of cloud deployment and blueprints (e.g. Terraform, Pulumi) \n \n More on Valo \n  Valo Health, Inc (\"Valo\") is a technology company built to transform the drug discovery and development process using human-centric data and artificial intelligence-driven computation. As a digitally native company, Valo aims to fully integrate human-centric data across the entire drug development life cycle into a single unified architecture, thereby accelerating the discovery and development of life-changing drugs while simultaneously reducing costs, time, and failure rates. The company's Opal Computational Platform\u2122 is an integrated set of capabilities designed to transform data into valuable insights that may accelerate discoveries and enable Valo to advance a robust pipeline of programs across cardiovascular metabolic renal, oncology, and neurodegenerative disease. Founded by Flagship Pioneering and headquartered in Boston, MA, Valo also has offices in Lexington, MA, and New York. To learn more, visit www.valohealth.com.", "cleaned_desc": " Proficient in Python, and shell scripting \n Proficient in administering AWS environments: Linux EC2 instances, EKS clusters, and general networking and security best practices. \n Comfortable with Software Engineering best practices such as the use of source control systems (specifically Git), code review, automated testing, and CI/CD pipelines ", "techs": ["python", "shell scripting", "aws", "linux ec2 instances", "eks clusters", "networking", "security best practices", "git", "code review", "automated testing", "ci/cd pipelines"]}, "4ba86ad27a4aed17": {"terms": ["machine learning engineer"], "salary_min": 160511.67, "salary_max": 203243.55, "title": "Sr. Staff Hardware Design Engineer", "company": "Recogni", "desc": "Sr. Staff Hardware Design Engineer \n  San Jose, CA \n \n \n  About our company - Recogni \n  Artificial intelligence (AI ) is  transforming  our world.  It can perform cognitive functions  that previously only humans  could do,  such  as perceiving interactions across different  environments  with the  ability  to quickly learn  and  then  solve complex problems . At Recogni we  have innovative  approaches to machine learning, high resolution imaging ,  perception  processing, and  high - performance computation  with industry- leading low power efficiency. We're a  well funded ,  fast -paced startup company with headquarters in  San Jose , CA, and Munich, Germany ; we also  have many talented team members  working  remotely.  We're at the leading edge of  advancing the  latest research  and  product  improvements for Al inference  solutions  that will make Al even  more useful  for compelling  new  applications. \n \n \n \n About the role \n  To keep pace in this exciting, multi-disciplinary field, we're looking for a Sr. Staff Hardware Design Engineer. You will be in a unique position to have ownership of a wide-ranging list of hardware system development aspects, including schematics, PCB layout and mechanical design, component selection and collaborating with operations in AVL management, EVT/DVT/PVT testing and certification. You will also have an opportunity to make impact on design and bringup of development systems, reference platforms and volume products. \n  This hands-on multi-disciplinary role provides a unique opportunity to interact directly with ASIC, camera sensor, software, product and operations teams to gather necessary requirements and specifications, and help set the overall methodology around hardware system development at Recogni. \n  Responsibilities \n \n Own multiple aspects of hardware system engineering of Recogni's flagship AI products. \n Gather requirements and specifications from engineering, product and operations teams for planning and implementing all hardware system deliverables, from lab bringup artifacts to reference system to shipping products. \n Hands on responsibility for the schematic capture, PCB design and other aspects of the hardware system around a complex custom AI ASIC. \n Plan for Compliance, Validation and FMEA Analysis for products. \n Drive hardware parts selection and vendor qualification processes in collaboration with manufacturing operations. \n \n Qualifications \n \n B.S. degree in Electrical or Computer Engineering. \n 10+ years of hardware engineering and experience with product-cycle aspects therein. \n Hands-on experience in all aspects of schematic capture, PCB design, as well as understanding signal integrity, mechanical and thermal design areas. \n Experience in part selection, AVL management and working with manufacturing operations teams. \n Previous involvement in representing engineering considerations in contract manufacturing relationships. \n Demonstrable experience with EVT, DVT, PVT testing and certification processes is a plus. \n Self-starter and highly-motivated to work in a dynamic start-up environment. \n \n \n \n Recogni is an equal opportunity employer. We believe that a diverse team is better at tackling complex problems and coming up with innovative solutions. All qualified applicants will receive consideration for employment without regard to age, color, gender identity or expression, marital status, national origin, disability, protected veteran status, race, religion, pregnancy, sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. \n  A note to Recruitment Agencies: Please don't reach out to Recogni employees or leaders about our roles - we've got it covered. We don't accept unsolicited agency resumes and we are not responsible for any fees related to unsolicited resumes. Thank you for your understanding.", "cleaned_desc": "", "techs": ""}, "790896b1a1109eb8": {"terms": ["machine learning engineer"], "salary_min": 101000.0, "salary_max": 173000.0, "title": "Senior Product Manager", "company": "Salesloft", "desc": "Job Title:  Senior Product Manager \n  Location:  Atlanta, Georgia \n \n  THE OPPORTUNITY: \n  Although we're proud of our history, we're just as excited about the future. We want to create a world-class culture and company that attracts, develops, engages and retains the nation's elite talent. \n  At Salesloft, our Product Managers are pivotal to our company's success. You will be a key member of our fast-growing and high-performing Product Management team, building innovative, industry-leading products and experiences (specifically data-related) for our customers. \n  In addition to working with amazing colleagues who exemplify our 'team over self' core value, you will also have the opportunity to drive innovation through cutting-edge product processes and product development technologies. You will have an opportunity to make a difference.       \n WHAT WE'RE LOOKING FOR: \n  We are seeking a talented Product Manager with proven experience building Conversations Intelligence or related AI-driven SaaS products. Familiarity with sales engagement and CRM platforms is highly advantageous. \n  We take technical objectives and combine them with insight into user problems we are uniquely suited to solve. The result: well-articulated product concepts, formulated with clear goals and benefits. \n  But that's just the beginning. We're the ones responsible for bringing together engineers, designers, and departments from around the company to ensure that our product is useful, delightful, and timely. And we release quality features 5-6 times per day, so our Product Managers love the fast pace, but more importantly, they love our 3,000+ customers. \n  On a day-to-day basis, you will be responsible for managing a highly collaborative, incredibly talented product delivery team by leading feature identification, prioritizing requirements, and defining product roadmaps that drive business goals and strategies. You'll collaborate with highly creative engineers, designers, researchers, and solutions consultants to reach the best possible version of a feature or product to bring to market. All while keeping your finger on the pulse of the market through market research and client interactions. \n  If you're passionate about sales technology, providing a world-class customer experience, and thrive in a fast-paced, hyper-growth startup environment, then becoming a Product Manager at Salesloft  is the career path for you! \n \n \n  THE TEAM: \n  Our Salesloft's Product Management team is comprised of seasoned and up-and-coming Product professionals who are all aligned on one mission: to redefine the Sales Engagement space and activate the authentic seller in all of us. \n  The Product Management team consists of highly motivated individuals who have a passion for building high-quality software that scales. They are deeply empathetic to serving the needs of our customers, understanding their points, and relentlessly prioritizing the most important work to serve them. They are also the epitome of our core values - Customers First. Team Over Self. Focus on Results. Bias Towards Action. Glass Half Full.     THE SKILL SET: \n \n 4+ years of experience delivering B2B SaaS products to market \n Experience partnering with design and engineering teams to solve challenging problems at scale \n Experience working with data driven products that generate insights for customers. Strong understanding of Conversations Intelligence, natural language processing, and machine learning technologies, particularly as applied to sales use cases is highly preferred. \n Strong customer and stakeholder empathy. \n Ability to distill complex requirements requests into easy-to-understand features and phases for delivery \n Experienced in working collaboratively to create, refine, and scope requirements with multiple, cross-functional stakeholders. \n Ability to develop and articulate written requirements and feature documentation \n Ability to effectively maintain a prioritized backlog of user stories, features and defects in a fast-paced environment \n Consistently using data to drive decisions and evaluate the success of features and overall health of the product \n Excellent communication skills and the ability to interface at all levels of the organization within and outside of the company \n Comfort in a fast-paced and dynamic environment \n A deep commitment to engaging and empowering the technologists who build our software. \n Bachelor's degree preferred \n \n \n \n  WITHIN ONE MONTH, YOU'LL: \n \n Learn Salesloft's core product development processes. Observe and understand our specific development processes and how features move through the development cycle. \n Onboard and learn development software stack (ie: Jira, Productboard, Confluence, etc.). Understand how they relate to the overall product life cycle. \n Effectively translate requirements into user stories with acceptance criteria. Identify requirement gaps needed for upcoming features. Groom and review the backlog with the team during planning sessions. Consult with development team, stakeholders, internal teams, and customers to gather feedback on upcoming features. \n Learn internal product processes such as Win/Loss interviews, customer interviews, and customer feedback processes. \n Shadow Saleslofters across the organization to understand how they use Salesloft and Salesloft's processes. \n Begin 1:1's with your manager, understand your 30-60-90 plan, meet & shadow current members of the Salesloft team, and delve into your product area \n Set your OKRs (Objectives and Key Results) with your manager and develop an action plan to achieve them \n \n WITHIN THREE MONTHS, YOU'LL: \n \n Successfully lead a development scrum team by running planning meetings, attending retrospectives and daily standups. Fully own the team backlog and identify high value features that align to the product vision. Leads requirements gathering effort on upcoming epics. \n Work closely with designers and engineering leads to scope complexity of upcoming features. Understand technical complexity when approaching epics and larger initiatives. Understand tradeoffs of time to build vs value to the customer. Able to communicate and negotiate tradeoffs with stakeholders to drive prioritization. \n Identify and scope appropriate MVP feature sets as they relate to the larger efforts of the product team. \n Write and communicate release documentation highlighting the customer pain point and the end solution. \n \n WITHIN SIX MONTHS, YOU'LL: \n \n Establish, track, and report progress on product metrics and KPIs for Product Leadership and internal stakeholders \n Identify key success metrics for a product surface and take ownership for evangelizing the surface with all Salesloft stakeholders. \n Conduct product feedback interviews with customers to solicit and gather feedback on existing features, as well as speak to new features coming up in development. \n Become certified in presenting the Product Vision to customers. Become comfortable talking about product vision with external stakeholders. \n \n WITHIN TWELVE MONTHS, YOU'LL: \n \n Be considered a subject matter expert in your product area, both internal stakeholders and externally with customers. \n Mentor junior members of the team, setting an example for Product Owners and motivating new team members. \n \n IS THIS ROLE NOT AN EXACT FIT? Keep an eye on our Careers Page for other positions! \n \n \n  WHY YOU'LL LOVE SALESLOFT: \n  At Salesloft, we're not just a company, we're a community built on shared values. \n \n \n  We put our customers first, prioritize our team over ourselves, focus on results, have a bias toward taking action, and choose to see the glass as half full. These values have been at the heart of our growth in becoming the #1 leader in sales engagement software, and we're still just getting started. \n \n \n  Salesloft helps sales teams drive more revenue with the only complete Sales Engagement platform available in the market. Salesloft is the one place for sellers and managers to go to execute all their digital selling tasks, communicate with buyers, understand what to do next, forecast with accuracy, and get the coaching and insights they need to win more deals. Thousands of the world's most successful sales teams, like those at Google, 3M, IBM, Shopify, Square, and Cisco, drive more revenue with Salesloft. \n \n \n  Since our founding in 2011, we have grown into a global, award-winning organization with Lofters based all over the world. As a testament to our organizational health, we have been named by Forbes as one of America's Best Startup Employers in 2021, Atlanta Business Chronicle's 2022 Healthiest Employers, three times by Deloitte as a 'Fastest-Growing Technology Company in North America,' and have been recognized as a top workplace by  Fortune, Glassdoor, Atlanta Journal-Constitution, and Inc Magazine . \n \n \n  In addition to our stand-out organizational health, G2 recently ranked us #1 in Enterprise Sales Engagement and we were named a leader in the 2022 Forrester Wave for Sales Engagement. We received the highest possible score in 26 out of 30 criteria, more than any other vendor evaluated in our category. \n \n \n  We're redefining an age-old industry. This is challenging work \u2013 but our team of driven innovators makes the journey thrilling. We're fast-paced, cutting-edge, and collaborative. We pursue excellence in everything we do and have a lot of fun along the way. Come join us! \n \n \n  Check us out on Glassdoor and see what people LOVE about working for Salesloft! \n \n  IS THIS ROLE NOT AN EXACT FIT?  Keep an eye on our Careers Page for other positions! \n \n \n  WHY SHOULD YOU WORK AT SALESLOFT: \n \n You will become part of an amazing culture with a supportive CEO and smart teammates who actually care \n You will work with an amazing team you can learn from and teach \n You will experience joining a high-growth/high-trajectory organization \n You will hear \"Yes, let's do that!\" and then have the opportunity to successfully execute on your ideas \n You will build community with Lofters of many cultures and backgrounds through ERGs and DEI initiatives \n We have a vibrant, open office that utilizes modern technology \n You will grow more here than you would anywhere else,  that is a promise \n \n \n \n  #li-remote \n \n \n  It is Salesloft\u2019s intent to pay all Lofters competitive wages and salaries that are motivational, fair and equitable. The goal of Salesloft\u2019s compensation program is to be transparent, attract potential employees, meet the needs of all current employees and encourage employees to stay with our organization. \n  Actual compensation packages are based on several factors that are unique to each candidate, including but not limited to skill set, depth of experience, certifications, and specific work location.    The total compensation package for this position may also include performance bonus, stock, benefits and/or other applicable incentive compensation plans.    Salesloft embraces diversity and invites applications from people of all walks of life. We are proud to be an Equal Opportunity Employer and provide equal employment opportunities to all employees and applicants without regard to race, color, religion, sex, age, national origin, disability, veteran status, pregnancy, sexual orientation, or any other characteristic protected by law. \n \n  Base Pay Range \n \n    $101,000\u2014$173,000 USD", "cleaned_desc": "", "techs": ""}, "9fc21100c0bb1280": {"terms": ["machine learning engineer"], "salary_min": 154615.88, "salary_max": 195778.16, "title": "Senior Cloud Software Engineer, Sensors", "company": "Job Board", "desc": "By making evidence the heart of security, we help customers stay ahead of ever-changing cyber-attacks. \n  Corelight is the cybersecurity company that transforms network and cloud activity into evidence. Evidence that elite defenders use to proactively hunt for threats, accelerate response to cyber incidents, gain complete network visibility and create powerful analytics using machine-learning and behavioral analysis tools. Easily deployed, and available in traditional and SaaS-based formats, Corelight is the fastest-growing Network Detection and Response (NDR) platform in the industry. And we are the only NDR platform that leverages the power of Open Source projects in addition to our own technology to deliver Intrusion Detection (IDS), Network Security Monitoring (NSM), and Smart PCAP solutions. We sell to some of the most sensitive, mission critical large enterprises and government agencies in the world. \n  In this role you will contribute to the development of our cloud-based Sensor solutions, focusing on making it as easy as possible for customers to deploy our Sensor technology with their preferred cloud provider. You will be creating resources for our customers to utilize such as Cloud Formation templates and reference architectures, crafting cloud-focused microservices in our Sensor product and ensuring that our software performs optimally in all supported cloud environments. \n  Role \n \n Provide technical expertise in planning, development, and execution of software efforts \n Implement functionality with appropriate test coverage and consideration of implications for product security and stability \n Engage in code-review and architectural analysis exercises \n Craft cloud-native automation solutions using tools such as Terraform in all of the major cloud providers (AWS, Azure, GCP, etc) \n Engineer software primarily in golang, while also crafting solutions using tools directly from cloud providers. \n \n Requirements \n \n 5+ years of Enterprise software design, development, and release experience \n 5+ years of development experience with Golang and/or Python \n 3+ years of design and hands-on experience crafting cloud topologies and networking solutions \n Experience deploying and managing Kubernetes clusters \n Experience with Git for version control \n Experience with Zeek or Suricata is a plus. \n Effective communicator and ability to collaborate across stakeholders \n Possess strong organizational skills, both for yourself and for the team while working with many people in a fast-paced environment \n Enjoys getting things done! \n \n \n \n We are proud of our culture and values - driving diversity of background and thought, low-ego results, applied curiosity and tireless service to our customers and community. Corelight is committed to a geographically dispersed yet connected employee base with employees working from home and office locations around the world. Fueled by an accelerating revenue stream, and investments from top-tier venture capital organizations such as Crowdstrike, Accel and Insight - we are rapidly expanding our team. \n  Check us out at www.corelight.com", "cleaned_desc": " Provide technical expertise in planning, development, and execution of software efforts \n Implement functionality with appropriate test coverage and consideration of implications for product security and stability \n Engage in code-review and architectural analysis exercises \n Craft cloud-native automation solutions using tools such as Terraform in all of the major cloud providers (AWS, Azure, GCP, etc) \n Engineer software primarily in golang, while also crafting solutions using tools directly from cloud providers.   \n Requirements \n \n 5+ years of Enterprise software design, development, and release experience \n 5+ years of development experience with Golang and/or Python   3+ years of design and hands-on experience crafting cloud topologies and networking solutions \n Experience deploying and managing Kubernetes clusters \n Experience with Git for version control \n Experience with Zeek or Suricata is a plus. \n Effective communicator and ability to collaborate across stakeholders ", "techs": ["terraform", "aws", "azure", "gcp", "golang", "python", "kubernetes", "git", "zeek", "suricata"]}, "e970a780ab85ed31": {"terms": ["machine learning engineer"], "salary_min": 80000.0, "salary_max": 105000.0, "title": "Senior Software Developer", "company": "Technergetics", "desc": "Position:  Senior  Software Developer \n \n \n  Beware of fraudulent job offers and postings!  Technergetics will never extend an offer of employment without a thorough interview process involving face to face interviews either in-person or a virtual Teams meeting from an official Technergetics email address ( @techngs.com ). If you receive any correspondence from an email other than  techngs.com , it is a scam. Pre-interview code testing is only administered through the  Codility  platform. We will not send out questionnaires or testing through any other platform/site prior to a first interview. \n \n \n  Opportunity Overview \n  Do you want to be an originator throughout the software development process and join a young, hungry, expanding business? Is learning a life-long pursuit for you? Traditional corporate culture (no sea of office cubicles here) not really your thing? Then this may be the place for you. Our software engineers work with teammates both native to the Mohawk Valley and across the country to deliver cutting-edge products to our customers. As an Associate Software Developer, you will work with peers and mentors to learn and evolve as a coder, task master and leader. Get fired up to join and remain fired up to perform!! \n \n \n  Position Details : \n  Salary Range:  $80,000-$105,000 a year. This is a full-time exempt position. \n  This is an 100% remote work arrangement! \n  Due to the clearance required for this position,  only U.S. citizens are eligible to apply ; as outlined in Executive Order 12968: Access to Classified Information, eligibility for access to classified information may only be granted to employees who are United States citizens. \n \n \n  Responsibilities and Duties \n  The successful candidate can participate, contribute, and document throughout the Software Development Lifecycle, including: \n \n \n The Senior Software Developer works independently designing and engineering new software products or major enhancements to existing software. \n May lead a team in design of highly complex software systems. Acts as highest-level technical expert, addressing problems of systems integration, compatibility, and multiple platforms. \n Works independently designing and engineering new software products or major enhancements to existing software. Devises or modifies procedures to solve complex problems considering computer equipment capacity and limitations, operating time and form of desired results. \n Designs, codes, tests, debug, and document those programs. Conducts code reviews of subordinate developers and peers. Competent to work at the highest technical level of all phases of applications programming activities. \n Coordinates with Cybersecurity team members to implement and maintain a SSDLC with an understanding of the NIST SP 800-63 RMF and the DoD implementation of RMF. \n \n \n \n   \n Education and Certifications: \n \n \n A Bachelor's Degree in Computer Science or comparable discipline is desired \n \n \n     IAT lvl II Certification\n     \n \n \n \n \n Qualifications: \n  Professional experience, knowledge, and skills in most of the following areas are required to be successful: \n \n \n \n    Requires seven (7+) years of experience in software design, development, installation, integration, evaluation, enhancement, maintenance, testing, or problem diagnosis and resolution.\n      \n \n \n    Required to be proficient, at a minimum, in the following software: \n     Apache Tomcat, Oracle RDS, Spring Framework , MSWIN Server 2019, RHEL7.9 ->RHEL8. Oracle Java 1.8, IronBank Containers\n      \n \n \n    Required to have a working knowledge of, at a minimum, with the following tech: Java, SAQL, XML, Maven, JavaScript, JSP, CSS, Freemarker Template, JSON\n      \n Security + or any IAT Level II equivalent certification \n \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and must meet and maintain eligibility requirements for, at minimum, Secret access to classified information. \n \n \n  Travel: \n  This position requires minimal travel, if any. \n \n \n  Benefits: \n  Our benefits package includes health, life, disability, dental, and vision insurance coverage and a 401(k) policy with a 3% company contribution & 3% company match. \n  Other perks include generous Paid Time Off (including a PTO \"gift day\" for your birthday), 11 Federal Holidays per year, two weeks paid maternity/paternity leave, and annual technology \"allowances\". \n  Wait! Even more perks include referral bonuses, professional recognition awards, healthcare stipends, tuition/education reimbursement (once certain requirements are met), and flexible daily start and stop times for most projects and positions. \n \n \n  Company Description \n  Technergetics is a US-based company headquartered in Utica, NY, with employees and clients located throughout the country. The Utica/Rome area is a hub of cutting-edge cyber technology research, bolstered by the Griffiss Business & Technology Park's tenants and facilities, including the Air Force Research Lab (AFRL). At Technergetics, we work with a wide variety of technologies, including mobile and web apps, Quantum computing, machine learning and artificial intelligence, AI-enabled edge devices, and many more.", "cleaned_desc": " \n  Responsibilities and Duties \n  The successful candidate can participate, contribute, and document throughout the Software Development Lifecycle, including: \n \n \n The Senior Software Developer works independently designing and engineering new software products or major enhancements to existing software. \n May lead a team in design of highly complex software systems. Acts as highest-level technical expert, addressing problems of systems integration, compatibility, and multiple platforms. \n Works independently designing and engineering new software products or major enhancements to existing software. Devises or modifies procedures to solve complex problems considering computer equipment capacity and limitations, operating time and form of desired results. \n Designs, codes, tests, debug, and document those programs. Conducts code reviews of subordinate developers and peers. Competent to work at the highest technical level of all phases of applications programming activities. \n Coordinates with Cybersecurity team members to implement and maintain a SSDLC with an understanding of the NIST SP 800-63 RMF and the DoD implementation of RMF. \n \n \n \n   \n Education and Certifications: ", "techs": ["nist sp 800-63 rmf", "dod implementation of rmf"]}, "70ad015217af3019": {"terms": ["machine learning engineer"], "salary_min": 250000.0, "salary_max": 370000.0, "title": "Vice President of Engineering \u2013 Exposure Management (Remote)", "company": "CrowdStrike", "desc": "#WeAreCrowdStrike and our mission is to stop breaches. As a global leader in cybersecurity, our team changed the game. Since our inception, our market leading cloud-native platform has offered unparalleled protection against the most sophisticated cyberattacks. We\u2019re looking for people with limitless passion, a relentless focus on innovation and a fanatical commitment to the customer to join us in shaping the future of cybersecurity. Consistently recognized as a top workplace, CrowdStrike is committed to cultivating an inclusive, remote-first culture that offers people the autonomy and flexibility to balance the needs of work and life while taking their career to the next level. Interested in working for a company that sets the standard and leads with integrity? Join us on a mission that matters - one team, one fight.\n  \n \n \n   About the Role:\n    CrowdStrike is seeking a Vice President of Engineering \u2013 Exposure Management to lead our Exposure Management engineering organization. The Exposure Management team will help to reduce the complexity of multi stacked and disjointed security vulnerabilities and misconfigurations to provide the context required to effectively reduce their cyber exposure. This team is responsible for building services using cutting edge data processing techniques that will enable ingesting web-scale amounts of data and present insights into various intricacies of a security posture (leveraging Machine Learning when reasonable). You will help drive our exposure management strategy and the technical roadmap for your areas of responsibilities, and deliver world-class products which delight CrowdStrike\u2019s customers. CrowdStrike is growing rapidly and you will be instrumental in the hiring, retaining and growth of world class engineers. You will work cross-functionally with your peers in the engineering organization as well as leaders in sales, product management, sensor, cloud engineering and UI/UX. We are a remote first company so you will bring your excellent verbal and written communication skills when you are working with your engineering teams and cross functional teams across the globe.\n  \n \n \n   What You'll Need:\n  \n \n \n \n     12+ years of software engineering experience in all phases of a software development lifecycle.\n    \n \n \n     8+ years of hands-on management experience leading engineering teams including experience managing engineering managers.\n    \n \n \n     Experience with shipping high quality software in a cloud environment.\n    \n \n \n     Solid grounding in the technology of at least one cloud environment (AWS, Azure, GCP).\n    \n \n \n     Broad grounding in all aspects of distributed systems development: OS internals and OS system engineering concepts, concurrency models, networking, broad understanding of distributed systems concepts, authN/Z (OAuth2, etc.) and API development.\n    \n \n \n     In depth knowledge with Vulnerability Management, Threat Management, Risk Monitoring, and Cyber Security.\n    \n \n \n     Solid design and problem-solving skills with demonstrated passion for engineering excellence, quality, security and performance.\n    \n \n \n     Strong cross-group collaboration and interpersonal communication skills working with a variety of roles including engineering, product management, support and sales engineering.\n    \n \n \n     Demonstrated ability to attract and hire talent and grow a team rapidly.\n    \n \n \n     Experience working with remote teams and individuals while ensuring agility and code velocity.\n    \n \n \n     Ability to communicate and articulate at all levels from executive staff to engineers\n    \n \n \n     Broad general knowledge of the high-technology industry gained in larger enterprise software environments enhanced by ongoing awareness of R&D practices / technology advances.\n    \n \n \n     BS in Computer Science or a related field, or equivalent work experience.\n    \n \n \n     Demonstrated track record of building a strong core engineering team and engineering team management.\n    \n \n \n \n   What You'll Do:\n  \n \n \n \n     Be the engineering leader that sets and clearly articulates the vision around threat exposure management.\n    \n \n \n     Be the engineering leader that drives execution on the vision both by direct as well as indirect impact and influence.\n    \n \n \n     Engage deeply cross functionally, with sales, marketing and support to make CrowdStrike a leader in Threat Exposure Management.\n    \n \n \n \n   Bonus Points:\n  \n \n \n \n     Experience of hybrid cloud environments.\n    \n \n \n     Technical knowledge on how to implement threat \n     exposure management  products with hands on experience in cloud security, vulnerability management and EDR.\n    \n \n \n     Exposure to/experience with cybersecurity and intelligence.\n    \n \n \n     Understand the significance of each exposure based on threat context through our innovative strategies and behavior analysis.\n    \n \n \n     Strong experience in cloud native compliance and \n     exposure management , ML-based remote user behavior identification, and fraud detection in complex technology landscapes.\n    \n \n \n \n   CrowdStrike, Inc. is committed to fair and equitable compensation practices. The salary range for this position in the U.S. is $250,000 - $370,000 per year + bonus + equity + benefits. A candidate\u2019s salary is determined by various factors including, but not limited to, relevant work experience, skills, certifications and location.\n  \n \n \n   #LI-Remote\n  \n \n   #LI-JF1\n  \n \n \n   Benefits of Working at CrowdStrike:\n  \n \n \n \n     Remote-first culture\n    \n \n \n     Market leader in compensation and equity awards\n    \n \n \n     Competitive vacation and flexible working arrangements\n    \n \n \n     Comprehensive and inclusive health benefits\n    \n \n \n     Physical and mental wellness programs\n    \n \n \n     Paid parental leave, including adoption\n    \n \n \n     A variety of professional development and mentorship opportunities\n    \n \n \n     Offices with stocked kitchens when you need to fuel innovation and collaboration\n    \n \n \n \n \n    We are committed to fostering a culture of belonging where everyone feels seen, heard, valued for who they are and empowered to succeed. Our approach to cultivating a diverse, equitable, and inclusive culture is rooted in listening, learning and collective action. By embracing the diversity of our people, we achieve our best work and fuel innovation - generating the best possible outcomes for our customers and the communities they serve.\n   \n \n \n \n   CrowdStrike is committed to maintaining an environment of Equal Opportunity and Affirmative Action. If you need reasonable accommodation to access the information provided on this website, please contact \n   \n   Recruiting@crowdstrike.com\n   , for further assistance.\n  \n \n \n \n    CrowdStrike participates in the E-Verify program.\n   \n \n \n     Notice of E-Verify Participation\n    \n \n \n \n     Right to Work", "cleaned_desc": " \n     Solid design and problem-solving skills with demonstrated passion for engineering excellence, quality, security and performance.\n    \n \n \n     Strong cross-group collaboration and interpersonal communication skills working with a variety of roles including engineering, product management, support and sales engineering.\n    \n \n \n     Demonstrated ability to attract and hire talent and grow a team rapidly.\n    \n \n \n     Experience working with remote teams and individuals while ensuring agility and code velocity.\n    \n \n \n     Ability to communicate and articulate at all levels from executive staff to engineers\n    \n \n \n     Broad general knowledge of the high-technology industry gained in larger enterprise software environments enhanced by ongoing awareness of R&D practices / technology advances.\n    \n \n \n     BS in Computer Science or a related field, or equivalent work experience.\n    \n \n \n     Demonstrated track record of building a strong core engineering team and engineering team management.\n    \n \n \n \n   What You'll Do:\n  \n ", "techs": ["none"]}, "091a750b23960b27": {"terms": ["machine learning engineer"], "salary_min": 160511.67, "salary_max": 203243.55, "title": "Sr. Staff Hardware Design Engineer", "company": "Recogni", "desc": "Sr. Staff Hardware Design Engineer \n  San Jose, CA \n \n \n  About our company - Recogni \n  Artificial intelligence (AI ) is  transforming  our world.  It can perform cognitive functions  that previously only humans  could do,  such  as perceiving interactions across different  environments  with the  ability  to quickly learn  and  then  solve complex problems . At Recogni we  have innovative  approaches to machine learning, high resolution imaging ,  perception  processing, and  high - performance computation  with industry- leading low power efficiency. We're a  well funded ,  fast -paced startup company with headquarters in  San Jose , CA, and Munich, Germany ; we also  have many talented team members  working  remotely.  We're at the leading edge of  advancing the  latest research  and  product  improvements for Al inference  solutions  that will make Al even  more useful  for compelling  new  applications. \n \n \n \n About the role \n  To keep pace in this exciting, multi-disciplinary field, we\u2019re looking for a Sr. Staff Hardware Design Engineer. You will be in a unique position to have ownership of a wide-ranging list of hardware system development aspects, including schematics, PCB layout and mechanical design, component selection and collaborating with operations in AVL management, EVT/DVT/PVT testing and certification. You will also have an opportunity to make impact on design and bringup of development systems, reference platforms and volume products. \n  This hands-on multi-disciplinary role provides a unique opportunity to interact directly with ASIC, camera sensor, software, product and operations teams to gather necessary requirements and specifications, and help set the overall methodology around hardware system development at Recogni. \n  Responsibilities \n \n Own multiple aspects of hardware system engineering of Recogni\u2019s flagship AI products. \n Gather requirements and specifications from engineering, product and operations teams for planning and implementing all hardware system deliverables, from lab bringup artifacts to reference system to shipping products. \n Hands on responsibility for the schematic capture, PCB design and other aspects of the hardware system around a complex custom AI ASIC. \n Plan for Compliance, Validation and FMEA Analysis for products. \n Drive hardware parts selection and vendor qualification processes in collaboration with manufacturing operations. \n \n Qualifications \n \n B.S. degree in Electrical or Computer Engineering. \n 10+ years of hardware engineering and experience with product-cycle aspects therein. \n Hands-on experience in all aspects of schematic capture, PCB design, as well as understanding signal integrity, mechanical and thermal design areas. \n Experience in part selection, AVL management and working with manufacturing operations teams. \n Previous involvement in representing engineering considerations in contract manufacturing relationships. \n Demonstrable experience with EVT, DVT, PVT testing and certification processes is a plus. \n Self-starter and highly-motivated to work in a dynamic start-up environment. \n \n \n \n Recogni is an equal opportunity employer. We believe that a diverse team is better at tackling complex problems and coming up with innovative solutions. All qualified applicants will receive consideration for employment without regard to age, color, gender identity or expression, marital status, national origin, disability, protected veteran status, race, religion, pregnancy, sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. \n  A note to Recruitment Agencies: Please don\u2019t reach out to Recogni employees or leaders about our roles - we\u2019ve got it covered. We don\u2019t accept unsolicited agency resumes and we are not responsible for any fees related to unsolicited resumes. Thank you for your understanding.", "cleaned_desc": "", "techs": ""}, "4bf73512884fa152": {"terms": ["machine learning engineer"], "salary_min": 66300.0, "salary_max": 119850.0, "title": "Sr. Network Engineer (Lead)", "company": "Leidos", "desc": "Description   \n Looking for an opportunity to make an impact?  \n \n At Leidos, we deliver innovative solutions through the efforts of our diverse and talented people who are dedicated to our customers\u2019 success. We empower our teams, contribute to our communities, and operate sustainable. Everything we do is built on a commitment to do the right thing for our customers, our people, and our community. Our Mission, Vision, and Values guide the way we do business. \n \n  If this sounds like a mission you want to be a part of, keep reading! \n \n  Civilian Health Solutions  uses a wide range of capabilities in Digital Modernization, Mission Software Systems, and enabling technologies like Artificial Intelligence and Machine Learning to support our customers\u2019 mission in advancing biomedical research and protecting public health. Our team\u2019s focus is ensuring our health customers have the right solutions to keep pace with an ever-evolving public health landscape and prevent the next public health crisis. To explore and learn more, click here! \n \n  Your greatest work is ahead! \n \n  Job Description \n  Leidos\u2019 Civilian Health Solutions Operation is seeking a dynamic, mission-centric hands-on  Sr. Network Engineer (Lead)  to support a federal agency\u2019s large, mission-critical, hybrid infrastructure. We are building out an amazing team of high-impact technology professionals, and we want you to be a part of our ongoing transformation. The Sr. Network Engineer (Lead) identified for this position shall be responsible for supporting the installation, implementation, troubleshooting, and maintenance of agency-wide-area networks (WANs) and local-area networks (LANs). Assist in designing and managing the WAN infrastructure and any processes related to the WAN. Provide Production Support of the Network, including day-to-day operations, monitoring and problem resolution client Networks. Provide second-level problem identification, diagnosis, and resolution of problems. Support the dispatch of circuit and hardware vendors involved in the resolution process. Support the escalation and communication of status to agency management and internal customers. Working knowledge is desirable in various software systems and architectures, communications protocols: and network hardware devices. The staff member is expected to be on-site and respond to major outage resolution outside of regular working hours within 90 minutes of notification. \n \n  Primary Responsibilities \n \n  Responsible for all aspects of network engineering for a hybrid network consisting of on-prem and cloud components, including servers, desktop systems, routers, switches, firewalls, printers, access points, etc. \n  Responsible in developing and implementing network solutions across an enterprise implementation. \n  Identify, define, and analyze complex problems and provide solutions that require an elevated level of ingenuity and innovativeness. \n  Recommend strategies for the continued improvements in the reliability, scalability, and maintainability of assigned network applications/systems/platforms. \n  Responsible for effective monitoring and keeping assigned network application/system/platform online and functioning (including trouble ticket resolution and network service availability) \n  Maintains network performance by performing network monitoring, analysis, and performance tuning; troubleshooting network problems; escalating problems to vendor. \n  Review, recommend, coordinate, and implement designs and analyses related to specific areas of responsibility. \n  Prepare plans for the installation or migration of new systems (Including network analysis, design, and build phases), management and implementation of VOIP systems across the WAN, and configure established best practices for VOIP traffic quality and performance. \n \n \n  Required Qualifications: \n \n  Active Public Trust Clearance or Ability to obtain a Public Trust Clearance \n  Bachelor\u2019s Degree in IT-related field and 7+ years of experience in network hardware configuration and maintenance \n  5+ years of recent hands-on experience in an enterprise-scale network environment as a Network Engineer \n  One or more of the following relevant certifications: CCNA, CCNP, CCIE, CCDE \n  Ability to potentially interact with senior staff in the agency and scientific community; \n  Ability to work/ collaborate with different contractor and government teams as well as industry and vendors with a high level of professionalism, good judgment, and tact. \n  Ability to work well under pressure and be flexible at juggling competing priorities. Must be resourceful and independent problem solvers. \n  Ability to obtain ITIL Foundations certification in 3 months of start date. \n \n \n  Preferred Qualifications: \n \n  Experience within healthcare domain (preferably FDA, NIH, or agencies in HHS) is highly preferred. \n  Certifications: ITIL Foundations, Cloud Certifications (AWS, Azure, Google Cloud Platform - GCP), VMware Certified, and/ or Linux \n \n \n  Pay Range:  Pay Range $66,300.00 - $119,850.00\n  \n  The Leidos pay range for this job level is a general guideline only and not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other law. \n  #Remote", "cleaned_desc": "", "techs": ""}, "f777a182b0aea781": {"terms": ["machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Insider Threat Analyst (Intelligence Analyst 3)- 16613", "company": "HII", "desc": "Date:  Oct 18, 2023  \n Location:  Arlington, VA, Virginia, United States  \n Company:  HII's Mission Technologies division  \n \n Requisition Number: 16613 \n Required Travel: 0 - 10% \n Employment Type: Full Time/Salaried/Exempt \n Security Clearance: TS/SCI \n Level of Experience: Mid HI \n \n \n This opportunity resides with  Command, Control, Communications, Computers, Cyber, Intelligence, Surveillance and Reconnaissance (C5ISR) , a business group within HII\u2019s Mission Technologies division. From towers to processors, we design, develop, integrate and manage the sensors, systems and other assets necessary to support integrated intelligence, surveillance and reconnaissance (ISR) operations, exploitation and analysis for the Intelligence Community, the military services, geographic and functional combatant commands and DoD agencies. \n \n \n Meet HII\u2019s Mission Technologies Division  Our team of more than 7,000 professionals worldwide delivers all-domain expertise and advanced technologies in service of mission partners across the globe. Mission Technologies is leading the next evolution of national defense \u2013 the data evolution - by accelerating a breadth of national security solutions for government and commercial customers. Our capabilities range from C5ISR, AI and Big Data, cyber operations and synthetic training environments to fleet sustainment, environmental remediation and the largest family of unmanned underwater vehicles in every class. Find the role that\u2019s right for you. Apply today. We look forward to meeting you. \n \n \n \n  Summary \n \n \n  HII- Mission Technologies is seeking an Insider Threat Analyst to support the DCSA DoD Insider Threat Management Analysis Center (DITMAC)! DITMAC focuses on detecting and responding to behaviors indicative of a potential insider threat. DITMAC informs DoD leaders and the Components to oversee threat mitigation, prepare risk assessments and recommendations, synchronize responses to potential threats, and enable sharing of relevant information. To this end, DITMAC supports the 43 DoD Components by analyzing threats and issues as they occur, promoting best practices, strengthening collaboration and information sharing among Departmental elements, and identifying and helping address systemic insider threat issues. \n \n \n Work performance location is 90% at DCSA\u2019s Crystal City, VA location, and 10% opportunity for remote work. Come join our growing team today! \n \n \n \n \n  What you will do \n \n \n \n Prepare assessments through research and analysis of classified and open-source information \n Collect data using a combination of doctrinal methods and business processes \n Assist with conducting operational readiness exercises as it pertains to receiving and reviewing Insider Threat data and determine if there are additional potential risk indicators (PRI) based on access to Insider Threat databases and Systems \n Analyze information to produce assessments, reports, articles, threat analyses, special studies etc., responsive to user needs, and complying with suspense dates for draft and final products \n Support executing activities to test Insider Threat technologies on a variety of systems. \n Assist in definition of verification methods and procedures for sufficient testing to ensure operational effectiveness, to include data integrity, usability of Insider Threat Systems, trainability, interface conformance, and supportability of current and future Insider Threat capabilities \n Perform Mission Engineering (ME) analyses to guide development, prototyping, and testing to achieve Insider Threat mission and DITMAC needs \n Organize and manage reviews and feedback of system performance, measures of effectiveness, and design characteristics of the data management program \n Organize statistical data for quantitative and qualitative metrics reports, summaries, case studies and trend reports as required \n Analyze requirements concepts, integration, and interoperability of multiple DCSA systems, to identify potential design changes to legacy and emerging systems that may provide operational effectiveness and efficiency benefits \n Other duties as assigned \n \n \n \n \n \n What we are looking for \n \n \n \n 5 years relevant experience with Bachelors in related field; 3 years relevant experience with Masters in related field; 0 years experience with PhD or Juris Doctorate in related field; or High School Diploma or equivalent and 9 years relevant experience \n Familiarity with Intelligence Community Directives 203 (Analytic Standards), 205 (Outreach), 206 (Sourcing), and 208 (Writing for Maximum Utility), template, and SOP standards as appropriate \n Ability to effectively communicate orally and in writing \n Ability to analyze and evaluate, on a quantitative or qualitative basis, the effectiveness of component level reporting in meeting established goals and objectives \n Ability to gather, identify, receive, ingest, examine, integrating data on potential insider threat incidents from various sources following established guidelines, policies, and procedures \n Ability to review and evaluate program progress status, trends in any functions, and goals and objectives \n Ability to prepare responses to queries, reports, justifications, and background papers on insider threat issues \n Ability to plan, organize, develop, coordinate, and represent the DITMAC in briefings with internal and external senior stakeholders to inform them of the progress of initiatives \n Clearance: Must possess and maintain a TS/SCI clearance \n \n \n \n \n \n Bonus points for... \n \n \n \n Records/data management experience \n DCSA/DITMAC experience \n \n \n \n \n \n Physical Requirements \n \n \n     May require working in an office, industrial, shipboard, or laboratory environment. Capable of climbing ladders and tolerating confined spaces and extreme temperature variances.\n     \n \n \n  Why HII  We build the world\u2019s most powerful, survivable naval ships and defense technology solutions that safeguard our seas, sky, land, space and cyber. Our diverse workforce includes skilled tradespeople; artificial intelligence, machine learning (AI/ML) experts; engineers; technologists; scientists; logistics experts; and business administration professionals. \n \n \n Recognized as one of America\u2019s top large company employers, we are a values and ethics driven organization that puts people\u2019s safety and well-being first. Regardless of your role or where you serve, at HII, you\u2019ll find a supportive and welcoming environment, competitive benefits, and valuable educational and training programs for continual career growth at every stage of your career. \n \n \n Together we are working to ensure a future where everyone can be free and thrive.  Today\u2019s challenges are bigger than ever, and the nation needs the best of us. It\u2019s why we\u2019re focused on hiring, developing and nurturing our diversity. We believe that diversity among our workforce strengthens the organization, stimulates creativity, promotes the exchange of ideas and enriches the work lives of all our employees. \n \n \n All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, physical or mental disability, age, or veteran status or any other basis protected by federal, state, or local law. \n \n \n Do You Need Assistance?  If you need a reasonable accommodation for any part of the employment process, please send an e-mail to  buildyourcareer@hii-co.com  and let us know the nature of your request and your contact information. Reasonable accommodations are considered on a case-by-case basis. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this email address. Additionally, you may also call  1-844-849-8463  for assistance. Press #3 for HII Technical Solutions.", "cleaned_desc": " Assist in definition of verification methods and procedures for sufficient testing to ensure operational effectiveness, to include data integrity, usability of Insider Threat Systems, trainability, interface conformance, and supportability of current and future Insider Threat capabilities \n Perform Mission Engineering (ME) analyses to guide development, prototyping, and testing to achieve Insider Threat mission and DITMAC needs \n Organize and manage reviews and feedback of system performance, measures of effectiveness, and design characteristics of the data management program \n Organize statistical data for quantitative and qualitative metrics reports, summaries, case studies and trend reports as required \n Analyze requirements concepts, integration, and interoperability of multiple DCSA systems, to identify potential design changes to legacy and emerging systems that may provide operational effectiveness and efficiency benefits \n Other duties as assigned \n \n \n \n \n \n What we are looking for \n \n \n \n 5 years relevant experience with Bachelors in related field; 3 years relevant experience with Masters in related field; 0 years experience with PhD or Juris Doctorate in related field; or High School Diploma or equivalent and 9 years relevant experience \n Familiarity with Intelligence Community Directives 203 (Analytic Standards), 205 (Outreach), 206 (Sourcing), and 208 (Writing for Maximum Utility), template, and SOP standards as appropriate \n Ability to effectively communicate orally and in writing \n Ability to analyze and evaluate, on a quantitative or qualitative basis, the effectiveness of component level reporting in meeting established goals and objectives ", "techs": ["verification methods and procedures", "testing", "data integrity", "usability", "insider threat systems", "trainability", "interface conformance", "supportability", "mission engineering (me) analyses", "development", "prototyping", "system performance", "measures of effectiveness", "design characteristics", "data management program", "statistical data analysis", "quantitative metrics reports", "qualitative metrics reports", "case studies", "trend reports", "requirements analysis", "integration", "interoperability", "dcsa systems", "design changes", "operational effectiveness", "efficiency benefits", "intelligence community directives", "analytic standards", "outreach", "sourcing", "writing for maximum utility", "template", "sop standards", "communication skills", "component level reporting"]}, "c8c4f67023e99c31": {"terms": ["machine learning engineer"], "salary_min": 106039.945, "salary_max": 134270.2, "title": "Senior Technical Services Engineer- East Coast", "company": "Weka", "desc": "WEKA is leading a paradigm shift in how data is stored, managed, and processed in the cloud and AI era. We are a pre-IPO, growth-stage company on a hyper-growth trajectory that has raised over $275M in capital and is backed by dozens of world-class venture capital and strategic investors. \n  Our flagship product, the WEKA\u00ae Data Platform, is a software-based, hybrid cloud solution transforming stagnant legacy data siloes into dynamic data pipelines that power GPUs efficiently and fuel performance-intensive workloads like generative AI and machine learning seamlessly and sustainably. \n  We\u2019re passionate about helping our customers overcome complex data management challenges to accelerate their innovation and help grow their businesses. If you share our passion, we invite you to join us on this exciting journey. \n \n  Summary \n  As Senior Technical Services Engineer, you will join a team of the most experienced Technical Services Engineers responsible for WEKA's post-sales success and big part of the 5 star gartner reviews. You will be working on cutting edge technologies with the most cutting edge customers. \n  General direction is provided on routine work, and detailed direction is provided on new projects and assignments; as well as on-going review of activities and priorities. The ideal candidate will be an important contributor on assigned projects. \n \n  Responsibilities \n \n  Bridging between the customer and R&D whenever current product features, reliability or documentation do not match the customer's expectations \n  Resolve technical problems by working with customers and engage with WEKA's R&D if required \n  Providing feedback to R&D and help to prioritize bugs, usability issues, etc. \n  Providing back-office support for pre-sales engineers, partners, and resellers \n  Keeping track of WEKA's systems via our remote monitoring tool, while proactively identifying corrective actions \n  Responsible for ownership, tracking and documenting customer issues using our ticketing system \n  Communicate effectively with employees, customer and partners, ensuring the message is concise and professional \n  Shares and documents knowledge via FAQ / KB articles, which can be internal or customer facing \n  Manage multiple projects/support cases simultaneously \n  Champion customer issues internally, and represents WEKA externally to our customers and partners \n  Become a subject matter expert in a technology \n  Be part of on-call, follow the sun model support as required \n  This position may involve alternative work hours including nights, weekends, and company holidays \n  Regional/Domestic/International travel may be required for this position \n \n  Required Skills \n \n  Hands-on experience in supporting Linux-based enterprise infrastructure products (storage, networking, virtualization, security, cloud etc.) \n  Experience in L3 support and customer interactions for enterprise infrastructure products \n  Experience in developing and optimizing interfaces between business organizations; specifically customer facing problem solving organizations and product development organizations. \n  Proven ability to resolve complex customer problems, and escalations utilizing appropriate internal and external resources and tools. \n  Strong technical troubleshooting, and fault isolation skills in a multi-platform-system-vendor environment \n  Experience Supporting Enterprise Software Solutions and/or applications, including hardware components \n  Ability to triage issues, and effectively escalate them to appropriate engineering groups as necessary \n  Understanding of networking including Infiniband, Ethernet, DPDK, UCX. \n  Demonstration of subject matter expertise and knowledge in cloud/computer/networking/storage. \n  Prior support experience at cloud/HPC related company is desired \n \n  Minimum Qualifications (Education & Experience) \n \n  Hands-on experience in supporting Linux-based enterprise infrastructure products (Cloud Applications, Storage, Networking, Virtualization, Security, etc.) \n  Proficient with at least one of the following Cloud Technologies; Amazon Web Services (AWS), Microsoft Azure, Oracle Cloud Infrastructure (OCI), or Google Cloud Platform (GCP). \n  Familiarity with Kubernetes/Containers/LXC technologies \n  Experience in L3 support and customer interactions for enterprise infrastructure products \n  Knowledge of various operating systems such as LINUX, Ubuntu and Windows \n  Technical writing \n  Highly proficient in verbal and written English \n  Minimum 10 years of experience in customer-facing, deep technical problem solving \n \n \n  USA Residents Only:  The base salary hiring wage range for this position which the Company reasonably and in good faith expects to pay for the position in the specified geographic areas or locations, is $165,000-185,000. Final compensation will be dependent on various factors relevant to the position and candidate such as geographical location, candidate qualifications, certifications, relevant job-related work experience, education, skillset and other relevant business and organizational factors, consistent with applicable law. In addition, the position may include some of the following comprehensive benefits such Medical, Dental, Vision, Life, 401(K), Flexible Time off (FTO), sick time, leave of absence as per the FMLA and other relevant leave laws. \n \n  Concerned you don\u2019t meet every qualification? Don\u2019t let it stop you from applying! \n  Studies have shown that traditionally underrepresented groups may be less likely to apply for jobs if they don\u2019t meet every qualification specified. WEKA is committed to building a diverse, inclusive, and authentic workplace. If you are excited about this position but are concerned your past work experience doesn\u2019t match up perfectly with the job description, we encourage you to apply anyway \u2013 you may be just the right candidate for this or other roles at WEKA. \n \n  WEKA is an equal-opportunity employer that prohibits discrimination and harassment of any kind. We provide equal opportunities to all employees and applicants for employment without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.", "cleaned_desc": "  This position may involve alternative work hours including nights, weekends, and company holidays \n  Regional/Domestic/International travel may be required for this position \n \n  Required Skills \n \n  Hands-on experience in supporting Linux-based enterprise infrastructure products (storage, networking, virtualization, security, cloud etc.) \n  Experience in L3 support and customer interactions for enterprise infrastructure products \n  Experience in developing and optimizing interfaces between business organizations; specifically customer facing problem solving organizations and product development organizations. \n  Proven ability to resolve complex customer problems, and escalations utilizing appropriate internal and external resources and tools. \n  Strong technical troubleshooting, and fault isolation skills in a multi-platform-system-vendor environment \n  Experience Supporting Enterprise Software Solutions and/or applications, including hardware components    Ability to triage issues, and effectively escalate them to appropriate engineering groups as necessary \n  Understanding of networking including Infiniband, Ethernet, DPDK, UCX. \n  Demonstration of subject matter expertise and knowledge in cloud/computer/networking/storage. \n  Prior support experience at cloud/HPC related company is desired \n \n  Minimum Qualifications (Education & Experience) \n \n  Hands-on experience in supporting Linux-based enterprise infrastructure products (Cloud Applications, Storage, Networking, Virtualization, Security, etc.) \n  Proficient with at least one of the following Cloud Technologies; Amazon Web Services (AWS), Microsoft Azure, Oracle Cloud Infrastructure (OCI), or Google Cloud Platform (GCP). \n  Familiarity with Kubernetes/Containers/LXC technologies \n  Experience in L3 support and customer interactions for enterprise infrastructure products ", "techs": ["linux-based enterprise infrastructure products", "storage", "networking", "virtualization", "security", "cloud", "l3 support", "customer interactions", "interfaces", "problem solving", "complex customer problems", "technical troubleshooting", "fault isolation", "multi-platform-system-vendor environment", "enterprise software solutions", "hardware components", "triage issues", "networking", "infiniband", "ethernet", "dpdk", "ucx", "cloud/computer/networking/storage", "support experience", "cloud/hpc related company", "cloud applications", "cloud technologies", "amazon web services (aws)", "microsoft azure", "oracle cloud infrastructure (oci)", "google cloud platform (gcp)", "kubernetes", "containers", "lxc technologies."]}, "dbeb1cfb48325d6b": {"terms": ["machine learning engineer"], "salary_min": 112.0, "salary_max": 112.0, "title": "Senior Manager of Data Engineering", "company": "Vail Resorts", "desc": "As a leading mountain resort operator with over 40 resorts in sixteen states and four countries. We exist to create an  Experience of a Lifetime  for our employees, so they can, in turn, provide and  Experience of a Lifetime  for our guests. We are looking for leaders, innovators, creators, and ambitious professionals to join our talented team. If you\u2019re ready to pursue your fullest potential, we want to get to know you! \n  Many of our Corporate function teams can now live and work in any of the states in which Vail Resorts currently operates* \u2013 enabling flexible remote work alongside a commitment to building and maintaining strong culture both in person and virtually. If you\u2019re ready to pursue your fullest potential, we want to get to know you. Find your purpose with us at www.vailresortscareers.com. \n \n  Job Summary: \n  We are looking for a passionate and driven leader to become an important part of our fast-paced, high-energy, and innovative culture. The Senior Manager of Data Engineering plays a key leadership role in the evolution of our Data Driven journey. The Senior Manager will work with a team of developers, principle architects, and specialists to provide leadership and direction in the digital transformation to a data driven organization. This position will partner with and support many lines of business across a fast-paced and highly collaborative environment, working closely with Project Managers and Business Analysts to ensure the on-time and quality delivery of complex programs. We are looking for an articulate leader that is highly collaborative, driven, and detail oriented. \n   \n A successful candidate will excel in the following areas: Leadership and development of data engineers and technology professionals, building and managing stakeholder partnerships, Business Intelligence and cloud platforms, data warehousing and data sourcing architecture, data pipeline architecture, data quality management, data governance, and KPIs. Previous experience managing people who are designing, building, operating and maintaining an engineering team. This position reports to the Director of Data Engineering and Data Enablement. \n \n  Job Specifications: \n \n  Outlet: Corporate / Remote \n  Shift & Schedule Availability: Year Round / Full Time \n  The budgeted range starts at $112,00 - $190,000 + annual bonus. Actual pay will be adjusted based on experience. \n \n \n  Job Responsibilities: \n \n  Develop a high performing team by increasing the high-potential employee mix, ensuring solid succession planning, and maintaining long-term organizational strategic designs. \n  Partner with multiple stakeholder groups (Data Engineers, Data Scientists, Infrastructure, Marketing, Hospitality, etc...) to consistently improve our data, data architecture, and the products that rely on. \n  Collaborating with our business and technology partners to educate our business and advance our data driven road map and associated investments \n  Coordinate with program management leadership to assess and prioritize strategic initiatives and timelines to ensure deliverables are met. \n  Act as the escalation point for business and staff issues with regards to technical delivery. \n  Translating business needs into data projects and data projects into business implications \n  Partnering with business and technology leadership to execute on the following initiatives: \n  Migration from traditional batch based on-premise to cloud based rapid data deployment \n  Identify improvement areas across people, process and technology \n  Research and implementation of new data-enabled strategies and capabilities \n  Implement a robust and agile information architecture \n \n \n  Job Requirements: \n \n  Bachelor\u2019s degree in Computer Science, data science, IS, mathematics, or related field, or equivalent work experience. \n  7+ years of experience in data engineering or related roles \n  2+ years of experience in managing or leading data engineering teams  \n Experience building modern Lakehouse solutions using Azure Databricks \n  Experience implementing CI/CD pipelines in Azure Databricks \n  Proficient in Python, Spark (Scala or Python), SQL and other scripting languages and has experience training team members on the use of these technologies \n  Experience in working with Azure cloud services such as Azure Data Lake, Azure Data Factory, Azure Databricks, Azure DevOps, Event Hubs/Service Bus, Function Apps, Container Apps, Kubernetes  \n Experience in building modern data warehouse solutions using Azure stack or similar technologies  \n Experience in working with various data formats such as JSON, XML, CSV, Parquet, etc.  \n Experience in working with relational databases such as SQL Server, Oracle, MySQL, etc. and NoSQL databases such as Redis, MongoDB, Cosmos DB, etc.  \n Experience in using various ETL tools such as SSIS, Informatica, Data Stage, etc.  \n Knowledge of machine learning, statistical modeling and data visualization techniques is a plus  \n Excellent communication, problem-solving and analytical skills  \n Ability to work independently and as part of a team \n \n \n  The expected Total Compensation for this role is $112,00 - $190,000 + annual bonus. Individual compensation decisions are based on a variety of factors. \n  The perks include a free ski pass, and a set of benefits including... \n \n  Medical, Dental, Vision insurance, and a 401(k) retirement plan \n  Hourly employees are generally eligible for accrued Paid Time Off (PTO) and Sick Time. Salaried employees are generally eligible for Flexible Time Off (FTO) \n  Paid Parental Leave for eligible mothers and fathers \n  Healthcare & Dependent Care Flexible Spending Accounts \n  Life, AD&D, and disability insurance \n \n \n  Reach Your Peak at Vail Resorts.  At Vail Resorts, our team is made whole by the brave, passionate individuals who ambitiously push boundaries and challenge the status quo. Whether you\u2019re looking for seasonal work or the career of a lifetime, join us today to reach your peak. \n \n   Remote work is currently permitted from British Columbia and the 16 U.S. states in which we currently operate. This includes: California, Colorado, Indiana, Michigan, Minnesota, Missouri, New Hampshire, New York, Nevada, Ohio, Pennsylvania, Utah, Vermont, Washington State, Wisconsin, and Wyoming. Please note that the ability to work remotely, and the particulars related to such work, are subject to change at any time; and, accordingly, the Company reserves the right to change its policies and/or require in-person/in-office work at any time in its sole discretion. \n \n \n  Vail Resorts is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability, protected veteran status or any other status protected by applicable law. \n \n  Requisition ID 498602   Reference Date: 10/17/2023   Job Code Function: Data Warehouse/Business Intel", "cleaned_desc": "  Research and implementation of new data-enabled strategies and capabilities \n  Implement a robust and agile information architecture \n \n \n  Job Requirements: \n \n  Bachelor\u2019s degree in Computer Science, data science, IS, mathematics, or related field, or equivalent work experience. \n  7+ years of experience in data engineering or related roles \n  2+ years of experience in managing or leading data engineering teams  \n Experience building modern Lakehouse solutions using Azure Databricks \n  Experience implementing CI/CD pipelines in Azure Databricks \n  Proficient in Python, Spark (Scala or Python), SQL and other scripting languages and has experience training team members on the use of these technologies \n  Experience in working with Azure cloud services such as Azure Data Lake, Azure Data Factory, Azure Databricks, Azure DevOps, Event Hubs/Service Bus, Function Apps, Container Apps, Kubernetes    Experience in building modern data warehouse solutions using Azure stack or similar technologies  \n Experience in working with various data formats such as JSON, XML, CSV, Parquet, etc.  \n Experience in working with relational databases such as SQL Server, Oracle, MySQL, etc. and NoSQL databases such as Redis, MongoDB, Cosmos DB, etc.  \n Experience in using various ETL tools such as SSIS, Informatica, Data Stage, etc.  \n Knowledge of machine learning, statistical modeling and data visualization techniques is a plus  \n Excellent communication, problem-solving and analytical skills  \n Ability to work independently and as part of a team \n \n \n  The expected Total Compensation for this role is $112,00 - $190,000 + annual bonus. Individual compensation decisions are based on a variety of factors. \n  The perks include a free ski pass, and a set of benefits including... \n \n  Medical, Dental, Vision insurance, and a 401(k) retirement plan ", "techs": ["azure databricks", "python", "spark", "sql", "azure data lake", "azure data factory", "azure devops", "event hubs/service bus", "function apps", "container apps", "kubernetes", "json", "xml", "csv", "parquet", "sql server", "oracle", "mysql", "redis", "mongodb", "cosmos db", "ssis", "informatica", "data stage"]}, "f5f186a6f3b7168f": {"terms": ["machine learning engineer"], "salary_min": 110729.805, "salary_max": 140208.61, "title": "Senior Data Engineer", "company": "Syngenta Crop Protection", "desc": "Company Description\n   As a world market leader in crop protection, we help farmers to counter these threats and ensure enough safe, nutritious, affordable food for all \u2013 while minimizing the use of land and other agricultural inputs. \n  Syngenta Crop Protection keeps plants safe from planting to harvesting. From the moment a seed is planted through to harvest, crops need to be protected from weeds, insects and diseases as well as droughts and floods, heat and cold. \n  Syngenta Crop Protection is headquartered in Switzerland. \n \n \n \n Job Description\n   The Senior Data Engineer will be part of a team working in a collaborative DataOps environment assembled from data engineers, data scientists, visualization and analytics experts drawn from IT and R&D teams. \n  Specific duties include: \n \n  Support an analytical data infrastructure providing application, tool and ad-hoc access to large datasets consisting of complex data types including genomic, phenotypic, environmental, image and geospatial data. \n  Process huge data using Big Data tools and technologies like Spark, Hadoop and Hive and extract, transform and load data using various ETL tools. \n  Engage with business stakeholders to understand strategic roadmaps and build a technical strategy to support them. \n  Deploy high value, high performance datasets in Snowflake. \n  Create and support real-time data pipelines built on AWS technologies including Glue, S3, Lambda, EMR, EventBridge, Athena, Kinesis, and IoT Core. \n  Create end to end database architecture and data modeling in Oracle, Microsoft SQL Server, PostgreSQL and Sybase and creating complex SQL queries, stored procedures and functions to implement business logic. \n  Embed quality and intelligent reporting capabilities into data pipelines including detection of anomalies and changes in trends with meaningful alerts and statistics. \n  Maintain versions of code and implement CI/CD (continuous integration and continuous deployment) pipelines using Github, Teamcity, Jenkins and SVN. \n  Continually research the latest big data and visualization technologies to provide new capabilities and increase efficiency. \n  Collaborate with data scientists and other tech teams to implement advanced analytics algorithms into our data pipelines that exploit our rich datasets for statistical analysis, prediction, clustering and machine learning. \n  Help continually improve automation and simplifying data as a service. \n  Performing work using cloud technologies including AWS, EC2, S3, Kinesis, Glue, Redshift/Spectrum, Lambda, EMR, Athena, Data Pipeline. \n  Create Graphical User Interfaces by coding in advance HTML, Java and Javascript and create various utilities by programming in Python, Powershell and Unix Shell Scripting. \n \n  Position based at company headquarters in Greensboro, NC; may telecommute from anywhere in the U.S. \n \n \n \n Qualifications\n   This position requires a Bachelor\u2019s degree or equivalent in Computer Science, Information Science, Engineering, Mathematics or related technical discipline and 5 years of related (progressive, post-baccalaureate) experience. \n  Must also have 12 months of experience (which may have been gained concurrently) with each of the following: \n \n  Processing huge data using Big Data tools and technologies like Spark, Hadoop and Hive and extracting, transforming and loading data using various ETL tools. \n  Maintaining versions of code and implementing CI/CD (continuous integration and continuous deployment) pipelines using Github, Teamcity, Jenkins and SVN. \n  Creating end to end database architecture and data modeling in Oracle, Microsoft SQL Server, PostgreSQL and Sybase and creating complex SQL queries, stored procedures and functions to implement business logic. \n  Performing work using cloud technologies including AWS, EC2, S3, Kinesis, Glue, Redshift/Spectrum, Lambda, EMR, Athena, Data Pipeline. \n  Creating Graphical User Interfaces by coding in advance HTML, Java and Javascript and creating various utilities by programming in Python, Powershell and Unix Shell Scripting. \n \n  All experience may have been gained concurrently. Must pass a background check and drug test before beginning employment. Position based at company headquarters in Greensboro, NC; may telecommute from anywhere in the U.S. \n  Additional Information\n   What We Offer: \n \n  A culture that celebrates diversity & inclusion, promotes professional development, and strives for a work-life balance that supports the team members. offers flexible work options to support your work and personal needs \n  Full Benefit Package (Medical, Dental & Vision) that starts your first day \n  401k plan with company match, Profit Sharing & Retirement Savings Contribution \n  Paid Vacation, 9 Paid Holidays, Maternity and Paternity Leave, Education Assistance, Wellness Programs, Corporate Discounts, among other benefits \n \n  Syngenta is an Equal Opportunity Employer and does not discriminate in recruitment, hiring, training, promotion or any other employment practices for reasons of race, color, religion, gender, national origin, age, sexual orientation, marital or veteran status, disability, or any other legally protected status. \n  Family and Medical Leave Act (FMLA) \n  (http://www.dol.gov/whd/regs/compliance/posters/fmla.htm) \n  Equal Employment Opportunity Commission's (EEOC) \n  (http://webapps.dol.gov/elaws/firststep/poster_direct.htm) \n  Employee Polygraph Protection Act (EPPA) \n  (http://www.dol.gov/whd/regs/compliance/posters/eppa.htm)", "cleaned_desc": " \n  Support an analytical data infrastructure providing application, tool and ad-hoc access to large datasets consisting of complex data types including genomic, phenotypic, environmental, image and geospatial data. \n  Process huge data using Big Data tools and technologies like Spark, Hadoop and Hive and extract, transform and load data using various ETL tools. \n  Engage with business stakeholders to understand strategic roadmaps and build a technical strategy to support them. \n  Deploy high value, high performance datasets in Snowflake. \n  Create and support real-time data pipelines built on AWS technologies including Glue, S3, Lambda, EMR, EventBridge, Athena, Kinesis, and IoT Core. \n  Create end to end database architecture and data modeling in Oracle, Microsoft SQL Server, PostgreSQL and Sybase and creating complex SQL queries, stored procedures and functions to implement business logic. \n  Embed quality and intelligent reporting capabilities into data pipelines including detection of anomalies and changes in trends with meaningful alerts and statistics. \n  Maintain versions of code and implement CI/CD (continuous integration and continuous deployment) pipelines using Github, Teamcity, Jenkins and SVN. \n  Continually research the latest big data and visualization technologies to provide new capabilities and increase efficiency.    Collaborate with data scientists and other tech teams to implement advanced analytics algorithms into our data pipelines that exploit our rich datasets for statistical analysis, prediction, clustering and machine learning. \n  Help continually improve automation and simplifying data as a service. \n  Performing work using cloud technologies including AWS, EC2, S3, Kinesis, Glue, Redshift/Spectrum, Lambda, EMR, Athena, Data Pipeline. \n  Create Graphical User Interfaces by coding in advance HTML, Java and Javascript and create various utilities by programming in Python, Powershell and Unix Shell Scripting. \n \n  Position based at company headquarters in Greensboro, NC; may telecommute from anywhere in the U.S. \n \n \n \n Qualifications    This position requires a Bachelor\u2019s degree or equivalent in Computer Science, Information Science, Engineering, Mathematics or related technical discipline and 5 years of related (progressive, post-baccalaureate) experience. \n  Must also have 12 months of experience (which may have been gained concurrently) with each of the following: \n \n  Processing huge data using Big Data tools and technologies like Spark, Hadoop and Hive and extracting, transforming and loading data using various ETL tools. \n  Maintaining versions of code and implementing CI/CD (continuous integration and continuous deployment) pipelines using Github, Teamcity, Jenkins and SVN. \n  Creating end to end database architecture and data modeling in Oracle, Microsoft SQL Server, PostgreSQL and Sybase and creating complex SQL queries, stored procedures and functions to implement business logic. \n  Performing work using cloud technologies including AWS, EC2, S3, Kinesis, Glue, Redshift/Spectrum, Lambda, EMR, Athena, Data Pipeline. \n  Creating Graphical User Interfaces by coding in advance HTML, Java and Javascript and creating various utilities by programming in Python, Powershell and Unix Shell Scripting. \n \n  All experience may have been gained concurrently. Must pass a background check and drug test before beginning employment. Position based at company headquarters in Greensboro, NC; may telecommute from anywhere in the U.S. ", "techs": ["analytical data infrastructure", "spark", "hadoop", "hive", "etl tools", "snowflake", "aws technologies", "glue", "s3", "lambda", "emr", "eventbridge", "athena", "kinesis", "iot core", "oracle", "microsoft sql server", "postgresql", "sybase", "sql queries", "stored procedures", "functions", "github", "teamcity", "jenkins", "svn", "big data", "visualization technologies", "data scientists", "algorithms", "statistical analysis", "prediction", "clustering", "machine learning", "cloud technologies", "ec2", "redshift/spectrum", "data pipeline", "graphical user interfaces", "html", "java", "javascript", "utilities", "python", "powershell", "unix shell scripting"]}, "b23743dfae302946": {"terms": ["machine learning engineer"], "salary_min": 131886.98, "salary_max": 166998.3, "title": "Senior Software Engineer - Systems", "company": "webAI", "desc": "Job Description: \n  We are seeking a Senior Software Engineer (Systems) with 4+ years of experience to join us in our endeavors at Iris Technology. \n  The ideal candidate will have experience in cloud native infrastructure and deployment, as well as expertise in systems architecture and distributed systems. As a Senior Software Engineer (Systems), you will be responsible for designing, developing, and maintaining our systems software to ensure scalability, reliability, and security. In this role you will leverage experience across a variety of software domains to build out critical systems and infrastructure. \n  Responsibilities: \n \n Design and architect scalable, robust, and secure system infrastructure to support WebAI's various product offerings. \n Developing and maintaining key software components within architected solutions \n Collaborate with cross-functional teams, including software engineers, ML engineers, R&D, and product managers, to ensure system design aligns with company objectives. \n Create and maintain documentation of system architecture, including diagrams and technical specifications. \n Evaluate new technologies and frameworks to improve performance, reliability, and scalability. \n Serve as the technical point of contact for architecture-related discussions and decisions. \n \n Qualifications/Requirements: \n \n Bachelor's or Master's degree in Computer Science, Information Systems, or related field. \n Minimum of 5 years of experience in system architecture or software engineering. \n Strong understanding of cloud computing, distributed systems, and microservices architecture. \n Experience developing and maining multi-cloud infrastructure and on-prem infrastructure \n Expertise in programming with both a higher level programming language and lower level programing language within the following: Rust, Python, C++, Golang, JS/TS \n Familiarity with data storage solutions, both SQL and NoSQL databases. \n Excellent communication skills, both written and verbal. \n \n Nice To Have: \n \n Previous experience in a startup or fast-paced environment. \n Experience with designing and developing distributed systems. \n Knowledge of machine learning and artificial intelligence. \n Experience with containerization technologies like Kubernetes and Docker Swarm. \n Certifications in cloud platforms like AWS, Azure, or Google Cloud. \n \n Values \n \n Ownership Mentality: Willingness to take ownership of projects and make informed decisions. \n Transparency: Being comfortable with conversations regardless if they are comfortable conversations \n Tenacity: No matter what happens, you get back up, and you support your teammates. \n Humility: Professional demeanor and ability to handle challenges with composure. \n Curiosity (Creative / Innovative): Ability to identify & design what isn't expected, but is needed.", "cleaned_desc": " Bachelor's or Master's degree in Computer Science, Information Systems, or related field. \n Minimum of 5 years of experience in system architecture or software engineering. \n Strong understanding of cloud computing, distributed systems, and microservices architecture. \n Experience developing and maining multi-cloud infrastructure and on-prem infrastructure \n Expertise in programming with both a higher level programming language and lower level programing language within the following: Rust, Python, C++, Golang, JS/TS \n Familiarity with data storage solutions, both SQL and NoSQL databases. \n Excellent communication skills, both written and verbal.   \n Nice To Have: \n \n Previous experience in a startup or fast-paced environment. \n Experience with designing and developing distributed systems. \n Knowledge of machine learning and artificial intelligence. \n Experience with containerization technologies like Kubernetes and Docker Swarm. ", "techs": ["bachelor's or master's degree in computer science", "information systems", "or related field", "cloud computing", "distributed systems", "microservices architecture", "multi-cloud infrastructure", "on-prem infrastructure", "rust", "python", "c++", "golang", "js/ts", "sql databases", "nosql databases", "communication skills", "startup experience", "designing distributed systems", "machine learning", "artificial intelligence", "kubernetes", "docker swarm."]}, "4f2c6352b6618929": {"terms": ["machine learning engineer", "mlops"], "salary_min": 180250.0, "salary_max": 208300.0, "title": "Staff Engineer, DevOps", "company": "Valo Health", "desc": "About Us \n  Valo Health is a technology company that is integrating human-centric data and AI-powered technology to accelerate the creation of life-changing drugs for more patients faster. Valo was created with the belief that the drug discovery and development process can and should be faster and less expensive, with a much higher probability of success. We are using models early to fail less often, executing clinical trials to add valuation to the company, and generating fit-for-purpose data to feed back into Valo's Opal Computational Platform\u2122 as we reinvent drug discovery and development from the ground up. Disease doesn't wait, so neither can we. \n  We are a multi-disciplinary team of experts in science, technology, and pharmaceuticals united in our mission to achieve better drugs for patients faster. Valo is committed to hiring diverse talent, prioritizing growth and development, fostering an inclusive environment, and creating opportunities to bring together a group of different experiences, backgrounds, and voices to work together. We achieve the widest-ranging impact when we leverage our broad backgrounds and perspectives to accelerate a new frontier in health. Valo seeks to become the catalyst for the pharmaceutical industry and drive the digital transformation of the industry. Are you ready to join us? \n  About the Role \n  We are looking for DevOps engineers to help manage the AWS Cloud infrastructure for our Data Science and Machine Learning environments. A successful candidate should be equally adept in handling day-to-day problems encountered by our users, as well as able to see the larger picture and change our infrastructure to lower our overall operational costs and improve user experience. \n  What You'll Do\u2026 \n \n Handle a ticket duty to resolve user problems in an AWS Cloud Environment. \n Able to extract the general shapes of problems based on ad hoc tasks and find a technical path to automate away repetitive tasks and/or create tools and processes to allow self-service by users to decrease user burden. \n \n What You Bring... \n \n Proficient in Python, and shell scripting \n Proficient in administering AWS environments: Linux EC2 instances, EKS clusters, and general networking and security best practices. \n Comfortable with Software Engineering best practices such as the use of source control systems (specifically Git), code review, automated testing, and CI/CD pipelines \n Experience with GitLab, including the deployment and administration of a self-managed GitLab server (with GitLab CI) \n Familiar with automation of cloud deployment and blueprints (e.g. Terraform, Pulumi) \n \n Salary \n  Base Salary: $180,250 to $208,300   This range represents the low and high end of the anticipated annual base salary range for the San Francisco based position. The actual annual base salary will depend on numerous factors such as: experience, knowledge, skills, and if the location of the job changes. \n  More on Valo \n  Valo Health, Inc (\"Valo\") is a technology company built to transform the drug discovery and development process using human-centric data and artificial intelligence-driven computation. As a digitally native company, Valo aims to fully integrate human-centric data across the entire drug development life cycle into a single unified architecture, thereby accelerating the discovery and development of life-changing drugs while simultaneously reducing costs, time, and failure rates. The company's Opal Computational Platform\u2122 is an integrated set of capabilities designed to transform data into valuable insights that may accelerate discoveries and enable Valo to advance a robust pipeline of programs across cardiovascular metabolic renal, oncology, and neurodegenerative disease. Founded by Flagship Pioneering and headquartered in Boston, MA, Valo also has offices in Lexington, MA, and New York. To learn more, visit www.valohealth.com.", "cleaned_desc": " Proficient in Python, and shell scripting \n Proficient in administering AWS environments: Linux EC2 instances, EKS clusters, and general networking and security best practices. \n Comfortable with Software Engineering best practices such as the use of source control systems (specifically Git), code review, automated testing, and CI/CD pipelines \n Experience with GitLab, including the deployment and administration of a self-managed GitLab server (with GitLab CI) ", "techs": ["python", "shell scripting", "linux ec2 instances", "eks clusters", "networking", "security", "aws", "git", "code review", "automated testing", "ci/cd pipelines", "gitlab", "self-managed gitlab server", "gitlab ci"]}, "66cbc46601e60721": {"terms": ["machine learning engineer"], "salary_min": 121282.83, "salary_max": 153571.08, "title": "Founding Engineer (Full Stack Software)", "company": "Cyberjin", "desc": "Hybrid/Remote role \n  Locations in multiple States \n  Our client is looking for a Founding Engineer (Full Stack Software) to join our team! You will lead the development of our Core Product: a soil carbon measurement, reporting, and verification (MRV) platform. As the first technical hire, you will work directly with the founders and own the entire technology stack, including making product decisions. You will set the technical roadmap and have the opportunity to build out a world-class technical team and culture as you see best. \n  Ideal candidate traits \n  5+ years of experience building and owning a complete end-to-end technology stack (Frontend + Backend + Cloud + CI/CD) \n  A track record of shipping and going through the full product development cycle right from writing the first line of code to product in the hands of users and iterating quickly on feedback \n  Experience with setting up the technology stack and development infrastructure from Day 1 and scaling it with growth \n \n Ability to develop infrastructure/pipelines to support Machine Learning / Remote Sensing workflows \n \n  Proactive and collaborative self-starter with a strong ability to attract other top technical talent and lead them effectively \n \n \ufe0f Past experience working in climate/agriculture is not a requirement, but a passion for climate is a plus! \n \ufe0f Past multidisciplinary teamwork (i.e. e.g. working on software in healthcare) is a huge plus, as you will be working with an interdisciplinary team with expertise in AI, Remote Sensing, Carbon Markets, Soil Carbon Modeling, Sustainable Finance \n \n  Machine Learning and Remote Sensing experience is not required, but understanding how to support these workflows (e.g. setting up data pipelines, setting up infrastructure to parallelize model runs, automating the deployment of models to integrate with the core MRV product) is a huge bonus! \n  You care deeply about climate change and feel a strong moral responsibility to act now. This extends into all facets of your life: both personal and professional. No action is too small and no goal is too big. Whether you have turned vegan or swear by public transport, we are big believers in embracing sustainability as a mindset and would love to learn what this means for you! \n   \n 0jdSUuQlGo", "cleaned_desc": "  Experience with setting up the technology stack and development infrastructure from Day 1 and scaling it with growth \n \n Ability to develop infrastructure/pipelines to support Machine Learning / Remote Sensing workflows ", "techs": ["technology stack", "development infrastructure", "machine learning", "remote sensing workflows"]}, "230d5adb172e514a": {"terms": ["machine learning engineer"], "salary_min": 106039.945, "salary_max": 134270.2, "title": "Senior Technical Services Engineer- East Coast", "company": "Weka", "desc": "WEKA is leading a paradigm shift in how data is stored, managed, and processed in the cloud and AI era. We are a pre-IPO, growth-stage company on a hyper-growth trajectory that has raised over $275M in capital and is backed by dozens of world-class venture capital and strategic investors. \n  Our flagship product, the WEKA\u00ae Data Platform, is a software-based, hybrid cloud solution transforming stagnant legacy data siloes into dynamic data pipelines that power GPUs efficiently and fuel performance-intensive workloads like generative AI and machine learning seamlessly and sustainably. \n  We\u2019re passionate about helping our customers overcome complex data management challenges to accelerate their innovation and help grow their businesses. If you share our passion, we invite you to join us on this exciting journey. \n \n  Summary \n  As Senior Technical Services Engineer, you will join a team of the most experienced Technical Services Engineers responsible for WEKA's post-sales success and big part of the 5 star gartner reviews. You will be working on cutting edge technologies with the most cutting edge customers. \n  General direction is provided on routine work, and detailed direction is provided on new projects and assignments; as well as on-going review of activities and priorities. The ideal candidate will be an important contributor on assigned projects. \n \n  Responsibilities \n \n  Bridging between the customer and R&D whenever current product features, reliability or documentation do not match the customer's expectations \n  Resolve technical problems by working with customers and engage with WEKA's R&D if required \n  Providing feedback to R&D and help to prioritize bugs, usability issues, etc. \n  Providing back-office support for pre-sales engineers, partners, and resellers \n  Keeping track of WEKA's systems via our remote monitoring tool, while proactively identifying corrective actions \n  Responsible for ownership, tracking and documenting customer issues using our ticketing system \n  Communicate effectively with employees, customer and partners, ensuring the message is concise and professional \n  Shares and documents knowledge via FAQ / KB articles, which can be internal or customer facing \n  Manage multiple projects/support cases simultaneously \n  Champion customer issues internally, and represents WEKA externally to our customers and partners \n  Become a subject matter expert in a technology \n  Be part of on-call, follow the sun model support as required \n  This position may involve alternative work hours including nights, weekends, and company holidays \n  Regional/Domestic/International travel may be required for this position \n \n  Required Skills \n \n  Hands-on experience in supporting Linux-based enterprise infrastructure products (storage, networking, virtualization, security, cloud etc.) \n  Experience in L3 support and customer interactions for enterprise infrastructure products \n  Experience in developing and optimizing interfaces between business organizations; specifically customer facing problem solving organizations and product development organizations. \n  Proven ability to resolve complex customer problems, and escalations utilizing appropriate internal and external resources and tools. \n  Strong technical troubleshooting, and fault isolation skills in a multi-platform-system-vendor environment \n  Experience Supporting Enterprise Software Solutions and/or applications, including hardware components \n  Ability to triage issues, and effectively escalate them to appropriate engineering groups as necessary \n  Understanding of networking including Infiniband, Ethernet, DPDK, UCX. \n  Demonstration of subject matter expertise and knowledge in cloud/computer/networking/storage. \n  Prior support experience at cloud/HPC related company is desired \n \n  Minimum Qualifications (Education & Experience) \n \n  Hands-on experience in supporting Linux-based enterprise infrastructure products (Cloud Applications, Storage, Networking, Virtualization, Security, etc.) \n  Proficient with at least one of the following Cloud Technologies; Amazon Web Services (AWS), Microsoft Azure, Oracle Cloud Infrastructure (OCI), or Google Cloud Platform (GCP). \n  Familiarity with Kubernetes/Containers/LXC technologies \n  Experience in L3 support and customer interactions for enterprise infrastructure products \n  Knowledge of various operating systems such as LINUX, Ubuntu and Windows \n  Technical writing \n  Highly proficient in verbal and written English \n  Minimum 10 years of experience in customer-facing, deep technical problem solving \n \n \n  USA Residents Only:  The base salary hiring wage range for this position which the Company reasonably and in good faith expects to pay for the position in the specified geographic areas or locations, is $165,000-185,000. Final compensation will be dependent on various factors relevant to the position and candidate such as geographical location, candidate qualifications, certifications, relevant job-related work experience, education, skillset and other relevant business and organizational factors, consistent with applicable law. In addition, the position may include some of the following comprehensive benefits such Medical, Dental, Vision, Life, 401(K), Flexible Time off (FTO), sick time, leave of absence as per the FMLA and other relevant leave laws. \n \n  Concerned you don\u2019t meet every qualification? Don\u2019t let it stop you from applying! \n  Studies have shown that traditionally underrepresented groups may be less likely to apply for jobs if they don\u2019t meet every qualification specified. WEKA is committed to building a diverse, inclusive, and authentic workplace. If you are excited about this position but are concerned your past work experience doesn\u2019t match up perfectly with the job description, we encourage you to apply anyway \u2013 you may be just the right candidate for this or other roles at WEKA. \n \n  WEKA is an equal-opportunity employer that prohibits discrimination and harassment of any kind. We provide equal opportunities to all employees and applicants for employment without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.", "cleaned_desc": "  This position may involve alternative work hours including nights, weekends, and company holidays \n  Regional/Domestic/International travel may be required for this position \n \n  Required Skills \n \n  Hands-on experience in supporting Linux-based enterprise infrastructure products (storage, networking, virtualization, security, cloud etc.) \n  Experience in L3 support and customer interactions for enterprise infrastructure products \n  Experience in developing and optimizing interfaces between business organizations; specifically customer facing problem solving organizations and product development organizations. \n  Proven ability to resolve complex customer problems, and escalations utilizing appropriate internal and external resources and tools. \n  Strong technical troubleshooting, and fault isolation skills in a multi-platform-system-vendor environment \n  Experience Supporting Enterprise Software Solutions and/or applications, including hardware components    Ability to triage issues, and effectively escalate them to appropriate engineering groups as necessary \n  Understanding of networking including Infiniband, Ethernet, DPDK, UCX. \n  Demonstration of subject matter expertise and knowledge in cloud/computer/networking/storage. \n  Prior support experience at cloud/HPC related company is desired \n \n  Minimum Qualifications (Education & Experience) \n \n  Hands-on experience in supporting Linux-based enterprise infrastructure products (Cloud Applications, Storage, Networking, Virtualization, Security, etc.) \n  Proficient with at least one of the following Cloud Technologies; Amazon Web Services (AWS), Microsoft Azure, Oracle Cloud Infrastructure (OCI), or Google Cloud Platform (GCP). \n  Familiarity with Kubernetes/Containers/LXC technologies \n  Experience in L3 support and customer interactions for enterprise infrastructure products ", "techs": ["linux-based enterprise infrastructure products", "storage", "networking", "virtualization", "security", "cloud", "l3 support", "customer interactions", "interfaces", "problem-solving organizations", "product development organizations", "customer problems", "escalations", "internal resources", "external resources", "tools", "technical troubleshooting", "fault isolation", "multi-platform-system-vendor environment", "enterprise software solutions", "triage issues", "networking", "infiniband", "ethernet", "dpdk", "ucx", "subject matter expertise", "knowledge", "cloud", "computer", "storage", "support experience", "cloud/hpc", "linux-based enterprise infrastructure products", "cloud applications", "networking", "virtualization", "security", "amazon web services", "aws", "microsoft azure", "oracle cloud infrastructure", "oci", "google cloud platform", "gcp", "kubernetes", "containers", "lxc technologies"]}, "442795100a8021ba": {"terms": ["machine learning engineer"], "salary_min": 106039.945, "salary_max": 134270.2, "title": "Senior Technical Services Engineer- East Coast", "company": "Weka", "desc": "WEKA is leading a paradigm shift in how data is stored, managed, and processed in the cloud and AI era. We are a pre-IPO, growth-stage company on a hyper-growth trajectory that has raised over $275M in capital and is backed by dozens of world-class venture capital and strategic investors. \n  Our flagship product, the WEKA\u00ae Data Platform, is a software-based, hybrid cloud solution transforming stagnant legacy data siloes into dynamic data pipelines that power GPUs efficiently and fuel performance-intensive workloads like generative AI and machine learning seamlessly and sustainably. \n  We\u2019re passionate about helping our customers overcome complex data management challenges to accelerate their innovation and help grow their businesses. If you share our passion, we invite you to join us on this exciting journey. \n \n  Summary \n  As Senior Technical Services Engineer, you will join a team of the most experienced Technical Services Engineers responsible for WEKA's post-sales success and big part of the 5 star gartner reviews. You will be working on cutting edge technologies with the most cutting edge customers. \n  General direction is provided on routine work, and detailed direction is provided on new projects and assignments; as well as on-going review of activities and priorities. The ideal candidate will be an important contributor on assigned projects. \n \n  Responsibilities \n \n  Bridging between the customer and R&D whenever current product features, reliability or documentation do not match the customer's expectations \n  Resolve technical problems by working with customers and engage with WEKA's R&D if required \n  Providing feedback to R&D and help to prioritize bugs, usability issues, etc. \n  Providing back-office support for pre-sales engineers, partners, and resellers \n  Keeping track of WEKA's systems via our remote monitoring tool, while proactively identifying corrective actions \n  Responsible for ownership, tracking and documenting customer issues using our ticketing system \n  Communicate effectively with employees, customer and partners, ensuring the message is concise and professional \n  Shares and documents knowledge via FAQ / KB articles, which can be internal or customer facing \n  Manage multiple projects/support cases simultaneously \n  Champion customer issues internally, and represents WEKA externally to our customers and partners \n  Become a subject matter expert in a technology \n  Be part of on-call, follow the sun model support as required \n  This position may involve alternative work hours including nights, weekends, and company holidays \n  Regional/Domestic/International travel may be required for this position \n \n  Required Skills \n \n  Hands-on experience in supporting Linux-based enterprise infrastructure products (storage, networking, virtualization, security, cloud etc.) \n  Experience in L3 support and customer interactions for enterprise infrastructure products \n  Experience in developing and optimizing interfaces between business organizations; specifically customer facing problem solving organizations and product development organizations. \n  Proven ability to resolve complex customer problems, and escalations utilizing appropriate internal and external resources and tools. \n  Strong technical troubleshooting, and fault isolation skills in a multi-platform-system-vendor environment \n  Experience Supporting Enterprise Software Solutions and/or applications, including hardware components \n  Ability to triage issues, and effectively escalate them to appropriate engineering groups as necessary \n  Understanding of networking including Infiniband, Ethernet, DPDK, UCX. \n  Demonstration of subject matter expertise and knowledge in cloud/computer/networking/storage. \n  Prior support experience at cloud/HPC related company is desired \n \n  Minimum Qualifications (Education & Experience) \n \n  Hands-on experience in supporting Linux-based enterprise infrastructure products (Cloud Applications, Storage, Networking, Virtualization, Security, etc.) \n  Proficient with at least one of the following Cloud Technologies; Amazon Web Services (AWS), Microsoft Azure, Oracle Cloud Infrastructure (OCI), or Google Cloud Platform (GCP). \n  Familiarity with Kubernetes/Containers/LXC technologies \n  Experience in L3 support and customer interactions for enterprise infrastructure products \n  Knowledge of various operating systems such as LINUX, Ubuntu and Windows \n  Technical writing \n  Highly proficient in verbal and written English \n  Minimum 10 years of experience in customer-facing, deep technical problem solving \n \n \n  USA Residents Only:  The base salary hiring wage range for this position which the Company reasonably and in good faith expects to pay for the position in the specified geographic areas or locations, is $165,000-185,000. Final compensation will be dependent on various factors relevant to the position and candidate such as geographical location, candidate qualifications, certifications, relevant job-related work experience, education, skillset and other relevant business and organizational factors, consistent with applicable law. In addition, the position may include some of the following comprehensive benefits such Medical, Dental, Vision, Life, 401(K), Flexible Time off (FTO), sick time, leave of absence as per the FMLA and other relevant leave laws. \n \n  Concerned you don\u2019t meet every qualification? Don\u2019t let it stop you from applying! \n  Studies have shown that traditionally underrepresented groups may be less likely to apply for jobs if they don\u2019t meet every qualification specified. WEKA is committed to building a diverse, inclusive, and authentic workplace. If you are excited about this position but are concerned your past work experience doesn\u2019t match up perfectly with the job description, we encourage you to apply anyway \u2013 you may be just the right candidate for this or other roles at WEKA. \n \n  WEKA is an equal-opportunity employer that prohibits discrimination and harassment of any kind. We provide equal opportunities to all employees and applicants for employment without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.", "cleaned_desc": "  This position may involve alternative work hours including nights, weekends, and company holidays \n  Regional/Domestic/International travel may be required for this position \n \n  Required Skills \n \n  Hands-on experience in supporting Linux-based enterprise infrastructure products (storage, networking, virtualization, security, cloud etc.) \n  Experience in L3 support and customer interactions for enterprise infrastructure products \n  Experience in developing and optimizing interfaces between business organizations; specifically customer facing problem solving organizations and product development organizations. \n  Proven ability to resolve complex customer problems, and escalations utilizing appropriate internal and external resources and tools. \n  Strong technical troubleshooting, and fault isolation skills in a multi-platform-system-vendor environment \n  Experience Supporting Enterprise Software Solutions and/or applications, including hardware components    Ability to triage issues, and effectively escalate them to appropriate engineering groups as necessary \n  Understanding of networking including Infiniband, Ethernet, DPDK, UCX. \n  Demonstration of subject matter expertise and knowledge in cloud/computer/networking/storage. \n  Prior support experience at cloud/HPC related company is desired \n \n  Minimum Qualifications (Education & Experience) \n \n  Hands-on experience in supporting Linux-based enterprise infrastructure products (Cloud Applications, Storage, Networking, Virtualization, Security, etc.) \n  Proficient with at least one of the following Cloud Technologies; Amazon Web Services (AWS), Microsoft Azure, Oracle Cloud Infrastructure (OCI), or Google Cloud Platform (GCP). \n  Familiarity with Kubernetes/Containers/LXC technologies \n  Experience in L3 support and customer interactions for enterprise infrastructure products ", "techs": ["linux-based enterprise infrastructure products", "storage", "networking", "virtualization", "security", "cloud", "l3 support", "customer interactions", "interfaces", "customer facing problem solving", "product development", "technical troubleshooting", "fault isolation", "multi-platform-system-vendor environment", "enterprise software solutions", "hardware components", "triage issues", "engineering groups", "networking", "infiniband", "ethernet", "dpdk", "ucx", "cloud/computer/networking/storage", "support experience", "cloud/hpc related company", "cloud applications", "cloud technologies", "amazon web services (aws)", "microsoft azure", "oracle cloud infrastructure (oci)", "google cloud platform (gcp)", "kubernetes", "containers", "lxc"]}, "9d0e29ab2361e87d": {"terms": ["machine learning engineer"], "salary_min": 106039.945, "salary_max": 134270.2, "title": "Senior Technical Services Engineer- East Coast", "company": "Weka", "desc": "WEKA is leading a paradigm shift in how data is stored, managed, and processed in the cloud and AI era. We are a pre-IPO, growth-stage company on a hyper-growth trajectory that has raised over $275M in capital and is backed by dozens of world-class venture capital and strategic investors. \n  Our flagship product, the WEKA\u00ae Data Platform, is a software-based, hybrid cloud solution transforming stagnant legacy data siloes into dynamic data pipelines that power GPUs efficiently and fuel performance-intensive workloads like generative AI and machine learning seamlessly and sustainably. \n  We\u2019re passionate about helping our customers overcome complex data management challenges to accelerate their innovation and help grow their businesses. If you share our passion, we invite you to join us on this exciting journey. \n \n  Summary \n  As Senior Technical Services Engineer, you will join a team of the most experienced Technical Services Engineers responsible for WEKA's post-sales success and big part of the 5 star gartner reviews. You will be working on cutting edge technologies with the most cutting edge customers. \n  General direction is provided on routine work, and detailed direction is provided on new projects and assignments; as well as on-going review of activities and priorities. The ideal candidate will be an important contributor on assigned projects. \n \n  Responsibilities \n \n  Bridging between the customer and R&D whenever current product features, reliability or documentation do not match the customer's expectations \n  Resolve technical problems by working with customers and engage with WEKA's R&D if required \n  Providing feedback to R&D and help to prioritize bugs, usability issues, etc. \n  Providing back-office support for pre-sales engineers, partners, and resellers \n  Keeping track of WEKA's systems via our remote monitoring tool, while proactively identifying corrective actions \n  Responsible for ownership, tracking and documenting customer issues using our ticketing system \n  Communicate effectively with employees, customer and partners, ensuring the message is concise and professional \n  Shares and documents knowledge via FAQ / KB articles, which can be internal or customer facing \n  Manage multiple projects/support cases simultaneously \n  Champion customer issues internally, and represents WEKA externally to our customers and partners \n  Become a subject matter expert in a technology \n  Be part of on-call, follow the sun model support as required \n  This position may involve alternative work hours including nights, weekends, and company holidays \n  Regional/Domestic/International travel may be required for this position \n \n  Required Skills \n \n  Hands-on experience in supporting Linux-based enterprise infrastructure products (storage, networking, virtualization, security, cloud etc.) \n  Experience in L3 support and customer interactions for enterprise infrastructure products \n  Experience in developing and optimizing interfaces between business organizations; specifically customer facing problem solving organizations and product development organizations. \n  Proven ability to resolve complex customer problems, and escalations utilizing appropriate internal and external resources and tools. \n  Strong technical troubleshooting, and fault isolation skills in a multi-platform-system-vendor environment \n  Experience Supporting Enterprise Software Solutions and/or applications, including hardware components \n  Ability to triage issues, and effectively escalate them to appropriate engineering groups as necessary \n  Understanding of networking including Infiniband, Ethernet, DPDK, UCX. \n  Demonstration of subject matter expertise and knowledge in cloud/computer/networking/storage. \n  Prior support experience at cloud/HPC related company is desired \n \n  Minimum Qualifications (Education & Experience) \n \n  Hands-on experience in supporting Linux-based enterprise infrastructure products (Cloud Applications, Storage, Networking, Virtualization, Security, etc.) \n  Proficient with at least one of the following Cloud Technologies; Amazon Web Services (AWS), Microsoft Azure, Oracle Cloud Infrastructure (OCI), or Google Cloud Platform (GCP). \n  Familiarity with Kubernetes/Containers/LXC technologies \n  Experience in L3 support and customer interactions for enterprise infrastructure products \n  Knowledge of various operating systems such as LINUX, Ubuntu and Windows \n  Technical writing \n  Highly proficient in verbal and written English \n  Minimum 10 years of experience in customer-facing, deep technical problem solving \n \n \n  USA Residents Only:  The base salary hiring wage range for this position which the Company reasonably and in good faith expects to pay for the position in the specified geographic areas or locations, is $165,000-185,000. Final compensation will be dependent on various factors relevant to the position and candidate such as geographical location, candidate qualifications, certifications, relevant job-related work experience, education, skillset and other relevant business and organizational factors, consistent with applicable law. In addition, the position may include some of the following comprehensive benefits such Medical, Dental, Vision, Life, 401(K), Flexible Time off (FTO), sick time, leave of absence as per the FMLA and other relevant leave laws. \n \n  Concerned you don\u2019t meet every qualification? Don\u2019t let it stop you from applying! \n  Studies have shown that traditionally underrepresented groups may be less likely to apply for jobs if they don\u2019t meet every qualification specified. WEKA is committed to building a diverse, inclusive, and authentic workplace. If you are excited about this position but are concerned your past work experience doesn\u2019t match up perfectly with the job description, we encourage you to apply anyway \u2013 you may be just the right candidate for this or other roles at WEKA. \n \n  WEKA is an equal-opportunity employer that prohibits discrimination and harassment of any kind. We provide equal opportunities to all employees and applicants for employment without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.", "cleaned_desc": "  This position may involve alternative work hours including nights, weekends, and company holidays \n  Regional/Domestic/International travel may be required for this position \n \n  Required Skills \n \n  Hands-on experience in supporting Linux-based enterprise infrastructure products (storage, networking, virtualization, security, cloud etc.) \n  Experience in L3 support and customer interactions for enterprise infrastructure products \n  Experience in developing and optimizing interfaces between business organizations; specifically customer facing problem solving organizations and product development organizations. \n  Proven ability to resolve complex customer problems, and escalations utilizing appropriate internal and external resources and tools. \n  Strong technical troubleshooting, and fault isolation skills in a multi-platform-system-vendor environment \n  Experience Supporting Enterprise Software Solutions and/or applications, including hardware components    Ability to triage issues, and effectively escalate them to appropriate engineering groups as necessary \n  Understanding of networking including Infiniband, Ethernet, DPDK, UCX. \n  Demonstration of subject matter expertise and knowledge in cloud/computer/networking/storage. \n  Prior support experience at cloud/HPC related company is desired \n \n  Minimum Qualifications (Education & Experience) \n \n  Hands-on experience in supporting Linux-based enterprise infrastructure products (Cloud Applications, Storage, Networking, Virtualization, Security, etc.) \n  Proficient with at least one of the following Cloud Technologies; Amazon Web Services (AWS), Microsoft Azure, Oracle Cloud Infrastructure (OCI), or Google Cloud Platform (GCP). \n  Familiarity with Kubernetes/Containers/LXC technologies \n  Experience in L3 support and customer interactions for enterprise infrastructure products ", "techs": ["linux-based enterprise infrastructure products", "storage", "networking", "virtualization", "security", "cloud", "l3 support", "customer interactions", "interfaces", "problem solving", "complex customer problems", "technical troubleshooting", "fault isolation", "multi-platform-system-vendor environment", "enterprise software solutions", "hardware components", "triage issues", "engineering groups", "networking", "infiniband", "ethernet", "dpdk", "ucx", "cloud/computer/networking/storage", "support experience", "cloud/hpc related company", "cloud applications", "cloud technologies", "amazon web services (aws)", "microsoft azure", "oracle cloud infrastructure (oci)", "google cloud platform (gcp)", "kubernetes", "containers", "lxc technologies"]}, "e3a17f7ef0e53249": {"terms": ["machine learning engineer"], "salary_min": 121282.83, "salary_max": 153571.08, "title": "Founding Engineer (Full Stack Software)", "company": "Cyberjin", "desc": "Hybrid/Remote role \n  Our client is looking for a Founding Engineer (Full Stack Software) to join our team! You will lead the development of our Core Product: a soil carbon measurement, reporting, and verification (MRV) platform. As the first technical hire, you will work directly with the founders and own the entire technology stack, including making product decisions. You will set the technical roadmap and have the opportunity to build out a world-class technical team and culture as you see best. \n  Ideal candidate traits \n  5+ years of experience building and owning a complete end-to-end technology stack (Frontend + Backend + Cloud + CI/CD) \n  A track record of shipping and going through the full product development cycle right from writing the first line of code to product in the hands of users and iterating quickly on feedback \n  Experience with setting up the technology stack and development infrastructure from Day 1 and scaling it with growth \n \n Ability to develop infrastructure/pipelines to support Machine Learning / Remote Sensing workflows \n \n  Proactive and collaborative self-starter with a strong ability to attract other top technical talent and lead them effectively \n \n \ufe0f Past experience working in climate/agriculture is not a requirement, but a passion for climate is a plus! \n \ufe0f Past multidisciplinary teamwork (i.e. e.g. working on software in healthcare) is a huge plus, as you will be working with an interdisciplinary team with expertise in AI, Remote Sensing, Carbon Markets, Soil Carbon Modeling, Sustainable Finance \n \n  Machine Learning and Remote Sensing experience is not required, but understanding how to support these workflows (e.g. setting up data pipelines, setting up infrastructure to parallelize model runs, automating the deployment of models to integrate with the core MRV product) is a huge bonus! \n  You care deeply about climate change and feel a strong moral responsibility to act now. This extends into all facets of your life: both personal and professional. No action is too small and no goal is too big. Whether you have turned vegan or swear by public transport, we are big believers in embracing sustainability as a mindset and would love to learn what this means for you! \n   \n dB7xNINclI", "cleaned_desc": "", "techs": ""}, "fa73dcca82b50049": {"terms": ["mlops"], "salary_min": null, "salary_max": null, "title": "Devops Manager, Software Engineering - Group Benefits", "company": "The Hartford", "desc": "Manager Software Engineering - IE07FE\n  \n \n   We\u2019re determined to make a difference and are proud to be an insurance company that goes well beyond coverages and policies. Working here means having every opportunity to achieve your goals \u2013 and to help others accomplish theirs, too. Join our team as we help shape the future.\n  \n \n \n  The Hartford is seeking a highly motivated IT professional with proven leadership experience who will be responsible for the advancement of our Devops and testing initiatives in the Group Benefits space.\n  \n \n  Responsibilities:\n  \n \n \n \n     Leads by hands-on-keyboard example, leveraging technical expertise to implement and execute Devops processes.\n    \n \n \n     Overall accountable for end-to-end automation of deployment, test environments and test data management.\n    \n \n \n     Establishes and executes overall test strategy, with strong partnership from our BIT and UAT teams.\n    \n \n \n     Leverages deep technical acumen to drive experimentation of emerging technologies to further automate our CI/CD pipeline and shift quality/security left. \n    \n \n \n    Collaborates with GB IT Operations and CTO team to drive observability which will continuously monitor and improve the health of our delivery processes.\n    \n \n \n     Partners with key stakeholders to plan and execute application suite Cloud Transformation.\n    \n \n \n     Collaborates across GB IT and enterprise to drive DevOps best practices.\n    \n \n \n     Leads release management capabilities and continuous improvement to optimize our automated continuous delivery processes.\n    \n \n \n \n   Qualifications:\n  \n \n \n \n     Proven track record as a results-oriented IT leader.\n    \n \n \n     Solid background in technology, and familiarity with release management and testing automation best practices.\n    \n \n \n     Experience with Playwright or equivalent.\n    \n \n \n     Experience with Github actions, Jenkins, or equivalent\n    \n \n \n     Experience with Infrastructure as Code (IaC) using CloudFormation and Terraform templates or equivalent\n    \n \n \n     AWS experience preferred\n    \n \n \n \n  Candidates must be authorized to work in the US without company sponsorship \n \n \n  Sustaining The Hartford\u2019s unique workplace culture is vital to delivering on our purpose \u2013 underwriting human achievement \u2013 and continuously producing outstanding results. Our enterprise work model, which reflects a mix of in-office, hybrid and fully remote roles, helps us attract, retain and develop the talent we need to achieve the company\u2019s strategic  \n goals. This \n  role will have a Hybrid work  \n arrangement. \n \n \n \n   Compensation\n  \n \n   The listed annualized base pay range is primarily based on analysis of similar positions in the external market. Actual base pay could vary and may be above or below the listed range based on factors including but not limited to performance, proficiency and demonstration of competencies required for the role. The base pay is just one component of The Hartford\u2019s total compensation package for employees. Other rewards may include short-term or annual bonuses, long-term incentives, and on-the-spot recognition. The annualized base pay range for this role is:\n  \n  $126,000 - $189,000\n  \n \n   Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age", "cleaned_desc": "     Solid background in technology, and familiarity with release management and testing automation best practices.\n    \n \n \n     Experience with Playwright or equivalent.\n    \n \n \n     Experience with Github actions, Jenkins, or equivalent\n    \n \n \n     Experience with Infrastructure as Code (IaC) using CloudFormation and Terraform templates or equivalent\n    \n \n \n     AWS experience preferred\n    \n ", "techs": ["playwright", "github actions", "jenkins", "infrastructure as code (iac) using cloudformation and terraform templates", "aws"]}, "d4f297a88b194919": {"terms": ["mlops"], "salary_min": 81800.0, "salary_max": 186000.0, "title": "Bioinformatics Specialist", "company": "Booz Allen Hamilton", "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Atlanta,GA,US \n         \n \n \n \n         Remote Work: \n         \n \n         Yes \n         \n \n \n \n         Job Number: \n         \n \n         R0182249\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Bioinformatics Specialist\n           The Challenge: \n  Are you excited at the prospect of unlocking the secrets held by a data set? Are you fascinated by the possibilities presented by the IoT, machine learning, and artificial intelligence advances? In an increasingly connected world, massive amounts of structured and unstructured data open up new opportunities. As a data scientist, you can turn these complex data sets into useful information to solve global challenges. Across private and public sectors \u2014 from fraud detection to cancer research, to national intelligence \u2014 you know the answers are in the data. \n \n  We have an opportunity for you to use your analytical skills to improve public health. You\u2019ll work closely with your customer to understand their questions and needs, and then dig into their data-rich environment to find the pieces of their information puzzle. You\u2019ll analyze analytics and automation and use the right combination of tools and frameworks to turn that set of disparate data points into objective answers to help the client make informed decisions. You\u2019ll provide your customer with a deep understanding of their data, what it all means, and how they can use it. Join us as we use data science for good in public health. \n \n  Empower change with us. \n \n  You Have: \n \n  Experience with bioinformatics and genomic toolkits, databases, and scripting languages, including Python, R, and Shell \n  Experience with using parallel programming capabilities through workflow tools, including Snakemake or Nextflow, on Linux based high-performance computing environments \n  Experience with next-generation sequencing, omics data analysis, and open-source omics analysis tools and workflows as they apply to public health genomics \n  Experience with data management using SQL and NoSQL based technologies \n  Knowledge of statistical techniques, including multivariate analysis and hypothesis testing for omics data analysis \n  Ability to conduct analysis, interpretation, and communication of complex large datasets independently clearly and concisely \n  Ability to obtain and maintain a Public Trust or Suitability/Fitness determination based on client requirements \n  Master\u2019s degree \n \n \n  Nice If You Have: \n \n  Experience with incorporating CI/CD, DevSecOps, and MLOps best practices into the development process \n  Experience with working in cloud based environments using AWS and Azure and data warehousing solutions, including Databricks \n  Experience with a wide range of supervised and unsupervised machine learning techniques, including neural networks, decision trees, logistic regressions, or dimension reduction \n  Experience with visualization tools, including Power BI, Tableau, ArcGIS, or Splunk \n  Experience with SAS and SSPS programming using advanced programming methods and techniques \n  Ability to write white papers and scientific and technical manuscripts for publication \n  Master's degree in Bioinformatics, Math, Biostatistics, Physics, Analytics, Computer Science, Data Science, Epidemiology, or Life Science or Doctorate degree in Bioinformatics, Math, Biostatistics, Physics, Analytics, Computer Science, Data Science, Epidemiology, or Life Science \n \n \n  Vetting: \n  Applicants selected will be subject to a government investigation and may need to meet eligibility requirements of the U.S. government client. \n \n  Build Your Career: \n  At Booz Allen, we know the power of analytics and we\u2019re dedicated to helping you grow as a data analysis professional. When you join Booz Allen, you\u2019ll have the chance to: \n \n  access online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk \n  change the world with the Data Science Bowl\u2014the world\u2019s premier data science for social good competition \n  participate in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government \n \n \n  You\u2019ll have access to a wealth of training resources through our Analytics University, an online learning portal specifically geared towards data science and analytics skills, where you can access more than 5000 functional and technical courses, certifications, and books. Build your technical skills through hands-on training on the latest tools and state-of-the-art tech from our in-house experts. Pursuing certifications that directly impact your role? You may be able to take advantage of our tuition assistance, on-site boot camps, certification training, academic programs, vendor relationships, and a network of professionals who can give you helpful tips. We\u2019ll help you develop the career you want as you chart your own course for success. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $81,800.00 to $186,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.", "cleaned_desc": " \n \n \n \n \n \n \n \n         Bioinformatics Specialist\n           The Challenge: \n  Are you excited at the prospect of unlocking the secrets held by a data set? Are you fascinated by the possibilities presented by the IoT, machine learning, and artificial intelligence advances? In an increasingly connected world, massive amounts of structured and unstructured data open up new opportunities. As a data scientist, you can turn these complex data sets into useful information to solve global challenges. Across private and public sectors \u2014 from fraud detection to cancer research, to national intelligence \u2014 you know the answers are in the data. \n \n  We have an opportunity for you to use your analytical skills to improve public health. You\u2019ll work closely with your customer to understand their questions and needs, and then dig into their data-rich environment to find the pieces of their information puzzle. You\u2019ll analyze analytics and automation and use the right combination of tools and frameworks to turn that set of disparate data points into objective answers to help the client make informed decisions. You\u2019ll provide your customer with a deep understanding of their data, what it all means, and how they can use it. Join us as we use data science for good in public health. \n \n  Empower change with us. \n \n  You Have: \n \n  Experience with bioinformatics and genomic toolkits, databases, and scripting languages, including Python, R, and Shell \n  Experience with using parallel programming capabilities through workflow tools, including Snakemake or Nextflow, on Linux based high-performance computing environments \n  Experience with next-generation sequencing, omics data analysis, and open-source omics analysis tools and workflows as they apply to public health genomics    Experience with data management using SQL and NoSQL based technologies \n  Knowledge of statistical techniques, including multivariate analysis and hypothesis testing for omics data analysis \n  Ability to conduct analysis, interpretation, and communication of complex large datasets independently clearly and concisely \n  Ability to obtain and maintain a Public Trust or Suitability/Fitness determination based on client requirements \n  Master\u2019s degree \n \n \n  Nice If You Have: \n \n  Experience with incorporating CI/CD, DevSecOps, and MLOps best practices into the development process \n  Experience with working in cloud based environments using AWS and Azure and data warehousing solutions, including Databricks \n  Experience with a wide range of supervised and unsupervised machine learning techniques, including neural networks, decision trees, logistic regressions, or dimension reduction \n  Experience with visualization tools, including Power BI, Tableau, ArcGIS, or Splunk \n  Experience with SAS and SSPS programming using advanced programming methods and techniques \n  Ability to write white papers and scientific and technical manuscripts for publication \n  Master's degree in Bioinformatics, Math, Biostatistics, Physics, Analytics, Computer Science, Data Science, Epidemiology, or Life Science or Doctorate degree in Bioinformatics, Math, Biostatistics, Physics, Analytics, Computer Science, Data Science, Epidemiology, or Life Science \n \n \n  Vetting: \n  Applicants selected will be subject to a government investigation and may need to meet eligibility requirements of the U.S. government client. \n ", "techs": ["bioinformatics toolkits", "databases", "scripting languages (python", "r", "shell)", "parallel programming capabilities (snakemake", "nextflow)", "linux based high-performance computing environments", "next-generation sequencing", "omics data analysis", "open-source omics analysis tools and workflows", "sql", "nosql", "statistical techniques", "multivariate analysis", "hypothesis testing", "data management", "ci/cd", "devsecops", "mlops", "cloud based environments (aws", "azure)", "data warehousing solutions (databricks)", "supervised and unsupervised machine learning techniques", "neural networks", "decision trees", "logistic regressions", "dimension reduction", "visualization tools (power bi", "tableau", "arcgis", "splunk)", "sas programming", "ssps programming", "white papers", "scientific and technical manuscripts", "public trust or suitability/fitness determination"]}, "01ad3e11cefaa9f5": {"terms": ["mlops"], "salary_min": 100000.0, "salary_max": 155000.0, "title": "DevOps Engineer", "company": "Qlik", "desc": "What makes us Qlik \n \n   Qlik helps enterprises around the world move faster, work smarter, and lead the way forward with an end-to-end solution for getting value out of data. A Gartner Magic Quadrant Leader for 13 years in a row! Our platform is the only one on the market that allows for open-ended, curiosity-driven exploration, giving everyone \u2013 at any skill level \u2013 the ability to make real discoveries that lead to real outcomes and transformative changes. We are a Values-Driven organization, operating over 100 countries with 38,000 customers around the world. If you think we are interesting, please read on \u2013 we may be looking for you!\n   \n \n    DevOps Engineer \n \n   In this role you\u2019ll need to collaborate effectively with people that have diverse backgrounds and skill sets in addition to having and applying a deep understanding of critical technical skills. You will mentor others in their areas of strength and experience, while quickly learning new skills, adapting, and contributing in areas outside of your previous focus as needs arise. We ask that you are an effective and compassionate communicator and are able to construct and present valid arguments for decisions and discuss solutions with humility and mutual respect for the opinions and thoughts of others. You are always ready both to learn and to teach with the primary goal that the team succeeds.\n  \n   \n Responsibilities include, but not limited to: \n \n  Helping to manage, expand, and improve the infrastructure on which our applications and services run. \n  Facilitating SOC compliance and security best practices as it is today and as it evolves. \n  Analyzing and monitoring applications and infrastructure to proactively identify issues before they become problems. \n  Facilitating application deployments and continuous integration deployment pipelines. \n  Helping developers to remain productive and assist them to remove blockers. \n  Participating in planning discussions to gain understanding of product road maps with an eye on staying ahead of infrastructure needs as we grow. \n  Assisting the team with architectural decisions. \n  Triaging when necessary and helping to address the problems and complexities that arise as products and teams grow. \n  Assisting in evaluating, or developing, and implementing new tools that help us more effectively and efficiently achieve our goals. \n  Mentoring junior engineers to help them improve their practices and understanding of networking, security, data management, compliance, tools and best practices. \n  Facilitating cost control by regularly evaluating and right-sizing provisioned resources \n  Assisting with writing and maintaining documentation required for soc compliance and business needs. \n \n  Skills and qualifications for this role include: \n  Required:  \n \n Three or more years DevOps experience. \n  Proficiency in one or more scripting languages. \n  A healthy fear of breaking our production environment. \n  Working knowledge of cloud development and infrastructure tools. \n  Proficiency with Kubernetes and related services.  \n Experience working in an AWS VPC environment.  \n Proficiency working with Docker including creating images. \n  Proficiency working with APIs. \n  Strong understanding of security best practices through multiple layers of infrastructure. \n  Familiarity working in Linux environments. \n  Ability to communicate and collaborate effectively. \n  Effective written communication skills. \n  Experience with Infrastructure as Code. \n  Experience working with Grafana or similar. \n \n  Preferred:  \n \n CKA (Certified Kubernetes Administrator). \n  Experience working in GitOps environments. \n  Experience working with Splunk or Dynatrace. \n  Proficiency with shell scripting. \n  Experience working with Helm charts and yaml. \n  RabbitMQ and/or Kafka or Solace. \n  Experience with SQL and relational databases. \n  Experience with MongoDB and/or PostGres. \n  Golang and/or Python scripting skills. \n  Experience with Terraform. \n  Familiarity with CI/CD pipeline. \n  Proficiency in networking and related technologies. \n \n \n  The location for this role is: \n \n  United States \n \n   \n About Qlik \n \n  Qlik Company Page \u2013 Who we are!  \n Our Values at Qlik:   Challenge, Take Responsibility, Move Fast, T eamwork for Results , Be Open and Straightforward   \n Competitive Benefits package \n  Flexible working environment \n  Giving back is a part of our culture \u2013 we give you a day to change the world. In addition, we encourage our employees to participate in our Corporate Responsibility Employee Programs \n  Learn about our Corporate Responsibility Program by visiting Qlik.org \n  Check out our careers in R&D here. \n  Check out our company page on Linkedin! \n  Follow us on Instagram @lifeatqlik and @Qlik @lifeatqliklund \n  Check us out on Youtube! \n \n \n \n  The base salary range for this role is $ \n 1 \n 00,000 \n -$ \n 155,000 \n . \n \n \n \n \n \n Compensation offered will be based on factors such as the candidate\u2019s location, job related skills, education, experience and other business and organizational needs.  \n \n \n Qlik offers a comprehensive benefits package which includes, but is not limited to, healthcare and dental benefits, a 401(k) plan and match, paid time off, and mental health benefits. \n \n \n \n  Qlik is an Equal Opportunity/Affirmative Action  \n Employer, \n  and we value the diversity of our workforce \n .  Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Click here to review the US Department of Labor\u2019s \n   Equal Employment Opportunity Posters , including the \n   EEO is The Law  notice and the \n   Pay Transparency  \n Nondiscrimination Provision .\n  \n \n \n  If you need assistance due to disability during the application and/or recruiting process, please contact us via the  \n Accessibility Request Form \n . \n \n \n \n  Qlik is not accepting unsolicited assistance from search firms for this employment opportunity. Please, no phone calls or emails. All resumes submitted by search firms to any employee at Qlik via-email, the Internet or in any form and/or method without a valid written search agreement in place for this position will be deemed the sole property of Qlik. No fee will be paid in the event the candidate is hired by Qlik as a result of the referral or through other means.", "cleaned_desc": "  Facilitating cost control by regularly evaluating and right-sizing provisioned resources \n  Assisting with writing and maintaining documentation required for soc compliance and business needs. \n \n  Skills and qualifications for this role include: \n  Required:  \n \n Three or more years DevOps experience. \n  Proficiency in one or more scripting languages. \n  A healthy fear of breaking our production environment. \n  Working knowledge of cloud development and infrastructure tools. \n  Proficiency with Kubernetes and related services.  \n Experience working in an AWS VPC environment.  \n Proficiency working with Docker including creating images. \n  Proficiency working with APIs. \n  Strong understanding of security best practices through multiple layers of infrastructure. \n  Familiarity working in Linux environments. \n  Ability to communicate and collaborate effectively. \n  Effective written communication skills. \n  Experience with Infrastructure as Code. \n  Experience working with Grafana or similar. \n \n  Preferred:    \n CKA (Certified Kubernetes Administrator). \n  Experience working in GitOps environments. \n  Experience working with Splunk or Dynatrace. \n  Proficiency with shell scripting. \n  Experience working with Helm charts and yaml. \n  RabbitMQ and/or Kafka or Solace. \n  Experience with SQL and relational databases. \n  Experience with MongoDB and/or PostGres. \n  Golang and/or Python scripting skills. \n  Experience with Terraform. \n  Familiarity with CI/CD pipeline. \n  Proficiency in networking and related technologies. \n \n \n  The location for this role is: \n \n  United States \n \n   \n About Qlik \n ", "techs": ["facilitating cost control", "right-sizing provisioned resources", "writing and maintaining documentation", "devops experience", "scripting languages", "cloud development and infrastructure tools", "kubernetes", "aws vpc environment", "docker", "apis", "security best practices", "linux environments", "communication and collaboration skills", "written communication skills", "infrastructure as code", "grafana", "cka (certified kubernetes administrator)", "gitops environments", "splunk or dynatrace", "shell scripting", "helm charts and yaml", "rabbitmq and/or kafka or solace", "sql and relational databases", "mongodb and/or postgres", "golang and/or python scripting skills", "terraform", "ci/cd pipeline", "networking and related technologies."]}, "1093bd48d0f223e7": {"terms": ["mlops"], "salary_min": 107417.55, "salary_max": 136014.55, "title": "DevOps Engineer", "company": "EX Squared Outcoding", "desc": "Become an Outcoder as a DevOps Engineer \n We seek a DevOps Engineer to help us build functional systems that improve customer experience. DevOps Engineer responsibilities include deploying product updates, identifying production issues, and implementing integrations that meet customer needs. If you have a solid background in software engineering and are familiar with Ruby or Python, we'd like to meet you. Ultimately, you will execute and automate operational processes fast, accurately, and securely. \n What you'll need to be successful: \n \n Work experience as a DevOps Engineer or similar software engineering role \n  Good knowledge of Ruby or Python \n  Working knowledge of databases and SQL \n  Problem-solving attitude \n  Team spirit \n  BSc in Computer Science, Engineering, or a relevant field \n \n About us:  EX\u00b2 Outcoding is a premier solution provider of a broad range of outsourcing services, combining proven expertise in technology and project execution for companies searching for high-quality software development solutions. We specialize in delivering the best technical solution but also in enhancing that solution creatively by working closely with stakeholders to understand the business context. \n #LI-REMOTE", "cleaned_desc": "", "techs": ""}, "5d4607f2ec3aee29": {"terms": ["mlops"], "salary_min": 70000.0, "salary_max": 79500.0, "title": "Junior DevOps Engineer", "company": "Viderity Inc.", "desc": "Viderity is an award-winning consulting firm that provides IT and outreach services to federal agencies and commercial organizations. You'll be working with a friendly and whip-smart team supporting a well-known organization responsible for exciting discoveries ranging from the first internet browser to black holes to the first semiconductor! \n \n  Job Description: \n  Design and develop automated build, test, and deployment systems across multiple codebases, build tools, application servers, and platforms. Work with emerging and legacy project teams to develop easy-to-adopt automated solutions for their development pipelines and software development lifecycle. Perform maintenance and troubleshooting of continuous integration systems including build and deployment used across multiple environments. Design, maintain, and troubleshoot automated testing and tools to support multiple projects and SDLC methodologies (i.e. Agile, Waterfall). Design and implement static code analysis standards and metrics, aggregate and track across project teams. Design and develop cloud architectures including configuring and spinning up virtual machines for application deployment, including Linux / Windows operating systems, cloud automation and configuration tools, understanding the need for scaling, templating and automation. Proactively communicate and coordinate with multiple project teams. Independently seek opportunities to implement speed and efficiency improvements as technology and capabilities evolve. Seek out new DevOps related capabilities via open-source industry and marketplace research \n  Required Skill \n \n 1+ years of relevant experience and a Bachelor's degree is required. Commensurate experience for education. \n Hands-on experience with complex build systems \n Hands-on experience with Linux (RedHat/CentOS) \n Hands-on experience with AWS \n Experience with continuous integration tools (Jenkins, GitLab) \n Experience with unit, integration and functional testing tools (JUnit, Selenium) \n Experience with source control management (SCM) systems (Git, Subversion) \n Familiarity with configuration management tools (Cloud Formation, Helm, Yaml) \n Containerization Tools (Kubernetes, Podman, Buildah, Docker) \n Familiarity with SCM branching strategies. \n Familiarity with build & dependency management (Maven, Nexus, AWS ECR) \n Strong written and verbal communication skills \n Strong organizational skills and the ability to multitask \n \n Preferred Skills \n \n Experience with test-driven development and/or behavior-driven development \n Experience with Groovy \n Experience with web services (REST, SOAP) \n Hands-on J2EE application deployment experience \n Familiarity with static code analysis (SonarQube) \n Systems development experience for federal clients \n Experience with J2EE application servers (i.e. Tomcat, WebLogic, Glassfish, JBoss) \n AWS Solutions Arch or Developer certification \n Familiarity with application vulnerability scanners (i.e. Prisma/TwistLock, Tenable/Ness \n \n Salary Range: \n \n $70,000 - $79,500 per year \n \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Health insurance \n Paid time off \n Professional development assistance \n Retirement plan \n Vision insurance", "cleaned_desc": "Viderity is an award-winning consulting firm that provides IT and outreach services to federal agencies and commercial organizations. You'll be working with a friendly and whip-smart team supporting a well-known organization responsible for exciting discoveries ranging from the first internet browser to black holes to the first semiconductor! \n \n  Job Description: \n  Design and develop automated build, test, and deployment systems across multiple codebases, build tools, application servers, and platforms. Work with emerging and legacy project teams to develop easy-to-adopt automated solutions for their development pipelines and software development lifecycle. Perform maintenance and troubleshooting of continuous integration systems including build and deployment used across multiple environments. Design, maintain, and troubleshoot automated testing and tools to support multiple projects and SDLC methodologies (i.e. Agile, Waterfall). Design and implement static code analysis standards and metrics, aggregate and track across project teams. Design and develop cloud architectures including configuring and spinning up virtual machines for application deployment, including Linux / Windows operating systems, cloud automation and configuration tools, understanding the need for scaling, templating and automation. Proactively communicate and coordinate with multiple project teams. Independently seek opportunities to implement speed and efficiency improvements as technology and capabilities evolve. Seek out new DevOps related capabilities via open-source industry and marketplace research \n  Required Skill \n \n 1+ years of relevant experience and a Bachelor's degree is required. Commensurate experience for education. \n Hands-on experience with complex build systems \n Hands-on experience with Linux (RedHat/CentOS)   Hands-on experience with AWS \n Experience with continuous integration tools (Jenkins, GitLab) \n Experience with unit, integration and functional testing tools (JUnit, Selenium) \n Experience with source control management (SCM) systems (Git, Subversion) \n Familiarity with configuration management tools (Cloud Formation, Helm, Yaml) \n Containerization Tools (Kubernetes, Podman, Buildah, Docker) \n Familiarity with SCM branching strategies. \n Familiarity with build & dependency management (Maven, Nexus, AWS ECR) \n Strong written and verbal communication skills   Strong organizational skills and the ability to multitask \n \n Preferred Skills \n \n Experience with test-driven development and/or behavior-driven development \n Experience with Groovy \n Experience with web services (REST, SOAP) \n Hands-on J2EE application deployment experience \n Familiarity with static code analysis (SonarQube) ", "techs": ["viderity", "it", "outreach services", "federal agencies", "commercial organizations", "automated build", "test", "deployment systems", "codebases", "build tools", "application servers", "platforms", "continuous integration systems", "agile", "waterfall", "static code analysis", "cloud architectures", "virtual machines", "linux", "windows operating systems", "cloud automation", "configuration tools", "scaling", "templating", "automation", "speed and efficiency improvements", "open-source industry", "marketplace research", "relevant experience", "bachelor's degree", "complex build systems", "linux (redhat/centos)", "aws", "continuous integration tools", "jenkins", "gitlab", "unit testing tools", "integration testing tools", "functional testing tools", "junit", "selenium", "source control management systems", "git", "subversion", "configuration management tools", "cloud formation", "helm", "yaml", "containerization tools", "kubernetes", "podman", "buildah", "docker", "scm branching strategies", "build dependency management", "maven", "nexus", "aws ecr", "written communication skills", "verbal communication skills", "organizational skills", "multitasking", "test-driven development", "behavior-driven development", "groovy", "web services (rest", "soap)", "j2ee application deployment experience", "static code analysis tool", "sonarqube"]}, "6f0b1b1873688dc7": {"terms": ["mlops"], "salary_min": 85107.4, "salary_max": 107764.93, "title": "DevOps Engineer", "company": "TMF Health Quality Institute", "desc": "*This role is located Remote, Anywhere US*   \n \n **Please make sure your application is complete, including your education, employment history, and any other applicable sections. Initial screening is based on the minimum requirements as defined in the job posting, such as education, experience, licenses, and certifications. Your experience should also address the knowledge, skills and abilities needed for the role. Incomplete applications will not be considered.**   \n \n Position Purpose:  \n Performs complex (journey-level) information technology development and operations work. Establishes, updates, and maintains the tools, processes and methodologies for automating deployments, testing, monitoring, and maintaining IT products and services. Collaborates with development and IT operations teams to conduct secure code deployment and releases. Works under moderate supervision, with moderate latitude for the use of initiative and independent judgement.   \n \n Essential Responsibilities:  \n \n Manages and maintains CI/CD tooling.  \n Designs playbooks for troubleshooting and maintenance.  \n Implements integrations as needed by the organization.  \n Authors custom scripts to automate deployment of production services and applications  \n Integrates monitoring and alerting tools to support Business Service Level Agreements.  \n Investigates and resolves technical issues in related production systems.  Contributes to the design and implementation of test automation strategies. \n      \n \n Minimum Qualifications  \n Education and Certification  \n \n Bachelor's degree from an accredited college or university \n        \n Additional experience in software testing in Microsoft technology or other related areas may be substituted for Bachelor\u2019s degree on a year per year basis. (Experience requirements may be satisfied by full-time experience or the prorated part-time equivalent.)  \n Relevant certification (i.e. Certified Kubernetes Administrator, SUSE Certified Administrator in SUSE Rancher), preferred \n      \n \n \n Experience  \n \n One (1) year scripting in one or more of the following languages: PowerShell, Python, Bash, Perl, Ruby  \n One (1) year Systems Administration in a Windows Server environment  \n One (1) year in API development and usage  Linux Server Administration \n      \n \n Benefits  \n TMF offers an excellent benefits package, including:  \n \n Medical, dental, vision, life, accidental death and dismemberment, and short and long-term disability insurance  \n Section 125 plan  \n 401K  \n Competitive salary  \n License/credentials reimbursement  Tuition Reimbursement \n      \n \n Please visit our Career Center to Apply and View the Full Job Description  \n https://jobs.tmf.org/  \n EOE Minorities/Females/Vet/Disability", "cleaned_desc": "", "techs": ""}, "d71f00490ff5794c": {"terms": ["mlops"], "salary_min": 123782.4, "salary_max": 156736.1, "title": "DevOps Engineer", "company": "Cyberjin", "desc": "Hybrid Role \n  Looking for a DevOps Engineer with prior experience with Big Data Solutions, Cloud technology, and strong working knowledge of Linux. Passionate about the concept of infrastructure as code and leverages modern tools to define, build and manage virtual infrastructure in the cloud. Work is performed in a hybrid environment with a great team. \n \n  Essential Job Responsibilities \n  The ideal candidate believes in exploring alternatives and quickly prototyping to validate hypothetical architectures or solutions.  \n Will significantly contribute to the development of custom software components and integration of open source code to address complex time series analysis problems through the use of cutting edge Big Data/ Cloud technology. Design, implement, and maintain core architecture and capabilities for software from prototype to operational applications.  \n Must understand software engineering fundamentals, OO programming, relational and time series databases, scripting knowledge and a basic level of development operations (DevOps) skill set.  \n Minimum Qualifications \n  Security Clearance - A current Secret is required and therefore all candidates must be a U.S. citizen.  \n 5+ years of experience in DevOps Engineering or Software Development (Java preferred) and Bachelors in related field; or 3 years relevant experience with Masters in related field; or High School Diploma or equivalent and 9 years relevant experience. \n  Have a strong working knowledge of Linux systems, hosts, storage, networks, security, applications and proficiency in shell scripting (Shell/Bash, JavaScript, Python). \n  Excellent oral and written communication skills. \n  Must have a Security+ certification.  \n Must be able to work in a hybrid environment. \n  Preferred Requirements \n  Must have experience with big data technologies such as Hadoop and NoSQL Databases. Experience with AWS is highly desired. \n  Prior experience or familiarity with Unified Platform (UP) Big Data Platform (formerly owned by DISA) is a plus. \n  Data parsing/transforming techniques to include JSON, XML, CSV formats. \n  Understanding of AGILE software development methodologies and use of standard software development tool suites. (e.g., JIRA, Confluence, Github Enterprise, etc.) \n  Willing to do on-call/pager duty is a big plus. Possible rotating shift in the future for this role as the current team is full. \n   \n eojOTQkfF5", "cleaned_desc": "  The ideal candidate believes in exploring alternatives and quickly prototyping to validate hypothetical architectures or solutions.  \n Will significantly contribute to the development of custom software components and integration of open source code to address complex time series analysis problems through the use of cutting edge Big Data/ Cloud technology. Design, implement, and maintain core architecture and capabilities for software from prototype to operational applications.  \n Must understand software engineering fundamentals, OO programming, relational and time series databases, scripting knowledge and a basic level of development operations (DevOps) skill set.  \n Minimum Qualifications    Security Clearance - A current Secret is required and therefore all candidates must be a U.S. citizen.  \n 5+ years of experience in DevOps Engineering or Software Development (Java preferred) and Bachelors in related field; or 3 years relevant experience with Masters in related field; or High School Diploma or equivalent and 9 years relevant experience. \n  Have a strong working knowledge of Linux systems, hosts, storage, networks, security, applications and proficiency in shell scripting (Shell/Bash, JavaScript, Python). \n  Excellent oral and written communication skills.    Must have a Security+ certification.  \n Must be able to work in a hybrid environment. \n  Preferred Requirements \n  Must have experience with big data technologies such as Hadoop and NoSQL Databases. Experience with AWS is highly desired. ", "techs": ["java", "linux", "shell/bash", "javascript", "python", "hadoop", "nosql databases", "aws"]}, "ae68ca71c738abb5": {"terms": ["mlops"], "salary_min": 156599.08, "salary_max": 198289.33, "title": "DevOps Engineer", "company": "NexHealth", "desc": "About NexHealth  Our healthcare system is frustratingly analog. When you live in a world of one-tap car rides, meal delivery, and unlimited streaming, why do you have to call to schedule an appointment with a doctor and are still handed a clipboard to fill in a form? NexHealth's mission is to accelerate innovation in healthcare. We're doing this by connecting patients, doctors, and developers. We're the first to fully automate the integration with health record systems, paving the way for a new generation of disruptive health-tech companies \n  Here's some of what we've accomplished: \n \n \n $125M Series C at $1B valuation \n \n \n Manage more than 38 million patient records \n \n \n 100%+ annual revenue growth \n \n \n Top 10% of Inc. 5000 (2022) \n \n \n Engineering at NexHealth  We're closing a giant gap in our healthcare system. Our integrations into a multitude of Electronic Health Record systems simplify healthcare for doctors, patients, and application developers. Your success in this role will ensure our systems are working flawlessly, our teams are highly efficient at building, maintaining, and quickly isolating issues. In addition you'll keep us secure and HIPAA compliant throughout our development lifecycle. As we build new integrations and capabilities you'll help drive improvements to our infrastructure, data pipelines, and resilience. You'll be working on our infrastructure team which works hand-in-hand with the rest of the engineering organization. \n  What You'll Do: \n \n Build and maintain our AWS cloud native infrastructure \n Build and maintain our CI/CD pipelines \n Help teams build and maintain our Kubernetes clusters \n Improve cloud security posture through procedures, tools, configurations, monitoring, alerting \n Support our data infrastructure, Synchronizer Aurora, RDS, Snowflake and their pipelines. \n Improve application visibility, monitoring and alerting dashboards \n \n What You'll Bring: \n \n 5+ years of DevOps experience with an AWS cloud-native focus \n 3+ years of software development experience \n Strong experience with Infrastructure as Code tools such as Terraform \n An ability to effectively work with colocated and remote teams \n Python, Ruby on Rails, PostgeSQL development experience will help you be effective across all of our systems. \n \n NexHealth Values \n \n Solve the customer's problems, not yours  When making decisions, think from the perspective of the customer. It's easy to make decisions that make our lives simpler, but not the customers. \n Do the things others are not willing to do  As a Nexer, always go after the hardest problems. Pursue things at the highest quality. Move at the fastest pace. \n Take ownership  Act like a founder. Own your roles, destinies, mistakes, behavior, and our mission. The buck stops with each of us - no blaming or excuses. \n Say what's on your mind, with positive intent  Be direct, proactive, transparent, and frequent in your communication. \n Default trust  As a Nexer, you do not have to earn trust, trust is given to you by default. If we by default trust each other, our speed of communication, feedback, information sharing, and overall improvements will be a lot faster. \n Think in first principles  We first identify the problem and then break it down to its fundamentals before diving into solutions. We constantly ask \"why\" to validate our assumptions. \n \n Here's a glimpse into our interview process: \n \n You'll talk with a NexHeath Recruiter \n You'll talk with the Hiring Manager on a video call \n You'll talk with Team Members on a video call \n You'll do a Panel Presentation or Working Session with a small panel \n \n Please note:  NexHealth interview requests and job offers only originate from nexhealth.com email addresses (e.g. jsmith@nexhealth.com). NexHealth will never ask for bank information (e.g. account and routing number), social security numbers, passwords, or other sensitive information to be delivered via email. If you receive a scam email or wish to report a security issue involving NexHealth, please notify us at: security@nexhealth.com. \n  Benefits \n \n Competitive salary plus equity \n Commuter benefits \n 401K \n Full Medical, Dental and Vision \n Unlimited PTO \n \n We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, sex, gender expression, sexual orientation, age, marital status, veteran status or disability status. We will provide reasonable accommodation to individuals with disabilities to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation at talent@nexhealth.com. \n  #LI-Remote", "cleaned_desc": " Improve application visibility, monitoring and alerting dashboards \n \n What You'll Bring: \n \n 5+ years of DevOps experience with an AWS cloud-native focus \n 3+ years of software development experience \n Strong experience with Infrastructure as Code tools such as Terraform \n An ability to effectively work with colocated and remote teams \n Python, Ruby on Rails, PostgeSQL development experience will help you be effective across all of our systems. \n \n NexHealth Values \n ", "techs": ["terraform", "python", "ruby on rails", "postgresql"]}, "5753b7b521bfc2cb": {"terms": ["mlops"], "salary_min": 144351.53, "salary_max": 182781.19, "title": "Senior DevOps Engineer", "company": "Guru Technologies, Inc.", "desc": "Overview   \n Guru is on a mission to reinvent the way people connect with information at work. Our knowledge management solution provides teams with expert-verified information where they work and when they need it most. Our goal is to give every team in the world trusted information so that they can do their best work. We're backed by an amazing group of investors and we're growing fast; in 2020 we raised a series C round which took our total funding to $70M. \n  At Guru, we know that talent is everywhere. We support remote and hybrid models of work, with our headquarters in Philadelphia and employees spread across 20 states. Time differences can make live collaboration difficult, which is why we're intentional about our internal communication practices, favoring asynchronous options where possible. \n  Everyone is welcome here. Guru is committed to building a diverse and inclusive workplace, where every employee experiences a sense of belonging every day. It's a fact that teams with diverse representation across race, ethnicity, gender, sexual orientation, and abilities perform better. If you're interested, please apply even if you don't check every box because you could be just what we're looking for! \n  Guru is seeking a Senior DevOps Engineer to help ensure that our continuous delivery platform, pipelines, and supporting technologies are run efficiently and built with scalability in mind. You will be expected to integrate with product development teams from the ground floor to provide direction and improvement to current automation processes and procedures. \n  Key Responsibilities: \n \n Promote a collaborative DevOps culture across Engineering, sharing infrastructure and operational responsibilities. \n Implement and refine Infrastructure-as-Code (IaC) using Terraform. \n Develop robust CI/CD pipelines alongside developers, enhancing deployment quality and efficiency. \n Drive continuous improvement, minimizing operational burdens through automation. \n Create and maintain tools and documentation that support a self-service mentality. \n Proactively identify and resolve development and process bottlenecks. \n Evaluate 'buy vs build' scenarios efficiently. \n Expose system health through product monitoring, alerting, and visualization. \n Engage in detailed root cause analyses and retrospectives. \n \n Requirements: \n \n 7+ years of software engineering or operations experience. \n 5+ years of CI/CD engineering, proficient in deployment pipelines (Jenkins, CircleCI). \n 3+ years of cloud tooling experience and docker (AWS preferred, Google, Azure). \n Extensive background in IaC technologies (Terraform preferred, Cloudformation, or CDK). \n Expertise with shell scripting, strong coding skill with Go (a big plus), Ruby, or Python. \n Extensive experience with AWS services including ECS, Lambda, Elasticsearch, Aurora, Elasticache, Code*, Kinesis. \n Experience building and maintaining software in multiple languages, including shell/bash, Ruby, Go, Python, etc\u2026 \n Strong understanding of proper security controls. \n Strong understanding of network fundamentals. \n Natural preference for iterative development and approaches. \n Strong preference for pairing, collaboration, and team work. \n Bachelor's degree in Computer Science, Engineering, and/or equivalent experience. \n \n Nice to Have: \n \n Experience operating Java-based apps in the cloud. \n Experience with CI/CD migrations. \n A background in a startup environment, preferably within the SaaS and B2B space. \n \n Hey, not everybody checks all the boxes, apply and let us get to know you and your experiences and we can learn and grow together here at Guru! \n  Compensation and benefits: \n  Note: Disclosure as required by relevant state law of the base salary compensation range for this role when being hired in Colorado, New York and Washington. The base salary compensation range for the position outlined is $183,000- $248,000. You may also be offered incentive stock options and benefits. Benefits include Health, Dental, Vision, 401k, PTO, Paid sick leave, Paid parental leave, Paid family leave, Paid holidays, Mental health and wellbeing offerings, HSA/FSA available (where applicable), Office set-up reimbursement, Life and accidental death and dismemberment coverage, Short & long term disability coverage, and a Company-issued laptop and accessories. \n  The final job level and compensation will be determined by various factors such as a candidate's relevant work experience, years of relevant experience, skills, qualifications, certifications, geographic location, and other business considerations. \n  In Addition: \n \n Competitive salary \n Employee Incentive Stock Option Plan \n Paid Parental, Family & Medical Leave \n Unlimited Vacation \n 401k \n Professional Development Stipend \n Wellness Stipend \n Home Office Stipend \n Tuition Reimbursement \n Thrive After Five: in recognition of our long-tenured employees, Guru celebrates your five year anniversary with a $10,000 personal travel reimbursement \n Remote perks \n Generous medical benefits package \n Guru-sponsored company & team events, no matter where you work \n \n We ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us at talent@getguru.com to request accommodation.", "cleaned_desc": " Create and maintain tools and documentation that support a self-service mentality. \n Proactively identify and resolve development and process bottlenecks. \n Evaluate 'buy vs build' scenarios efficiently. \n Expose system health through product monitoring, alerting, and visualization. \n Engage in detailed root cause analyses and retrospectives. \n \n Requirements: \n \n 7+ years of software engineering or operations experience. \n 5+ years of CI/CD engineering, proficient in deployment pipelines (Jenkins, CircleCI). \n 3+ years of cloud tooling experience and docker (AWS preferred, Google, Azure).   Extensive background in IaC technologies (Terraform preferred, Cloudformation, or CDK). \n Expertise with shell scripting, strong coding skill with Go (a big plus), Ruby, or Python. \n Extensive experience with AWS services including ECS, Lambda, Elasticsearch, Aurora, Elasticache, Code*, Kinesis. \n Experience building and maintaining software in multiple languages, including shell/bash, Ruby, Go, Python, etc\u2026 \n Strong understanding of proper security controls. \n Strong understanding of network fundamentals. \n Natural preference for iterative development and approaches. \n Strong preference for pairing, collaboration, and team work. \n Bachelor's degree in Computer Science, Engineering, and/or equivalent experience. \n \n Nice to Have: ", "techs": ["jenkins", "circleci", "aws", "google", "azure", "terraform", "cloudformation", "cdk", "go", "ruby", "python", "ecs", "lambda", "elasticsearch", "aurora", "elasticache", "code*", "kinesis"]}, "1cb18cb8499a400d": {"terms": ["mlops"], "salary_min": null, "salary_max": null, "title": "Senior Product Manager, Backend API / DevOps", "company": "Keeper Security, Inc.", "desc": "Keeper Security is hiring an experienced and execution-oriented Senior Product Manager to define and drive our backend and DevOps roadmap. This is a 100% remote position! \n  Keeper\u2019s cybersecurity software is trusted by millions of users and thousands of organizations, globally. Join one of the fastest-growing cybersecurity companies and be responsible for taking our backend products to the next level! \n  About Keeper \n  Keeper Security is transforming cybersecurity for people and organizations around the world. Keeper\u2019s affordable and easy-to-use solutions are built on a foundation of zero-trust and zero-knowledge security to protect every user on every device. Our next-generation privileged access management solution deploys in minutes and seamlessly integrates with any tech stack to prevent breaches, reduce help desk costs and ensure compliance. Trusted by millions of individuals and thousands of organizations, Keeper is the leader for best-in-class password management, secrets management, privileged access, secure remote access and encrypted messaging. Learn more at KeeperSecurity.com. \n  About the Job \n  The Senior Product Manager will report to the Head of Product Management, serving as the primary driver of Keeper\u2019s backend API product vision and growth, as well as managing the DevOps roadmap. Inspire and collaborate with an elite team of industry experts at Keeper to successively innovate and deliver industry-leading products. \n  Responsibilities \n \n Partner with leadership to drive product vision, strategy and roadmap in support of our backend API and DevOps roadmap \n Drive the execution rhythm and deliver products, services and features to market with speed \n Conduct research and engage with customers, partners and internal teams to identify market opportunities, determine requirements and drive roadmap prioritization  \n Build strong working relationships across Keeper to drive a best-in-class customer experience \n Author product documentation, product demos, blog posts, sales readiness material and other content \n Measure and evaluate product performance and overall business impact and effectively communicate progress and learnings around the company \n \n Requirements \n \n 5+ years of progressive technical product management experience; SaaS experience required \n 5+ years of experience with developer platforms, developer experience, tools, workflows, and/or infrastructure \n Effective at driving complex multi-stakeholder processes and cross team programs \n Ability to build cross-functional relationships, influence and collaborate at all organizational levels \n Outstanding verbal and written communications skills for a global audience \n Strong business acumen, analytical and detail oriented \n Passionate about data and analytics as a lever to improve business performance \n BS in computer science, engineering or relevant field \n \n Benefits \n \n Medical, Dental & Vision (inclusive of domestic partnerships) \n Employer Paid Life Insurance & Employee/Spouse/Child Supplemental life \n Voluntary Short/Long-Term Disability Insurance \n 401K (Roth/Traditional) \n A generous PTO plan that celebrates your commitment and seniority (including paid Bereavement/Jury Duty, etc) \n Above-market annual bonuses \n \n Keeper Security, Inc. is an equal opportunity employer and participant in the U.S. Federal E-Verify program. We celebrate diversity and are committed to creating an inclusive environment for all employees. \n  Classification:  Exempt", "cleaned_desc": " \n Requirements \n \n 5+ years of progressive technical product management experience; SaaS experience required \n 5+ years of experience with developer platforms, developer experience, tools, workflows, and/or infrastructure \n Effective at driving complex multi-stakeholder processes and cross team programs \n Ability to build cross-functional relationships, influence and collaborate at all organizational levels ", "techs": ["none"]}, "81851a4e76f04736": {"terms": ["mlops"], "salary_min": 119930.55, "salary_max": 151858.8, "title": "DevOps Engineer", "company": "Baer Group", "desc": "**Federal Project - Applicant must be a United States Citizen with Active Secret Clearance** \n \n   \n \n Baer is looking for DevOps Engineer for a 6+ month Federal remote project. \n \n \n Title:  DevOps Engineer\n  \n Location:  Remote (Must be based in US) \u2013 Preference to Consultants Commutable to Kingstowne, VA\n  \n Duration : 6+ months\n  \n Rate:  All-Inclusive\n  \n Alignment:  W2 or C2C\n  \n \n Description: \n \n Deploy infrastructure and platform environments, creates a proof of architecture to test architecture viability security, and performance.  \n Deploy and manage AWS cloud infrastructure and services.  \n Deploy, configure, and operationalize resilient, highly available production grade containers using AWS EKS  \n Develop IaC for cluster orchestration and application deployment using a variety of tools such as Ansible, Terraform  \n Work with a variety of cloud native tools to add capabilities and secure the platform.  \n Troubleshoot complex technical issues across all layers of the technology stack.  \n Design and build features for implementation in the production system and operational employment by our customer.  \n Proactively resolve technical hurdles and continue innovative efforts within SAFe development practices.  \n Collaborate and communicate with other team members to decompose large tasks into small testable tasks.  \n \n \n Requirements: \n \n 5+ years of experience in cloud-based solutions and cloud CLIs  \n Experience troubleshooting DNS, VPN, HTTPS, and networking configurations  \n Knowledge of software development methodologies, security concepts, network, and system design  \n Advanced experience in various technology areas including cloud, identity solutions.  \n Experience developing and deploying Infrastructure as Code solutions in a cloud environment.  \n Experience hardening and testing systems and applications.  \n Experience configuring physical/virtual networks (VLANs, VNIC, Switches, & other networking hardware)  \n Experience with Linux and Windows Server file systems and operations.  \n Certified in one or more of top for CSP (AWS Preferred)  \n DoD 8140 Baseline Certification (Security+, CASP, CISM, CISSP)  \n Preferred experience in DoD Cloud environments  \n Education Requirement: Bachelor\u2019s Degree \n \n \n \n \n Company Overview: \n \n  Baer is an Enterprise Performance Partner providing job opportunities with several 1st Tier Global Systems Integrators and a wide array of Fortune 1000 clients. Baer consultants and employees enjoy access to the highest profile job opportunities across leading Enterprise Technology Solutions ranging from Digital Transformation programs utilizing the latest technologies from SAP and Oracle to a wide range of emerging Cloud based infrastructure, application and AI related solutions.\n  \n  At Baer we aim to provide a best-in-class engagement experience for our consultants. Our job requirements are carefully vetted and are typically associated with pivotal programs offering tremendous opportunities to expand your skills leveraging the latest solutions.\n  \n  Baer is an equal opportunity employer including disability/veteran.", "cleaned_desc": " Deploy, configure, and operationalize resilient, highly available production grade containers using AWS EKS  \n Develop IaC for cluster orchestration and application deployment using a variety of tools such as Ansible, Terraform  \n Work with a variety of cloud native tools to add capabilities and secure the platform.  \n Troubleshoot complex technical issues across all layers of the technology stack.  \n Design and build features for implementation in the production system and operational employment by our customer.  \n Proactively resolve technical hurdles and continue innovative efforts within SAFe development practices.  \n Collaborate and communicate with other team members to decompose large tasks into small testable tasks.  \n \n \n Requirements: \n   5+ years of experience in cloud-based solutions and cloud CLIs  \n Experience troubleshooting DNS, VPN, HTTPS, and networking configurations  \n Knowledge of software development methodologies, security concepts, network, and system design  \n Advanced experience in various technology areas including cloud, identity solutions.  \n Experience developing and deploying Infrastructure as Code solutions in a cloud environment.  \n Experience hardening and testing systems and applications.  \n Experience configuring physical/virtual networks (VLANs, VNIC, Switches, & other networking hardware)  \n Experience with Linux and Windows Server file systems and operations.  \n Certified in one or more of top for CSP (AWS Preferred)  \n DoD 8140 Baseline Certification (Security+, CASP, CISM, CISSP)  \n Preferred experience in DoD Cloud environments  ", "techs": ["aws eks", "ansible", "terraform", "safe development practices", "dns", "vpn", "https", "vlans", "vnic", "switches", "linux", "windows server", "csp"]}, "b8e44443279ad780": {"terms": ["mlops"], "salary_min": 100000.0, "salary_max": 120000.0, "title": "DevOps Engineer - GCP Required", "company": "Marler Search Group", "desc": "DEVOPS ENGINEER  (GCP REQUIRED) This is a FULLY REMOTE role and can be done from anywhere in the US \n (We are only considering US Citizens and US Permanent Residents for this role as it supports our FedRAMP effort) \n What We Do - Managing cyber risk, together. We deliver automated cybersecurity across the digital terrain. We empower our customers to achieve continuous alignment of their security frameworks with their digital realities, across all asset types \u2013 IT, IoT, OT, and IoMT. It is a non-stop journey, managing cyber risk through automation and data-powered insights. \n What You Will Do \n \n Work with the development teams to design and support our security products and platforms. \n Provide guidelines and best practices for DevOps, Continuous Delivery, Automation and Software delivery within our development teams. \n Provide consultation to development team members on cloud architecture to guide resource planning. \n Deploy major changes and provide Tier 2/3 support during maintenance windows. \n Support a SaaS service which may require irregular work hours at times and on call support during North American business hours. Document day-to-day activities in our ticketing system \n Perform capacity planning and operational activities as we grow for our key infrastructure services. \n \n What You Bring: \n \n REQUIRED 2+ years of experience with  Google Cloud Platform . \n 3+ years of hands-on experience with deploying and integrating complex systems with a variety of operating system environments. \n Advanced scripting experience required (e.g. bash & python). \n Must be comfortable and capable with Kubernetes and kubectl to deploy, manage and troubleshoot workloads. \n Familiarity with DevOps tooling for development and deployment (e.g. Docker, Jenkins, Helm, Terraform). \n In-depth experience with running production workloads (e.g. monitoring, capacity planning, new service deployments, pod debugging). \n Strong written and verbal communication skills. \n Strong skills working with remote teams in different time zones. \n Excellent and proven analytic and troubleshooting skills for problems that span multiple domains (applications, network, system). \n \n Plusses to Have \n \n Experience with the FedRAMP process. \n Professional experience with other major cloud platforms (AWS, Azure). \n Web Development skills in HTML, CSS, JavaScript along with Web libraries. \n Experience with Elastic search, PostgreSQL, Redis, and other data indexing and searching applications. \n Experience or certifications in Google Cloud Platform. \n \n What We Offer You \n \n Competitive compensation and benefits \u2013 we cover 80% of employee and dependents\u2019 benefits premiums (US only), 401K match, generous PTO policy, and much more \n Collaborative and innovative environment \u2013 make an impact on worldwide security while working on the hottest technology \n Leadership that supports and encourages professional growth and development \n \n Job Type: Full-time \n Salary: $100,000.00 - $120,000.00 per year \n Benefits: \n \n Dental insurance \n Flexible schedule \n Life insurance \n Paid time off \n Vision insurance \n \n Compensation package: \n \n Bonus opportunities \n \n Experience level: \n \n 2 years \n \n Schedule: \n \n Monday to Friday \n \n Experience: \n \n Scripting (Bash or Python): 3 years (Required) \n FedRAMP: 1 year (Preferred) \n Kubectl: 2 years (Required) \n SOUND, ACTUAL hands-on Google Cloud Platform: 2 years (Required) \n \n Work Location: Remote", "cleaned_desc": " \n REQUIRED 2+ years of experience with  Google Cloud Platform . \n 3+ years of hands-on experience with deploying and integrating complex systems with a variety of operating system environments. \n Advanced scripting experience required (e.g. bash & python). \n Must be comfortable and capable with Kubernetes and kubectl to deploy, manage and troubleshoot workloads. \n Familiarity with DevOps tooling for development and deployment (e.g. Docker, Jenkins, Helm, Terraform). \n In-depth experience with running production workloads (e.g. monitoring, capacity planning, new service deployments, pod debugging). \n Strong written and verbal communication skills. \n Strong skills working with remote teams in different time zones. \n Excellent and proven analytic and troubleshooting skills for problems that span multiple domains (applications, network, system). \n \n Plusses to Have \n ", "techs": ["google cloud platform", "bash", "python", "kubernetes", "kubectl", "docker", "jenkins", "helm", "terraform."]}, "2015402b903c6c24": {"terms": ["mlops"], "salary_min": 65.0, "salary_max": 80.0, "title": "AWS DevOps Engineer/Architect", "company": "Glotel", "desc": "Exciting 12 month long W2 contract assignment for an AWS DevOps Engineer/Architect. Can sit remote in most US markets but working Central Time \n TOP SKILLS: 5+ years AWS experience, terraform experience, CI/CD pipeline, deploying infrastructure \n SECURITY CLEARANCE: Will require going through security clearance, this position requires that the candidate selected be a US Citizen \n The successful candidate will be tasked with the below: \n \n Automate deployments utilizing custom templates and modules for customer environments on AWS \n Architect Azure environment best practices and deployment methodologies \n Create automation tools and processes to improve Team and Racker day to day functions \n Assist in educational briefings for teammates to advance in technical trainings for continued growth \n Provide first class customer service \n \n The ideal candidate will be able to prove the following: \n \n 4-5+ years AWS experience, terraform experience, CI/CD pipeline, deploying infrastructure \n AWS Certifications required \n Ability to go through Security Clearance process (US Citizenship required) \n Expert knowledge of AWS Products & Services, Caching, EBS, Scaling, Load Balancing, Networking etc. \n Extensive Automation expertise \n Excellent understanding of central networking concepts: VLANs, layer 2/3 routing, access lists & load balancing \n \n **Candidate will have successfully passed a Background Check. Start date is contingent on client** \n Job Type: Contract \n Pay: $65.00 - $80.00 per hour \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n Vision insurance \n \n Experience level: \n \n 4 years \n 5 years \n \n Application Question(s): \n \n This role requires the successful candidate to go through Govt Security Clearance, US Citizenship is required for this purpose. \n \n Please confirm you can meet these requirements? \n \n Please list any active AWS certifications that you currently hold \n \n Experience: \n \n AWS: 4 years (Required) \n Terraform: 2 years (Required) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "7f32fa7a8132ff8d": {"terms": ["mlops"], "salary_min": 138160.0, "salary_max": 215875.0, "title": "(Remote) Principal DevOps Engineer", "company": "First American Financial Corporation", "desc": "Who We Are \n \n  Join a team that puts its People First! Since 1889, First American (NYSE: FAF) has held an unwavering belief in its people. They are passionate about what they do, and we are equally passionate about fostering an environment where all feel welcome, supported, and empowered to be innovative and reach their full potential. Our inclusive, people-first culture has earned our company numerous accolades, including being named to the Fortune 100 Best Companies to Work For\u00ae list for seven consecutive years. We have also earned awards as a best place to work for women, diversity and LGBTQ+ employees, and have been included on more than 50 regional best places to work lists. First American will always strive to be a great place to work, for all. For more information, please visit www.careers.firstam.com. \n \n  What We Do \n \n  ** Remote Work Welcome** Be part of a transformative team that is shaping the way First American builds and delivers world-class technology products that fuel the real estate industry. We are looking for the best-of-the-best technology experts that will envision, design, build, and deliver innovative solutions that provides exceptional experiences and lasting value to our customers. First American is seeking candidates for an engineering role in our Platform Engineering team. An ideal candidate has strong technical expertise, a product mindset, and takes a hands-on approach for driving engineering best practices. As a Principal DevOps Engineer, you will help design and implement our technical architecture, software, and tooling used to deliver and operate our core, mission critical, software platforms. The ideal candidate will have a firm grasp of emerging technologies, platforms, and applications and an ability to customize them to help our business remain secure and efficient. \n  What You\u2019ll Do \n \n  Technical Leadership:  Provide vision and technical leadership to guide us in designing, delivering, and supporting \u201cgolden paths\u201d including on demand delivery of infrastructure and CI/CD for our software teams to consume with low cognitive load and high security. Define and document best practices and strategies regarding application deployment and infrastructure maintenance. \n  Collaborate/Partner:  Work in tandem with our engineering teams and leaders to identify and implement optimal cloud-based solutions for the company. \n  People Leadership & Development:  Our people are our greatest asset, and you provide guidance, thought leadership, and mentorship to help our teams develop their technical skillsets. You will educate teams on the implementation of new cloud-based initiatives, providing associated training when necessary. \n  Quality & Security Focused:  Drive implementation of functionally appropriate and technically sound solutions meeting all quality & security standards. \n  Continuous Improvement:  Lead the team in achieving ambitious goals, providing regular feedback, and driving continuous improvement. You will participate in all aspects of our software development lifecycle for cloud based solutions, including planning, defining requirements, developing, and testing those solutions with the team. \n \n \n  What You\u2019ll Bring \n \n  6+ years in the cloud and DevOps field \n  Proven track record for delivering fit for purpose technical solutions balancing complexity, performance, and maintainability \n  A balanced approach between Software Engineering principles and modern Infrastructure Operations \n  Automation orchestration tooling such Azure DevOps (ADO), Github Enterprise, or Gitlab \n  Infrastructure automation tooling such as Terraform and Ansible \n  CI/CD best practices and implementation \n  AWS infrastructure and cloud native services such as Lambda and EKS \n  Windows Server automation \n  Various git patterns such as gitflow and trunk based development \n  Working within a highly regulated industry such as Financials Services or Healthcare \n \n \n  Technical Skills \n \n  Powershell, Bash, Python, and/or Golang development \n  Supporting .NET (Core & Framework), Node.js, and Golang applications \n  Containers (Windows and Linux) \n  Kubernetes \n  Database automation & administration \n  Cloud cost management & automation \n  Network/Cloud security core concepts and tooling \n  AppSec/DevSecOps tooling such as Veracode SAST and DAST \n  Automated software testing (unit, component, API, functional) \n  GitOps methodologies \n  Effective communication skills, both verbal and written, with strong relationship, collaborative, and organization skills \n \n \n  Pay Range: $138,160 - $215,875 Annually \n \n  This hiring range is a reasonable estimate of the base pay range for this position at the time of posting. Pay is based on a number of factors which may include job-related knowledge, skills, experience, business requirements and geographic location . \n \n  What We Offer \n \n  By choice, we don\u2019t simply accept individuality \u2013 we embrace it, we support it, and we thrive on it! Our People First Culture celebrates diversity, equity and inclusion not simply because it\u2019s the right thing to do, but also because it\u2019s the key to our success. We are proud to foster an authentic and inclusive workplace For All. You are free and encouraged to bring your entire, unique self to work. First American is an equal opportunity employer in every sense of the term. \n \n  Based on eligibility, First American offers a comprehensive benefits package including medical, dental, vision, 401k, PTO/paid sick leave and other great benefits like an employee stock purchase plan.", "cleaned_desc": "  A balanced approach between Software Engineering principles and modern Infrastructure Operations \n  Automation orchestration tooling such Azure DevOps (ADO), Github Enterprise, or Gitlab \n  Infrastructure automation tooling such as Terraform and Ansible \n  CI/CD best practices and implementation \n  AWS infrastructure and cloud native services such as Lambda and EKS \n  Windows Server automation \n  Various git patterns such as gitflow and trunk based development \n  Working within a highly regulated industry such as Financials Services or Healthcare \n \n ", "techs": ["azure devops (ado)", "github enterprise", "gitlab", "terraform", "ansible", "lambda", "eks", "windows server"]}, "1f113e7302a111a4": {"terms": ["mlops"], "salary_min": 58300.0, "salary_max": 133000.0, "title": "DevOps Engineer", "company": "Booz Allen Hamilton", "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Annapolis Junction,MD,US \n         \n \n \n \n         Remote Work: \n         \n \n         Hybrid \n         \n \n \n \n         Job Number: \n         \n \n         R0182581\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         DevOps Engineer\n           The Opportunity:  \n Are you looking for an opportunity to make a difference in the DoD\u2019s pursuit of Offensive and Defensive Cyber Operations tools and capabilities? What if you could find a position that is tailor made for your mix of development, engineering, and communication skills? Everyone is trying to \u201charness the cloud,\u201d but not everyone knows how. That\u2019s why we need you, an experienced DevOps engineer, to help us shorten the time it takes to get critical tools developed. \n \n  As a DevOps engineer, you\u2019re eager to develop, manage, and secure a container platform that meets your client\u2019s needs and takes advantage of cloud capabilities. We need you to develop container management software to solve some of our client's toughest challenges. As a senior platform DevOps engineer at Booz Allen, you can use your technical skills to affect the development of Cyber Capabilities directly. On our team, you\u2019ll hone your skills using the latest cloud technologies as you look for ways to improve your client\u2019s environment with container software to ensure seamless orchestration. Using your DevOps platform experience, you\u2019ll support your team as you inform strategy and design while ensuring standards are met throughout the containerization process. You\u2019ll recommend and build out resources that will help your client manage and securely adopt container technology. Additionally, you\u2019ll continue to strengthen your DevOps skills while supporting the development of critical cloud platforms. \n \n  With access to our internal innovative labs, there\u2019s no better place to expand your skills and explore different ways of solving our clients\u2019 challenges. Whether helping to develop, deploy, or manage IT infrastructures for crucial server and network components, here you\u2019ll have the latest tech and brightest teammates at your fingertips. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  Experience in the development of tools and processes to drive DevOps or DevSecOps maturity by automating builds, regression testing, monitoring, and pushing releases across environments \n  Experience working with, building, and maintaining DevSecOps services with infrastructure as code (IaC) platforms and configuration management tools \n  Experience with containerization tools, including Docker and Kubernetes \n  Experience with automation tools, including SaltStack, Ansible, or Puppet \n  Experience with DevOps and CI/CD tools and automation, including Jenkins and GitHub Actions \n  Experience with network and server infrastructure monitoring and management \n  Experience with Linux systems use, including patching, optimization, scripting, automation, and other tasks \n  Experience working with application development teams across the software development lifecycle \n  Secret clearance  \n HS diploma or GED \n \n \n  Nice If You Have: \n \n  5+ years of experience in an infrastructure, DevSecOps, or application development role \n  Experience developing enterprise cloud-native solutions, including Kubernetes, Docker, AWS, Jenkins, or Azure \n  Experience installing, configuring, and managing Atlassian suite of development tools \n  Experience with Cross Domain Solutions, including tools like AWS Diode and DoD approved CDS technologies \n  Experience triaging and resolving issues related to both open-source and commercial tools in public cloud environments \n  Knowledge of scripting languages, including Python, Linux, or Shell Script \n  Master\u2019s degree \n  Industry Certifications, including Kubernetes Administrator (CKA) Certification \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. \n \n  Create Your Career: \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll develop your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $58,300.00 to $133,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.", "cleaned_desc": "  Experience with DevOps and CI/CD tools and automation, including Jenkins and GitHub Actions \n  Experience with network and server infrastructure monitoring and management \n  Experience with Linux systems use, including patching, optimization, scripting, automation, and other tasks \n  Experience working with application development teams across the software development lifecycle \n  Secret clearance  \n HS diploma or GED \n \n \n  Nice If You Have: \n \n  5+ years of experience in an infrastructure, DevSecOps, or application development role \n  Experience developing enterprise cloud-native solutions, including Kubernetes, Docker, AWS, Jenkins, or Azure \n  Experience installing, configuring, and managing Atlassian suite of development tools \n  Experience with Cross Domain Solutions, including tools like AWS Diode and DoD approved CDS technologies \n  Experience triaging and resolving issues related to both open-source and commercial tools in public cloud environments \n  Knowledge of scripting languages, including Python, Linux, or Shell Script \n  Master\u2019s degree \n  Industry Certifications, including Kubernetes Administrator (CKA) Certification \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. ", "techs": ["jenkins", "github actions", "linux systems", "kubernetes", "docker", "aws", "azure", "atlassian suite of development tools", "aws diode", "dod approved cds technologies", "python", "shell script", "kubernetes administrator (cka) certification"]}, "58c5aeec45cdf589": {"terms": ["mlops"], "salary_min": 100000.0, "salary_max": 155000.0, "title": "DevOps Engineer", "company": "Qlik", "desc": "What makes us Qlik \n \n   Qlik helps enterprises around the world move faster, work smarter, and lead the way forward with an end-to-end solution for getting value out of data. A Gartner Magic Quadrant Leader for 13 years in a row! Our platform is the only one on the market that allows for open-ended, curiosity-driven exploration, giving everyone \u2013 at any skill level \u2013 the ability to make real discoveries that lead to real outcomes and transformative changes. We are a Values-Driven organization, operating over 100 countries with 38,000 customers around the world. If you think we are interesting, please read on \u2013 we may be looking for you!\n   \n \n    DevOps Engineer \n \n   In this role you\u2019ll need to collaborate effectively with people that have diverse backgrounds and skill sets in addition to having and applying a deep understanding of critical technical skills. You will mentor others in their areas of strength and experience, while quickly learning new skills, adapting, and contributing in areas outside of your previous focus as needs arise. We ask that you are an effective and compassionate communicator and are able to construct and present valid arguments for decisions and discuss solutions with humility and mutual respect for the opinions and thoughts of others. You are always ready both to learn and to teach with the primary goal that the team succeeds.\n  \n   \n Responsibilities include, but not limited to: \n \n  Helping to manage, expand, and improve the infrastructure on which our applications and services run. \n  Facilitating SOC compliance and security best practices as it is today and as it evolves. \n  Analyzing and monitoring applications and infrastructure to proactively identify issues before they become problems. \n  Facilitating application deployments and continuous integration deployment pipelines. \n  Helping developers to remain productive and assist them to remove blockers. \n  Participating in planning discussions to gain understanding of product road maps with an eye on staying ahead of infrastructure needs as we grow. \n  Assisting the team with architectural decisions. \n  Triaging when necessary and helping to address the problems and complexities that arise as products and teams grow. \n  Assisting in evaluating, or developing, and implementing new tools that help us more effectively and efficiently achieve our goals. \n  Mentoring junior engineers to help them improve their practices and understanding of networking, security, data management, compliance, tools and best practices. \n  Facilitating cost control by regularly evaluating and right-sizing provisioned resources \n  Assisting with writing and maintaining documentation required for soc compliance and business needs. \n \n  Skills and qualifications for this role include: \n  Required:  \n \n Three or more years DevOps experience. \n  Proficiency in one or more scripting languages. \n  A healthy fear of breaking our production environment. \n  Working knowledge of cloud development and infrastructure tools. \n  Proficiency with Kubernetes and related services.  \n Experience working in an AWS VPC environment.  \n Proficiency working with Docker including creating images. \n  Proficiency working with APIs. \n  Strong understanding of security best practices through multiple layers of infrastructure. \n  Familiarity working in Linux environments. \n  Ability to communicate and collaborate effectively. \n  Effective written communication skills. \n  Experience with Infrastructure as Code. \n  Experience working with Grafana or similar. \n \n  Preferred:  \n \n CKA (Certified Kubernetes Administrator). \n  Experience working in GitOps environments. \n  Experience working with Splunk or Dynatrace. \n  Proficiency with shell scripting. \n  Experience working with Helm charts and yaml. \n  RabbitMQ and/or Kafka or Solace. \n  Experience with SQL and relational databases. \n  Experience with MongoDB and/or PostGres. \n  Golang and/or Python scripting skills. \n  Experience with Terraform. \n  Familiarity with CI/CD pipeline. \n  Proficiency in networking and related technologies. \n \n \n  The location for this role is: \n \n  United States \n \n   \n About Qlik \n \n  Qlik Company Page \u2013 Who we are!  \n Our Values at Qlik:   Challenge, Take Responsibility, Move Fast, T eamwork for Results , Be Open and Straightforward   \n Competitive Benefits package \n  Flexible working environment \n  Giving back is a part of our culture \u2013 we give you a day to change the world. In addition, we encourage our employees to participate in our Corporate Responsibility Employee Programs \n  Learn about our Corporate Responsibility Program by visiting Qlik.org \n  Check out our careers in R&D here. \n  Check out our company page on Linkedin! \n  Follow us on Instagram @lifeatqlik and @Qlik @lifeatqliklund \n  Check us out on Youtube! \n \n \n \n  The base salary range for this role is $ \n 1 \n 00,000 \n -$ \n 155,000 \n . \n \n \n \n \n \n Compensation offered will be based on factors such as the candidate\u2019s location, job related skills, education, experience and other business and organizational needs.  \n \n \n Qlik offers a comprehensive benefits package which includes, but is not limited to, healthcare and dental benefits, a 401(k) plan and match, paid time off, and mental health benefits. \n \n \n \n  Qlik is an Equal Opportunity/Affirmative Action  \n Employer, \n  and we value the diversity of our workforce \n .  Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Click here to review the US Department of Labor\u2019s \n   Equal Employment Opportunity Posters , including the \n   EEO is The Law  notice and the \n   Pay Transparency  \n Nondiscrimination Provision .\n  \n \n \n  If you need assistance due to disability during the application and/or recruiting process, please contact us via the  \n Accessibility Request Form \n . \n \n \n \n  Qlik is not accepting unsolicited assistance from search firms for this employment opportunity. Please, no phone calls or emails. All resumes submitted by search firms to any employee at Qlik via-email, the Internet or in any form and/or method without a valid written search agreement in place for this position will be deemed the sole property of Qlik. No fee will be paid in the event the candidate is hired by Qlik as a result of the referral or through other means.", "cleaned_desc": "  Facilitating cost control by regularly evaluating and right-sizing provisioned resources \n  Assisting with writing and maintaining documentation required for soc compliance and business needs. \n \n  Skills and qualifications for this role include: \n  Required:  \n \n Three or more years DevOps experience. \n  Proficiency in one or more scripting languages. \n  A healthy fear of breaking our production environment. \n  Working knowledge of cloud development and infrastructure tools. \n  Proficiency with Kubernetes and related services.  \n Experience working in an AWS VPC environment.  \n Proficiency working with Docker including creating images. \n  Proficiency working with APIs. \n  Strong understanding of security best practices through multiple layers of infrastructure. \n  Familiarity working in Linux environments. \n  Ability to communicate and collaborate effectively. \n  Effective written communication skills. \n  Experience with Infrastructure as Code. \n  Experience working with Grafana or similar. \n \n  Preferred:    \n CKA (Certified Kubernetes Administrator). \n  Experience working in GitOps environments. \n  Experience working with Splunk or Dynatrace. \n  Proficiency with shell scripting. \n  Experience working with Helm charts and yaml. \n  RabbitMQ and/or Kafka or Solace. \n  Experience with SQL and relational databases. \n  Experience with MongoDB and/or PostGres. \n  Golang and/or Python scripting skills. \n  Experience with Terraform. \n  Familiarity with CI/CD pipeline. \n  Proficiency in networking and related technologies. \n \n \n  The location for this role is: \n \n  United States \n \n   \n About Qlik \n ", "techs": ["facilitating cost control by regularly evaluating and right-sizing provisioned resources", "working knowledge of cloud development and infrastructure tools", "proficiency with kubernetes and related services", "experience working in an aws vpc environment", "proficiency working with docker including creating images", "proficiency working with apis", "strong understanding of security best practices through multiple layers of infrastructure", "familiarity working in linux environments", "ability to communicate and collaborate effectively", "effective written communication skills", "experience with infrastructure as code", "experience working with grafana or similar", "cka (certified kubernetes administrator)", "experience working in gitops environments", "experience working with splunk or dynatrace", "proficiency with shell scripting", "experience working with helm charts and yaml", "rabbitmq and/or kafka or solace", "experience with sql and relational databases", "experience with mongodb and/or postgres", "golang and/or python scripting skills", "experience with terraform", "familiarity with ci/cd pipeline", "proficiency in networking and related technologies."]}, "247578121ebfed06": {"terms": ["mlops"], "salary_min": 100000.0, "salary_max": 155000.0, "title": "DevOps Engineer", "company": "Qlik", "desc": "What makes us Qlik \n \n   Qlik helps enterprises around the world move faster, work smarter, and lead the way forward with an end-to-end solution for getting value out of data. A Gartner Magic Quadrant Leader for 13 years in a row! Our platform is the only one on the market that allows for open-ended, curiosity-driven exploration, giving everyone \u2013 at any skill level \u2013 the ability to make real discoveries that lead to real outcomes and transformative changes. We are a Values-Driven organization, operating over 100 countries with 38,000 customers around the world. If you think we are interesting, please read on \u2013 we may be looking for you!\n   \n \n    DevOps Engineer \n \n   In this role you\u2019ll need to collaborate effectively with people that have diverse backgrounds and skill sets in addition to having and applying a deep understanding of critical technical skills. You will mentor others in their areas of strength and experience, while quickly learning new skills, adapting, and contributing in areas outside of your previous focus as needs arise. We ask that you are an effective and compassionate communicator and are able to construct and present valid arguments for decisions and discuss solutions with humility and mutual respect for the opinions and thoughts of others. You are always ready both to learn and to teach with the primary goal that the team succeeds.\n  \n   \n Responsibilities include, but not limited to: \n \n  Helping to manage, expand, and improve the infrastructure on which our applications and services run. \n  Facilitating SOC compliance and security best practices as it is today and as it evolves. \n  Analyzing and monitoring applications and infrastructure to proactively identify issues before they become problems. \n  Facilitating application deployments and continuous integration deployment pipelines. \n  Helping developers to remain productive and assist them to remove blockers. \n  Participating in planning discussions to gain understanding of product road maps with an eye on staying ahead of infrastructure needs as we grow. \n  Assisting the team with architectural decisions. \n  Triaging when necessary and helping to address the problems and complexities that arise as products and teams grow. \n  Assisting in evaluating, or developing, and implementing new tools that help us more effectively and efficiently achieve our goals. \n  Mentoring junior engineers to help them improve their practices and understanding of networking, security, data management, compliance, tools and best practices. \n  Facilitating cost control by regularly evaluating and right-sizing provisioned resources \n  Assisting with writing and maintaining documentation required for soc compliance and business needs. \n \n  Skills and qualifications for this role include: \n  Required:  \n \n Three or more years DevOps experience. \n  Proficiency in one or more scripting languages. \n  A healthy fear of breaking our production environment. \n  Working knowledge of cloud development and infrastructure tools. \n  Proficiency with Kubernetes and related services.  \n Experience working in an AWS VPC environment.  \n Proficiency working with Docker including creating images. \n  Proficiency working with APIs. \n  Strong understanding of security best practices through multiple layers of infrastructure. \n  Familiarity working in Linux environments. \n  Ability to communicate and collaborate effectively. \n  Effective written communication skills. \n  Experience with Infrastructure as Code. \n  Experience working with Grafana or similar. \n \n  Preferred:  \n \n CKA (Certified Kubernetes Administrator). \n  Experience working in GitOps environments. \n  Experience working with Splunk or Dynatrace. \n  Proficiency with shell scripting. \n  Experience working with Helm charts and yaml. \n  RabbitMQ and/or Kafka or Solace. \n  Experience with SQL and relational databases. \n  Experience with MongoDB and/or PostGres. \n  Golang and/or Python scripting skills. \n  Experience with Terraform. \n  Familiarity with CI/CD pipeline. \n  Proficiency in networking and related technologies. \n \n \n  The location for this role is: \n \n  United States \n \n   \n About Qlik \n \n  Qlik Company Page \u2013 Who we are!  \n Our Values at Qlik:   Challenge, Take Responsibility, Move Fast, T eamwork for Results , Be Open and Straightforward   \n Competitive Benefits package \n  Flexible working environment \n  Giving back is a part of our culture \u2013 we give you a day to change the world. In addition, we encourage our employees to participate in our Corporate Responsibility Employee Programs \n  Learn about our Corporate Responsibility Program by visiting Qlik.org \n  Check out our careers in R&D here. \n  Check out our company page on Linkedin! \n  Follow us on Instagram @lifeatqlik and @Qlik @lifeatqliklund \n  Check us out on Youtube! \n \n \n \n  The base salary range for this role is $ \n 1 \n 00,000 \n -$ \n 155,000 \n . \n \n \n \n \n \n Compensation offered will be based on factors such as the candidate\u2019s location, job related skills, education, experience and other business and organizational needs.  \n \n \n Qlik offers a comprehensive benefits package which includes, but is not limited to, healthcare and dental benefits, a 401(k) plan and match, paid time off, and mental health benefits. \n \n \n \n  Qlik is an Equal Opportunity/Affirmative Action  \n Employer, \n  and we value the diversity of our workforce \n .  Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Click here to review the US Department of Labor\u2019s \n   Equal Employment Opportunity Posters , including the \n   EEO is The Law  notice and the \n   Pay Transparency  \n Nondiscrimination Provision .\n  \n \n \n  If you need assistance due to disability during the application and/or recruiting process, please contact us via the  \n Accessibility Request Form \n . \n \n \n \n  Qlik is not accepting unsolicited assistance from search firms for this employment opportunity. Please, no phone calls or emails. All resumes submitted by search firms to any employee at Qlik via-email, the Internet or in any form and/or method without a valid written search agreement in place for this position will be deemed the sole property of Qlik. No fee will be paid in the event the candidate is hired by Qlik as a result of the referral or through other means.", "cleaned_desc": "  Facilitating cost control by regularly evaluating and right-sizing provisioned resources \n  Assisting with writing and maintaining documentation required for soc compliance and business needs. \n \n  Skills and qualifications for this role include: \n  Required:  \n \n Three or more years DevOps experience. \n  Proficiency in one or more scripting languages. \n  A healthy fear of breaking our production environment. \n  Working knowledge of cloud development and infrastructure tools. \n  Proficiency with Kubernetes and related services.  \n Experience working in an AWS VPC environment.  \n Proficiency working with Docker including creating images. \n  Proficiency working with APIs. \n  Strong understanding of security best practices through multiple layers of infrastructure. \n  Familiarity working in Linux environments. \n  Ability to communicate and collaborate effectively. \n  Effective written communication skills. \n  Experience with Infrastructure as Code. \n  Experience working with Grafana or similar. \n \n  Preferred:    \n CKA (Certified Kubernetes Administrator). \n  Experience working in GitOps environments. \n  Experience working with Splunk or Dynatrace. \n  Proficiency with shell scripting. \n  Experience working with Helm charts and yaml. \n  RabbitMQ and/or Kafka or Solace. \n  Experience with SQL and relational databases. \n  Experience with MongoDB and/or PostGres. \n  Golang and/or Python scripting skills. \n  Experience with Terraform. \n  Familiarity with CI/CD pipeline. \n  Proficiency in networking and related technologies. \n \n \n  The location for this role is: \n \n  United States \n \n   \n About Qlik \n ", "techs": ["facilitating cost control", "right-sizing provisioned resources", "writing and maintaining documentation", "devops experience", "proficiency in scripting languages", "knowledge of cloud development and infrastructure tools", "proficiency with kubernetes", "experience in aws vpc environment", "proficiency with docker", "proficiency with apis", "understanding of security best practices", "working in linux environments", "communication and collaboration skills", "written communication skills", "experience with infrastructure as code", "experience with grafana", "cka (certified kubernetes administrator)", "experience with gitops environments", "experience with splunk or dynatrace", "proficiency with shell scripting", "experience with helm charts and yaml", "rabbitmq and/or kafka or solace", "experience with sql and relational databases", "experience with mongodb and/or postgres", "golang and/or python scripting skills", "experience with terraform", "familiarity with ci/cd pipeline", "proficiency in networking and related technologies."]}, "9aa7c840202457f3": {"terms": ["mlops"], "salary_min": 100000.0, "salary_max": 155000.0, "title": "DevOps Engineer", "company": "Qlik", "desc": "What makes us Qlik \n \n   Qlik helps enterprises around the world move faster, work smarter, and lead the way forward with an end-to-end solution for getting value out of data. A Gartner Magic Quadrant Leader for 13 years in a row! Our platform is the only one on the market that allows for open-ended, curiosity-driven exploration, giving everyone \u2013 at any skill level \u2013 the ability to make real discoveries that lead to real outcomes and transformative changes. We are a Values-Driven organization, operating over 100 countries with 38,000 customers around the world. If you think we are interesting, please read on \u2013 we may be looking for you!\n   \n \n    DevOps Engineer \n \n   In this role you\u2019ll need to collaborate effectively with people that have diverse backgrounds and skill sets in addition to having and applying a deep understanding of critical technical skills. You will mentor others in their areas of strength and experience, while quickly learning new skills, adapting, and contributing in areas outside of your previous focus as needs arise. We ask that you are an effective and compassionate communicator and are able to construct and present valid arguments for decisions and discuss solutions with humility and mutual respect for the opinions and thoughts of others. You are always ready both to learn and to teach with the primary goal that the team succeeds.\n  \n   \n Responsibilities include, but not limited to: \n \n  Helping to manage, expand, and improve the infrastructure on which our applications and services run. \n  Facilitating SOC compliance and security best practices as it is today and as it evolves. \n  Analyzing and monitoring applications and infrastructure to proactively identify issues before they become problems. \n  Facilitating application deployments and continuous integration deployment pipelines. \n  Helping developers to remain productive and assist them to remove blockers. \n  Participating in planning discussions to gain understanding of product road maps with an eye on staying ahead of infrastructure needs as we grow. \n  Assisting the team with architectural decisions. \n  Triaging when necessary and helping to address the problems and complexities that arise as products and teams grow. \n  Assisting in evaluating, or developing, and implementing new tools that help us more effectively and efficiently achieve our goals. \n  Mentoring junior engineers to help them improve their practices and understanding of networking, security, data management, compliance, tools and best practices. \n  Facilitating cost control by regularly evaluating and right-sizing provisioned resources \n  Assisting with writing and maintaining documentation required for soc compliance and business needs. \n \n  Skills and qualifications for this role include: \n  Required:  \n \n Three or more years DevOps experience. \n  Proficiency in one or more scripting languages. \n  A healthy fear of breaking our production environment. \n  Working knowledge of cloud development and infrastructure tools. \n  Proficiency with Kubernetes and related services.  \n Experience working in an AWS VPC environment.  \n Proficiency working with Docker including creating images. \n  Proficiency working with APIs. \n  Strong understanding of security best practices through multiple layers of infrastructure. \n  Familiarity working in Linux environments. \n  Ability to communicate and collaborate effectively. \n  Effective written communication skills. \n  Experience with Infrastructure as Code. \n  Experience working with Grafana or similar. \n \n  Preferred:  \n \n CKA (Certified Kubernetes Administrator). \n  Experience working in GitOps environments. \n  Experience working with Splunk or Dynatrace. \n  Proficiency with shell scripting. \n  Experience working with Helm charts and yaml. \n  RabbitMQ and/or Kafka or Solace. \n  Experience with SQL and relational databases. \n  Experience with MongoDB and/or PostGres. \n  Golang and/or Python scripting skills. \n  Experience with Terraform. \n  Familiarity with CI/CD pipeline. \n  Proficiency in networking and related technologies. \n \n \n  The location for this role is: \n \n  United States \n \n   \n About Qlik \n \n  Qlik Company Page \u2013 Who we are!  \n Our Values at Qlik:   Challenge, Take Responsibility, Move Fast, T eamwork for Results , Be Open and Straightforward   \n Competitive Benefits package \n  Flexible working environment \n  Giving back is a part of our culture \u2013 we give you a day to change the world. In addition, we encourage our employees to participate in our Corporate Responsibility Employee Programs \n  Learn about our Corporate Responsibility Program by visiting Qlik.org \n  Check out our careers in R&D here. \n  Check out our company page on Linkedin! \n  Follow us on Instagram @lifeatqlik and @Qlik @lifeatqliklund \n  Check us out on Youtube! \n \n \n \n  The base salary range for this role is $ \n 1 \n 00,000 \n -$ \n 155,000 \n . \n \n \n \n \n \n Compensation offered will be based on factors such as the candidate\u2019s location, job related skills, education, experience and other business and organizational needs.  \n \n \n Qlik offers a comprehensive benefits package which includes, but is not limited to, healthcare and dental benefits, a 401(k) plan and match, paid time off, and mental health benefits. \n \n \n \n  Qlik is an Equal Opportunity/Affirmative Action  \n Employer, \n  and we value the diversity of our workforce \n .  Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Click here to review the US Department of Labor\u2019s \n   Equal Employment Opportunity Posters , including the \n   EEO is The Law  notice and the \n   Pay Transparency  \n Nondiscrimination Provision .\n  \n \n \n  If you need assistance due to disability during the application and/or recruiting process, please contact us via the  \n Accessibility Request Form \n . \n \n \n \n  Qlik is not accepting unsolicited assistance from search firms for this employment opportunity. Please, no phone calls or emails. All resumes submitted by search firms to any employee at Qlik via-email, the Internet or in any form and/or method without a valid written search agreement in place for this position will be deemed the sole property of Qlik. No fee will be paid in the event the candidate is hired by Qlik as a result of the referral or through other means.", "cleaned_desc": "  Facilitating cost control by regularly evaluating and right-sizing provisioned resources \n  Assisting with writing and maintaining documentation required for soc compliance and business needs. \n \n  Skills and qualifications for this role include: \n  Required:  \n \n Three or more years DevOps experience. \n  Proficiency in one or more scripting languages. \n  A healthy fear of breaking our production environment. \n  Working knowledge of cloud development and infrastructure tools. \n  Proficiency with Kubernetes and related services.  \n Experience working in an AWS VPC environment.  \n Proficiency working with Docker including creating images. \n  Proficiency working with APIs. \n  Strong understanding of security best practices through multiple layers of infrastructure. \n  Familiarity working in Linux environments. \n  Ability to communicate and collaborate effectively. \n  Effective written communication skills. \n  Experience with Infrastructure as Code. \n  Experience working with Grafana or similar. \n \n  Preferred:    \n CKA (Certified Kubernetes Administrator). \n  Experience working in GitOps environments. \n  Experience working with Splunk or Dynatrace. \n  Proficiency with shell scripting. \n  Experience working with Helm charts and yaml. \n  RabbitMQ and/or Kafka or Solace. \n  Experience with SQL and relational databases. \n  Experience with MongoDB and/or PostGres. \n  Golang and/or Python scripting skills. \n  Experience with Terraform. \n  Familiarity with CI/CD pipeline. \n  Proficiency in networking and related technologies. \n \n \n  The location for this role is: \n \n  United States \n \n   \n About Qlik \n ", "techs": ["right-sizing provisioned resources", "devops", "scripting languages", "cloud development", "infrastructure tools", "kubernetes", "aws vpc environment", "docker", "apis", "security best practices", "linux environments", "communication and collaboration", "written communication skills", "infrastructure as code", "grafana", "cka (certified kubernetes administrator)", "gitops", "splunk", "dynatrace", "shell scripting", "helm charts", "yaml", "rabbitmq", "kafka", "solace", "sql", "relational databases", "mongodb", "postgres", "golang scripting skills", "python scripting skills", "terraform", "ci/cd pipeline", "networking technologies."]}, "1e96739d1722f555": {"terms": ["mlops"], "salary_min": 100000.0, "salary_max": 155000.0, "title": "DevOps Engineer", "company": "Qlik", "desc": "What makes us Qlik \n \n   Qlik helps enterprises around the world move faster, work smarter, and lead the way forward with an end-to-end solution for getting value out of data. A Gartner Magic Quadrant Leader for 13 years in a row! Our platform is the only one on the market that allows for open-ended, curiosity-driven exploration, giving everyone \u2013 at any skill level \u2013 the ability to make real discoveries that lead to real outcomes and transformative changes. We are a Values-Driven organization, operating over 100 countries with 38,000 customers around the world. If you think we are interesting, please read on \u2013 we may be looking for you!\n   \n \n    DevOps Engineer \n \n   In this role you\u2019ll need to collaborate effectively with people that have diverse backgrounds and skill sets in addition to having and applying a deep understanding of critical technical skills. You will mentor others in their areas of strength and experience, while quickly learning new skills, adapting, and contributing in areas outside of your previous focus as needs arise. We ask that you are an effective and compassionate communicator and are able to construct and present valid arguments for decisions and discuss solutions with humility and mutual respect for the opinions and thoughts of others. You are always ready both to learn and to teach with the primary goal that the team succeeds.\n  \n   \n Responsibilities include, but not limited to: \n \n  Helping to manage, expand, and improve the infrastructure on which our applications and services run. \n  Facilitating SOC compliance and security best practices as it is today and as it evolves. \n  Analyzing and monitoring applications and infrastructure to proactively identify issues before they become problems. \n  Facilitating application deployments and continuous integration deployment pipelines. \n  Helping developers to remain productive and assist them to remove blockers. \n  Participating in planning discussions to gain understanding of product road maps with an eye on staying ahead of infrastructure needs as we grow. \n  Assisting the team with architectural decisions. \n  Triaging when necessary and helping to address the problems and complexities that arise as products and teams grow. \n  Assisting in evaluating, or developing, and implementing new tools that help us more effectively and efficiently achieve our goals. \n  Mentoring junior engineers to help them improve their practices and understanding of networking, security, data management, compliance, tools and best practices. \n  Facilitating cost control by regularly evaluating and right-sizing provisioned resources \n  Assisting with writing and maintaining documentation required for soc compliance and business needs. \n \n  Skills and qualifications for this role include: \n  Required:  \n \n Three or more years DevOps experience. \n  Proficiency in one or more scripting languages. \n  A healthy fear of breaking our production environment. \n  Working knowledge of cloud development and infrastructure tools. \n  Proficiency with Kubernetes and related services.  \n Experience working in an AWS VPC environment.  \n Proficiency working with Docker including creating images. \n  Proficiency working with APIs. \n  Strong understanding of security best practices through multiple layers of infrastructure. \n  Familiarity working in Linux environments. \n  Ability to communicate and collaborate effectively. \n  Effective written communication skills. \n  Experience with Infrastructure as Code. \n  Experience working with Grafana or similar. \n \n  Preferred:  \n \n CKA (Certified Kubernetes Administrator). \n  Experience working in GitOps environments. \n  Experience working with Splunk or Dynatrace. \n  Proficiency with shell scripting. \n  Experience working with Helm charts and yaml. \n  RabbitMQ and/or Kafka or Solace. \n  Experience with SQL and relational databases. \n  Experience with MongoDB and/or PostGres. \n  Golang and/or Python scripting skills. \n  Experience with Terraform. \n  Familiarity with CI/CD pipeline. \n  Proficiency in networking and related technologies. \n \n \n  The location for this role is: \n \n  United States \n \n   \n About Qlik \n \n  Qlik Company Page \u2013 Who we are!  \n Our Values at Qlik:   Challenge, Take Responsibility, Move Fast, T eamwork for Results , Be Open and Straightforward   \n Competitive Benefits package \n  Flexible working environment \n  Giving back is a part of our culture \u2013 we give you a day to change the world. In addition, we encourage our employees to participate in our Corporate Responsibility Employee Programs \n  Learn about our Corporate Responsibility Program by visiting Qlik.org \n  Check out our careers in R&D here. \n  Check out our company page on Linkedin! \n  Follow us on Instagram @lifeatqlik and @Qlik @lifeatqliklund \n  Check us out on Youtube! \n \n \n \n  The base salary range for this role is $ \n 1 \n 00,000 \n -$ \n 155,000 \n . \n \n \n \n \n \n Compensation offered will be based on factors such as the candidate\u2019s location, job related skills, education, experience and other business and organizational needs.  \n \n \n Qlik offers a comprehensive benefits package which includes, but is not limited to, healthcare and dental benefits, a 401(k) plan and match, paid time off, and mental health benefits. \n \n \n \n  Qlik is an Equal Opportunity/Affirmative Action  \n Employer, \n  and we value the diversity of our workforce \n .  Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Click here to review the US Department of Labor\u2019s \n   Equal Employment Opportunity Posters , including the \n   EEO is The Law  notice and the \n   Pay Transparency  \n Nondiscrimination Provision .\n  \n \n \n  If you need assistance due to disability during the application and/or recruiting process, please contact us via the  \n Accessibility Request Form \n . \n \n \n \n  Qlik is not accepting unsolicited assistance from search firms for this employment opportunity. Please, no phone calls or emails. All resumes submitted by search firms to any employee at Qlik via-email, the Internet or in any form and/or method without a valid written search agreement in place for this position will be deemed the sole property of Qlik. No fee will be paid in the event the candidate is hired by Qlik as a result of the referral or through other means.", "cleaned_desc": "  Facilitating cost control by regularly evaluating and right-sizing provisioned resources \n  Assisting with writing and maintaining documentation required for soc compliance and business needs. \n \n  Skills and qualifications for this role include: \n  Required:  \n \n Three or more years DevOps experience. \n  Proficiency in one or more scripting languages. \n  A healthy fear of breaking our production environment. \n  Working knowledge of cloud development and infrastructure tools. \n  Proficiency with Kubernetes and related services.  \n Experience working in an AWS VPC environment.  \n Proficiency working with Docker including creating images. \n  Proficiency working with APIs. \n  Strong understanding of security best practices through multiple layers of infrastructure. \n  Familiarity working in Linux environments. \n  Ability to communicate and collaborate effectively. \n  Effective written communication skills. \n  Experience with Infrastructure as Code. \n  Experience working with Grafana or similar. \n \n  Preferred:    \n CKA (Certified Kubernetes Administrator). \n  Experience working in GitOps environments. \n  Experience working with Splunk or Dynatrace. \n  Proficiency with shell scripting. \n  Experience working with Helm charts and yaml. \n  RabbitMQ and/or Kafka or Solace. \n  Experience with SQL and relational databases. \n  Experience with MongoDB and/or PostGres. \n  Golang and/or Python scripting skills. \n  Experience with Terraform. \n  Familiarity with CI/CD pipeline. \n  Proficiency in networking and related technologies. \n \n \n  The location for this role is: \n \n  United States \n \n   \n About Qlik \n ", "techs": ["kubernetes", "aws", "docker", "apis", "linux", "grafana", "cka", "gitops", "splunk", "dynatrace", "shell scripting", "helm charts", "rabbitmq", "kafka", "solace", "sql", "relational databases", "mongodb", "postgres", "golang scripting", "python scripting", "terraform", "ci/cd pipeline", "networking"]}, "ea1f6b60f2637bc9": {"terms": ["mlops"], "salary_min": 100000.0, "salary_max": 155000.0, "title": "DevOps Engineer", "company": "Qlik", "desc": "What makes us Qlik \n \n   Qlik helps enterprises around the world move faster, work smarter, and lead the way forward with an end-to-end solution for getting value out of data. A Gartner Magic Quadrant Leader for 13 years in a row! Our platform is the only one on the market that allows for open-ended, curiosity-driven exploration, giving everyone \u2013 at any skill level \u2013 the ability to make real discoveries that lead to real outcomes and transformative changes. We are a Values-Driven organization, operating over 100 countries with 38,000 customers around the world. If you think we are interesting, please read on \u2013 we may be looking for you!\n   \n \n    DevOps Engineer \n \n   In this role you\u2019ll need to collaborate effectively with people that have diverse backgrounds and skill sets in addition to having and applying a deep understanding of critical technical skills. You will mentor others in their areas of strength and experience, while quickly learning new skills, adapting, and contributing in areas outside of your previous focus as needs arise. We ask that you are an effective and compassionate communicator and are able to construct and present valid arguments for decisions and discuss solutions with humility and mutual respect for the opinions and thoughts of others. You are always ready both to learn and to teach with the primary goal that the team succeeds.\n  \n   \n Responsibilities include, but not limited to: \n \n  Helping to manage, expand, and improve the infrastructure on which our applications and services run. \n  Facilitating SOC compliance and security best practices as it is today and as it evolves. \n  Analyzing and monitoring applications and infrastructure to proactively identify issues before they become problems. \n  Facilitating application deployments and continuous integration deployment pipelines. \n  Helping developers to remain productive and assist them to remove blockers. \n  Participating in planning discussions to gain understanding of product road maps with an eye on staying ahead of infrastructure needs as we grow. \n  Assisting the team with architectural decisions. \n  Triaging when necessary and helping to address the problems and complexities that arise as products and teams grow. \n  Assisting in evaluating, or developing, and implementing new tools that help us more effectively and efficiently achieve our goals. \n  Mentoring junior engineers to help them improve their practices and understanding of networking, security, data management, compliance, tools and best practices. \n  Facilitating cost control by regularly evaluating and right-sizing provisioned resources \n  Assisting with writing and maintaining documentation required for soc compliance and business needs. \n \n  Skills and qualifications for this role include: \n  Required:  \n \n Three or more years DevOps experience. \n  Proficiency in one or more scripting languages. \n  A healthy fear of breaking our production environment. \n  Working knowledge of cloud development and infrastructure tools. \n  Proficiency with Kubernetes and related services.  \n Experience working in an AWS VPC environment.  \n Proficiency working with Docker including creating images. \n  Proficiency working with APIs. \n  Strong understanding of security best practices through multiple layers of infrastructure. \n  Familiarity working in Linux environments. \n  Ability to communicate and collaborate effectively. \n  Effective written communication skills. \n  Experience with Infrastructure as Code. \n  Experience working with Grafana or similar. \n \n  Preferred:  \n \n CKA (Certified Kubernetes Administrator). \n  Experience working in GitOps environments. \n  Experience working with Splunk or Dynatrace. \n  Proficiency with shell scripting. \n  Experience working with Helm charts and yaml. \n  RabbitMQ and/or Kafka or Solace. \n  Experience with SQL and relational databases. \n  Experience with MongoDB and/or PostGres. \n  Golang and/or Python scripting skills. \n  Experience with Terraform. \n  Familiarity with CI/CD pipeline. \n  Proficiency in networking and related technologies. \n \n \n  The location for this role is: \n \n  United States \n \n   \n About Qlik \n \n  Qlik Company Page \u2013 Who we are!  \n Our Values at Qlik:   Challenge, Take Responsibility, Move Fast, T eamwork for Results , Be Open and Straightforward   \n Competitive Benefits package \n  Flexible working environment \n  Giving back is a part of our culture \u2013 we give you a day to change the world. In addition, we encourage our employees to participate in our Corporate Responsibility Employee Programs \n  Learn about our Corporate Responsibility Program by visiting Qlik.org \n  Check out our careers in R&D here. \n  Check out our company page on Linkedin! \n  Follow us on Instagram @lifeatqlik and @Qlik @lifeatqliklund \n  Check us out on Youtube! \n \n \n \n  The base salary range for this role is $ \n 1 \n 00,000 \n -$ \n 155,000 \n . \n \n \n \n \n \n Compensation offered will be based on factors such as the candidate\u2019s location, job related skills, education, experience and other business and organizational needs.  \n \n \n Qlik offers a comprehensive benefits package which includes, but is not limited to, healthcare and dental benefits, a 401(k) plan and match, paid time off, and mental health benefits. \n \n \n \n  Qlik is an Equal Opportunity/Affirmative Action  \n Employer, \n  and we value the diversity of our workforce \n .  Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Click here to review the US Department of Labor\u2019s \n   Equal Employment Opportunity Posters , including the \n   EEO is The Law  notice and the \n   Pay Transparency  \n Nondiscrimination Provision .\n  \n \n \n  If you need assistance due to disability during the application and/or recruiting process, please contact us via the  \n Accessibility Request Form \n . \n \n \n \n  Qlik is not accepting unsolicited assistance from search firms for this employment opportunity. Please, no phone calls or emails. All resumes submitted by search firms to any employee at Qlik via-email, the Internet or in any form and/or method without a valid written search agreement in place for this position will be deemed the sole property of Qlik. No fee will be paid in the event the candidate is hired by Qlik as a result of the referral or through other means.", "cleaned_desc": "  Facilitating cost control by regularly evaluating and right-sizing provisioned resources \n  Assisting with writing and maintaining documentation required for soc compliance and business needs. \n \n  Skills and qualifications for this role include: \n  Required:  \n \n Three or more years DevOps experience. \n  Proficiency in one or more scripting languages. \n  A healthy fear of breaking our production environment. \n  Working knowledge of cloud development and infrastructure tools. \n  Proficiency with Kubernetes and related services.  \n Experience working in an AWS VPC environment.  \n Proficiency working with Docker including creating images. \n  Proficiency working with APIs. \n  Strong understanding of security best practices through multiple layers of infrastructure. \n  Familiarity working in Linux environments. \n  Ability to communicate and collaborate effectively. \n  Effective written communication skills. \n  Experience with Infrastructure as Code. \n  Experience working with Grafana or similar. \n \n  Preferred:    \n CKA (Certified Kubernetes Administrator). \n  Experience working in GitOps environments. \n  Experience working with Splunk or Dynatrace. \n  Proficiency with shell scripting. \n  Experience working with Helm charts and yaml. \n  RabbitMQ and/or Kafka or Solace. \n  Experience with SQL and relational databases. \n  Experience with MongoDB and/or PostGres. \n  Golang and/or Python scripting skills. \n  Experience with Terraform. \n  Familiarity with CI/CD pipeline. \n  Proficiency in networking and related technologies. \n \n \n  The location for this role is: \n \n  United States \n \n   \n About Qlik \n ", "techs": ["facilitating cost control by regularly evaluating and right-sizing provisioned resources", "devops experience", "proficiency in scripting languages", "working knowledge of cloud development and infrastructure tools", "proficiency with kubernetes and related services", "experience working in an aws vpc environment", "proficiency working with docker including creating images", "proficiency working with apis", "strong understanding of security best practices", "familiarity with linux environments", "ability to communicate and collaborate effectively", "experience with infrastructure as code", "experience working with grafana or similar", "cka (certified kubernetes administrator)", "experience working in gitops environments", "experience working with splunk or dynatrace", "proficiency with shell scripting", "experience working with helm charts and yaml", "rabbitmq and/or kafka or solace", "experience with sql and relational databases", "experience with mongodb and/or postgres", "golang and/or python scripting skills", "experience with terraform", "familiarity with ci/cd pipeline", "proficiency in networking and related technologies."]}, "af453c5311d30639": {"terms": ["mlops"], "salary_min": 73100.0, "salary_max": 166000.0, "title": "DevOps Engineer, Senior", "company": "Booz Allen Hamilton", "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Annapolis Junction,MD,US \n         \n \n \n \n         Remote Work: \n         \n \n         Hybrid \n         \n \n \n \n         Job Number: \n         \n \n         R0182579\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         DevOps Engineer, Senior\n           The Opportunity: \n  As a DevOps engineer, you know how to set up cloud environments and provision computer networking, storage, and virtual networks\u2014ultimately, how to \u201charness the cloud.\u201d We\u2019re looking for an experienced DevOps infrastructure engineer like you to support our clients as they modernize their IT infrastructures and meet their most challenging missions. \n \n  As a DevOps infrastructure engineer at Booz Allen, you\u2019ll work closely with cloud architects and engineers to manage server configuration for modern cloud solutions. You\u2019ll apply your skills within a DevOps framework to establish or provision virtual machines or networks and use cloud service providers to further your clients\u2019 meaningful missions. \n \n  With access to our internal innovative labs, there\u2019s no better place to further your skills and explore different ways of solving our clients\u2019 challenges. Whether helping to develop, deploy, or manage IT infrastructures for crucial server and network components, here you\u2019ll have the latest tech and brightest teammates at your fingertips. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  Experience in the development of tools and processes to drive DevOps or DevSecOps maturity by automating builds, regression testing, monitoring, and pushing releases across environments \n  Experience working with, building, and maintaining DevSecOps services with infrastructure as code (IaC) platforms and configuration management tools \n  Experience with containerization tools, including Docker and Kubernetes \n  Experience with automation tools, including SaltStack, Ansible, or Puppet \n  Experience with DevOps and CI/CD tools and automation, including Jenkins and GitHub Actions \n  Experience with network and server infrastructure monitoring and management \n  Experience with Linux systems use, including patching, optimization, scripting, automation, and other tasks \n  Experience working with application development teams across the software development lifecycle \n  Secret clearance  \n HS diploma or GED \n \n \n  Nice If You Have: \n \n  5+ years of experience in an infrastructure, DevSecOps, or application development role \n  Experience developing enterprise cloud-native solutions, including Kubernetes, Docker, AWS, Jenkins, or Azure \n  Experience installing, configuring, and managing Atlassian suite of development tools \n  Experience with Cross Domain Solutions, including tools like AWS Diode and DoD approved CDS technologies \n  Experience triaging and resolving issues related to both open-source and commercial tools in public cloud environments \n  Knowledge of scripting languages, including Python, Linux, or Shell Script \n  Master\u2019s degree \n  Industry Certifications, including Kubernetes Administrator (CKA) Certification \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. \n \n  Create Your Career: \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll develop your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $73,100.00 to $166,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.", "cleaned_desc": " \n \n \n \n \n \n         DevOps Engineer, Senior\n           The Opportunity: \n  As a DevOps engineer, you know how to set up cloud environments and provision computer networking, storage, and virtual networks\u2014ultimately, how to \u201charness the cloud.\u201d We\u2019re looking for an experienced DevOps infrastructure engineer like you to support our clients as they modernize their IT infrastructures and meet their most challenging missions. \n \n  As a DevOps infrastructure engineer at Booz Allen, you\u2019ll work closely with cloud architects and engineers to manage server configuration for modern cloud solutions. You\u2019ll apply your skills within a DevOps framework to establish or provision virtual machines or networks and use cloud service providers to further your clients\u2019 meaningful missions. \n \n  With access to our internal innovative labs, there\u2019s no better place to further your skills and explore different ways of solving our clients\u2019 challenges. Whether helping to develop, deploy, or manage IT infrastructures for crucial server and network components, here you\u2019ll have the latest tech and brightest teammates at your fingertips. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  Experience in the development of tools and processes to drive DevOps or DevSecOps maturity by automating builds, regression testing, monitoring, and pushing releases across environments \n  Experience working with, building, and maintaining DevSecOps services with infrastructure as code (IaC) platforms and configuration management tools \n  Experience with containerization tools, including Docker and Kubernetes \n  Experience with automation tools, including SaltStack, Ansible, or Puppet    Experience with DevOps and CI/CD tools and automation, including Jenkins and GitHub Actions \n  Experience with network and server infrastructure monitoring and management \n  Experience with Linux systems use, including patching, optimization, scripting, automation, and other tasks \n  Experience working with application development teams across the software development lifecycle \n  Secret clearance  \n HS diploma or GED \n \n \n  Nice If You Have: \n \n  5+ years of experience in an infrastructure, DevSecOps, or application development role \n  Experience developing enterprise cloud-native solutions, including Kubernetes, Docker, AWS, Jenkins, or Azure \n  Experience installing, configuring, and managing Atlassian suite of development tools \n  Experience with Cross Domain Solutions, including tools like AWS Diode and DoD approved CDS technologies \n  Experience triaging and resolving issues related to both open-source and commercial tools in public cloud environments \n  Knowledge of scripting languages, including Python, Linux, or Shell Script \n  Master\u2019s degree \n  Industry Certifications, including Kubernetes Administrator (CKA) Certification \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. ", "techs": ["devops engineer", "senior", "docker", "kubernetes", "saltstack", "ansible", "puppet", "jenkins", "github actions", "linux", "aws", "atlassian suite", "aws diode", "dod approved cds technologies", "python", "shell script", "kubernetes administrator (cka) certification"]}, "35c1abee26026831": {"terms": ["mlops"], "salary_min": 73100.0, "salary_max": 166000.0, "title": "DevOps Engineer, Senior", "company": "Booz Allen Hamilton", "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Annapolis Junction,MD,US \n         \n \n \n \n         Remote Work: \n         \n \n         Hybrid \n         \n \n \n \n         Job Number: \n         \n \n         R0182586\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         DevOps Engineer, Senior\n           The Opportunity:  \n Are you looking for an opportunity to make a difference in the DoD\u2019s pursuit of Offensive and Defensive Cyber Operations tools and capabilities? What if you could find a position that is tailor made for your mix of development, engineering, and communication skills? Everyone is trying to \u201charness the cloud,\u201d but not everyone knows how. That\u2019s why we need you, an experienced DevOps engineer, to help us shorten the time it takes to get critical tools developed. \n \n  As a DevOps engineer, you\u2019re eager to develop, manage, and secure a container platform that meets your client\u2019s needs and takes advantage of cloud capabilities. We need you to develop container management software to solve some of our client's toughest challenges. As a senior platform DevOps engineer at Booz Allen, you can use your technical skills to affect the development of Cyber Capabilities directly. On our team, you\u2019ll hone your skills using the latest cloud technologies as you look for ways to improve your client\u2019s environment with container software to ensure seamless orchestration. Using your DevOps platform experience, you\u2019ll support your team as you inform strategy and design while ensuring standards are met throughout the containerization process. You\u2019ll recommend and build out resources that will help your client manage and securely adopt container technology. Additionally, you\u2019ll continue to strengthen your DevOps skills while supporting the development of critical cloud platforms. \n \n  With access to our internal innovative labs, there\u2019s no better place to expand your skills and explore different ways of solving our clients\u2019 challenges. Whether helping to develop, deploy, or manage IT infrastructures for crucial server and network components, here you\u2019ll have the latest tech and brightest teammates at your fingertips. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  Experience in the development of tools and processes to drive DevOps or DevSecOps maturity by automating builds, regression testing, monitoring, and pushing releases across environments \n  Experience working with, building, and maintaining DevSecOps services with infrastructure as code (IaC) platforms and configuration management tools \n  Experience with containerization tools, including Docker and Kubernetes \n  Experience with automation tools, including SaltStack, Ansible, or Puppet \n  Experience with DevOps and CI/CD tools and automation, including Jenkins and GitHub Actions \n  Experience with network and server infrastructure monitoring and management \n  Experience with Linux systems use, including patching, optimization, scripting, automation, and other tasks \n  Experience working with application development teams across the software development lifecycle \n  Secret clearance \n  HS diploma or GED \n \n \n  Nice If You Have: \n \n  5+ years of experience in an infrastructure, DevSecOps, or application development role \n  Experience developing enterprise cloud-native solutions, including Kubernetes, Docker, AWS, Jenkins, or Azure \n  Experience with installing, configuring, and managing Atlassian suite of development tools \n  Experience with Cross Domain Solutions, including tools like AWS Diode and DoD approved CDS technologies \n  Experience triaging and resolving issues related to both open-source and commercial tools in public cloud environments \n  Knowledge of scripting languages, including Python, Linux, or Shell Script \n  Master\u2019s degree \n  Industry Certifications, including Kubernetes Administrator (CKA) Certification \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. \n \n  Create Your Career: \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll develop your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $73,100.00 to $166,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.", "cleaned_desc": "  Experience with DevOps and CI/CD tools and automation, including Jenkins and GitHub Actions \n  Experience with network and server infrastructure monitoring and management \n  Experience with Linux systems use, including patching, optimization, scripting, automation, and other tasks \n  Experience working with application development teams across the software development lifecycle \n  Secret clearance \n  HS diploma or GED \n \n \n  Nice If You Have: \n \n  5+ years of experience in an infrastructure, DevSecOps, or application development role \n  Experience developing enterprise cloud-native solutions, including Kubernetes, Docker, AWS, Jenkins, or Azure \n  Experience with installing, configuring, and managing Atlassian suite of development tools \n  Experience with Cross Domain Solutions, including tools like AWS Diode and DoD approved CDS technologies \n  Experience triaging and resolving issues related to both open-source and commercial tools in public cloud environments \n  Knowledge of scripting languages, including Python, Linux, or Shell Script \n  Master\u2019s degree \n  Industry Certifications, including Kubernetes Administrator (CKA) Certification \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. ", "techs": ["jenkins,github actions,linux,kubernetes,docker,aws,azure,atlassian,python,shell script,kubernetes administrator (cka) certification"]}, "bffc97b6c48ace95": {"terms": ["mlops"], "salary_min": 73100.0, "salary_max": 166000.0, "title": "DevOps Engineer, Senior", "company": "Booz Allen Hamilton", "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Annapolis Junction,MD,US \n         \n \n \n \n         Remote Work: \n         \n \n         Hybrid \n         \n \n \n \n         Job Number: \n         \n \n         R0182587\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         DevOps Engineer, Senior\n           The Opportunity:  \n Are you looking for an opportunity to make a difference in the DoD\u2019s pursuit of Offensive and Defensive Cyber Operations tools and capabilities? What if you could find a position that is tailor made for your mix of development, engineering, and communication skills? Everyone is trying to \u201charness the cloud,\u201d but not everyone knows how. That\u2019s why we need you, an experienced DevOps engineer, to help us shorten the time it takes to get critical tools developed. \n \n  As a DevOps engineer, you\u2019re eager to develop, manage, and secure a container platform that meets your client\u2019s needs and takes advantage of cloud capabilities. We need you to develop container management software to solve some of our client's toughest challenges. As a senior platform DevOps engineer at Booz Allen, you can use your technical skills to affect the development of Cyber Capabilities directly. On our team, you\u2019ll hone your skills using the latest cloud technologies as you look for ways to improve your client\u2019s environment with container software to ensure seamless orchestration. Using your DevOps platform experience, you\u2019ll support your team as you inform strategy and design while ensuring standards are met throughout the containerization process. You\u2019ll recommend and build out resources that will help your client manage and securely adopt container technology. Additionally, you\u2019ll continue to strengthen your DevOps skills while supporting the development of critical cloud platforms. \n \n  With access to our internal innovative labs, there\u2019s no better place to expand your skills and explore different ways of solving our clients\u2019 challenges. Whether helping to develop, deploy, or manage IT infrastructures for crucial server and network components, here you\u2019ll have the latest tech and brightest teammates at your fingertips. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  Experience in the development of tools and processes to drive DevOps or DevSecOps maturity by automating builds, regression testing, monitoring, and pushing releases across environments \n  Experience working with, building, and maintaining DevSecOps services with infrastructure as code (IaC) platforms and configuration management tools \n  Experience with containerization tools, including Docker and Kubernetes \n  Experience with automation tools, including SaltStack, Ansible, or Puppet \n  Experience with DevOps and CI/CD tools and automation, including Jenkins and GitHub Actions \n  Experience with network and server infrastructure monitoring and management \n  Experience with Linux systems use, including patching, optimization, scripting, automation, and other tasks \n  Experience working with application development teams across the software development lifecycle \n  Secret clearance \n  HS diploma or GED \n \n \n  Nice If You Have: \n \n  5+ years of experience in an infrastructure, DevSecOps, or application development role \n  Experience developing enterprise cloud-native solutions, including Kubernetes, Docker, AWS, Jenkins, or Azure \n  Experience installing, configuring, and managing Atlassian suite of development tools \n  Experience with Cross Domain Solutions, including tools like AWS Diode and DoD approved CDS technologies \n  Experience triaging and resolving issues related to both open-source and commercial tools in public cloud environments \n  Knowledge of scripting languages, including Python, Linux, or Shell Script \n  Master\u2019s degree \n  Industry Certifications, including Kubernetes Administrator (CKA) Certification \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. \n \n  Create Your Career: \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll develop your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $73,100.00 to $166,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.", "cleaned_desc": "  Experience with DevOps and CI/CD tools and automation, including Jenkins and GitHub Actions \n  Experience with network and server infrastructure monitoring and management \n  Experience with Linux systems use, including patching, optimization, scripting, automation, and other tasks \n  Experience working with application development teams across the software development lifecycle \n  Secret clearance \n  HS diploma or GED \n \n \n  Nice If You Have: \n \n  5+ years of experience in an infrastructure, DevSecOps, or application development role \n  Experience developing enterprise cloud-native solutions, including Kubernetes, Docker, AWS, Jenkins, or Azure \n  Experience installing, configuring, and managing Atlassian suite of development tools \n  Experience with Cross Domain Solutions, including tools like AWS Diode and DoD approved CDS technologies \n  Experience triaging and resolving issues related to both open-source and commercial tools in public cloud environments \n  Knowledge of scripting languages, including Python, Linux, or Shell Script \n  Master\u2019s degree \n  Industry Certifications, including Kubernetes Administrator (CKA) Certification \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. ", "techs": ["jenkins", "github actions", "linux", "kubernetes", "docker", "aws", "azure", "atlassian suite", "aws diode", "cds technologies", "python", "shell script", "kubernetes administrator (cka) certification"]}, "f4feb8c0360386b5": {"terms": ["mlops"], "salary_min": 112000.0, "salary_max": 179000.0, "title": "DevOps Engineer", "company": "Peraton", "desc": "Peraton Overview \n  Peraton drives missions of consequence spanning the globe and extending to the farthest reaches of the galaxy. As the world's leading mission capability integrator and transformative enterprise IT provider, we deliver trusted and highly differentiated national security solutions and technologies that keep people safe and secure. Peraton serves as a valued partner to essential government agencies across the intelligence, space, cyber, defense, civilian, health, and state and local markets. Every day, our employees do the can't be done, solving the most daunting challenges facing our customers.\n  \n Responsibilities \n \n  We are looking to add a \n  DevOps Engineer  who will design, develop and modify our DevOps platform/infrastructure and create CI/CD orchestration across our AWS cloud and mainframe ecosystem as we modernize applications to AWS. \n  \n \n What you'll do: \n \n \n Automate and orchestrate application and testing CI/CD pipelines across Mainframe and Amazon Web Services  \n Collaborate with our DevOps team in designing orchestration for mainframe and cloud application deployments and maintenance  \n Integrate test and security automation within CI/CD pipelines to include both legacy mainframe and modern cloud architectures.  \n Support unit testing and integration of developed orchestration and CI/CD components.  \n Evaluate and recommend DevOps tools sets and platforms  \n Provide coaching and mentoring to junior staff.  \n Be passionate and curious about technology and cloud computing.  \n Determine integrated application user needs; analyze system capabilities, and design orchestration workloads to deliver mainframe and cloud applications  \n Coordinates software system installations and monitors equipment functioning to ensure specifications are met.  \n \n \n Qualifications \n \n \n Basic Qualifications: \n \n \n Bachelors degree and 8-10 years, Masters degree 6-8 years, PhD 3-5 years of work experience  \n Automation experience with configuration/deployment management systems such as, Terraform, Jenkins, Chef, Puppet, Ansible, AWS Cloud Formation or other such tools  \n Experience delivering change in an Agile/Scrum environment.  \n Experience in the Atlassian toolset: Jira, Confluence, etc.  \n Proven experience with the following or similar languages: Python, PHP, Ruby, Groovy and Java.  \n Proficient with git and git workflows  \n Proficient in leveraging CI and CD tools to automate testing and deployment  \n Familiarity with one or more of the following DevOps Tools: Git or GitHub, Jenkins, puppet, chef ansible  \n \n \n Preferred Qualifications: \n \n \n Experience in implementing DevOps and CI/CD pipelines in a mainframe zOS environment a plus  \n Experience with mainframe DevOps tools such as IBM Dependency, Based Build, Groovy, and Urban Code Deploy a plus.  \n Verbal and written communication skills, problem solving skills, customer service and interpersonal skills.  \n \n \n Benefits:  \n \n  At Peraton, our benefits are designed to help keep you at your best beyond the work you do with us daily. We're fully committed to the growth of our employees. From fully comprehensive medical plans to tuition reimbursement, tuition assistance, and fertility treatment, we are there to support you all the way. \n  \n  . \n  \n \n Target Salary Range \n \n  $112,000 - $179,000. This represents the typical salary range for this position based on experience and other factors.\n  \n \n SCA / Union / Intern Rate or Range \n \n \n EEO \n  An Equal Opportunity Employer including Disability/Veteran.\n  \n \n Our Values \n \n \n Benefits \n  At Peraton, our benefits are designed to help keep you at your best beyond the work you do with us daily. We're fully committed to the growth of our employees. From fully comprehensive medical plans to tuition reimbursement, tuition assistance, and fertility treatment, we are there to support you all the way.\n  \n \n  Paid Time-Off and Holidays \n  Retirement \n  Life & Disability Insurance \n  Career Development \n  Tuition Assistance and Student Loan Financing \n  Paid Parental Leave \n  Additional Benefits \n  Medical, Dental, & Vision Care", "cleaned_desc": " Experience in the Atlassian toolset: Jira, Confluence, etc.  \n Proven experience with the following or similar languages: Python, PHP, Ruby, Groovy and Java.  \n Proficient with git and git workflows  \n Proficient in leveraging CI and CD tools to automate testing and deployment  \n Familiarity with one or more of the following DevOps Tools: Git or GitHub, Jenkins, puppet, chef ansible  \n \n \n Preferred Qualifications: \n \n \n Experience in implementing DevOps and CI/CD pipelines in a mainframe zOS environment a plus  \n Experience with mainframe DevOps tools such as IBM Dependency, Based Build, Groovy, and Urban Code Deploy a plus.  \n Verbal and written communication skills, problem solving skills, customer service and interpersonal skills.  \n \n \n Benefits:  ", "techs": ["atlassian toolset: jira", "confluence\npython", "php", "ruby", "groovy", "java\ngit", "github\njenkins", "puppet", "chef", "ansible\nibm dependency", "based build", "groovy", "urban code deploy"]}, "bd65ffa74521fd62": {"terms": ["mlops"], "salary_min": 100000.0, "salary_max": 130000.0, "title": "DevOps Engineer - Remote", "company": "CyberCoders", "desc": "DevOps Engineer - Remote \n  \n  We are a rapidly growing pharmacy based out of Atlantic County, NJ. We are committed to improving patients outcomes by providing optimal service and an unsurpassed level of care. By integrating clinical pharmacy care with technology and dedication to the patient we offer an unparalleled pharmacy experience enabling a healthier tomorrow.\n   \n  The DevOps Engineer will be responsible for the smooth operation of our IT infrastructure. Work with developers to deploy and manage code changes, and with operations staff to ensure that systems are up and running smoothly. To be successful in this role, a DevOps engineer must have a deep understanding of both development and operations processes, as well as a strong technical background.\n  \n  What You Will Be Doing \n \n Collaborate with development teams to design and implement CI/CD pipelines for PHP and Laravel applications on Azure, Windows, and Linux. \n Manage and automate deployment, scaling, and monitoring of PHP applications in Azure Kubernetes Service (AKS) or Azure App Service. \n Ensure the reliability and performance of our systems \n Implement and maintain security best practices, including identity and access management, encryption, and compliance on Azure. \n Troubleshoot and resolve infrastructure issues in a timely manner. \n Continuously monitor system performance and proactively optimize infrastructure for cost efficiency. \n Collaborate with cross-functional teams to optimize application architecture for cloud scalability. \n Stay updated on industry trends and emerging technologies to drive innovation within the team. \n \n  What You Need for this Position \n \n   BSCS or similar and 3+ years of:\n   \n \n Experience with containerization and orchestration tools such as Docker. \n Experience with software development using LAMP stack. \n Familiarity with CI/CD tools such as GitLab CI/CD, or Azure DevOps Pipelines. \n Strong expertise in Azure services, including Azure DevOps, Azure Kubernetes Service, Azure App Service, and Azure Monitor. \n Strong analytical and problem-solving skills required. \n \n \n  What's In It for You \n \n   Salary: $100,000-$130,000/year\n   \n \n Full benefits: Medical, Dental, Vision \n 401 (K) with generous company match \n Vacation, sick, and paid holidays \n Life Insurance coverage \n \n \n  Benefits \n \n Vacation/PTO \n Medical \n Dental \n Vision \n 401k \n \n \n   So, if this sounds like you, we'd love to hear from you!\n   \n  Either:\n    1. Apply directly to this job opening here!\n   \n  Or\n   \n  2. E-mail directly for more information to patrick.solano@cybercoders.com\n  \n \n   Colorado employees will receive paid sick leave. For additional information about available benefits, please contact Patrick Solano\n  \n \n Applicants must be authorized to work in the U.S. \n  CyberCoders is proud to be an Equal Opportunity Employer \n \n  All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.\n  \n \n Your Right to Work  \u2013 In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.", "cleaned_desc": "DevOps Engineer - Remote \n  \n  We are a rapidly growing pharmacy based out of Atlantic County, NJ. We are committed to improving patients outcomes by providing optimal service and an unsurpassed level of care. By integrating clinical pharmacy care with technology and dedication to the patient we offer an unparalleled pharmacy experience enabling a healthier tomorrow.\n   \n  The DevOps Engineer will be responsible for the smooth operation of our IT infrastructure. Work with developers to deploy and manage code changes, and with operations staff to ensure that systems are up and running smoothly. To be successful in this role, a DevOps engineer must have a deep understanding of both development and operations processes, as well as a strong technical background.\n  \n  What You Will Be Doing \n \n Collaborate with development teams to design and implement CI/CD pipelines for PHP and Laravel applications on Azure, Windows, and Linux. \n Manage and automate deployment, scaling, and monitoring of PHP applications in Azure Kubernetes Service (AKS) or Azure App Service. \n Ensure the reliability and performance of our systems \n Implement and maintain security best practices, including identity and access management, encryption, and compliance on Azure. \n Troubleshoot and resolve infrastructure issues in a timely manner.   Continuously monitor system performance and proactively optimize infrastructure for cost efficiency. \n Collaborate with cross-functional teams to optimize application architecture for cloud scalability. \n Stay updated on industry trends and emerging technologies to drive innovation within the team. \n \n  What You Need for this Position \n \n   BSCS or similar and 3+ years of:\n   \n \n Experience with containerization and orchestration tools such as Docker. \n Experience with software development using LAMP stack. \n Familiarity with CI/CD tools such as GitLab CI/CD, or Azure DevOps Pipelines. \n Strong expertise in Azure services, including Azure DevOps, Azure Kubernetes Service, Azure App Service, and Azure Monitor. ", "techs": ["docker", "lamp stack", "gitlab ci/cd", "azure devops", "azure kubernetes service", "azure app service", "azure monitor"]}, "2f2f1bc6080eb3f5": {"terms": ["mlops"], "salary_min": 89172.11, "salary_max": 112911.766, "title": "DevOps Engineer", "company": "Regional Management Corp.", "desc": "Are you ready to take your career to the next level? Regional strives to positively impact the financial lives of our customers. \n \n  For over 35 years, our Team Members have been passionate about supporting customers through their financial challenges in life. They take pleasure in finding solutions and lending a helping hand, both to our customers and our communities. As we continue to grow and become a national brand in consumer financing, we hope you\u2019ll consider us for future career opportunities. \n \n  If you are looking to make a meaningful impact in people\u2019s lives by bringing a personal touch to finances, join our team today! \n \n  DevOps Engineer \n  Design, build and maintain a stable and efficient infrastructure to optimize service delivery across production, QA, and development environments throughout the development lifecycle. Monitor, troubleshoot, maintain, and continuously improve building, packaging, and deployment processes. Implement automated infrastructure capabilities like backups, security tools, monitoring. Utilize a consistent DevOps approach to improve all phases of the process and ensure end-to-end quality across functions. \n \n  Duties and Responsibilities \n \n  Implement infrastructure as code including automated creation of environments, their settings, and spin down. Designing and building resilient infrastructure and environment automation solutions at scale. \n  Develop the CI/CD environment including timely upgrades to source control systems. \n  Build and maintain the CI/CD pipelines of our custom software using industry standard tools or custom tools. \n  Working with software engineers and quality assurance teams to implement standardized builds and releases (Release engineering including branching, versioning). \n  Work closely with our internal engineering teams to automate manual processes and build/support our continuous integration and continuous delivery code pipelines by leveraging industry standard toolsets and security mindset. \n \n \n  Minimum Qualifications \n \n  BA/BS in Computer Science, Electrical Engineering, Mathematics, Statistics, a related field, or equivalent. \n  2-5 years of work experience in TechOps, DevOps or software engineering space. \n  2+ years working in managing DevOps infrastructure and deployments. \n  Understanding of core concepts for Public/Private/Hybrid clouds (networking, security, identity access management, etc.). \n  Public/Private Cloud Experience from major providers (such as: AWS / Azure / Google Cloud / VMware or OpenStack). \n  Container Orchestration/Virtualization Experience (such as Docker, Kubernetes, etc.). \n  Varied OS Experience (Windows Server, Linux variants). \n  Understanding of security and networking (ports/protocols), firewalls, load balancers and IPS, container security. \n  CI/CD Tools experience (Git, GitHub, Bitbucket, Terraform, Jenkins, CircleCI, etc.). \n  Experience with database technologies such as MS SQL server, PostgreSQL, or Redis, etc. \n  Strong programming Skills (Interpretive languages such as Python, Perl, or PowerShell and Compiled languages such as C# etc. - Ability to learn new programming languages as needed). \n \n \n  Preferred Qualifications \n \n  3+ years working in managing DevOps infrastructure and deployments. \n \n \n  MS in Computer Science, Electrical Engineering, Mathematics, Statistics, a related field Proven experiences in a public cloud infrastructure such as AWS, Azure or Google Cloud. \n  Experience with change management compliance in the context of SOC 2 certification or SOX. \n  Experience with security compliance in the context of SOC 2 certification or SOX. \n \n \n  #LI-remote \n \n  Regional is an equal opportunity employer and does not discriminate on the basis of race, color, religion, creed, national origin, sex (including pregnancy, childbirth, and related medical conditions), sexual orientation, gender identity, transgender status, age, disability, genetic information, veteran status, uniform service, or any other characteristic protected by applicable law (\u201cProtected Characteristics\u201d). Regional\u2019s policy of non-discrimination applies to all phases of the employment process and relationship, including, but not limited to, recruitment and selection; compensation and benefits; professional development and training; promotions and opportunities; transfers; social and recreational programs; layoff; and terminations.", "cleaned_desc": "  Duties and Responsibilities \n \n  Implement infrastructure as code including automated creation of environments, their settings, and spin down. Designing and building resilient infrastructure and environment automation solutions at scale. \n  Develop the CI/CD environment including timely upgrades to source control systems. \n  Build and maintain the CI/CD pipelines of our custom software using industry standard tools or custom tools. \n  Working with software engineers and quality assurance teams to implement standardized builds and releases (Release engineering including branching, versioning). \n  Work closely with our internal engineering teams to automate manual processes and build/support our continuous integration and continuous delivery code pipelines by leveraging industry standard toolsets and security mindset. \n \n    Minimum Qualifications \n \n  BA/BS in Computer Science, Electrical Engineering, Mathematics, Statistics, a related field, or equivalent. \n  2-5 years of work experience in TechOps, DevOps or software engineering space. \n  2+ years working in managing DevOps infrastructure and deployments. \n  Understanding of core concepts for Public/Private/Hybrid clouds (networking, security, identity access management, etc.). \n  Public/Private Cloud Experience from major providers (such as: AWS / Azure / Google Cloud / VMware or OpenStack). \n  Container Orchestration/Virtualization Experience (such as Docker, Kubernetes, etc.). \n  Varied OS Experience (Windows Server, Linux variants).    Understanding of security and networking (ports/protocols), firewalls, load balancers and IPS, container security. \n  CI/CD Tools experience (Git, GitHub, Bitbucket, Terraform, Jenkins, CircleCI, etc.). \n  Experience with database technologies such as MS SQL server, PostgreSQL, or Redis, etc. \n  Strong programming Skills (Interpretive languages such as Python, Perl, or PowerShell and Compiled languages such as C# etc. - Ability to learn new programming languages as needed). \n \n \n  Preferred Qualifications \n \n  3+ years working in managing DevOps infrastructure and deployments.   \n \n  MS in Computer Science, Electrical Engineering, Mathematics, Statistics, a related field Proven experiences in a public cloud infrastructure such as AWS, Azure or Google Cloud. \n  Experience with change management compliance in the context of SOC 2 certification or SOX. \n  Experience with security compliance in the context of SOC 2 certification or SOX. \n \n \n  #LI-remote \n ", "techs": ["infrastructure as code", "environments", "settings", "spin down", "resilient infrastructure", "environment automation solutions", "ci/cd environment", "source control systems", "ci/cd pipelines", "standardized builds", "releases", "devops infrastructure", "public/private/hybrid clouds", "networking", "security", "identity access management", "aws", "azure", "google cloud", "vmware", "openstack", "container orchestration", "virtualization", "docker", "kubernetes", "os experience", "security", "networking", "firewalls", "load balancers", "ips", "container security", "ci/cd tools", "git", "github", "bitbucket", "terraform", "jenkins", "circleci", "database technologies", "ms sql server", "postgresql", "redis", "programming skills", "python", "perl", "powershell", "c#", "change management compliance", "soc 2 certification", "sox", "security compliance"]}, "metadata": {"keywords": ["data science", "data analyst", "data engineer", "machine learning engineer", "mlops"], "locations": ["remote"], "time_ran": "19:22:21-19-10-23", "num_jobs": 341, "timings": {"start_drivers": 45.4499671459198, "find_job_ids": 418.67814207077026, "get_job_descs": 143.6414349079132}, "models": {"classifier": {"clf": "data/classifier_models/job_desc_classifier_v1.0.pkl", "tfidf": "data/classifier_models/job_desc_tfidf_vectorizer_v1.0.pkl"}, "NER": "gpt-3.5-turbo"}}}