{
    "0df54db4f5309bf4": {
        "terms": [
            "data science"
        ],
        "salary_min": 130000.0,
        "salary_max": -1.0,
        "title": "Data Scientist",
        "company": "Spring Oaks Capital, LLC",
        "desc": "About Spring Oaks \n Spring Oaks Capital is a national financial technology company, focused on the acquisition of credit portfolios. The Company subscribes to an employee and consumer-centric operating philosophy that creates high-value jobs, a significant performance lift, and the highest standards of compliance. Spring Oaks\u2019 business strategy is rooted in innovative data-driven technology to maximize collection results and a contact platform that offers multi-channel options to meet each consumer\u2019s communication preference. Spring Oaks has the management vision and experience to nurture a culture and DNA that is unique in the space. The executive team maintains deep experience end-to-end across the consumer finance lifecycle with some of the largest global banks and innovative FinTech platforms. To learn more about Spring Oaks and our revolutionary FinTech platform, please visit www.springoakscapital.com. \n Position Description \n Data and machine learning fuel our business, therefore we invest in highly scalable, flexible data infrastructure and machine learning in all critical aspects of our business. We are looking for a Data Scientist that will expand and maintain the machine learning pipelines that are crucial to optimizing the customer experience and outcomes across our entire value-chain. The Data Scientist will work closely with our product and data engineering teams to develop and deploy innovative machine learning products using a highly iterative, experiment-based approach. \n Responsibilities \n \n Build and implement prototype and production models \n Measure and monitor model performance/iterate on modeling strategies to improve performance \n Rapidly develop data collection, tagging, and workflow instrumentation strategies \n Support the operations team \n Contribute to the development and well-being of the team \n \n What We\u2019re Looking For \n \n Bachelor\u2019s degree or higher in Computer Science, Data Science, Statistics, Physics, or related fields \n 3+ years\u2019 machine learning experience \n Expertise in Python and Pandas \n Experience with scikit-learn, TensorFlow, PyTorch, or similar \n 3+ years\u2019 experience in SQL and No-SQL databases \n Strong communication skills \n Self-motivated, creative, and proactive \n \n Nice To Have \n \n Advanced degree in Computer Science, Statistics, Physics, or related fields \n Knowledge of AWS or comparable cloud service provider \n Experience working with optimization software such as Google OR Tools \n Experience with Airflow, Spark, Kafka, or similar \n Experience working in fintech or financial services \n \n Important Note \n While we\u2019ve described what we\u2019re generally looking for, we are probably missing skills or attributes that would make you a great fit. We know that some people won\u2019t apply for jobs unless they meet every qualification. Don\u2019t let the lack of a few qualifications stop you because we look past checklists to hire the best people. \n Equal Employment Opportunity \n Spring Oaks Capital is proud to be an equal opportunity workplace. All qualified applicants will receive consideration for employment without regard to age, sex, ancestry, race, religion, gender identity, genetic information, marital status, national origin, disability, protected veteran status, sexual orientation, or any other characteristic protected by applicable laws, regulations, and ordinances. \n Job Type: Full-time \n Pay: From $130,000.00 per year \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Employee assistance program \n Flexible spending account \n Health insurance \n Health savings account \n Life insurance \n Paid time off \n Parental leave \n Vision insurance \n \n Compensation package: \n \n Weekly pay \n \n Experience level: \n \n 3 years \n \n Work Location: Remote",
        "cleaned_desc": " \n What We\u2019re Looking For \n \n Bachelor\u2019s degree or higher in Computer Science, Data Science, Statistics, Physics, or related fields \n 3+ years\u2019 machine learning experience \n Expertise in Python and Pandas \n Experience with scikit-learn, TensorFlow, PyTorch, or similar \n 3+ years\u2019 experience in SQL and No-SQL databases \n Strong communication skills \n Self-motivated, creative, and proactive \n ",
        "techs": [
            "python",
            "pandas",
            "scikit-learn",
            "tensorflow",
            "pytorch",
            "sql",
            "no-sql"
        ],
        "cleaned_techs": [
            "python",
            "pandas",
            "scikit-learn",
            "tensorflow",
            "pytorch",
            "sql",
            "no-sql"
        ]
    },
    "56e32fe81b8ef863": {
        "terms": [
            "data science"
        ],
        "salary_min": 88000.0,
        "salary_max": 136000.0,
        "title": "Data Scientist",
        "company": "Nationwide IT Services, Inc",
        "desc": "Data Scientist   DMV (Remote)     Position Overview:  Nationwide IT Services (NIS) is seeking an experienced Data Scientist in support of a Federal Agency focused on providing expert leadership and guidance under the contract. It is expected that this key personnel position shall be responsible for leading the overall development of date models and algorithms to support machine learning.     Responsibilities:   The data scientist shall provide expert leadership and guidance in performance under this contract.  Responsible for leading the overall development of data models and algorithms to support machine learning.     Required Certifications:   Five (5) years of experience as a Data Scientist leading data science efforts.  Bachelor of Science in Computer Science, Engineering, Mathematics, or related subject     About Nationwide IT Services  NIS is an IT and Management consulting company, designated 8(a) by the SBA, and a CVE-verified Service Disabled Veteran Owned Small Business. Our mission is to deliver value-added services to our customers, leveraging technology, people, and industry best practices to implement innovative solutions through our trusted employees and team members.    Our benefits package includes medical, dental, and vision insurance, life and disability insurance, 401(k) plan with employer match, paid holidays, PTO (sick/vacation), commuter benefits, employee assistance program (EAP) and educational reimbursement along with Pet Insurance.     Nationwide IT Services, Inc. provides equal employment opportunities (EEO) to all qualified applicants for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, genetics, disability or protected veteran status.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "915fae227e0ccc6a": {
        "terms": [
            "data science"
        ],
        "salary_min": 85000.0,
        "salary_max": 167300.0,
        "title": "Manager Data Science - Remote",
        "company": "UnitedHealthcare",
        "desc": "At UnitedHealthcare, we\u2019re simplifying the health care experience, creating healthier communities and removing barriers to quality care. The work you do here impacts the lives of millions of people for the better. Come build the health care system of tomorrow, making it more responsive, affordable and equitable. Ready to make a difference? Join us to start  Caring. Connecting. Growing together. \n \n \n \n The BASIS (Business-Analytics-Sciences-Insights-Strategies) organization of UnitedHealthcare delivers end to end analytics and business insights solutions to support all aspects of UHC Core Operations to drive operational efficiency and member and provider NPS improvement. We deliver these business values through data enablement, business and actionable insight-driven reporting, innovative AI/ML advanced analytics and transformative automation solutions. \n  As the Manager, Data Analytics & Science, you will be both a SME and a lead data analyst/scientist/manager and will provide advanced analytic leadership to support Core Operation. You'll work closely with business leaders to develop innovative reporting & analytic solutions, create actionable insights, and drive better decisions and performance to help Core Operation fulfill its mission. \n \n \n \n You\u2019ll enjoy the flexibility to work remotely * from anywhere within the U.S. as you take on some tough challenges. \n \n \n \n   \n \n \n Primary Responsibilities: \n \n \n \n In conjunction with the director, take lead on reporting, analytics and data science projects to develop and execute on critical business goals \n Lead the design /development /programming /maintenance and production of operational reports /dashboards. Provide operational analysis utilized for decision making and make recommendations to Sr. Leadership to support key initiatives \n Develop data analytic solutions to support analyses, including management and manipulation of data, partnering with stakeholders to understand data requirements, and developing algorithms, coding, queries, tools, and analytic models \n Develop innovation solutions and machine learning advanced analytics. Work alongside other data scientists and analysts to design and implement models and experiments from end to end, including data ingestion and preparation, feature engineering, simulation, analysis and machine learning modeling to provide predictive and prescriptive analytics to stakeholders \n Serves as a leader /mentor to other analysts to drive the application of advanced analytics to business solution \n Develop visionary and creative analytic solutions to measure business performance; identifies / quantifies drivers, risks and opportunities and defines solutions to mitigate risks and leverage opportunities \n Influences senior leadership to adopt new ideas, projects and / or approaches \n \n \n \n  Competencies: \n \n Self-starter with an engaging leadership style, solid influencing and facilitation skills that will quickly develop relationships across the organization while building a collaborative work environment \n Analytic thought leadership with skills in developing innovative and creative analytic solutions to complex problem \n Solid business acumen and critical thinking ability \n Executive presence and presentation skill - ability to \u201ctell a compelling story\u201d in a concise and effective manner to non-financial executives \n Solid problem solving skills with the ability to anticipate, identify and diagnose problems and make recommendations \n Candidate must be goal-directed, persistent and driven to achieve positive results. Is positive influence on others and deals well with set-backs. Identifies integration issues, removes barriers and tracks project status in order to obtain desired results \n Detail orientation - getting \"into the trenches\" to evaluate all aspects of operations. Pivotal to success will be the ability to take a hands-on approach to getting the information needed and driving effective and lasting change \n A people leader with solid ability to develop relationships/influence across functional teams that work across multiple business units \n Serve as a solid coach and will foster career development of team members \n \n \n \n \n \n \n \n You\u2019ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in. \n \n \n Required Qualifications: \n \n \n \n 5+ years of experience with relational database such as SQL Server/Oracle/Teradata/IBM DB2/MySQL \n 3+ years of experience within a Data Science environment with demonstrated experience with big data tools and platforms (SAS, R, Python, Spark, Databricks, Hadoop, Hive, etc.) \n 3+ years of experience applying computational algorithms, statistical and programming methods to structured and unstructured data \n 2+ years: MS Public Cloud, Azure Data Factory, Data Bricks, SPARK \n 2+ years of experience leading a team \n 2+ years of experience with agile /SCRUM methodology \n \n \n \n  Preferred Qualifications:   \n \n Experience with cognitive computing with Google Cloud AI or Microsoft Azure Cognitive Services \n Experience with ETL or software development \n Managed care/health insurance industry experience in government programs, and/or finance \n \n \n \n \n \n California, Colorado, Connecticut, Nevada, New Jersey, New York, Rhode Island, or Washington Residents Only:  The salary range for California, Colorado, Connecticut, Nevada, New Jersey, New York, Rhode Island or Washington residents is $85,000 to $167,300 per year. Pay is based on several factors including but not limited to education, work experience, certifications, etc. In addition to your salary, UnitedHealth Group offers benefits such as, a comprehensive benefits package, incentive and recognition programs, equity stock purchase and 401k contribution (all benefits are subject to eligibility requirements). No matter where or when you begin a career with UnitedHealth Group, you\u2019ll find a far-reaching choice of benefits and incentives.\n   \n \n \n \n   \n \n \n \n All employees working remotely will be required to adhere to UnitedHealth Group\u2019s Telecommuter Policy \n \n \n \n \n At UnitedHealth Group, our mission is to help people live healthier lives and make the health system work better for everyone. We believe everyone\u2013of every race, gender, sexuality, age,  location  and income\u2013deserves the opportunity to live their healthiest life. Today, however, there are still far too many barriers to good health which are disproportionately experienced by people of color, historically marginalized  groups  and those with lower incomes. We are committed to mitigating our impact on the environment and enabling and delivering  equitable  care that addresses health disparities and improves health outcomes \u2014 an enterprise priority reflected in our mission . \n \n \n \n \n \n \n \n Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action  employer  and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law . \n \n \n \n   \n \n \n UnitedHealth Group is a  drug -  free workplace. Candidates  are required to  pass a drug test before beginning employment .",
        "cleaned_desc": " In conjunction with the director, take lead on reporting, analytics and data science projects to develop and execute on critical business goals \n Lead the design /development /programming /maintenance and production of operational reports /dashboards. Provide operational analysis utilized for decision making and make recommendations to Sr. Leadership to support key initiatives \n Develop data analytic solutions to support analyses, including management and manipulation of data, partnering with stakeholders to understand data requirements, and developing algorithms, coding, queries, tools, and analytic models \n Develop innovation solutions and machine learning advanced analytics. Work alongside other data scientists and analysts to design and implement models and experiments from end to end, including data ingestion and preparation, feature engineering, simulation, analysis and machine learning modeling to provide predictive and prescriptive analytics to stakeholders \n Serves as a leader /mentor to other analysts to drive the application of advanced analytics to business solution \n Develop visionary and creative analytic solutions to measure business performance; identifies / quantifies drivers, risks and opportunities and defines solutions to mitigate risks and leverage opportunities \n Influences senior leadership to adopt new ideas, projects and / or approaches \n \n \n \n  Competencies: \n \n Self-starter with an engaging leadership style, solid influencing and facilitation skills that will quickly develop relationships across the organization while building a collaborative work environment \n Analytic thought leadership with skills in developing innovative and creative analytic solutions to complex problem \n Solid business acumen and critical thinking ability \n Executive presence and presentation skill - ability to \u201ctell a compelling story\u201d in a concise and effective manner to non-financial executives \n Solid problem solving skills with the ability to anticipate, identify and diagnose problems and make recommendations \n Candidate must be goal-directed, persistent and driven to achieve positive results. Is positive influence on others and deals well with set-backs. Identifies integration issues, removes barriers and tracks project status in order to obtain desired results \n Detail orientation - getting \"into the trenches\" to evaluate all aspects of operations. Pivotal to success will be the ability to take a hands-on approach to getting the information needed and driving effective and lasting change \n A people leader with solid ability to develop relationships/influence across functional teams that work across multiple business units   Serve as a solid coach and will foster career development of team members \n \n \n \n \n \n \n \n You\u2019ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in. \n \n \n Required Qualifications: \n \n \n \n 5+ years of experience with relational database such as SQL Server/Oracle/Teradata/IBM DB2/MySQL \n 3+ years of experience within a Data Science environment with demonstrated experience with big data tools and platforms (SAS, R, Python, Spark, Databricks, Hadoop, Hive, etc.) \n 3+ years of experience applying computational algorithms, statistical and programming methods to structured and unstructured data \n 2+ years: MS Public Cloud, Azure Data Factory, Data Bricks, SPARK \n 2+ years of experience leading a team ",
        "techs": [
            "sql server",
            "oracle",
            "teradata",
            "ibm db2",
            "mysql",
            "sas",
            "r",
            "python",
            "spark",
            "databricks",
            "hadoop",
            "hive",
            "ms public cloud",
            "azure data factory",
            "data bricks"
        ],
        "cleaned_techs": [
            "sql",
            "oracle",
            "teradata",
            "ibm db2",
            "mysql",
            "sas",
            "r",
            "python",
            "spark",
            "databricks",
            "hadoop",
            "hive",
            "ms public cloud",
            "azure",
            "data bricks"
        ]
    },
    "69e35973457c61a8": {
        "terms": [
            "data science"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Director Data Engineering",
        "company": "Providence",
        "desc": "Description \n This position is remote with some in person meetings required and can only be located in the states of WA, OR, or CA. \n Leads highly technical data engineers. Accountable for all aspects of the technical design and build of modern data-centric solutions and applications to support clinical and operational processes across all parts of the enterprise health system. These solutions leverage cloud, big data, data science, and modern software development methodologies (such as SAFe) and tools and services (such as Snowflake and Databricks in Azure). Responsible for the buildout of our data engineering center of excellence for the enterprise and a community of practice across teams. Collaborates on technical solutions with teams at the Providence Global Center at Hyderabad, India. \n Providence caregivers are not simply valued \u2013 they\u2019re invaluable. Join our team at Enterprise Information Services and thrive in our culture of patient-focused, whole-person care built on understanding, commitment, and mutual respect. Your voice matters here, because we know that to inspire and retain the best people, we must empower them. \n Required Qualifications: \n \n Bachelor's Degree - Computer Engineering, Computer Science, Mathematics, Engineering. Or equivalent educ/experience, \n 10 or more years - Related experience in engineering or development roles. \n 8 years Leadership experience leading teams in a complex and fast-paced moving environment. \n Experience in cloud computing and data warehousing, Linux, Hadoop, Spark, and other NoSQL platforms. \n Strong experience working with both the product and technical sides of issues. \n Practical solutions development experience in a data-centric domain. \n Strong experience in managing and coaching a team of technical resources. \n \n Preferred Qualifications: \n \n Bachelor's Degree in Computer Science and Engineering, Mathematics, Engineering and related technical fields. \n \n The salary range listed for this position MIN:$79.20 to MAX:$131.66 per hour is based upon the primary work location Renton, WA posted. This position is remote. Salary range and offers are determined by internal pay equity and geographic cost of living differences. Salary range will vary from State and region. Salary max is limited to 75% range in order to continue to offer internal pay growth. We welcome open and transparent discussions on salary at Providence. \n Why Join Providence? \n Our best-in-class benefits are uniquely designed to support you and your family in staying well, growing professionally, and achieving financial security. We take care of you, so you can focus on delivering our Mission of caring for everyone, especially the most vulnerable in our communities. \n About Providence \n At Providence, our strength lies in Our Promise of \u201cKnow me, care for me, ease my way.\u201d Working at our family of organizations means that regardless of your role, we\u2019ll walk alongside you in your career, supporting you so you can support others. We provide best-in-class benefits and we foster an inclusive workplace where diversity is valued, and everyone is essential, heard and respected. Together, our 120,000 caregivers (all employees) serve in over 50 hospitals, over 1,000 clinics and a full range of health and social services across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. As a comprehensive health care organization, we are serving more people, advancing best practices and continuing our more than 100-year tradition of serving the poor and vulnerable. \n The amounts listed are the base pay range; additional compensation may be available for this role, such as shift differentials, standby/on-call, overtime, premiums, extra shift incentives, or bonus opportunities. \n Check out our benefits page for more information about our Benefits and Rewards. \n About the Team \n Providence Shared Services is a service line within Providence that provides a variety of functional and system support services for our family of organizations across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. We are focused on supporting our Mission by delivering a robust foundation of services and sharing of specialized expertise. \n We are committed to the principle that every workforce member has the right to work in surroundings that are free from all forms of unlawful discrimination and harassment. \n We are committed to cultural diversity and equal employment for all individuals. It is our policy to recruit, hire, promote, compensate, transfer, train, retain, terminate, and make all other employment-related decisions without regard to race, color, religious creed (including religious dress and grooming practices), national origin (including certain language use restrictions), ancestry, disability (mental and physical including HIV and AIDS), medical condition (including cancer and genetic characteristics), genetic information, marital status, age, sex (which includes pregnancy, childbirth, breastfeeding and related medical conditions), gender, gender identity, gender expression, sexual orientation, genetic information, and military and veteran status or any other applicable legally protected status. We will also provide reasonable accommodation to known physical or mental limitations of an otherwise qualified caregiver or applicant for employment, unless the accommodation would impose undue hardship on the operation of our business. \n We are a community where all people, regardless of differences, are welcome, secure, and valued. We value respect, appreciation, collaboration, diversity, and a shared commitment to serving our communities. We expect that all workforce members in our community will act in ways which reflect a commitment to and accountability for, racial and social justice and equality in the workplace. As such, we will maintain a workplace free of discrimination and harassment based on any applicable legally protected status. We also expect that all workforce members will maintain a positive workplace free from any unacceptable conduct which creates an intimidating, hostile, or offensive work environment. \n Requsition ID:  226882  \n Company:  Providence Jobs  \n Job Category:  Development/Engineering  \n Job Function:  Information Technology  \n Job Schedule:  Full time  \n Job Shift:  Day  \n Career Track:  Leadership  \n Department:  4011 SS IS HI DP 3  \n Address:  WA Renton 1801 Lind Ave SW  \n Work Location:  Providence Valley Office Park-Renton  \n Pay Range:  $79.20 - $131.66  \n The amounts listed are the base pay range; additional compensation may be available for this role, such as shift differentials, standby/on-call, overtime, premiums, extra shift incentives, or bonus opportunities.  \n Check out our benefits page for more information about our Benefits and Rewards. \n Providence is proud to be an Equal Opportunity Employer. Providence does not discriminate on the basis of race, color, gender, disability, veteran, military status, religion, age, creed, national origin, sexual identity or expression, sexual orientation, marital status, genetic information, or any other basis prohibited by local, state, or federal law.",
        "cleaned_desc": " 8 years Leadership experience leading teams in a complex and fast-paced moving environment. \n Experience in cloud computing and data warehousing, Linux, Hadoop, Spark, and other NoSQL platforms. \n Strong experience working with both the product and technical sides of issues. \n Practical solutions development experience in a data-centric domain. \n Strong experience in managing and coaching a team of technical resources. \n \n Preferred Qualifications: \n ",
        "techs": [
            "cloud computing",
            "data warehousing",
            "linux",
            "hadoop",
            "spark",
            "nosql platforms"
        ],
        "cleaned_techs": [
            "cloud computing",
            "data warehousing",
            "linux",
            "hadoop",
            "spark",
            "nosql"
        ]
    },
    "708d0c653991e781": {
        "terms": [
            "data science"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Director Data Engineering",
        "company": "Providence",
        "desc": "Description \n This position is remote with some in person meetings required and can only be located in the states of WA, OR, or CA. \n Leads highly technical data engineers. Accountable for all aspects of the technical design and build of modern data-centric solutions and applications to support clinical and operational processes across all parts of the enterprise health system. These solutions leverage cloud, big data, data science, and modern software development methodologies (such as SAFe) and tools and services (such as Snowflake and Databricks in Azure). Responsible for the buildout of our data engineering center of excellence for the enterprise and a community of practice across teams. Collaborates on technical solutions with teams at the Providence Global Center at Hyderabad, India. \n Providence caregivers are not simply valued \u2013 they\u2019re invaluable. Join our team at Enterprise Information Services and thrive in our culture of patient-focused, whole-person care built on understanding, commitment, and mutual respect. Your voice matters here, because we know that to inspire and retain the best people, we must empower them. \n Required Qualifications: \n \n Bachelor's Degree - Computer Engineering, Computer Science, Mathematics, Engineering. Or equivalent educ/experience, \n 10 or more years - Related experience in engineering or development roles. \n 8 years Leadership experience leading teams in a complex and fast-paced moving environment. \n Experience in cloud computing and data warehousing, Linux, Hadoop, Spark, and other NoSQL platforms. \n Strong experience working with both the product and technical sides of issues. \n Practical solutions development experience in a data-centric domain. \n Strong experience in managing and coaching a team of technical resources. \n \n Preferred Qualifications: \n \n Bachelor's Degree in Computer Science and Engineering, Mathematics, Engineering and related technical fields. \n \n The salary range listed for this position MIN:$79.20 to MAX:$131.66 per hour is based upon the primary work location Renton, WA posted. This position is remote. Salary range and offers are determined by internal pay equity and geographic cost of living differences. Salary range will vary from State and region. Salary max is limited to 75% range in order to continue to offer internal pay growth. We welcome open and transparent discussions on salary at Providence. \n Why Join Providence? \n Our best-in-class benefits are uniquely designed to support you and your family in staying well, growing professionally, and achieving financial security. We take care of you, so you can focus on delivering our Mission of caring for everyone, especially the most vulnerable in our communities. \n About Providence \n At Providence, our strength lies in Our Promise of \u201cKnow me, care for me, ease my way.\u201d Working at our family of organizations means that regardless of your role, we\u2019ll walk alongside you in your career, supporting you so you can support others. We provide best-in-class benefits and we foster an inclusive workplace where diversity is valued, and everyone is essential, heard and respected. Together, our 120,000 caregivers (all employees) serve in over 50 hospitals, over 1,000 clinics and a full range of health and social services across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. As a comprehensive health care organization, we are serving more people, advancing best practices and continuing our more than 100-year tradition of serving the poor and vulnerable. \n The amounts listed are the base pay range; additional compensation may be available for this role, such as shift differentials, standby/on-call, overtime, premiums, extra shift incentives, or bonus opportunities. \n Check out our benefits page for more information about our Benefits and Rewards. \n About the Team \n Providence Shared Services is a service line within Providence that provides a variety of functional and system support services for our family of organizations across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. We are focused on supporting our Mission by delivering a robust foundation of services and sharing of specialized expertise. \n We are committed to the principle that every workforce member has the right to work in surroundings that are free from all forms of unlawful discrimination and harassment. \n We are committed to cultural diversity and equal employment for all individuals. It is our policy to recruit, hire, promote, compensate, transfer, train, retain, terminate, and make all other employment-related decisions without regard to race, color, religious creed (including religious dress and grooming practices), national origin (including certain language use restrictions), ancestry, disability (mental and physical including HIV and AIDS), medical condition (including cancer and genetic characteristics), genetic information, marital status, age, sex (which includes pregnancy, childbirth, breastfeeding and related medical conditions), gender, gender identity, gender expression, sexual orientation, genetic information, and military and veteran status or any other applicable legally protected status. We will also provide reasonable accommodation to known physical or mental limitations of an otherwise qualified caregiver or applicant for employment, unless the accommodation would impose undue hardship on the operation of our business. \n We are a community where all people, regardless of differences, are welcome, secure, and valued. We value respect, appreciation, collaboration, diversity, and a shared commitment to serving our communities. We expect that all workforce members in our community will act in ways which reflect a commitment to and accountability for, racial and social justice and equality in the workplace. As such, we will maintain a workplace free of discrimination and harassment based on any applicable legally protected status. We also expect that all workforce members will maintain a positive workplace free from any unacceptable conduct which creates an intimidating, hostile, or offensive work environment. \n Requsition ID:  226882  \n Company:  Providence Jobs  \n Job Category:  Development/Engineering  \n Job Function:  Information Technology  \n Job Schedule:  Full time  \n Job Shift:  Day  \n Career Track:  Leadership  \n Department:  4011 SS IS HI DP 3  \n Address:  WA Renton 1801 Lind Ave SW  \n Work Location:  Providence Valley Office Park-Renton  \n Pay Range:  $79.20 - $131.66  \n The amounts listed are the base pay range; additional compensation may be available for this role, such as shift differentials, standby/on-call, overtime, premiums, extra shift incentives, or bonus opportunities.  \n Check out our benefits page for more information about our Benefits and Rewards. \n Providence is proud to be an Equal Opportunity Employer. Providence does not discriminate on the basis of race, color, gender, disability, veteran, military status, religion, age, creed, national origin, sexual identity or expression, sexual orientation, marital status, genetic information, or any other basis prohibited by local, state, or federal law.",
        "cleaned_desc": " 8 years Leadership experience leading teams in a complex and fast-paced moving environment. \n Experience in cloud computing and data warehousing, Linux, Hadoop, Spark, and other NoSQL platforms. \n Strong experience working with both the product and technical sides of issues. \n Practical solutions development experience in a data-centric domain. \n Strong experience in managing and coaching a team of technical resources. \n \n Preferred Qualifications: \n ",
        "techs": [
            "cloud computing",
            "data warehousing",
            "linux",
            "hadoop",
            "spark",
            "nosql platforms"
        ],
        "cleaned_techs": [
            "cloud computing",
            "data warehousing",
            "linux",
            "hadoop",
            "spark",
            "nosql"
        ]
    },
    "54d1218cacaebf3c": {
        "terms": [
            "data science"
        ],
        "salary_min": 5000.0,
        "salary_max": -1.0,
        "title": "Data Scientist",
        "company": "L3A Protocol",
        "desc": "Job Description: \n We're seeking a skilled Data Scientist to join our team, collaborating with experts to maximize data's potential for informed decision-making. You'll be a pivotal data science team member, driving data-centric solutions that propel growth and enhance decision-making. This role involves leveraging your expertise in data products and utilizing tools such as Dune Analytics, TradingView, and The Graph. \n Key Responsibilities: \n \n Collaborate cross-functionally to identify and tackle data-driven opportunities and challenges. \n Develop data products and analytical solutions, extracting actionable insights. \n Construct and maintain data pipelines and ETL processes. \n Harness the power of Dune Analytics, TradingView, and The Graph for data extraction and analysis. \n Tackle data cleansing, data wrangling, and statistical analysis. \n Create predictive models to advance business objectives. \n Craft data visualizations and reports for clear, non-technical stakeholder communication. \n Stay current with industry trends and data science best practices. \n \n Qualifications: \n \n Bachelor's or Master's degree in Data Science, Computer Science, Statistics, or a related field. \n Proven experience in Data Science or a similar role. \n Proficiency in data analysis tools like Dune Analytics, TradingView, and The Graph. \n Strong programming skills in Python, R, or SQL. \n Familiarity with data visualization tools (e.g., Tableau, Power BI). \n Solid knowledge of machine learning, statistical analysis, and data modeling. \n Strong problem-solving skills, both independently and collaboratively. \n Exceptional communication skills to convey complex data findings to non-technical stakeholders. \n \n Job Type: Full-time \n Salary: From $5,000.00 per month \n Experience: \n \n Data science: 2 years (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": " Construct and maintain data pipelines and ETL processes. \n Harness the power of Dune Analytics, TradingView, and The Graph for data extraction and analysis. \n Tackle data cleansing, data wrangling, and statistical analysis. \n Create predictive models to advance business objectives. \n Craft data visualizations and reports for clear, non-technical stakeholder communication. \n Stay current with industry trends and data science best practices.   Strong programming skills in Python, R, or SQL. \n Familiarity with data visualization tools (e.g., Tableau, Power BI). \n Solid knowledge of machine learning, statistical analysis, and data modeling. \n Strong problem-solving skills, both independently and collaboratively. \n Exceptional communication skills to convey complex data findings to non-technical stakeholders. \n ",
        "techs": [
            "dune analytics",
            "tradingview",
            "the graph",
            "python",
            "r",
            "sql",
            "tableau",
            "power bi"
        ],
        "cleaned_techs": [
            "dune analytics",
            "tradingview",
            "the graph",
            "python",
            "r",
            "sql",
            "tableau",
            "powerbi"
        ]
    },
    "b8619d587c714e2d": {
        "terms": [
            "data science"
        ],
        "salary_min": 28.67,
        "salary_max": 65.0,
        "title": "Data Scientist",
        "company": "IT Engagements,Inc.",
        "desc": "Greetings from IT Engagements\u2026! \n IT Engagements is a global staff augmentation firm providing a wide-range of talent on-demand and total workforce solutions. We have an immediate opening for the below position with one of our premium clients \n Role:- Data Scientist \n Location: Remote \n USC, GC and EADs only  \n he Data Scientist and data visualization specialist is responsible for creating dashboards and reporting solutions to measure the effectiveness of implementations. They will also work with Natural Language Processing and use data science tools and techniques. Extract, merge, clean, and normalize large-scale data from disparate sources in preparation for exploratory data analysis, model building, and validation within a big data environment. Develop and validate machine learning (ML classifications and regression models using Python or similar tools to answer business needs and positively impact business operations. Prepare data visualizations and presentations to highlight findings and recommendations for both a technical and executive audience. Experience with Databricks to analyze usage data, and create dashboards and reports. \n Job Function: \n \n Parse and automate the analysis of large volumes of unstructured data to generate useful business metrics that measure the performance \n \n Extract, merge, clean, and normalize large-scale data from disparate sources in preparation for exploratory data analysis, model building, and validation within a big-data environment \n \n Create informative data visualizations to articulate findings \n Conduct regression analysis to identify relationships between data elements \n Develop and maintain a thorough working knowledge of the data model \n Support the operational teams during development, testing, implementation, and production \n Follow Information Technology department processes and implement change requirements as part of a structured change control process \n Ensure the quality of coded components \n Design and enforce coding standards, policies, and procedures \n Create and maintain solution documentation \n Consult with partners to provide functional and technical expertise in areas including solution, design, development, testing, and risk identification/mitigation \n Create and document test procedures and scenarios \n Collaborate with other automation developers and IT practitioners \n \n Skills and requirements: \n \n Experience with Python, SQL, and relational data models is required \n Extensive knowledge of data warehousing and data lake concepts and hands-on experience deploying pipelines using Databricks \n Use Databricks to analyze usage data, and create dashboards and reports \n Experience designing architectures within a public cloud (AWS or Azure) \n Hands-on experience with Big Data technologies, including Spark, Hadoop, Cassandra, and others \n Experience with Typescript/NodeJS is a plus \n Experience with Tableau is a plus \n Ability to demonstrate successful delivery and support of configuration/scripting technology \n Understanding of workflow-based logic and the ability to understand a business process from a workflow diagram and to conceptualize it as an automated solution \n Willingness and ability to blend business analysis with hands-on configuration of automated processes \n The ability to learn quickly and progress rapidly from theoretical exercises to real-world delivery  Good communication skills with the ability to present technical details to a non-technical audience; both written and verbal \n Good written skills with the ability to produce clear and concise documentation \n An aptitude for analysis, evaluation, and problem-solving, with the ability to take a logical route to the source of an error \n A self-starter who delivers high-quality work and can adapt to new challenges, either on their own or as part of a team \n \n Thanks and Regards \n Shashank Jaitly \n Sr. Technical Recruiter \n IT Engagements, Inc. \n Shashank@itengagements.com \n Job Type: Contract \n Pay: $28.67 - $65.00 per hour \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Experience: \n \n Data science: 8 years (Preferred) \n Python: 4 years (Preferred) \n data warehousing and data lake: 6 years (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": "Greetings from IT Engagements\u2026! \n IT Engagements is a global staff augmentation firm providing a wide-range of talent on-demand and total workforce solutions. We have an immediate opening for the below position with one of our premium clients \n Role:- Data Scientist \n Location: Remote \n USC, GC and EADs only  \n he Data Scientist and data visualization specialist is responsible for creating dashboards and reporting solutions to measure the effectiveness of implementations. They will also work with Natural Language Processing and use data science tools and techniques. Extract, merge, clean, and normalize large-scale data from disparate sources in preparation for exploratory data analysis, model building, and validation within a big data environment. Develop and validate machine learning (ML classifications and regression models using Python or similar tools to answer business needs and positively impact business operations. Prepare data visualizations and presentations to highlight findings and recommendations for both a technical and executive audience. Experience with Databricks to analyze usage data, and create dashboards and reports. \n Job Function: \n \n Parse and automate the analysis of large volumes of unstructured data to generate useful business metrics that measure the performance \n \n Extract, merge, clean, and normalize large-scale data from disparate sources in preparation for exploratory data analysis, model building, and validation within a big-data environment   Collaborate with other automation developers and IT practitioners \n \n Skills and requirements: \n \n Experience with Python, SQL, and relational data models is required \n Extensive knowledge of data warehousing and data lake concepts and hands-on experience deploying pipelines using Databricks \n Use Databricks to analyze usage data, and create dashboards and reports \n Experience designing architectures within a public cloud (AWS or Azure) \n Hands-on experience with Big Data technologies, including Spark, Hadoop, Cassandra, and others \n Experience with Typescript/NodeJS is a plus \n Experience with Tableau is a plus   Ability to demonstrate successful delivery and support of configuration/scripting technology \n Understanding of workflow-based logic and the ability to understand a business process from a workflow diagram and to conceptualize it as an automated solution \n Willingness and ability to blend business analysis with hands-on configuration of automated processes \n The ability to learn quickly and progress rapidly from theoretical exercises to real-world delivery  Good communication skills with the ability to present technical details to a non-technical audience; both written and verbal \n Good written skills with the ability to produce clear and concise documentation \n An aptitude for analysis, evaluation, and problem-solving, with the ability to take a logical route to the source of an error \n A self-starter who delivers high-quality work and can adapt to new challenges, either on their own or as part of a team \n \n Thanks and Regards \n Shashank Jaitly \n Sr. Technical Recruiter ",
        "techs": [
            "python",
            "sql",
            "databricks",
            "aws",
            "azure",
            "spark",
            "hadoop",
            "cassandra",
            "typescript/nodejs",
            "tableau"
        ],
        "cleaned_techs": [
            "python",
            "sql",
            "databricks",
            "aws",
            "azure",
            "spark",
            "hadoop",
            "cassandra",
            "typescript/nodejs",
            "tableau"
        ]
    },
    "d1c758b3be3c3a77": {
        "terms": [
            "data science"
        ],
        "salary_min": 227500.0,
        "salary_max": 292500.0,
        "title": "Director, Data Science and Analytics",
        "company": "Circle",
        "desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  Circle is looking for a Director, Data Science & Analytics to work closely with the Business, Product, and Engineering to produce analysis, deep research, and scalable data practices. This role has the opportunity to significantly impact internal data consumption and decision making. We are a passionate team with a deeply analytical approach, and your work will support us in our mission to be a world-class company driven by data. \n  What you'll work on: \n \n Build road maps, prioritize and drive data science and analytics efforts, communicate cross-functionally, and be a domain expert \n Support the individual and career growth of team members to minimize attrition and enhance output \n Partner with product and operations teams to identify and resolve analytical problems at scale in a variety of domains, including crypto ecosystem understanding, developers, accounting and financial processes, fraud detection, and risk management \n Help your team ideate and complete the right analysis, models, and stories \n Become an expert on data sources and flows at Circle \n Evangelize the power of data science to understand and improve our business and operations. \n \n You will aspire to our four core values: \n \n Multistakeholder -  you have dedication and commitment to our customers, shareholders, employees and families and local communities. \n Mindful -  you seek to be respectful, an active listener and to pay attention to detail. \n Driven by Excellence -  you are driven by our mission and our passion for customer success which means you relentlessly pursue excellence, that you do not tolerate mediocrity and you work intensely to achieve your goals. \n High Integrity -  you seek open and honest communication, and you hold yourself to very high moral and ethical standards. You reject manipulation, dishonesty and intolerance. \n \n What you'll bring to Circle: \n \n 12+ years of industry experience working with and analyzing large data sets \n 5+ years of experience with technical leadership and people management \n Knowledge of a scientific computing language (Python) and SQL \n Theoretical and applied expertise in statistics, experimental design, and analysis \n Experience building reporting systems and dashboards \n Strong communicator who can take complex ideas and methodologies, and simplify them for non-technical audiences \n Ability to understand complex business problems and break down analytics projects into a structured approach \n Track record of managing data scientists and analysts, both individual contributors and managers \n Experience managing remote teams \n \n Additional Information: \n \n This position is eligible for day-one PERM sponsorship for qualified candidates. \n \n Circle is on a mission to create an inclusive financial future, with transparency at our core. We consider a wide variety of elements when crafting our compensation ranges and total compensation packages. \n  Starting pay is determined by various factors, including but not limited to: relevant experience, skill set, qualifications, and other business and organizational needs. Please note that compensation ranges may differ for candidates in other locations. \n  Base Pay Range: $227,500 - $292,500 \n  Annual Bonus Target: 20% \n  Also Included: Equity & Benefits (including medical, dental, vision and 401(k)). Circle has a discretionary vacation policy. We also provide 10 days of paid sick leave per year and 11 paid holidays per year in the U.S. \n \n  We are an  equal opportunity employer  and value diversity at Circle. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Additionally, Circle participates in the  E-Verify Program  in certain locations, as required by law. \n  #LI-Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "f01005ed07d36be5": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 73100.0,
        "salary_max": 166000.0,
        "title": "Data Scientist, Mid",
        "company": "Booz Allen Hamilton",
        "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Washington,DC,US \n         \n \n \n \n         Remote Work: \n         \n \n         Yes \n         \n \n \n \n         Job Number: \n         \n \n         R0182254\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Data Scientist, Mid\n           The Opportunity: \n  As a data scientist, you\u2019re excited at the prospect of unlocking the secrets held by a data set, and you\u2019re fascinated by the possibilities presented by IoT, machine learning, and artificial intelligence. In an increasingly connected world, massive amounts of structured and unstructured data open new opportunities. As a data scientist at Booz Allen, you can help turn these complex data sets into useful information to solve global challenges. Across private and public sectors\u2014from fraud detection to cancer research to national intelligence\u2014we need you to help find the answers in the data. \n \n  On our team, you\u2019ll use your analytical skills and data science knowledge to create real-world impact. You\u2019ll work closely with your clients to understand their questions and needs, and then dig into their data-rich environments to find the pieces of their information puzzle. You\u2019ll develop algorithms and systems and use the right combination of tools and frameworks to turn sets of disparate data points into objective answers to help clients make informed decisions. Ultimately, you\u2019ll provide a deep understanding of the data, what it all means, and how it can be used. \n \n  Work with us as we use data science for good. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  2+ years of experience with data exploration, data cleaning, data analysis, data visualization, or data mining \n  2+ years of experience with statistical and general-purpose programming languages for data analysis \n  Experience in data analytics, statistical analysis, and machine learning techniques \n  Experience in computer science principles, algorithms, and programming \n  Experience with data manipulation, cleaning, and transformation \n  Knowledge of cloud computing and its integration with data science workflows \n  Bachelor's degree in Computer Science or Data Science \n \n \n  Nice If You Have: \n \n  2+ years of experience in the development of algorithms leveraging R, Python, or SQL/NoSQL \n  Knowledge of DevSecOps methodologies, including CI/CI pipelines, code, and container scanning \n  Possession of excellent oral and written communications skills \n  Master's degree in Computer Science or Data Science \n  Microsoft Certified: Data Scientist Associate or Google Data Engineer Certifications \n \n \n  Create Your Career: \n \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll develop your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $73,100.00 to $166,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",
        "cleaned_desc": "  You Have: \n \n  2+ years of experience with data exploration, data cleaning, data analysis, data visualization, or data mining \n  2+ years of experience with statistical and general-purpose programming languages for data analysis \n  Experience in data analytics, statistical analysis, and machine learning techniques \n  Experience in computer science principles, algorithms, and programming \n  Experience with data manipulation, cleaning, and transformation \n  Knowledge of cloud computing and its integration with data science workflows \n  Bachelor's degree in Computer Science or Data Science \n \n \n  Nice If You Have: \n \n  2+ years of experience in the development of algorithms leveraging R, Python, or SQL/NoSQL \n  Knowledge of DevSecOps methodologies, including CI/CI pipelines, code, and container scanning \n  Possession of excellent oral and written communications skills \n  Master's degree in Computer Science or Data Science \n  Microsoft Certified: Data Scientist Associate or Google Data Engineer Certifications \n \n ",
        "techs": [
            "r",
            "python",
            "sql/nosql",
            "devsecops methodologies",
            "ci/cd pipelines",
            "code scanning",
            "container scanning",
            "microsoft certified: data scientist associate",
            "google data engineer certifications."
        ],
        "cleaned_techs": [
            "r",
            "python",
            "sql",
            "devsecops methodologies",
            "ci/cd pipelines",
            "code scanning",
            "container scanning",
            "microsoft certified: data scientist associate",
            "google data engineer certifications."
        ]
    },
    "c7a146e384e20db9": {
        "terms": [
            "data science"
        ],
        "salary_min": 130000.0,
        "salary_max": -1.0,
        "title": "Remote Senior Data Scientist",
        "company": "Intoxalock",
        "desc": "Consumer Safety Technology (CST)  and our family of brands have helped millions of individuals to live and drive responsibly. We provide products and services to consumers and program monitoring authorities to effectively deter impaired driving and support individuals as they navigate the license restoration process. We are the largest provider of IIDs in the United States and the only company working to assist individuals in successfully navigating the often-daunting DUI process. \n We hire people who we expect will produce exceptional results, deliver amazing service to our clients including customers, attorneys, state associations and more, and inspire positive change within the company. \n We are hiring a  Remote Senior Data Scientist . \n Job Summary:  The  Senior Data Scientist  is responsible for leading key data science initiatives for CST and Brands. The Senior Data Scientist has oversight of the production, automation, and distribution of key metrics that encompass all operational, technology and customer experience metrics. The Senior Data Scientist applies and inspires adoption of advanced analytics across the CST Brands, in a way that contributes deepened insights on highlights & opportunities to optimize performance. \n \n Duties and Responsibilities: \n \n \n Lead key business analysis efforts as defined by VP Finance; Collaborate on useful modifications to analysis requests \n Partner with analytical peers to adopt best practices, data definition standards and explore new tools/technology \n Oversee preparation and distribution of key periodic (daily, weekly, monthly, quarterly) reports \n Strive to eliminate manual processes through automation and testing of technologies \n Identify data patterns that are key business indicators; communicate trends and recommendations \n Provide mentorship to junior analysts \u2013 share and help to grow technical knowledge, skills and professional maturity \n Participate in budgeting and forecast processes \u2013 implementing improved forecasting models \n Be a cross disciplinary partner \u2013 sharing best practices and unifying business logic bringing consistency to reporting and analysis \n Present insights to senior level leadership, distilling complex statistical findings to non technical audiences \n Respond to ad hoc analytical requests as needed \n \n \n \n Job Requirements: \n \n \n You have a MS in Data Science, Business Analytics, Statistics, or Computer Science \n You have 10+ years\u2019 experience working with relational databases and usage of SQL \n You have 10+ years\u2019 experience distilling data into dashboards/summary reports (PowerBI, Tableau, Visual Studio, SSRS, etc.) \n You have 10+ years\u2019 experience working with statistical analysis software (SAS, R, Python, SPSS, etc.) \n  - You have 10+ years reporting/analytics experience (Finance, Operations, Marketing, Sales - any combination)\n   \n \n You are flexible and enjoy working in a fast-paced environment with regular opportunities for new development \n You are a curious problem-solver that can work independently and deliver on a clear timeline \n Strong verbal and written communication skills required, including a high level of comfort in interacting with senior management \n \n \n \n \n \n Why work for us? \n  Check out this list of just a few of the many good reasons why\u2026\n   \n \n Pay starts at $130,000 \n Our Mission is to help people live and drive responsibly. Last year our product stopped 243,000 illicit startup attempts by people who were too intoxicated to drive. \n CST won the 2022 Top Workplace Award locally and nationally\u2013and 2023 Best Place for Working Parents Award \n We are the nation\u2019s largest interlock provider \n Growth Oriented- 7 years of over 10%+ growth annually. Doubled in size over the past 2-3 years \n Full-time/40 hours guaranteed weekly \n Benefits include Paid Time Off, 401(k) & Health/Life/Vision/Dental insurance \n Ongoing Professional Training online via Litmos   \n \n \n   Equal Opportunity Employer  It is and will continue to be the policy of CST, LLC to practice a program of equal employment opportunity designed to assure that employment and advancement opportunities are made available to all employees and applicants on the basis of individual qualifications and without unlawful regard to race, religion, color, veteran status, national origin, disability, age, gender identity, sexual orientation, sex or genetic information.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "5e2a917500c2b7d4": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 104369.516,
        "salary_max": 132155.06,
        "title": "Senior Data Analyst, Data Science - Verity Tracking",
        "company": "Gevo, Inc.",
        "desc": "About the Role \n \n  We are looking for a team member with excellent programming, data engineering, and analytical skills for the position of Senior Data Analyst, Data Science. To be successful in this role you will:  \n \n Design scalable data science programs to help capture, organize, and analyze data  \n Write clean, testable, and modularized code  \n Build automatic data science workflows and analysis of data science life cycle (including model deployment and monitoring)  \n Aggregate, clean, and study data while identifying trends and insights to solve significant near- and long-term business problems  \n Clean data and automate basic data characterization processes and anomaly detection algorithms  \n Identify opportunities to enhance the flow and analysis of multiple different data sets into and across the company  \n Transparently communicate priorities, obstacles, and progress on a regular basis to the Product Analytics Lead  Comfortably lead technical data science operations while following agile principles \n  \n \n Who you are:   \n \n Degree in a quantitative field such as data science, data analytics, or statistics; with applied experience in technical data science implementation (programming)  \n Comfortable in data validation and quality assurance methods, including validating and verifying GIS-type data  \n Logic-driven critical thinker hungry for precision and increasing understanding and confidence in data  \n Proficient in common data science programming languages such as Python or R and proficient with data management systems  \n Passionate about environmental sustainability with domain knowledge in agricultural practices and industrial processes  \n Experienced in building trusted business relationships  \n Strong written and verbal communicator  \n \n Education:  \n \n Bachelor's (Required) in a quantitative field such as data science, computer science, physics, engineering, applied mathematics, or statistics.  \n MS Analytics or similar degree (Preferred)  \n \n Experience:  \n \n Data Engineering Knowledge (SQL or similar): 3+ years (Required)  \n Data analytics/science: 3+ years (Required)  \n Programming Knowledge (R or Python): 3+ years (Required)  \n Data science program design: 2+ years (Preferred)  \n \n Who We Are \n \n We are People First  \n We are Mission-Focused  \n We are Agile  \n We are Innovators \n \n Gevo  is a next generation, \u201clow-carbon\u201d fuel company focused on the development and commercialization of renewable alternatives to petroleum-based products. Low-carbon fuels reduce the carbon intensity, or the level of greenhouse gas emissions, compared to standard fossil-based fuels across their lifecycle. The most common low-carbon fuels are renewable fuels. Gevo is focused on the development and production of mainstream fuels like gasoline and jet fuel using renewable feedstocks that have the potential to lower greenhouse gas emissions at a meaningful scale and enhance agricultural production, including food and other related products. \n  What Gevo Offers You   \n \n Free health, dental, vision, life and disability insurance for employee and family  \n 21 days of vacation and sick leave plus 11 paid holidays  \n 401k contribution plan with match in Gevo stock \n Annual incentive plan, based on Company performance  \n Paid community service time  \n \n \n Be part of a smart, high performing, passionate team  \n Work-from-home stipend, if remote \n \n \n  Commitment to Diversity and Inclusion   \n Gevo, Inc. is an equal opportunity employer that is committed to diversity and inclusion in the workplace. We prohibit discrimination and harassment of any kind based on race, color, sex, religion, sexual orientation, national origin, disability, genetic information, pregnancy, or any other protected characteristic as outlined by federal, state, or local laws. \n  Physical Requirements \n \n Light work that includes moving objects up to 20 pounds \n Remaining in a stationary position, often standing or sitting for prolonged periods \n Communicating with others to exchange information",
        "cleaned_desc": "About the Role \n \n  We are looking for a team member with excellent programming, data engineering, and analytical skills for the position of Senior Data Analyst, Data Science. To be successful in this role you will:  \n \n Design scalable data science programs to help capture, organize, and analyze data  \n Write clean, testable, and modularized code  \n Build automatic data science workflows and analysis of data science life cycle (including model deployment and monitoring)  \n Aggregate, clean, and study data while identifying trends and insights to solve significant near- and long-term business problems  \n Clean data and automate basic data characterization processes and anomaly detection algorithms  \n Identify opportunities to enhance the flow and analysis of multiple different data sets into and across the company  \n Transparently communicate priorities, obstacles, and progress on a regular basis to the Product Analytics Lead  Comfortably lead technical data science operations while following agile principles \n    \n Who you are:   \n \n Degree in a quantitative field such as data science, data analytics, or statistics; with applied experience in technical data science implementation (programming)  \n Comfortable in data validation and quality assurance methods, including validating and verifying GIS-type data  \n Logic-driven critical thinker hungry for precision and increasing understanding and confidence in data  \n Proficient in common data science programming languages such as Python or R and proficient with data management systems  \n Passionate about environmental sustainability with domain knowledge in agricultural practices and industrial processes  \n Experienced in building trusted business relationships  \n Strong written and verbal communicator  \n \n Education:  ",
        "techs": [
            "none"
        ],
        "cleaned_techs": []
    },
    "0944d4963e017b42": {
        "terms": [
            "data science"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Director Data Analytics",
        "company": "Sodexo",
        "desc": "Unit Description: \n   Sodexo is in search of a  Director, Data Analytics  to lead the execution of Segment Business Analytics roadmap and build support structures to achieve our objectives. This position will play a critical role in optimizing the operational and financial performance of our North America Healthcare business. They will assist in creating and operationalizing models that support organizational strategic objectives, as well as the development of effective tracking and analytics of key indicators to attain proactive and predictive insights, helping to improve both business and sales executive performance indicators. They will work closely with our leadership teams to identify opportunities, develop, and manage strategic initiatives and drive transformation. \n  *This is a virtual position & the person can reside anywhere in the US* \n \n  Key activities: \n \n  Spearhead the Data and Analytics function and align it with the segment strategic direction, setting ambitious goals and ensuring that the function's roadmap is broadly informed by key stakeholders, clearly communicated, and thoughtfully executed. \n  Create, manage, and improve the segment databases. \n  Lead the design, development, maintenance, growth, quality, analysis, and presentation of our datasets. \n  Evaluate and manage customer data, customer research, market conditions and competitor data. \n  Develop strategic data initiatives; this includes resourcing and prioritizing key initiatives as well as showcasing relevant data via data presentation and self-service platforms; some examples include go-to-market strategy, market share and sizing analysis, territory mapping, organization design planning, monitoring Customer Experience etc.  \n Work with stakeholders and business leaders to provide insights and analysis support to help them make critical decisions and identify areas of opportunity. \n  Based on analysis of data, create & manage forecast model tracking key indicator trends \n  Manage fielding, prioritizing, and delivering analytics requests, and fostering a data-driven culture by supporting other teams in the consumption and use of our data.  \n Support all NorAm segment specific commercial organization data and analytics needs.  \n \n Responsibilities: \n \n  Data Collection and Management \n \n  Gather and integrate data from multiple sources, including internal databases, CRM systems, and external sources. \n  Maintain and update databases, ensuring data accuracy, completeness, and reliability. \n \n  Data Analysis \n \n  Analyze data to identify trends, patterns, and anomalies. \n  Provide insights on sales performance metrics like quote achievement, conversion rates, average deal sizes, etc. \n  Use statistical methods to analyze data and produce actionable insights. \n \n  Reporting \n \n  Develop regular sales performance reports for leadership and sales teams. \n  Design and create data reports using visualization tools, making complex data more accessible, understandable, and usable through visuals and dashboards. \n  Transform raw data into meaningful and actionable business information. \n  Present findings to stakeholders through standard and ad hoc reports \n \n  Forecasting and Predictive Analysis \n \n  Utilize statistical methods to forecast future sales trends. \n  Help in setting realistic sales targets based on historical data and market analysis. \n  Develop models to predict future trends based on historical data. \n \n  Collaboration \n \n  Work closely with the sales team to understand their needs and provide data for sales pitches, strategies, and campaigns. \n  Liaise with the IT department to improve data collection and reporting systems. \n \n  Continuous Improvement \n \n  Recommend improvements in sales strategies based on the data-driven insights. \n  Stay updated with the latest trends, data analysis tools, techniques, and best practices. \n \n \n \n  Qualifications: \n \n  Bachelor\u2019s degree in data science, Statistics, Business, Finance, Operations, or comparable proven experience in related field \n  Previous experience in data analysis, strategic thinking, commercial mindset, and strong execution \n  Proficiency in data analysis tools like Excel, SQL, and data visualization tools like Tableau or PowerBI \n  Naturally curious and logical with strong analytical and problem-solving skills \n  Detail-oriented with a knack for spotting data anomalies and discrepancies \n  Able to work in a fast-paced environment and manage multiple tasks. \n \n \n  Agile with the ability to speak and relate to each business function. Can quickly come up to speed and understand support services sales, operations, HR, and all other areas. \n  Excellent communication skills, both verbal and written \n  Able to communicate complex data findings clearly to non-technical audiences. \n  Willing to be coached and mentored. \n \n \n  What We Offer: \n  \n   Sodexo offers fair and equitable compensation, partially determined by a candidate's education level or years of relevant experience. While the budgeted range for the position is posted, Sodexo salary offers are based on a candidate's specific criteria, like experience, skills, education and training.\n   Position Summary: \n  \n   Sodexo\u2019s is in search of a Director, Data Analytics to lead the execution of Segment Business Analytics roadmap and build support structures to achieve sustainable operations. The Director, Data Analytics will assist in creating and operationalizing models that support organizational strategic objectives, as well as the development of effective tracking and analytics of key indicators to attain proactive and predictive insights, helping to articulate offer value, client & patient experience and to improve performance indicators.\n  \n \n   Key activities:\n   \n \n Manage and improve the Segment strategic databases. \n Evaluate and manage customer data, customer research, market conditions and competitor data. \n Work with stakeholders to define business and systems requirements for new information technologies, particularly in the areas of BI, analytics, and data warehousing. \n Based on analysis of data, create & manage forecast model tracking key indicator trends. \n Oversee and facilitate management of unit segmentation. \n Facilitate strategic initiatives supporting market share/sizing analysis, territory mapping, organization design planning. \n Facilitate operational design for analytical models driving both operational and enabler metrics. \n Work as a lead architect to facilitate tracking, monitoring of key strategic initiatives such as Patient experience using Service Depot, EIC using Trakkar tools and formulate models to measure effectiveness. \n \n  Qualifications & Requirements: \n  \n   Basic Education Requirement - Bachelor\u2019s Degree or equivalent experience\n  \n \n   Basic Management Experience - 7 years\n  \n \n   Basic Functional Experience - 7 years of experience in compensation\n  \n \n \n  Sodexo is an EEO/AA/Minority/Female/Disability/Veteran employer.",
        "cleaned_desc": "  Gather and integrate data from multiple sources, including internal databases, CRM systems, and external sources. \n  Maintain and update databases, ensuring data accuracy, completeness, and reliability. \n \n  Data Analysis \n \n  Analyze data to identify trends, patterns, and anomalies. \n  Provide insights on sales performance metrics like quote achievement, conversion rates, average deal sizes, etc. \n  Use statistical methods to analyze data and produce actionable insights. \n \n  Reporting \n \n  Develop regular sales performance reports for leadership and sales teams. \n  Design and create data reports using visualization tools, making complex data more accessible, understandable, and usable through visuals and dashboards. \n  Transform raw data into meaningful and actionable business information. \n  Present findings to stakeholders through standard and ad hoc reports \n \n  Forecasting and Predictive Analysis \n \n  Utilize statistical methods to forecast future sales trends. \n  Help in setting realistic sales targets based on historical data and market analysis.    Develop models to predict future trends based on historical data. \n \n  Collaboration \n \n  Work closely with the sales team to understand their needs and provide data for sales pitches, strategies, and campaigns. \n  Liaise with the IT department to improve data collection and reporting systems. \n \n  Continuous Improvement \n \n  Recommend improvements in sales strategies based on the data-driven insights. \n  Stay updated with the latest trends, data analysis tools, techniques, and best practices. \n \n \n \n  Qualifications: \n \n  Bachelor\u2019s degree in data science, Statistics, Business, Finance, Operations, or comparable proven experience in related field \n  Previous experience in data analysis, strategic thinking, commercial mindset, and strong execution \n  Proficiency in data analysis tools like Excel, SQL, and data visualization tools like Tableau or PowerBI \n  Naturally curious and logical with strong analytical and problem-solving skills   \n Manage and improve the Segment strategic databases. \n Evaluate and manage customer data, customer research, market conditions and competitor data. \n Work with stakeholders to define business and systems requirements for new information technologies, particularly in the areas of BI, analytics, and data warehousing. \n Based on analysis of data, create & manage forecast model tracking key indicator trends. \n Oversee and facilitate management of unit segmentation. \n Facilitate strategic initiatives supporting market share/sizing analysis, territory mapping, organization design planning. \n Facilitate operational design for analytical models driving both operational and enabler metrics. \n Work as a lead architect to facilitate tracking, monitoring of key strategic initiatives such as Patient experience using Service Depot, EIC using Trakkar tools and formulate models to measure effectiveness. \n \n  Qualifications & Requirements: \n  \n   Basic Education Requirement - Bachelor\u2019s Degree or equivalent experience\n  \n \n   Basic Management Experience - 7 years\n  \n \n   Basic Functional Experience - 7 years of experience in compensation\n  ",
        "techs": [
            "excel",
            "sql",
            "tableau",
            "powerbi"
        ],
        "cleaned_techs": [
            "excel",
            "sql",
            "tableau",
            "powerbi"
        ]
    },
    "48b3bdc7659909e9": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 65.0,
        "salary_max": 72.0,
        "title": "Sr. Business Data Analyst",
        "company": "Buzzency LLC",
        "desc": "Data analysis: \n \n Understand the data available in the source systems and the data needs of the required solution. \n Prepare data mapping and interface contract documents. \n Analyze the data to identify trends and patterns. \n Analyze the quality of the data and identify gaps and potential problems for the solution. \n Develop reports and presentations to communicate findings to stakeholders. \n Help prepare the cutover and data migration plan. \n \n Provide ongoing application support: \n \n Document and track reported problems and issues with the application thoughout the different test phases and after go-live. \n Escalate problems as required. \n Research and resolve issues related to application defects. \n Coordinate resolution with the technical team and the user community. \n Assist user management in defining required changes in business processes and documents the required changes. \n Create application documentation for end-users and technical staff, provide training as needed. \n \n Essential: \n \n Bachelor\u2019s degree in Business Administration, Computer Science, or a related field \n 5+ years of experience in business systems and/or data analysis \n Experience in gathering specifications in big development projects for web-based applications \n Experience in working in Agile teams \n Strong data analysis skills \n Strong understanding of business systems analysis and design techniques \n Expert writing skills of requirements and technical documentation \n Expert knowledge of tools like Jira, Confluence, Teams, SharePoint \n Strong SQL and Excel skills \n Solid understanding of data modelling, web (UI/UX) and API development \n Experience with AWS, Redshift, authentication and authorization technologies a plus \n Eager to learn \n Strong critical thinking and problem solving skills \n Detail-oriented and capable of delivering a high level of accuracy \n Strong communication and organization skills \n Team player, who also can work independently \n Ability to work efficiently and meet deadlines in a fast-paced environment \n Willing to work flexible hours for collaboration with the off-shore team \n \n Desirable: \n \n Entertainment industry/royalties experience \n SAP FI experience \n Redshift - DB \n AWS \n \n Job Type: Contract \n Pay: $65.00 - $72.00 per hour \n Expected hours: 40 per week \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n \n Compensation package: \n \n 1099 contract \n \n Experience level: \n \n 6 years \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Experience: \n \n SQL: 4 years (Required) \n AWS: 3 years (Preferred) \n Data modeling: 2 years (Required) \n Business analysis: 4 years (Required) \n Jira: 2 years (Required) \n Redshift: 1 year (Required) \n \n Work Location: Remote",
        "cleaned_desc": "Data analysis: \n \n Understand the data available in the source systems and the data needs of the required solution. \n Prepare data mapping and interface contract documents. \n Analyze the data to identify trends and patterns. \n Analyze the quality of the data and identify gaps and potential problems for the solution. \n Develop reports and presentations to communicate findings to stakeholders. \n Help prepare the cutover and data migration plan. \n \n Provide ongoing application support: \n \n Document and track reported problems and issues with the application thoughout the different test phases and after go-live. \n Escalate problems as required. \n Research and resolve issues related to application defects. \n Coordinate resolution with the technical team and the user community.   Assist user management in defining required changes in business processes and documents the required changes. \n Create application documentation for end-users and technical staff, provide training as needed. \n \n Essential: \n \n Bachelor\u2019s degree in Business Administration, Computer Science, or a related field \n 5+ years of experience in business systems and/or data analysis \n Experience in gathering specifications in big development projects for web-based applications \n Experience in working in Agile teams \n Strong data analysis skills \n Strong understanding of business systems analysis and design techniques \n Expert writing skills of requirements and technical documentation \n Expert knowledge of tools like Jira, Confluence, Teams, SharePoint \n Strong SQL and Excel skills \n Solid understanding of data modelling, web (UI/UX) and API development   Experience with AWS, Redshift, authentication and authorization technologies a plus \n Eager to learn \n Strong critical thinking and problem solving skills \n Detail-oriented and capable of delivering a high level of accuracy \n Strong communication and organization skills \n Team player, who also can work independently \n Ability to work efficiently and meet deadlines in a fast-paced environment \n Willing to work flexible hours for collaboration with the off-shore team \n \n Desirable: \n \n Entertainment industry/royalties experience \n SAP FI experience \n Redshift - DB \n AWS ",
        "techs": [
            "jira",
            "confluence",
            "teams",
            "sharepoint",
            "sql",
            "excel",
            "aws",
            "redshift"
        ],
        "cleaned_techs": [
            "jira",
            "confluence",
            "teams",
            "sharepoint",
            "sql",
            "excel",
            "aws",
            "redshift"
        ]
    },
    "46afedc7d92d5754": {
        "terms": [
            "data science",
            "data analyst",
            "machine learning engineer"
        ],
        "salary_min": 106022.18,
        "salary_max": 134247.7,
        "title": "Sr. Data Analyst",
        "company": "Bainbridge, Inc.",
        "desc": "Sr. Data Analyst-BC Capital , LLC \n  Position location:  Remote (work from home, must be U.S. based) \n  Position Type:   Full-Time or Contract \n  Pay Scale:  $75,000.00-$150,000.00 (commensurate with experience) \n  How to Apply:  Please submit resume and cover letter \n \n  About Us \n  Bainbridge is Forbes-ranked, Strategy Analytics & Capital Advisory firm serving industry leaders across the Fortune 1000 to the small & mid-cap private US businesses. Founded out of MIT, Bainbridge has a strong technological and academic heritage that, along with its differentiated work-product, continues to make us the choice Strategy & Analytics partner for global firms. To serve our clients, we have an in-house B2B data analytics team, comprehensive marketing platform & a successful M&A platform, making Bainbridge a true laboratory of data, analytics & marketing-sciences driven execution. Every team member at Bainbridge is a product owner, leader & entrepreneur. We are a disruptive team of technologists and strategists that believe in innovating at every turn. If this approach resonates with you, we encourage you to apply to our company! \n \n  Position Summary:  \n Seeking an experienced Sr. Data Analyst responsible for utilizing their expertise in data analysis to drive strategic decisions, optimize business performance, and identify opportunities for growth. Ability to work with CapitalSphere management team to identify business KPI metrics, do analysis, submit reports, and make dashboards for CapitalSphere board members. \n  Responsibilities: \n \n  Data analysis and interpretation:  Collect, clean, and analyze large datasets using various tools and techniques. Apply statistical methods and data modeling to uncover trends, patterns, and insights. Interpret findings and present them in a clear and meaningful manner to stakeholders. \n  Strategic decision-making:  Collaborate with business stakeholders, managers, and executives to understand their requirements and provide data-driven insights and recommendations. Support strategic initiatives and help shape the organization's long-term goals. \n  Business performance optimization:  Identify areas of improvement within the organization by analyzing key performance indicators (KPIs) and operational metrics. Develop and implement data-driven strategies to enhance business processes, efficiency, and effectiveness. \n  Data visualization and reporting:  Create visually appealing and informative dashboards, reports, and presentations to communicate complex data analysis results to non-technical audiences. Use data visualization tools (such as Tableau, Power BI, or Excel) to illustrate trends, patterns, and key findings. \n  Data quality and integrity:  Ensure the accuracy, reliability, and consistency of data through data cleansing, validation, and quality assurance techniques. Develop and implement data governance processes and standards to maintain data integrity. \n  Data-driven insights:  Identify new data sources and implement data collection methodologies to gather relevant information for analysis. Stay up to date with industry trends, emerging technologies, and best practices in data analysis to continuously enhance analytical capabilities. \n  Team collaboration and leadership:  Collaborate with cross-functional teams, including data engineers, data scientists, and business stakeholders, to gather requirements, exchange insights, and deliver high-quality analysis. Provide mentorship and guidance to junior analysts and contribute to their professional development. \n  Technical expertise:  Possess strong proficiency in data analysis tools and programming languages (such as SQL, Python, R, or SAS). Have a deep understanding of data manipulation, data warehousing, and data visualization techniques. Stay updated with the latest advancements in data analysis methodologies and tools. \n  Project management:  Lead and manage data analysis projects from initiation to completion, ensuring timely delivery of high-quality results. Define project objectives, develop work plans, allocate resources, and monitor progress. Communicate project updates to stakeholders and address any issues or risks. \n  Data privacy and security:  Adhere to data privacy regulations and ensure the security of sensitive data throughout the data analysis process. Implement measures to protect data confidentiality and comply with relevant industry standards (such as GDPR or HIPAA). \n \n \n  Qualifications: \n \n  Advanced Degree:  A master's or Ph.D. in a quantitative field such as Data Science, Computer Science, Statistics, or Mathematics is typically required. \n  Technical Expertise : Proficiency in programming languages such as Python or R, along with expertise in data manipulation, statistical analysis, and machine learning techniques. \n  Data Engineering:  Experience in data wrangling, data preprocessing, and working with large-scale databases and distributed computing frameworks. \n  Analytical Skills:  Strong analytical thinking and problem-solving abilities, with a deep understanding of statistical methods, hypothesis testing, and experimental design. \n  Business Acumen:  The ability to translate complex data analysis into actionable insights and strategic recommendations for the organization. \n  Communication and Visualization:  Excellent written and verbal communication skills, with the ability to present complex findings to both technical and non-technical stakeholders using data visualizations and storytelling techniques. \n  Leadership and Mentoring:  Demonstrated leadership skills, with the ability to guide and mentor junior team members, provide technical direction, and collaborate effectively with cross-functional teams. \n  Industry Knowledge:  Familiarity with the specific industry or domain in which the organization operates, along with a deep understanding of the business goals and challenges. \n \n \n  Benefits: \n  We know that it is our people that make the difference. We are proud to offer a comprehensive benefits package to all full-time employees. \n \n  #LI-REMOTE \n   \n 3MWofFHjkq",
        "cleaned_desc": "  Data visualization and reporting:  Create visually appealing and informative dashboards, reports, and presentations to communicate complex data analysis results to non-technical audiences. Use data visualization tools (such as Tableau, Power BI, or Excel) to illustrate trends, patterns, and key findings. \n  Data quality and integrity:  Ensure the accuracy, reliability, and consistency of data through data cleansing, validation, and quality assurance techniques. Develop and implement data governance processes and standards to maintain data integrity. \n  Data-driven insights:  Identify new data sources and implement data collection methodologies to gather relevant information for analysis. Stay up to date with industry trends, emerging technologies, and best practices in data analysis to continuously enhance analytical capabilities. \n  Team collaboration and leadership:  Collaborate with cross-functional teams, including data engineers, data scientists, and business stakeholders, to gather requirements, exchange insights, and deliver high-quality analysis. Provide mentorship and guidance to junior analysts and contribute to their professional development. \n  Technical expertise:  Possess strong proficiency in data analysis tools and programming languages (such as SQL, Python, R, or SAS). Have a deep understanding of data manipulation, data warehousing, and data visualization techniques. Stay updated with the latest advancements in data analysis methodologies and tools. \n  Project management:  Lead and manage data analysis projects from initiation to completion, ensuring timely delivery of high-quality results. Define project objectives, develop work plans, allocate resources, and monitor progress. Communicate project updates to stakeholders and address any issues or risks. \n  Data privacy and security:  Adhere to data privacy regulations and ensure the security of sensitive data throughout the data analysis process. Implement measures to protect data confidentiality and comply with relevant industry standards (such as GDPR or HIPAA). \n   \n  Qualifications: \n \n  Advanced Degree:  A master's or Ph.D. in a quantitative field such as Data Science, Computer Science, Statistics, or Mathematics is typically required. \n  Technical Expertise : Proficiency in programming languages such as Python or R, along with expertise in data manipulation, statistical analysis, and machine learning techniques. \n  Data Engineering:  Experience in data wrangling, data preprocessing, and working with large-scale databases and distributed computing frameworks. \n  Analytical Skills:  Strong analytical thinking and problem-solving abilities, with a deep understanding of statistical methods, hypothesis testing, and experimental design. \n  Business Acumen:  The ability to translate complex data analysis into actionable insights and strategic recommendations for the organization. ",
        "techs": [
            "tableau",
            "power bi",
            "excel",
            "sql",
            "python",
            "r",
            "sas",
            "gdpr",
            "hipaa"
        ],
        "cleaned_techs": [
            "tableau",
            "powerbi",
            "excel",
            "sql",
            "python",
            "r",
            "sas",
            "gdpr",
            "hipaa"
        ]
    },
    "f8cbe030db0c4a7c": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 142102.19,
        "salary_max": 179933.03,
        "title": "Principal Data Scientist - Customer Growth Marketing",
        "company": "Dell Technologies",
        "desc": "Principal Data Scientist \u2013 Customer Growth Marketing \n  Data Science is all about breaking new ground to enable businesses to answer their most urgent questions.Pioneering massively parallel data-intensive analytic processing, our mission is to develop a whole new approach to generating meaning and value from petabyte-scale data sets and shape brand-new methodologies, tools, statistical methods, and models. What\u2019s more, we are in collaboration with leading academics, industry experts, and highly skilled engineers to equip our customers to generate sophisticated new insights from the biggest of big data. \n  Join us to do the best work of your career and make a profound social impact as a  Principal Data Scientist  on our Customer  Growth Marketing Team  working remotely in  Brazil,  or  Panama . \n  What you\u2019ll achieve  As a Principal Data Scientist on a growing team, you will bring your industry expertise to build machine-learning models.You will collaborate closely with our Field Marketing and Sales stakeholders to solve critical and highly-visible business problems with machine learning. \n \n \n  You will: \n \n \n \n  You will work with other Data Scientists, Data Engineers, ML Engineers, and Business Analyststo lead the end-to-end ML lifecycle, from use-case identification through model productionization, business outcome measurement, and data storytelling \n  Lead the growth and maturation of our marketing capabilities with machine learning at its core \n  Engage with business stakeholders to support customer-centric design of solutions \n  Mentor junior data scientists \n \n \n \n \n  Take the first step toward your dream career \n \n \n  Every Dell Technologies team member brings something unique to the table. Here\u2019s what we are looking for with this role: \n \n \n  Essential Requirements \n \n \n \n  Expertise in machine learning, data science, statistics, or related, including a demonstrated portfolio of productionized models. \n  Expertise in statistical programming with proficiency in Python (including packages such as pandas, scikit-learn, TensorFlow, or PyTorch) and Jupyter Notebooks \n  Ability to quickly gain deep understanding of multiple domain data, business processes, business objectives, and build appropriate stakeholderrelationships. \n  Experience with data storytelling, including providing clear and concise analyses around model performance and business outcomes to nonexpert stakeholders in very good written and verbal English. \n \n \n \n  Desired Requirements \n \n \n \n  Bachelor\u2019s degree in Data Science, Machine Learning, Statistics, Economics, Physics, other quantitative fields, or equivalent professional experience; Master\u2019s degree preferred \n  Demonstrated experience of researching and applying new industry methodologies or techniques to solve business problems in unique ways \n \n \n \n \n  Who we are \n \n \n  We believe that each of us has the power to make an impact. That\u2019s why we put our team members at the center of everything we do. If you\u2019re looking for an opportunity to grow your career with some of the best minds and most advanced tech in the industry, we\u2019re looking for you.     Dell Technologies is a unique family of businesses that helps individuals and organizations transform how they work, live and play. Join us to build a future that works for everyone because Progress Takes All of Us. \n  Application close date: September 30th - 2023    Dell Technologies is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment.",
        "cleaned_desc": " \n  Expertise in machine learning, data science, statistics, or related, including a demonstrated portfolio of productionized models. \n  Expertise in statistical programming with proficiency in Python (including packages such as pandas, scikit-learn, TensorFlow, or PyTorch) and Jupyter Notebooks \n  Ability to quickly gain deep understanding of multiple domain data, business processes, business objectives, and build appropriate stakeholderrelationships. \n  Experience with data storytelling, including providing clear and concise analyses around model performance and business outcomes to nonexpert stakeholders in very good written and verbal English. \n \n \n \n  Desired Requirements ",
        "techs": [
            "machine learning",
            "data science",
            "statistics",
            "pandas",
            "scikit-learn",
            "tensorflow",
            "pytorch",
            "jupyter notebooks"
        ],
        "cleaned_techs": [
            "data science",
            "statistics",
            "pandas",
            "scikit-learn",
            "tensorflow",
            "pytorch",
            "jupyter notebooks"
        ]
    },
    "09b4150634110e95": {
        "terms": [
            "data science"
        ],
        "salary_min": 70000.0,
        "salary_max": 75000.0,
        "title": "Data Scientist",
        "company": "Numero Data",
        "desc": "#ONLY W2 \n Numero Data LLC  is a well-established, E-Verified, strategic, IT consulting firm, focused on delivering Business Intelligence, Data Analytics, Development Solutions, Implementation services and support to leading clients in the commercial and government sectors. We specialize ad provide highest level of  placement services in the following technologies:  Business Analysis, Quality Assurance, BI-Tableau, Power BI, QlikView, BOBJ, Data Science & Data Analytics, DB2 Administration, iOS & Android Development, Python Programming. To learn more about Numero Data LLC, please visit our website www.numerodata.com. \n We are currently recruiting new, talented individuals who can  join our team of Business Intelligence consultants at Herndon, VA. \n Our Placement  Program highlights : \n \u00b7 Our Clients are Fortune 500 companies. \n \u00b7 Full Project Placement Assurance \n \u00b7  Very strong in H1 and Green Card Sponsorship \n \u00b7 We are registered under the E-Verify Program \n \u00b7 Competitive Salary Package with Benefits \n \u00b7 Health/Dental/Vision Insurance \n \u00b7 Free Training \n Job Description: \n \u00b7 Knowledge on Tableau Desktop and Tableau Server. \n \u00b7 Extensive knowledge in various reporting objects like Facts, Attributes, Hierarchies , filters, Calculated fields, Sets , Groups, Parameters etc., in Tableau. \n \u00b7 Interfacing of Tableau Dashboard with external portal and applications. \n \u00b7 Design rich Graphic visualizations with modular design of reports, worksheets, and views in Tableau with a strong understanding of the appropriate chart types (Bar charts, Line charts, scatter plot, Heat Maps) to use to highlight patterns in the data. \n \u00b7 Should have knowledge of administration and installation of Tableau servers. \n \u00b7 Skilled on different databases like RDBMS (SQL Server, Oracle), Vertica. \n Qualifications: \n \u00b7 Reporting analysts must have a strong background in computer science and programming since they often need to create customized tools and applications to handle the specific reporting needs of a business. \n \u00b7 They also need to exhibit excellent written and verbal communication skills since they deal closely with a business' information technology (IT) workers, training them to troubleshoot user issues with customized tools and software. \n \u00b7 Analysts must work with both IT departments and project managers to find any issues with custom software, as well as to propose and develop upgrades to deal with technical issues and enhance efficiency as business needs change. \n I\u2019d really appreciate, If you could please answer following questions along with your updated resume in regard with the job position and send it back to me. \n \u00b7 Full Name: \n \u00b7  Contact no: \n \u00b7  E-mail ID: \n \u00b7  Current Location: \n \u00b7  Willing to relocate anywhere in US ?(Y/N): \n \u00b7  Visa Status: \n \u00b7  Visa Expiry Date: \n \u00b7  DOB: \n \u00b7  Highest Qualification: \n \u00b7  University: \u00b7  Relevant Experience \n Job Type: Contract \n Salary: $70,000.00 - $75,000.00 per year \n Benefits: \n \n Dental insurance \n Vision insurance \n \n Schedule: \n \n 8 hour shift \n \n Work Location: Remote",
        "cleaned_desc": " \u00b7 Should have knowledge of administration and installation of Tableau servers. \n \u00b7 Skilled on different databases like RDBMS (SQL Server, Oracle), Vertica. \n Qualifications: \n \u00b7 Reporting analysts must have a strong background in computer science and programming since they often need to create customized tools and applications to handle the specific reporting needs of a business. \n \u00b7 They also need to exhibit excellent written and verbal communication skills since they deal closely with a business' information technology (IT) workers, training them to troubleshoot user issues with customized tools and software. \n \u00b7 Analysts must work with both IT departments and project managers to find any issues with custom software, as well as to propose and develop upgrades to deal with technical issues and enhance efficiency as business needs change. \n I\u2019d really appreciate, If you could please answer following questions along with your updated resume in regard with the job position and send it back to me. \n \u00b7 Full Name: ",
        "techs": [
            "tableau servers",
            "rdbms (sql server",
            "oracle)",
            "vertica"
        ],
        "cleaned_techs": [
            "tableau servers",
            "rdbms (sql server",
            "oracle",
            "vertica"
        ]
    },
    "fe06e230aa5a35fd": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 105950.05,
        "salary_max": 134156.36,
        "title": "Data Scientist \u2013 Customer Growth Marketing",
        "company": "Dell Technologies",
        "desc": "Principal Data Scientist \u2013 Customer Growth Marketing \n  Data Science is all about breaking new ground to enable businesses to answer their most urgent questions.Pioneering massively parallel data-intensive analytic processing, our mission is to develop a whole new approach to generating meaning and value from petabyte-scale data sets and shape brand-new methodologies, tools, statistical methods, and models. What\u2019s more, we are in collaboration with leading academics, industry experts, and highly skilled engineers to equip our customers to generate sophisticated new insights from the biggest of big data. \n  Join us to do the best work of your career and make a profound social impact as a  Data Scientist  on our Customer  Growth Marketing Team  working remotely in  Brazil,  or  Panama . \n  What you\u2019ll achieve \n  As a Senior Data Scientist on a growing team, you will bring your industry expertise to build machine-learning models.You will collaborate closely with our Field Marketing and Sales stakeholders to solve critical and highly-visible business problems with machine learning. \n \n \n  You will: \n \n \n \n \n \n  You will work with other Data Scientists, Data Engineers, ML Engineers, and Business Analysts to support the end-to-end ML lifecycle, from use-case identification through model productionization and business outcome measurement. \n  Play a critical role in growing and maturing our marketing capabilities with machine learning at its core \n  Engage with business stakeholders to support customer-centric design of solutions \n \n   \n \n \n \n \n \n Take the first step toward your dream career \n \n \n  Every Dell Technologies team member brings something unique to the table. Here\u2019s what we are looking for with this role: \n \n \n  Essential Requirements \n \n \n \n  Solid industry experience in machine learning, data science, statistics, or related, including a demonstrated portfolio of productionized models and model training, evaluation, validation, implementation, and monitoring \n  Solid industry experience in statistical programming, including Python (with packages such as pandas, scikit-learn, TensorFlow, or PyTorch) and Jupyter Notebooks \n  Ability to gain an understanding of domain data, business processes, and business objectives \n \n \n \n  Desired Requirements \n \n \n \n  Bachelor\u2019s degree in Data Science, Machine Learning, Statistics, Economics, Physics, other quantitative fields, or equivalent professional experience \n  Experience with model registries (i.e.MLflow) and version control (i.e.Gitlab) \n \n \n \n \n  Who we are \n \n \n  We believe that each of us has the power to make an impact. That\u2019s why we put our team members at the center of everything we do. If you\u2019re looking for an opportunity to grow your career with some of the best minds and most advanced tech in the industry, we\u2019re looking for you.     Dell Technologies is a unique family of businesses that helps individuals and organizations transform how they work, live and play. Join us to build a future that works for everyone because Progress Takes All of Us. \n  Application close date: September 15th - 2023    Dell Technologies is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. Read the full Equal Employment Opportunity Policy here. \n \n \n  Job ID: R227251\n   Dell\u2019s Flexible & Hybrid Work Culture    At Dell Technologies, we believe our best work is done when flexibility is offered.    We know that freedom and flexibility are crucial to all our employees no matter where you are located and our flexible and hybrid work style allows team members to have the freedom to ideate, be innovative, and drive results their way. To learn more about our work culture, please visit our locations page.",
        "cleaned_desc": "  Solid industry experience in machine learning, data science, statistics, or related, including a demonstrated portfolio of productionized models and model training, evaluation, validation, implementation, and monitoring \n  Solid industry experience in statistical programming, including Python (with packages such as pandas, scikit-learn, TensorFlow, or PyTorch) and Jupyter Notebooks \n  Ability to gain an understanding of domain data, business processes, and business objectives \n \n \n \n  Desired Requirements \n \n \n \n  Bachelor\u2019s degree in Data Science, Machine Learning, Statistics, Economics, Physics, other quantitative fields, or equivalent professional experience ",
        "techs": [
            "python",
            "pandas",
            "scikit-learn",
            "tensorflow",
            "pytorch",
            "jupyter notebooks"
        ],
        "cleaned_techs": [
            "python",
            "pandas",
            "scikit-learn",
            "tensorflow",
            "pytorch",
            "jupyter notebooks"
        ]
    },
    "9b54d74e1d5de019": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 80.0,
        "salary_max": 80.0,
        "title": "Need H1 Transfers -- Generative AI",
        "company": "American Unit Inc",
        "desc": "Generative AI Developer \n Remote \n Salary: based on market ( negotiate) \n No of Positions: 3 \n The ideal candidate will possess a blend of data engineering expertise hands-on development experience and a deep understanding of Generative AI technologies. \n Technical Skills:  Gernerative AI \n Technical Skills:  Azure Databricks, Azure Synapse and Python \n Proven experience as a Data Engineer or in a similar role with significant hands-on development experience \n We are seeking an innovative Generative AI Machine Learning Developer to join a brand new team focused on designing, developing and implementing cutting-edge generative AI models and solutions that can be entrenched into prevailing applications or the new application \n \n Strong proficiency in Python and exposure to other similar programming languages \n Python Expertise: Strong expertise in Python, which is commonly used for machine learning and AI development \n Solid understanding of system architecture with a focus on building solutions for scalability and performance \n Deep knowledge of Generative AI/LLM technologies, including but not limited to GPT-3 and Transformers \n Generative AI and LLMs: Generative AI models and Large Language Models (LLMs) like BERT, GPT, and others. \n Familiarity with Linux operating systems and basic programming concepts \n Hands-on development experience with at least one public cloud provider (AWS, Azure, GCP, etc.) \n \n Responsibilities \n \n This role is instrumental in developing and deploying state-of-the-art Generative AI solutions that drive critical business functions \n Design, develop, and deploy solutions using OpenAI API and other LLM-related technologies to cater to critical business functions \n \n Preferred Qualifications: \n \n Research publications or contributions in the fields of NLP, NLU and Generative AI \n Experience with Conversational AI, Chatbots (Kore.ai, Botpress, Nuance etc.,) \n \n Job Type: Full-time \n Salary: $80.00 per hour \n Expected hours: 40 per week \n Schedule: \n \n 8 hour shift \n \n Work Location: Remote",
        "cleaned_desc": " Proven experience as a Data Engineer or in a similar role with significant hands-on development experience \n We are seeking an innovative Generative AI Machine Learning Developer to join a brand new team focused on designing, developing and implementing cutting-edge generative AI models and solutions that can be entrenched into prevailing applications or the new application \n \n Strong proficiency in Python and exposure to other similar programming languages \n Python Expertise: Strong expertise in Python, which is commonly used for machine learning and AI development \n Solid understanding of system architecture with a focus on building solutions for scalability and performance \n Deep knowledge of Generative AI/LLM technologies, including but not limited to GPT-3 and Transformers   Generative AI and LLMs: Generative AI models and Large Language Models (LLMs) like BERT, GPT, and others. \n Familiarity with Linux operating systems and basic programming concepts \n Hands-on development experience with at least one public cloud provider (AWS, Azure, GCP, etc.) \n \n Responsibilities \n \n This role is instrumental in developing and deploying state-of-the-art Generative AI solutions that drive critical business functions   Design, develop, and deploy solutions using OpenAI API and other LLM-related technologies to cater to critical business functions \n \n Preferred Qualifications: \n \n Research publications or contributions in the fields of NLP, NLU and Generative AI \n Experience with Conversational AI, Chatbots (Kore.ai, Botpress, Nuance etc.,) \n ",
        "techs": [
            "generative ai machine learning developer",
            "python",
            "system architecture",
            "scalability",
            "performance",
            "gpt-3",
            "transformers",
            "linux",
            "aws",
            "azure",
            "gcp",
            "openai api",
            "nlp",
            "nlu",
            "conversational ai",
            "chatbots"
        ],
        "cleaned_techs": [
            "generative ai machine learning developer",
            "python",
            "system architecture",
            "scalability",
            "performance",
            "gpt-3",
            "transformers",
            "linux",
            "aws",
            "azure",
            "gcp",
            "openai api",
            "nlp",
            "nlu",
            "conversational ai",
            "chatbots"
        ]
    },
    "e4cffae58830294c": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 111799.56,
        "salary_max": 141563.16,
        "title": "Senior Data and AI Engineer",
        "company": "Core4ce",
        "desc": "Responsibilities \n  As a Senior Data and AI Engineer, you will be responsible for the following: \n \n Evaluate and Transform Datasets: Utilize a wide range of manual, machine learning, and AI tools and techniques to evaluate and transform new datasets effectively. Your expertise will contribute to enhancing data quality and accessibility for advanced analytics. \n Multi-Level Data Engineering and Analysis: Perform comprehensive data engineering and analysis across multiple levels, ensuring data is processed efficiently and accurately. This will involve designing and implementing data pipelines to extract, transform, normalize, and load data. \n Develop Innovative Techniques and Applications: Innovate new techniques and applications for rapid data characterization, engineering, analysis, and cataloging. Your contributions will drive advanced approaches that facilitate efficient data management. \n Lead: Be prepared to lead, a team of part-time employees conducting initial data triage of data and serve as the principal point of interface and listing agent for data sales with a strategic partner. \n Contribute, Troubleshoot and Support: Tackle complex problems, providing technical support for software systems and application issues related to data engineering and AI tools. Your problem-solving skills will be essential to ensure smooth operations. \n \n \n \n  Requirements \n  To excel in this role, you should possess the following qualifications: \n \n Education and Experience: A master\u2019s degree or PhD in Computer Science, Electrical or Computer Engineering, or a related technical discipline, or an equivalent combination of education, technical training, and work experience. \n Data Engineering and Analysis Expertise: You should have at least 5+ years of hands-on experience in data engineering, including designing common data formats and creating efficient data pipelines for data extraction, transformation, normalization, and loading. \n Proficiency in Programming: Demonstrated experience with C/C++, C#, or Java in a Microsoft Windows environment for at least 2+ years is required to develop and optimize data engineering applications. \n In-Depth Data Engineering Knowledge: You must possess a strong foundation in data engineering concepts and practices, with at least 4+ years of experience in this field. \n Self-Driven and Prioritization: Ability to independently deliver on multiple competing priorities with minimal supervision, showcasing excellent time management and organizational skills. \n Communication Skills: Strong written and oral communication skills are essential to effectively collaborate with team members and stakeholders. \n \n \n \n  Preferred \n  While not mandatory, the following skills and experiences will be considered advantageous: \n \n Knowledge of Python: Familiarity with Python will be beneficial in handling data-related tasks efficiently. \n Entity Resolution Expertise: Experience in entity resolution across various datasets will enhance the accuracy and reliability of data processing. \n \n \n \n  All qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity, religion, national origin, disability, veteran status, age, marital status, pregnancy, genetic information, or other legally protected status.",
        "cleaned_desc": "Responsibilities \n  As a Senior Data and AI Engineer, you will be responsible for the following: \n \n Evaluate and Transform Datasets: Utilize a wide range of manual, machine learning, and AI tools and techniques to evaluate and transform new datasets effectively. Your expertise will contribute to enhancing data quality and accessibility for advanced analytics. \n Multi-Level Data Engineering and Analysis: Perform comprehensive data engineering and analysis across multiple levels, ensuring data is processed efficiently and accurately. This will involve designing and implementing data pipelines to extract, transform, normalize, and load data. \n Develop Innovative Techniques and Applications: Innovate new techniques and applications for rapid data characterization, engineering, analysis, and cataloging. Your contributions will drive advanced approaches that facilitate efficient data management.    To excel in this role, you should possess the following qualifications: \n \n Education and Experience: A master\u2019s degree or PhD in Computer Science, Electrical or Computer Engineering, or a related technical discipline, or an equivalent combination of education, technical training, and work experience. \n Data Engineering and Analysis Expertise: You should have at least 5+ years of hands-on experience in data engineering, including designing common data formats and creating efficient data pipelines for data extraction, transformation, normalization, and loading. \n Proficiency in Programming: Demonstrated experience with C/C++, C#, or Java in a Microsoft Windows environment for at least 2+ years is required to develop and optimize data engineering applications. \n In-Depth Data Engineering Knowledge: You must possess a strong foundation in data engineering concepts and practices, with at least 4+ years of experience in this field.    While not mandatory, the following skills and experiences will be considered advantageous: \n \n Knowledge of Python: Familiarity with Python will be beneficial in handling data-related tasks efficiently. \n Entity Resolution Expertise: Experience in entity resolution across various datasets will enhance the accuracy and reliability of data processing. \n \n ",
        "techs": [
            "manual",
            "machine learning",
            "ai",
            "data engineering",
            "data analysis",
            "data pipelines",
            "data extraction",
            "data transformation",
            "data normalization",
            "data loading",
            "data management",
            "c/c++",
            "c#",
            "java",
            "microsoft windows",
            "python",
            "entity resolution"
        ],
        "cleaned_techs": [
            "manual",
            "ai",
            "data pipelines",
            "data extraction",
            "data transformation",
            "data normalization",
            "data loading",
            "data management",
            "c/c++",
            "c#",
            "java",
            "microsoft windows",
            "python",
            "entity resolution"
        ]
    },
    "f9e50f3012946c3b": {
        "terms": [
            "data science"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Director Data Engineering",
        "company": "Providence",
        "desc": "Description \n This position is remote with some in person meetings required and can only be located in the states of WA, OR, or CA. \n Leads highly technical data engineers. Accountable for all aspects of the technical design and build of modern data-centric solutions and applications to support clinical and operational processes across all parts of the enterprise health system. These solutions leverage cloud, big data, data science, and modern software development methodologies (such as SAFe) and tools and services (such as Snowflake and Databricks in Azure). Responsible for the buildout of our data engineering center of excellence for the enterprise and a community of practice across teams. Collaborates on technical solutions with teams at the Providence Global Center at Hyderabad, India. \n Providence caregivers are not simply valued \u2013 they\u2019re invaluable. Join our team at Enterprise Information Services and thrive in our culture of patient-focused, whole-person care built on understanding, commitment, and mutual respect. Your voice matters here, because we know that to inspire and retain the best people, we must empower them. \n Required Qualifications: \n \n Bachelor's Degree - Computer Engineering, Computer Science, Mathematics, Engineering. Or equivalent educ/experience, \n 10 or more years - Related experience in engineering or development roles. \n 8 years Leadership experience leading teams in a complex and fast-paced moving environment. \n Experience in cloud computing and data warehousing, Linux, Hadoop, Spark, and other NoSQL platforms. \n Strong experience working with both the product and technical sides of issues. \n Practical solutions development experience in a data-centric domain. \n Strong experience in managing and coaching a team of technical resources. \n \n Preferred Qualifications: \n \n Bachelor's Degree in Computer Science and Engineering, Mathematics, Engineering and related technical fields. \n \n The salary range listed for this position MIN:$79.20 to MAX:$131.66 per hour is based upon the primary work location Renton, WA posted. This position is remote. Salary range and offers are determined by internal pay equity and geographic cost of living differences. Salary range will vary from State and region. Salary max is limited to 75% range in order to continue to offer internal pay growth. We welcome open and transparent discussions on salary at Providence. \n Why Join Providence? \n Our best-in-class benefits are uniquely designed to support you and your family in staying well, growing professionally, and achieving financial security. We take care of you, so you can focus on delivering our Mission of caring for everyone, especially the most vulnerable in our communities. \n About Providence \n At Providence, our strength lies in Our Promise of \u201cKnow me, care for me, ease my way.\u201d Working at our family of organizations means that regardless of your role, we\u2019ll walk alongside you in your career, supporting you so you can support others. We provide best-in-class benefits and we foster an inclusive workplace where diversity is valued, and everyone is essential, heard and respected. Together, our 120,000 caregivers (all employees) serve in over 50 hospitals, over 1,000 clinics and a full range of health and social services across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. As a comprehensive health care organization, we are serving more people, advancing best practices and continuing our more than 100-year tradition of serving the poor and vulnerable. \n The amounts listed are the base pay range; additional compensation may be available for this role, such as shift differentials, standby/on-call, overtime, premiums, extra shift incentives, or bonus opportunities. \n Check out our benefits page for more information about our Benefits and Rewards. \n About the Team \n Providence Shared Services is a service line within Providence that provides a variety of functional and system support services for our family of organizations across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. We are focused on supporting our Mission by delivering a robust foundation of services and sharing of specialized expertise. \n We are committed to the principle that every workforce member has the right to work in surroundings that are free from all forms of unlawful discrimination and harassment. \n We are committed to cultural diversity and equal employment for all individuals. It is our policy to recruit, hire, promote, compensate, transfer, train, retain, terminate, and make all other employment-related decisions without regard to race, color, religious creed (including religious dress and grooming practices), national origin (including certain language use restrictions), ancestry, disability (mental and physical including HIV and AIDS), medical condition (including cancer and genetic characteristics), genetic information, marital status, age, sex (which includes pregnancy, childbirth, breastfeeding and related medical conditions), gender, gender identity, gender expression, sexual orientation, genetic information, and military and veteran status or any other applicable legally protected status. We will also provide reasonable accommodation to known physical or mental limitations of an otherwise qualified caregiver or applicant for employment, unless the accommodation would impose undue hardship on the operation of our business. \n We are a community where all people, regardless of differences, are welcome, secure, and valued. We value respect, appreciation, collaboration, diversity, and a shared commitment to serving our communities. We expect that all workforce members in our community will act in ways which reflect a commitment to and accountability for, racial and social justice and equality in the workplace. As such, we will maintain a workplace free of discrimination and harassment based on any applicable legally protected status. We also expect that all workforce members will maintain a positive workplace free from any unacceptable conduct which creates an intimidating, hostile, or offensive work environment. \n Requsition ID:  226882  \n Company:  Providence Jobs  \n Job Category:  Development/Engineering  \n Job Function:  Information Technology  \n Job Schedule:  Full time  \n Job Shift:  Day  \n Career Track:  Leadership  \n Department:  4011 SS IS HI DP 3  \n Address:  WA Renton 1801 Lind Ave SW  \n Work Location:  Providence Valley Office Park-Renton  \n Pay Range:  $79.20 - $131.66  \n The amounts listed are the base pay range; additional compensation may be available for this role, such as shift differentials, standby/on-call, overtime, premiums, extra shift incentives, or bonus opportunities.  \n Check out our benefits page for more information about our Benefits and Rewards. \n Providence is proud to be an Equal Opportunity Employer. Providence does not discriminate on the basis of race, color, gender, disability, veteran, military status, religion, age, creed, national origin, sexual identity or expression, sexual orientation, marital status, genetic information, or any other basis prohibited by local, state, or federal law.",
        "cleaned_desc": " 8 years Leadership experience leading teams in a complex and fast-paced moving environment. \n Experience in cloud computing and data warehousing, Linux, Hadoop, Spark, and other NoSQL platforms. \n Strong experience working with both the product and technical sides of issues. \n Practical solutions development experience in a data-centric domain. \n Strong experience in managing and coaching a team of technical resources. \n \n Preferred Qualifications: \n ",
        "techs": [
            "cloud computing",
            "data warehousing",
            "linux",
            "hadoop",
            "spark",
            "nosql"
        ],
        "cleaned_techs": [
            "cloud computing",
            "data warehousing",
            "linux",
            "hadoop",
            "spark",
            "nosql"
        ]
    },
    "d07b8d28ecd00677": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 77969.51,
        "salary_max": 98726.77,
        "title": "SCIS Data Analyst",
        "company": "Martin Brower",
        "desc": "Overview: \n  \n   Martin Brower is a global supply chain leader that provides smart, sustainable solutions for customers across 18 countries. We are dedicated to creating an outstanding work environment for our team of 12,500+ employees, who combine our expertise with the latest technologies to deliver unmatched value for our customers.\n  \n \n  Responsibilities: \n  \n  Pay Transparency Statement:  \n \n \n  The compensation philosophy reflects the Company\u2019s reasonable expectation at the time of posting. We consider a number of factors when making individual compensation decisions including, but not limited to, skill sets, experience and training, and other business needs. This role may also be eligible to participate in a discretionary incentive program, subject to the rule governing the program.\n  \n \n \n  Position Summary: \n \n \n   The SCIS Data Analyst is a role defined within the Global Data and Analytics Center of Excellence, which provides design, development, consulting, and support services to various markets. The SCIS Data Analyst will design and develop Global Analytics solutions to support strategic product and service offerings. In addition, this role will provide ongoing maintenance and support of Global Analytics solutions. This role reports to the Manager, Global Supply Chain Analytics.\n  \n \n \n  Position Responsibilities may include, but not limited to: \n \n \n  Design and develop Global Reports and Analytics using modern data visualization tools \n  Work with business stakeholders to define data and report specifications \n  Understand and prioritize business requirements while managing the expectations of stakeholders \n  Align disparate business teams and stakeholders in the use of common Global Analytics metrics and standards \n  Visualize and present Global Analytics to key stakeholders to identify areas of opportunity \n  Execute a portfolio of global analytics projects that enable growth of the business, including enabling technologies such as self-service discovery and analytics that make it easier for personnel to use data to drive decisions, reduce costs, and optimize supply chain processes \n  Establish strong, strategic partnerships with key IT contacts, supply chain partners, and end users \n  Participate in global data governance processes to ensure data is both managed and used consistently and is compliant with enterprise standards \n  Other projects or duties as assigned \n  Qualifications: \n  \n  Required Skills and Experience: \n \n \n  Bachelor\u2019s Degree with 2+ years of related technical experience \n  Strong understanding of business process analytics and/or business process management, including common methods for deriving business value from data \n  At least 2+ years of experience in a business or business-facing IT role within a global or multinational organization, in which the following occurred:\n    \n  Demonstrated capabilities for analyzing business needs and finding solutions \n  Demonstrated knowledge and real-world application of modern Business Intelligence tools \n  Demonstrated experience developing solutions within either Microsoft Power BI or Tableau \n  Employed the use of report design best practices in the areas of dimensional data modeling, UI/UX, and report performance \n  Worked successfully in both Customer- and Business-facing roles \n  Gathered business requirements and translated into data and/or report specifications \n  Conceptualized efficient and effective analytics solutions to diverse and complex business problems \n  Developed both functional and technical subject matter expertise \n \n  Proven ability to collaborate with IT and business teams working at remote locations \n  Excellent verbal and written communication skills, with the ability to communicate technical subjects to non-technical audiences \n  Ability to travel as needed for projects. Estimated to be 10% per year \n  Strong teamwork and interpersonal skills \n  This position must pass a post-offer background and drug test \n \n \n  Preferred Skills and Experience: \n \n \n  Post graduate degree in Computer Science, Business Administration or related field \n  Technical Certification \n  Experience with Supply Chain business processes and analytics \n  Experience working both in a business and IT role \n  Experience as a liaison between IT and business \n  Experience within the distribution or Food Service industry \n  Familiarity with data science concepts like statistical modeling, machine learning and forecasting models with an ability to explain them to non-technical audiences \n \n \n  Physical Demands and Work Environment :\n  \n \n   Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Due to the nature of our business in regard to such things as delivery schedules, order inputs, selection, and Department of Transportation Hours of Service, overtime, attendance and punctuality are essential job functions. Should an individual in this classification not be able to adhere to this requirement due to a disability, they should contact their Human Resources department to see what, if any, reasonable accommodation may be made.",
        "cleaned_desc": "  Demonstrated capabilities for analyzing business needs and finding solutions \n  Demonstrated knowledge and real-world application of modern Business Intelligence tools \n  Demonstrated experience developing solutions within either Microsoft Power BI or Tableau \n  Employed the use of report design best practices in the areas of dimensional data modeling, UI/UX, and report performance \n  Worked successfully in both Customer- and Business-facing roles \n  Gathered business requirements and translated into data and/or report specifications \n  Conceptualized efficient and effective analytics solutions to diverse and complex business problems \n  Developed both functional and technical subject matter expertise \n \n  Proven ability to collaborate with IT and business teams working at remote locations \n  Excellent verbal and written communication skills, with the ability to communicate technical subjects to non-technical audiences \n  Ability to travel as needed for projects. Estimated to be 10% per year \n  Strong teamwork and interpersonal skills \n  This position must pass a post-offer background and drug test   \n \n  Preferred Skills and Experience: \n \n \n  Post graduate degree in Computer Science, Business Administration or related field \n  Technical Certification \n  Experience with Supply Chain business processes and analytics \n  Experience working both in a business and IT role \n  Experience as a liaison between IT and business \n  Experience within the distribution or Food Service industry \n  Familiarity with data science concepts like statistical modeling, machine learning and forecasting models with an ability to explain them to non-technical audiences \n \n ",
        "techs": [
            "microsoft power bi",
            "tableau"
        ],
        "cleaned_techs": [
            "powerbi",
            "tableau"
        ]
    },
    "63df6b3471f3495e": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 32.71,
        "salary_max": 48.51,
        "title": "Data Analysis and Reporting - Agency Policy Specialist",
        "company": "State of Minnesota",
        "desc": "When  all  employees are embraced, respected and heard, we will build a collaborative, equitable, inclusive and anti-racist culture where everyone thrives. \n \n \n \n \n \n \n  Job Details \n \n \n \n \n \n Working Title: Data Analysis and Reporting   Job Class: Agency Policy Specialist   Agency: Human Services Dept \n \n Who May Apply : Open to all qualified job seekers \n Date Posted : 10/17/2023 \n Closing Date : 10/23/2023 \n Hiring Agency/Seniority Unit : Human Services Dept / MAPE DHS Central Office \n Division/Unit : Children and Family Services / Data Analysis and Statistics \n Work Shift : Day Shift \n Work Hours : 8:00am - 4:30pm \n Days of Work : Monday - Friday \n Travel Required : No \n Salary Range:  $32.71 - $48.51 / hourly; $68,298 - $101,288 / annually \n Classified Status : Classified \n Bargaining Unit/Union : 214 - MN Assoc of Professional Empl/MAPE \n FLSA Status : Exempt - Administrative \n Telework Eligible : Yes \n Designated in Connect 700 Program for Applicants with Disabilities: Yes \n \n  Make a difference in the lives of Minnesotans. \n  The work you\u2019ll do is more than just a job. Join the talented, engaged and inclusive workforce dedicated to creating a better Minnesota. \n \n \n \n \n \n \n  Job Summary \n \n \n \n \n \n ***   Telework   (Within Minnesota or Neighboring States) and flexible hours options are available .*** \n \n  The Data Analytics and Data Management Agency Policy Specialist will lead complex data management, extraction, and analytic projects to help decision makers and program administrators understand policy and operational components of Minnesota\u2019s family cash and food assistance programs. This position will have a primary role in the development of data models/data marts to support reporting and performance measurement related to the Minnesota Family Investment Program (MFIP), Diversionary Work Program (DWP) and Supplemental Nutrition Assistance Program (SNAP), respond to ongoing and ad hoc requests for information and lead a continuous improvement effort around metadata development. \n  Importantly, this position serves a consultant role, translating complicated policy questions, performance measures, reporting requirements, legislative proposals, media inquiries and/or operational challenges, into data marts/models and/or data warehouse queries, or devising other data collection methods. A team of agency policy specialists and research scientists in the unit share responsibility for data modeling, data extraction, data analysis and sampling, federal and state reporting, research, evaluation, and measurement work. \n   \n Responsibilities include but may not be limited to: \n \n Develop and maintain data marts/models to support timely ongoing and ad hoc reporting and serve as the foundation for program performance measures. \n Maintain a high level of expertise in data extraction, preparation, and presentation including data visualization to respond to request for information and reporting from within the Department, the legislature, media, and other stakeholders. \n Maintain expert level knowledge of Structured Query Language (SQL) using the Department\u2019s available data management, extraction and analytic tools including Teradata SQL Assistant /Studio Express, SAS, R Statistical software to extract data from complex relational databases, analyze data, synthesize, and present results.  \n Utilize data visualization tools currently available to the department such as Tableau, Microsoft Excel and Infogram, to present results in a variety of formats. \n Communicate results effectively to a variety of audiences. Interpret findings to support policy and action recommendations. Meet with requestors and policy makers to think through their questions and interpret results.  \n Lead the development of data documentation of the MAXIS data system, including supporting the production of the first complete metadata on this source system. Serve as one of the Department experts in MAXIS views relational data model and other data systems available to Division analysts. \n \n \n \n \n \n \n \n Qualifications \n \n \n \n Minimum Qualifications \n  To facilitate proper crediting, please ensure that your resume clearly describes your experience in the areas listed and indicates the beginning and ending month and year for each job held. \n  Three (3) years of professional data management and analysis experience that demonstrates competency in: \n \n Writing complex queries using SQL, SAS, R (or equivalent) to extract data from relational databases. \n Utilizing relational database structure and/or data warehouse environments. \n Creating dashboards, reports, and other methods of synthesizing analytic results. \n Producing metadata products or processes. \n \n \n A Bachelor\u2019s degree in social services, data science or related field may substitute for 1 year of professional experience. \n \n  OR \n \n A Master\u2019s degree in social services, data science or related field may substitute for 2 years of professional experience. \n \n  Preferred Qualifications \n \n A graduate degree in data science, social science, or related field. \n Demonstrated experience developing data models / data marts. \n Demonstrated data visualization expertise. \n Demonstrated expertise in quantitative analysis, performance measurement, sampling etc. \n Knowledge of state and federal assistance programs and resulting data systems especially MAXIS. \n Working effectively with technical and non-technical staff. \n \n  Additional Requirements \n  REFERENCE/BACKGROUND CHECKS \u2013 DHS will conduct reference checks to verify job-related credentials and a criminal background check prior to appointment. \n  EDUCATION VERIFICATION - Applicants will be required to provide a copy of their college transcript or college degree/diploma at time of interview. Copies of the college degree/diploma are acceptable ONLY if it clearly identifies the field in which it was earned. \n \n \n \n \n \n \n  Application Details \n \n \n \n How to Apply   \n Select \u201cApply for Job\u201d at the top of this page. If you have questions about applying for jobs, contact the job information line at 651-259-3637 or email careers@state.mn.us. For additional information about the application process, go to http://www.mn.gov/careers.  \n If you have questions about the position, contact Kristen Boelcke-Stennes at kristen.boelcke-stennes@state.mn.us. \n  To receive consideration as a Connect 700 Program applicant, apply online, email the Job ID#, the Working Title and your valid Proof of Eligibility Certificate by the closing date to Alexander Duren at alexander.duren@state.mn.us.  \n If you are an individual with a disability and need an ADA accommodation for an interview, you may contact the Department of Human Services\u2019 ADA Coordinator at 651-431-4945 or DHS_ADA@state.mn.us for assistance. \n  About Human Services Dept   \n WE MAKE A DIFFERENCE! The Minnesota Department of Human Services impacts the lives of 1.7 million people every year, helping them meet their basic needs so they can achieve their highest potential.  \n Why Work for Us   \n Diverse Workforce   \n We are committed to continually developing a workforce that reflects the diversity of our state and the populations we serve. The varied experiences and perspectives of employees strengthen the work we do together and our ability to best serve the people of Minnesota.  \n A recent engagement survey of State of Minnesota employees found:   \n \n 95% of employees understand how their work helps achieve their agency\u2019s mission  \n 91% of employees feel trusted to do their jobs  \n 88% of employees feel equipped to look at situations from other cultural perspectives when doing their job  \n 87% of employees report flexibility in their work schedule  \n \n Comprehensive Benefits   \n Our benefits aim to balance four key elements that make life and work meaningful: health and wellness, financial well-being, professional development, and work/life harmony. As an employee, your benefits may include:  \n \n Public pension plan  \n Training and professional development  \n Paid vacation and sick leave  \n 12 paid holidays each year  \n Paid parental leave  \n Low-cost medical and dental coverage  \n Prescription drug coverage  \n Vision coverage  \n Wellness programs and resources  \n Employer paid life insurance  \n Short-term and long-term disability  \n Health care spending and savings accounts  \n Dependent care spending account  \n Tax-deferred compensation  \n Employee Assistance Program (EAP)  \n Tuition reimbursement  \n Federal Public Service Student Loan Forgiveness Program  \n \n Programs, resources and benefits eligibility varies  based on type of employment, agency, funding availability, union/collective bargaining agreement, location, and length of service with the State of Minnesota.  \n \n AN EQUAL OPPORTUNITY EMPLOYER   \n Minnesota state agencies are equal opportunity, affirmative action, and veteran-friendly employers. The State of Minnesota recognizes that a diverse workforce is essential and strongly encourages qualified women, minorities, individuals with disabilities, and veterans to apply.  \n We will make reasonable accommodations to all qualified applicants with disabilities. If you are an individual with a disability who needs assistance or cannot access the online job application system, please contact the job information line at 651-259-3637 or email careers@state.mn.us and indicate what assistance is needed.",
        "cleaned_desc": " Designated in Connect 700 Program for Applicants with Disabilities: Yes \n \n  Make a difference in the lives of Minnesotans. \n  The work you\u2019ll do is more than just a job. Join the talented, engaged and inclusive workforce dedicated to creating a better Minnesota. \n \n \n \n \n \n \n  Job Summary \n \n \n \n \n \n ***   Telework   (Within Minnesota or Neighboring States) and flexible hours options are available .*** \n \n  The Data Analytics and Data Management Agency Policy Specialist will lead complex data management, extraction, and analytic projects to help decision makers and program administrators understand policy and operational components of Minnesota\u2019s family cash and food assistance programs. This position will have a primary role in the development of data models/data marts to support reporting and performance measurement related to the Minnesota Family Investment Program (MFIP), Diversionary Work Program (DWP) and Supplemental Nutrition Assistance Program (SNAP), respond to ongoing and ad hoc requests for information and lead a continuous improvement effort around metadata development. \n  Importantly, this position serves a consultant role, translating complicated policy questions, performance measures, reporting requirements, legislative proposals, media inquiries and/or operational challenges, into data marts/models and/or data warehouse queries, or devising other data collection methods. A team of agency policy specialists and research scientists in the unit share responsibility for data modeling, data extraction, data analysis and sampling, federal and state reporting, research, evaluation, and measurement work. \n   \n Responsibilities include but may not be limited to: \n \n Develop and maintain data marts/models to support timely ongoing and ad hoc reporting and serve as the foundation for program performance measures. \n Maintain a high level of expertise in data extraction, preparation, and presentation including data visualization to respond to request for information and reporting from within the Department, the legislature, media, and other stakeholders. \n Maintain expert level knowledge of Structured Query Language (SQL) using the Department\u2019s available data management, extraction and analytic tools including Teradata SQL Assistant /Studio Express, SAS, R Statistical software to extract data from complex relational databases, analyze data, synthesize, and present results.  \n Utilize data visualization tools currently available to the department such as Tableau, Microsoft Excel and Infogram, to present results in a variety of formats. \n Communicate results effectively to a variety of audiences. Interpret findings to support policy and action recommendations. Meet with requestors and policy makers to think through their questions and interpret results.  \n Lead the development of data documentation of the MAXIS data system, including supporting the production of the first complete metadata on this source system. Serve as one of the Department experts in MAXIS views relational data model and other data systems available to Division analysts.   \n \n \n \n \n \n \n Qualifications \n \n \n \n Minimum Qualifications \n  To facilitate proper crediting, please ensure that your resume clearly describes your experience in the areas listed and indicates the beginning and ending month and year for each job held. \n  Three (3) years of professional data management and analysis experience that demonstrates competency in: \n \n Writing complex queries using SQL, SAS, R (or equivalent) to extract data from relational databases. \n Utilizing relational database structure and/or data warehouse environments. \n Creating dashboards, reports, and other methods of synthesizing analytic results. \n Producing metadata products or processes. \n \n \n A Bachelor\u2019s degree in social services, data science or related field may substitute for 1 year of professional experience. \n \n  OR \n \n A Master\u2019s degree in social services, data science or related field may substitute for 2 years of professional experience. \n \n  Preferred Qualifications \n ",
        "techs": [
            "connect 700 program",
            "telework",
            "data analytics",
            "data management",
            "minnesota family investment program",
            "diversionary work program",
            "supplemental nutrition assistance program",
            "data models/data marts",
            "metadata development",
            "structured query language (sql)",
            "teradata sql assistant/studio express",
            "sas",
            "r statistical software",
            "tableau",
            "microsoft excel",
            "infogram",
            "maxis data system",
            "maxis views",
            "relational data model",
            "dashboards",
            "reports",
            "metadata products"
        ],
        "cleaned_techs": [
            "connect 700 program",
            "telework",
            "data analytics",
            "data management",
            "minnesota family investment program",
            "diversionary work program",
            "supplemental nutrition assistance program",
            "data models/data marts",
            "metadata development",
            "structured query language (sql)",
            "teradata sql assistant/studio express",
            "sas",
            "r statistical software",
            "tableau",
            "excel",
            "infogram",
            "maxis data system",
            "maxis views",
            "relational data model",
            "dashboards",
            "reports",
            "metadata products"
        ]
    },
    "37a641949df0bb21": {
        "terms": [
            "data science"
        ],
        "salary_min": 192965.39,
        "salary_max": 244337.17,
        "title": "Director, Product Analytics",
        "company": "Instacart",
        "desc": "We're transforming the grocery industry \n  At Instacart, we invite the world to share love through food because we believe everyone should have access to the food they love and more time to enjoy it together. Where others see a simple need for grocery delivery, we see exciting complexity and endless opportunity to serve the varied needs of our community. We work to deliver an essential service that customers rely on to get their groceries and household goods, while also offering safe and flexible earnings opportunities to Instacart Personal Shoppers. \n  Instacart has become a lifeline for millions of people, and we're building the team to help push our shopping cart forward. If you're ready to do the best work of your life, come join our table. \n  Instacart is a Flex First team  \n There's no one-size fits all approach to how we do our best work. Our employees have the flexibility to choose where they do their best work\u2014whether it's from home, an office, or your favorite coffee shop\u2014while staying connected and building community through regular in-person events. Learn more about our flexible approach to where we work. \n \n  OVERVIEW \n  Instacart's Marketplace org is responsible for efficient and high quality fulfillment of online grocery orders. This space encompasses problems ranging from logistics (batching, pricing, routing) to shopper experience (shopper onboarding, shopper app, shopper pay), and retailer fulfillment (making Instacart's marketplace products work for retailers and CPG companies). As the Head of Analytics for Marketplace, you will be responsible for partnering closely with the cross-functional leadership team to develop our long term strategies and formulate operational plans to drive business outcomes with data. \n  You will lead a small but mighty team of analysts to take on open-ended strategic problems, conduct in-depth data driven analysis, translate insights into actions that ensure quality fulfillment for customers and create meaningful work and earnings for shoppers. \n  ABOUT THE JOB \n \n Work with Marketplace leadership (product, engineering, design) to drive strategic initiatives, formulate business plans, evaluate options and trade-offs and make recommendations to the executive team. \n Work on open-ended business problems with a lot of uncertainty and bring structure, data and sound judgment to propose a path forward. \n \n \n Develop a detailed understanding of the P&L across multiple dimensions to understand critical profit drivers and develop insights. \n Identify and triage key questions, issues, and roadblocks facing the company using your business acumen and experience. \n Lead the centralized planning process across functions - size new opportunities, estimate effort and risks, prioritize projects based on impact, and establish robust processes to track business impact of completed work. \n Manage a team of high performing Analysts and Senior Analysts, fostering a culture of excellence. Partner closely with the Data Scientists on more advanced technical problems. \n \n ABOUT YOU \n \n You have 10+ years of work experience in Analytics, or a similar role. \n You are a strategic thinker that can also dive deep into business problems. You bring a strong product and user lens while solving analytical problems. \n You think critically and evaluate options objectively to drive the best business decisions. \n You think with data and are proficient with SQL, dashboarding/BI tools and spreadsheets. \n You are confident in your verbal and written communication and are able to convey complex ideas to a wide range of audiences with clarity and structure. \n You are a self-starter with the ability to quickly respond to problems independently and proactively address conflicting stakeholder requirements to achieve creative compromise. \n You have a proven track record of designing and implementing process improvement projects and improving business metrics in resource-constrained environments. \n Ideally, you have an advanced degree in a technical field (e.g. masters in math, engineering, econ, analytics, data science, statistics). \n Ideally, you have a background in marketplace/gig companies and are able to think through the implications of decisions on multiple sides of the marketplace. \n \n #LI-Remote \n \n \n  Instacart provides highly market-competitive compensation and benefits in each location where our employees work. This role is remote and the base pay range for a successful candidate is dependent on their permanent work location. Please review our Flex First remote work policy here. \n  Offers may vary based on many factors, such as candidate experience and skills required for the role. Additionally, this role is eligible for a new hire equity grant as well as annual refresh grants. Please read more about our benefits offerings here.     For US based candidates, the base pay ranges for a successful candidate are listed below. \n \n  CA, NY, CT, NJ \n \n    $239,000\u2014$305,000 USD\n   \n  WA \n \n    $229,000\u2014$293,000 USD\n   \n  OR, DE, ME, MA, MD, NH, RI, VT, DC, PA, VA, CO, TX, IL, HI \n \n    $220,000\u2014$281,000 USD\n   \n  All other states \n \n    $198,000\u2014$253,000 USD",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "b3759b9ecf563a08": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 80510.0,
        "salary_max": 116513.0,
        "title": "LEAD DATA ENGINEER",
        "company": "Lumen",
        "desc": "About Lumen \n  Lumen is a global technology leader, digitally connecting people, data and applications \u2013 quickly, securely, and effortlessly. Together, we are building a culture and company from the people up \u2013 committed to teamwork, trust and transparency. People power progress. We\u2019re looking for top-tier talent and offer the flexibility you need to thrive and deliver lasting impact. Join us as we digitally connect the world and shape the future. \n \n \n \n  The Role \n \n \n  Are you interested in serving as an integral part of our digital marketing team developing new tools and capabilities that will continue to advance Lumen\u2019s reputation as a technology leader?    In this role, you will be partnering closely with marketing, operations, and data science teams to utilize terabytes of data and translate them into actionable insights to create a competitive advantage for marketing/sales initiatives to win market share. Furthermore, you will be accountable for building and operationalizing critical components and tools to ensure the data coming in and going out are of the highest data quality and integrity. In the end state, the data solutions built and operated by you would rival the absolute best in the industry in engineering, operations, and usability excellence. \n \n \n \n \n  The Main Responsibilities \n \n \n  You are a great fit for this position if you: \n \n  Have strong passion in building reliable, accurate datasets that power end-to-end user scenarios and used in business decisions. \n  Highly believe that data is an asset that must be accessible to and applicable by every function in a modern business to guide and assess growth investments. \n  Are passionate about Data Engineering and believe that it is one of a kind emerging discipline and career path that you want to grow in. \n  Enjoy building and operating data services at terabyte and higher scales to enable data driven organizations. \n \n \n \n \n \n  What We Look For in a Candidate \n \n \n  Qualifications: \n \n  Experience building data models and performing complex queries using SQL \n  Experience performance tuning large datasets \n  Experience building large data pipelines and/or web services \n  Strong programming skills with Python and other scripting languages \n  4+ years of Business Intelligence or software development experience using industry technologies \n  3+ years of experience in building integration with upstream and downstream systems with REST APIs \n  Excellent problem solving, critical thinking, and communication skills \n  Ability to communicate effectively with technical and business teams, drive issues to closure \n  Strong understanding of data engineering and data stewardship roles in an organization \n  Strong time management and organization skills. Ability to work on multiple projects concurrently. \n  BA/BS in Computer Science, Engineering or related technical field such as Statistics or Data Science \n \n \n  Other Qualifications: \n \n  Strong familiarity with Azure ecosystem is highly valuable \n  Knowledge of Lumen data, systems and processes including paid media, financial and inventory systems highly desirable \n  Experience with ETL and data integration development using multiple tools, including Informatica, Microsoft SSIS or other technologies \n  Combined IT and Marketing background \n  Machine Learning, Data Science, and statistical modeling experience are highly valued \n \n \n \n \n \n  Compensation \n \n \n  The starting salary for this role differs based on the employee's primary work location. Employees typically do not start at the top of the range, though compensation depends on each individual's qualifications. \n  Location Based Pay Ranges \n  $80510 - $100635  in these states: AR, ID, KY, LA, ME, MS, NE, SC, and SD.   $84740 - $105923  in these states: AZ, FL, GA, IN, IA, KS, MO, MT, NM, ND, OH, OK, PA, TN, UT, VT, WV, WI, and WY.   $88980 - $111218  in these states: CO, HI, MI, MN, NV, NH, NC, OR, and RI.   $93210 - $116513  in these states: AK, CA, CT, DE, DC, IL, MD, MA, NJ, NY, TX, VA, and WA. \n  As with the pay range variety that's based on the region of a country, specific offers are determined by various factors such as experience, education, skills, certifications and other business needs. \n \n \n \n  Requisition #: 331444 \n  Background Screening \n  If you are selected for a position, there will be a background screen, which may include checks for criminal records and/or motor vehicle reports and/or drug screening, depending on the position requirements. For more information on these checks, please refer to the Post Offer section of our FAQ page. Job-related concerns identified during the background screening may disqualify you from the new position or your current role. Background results will be evaluated on a case-by-case basis. \n  Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. \n  Equal Employment Opportunities \n  We are committed to providing equal employment opportunities to all persons regardless of race, color, ancestry, citizenship, national origin, religion, veteran status, disability, genetic characteristic or information, age, gender, sexual orientation, gender identity, gender expression, marital status, family status, pregnancy, or other legally protected status (collectively, \u201cprotected statuses\u201d). We do not tolerate unlawful discrimination in any employment decisions, including recruiting, hiring, compensation, promotion, benefits, discipline, termination, job assignments or training. \n  Disclaimer \n  The job responsibilities described above indicate the general nature and level of work performed by employees within this classification. It is not intended to include a comprehensive inventory of all duties and responsibilities for this job. Job duties and responsibilities are subject to change based on evolving business needs and conditions. \n \n  Salary Range \n \n  Salary Min :  \n 80510 \n \n \n  Salary Max :  \n 116513 \n \n \n  This information reflects the anticipated base salary range for this position based on current national data. Minimums and maximums may vary based on location. Individual pay is based on skills, experience and other relevant factors.  \n This position is eligible for either short-term incentives or sales compensation. Director and VP positions also are eligible for long-term incentive. To learn more about our bonus structure, you can view additional information here. We're able to answer any additional questions you may have as you move through the selection process. \n  As part of our comprehensive benefits package, Lumen offers a broad range of Health, Life, Voluntary Lifestyle and other benefits and perks that enhance your physical, mental, emotional and financial wellbeing. You can learn more by clicking here. \n  Note: For union-represented postings, wage rates and ranges are governed by applicable collective bargaining agreement provisions.",
        "cleaned_desc": " \n  Have strong passion in building reliable, accurate datasets that power end-to-end user scenarios and used in business decisions. \n  Highly believe that data is an asset that must be accessible to and applicable by every function in a modern business to guide and assess growth investments. \n  Are passionate about Data Engineering and believe that it is one of a kind emerging discipline and career path that you want to grow in. \n  Enjoy building and operating data services at terabyte and higher scales to enable data driven organizations. \n \n \n \n \n \n  What We Look For in a Candidate \n \n \n  Qualifications: \n \n  Experience building data models and performing complex queries using SQL \n  Experience performance tuning large datasets    Experience building large data pipelines and/or web services \n  Strong programming skills with Python and other scripting languages \n  4+ years of Business Intelligence or software development experience using industry technologies \n  3+ years of experience in building integration with upstream and downstream systems with REST APIs \n  Excellent problem solving, critical thinking, and communication skills \n  Ability to communicate effectively with technical and business teams, drive issues to closure \n  Strong understanding of data engineering and data stewardship roles in an organization \n  Strong time management and organization skills. Ability to work on multiple projects concurrently. \n  BA/BS in Computer Science, Engineering or related technical field such as Statistics or Data Science \n \n \n  Other Qualifications: \n \n  Strong familiarity with Azure ecosystem is highly valuable \n  Knowledge of Lumen data, systems and processes including paid media, financial and inventory systems highly desirable \n  Experience with ETL and data integration development using multiple tools, including Informatica, Microsoft SSIS or other technologies \n  Combined IT and Marketing background ",
        "techs": [
            "sql",
            "python",
            "rest apis",
            "azure ecosystem",
            "lumen data",
            "informatica",
            "microsoft ssis"
        ],
        "cleaned_techs": [
            "sql",
            "python",
            "rest apis",
            "azure",
            "lumen data",
            "informatica",
            "microsoft ssis"
        ]
    },
    "d0fc2b0d89d80ce9": {
        "terms": [
            "data science"
        ],
        "salary_min": 70560.0,
        "salary_max": 78400.0,
        "title": "Quality Assurance Manager",
        "company": "StrongHearts Native Helpline",
        "desc": "Job Description \n BASIC INFORMATION \n FLSA Status  Exempt \n Provisional Period  180 days \n Job Title  Quality Assurance Manager \n Location  Remote \n Funding Source  Grant Funded \n Position Type  Full-time \n Reports to  Chief Operations Officer \n Supervises  Data Coordinator and Grant Compliance Specialist \n Shift  8am-5pm CST \n Salary/Hourly Rate  $70,560.00 - $78,400.00 \n GENERAL POSITION PURPOSE STATEMENT \n Organizational Summary: StrongHearts Native Helpline is a safe, anonymous and confidential helpline for Native Americans and Alaska Natives affected by domestic, dating and sexual violence. By dialing 1-844-7NATIVE (1-844-762-8483), nationwide 24/7, callers can connect at no cost one-on-one with knowledgeable StrongHearts advocates who can provide lifesaving tools and immediate support to enable survivors to find safety and live lives free of abuse. \n JOB SUMMARY \n As the Quality Assurance Manager at StrongHearts Native Helpline, you will play a pivotal role in providing essential direction and oversight to our Quality program. Your primary focus will be on continuous quality improvement, data analysis and grant compliance, strategically engaging all areas of the organization and fostering a culture of accountability and transparency. Your dedication to maintaining and enhancing the overall quality, effectiveness, and efficiency of our helpline services for Native American and Alaska Native communities will be critical. \n ESSENTIAL RESPONSIBILITIES, DUTIES AND ABILITIES \n Overall: \u25cf Drive activities and initiatives relative to Quality Assurance - collaboration with the department managers. \u25cf Serve as subject matter expert for Salesforce database and various criteria of grant programs. \u25cf Oversee work of and supervise Grant Compliance Specialist and Database Coordinator, supporting these positions in meeting stated goals. \u25cf Strong capability to work remotely, with proven experience effectively communicating and collaborating in a virtual environment. \n Quality Management \u25cf Develop and implement quality assurance policies, procedures, and standards to ensure consistent and exceptional service delivery. \u25cf Monitor and evaluate helpline calls, text messages, and online chats to assess the quality and effectiveness of interactions with callers. \u25cf Conduct regular audits of helpline conversations to ensure adherence to established protocols and compliance with relevant regulations. \u25cf Conduct contact satisfaction surveys to ensure service provision is meeting the needs \n of those who contact StrongHearts \u25cf Collaborate with the HR/Training team to identify areas for improvement in advocate training and development. \n Data Analysis and Reporting: \u25cf Oversee the Salesforce database, become Salesforce certified, work with Database \n Coordinator to ensure data integrity and meaningful data analysis \u25cf Maintain service provider database, ensuring annual update is completed \u25cf Collect and analyze data on call volume, caller demographics, trends in issues faced by Native \n American and Alaska Native communities, and organizational marketing tactics. \u25cf Generate regular reports on helpline performance and present findings to the management team. \u25cf Utilize data-driven insights to identify opportunities for service improvement and innovation. \u25cf Design and implementation of various intra-system and inter-system data quality controls to ensure communication programs are protected from data or process errors \u25cf Fully investigate errors and discrepancies and work with appropriate business groups to identify patterns, trends and inconsistencies \n Grant Compliance Oversight: \u25cf Develop and implement a comprehensive grant compliance program to ensure adherence to all grant requirements and regulations. \u25cf Stay up-to-date with grant guidelines, federal and state regulations, and reporting deadlines, and communicate changes to relevant staff members. \u25cf Work closely with peer managers and the finance department to ensure all grant activities are in compliance with funding agency guidelines. \u25cf Stay informed about industry best practices, helpline standards, and relevant laws/regulations to maintain compliance. \u25cf Foster a culture of compliance throughout the organization by promoting awareness and understanding of grant-related rules and regulations. \n \u25cf Ensure the helpline adheres to all relevant confidentiality and reporting requirements. \n Continuous Improvement: \u25cf Partner with HR to participate in internal quality improvement initiatives to enhance helpline operations. \u25cf Collaborate with other departments to address cross-functional quality concerns and implement solutions. \n KNOWLEDGE AND SKILLS \n A Bachelor's Degree in data science; nonprofit management, business administration or a related field is Preferred. Must have at least 3 years of demonstrated experience in quality process and improvement. Must have 2 years leadership or supervisory experience. Must have advanced experience in using techniques and tools to present data in visual format including formulas, data management and complex Excel features. Required experience in Salesforce, audit, process improvement, policy implementation, data visualization, and quality data analysis experience. Proficiency preferred. Preferred work experience working with American Indian and Alaska Native communities. Preferred work experience with community-based domestic violence/victim assistance programs, human services, social services or related direct client services. Knowledge of the history of the battered women\u2019s movement in the United States and the impact on Native Americans. \n Any equivalent combination of education and experience that will allow the applicant to satisfactorily perform the duties of the job may be considered. \n PHYSICAL AND SENSORY REQUIREMENT \n The responsibilities of this position require certain physical and sensory abilities, which must be performed with or without reasonable accommodation. Must be able to hear and speak clearly. Ability to use hands and fingers on a keyboard and use a mouse. Ability to clearly see and view the details of words, tables and images on a computer screen for long periods of time. \n BENEFITS \n StrongHearts offers the work life balance, opportunities for growth and the upward mobility you've been searching for! Benefits include employer paid health, dental, vision, and life insurance benefits that begin two full calendar months after your official start date. Benefits also include generous paid time off so you can spend more time with your family and enjoy a positive work life balance. \n *StrongHearts is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, or veteran status. StrongHearts is a drug-free workplace.* \n Job Type: Full-time \n Pay: $70,560.00 - $78,400.00 per year \n Benefits: \n \n Dental insurance \n Health insurance \n Life insurance \n Paid time off \n Parental leave \n Retirement plan \n Vision insurance \n \n Schedule: \n \n 8 hour shift \n \n Work Location: Remote",
        "cleaned_desc": " Data Analysis and Reporting: \u25cf Oversee the Salesforce database, become Salesforce certified, work with Database \n Coordinator to ensure data integrity and meaningful data analysis \u25cf Maintain service provider database, ensuring annual update is completed \u25cf Collect and analyze data on call volume, caller demographics, trends in issues faced by Native \n American and Alaska Native communities, and organizational marketing tactics. \u25cf Generate regular reports on helpline performance and present findings to the management team. \u25cf Utilize data-driven insights to identify opportunities for service improvement and innovation. \u25cf Design and implementation of various intra-system and inter-system data quality controls to ensure communication programs are protected from data or process errors \u25cf Fully investigate errors and discrepancies and work with appropriate business groups to identify patterns, trends and inconsistencies \n Grant Compliance Oversight: \u25cf Develop and implement a comprehensive grant compliance program to ensure adherence to all grant requirements and regulations. \u25cf Stay up-to-date with grant guidelines, federal and state regulations, and reporting deadlines, and communicate changes to relevant staff members. \u25cf Work closely with peer managers and the finance department to ensure all grant activities are in compliance with funding agency guidelines. \u25cf Stay informed about industry best practices, helpline standards, and relevant laws/regulations to maintain compliance. \u25cf Foster a culture of compliance throughout the organization by promoting awareness and understanding of grant-related rules and regulations. \n \u25cf Ensure the helpline adheres to all relevant confidentiality and reporting requirements. \n Continuous Improvement: \u25cf Partner with HR to participate in internal quality improvement initiatives to enhance helpline operations. \u25cf Collaborate with other departments to address cross-functional quality concerns and implement solutions. \n KNOWLEDGE AND SKILLS \n A Bachelor's Degree in data science; nonprofit management, business administration or a related field is Preferred. Must have at least 3 years of demonstrated experience in quality process and improvement. Must have 2 years leadership or supervisory experience. Must have advanced experience in using techniques and tools to present data in visual format including formulas, data management and complex Excel features. Required experience in Salesforce, audit, process improvement, policy implementation, data visualization, and quality data analysis experience. Proficiency preferred. Preferred work experience working with American Indian and Alaska Native communities. Preferred work experience with community-based domestic violence/victim assistance programs, human services, social services or related direct client services. Knowledge of the history of the battered women\u2019s movement in the United States and the impact on Native Americans. \n Any equivalent combination of education and experience that will allow the applicant to satisfactorily perform the duties of the job may be considered. \n PHYSICAL AND SENSORY REQUIREMENT ",
        "techs": [
            "salesforce",
            "database coordinator",
            "data analysis",
            "call volume analysis",
            "data-driven insights",
            "data quality controls",
            "grant compliance program",
            "grant guidelines",
            "grant reporting",
            "industry best practices",
            "helpline standards",
            "confidentiality and reporting requirements",
            "quality improvement initiatives",
            "cross-functional collaboration",
            "data science",
            "nonprofit management",
            "business administration",
            "leadership",
            "advanced excel features",
            "salesforce",
            "audit",
            "process improvement",
            "policy implementation",
            "data visualization",
            "quality data analysis",
            "american indian and alaska native communities",
            "community-based domestic violence/victim assistance programs",
            "human services",
            "social services",
            "direct client services",
            "battered women's movement knowledge"
        ],
        "cleaned_techs": [
            "salesforce",
            "database coordinator",
            "call volume analysis",
            "data-driven insights",
            "data quality controls",
            "grant compliance program",
            "grant guidelines",
            "grant reporting",
            "helpline standards",
            "confidentiality and reporting requirements",
            "quality improvement initiatives",
            "cross-functional collaboration",
            "data science",
            "nonprofit management",
            "business administration",
            "leadership",
            "advanced excel features",
            "audit",
            "process improvement",
            "policy implementation",
            "data visualization",
            "quality data analysis",
            "american indian and alaska native communities",
            "community-based domestic violence/victim assistance programs",
            "human services",
            "social services",
            "direct client services",
            "battered women's movement knowledge"
        ]
    },
    "06dca8db8afd7888": {
        "terms": [
            "data science"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Director Data Engineering",
        "company": "Providence",
        "desc": "Description \n This position is remote with some in person meetings required and can only be located in the states of WA, OR, or CA. \n Leads highly technical data engineers. Accountable for all aspects of the technical design and build of modern data-centric solutions and applications to support clinical and operational processes across all parts of the enterprise health system. These solutions leverage cloud, big data, data science, and modern software development methodologies (such as SAFe) and tools and services (such as Snowflake and Databricks in Azure). Responsible for the buildout of our data engineering center of excellence for the enterprise and a community of practice across teams. Collaborates on technical solutions with teams at the Providence Global Center at Hyderabad, India. \n Providence caregivers are not simply valued \u2013 they\u2019re invaluable. Join our team at Enterprise Information Services and thrive in our culture of patient-focused, whole-person care built on understanding, commitment, and mutual respect. Your voice matters here, because we know that to inspire and retain the best people, we must empower them. \n Required Qualifications: \n \n Bachelor's Degree - Computer Engineering, Computer Science, Mathematics, Engineering. Or equivalent educ/experience, \n 10 or more years - Related experience in engineering or development roles. \n 8 years Leadership experience leading teams in a complex and fast-paced moving environment. \n Experience in cloud computing and data warehousing, Linux, Hadoop, Spark, and other NoSQL platforms. \n Strong experience working with both the product and technical sides of issues. \n Practical solutions development experience in a data-centric domain. \n Strong experience in managing and coaching a team of technical resources. \n \n Preferred Qualifications: \n \n Bachelor's Degree in Computer Science and Engineering, Mathematics, Engineering and related technical fields. \n \n The salary range listed for this position MIN:$79.20 to MAX:$131.66 per hour is based upon the primary work location Renton, WA posted. This position is remote. Salary range and offers are determined by internal pay equity and geographic cost of living differences. Salary range will vary from State and region. Salary max is limited to 75% range in order to continue to offer internal pay growth. We welcome open and transparent discussions on salary at Providence. \n Why Join Providence? \n Our best-in-class benefits are uniquely designed to support you and your family in staying well, growing professionally, and achieving financial security. We take care of you, so you can focus on delivering our Mission of caring for everyone, especially the most vulnerable in our communities. \n About Providence \n At Providence, our strength lies in Our Promise of \u201cKnow me, care for me, ease my way.\u201d Working at our family of organizations means that regardless of your role, we\u2019ll walk alongside you in your career, supporting you so you can support others. We provide best-in-class benefits and we foster an inclusive workplace where diversity is valued, and everyone is essential, heard and respected. Together, our 120,000 caregivers (all employees) serve in over 50 hospitals, over 1,000 clinics and a full range of health and social services across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. As a comprehensive health care organization, we are serving more people, advancing best practices and continuing our more than 100-year tradition of serving the poor and vulnerable. \n The amounts listed are the base pay range; additional compensation may be available for this role, such as shift differentials, standby/on-call, overtime, premiums, extra shift incentives, or bonus opportunities. \n Check out our benefits page for more information about our Benefits and Rewards. \n About the Team \n Providence Shared Services is a service line within Providence that provides a variety of functional and system support services for our family of organizations across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. We are focused on supporting our Mission by delivering a robust foundation of services and sharing of specialized expertise. \n We are committed to the principle that every workforce member has the right to work in surroundings that are free from all forms of unlawful discrimination and harassment. \n We are committed to cultural diversity and equal employment for all individuals. It is our policy to recruit, hire, promote, compensate, transfer, train, retain, terminate, and make all other employment-related decisions without regard to race, color, religious creed (including religious dress and grooming practices), national origin (including certain language use restrictions), ancestry, disability (mental and physical including HIV and AIDS), medical condition (including cancer and genetic characteristics), genetic information, marital status, age, sex (which includes pregnancy, childbirth, breastfeeding and related medical conditions), gender, gender identity, gender expression, sexual orientation, genetic information, and military and veteran status or any other applicable legally protected status. We will also provide reasonable accommodation to known physical or mental limitations of an otherwise qualified caregiver or applicant for employment, unless the accommodation would impose undue hardship on the operation of our business. \n We are a community where all people, regardless of differences, are welcome, secure, and valued. We value respect, appreciation, collaboration, diversity, and a shared commitment to serving our communities. We expect that all workforce members in our community will act in ways which reflect a commitment to and accountability for, racial and social justice and equality in the workplace. As such, we will maintain a workplace free of discrimination and harassment based on any applicable legally protected status. We also expect that all workforce members will maintain a positive workplace free from any unacceptable conduct which creates an intimidating, hostile, or offensive work environment. \n Requsition ID:  226882  \n Company:  Providence Jobs  \n Job Category:  Development/Engineering  \n Job Function:  Information Technology  \n Job Schedule:  Full time  \n Job Shift:  Day  \n Career Track:  Leadership  \n Department:  4011 SS IS HI DP 3  \n Address:  WA Renton 1801 Lind Ave SW  \n Work Location:  Providence Valley Office Park-Renton  \n Pay Range:  $79.20 - $131.66  \n The amounts listed are the base pay range; additional compensation may be available for this role, such as shift differentials, standby/on-call, overtime, premiums, extra shift incentives, or bonus opportunities.  \n Check out our benefits page for more information about our Benefits and Rewards. \n Providence is proud to be an Equal Opportunity Employer. Providence does not discriminate on the basis of race, color, gender, disability, veteran, military status, religion, age, creed, national origin, sexual identity or expression, sexual orientation, marital status, genetic information, or any other basis prohibited by local, state, or federal law.",
        "cleaned_desc": " 8 years Leadership experience leading teams in a complex and fast-paced moving environment. \n Experience in cloud computing and data warehousing, Linux, Hadoop, Spark, and other NoSQL platforms. \n Strong experience working with both the product and technical sides of issues. \n Practical solutions development experience in a data-centric domain. \n Strong experience in managing and coaching a team of technical resources. \n \n Preferred Qualifications: \n ",
        "techs": [
            "cloud computing",
            "data warehousing",
            "linux",
            "hadoop",
            "spark",
            "nosql platforms"
        ],
        "cleaned_techs": [
            "cloud computing",
            "data warehousing",
            "linux",
            "hadoop",
            "spark",
            "nosql"
        ]
    },
    "7558a840bfa4768d": {
        "terms": [
            "data science"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Director Data Engineering",
        "company": "Providence",
        "desc": "Description \n This position is remote with some in person meetings required and can only be located in the states of WA, OR, or CA. \n Leads highly technical data engineers. Accountable for all aspects of the technical design and build of modern data-centric solutions and applications to support clinical and operational processes across all parts of the enterprise health system. These solutions leverage cloud, big data, data science, and modern software development methodologies (such as SAFe) and tools and services (such as Snowflake and Databricks in Azure). Responsible for the buildout of our data engineering center of excellence for the enterprise and a community of practice across teams. Collaborates on technical solutions with teams at the Providence Global Center at Hyderabad, India. \n Providence caregivers are not simply valued \u2013 they\u2019re invaluable. Join our team at Enterprise Information Services and thrive in our culture of patient-focused, whole-person care built on understanding, commitment, and mutual respect. Your voice matters here, because we know that to inspire and retain the best people, we must empower them. \n Required Qualifications: \n \n Bachelor's Degree - Computer Engineering, Computer Science, Mathematics, Engineering. Or equivalent educ/experience, \n 10 or more years - Related experience in engineering or development roles. \n 8 years Leadership experience leading teams in a complex and fast-paced moving environment. \n Experience in cloud computing and data warehousing, Linux, Hadoop, Spark, and other NoSQL platforms. \n Strong experience working with both the product and technical sides of issues. \n Practical solutions development experience in a data-centric domain. \n Strong experience in managing and coaching a team of technical resources. \n \n Preferred Qualifications: \n \n Bachelor's Degree in Computer Science and Engineering, Mathematics, Engineering and related technical fields. \n \n The salary range listed for this position MIN:$79.20 to MAX:$131.66 per hour is based upon the primary work location Renton, WA posted. This position is remote. Salary range and offers are determined by internal pay equity and geographic cost of living differences. Salary range will vary from State and region. Salary max is limited to 75% range in order to continue to offer internal pay growth. We welcome open and transparent discussions on salary at Providence. \n Why Join Providence? \n Our best-in-class benefits are uniquely designed to support you and your family in staying well, growing professionally, and achieving financial security. We take care of you, so you can focus on delivering our Mission of caring for everyone, especially the most vulnerable in our communities. \n About Providence \n At Providence, our strength lies in Our Promise of \u201cKnow me, care for me, ease my way.\u201d Working at our family of organizations means that regardless of your role, we\u2019ll walk alongside you in your career, supporting you so you can support others. We provide best-in-class benefits and we foster an inclusive workplace where diversity is valued, and everyone is essential, heard and respected. Together, our 120,000 caregivers (all employees) serve in over 50 hospitals, over 1,000 clinics and a full range of health and social services across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. As a comprehensive health care organization, we are serving more people, advancing best practices and continuing our more than 100-year tradition of serving the poor and vulnerable. \n The amounts listed are the base pay range; additional compensation may be available for this role, such as shift differentials, standby/on-call, overtime, premiums, extra shift incentives, or bonus opportunities. \n Check out our benefits page for more information about our Benefits and Rewards. \n About the Team \n Providence Shared Services is a service line within Providence that provides a variety of functional and system support services for our family of organizations across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. We are focused on supporting our Mission by delivering a robust foundation of services and sharing of specialized expertise. \n We are committed to the principle that every workforce member has the right to work in surroundings that are free from all forms of unlawful discrimination and harassment. \n We are committed to cultural diversity and equal employment for all individuals. It is our policy to recruit, hire, promote, compensate, transfer, train, retain, terminate, and make all other employment-related decisions without regard to race, color, religious creed (including religious dress and grooming practices), national origin (including certain language use restrictions), ancestry, disability (mental and physical including HIV and AIDS), medical condition (including cancer and genetic characteristics), genetic information, marital status, age, sex (which includes pregnancy, childbirth, breastfeeding and related medical conditions), gender, gender identity, gender expression, sexual orientation, genetic information, and military and veteran status or any other applicable legally protected status. We will also provide reasonable accommodation to known physical or mental limitations of an otherwise qualified caregiver or applicant for employment, unless the accommodation would impose undue hardship on the operation of our business. \n We are a community where all people, regardless of differences, are welcome, secure, and valued. We value respect, appreciation, collaboration, diversity, and a shared commitment to serving our communities. We expect that all workforce members in our community will act in ways which reflect a commitment to and accountability for, racial and social justice and equality in the workplace. As such, we will maintain a workplace free of discrimination and harassment based on any applicable legally protected status. We also expect that all workforce members will maintain a positive workplace free from any unacceptable conduct which creates an intimidating, hostile, or offensive work environment. \n Requsition ID:  226882  \n Company:  Providence Jobs  \n Job Category:  Development/Engineering  \n Job Function:  Information Technology  \n Job Schedule:  Full time  \n Job Shift:  Day  \n Career Track:  Leadership  \n Department:  4011 SS IS HI DP 3  \n Address:  WA Renton 1801 Lind Ave SW  \n Work Location:  Providence Valley Office Park-Renton  \n Pay Range:  $79.20 - $131.66  \n The amounts listed are the base pay range; additional compensation may be available for this role, such as shift differentials, standby/on-call, overtime, premiums, extra shift incentives, or bonus opportunities.  \n Check out our benefits page for more information about our Benefits and Rewards. \n Providence is proud to be an Equal Opportunity Employer. Providence does not discriminate on the basis of race, color, gender, disability, veteran, military status, religion, age, creed, national origin, sexual identity or expression, sexual orientation, marital status, genetic information, or any other basis prohibited by local, state, or federal law.",
        "cleaned_desc": " 8 years Leadership experience leading teams in a complex and fast-paced moving environment. \n Experience in cloud computing and data warehousing, Linux, Hadoop, Spark, and other NoSQL platforms. \n Strong experience working with both the product and technical sides of issues. \n Practical solutions development experience in a data-centric domain. \n Strong experience in managing and coaching a team of technical resources. \n \n Preferred Qualifications: \n ",
        "techs": [
            "cloud computing",
            "data warehousing",
            "linux",
            "hadoop",
            "spark",
            "nosql platforms"
        ],
        "cleaned_techs": [
            "cloud computing",
            "data warehousing",
            "linux",
            "hadoop",
            "spark",
            "nosql"
        ]
    },
    "25e30d030d812198": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 230000.0,
        "salary_max": 290000.0,
        "title": "Chief Data Scientist",
        "company": "FourKites",
        "desc": "Chief Data Scientist  Remote, USA \n  At FourKites we have the opportunity to tackle complex challenges with real-world impacts. Whether it's medical supplies from Cardinal Health or groceries for Walmart, the FourKites platform helps customers operate global supply chains that are efficient, agile and sustainable. \n  Join a team of curious problem solvers that celebrates differences, leads with empathy and values inclusivity . \n  The  Chief Data Scientist  will spearhead our data science initiatives and drive innovations in data and AI. This strategic role will work across departments to harness the power of big data and machine learning, ensuring that our software remains at the cutting edge of the industry. This position will report to the Chief Technology Officer. \n  What you'll be doing: \n \n Lead, grow, and mentor the data science team, fostering a culture of excellence. \n Set the long-term vision and strategy for the data science function in alignment with company goals. \n Partner with product and engineering teams to integrate advanced machine learning algorithms into our software offerings. \n Drive the research and development of state-of-the-art algorithms and ensure that the data science initiatives add value to our customers and provide a competitive edge. \n Serve as the primary liaison between the data science team and other departments. \n Translate complex data insights into actionable strategies for executive and non-technical stakeholders. \n Foster cross-functional collaborations to maximize the impact of data science across the company. \n Oversee the full lifecycle of data science projects, ensuring timely delivery and high-quality outputs. \n Implement best practices for data processing, model development, validation, and deployment. \n Ensure proper infrastructure and tools are available for the data science team. \n Stay updated with the latest industry trends in big data and machine learning. \n Hands-on work is desirable, although not required \n \n About the team: \n  Our passionate global data science team has a mix of engineers with algorithm and engineering skills. Over the years the team has developed cutting-edge solutions for the supply chain industry, including our recent launches using Gen AI to improve user experience. \n  Who you are: \n \n Minimum of 15 years of experience in data science, machine learning or related fields, with at least 5 years in a leadership role. \n Proven experience in launching successful products with significant data science components and going through entire life cycle of model development \n Demonstrable expertise in building and deploying machine learning models \n Knowledge of data technologies and ML platforms \n Strong coding skills \n PhD or Master's degree in Computer Science, Statistics, Mathematics, or a related field. \n Familiarity with cloud platforms like AWS, Azure, or Google Cloud and their AI platforms \n A track record of thought leadership through publications, speaking engagements, or contributions to the data science community. \n \n We know that job postings can be intimidating, and research shows that while men apply to jobs when they meet an average of 60% of the criteria, women and other marginalized folks tend to only apply when they check every box. We encourage you to apply if you think you may be a fit and give us both a chance to find out! \n  Who we are: \n  FourKites\u00ae is the #1 supply chain visibility platform in the world, extending visibility beyond transportation into yards, warehouses, stores and beyond. Tracking more than 2.5 million shipments daily across road, rail, ocean, air, parcel and courier, and reaching over 185 countries, FourKites combines real-time data and powerful machine learning to help companies digitize their end-to-end supply chains. More than 1,000 of the world's most recognized brands \u2014 including 9 of the top-10 CPG and 18 of the top-20 food and beverage companies \u2014 trust FourKites to transform their business and create more agile, efficient and sustainable supply chains. \n  FourKites provides competitive compensation with stock options, outstanding benefits and a collaborative culture for all employees around the globe. To help you be your best, we have 5 global recharge days, in addition to standard holidays, and a hybrid, flexible approach to work. Parental leave for all parents, an annual wellness stipend and volunteer days also provide you with time and resources for self care and to care for others. Throughout the year, FourKites sets aside time during the workday to learn and celebrate diversity. And we're always listening for new ways to support everyone in and out of the office. \n  If you are a California resident, here is our California Applicant Privacy Notice. \n  If you are a European Union resident, here is our EU Applicant Privacy Notice. \n \n Salary range: $230,000.00 - $290,000.00 \n Medical, Dental & Vision benefits start on first day of employment \n 20 PTO days, 5 recharge days, 2 volunteer days \n Technology reimbursement \n Commuter benefits for in office employees (Chicago) \n Annual Wellness Stipend \n Ongoing learning & development opportunities",
        "cleaned_desc": " Drive the research and development of state-of-the-art algorithms and ensure that the data science initiatives add value to our customers and provide a competitive edge. \n Serve as the primary liaison between the data science team and other departments. \n Translate complex data insights into actionable strategies for executive and non-technical stakeholders. \n Foster cross-functional collaborations to maximize the impact of data science across the company. \n Oversee the full lifecycle of data science projects, ensuring timely delivery and high-quality outputs. \n Implement best practices for data processing, model development, validation, and deployment. \n Ensure proper infrastructure and tools are available for the data science team. \n Stay updated with the latest industry trends in big data and machine learning. \n Hands-on work is desirable, although not required   \n About the team: \n  Our passionate global data science team has a mix of engineers with algorithm and engineering skills. Over the years the team has developed cutting-edge solutions for the supply chain industry, including our recent launches using Gen AI to improve user experience. \n  Who you are: \n \n Minimum of 15 years of experience in data science, machine learning or related fields, with at least 5 years in a leadership role. \n Proven experience in launching successful products with significant data science components and going through entire life cycle of model development \n Demonstrable expertise in building and deploying machine learning models \n Knowledge of data technologies and ML platforms ",
        "techs": [
            "algorithms",
            "data science initiatives",
            "competitive edge",
            "data science team",
            "departments",
            "data insights",
            "strategies",
            "executive stakeholders",
            "non-technical stakeholders",
            "cross-functional collaborations",
            "data science projects",
            "timely delivery",
            "high-quality outputs",
            "best practices",
            "data processing",
            "model development",
            "validation",
            "deployment",
            "infrastructure",
            "tools",
            "industry trends",
            "big data",
            "machine learning",
            "global data science team",
            "engineers",
            "algorithm skills",
            "engineering skills",
            "supply chain industry",
            "gen ai",
            "user experience",
            "experience in data science",
            "machine learning",
            "leadership role",
            "launching successful products",
            "model development",
            "machine learning models",
            "data technologies",
            "ml platforms"
        ],
        "cleaned_techs": [
            "algorithms",
            "data science initiatives",
            "competitive edge",
            "data science team",
            "departments",
            "data insights",
            "strategies",
            "executive stakeholders",
            "non-technical stakeholders",
            "cross-functional collaborations",
            "data science projects",
            "timely delivery",
            "high-quality outputs",
            "model development",
            "validation",
            "deployment",
            "infrastructure",
            "tools",
            "industry trends",
            "big data",
            "global data science team",
            "engineers",
            "supply chain industry",
            "gen ai",
            "user experience",
            "experience in data science",
            "leadership role",
            "launching successful products",
            "data technologies",
            "ml platforms"
        ]
    },
    "93ce0fa2d914da5f": {
        "terms": [
            "data science",
            "mlops"
        ],
        "salary_min": 116975.45,
        "salary_max": 148116.98,
        "title": "Sr Data Scientist (A.I.)",
        "company": "Blackpoint Cyber",
        "desc": "Blackpoint Cyber is a provider of leading-edge cybersecurity threat hunting, detection, and response technology. Blackpoint was founded by former National Security Agency (NSA) cyber operations experts that applied their expertise to bring nation/state grade technologies to commercial customers around the world \n  What You\u2019ll Do  Blackpoint Cyber is a provider of leading-edge cybersecurity threat hunting, detection, and response technology. Blackpoint was founded by former National Security Agency (NSA) cyber operations experts that applied their expertise to bring nation/state grade technologies to commercial customers around the world.    We are looking for an experienced Sr. Data Scientist who will operate in a technical lead role for the data science function of our A.I. business unit. Candidates will directly support Blackpoint\u2019s cyber security mission, helping to stop cyber-attacks, and protecting Blackpoint\u2019s rapidly growing customer base.     Summary: \n  As Sr. Data Scientist, you will be responsible for building out Blackpoint Cyber\u2019s data science solutions to support development of our A.I. products and features. You will report directly to the Head of Artificial Intelligence.     Who You Are:  Blackpoint Cyber is looking for someone who has: \n \n  5+ years of experience in hands-on Data Science, with a track record of delivering A.I. products and services into production. \n  Experience building in the well-architected mindset\u2014for efficiency, performance, security, and reliability. \n  Strong analytical and problem-solving abilities, with a focus on data-driven decision-making. \n \n \n  Excellent communication and interpersonal skills, with the ability to influence and collaborate with stakeholders at all levels. \n \n  What You\u2019ll Bring: \n \n  Experienced in: \n \n \n  Cloud-based ML development (AWS) \n \n \n  Data Ingestion & Wrangling (S3, EC2, SageMaker) \n  Feature Engineering (Feature Pipelines, Feature Store) \n  Model Development, Analysis, & Deployment (SageMaker) \n  Inference Streams & Event-driven Processing (Kafka, Kinesis) \n  Scripting Language (Python, Bash) \n \n \n  Query Language (SQL, KsqlDB) \n  Containerized Services (Docker, Kubernetes) \n  MLOps Workflows (Sagemaker, MLFlow) \n  GitFlow & DevOps Best Practices \n \n \n  Nice to Have: \n \n \n  Time-Series Analysis \n  Transformer Neural Nets \n  Kubeflow \n  DVC (data versioning) \n  Agile Scrum \n \n \n  Programming (Java, Scala) \n  Experience in Cybersecurity, IoT, or NLP fields \n \n  How You\u2019ll Make an Impact: \n \n  Define, implement, train, and evaluate ML models. \n \n \n  Design and implement algorithms to ingest, wrangle, and transform model input data. \n  Conduct feature engineering to extract, construct, derive, and evaluate model inputs. \n  Perform statistical analyses per stakeholder requirements and modeling objectives. \n  Deploy models and feature engineering algorithms as scalable containerized solutions. \n  Develop model governance utilities and dashboards to monitor, report, and visualize performance of deployed solutions. \n \n \n  Implement data, feature, and model lifecycle best practices. \n  Contribute to A.I. architecture and design decisions. \n  Collaborate closely with cross-functional teams, including Engineering, Blackpoint Cyber\u2019s Security Operations Center (SOC), and our Adversary Pursuit Group (APG). \n \n  Interested? \n  To apply, please prepare a resume and cover letter. For more information about Blackpoint Cyber, visit our website at www.blackpointcyber.com. \n  Blackpoint Cyber welcomes and encourages applications from qualified individuals of all races, colors, religions, sex, sexual orientation, gender identity or expression, national origin, age, marital status, or any other legally protected status. We are committed to equality of opportunity in all aspects of employment. \n  We thank everyone for their interest, but only those candidates selected for an interview will be contacted. \n  Blackpoint\u2019s Response to COVID-19 \n  We take a very proactive response to COVID-19 with all staff working remotely from home. Hygiene protocols are in place throughout the building and office if there is a need to visit. Our company\u2019s systems and processes are set in such a manner that there should be no limitations to your productivity when working from home. We are in constant communication globally. During these challenging times, Blackpoint Cyber takes the opportunity to envision a new way of working together while continuing to collaborate meaningfully with those whom we serve and defend. \n  Blackpoint Cyber welcomes and encourages applications from qualified individuals of all races, colors, religions, sex, sexual orientation, gender identity or expression, national origin, age, marital status, or any other legally protected status. We are committed to equality of opportunity in all aspects of employment. \n  We thank everyone for their interest, but only those candidates selected for an interview will be contacted.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "c9507db15ed950fb": {
        "terms": [
            "data science"
        ],
        "salary_min": 97756.31,
        "salary_max": 123781.266,
        "title": "Data Scientist II - Workforce Surveys and Ana",
        "company": "GovStrive LLC",
        "desc": "Title:  Data Scientist II \u2013 Workforce Surveys and Analytics\n  \n \n  Location:  Remote\n  \n \n   Data Scientist II \u2013 Workforce Surveys and Analytics\n  \n \n   GovStrive is seeking a Data Scientist II who has experience with workforce surveys and analytics. The Data Scientist II will work with GovStrive personnel on several survey projects, including assessments of federal work environments, and evaluations of training and employee development programs. Typical project tasks include questionnaire design, sample design, survey administration, data preparation, statistical analysis, reporting, and meeting facilitation with clients.\n  \n \n  The Data Scientist II is a mid-level role at GovStrive. Successful candidates for this role must have the following skills: \n \n \n  Survey questionnaire design, with knowledge of best practices from the fields of econometrics, psychometrics, and general social sciences. \n  Sample design and implementation, including simple random, stratified, probability proportional to size, cluster, and convenience sampling. \n  Statistical analysis, including descriptive and inferential statistics, regression analysis, factor analysis, and topic modeling. \n  Technical writing and action planning based on survey results. \n  Project Management Office support, including development of critical pathways to project completion and project timelines. \n  Client management, including direct communications with clients regarding project timelines and deliverables, meeting facilitation, and briefings based on survey results. \n  Employee mentorship and development, including training junior employees in survey methods, statistical analysis, and project management office support. \n \n \n \n  Successful candidates for the Data Scientist II role must have the following education and experience: \n \n \n  Bachelor\u2019s degree in sociology, psychology, or economics and at least 4 years of experience with workforce surveys and analytics. \n  Master\u2019s degree in sociology, psychology, or economics and at least 2 years of experience with workforce surveys and analytics. \n  Doctorate in sociology, psychology, or economics with training in survey research and quantitative methods. \n \n \n \n   Candidates with a history of successful project experience in workforce surveys and analytics are preferred. \n \n \n  Additional Required Education and Experience: \n \n \n  Bachelor\u2019s Degree and 4+ years of experience, or a MA/PhD in social science or statistics. \n  US Citizenship is required. \n \n \n \n  Your growth \n \n \n   GovStrive is dedicated to helping you grow professionally. We want to help you learn and grow throughout your career. We do this by aligning your personal development with GovStrive\u2019s growth, and ongoing communication between you and your supervisor to ensure alignment.\n  \n \n  EEO Statement \n \n \n \n  GovStrive is an equal-opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. All aspects of employment including the decision to hire, promote, discipline, or discharge, will be based on merit, competence, performance, and business needs. GovStrive does not discriminate in employment on the basis of \n   age, disability, ethnicity, gender, gender identity and expression, religion, sexual orientation, or protected veteran status.",
        "cleaned_desc": " \n \n \n  Successful candidates for the Data Scientist II role must have the following education and experience: \n \n \n  Bachelor\u2019s degree in sociology, psychology, or economics and at least 4 years of experience with workforce surveys and analytics. \n  Master\u2019s degree in sociology, psychology, or economics and at least 2 years of experience with workforce surveys and analytics. \n  Doctorate in sociology, psychology, or economics with training in survey research and quantitative methods. \n \n ",
        "techs": [
            "none"
        ],
        "cleaned_techs": []
    },
    "aa10151ab9747275": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 70000.0,
        "salary_max": 110000.0,
        "title": "Machine Learning Support Engineer",
        "company": "Labelbox",
        "desc": "Labelbox is the leading data-centric AI platform for building intelligent applications. Teams looking to capitalize on the latest advances in generative AI and LLMs use the Labelbox platform to inject these systems with the right degree of human supervision and automation. Whether they are building AI products by using LLMs that require human fine-tuning, or applying AI to reduce the time associated with manually-intensive tasks like data labeling or finding business insights, Labelbox enables teams to do so effectively and quickly. \n  Current Labelbox customers are transforming industries within insurance, retail, manufacturing/robotics, healthcare, and beyond. Our platform is used by Fortune 500 enterprises including Walmart, Procter & Gamble, Genentech, and Adobe, as well as hundreds of leading AI teams. We are backed by leading investors including SoftBank, Andreessen Horowitz, B Capital, Gradient Ventures (Google's AI-focused fund), Databricks Ventures, Snowpoint Ventures and Kleiner Perkins. \n \n About the Role \n  As a Machine Learning Support Engineer, you\u2019ll act as the frontline of customer love, utilizing live chat and internal resources to resolve product issues and provide proactive guidance to customers. \n  As Labelbox continues to grow, we often have multiple openings for this role. Should your skills and experience align with our requirements and timeline, our team will reach out to you as soon as opportunities become available on this team. \n  Your Day to Day \n \n Create great experiences for our customers when they need help. Build trust and advisory relationships with customers to help them better use the product. \n Learn Labelbox's product at a deep level and help customers do the same. Learn what\u2019s happening next with the product, and help customers prepare for the use of new features. \n Go beyond the question being asked; understand how our customers define their own success with the product and help them work toward that success. \n Proactively propose creative solutions to address customers\u2019 business problems and goals. \n Be a voice for our customers during internal discussions and projects at Labelbox. Represent their needs and struggles to help drive our products in a strong direction. \n Monitor and identify trends in customer experiences. Work within the team and with other teams at Labelbox to give customers the information and tools they need to more effectively and efficiently support themselves in the use of the product. \n \n About You \n \n 1+ years experience on a Technical Support team \n BA/BS in Computer Science/Engineering degree \n Proficient in Python \n Experience with Machine Learning a plus \n An ability to navigate and advise on efforts related to complex customer requests or projects, gathering additional human resources for assistance if needed \n Empathy, patience, phenomenal people skills; \n An ability to learn quickly to understand and articulate new technologies and corresponding value propositions \n Outstanding organizational skills and ability to multitask in order to effectively prioritize and manage workflow \n A creative problem solver who isn\u2019t afraid to get their hands dirty \n Ability to quickly pick up a variety of software applications with ease \n Experience with common support software like Intercom, GitHub, Jira, etc \n \n Labelbox strives to ensure pay parity across the organization and discuss compensation transparently. The expected annual base salary range for United States-based candidates   is $70,000 - $110,000. This range is not inclusive of any potential equity packages or additional benefits. Exact compensation varies based on a variety of factors, including skills and competencies, experience, and geographical location. \n \n Excel in a Hub-centric Remote Model. \n  We\u2019re committed to excellence and understand the importance of bringing our talented people together. While we continue to embrace remote work, we\u2019ve transitioned to a Hub-Centric Remote Model with a focus on nurturing collaboration and connection within our dedicated hubs in the San Francisco Bay Area, New York City Metropolitan Area, Miami-Fort Lauderdale Area, and Warsaw, Poland. We encourage asynchronous communication, autonomy, and ownership of your tasks, with the added convenience of hub-based gatherings. \n  Your Personal Data Privacy:  Any personal information you provide Labelbox as a part of your application will be processed in accordance with Labelbox\u2019s Job Applicant Privacy notice. \n  Any emails from Labelbox team members will originate from a @labelbox.com email address. If you encounter anything that raises suspicions during your interactions, we encourage you to exercise caution and suspend or discontinue communications. If you are uncertain about the legitimacy of any communication you have received, please do not hesitate to reach out to us at recruiting@labelbox.com for clarification and verification. \n \n \n  #LI-Hybrid",
        "cleaned_desc": " An ability to navigate and advise on efforts related to complex customer requests or projects, gathering additional human resources for assistance if needed \n Empathy, patience, phenomenal people skills; \n An ability to learn quickly to understand and articulate new technologies and corresponding value propositions \n Outstanding organizational skills and ability to multitask in order to effectively prioritize and manage workflow \n A creative problem solver who isn\u2019t afraid to get their hands dirty \n Ability to quickly pick up a variety of software applications with ease \n Experience with common support software like Intercom, GitHub, Jira, etc ",
        "techs": [
            "intercom",
            "github",
            "jira"
        ],
        "cleaned_techs": [
            "intercom",
            "github",
            "jira"
        ]
    },
    "869a65b714ec19d3": {
        "terms": [
            "data science"
        ],
        "salary_min": 17.0,
        "salary_max": 17.0,
        "title": "Welcome Specialist",
        "company": "Ashfield Nordic AB",
        "desc": "Inizio Engage has a long-standing partnership with a leading Biotechnology company, across Commercial, Patient Solutions and Medical Affairs businesses.\n  \n \n \n   This is your opportunity to join Ashfield and represent a top Patient Engagement Project on a temporary basis.\n  \n \n   Project Length: 2 Months\n  \n \n   Salary: $17/hr\n  \n \n \n   What\u2019s in it for you?\n  \n \n  Competitive compensation \n  Excellent Benefits \u2013 accrued time off, medical, dental, vision, 401k, disability & life insurance, paid maternity and bonding time benefits, employee discounts/promotions \n  Generous performance-driven Incentive Compensation package \n  Competitive environment with company wide recognition, contests, and coveted awards \n  Exceptional company culture \n  Recognized as a Top Workplace USA 2021 \n  Awarded a \u201cGreat Place to Work\u201d award in 2022 and 2023 \n  Fortune Best Workplaces in Biopharma 2022 \n \n \n \n  What will you be doing?\n  \n \n  Maintain excellent quality standards for all client programs; adhere to program scripts and guidelines. Accurately collect information required by individual programs and correctly capture in specific program databases. \n  Exhibit effective communication and tele-management skills. \n  Converse with callers in an empathetic manner and facilitate the callers in their ability to understand medical terminology, as needed. \n  Possess effective organizational skills, including working with multiple projects simultaneously. \n  Adhere to all company policies and Standard Operating Procedures. \n  Display flexibility within department to maximize utilization, including performing administrative and non-telecommunication duties as needed. \n  Must safeguard patient privacy and confidentiality by following the guidelines set forth in the Privacy and Security Rules of the Health Insurance Portability and Accountability Act (HIPAA). \n \n \n \n  What do you need for this position?\n  \n \n  High School Diploma, or equivalent work-related experience required. \n  Excellent verbal, written and listening communication skills. \n  Competency with a computer keyboard and mouse. \n  Pleasant telephone manner. \n  All Amgen Welcome specialists are expected to consistently maintain the ability to join frequent meetings and calls without disruption and actively participate. \n  Must have a designated separate home office space that is quiet and away from distractions \n \n \n \n  About Inizio Engage\n  \n \n \n  Inizio Engage is a strategic, commercial, and creative engagement partner that specializes in healthcare. Our passionate, global workforce augments local expertise and diverse mix of skills with data, science, and technology to deliver bespoke engagement solutions that help clients reimagine how they engage with their patients, payers, people and providers to improve treatment outcomes. Our mission is to partner with our clients, improving lives by helping healthcare professionals and patients get the medicines, knowledge and support they need.\n  \n \n \n   We believe in our values: We empower everyone/We rise to the challenge/We work as one/We ask what if/We do the right thing, and we will ask you how your personal values align to them.\n  \n \n \n   To learn more about Inizio Engage, visit us at: \n   \n   https://inizio.health/\n   \n \n \n   Inizio Engage is proud to be an equal opportunity employer. Individuals seeking employment at Inizio are considered without regards to age, ancestry, color, gender, gender identity or expression, genetic information, marital status, medical condition (including pregnancy, childbirth, or related medical conditions), mental or physical disability, national origin, protected family care or medical leave status, race, religion (including beliefs and practices or the absence thereof), sexual orientation, military or veteran status, or any other characteristic protected by federal, state, or local laws. Further, pursuant to applicable local ordinances, Inizio will consider for employment qualified applicants with arrest and conviction records.\n  \n \n \n   Inizio Engage is an equal opportunity employer M/F/V/D. We appreciate your interest in our company, however, only qualified candidates will be considered.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "f4affe49efbae33c": {
        "terms": [
            "data science"
        ],
        "salary_min": 230000.0,
        "salary_max": 325000.0,
        "title": "VP, Customer Excellence (REMOTE)",
        "company": "Sears Home Services",
        "desc": "JOB SCOPE: \n  The VP, Customer Excellence will lead the Customer Service Operations team by owning and developing the operational culture, customer service processes and performance improvement initiatives that drive operational efficiencies for the customer experience and developing a customer service team that consistently provides effective customer interactions across multiple service channels (Telephone, Email, Online, Live Chat, Video, Social Media) for the Sears Home Services organization.\n     \n \n JOB SUMMARY: \n  The VP, Customer Excellence is a strategic business partner and operational leader who is responsible for the development and delivery of a WOW customer experience for the Sears Home Services business. The Customer Excellence Leader, SHS develops and implements operational processes and procedures to meet key service outcomes for Home Services customer relationships. The Customer Excellence Leader, SHS establishes effective business partnerships with internal/external stakeholders, support functions and drives continuous improvement initiatives by identifying operational requirements, including personnel development and technology/resource needs for both B2B and B2C businesses. The role has significant levels of responsibility and accountability for operational delivery of customer experience across multiple customer channels.\n    \n \n \n Responsibilities/Skills/Experience Requirements \n \n JOB DUTIES/RESPONSIBILITIES: \n \n  Develops clear and accountable performance measures to drive continuous performance improvement / Create a culture and processes which achieve the business goals and objectives with regards to customer experience \n  Identifies new tools and technologies to better serve the customer & drive better sales through service, enhancing the processes that are currently in place for customer service resolution \n  Identifies improvements through the use of Customer Insight data and Root Cause Analytics to present to Home Services Leadership for adoption with internal and external business partners \n  Owns full regulatory compliance and legal requirements along with identifying any potential business risks \n  Defines and negotiates utilization of company resources in line with service specifications & works effectively with all peers and stakeholders to negotiate and influence customer experience improvements \n  Coordinates Customer Quality Issue responses between sales and product management \n  Evaluates and continuously improves customer experience operations for Sears Home Services by identifying cost savings by driving quality and consistency \n  Builds predictive models to anticipate customer behavior, product demand, and market trends \n  Utilizes data science methodologies to analyze customer data, behavior, and feedback to gain deep insights into customer preferences, pain points, and trends \n  Leads and manages customer excellence team by providing feedback through 1:1s, effective use of personal development plans and provision of coaching & development opportunities \n  Performs supervisory functions, including but not limited to, making employment decisions regarding hiring, promoting, demoting and terminating, conducting performance appraisals and coaching and developing associates \n \n \n  REQUIRED SKILLS: \n \n  In-depth understanding of customer service, operations, and some selling experience \n  Demonstrates and leads a culture that advocate as the \"Voice of the Customer\" across the organization \n  Strong interpersonal and communication (written & oral) skills to interact effectively with all levels; both within and outside of the organization \n  Ability to interface and influence individuals and organizations outside of span of direct control and at all levels \n  Strong decision-making, problem solving, negotiation & conflict resolution skills \n  Highly skilled in problem solving and analysis, conveys innovative ideas and can communicate complex theories and issues to senior levels of management \n  Strong background in data science, including experience with statistical analysis, machine learning, and predictive modeling \n  Ability to develop short term strategic plans that easily translate into long term solutions and/or cohesive strategies \n  Project management, planning and process improvement experience \n  Extensive management experience including developing, mentoring and coaching a team of associates \n \n \n  PREFERRED SKILLS: \n \n  Master's degree in a relevant field, such as Data Science, Business Analytics, Marketing, or a related discipline \n \n \n \n \n Years Experience \n \n    10 - 15 Years Experience\n    \n \n \n Travel Requirements \n \n    Moderate (15-30%) \n    \n \n \n Country \n \n    United States \n    \n \n \n Work-In Address 1 \n \n    REMOTE\n    \n \n \n Work-In City \n \n    REMOTE\n    \n \n \n Work-In State \n \n    REMOTE\n    \n \n \n Work-In Postal Code \n \n    REMOTE\n    \n \n \n Business \n \n    Transformco Home Services - Strategy \n    \n \n \n Job Function \n \n    Call Center \n    \n \n \n Employment Category \n \n    Regular, Full-time \n    \n \n \n Compensation Range \n \n    230k - 325k\n    \n \n \n Additional Compensation Explanation \n \n    N/A \n    \n \n \n EEO/EOE Footer \n \n    Equal Opportunity Employer / Disability / Vet.\n    \n \n \n Posting Tags \n \n    #HSCorporate \n    \n \n \n Company Brand \n \n    Sears Home Services \n    \n \n \n Location City \n \n    Hoffman Estates",
        "cleaned_desc": " \n  In-depth understanding of customer service, operations, and some selling experience \n  Demonstrates and leads a culture that advocate as the \"Voice of the Customer\" across the organization \n  Strong interpersonal and communication (written & oral) skills to interact effectively with all levels; both within and outside of the organization \n  Ability to interface and influence individuals and organizations outside of span of direct control and at all levels \n  Strong decision-making, problem solving, negotiation & conflict resolution skills \n  Highly skilled in problem solving and analysis, conveys innovative ideas and can communicate complex theories and issues to senior levels of management \n  Strong background in data science, including experience with statistical analysis, machine learning, and predictive modeling \n  Ability to develop short term strategic plans that easily translate into long term solutions and/or cohesive strategies \n  Project management, planning and process improvement experience \n  Extensive management experience including developing, mentoring and coaching a team of associates \n \n \n  PREFERRED SKILLS: \n \n  Master's degree in a relevant field, such as Data Science, Business Analytics, Marketing, or a related discipline \n \n \n \n \n Years Experience \n \n    10 - 15 Years Experience\n    \n \n \n Travel Requirements ",
        "techs": [
            "none"
        ],
        "cleaned_techs": []
    },
    "662ae79b124722a5": {
        "terms": [
            "data science"
        ],
        "salary_min": 97463.0,
        "salary_max": 123409.875,
        "title": "Brokerage Ops Specialist",
        "company": "Cash App",
        "desc": "Company Description\n   It all started with an idea at Block in 2013. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic ecosystem, developing unique financial products, including Afterpay/Clearpay, to provide a better way to send, spend, invest, borrow and save to our 47 million monthly active customers. We want to redefine the world\u2019s relationship with money to make it more relatable, instantly available, and universally accessible.    Today, Cash App has thousands of employees working globally across office and remote locations, with a culture geared toward innovation, collaboration and impact. We\u2019ve been a distributed team since day one, and many of our roles can be done remotely from the countries where Cash App operates. No matter the location, we tailor our experience to ensure our employees are creative, productive, and happy.    Check out our locations, benefits, and more at cash.app/careers. \n \n \n \n Job Description\n   We've recently introduced Cash App Investing and now you can instantly buy stock in your favorite companies with as little as $1 using our free fractional trading feature! We're looking for a world class talent to join our broker-dealer subsidiary, Cash App Investing LLC. The ideal candidate for this role is someone who has deep experience in brokerage operations. \n  You will: \n \n  This role is within the account operations team at Cash App Investing and reports to the brokerage operations accounts lead. \n  Provide subject matter expertise on strategic initiatives related to brokerage functions. \n  Document standard operating procedures and job aids and update as needed. \n  Identify areas for process improvement and work toward implementation with respective teams. \n  Scale processes to operate broker-dealer. \n  Willing to work and get comfortable with ambiguity in a fast paced environment. \n  Works closely with peers to provide support in functional areas of operation and provides feedback \n  Reviews and actions accounts in accordance with firm policy and procedure. \n  Assist in establish controls, metrics, and data in partnership with Data Science for Brokerage operational use. \n  Collaborates with lead, peers, and cross functional teams to identify areas of opportunity and risks. \n  Performs and completes daily operational processing functions and maintains records in accordance with firms Written Supervisory Procedures and operational processes. \n  High-level understanding of SEC / FINRA regulations that pertain to the subject matter. \n  Collaborates with engineering, support, and product teams to facilitate improvements and increase efficiency within the current back office structure for the broker-dealer\u2019s risk operation. \n \n \n \n \n Qualifications\n   You have: \n \n  5+ years of experience in brokerage operations. \n  Active FINRA Licenses: Series 7 & 63 required. \n  Fundamental SQL knowledge/experience \n  Functional experience with Looker / Tableau or other data analytics tools. \n  Brokerage operations generalist, you have worked in various functions of a brokerage operations team which may include accounts, risk, fraud, trading, etc. \n  Knowledge and respect for SEC/FINRA regulatory and compliance rules and regulations. \n  Well versed in collaborating with peer disciplines such as Product, Engineering, Data Science, Compliance etc \n  Technical experience scaling processes or managing projects. \n  Highly organized and detail oriented. \n  Someone who thrives in a highly collaborative and fast-paced environment. \n  Excellent verbal and written communication skills. \n  A passion for our mission of economic empowerment through serving the underserved \n \n  Additional Information\n   Block takes a market-based approach to pay, and pay may vary depending on your location. U.S. locations are categorized into one of four zones based on a cost of labor index for that geographic area. The successful candidate\u2019s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. These ranges may be modified in the future.    Zone A: USD $94,400 - USD $115,400  Zone B: USD $87,800 - USD $107,400  Zone C: USD $80,300 - USD $98,100  Zone D: USD $70,800 - USD $86,600 \n \n  To find a location\u2019s zone designation, please refer to this resource. If a location of interest is not listed, please speak with a recruiter for additional information. \n  Full-time employee benefits include the following: \n \n  Healthcare coverage (Medical, Vision and Dental insurance) \n  Health Savings Account and Flexible Spending Account \n  Retirement Plans including company match \n  Employee Stock Purchase Program \n  Wellness programs, including access to mental health, 1:1 financial planners, and a monthly wellness allowance \n  Paid parental and caregiving leave \n  Paid time off (including 12 paid holidays) \n  Paid sick leave (1 hour per 26 hours worked (max 80 hours per calendar year to the extent legally permissible) for non-exempt employees and covered by our Flexible Time Off policy for exempt employees) \n  Learning and Development resources \n  Paid Life insurance, AD&D, and disability benefits \n  Additional Perks such as WFH reimbursements and free access to caregiving, legal, and discounted resources \n \n  These benefits are further detailed in Block's policies. This role is also eligible to participate in Block's equity plan subject to the terms of the applicable plans and policies, and may be eligible for a sign-on bonus. Sales roles may be eligible to participate in a commission plan subject to the terms of the applicable plans and policies. Pay and benefits are subject to change at any time, consistent with the terms of any applicable compensation or benefit plans. \n  US and Canada EEOC Statement \n  We\u2019re working to build a more inclusive economy where our customers have equal access to opportunity, and we strive to live by these same values in building our workplace. Block is a proud equal opportunity employer. We work hard to evaluate all employees and job applicants consistently, without regard to race, color, religion, gender, national origin, age, disability, pregnancy, gender expression or identity, sexual orientation, citizenship, or any other legally protected class. \n  We believe in being fair, and are committed to an inclusive interview experience, including providing reasonable accommodations to disabled applicants throughout the recruitment process. We encourage applicants to share any needed accommodations with their recruiter, who will treat these requests as confidentially as possible.  Want to learn more about what we\u2019re doing to build a workplace that is fair and square? Check out our  I+D page . \n  Additionally, we consider qualified applicants with criminal histories for employment on our team, and always assess candidates on an individualized basis. \n \n \n  Block, Inc. (NYSE: SQ) is a global technology company with a focus on financial services. Made up of Square, Cash App, Spiral, TIDAL, and TBD, we build tools to help more people access the economy. Square helps sellers run and grow their businesses with its integrated ecosystem of commerce solutions, business software, and banking services. With Cash App, anyone can easily send, spend, or invest their money in stocks or Bitcoin. Spiral (formerly Square Crypto) builds and funds free, open-source Bitcoin projects. Artists use TIDAL to help them succeed as entrepreneurs and connect more deeply with fans. TBD is building an open developer platform to make it easier to access Bitcoin and other blockchain technologies without having to go through an institution.",
        "cleaned_desc": " Qualifications\n   You have: \n \n  5+ years of experience in brokerage operations. \n  Active FINRA Licenses: Series 7 & 63 required. \n  Fundamental SQL knowledge/experience \n  Functional experience with Looker / Tableau or other data analytics tools. \n  Brokerage operations generalist, you have worked in various functions of a brokerage operations team which may include accounts, risk, fraud, trading, etc. \n  Knowledge and respect for SEC/FINRA regulatory and compliance rules and regulations. \n  Well versed in collaborating with peer disciplines such as Product, Engineering, Data Science, Compliance etc \n  Technical experience scaling processes or managing projects. \n  Highly organized and detail oriented. \n  Someone who thrives in a highly collaborative and fast-paced environment. ",
        "techs": [
            "sql",
            "looker",
            "tableau"
        ],
        "cleaned_techs": [
            "sql",
            "looker",
            "tableau"
        ]
    },
    "5fe5dfd4869c4077": {
        "terms": [
            "data science"
        ],
        "salary_min": 95562.61,
        "salary_max": 121003.56,
        "title": "Data Scientist",
        "company": "Frankenmuth Insurance Company",
        "desc": "Summary:  Under direct supervision and following standard procedures, applies advanced analytical techniques to complex data sets to develop distinctive analytical and risk insights that deliver improvements in business results; structures business challenges/opportunities for data sourcing, insight generation, and testing; and generates distinctive analytical and risk insights while working with one or more business units such as Personal Lines, Commercial Lines, Claims, IT and Marketing, by performing the following duties. \n \n \n Essential Duties and Responsibilities: \n  1. Understands ratemaking and reserving actuarial principles and researches and applies those principles to business problems. \n 2. Acts as a strong contributor to distinctive analytical and risk insights within the Actuarial, Risk, & Compliance Services team by: \n a. Understanding and structuring business challenges and opportunities for insights \n b. Generating insights, drawing from a broad range of sources and functions \n c. Scanning a broad spectrum of internal/external, structured/unstructured data sources to define the optimal data set for testing the hypotheses, and partnering across the organization to connect these data sources to build the data set \n d. Presenting insights and recommendations to business units \n e. Establishing and maintaining collaborative relationships throughout the organization \n \n  3. Tests and validates hypotheses to generate risk insights that can deliver improved business results. \n 4. Assists with synthesizing risk insights into compelling ideas and messages. \n 5. Assists with the development of improvements to analytical techniques for generating insight. \n 6. Assists with the preparation of internal/external, structured/unstructured data sets to build and refresh predictive models. \n 7. Maintains a working knowledge of loss reserving software and rate modeling software. \n 8. Performs other duties as assigned. \n \n \n Qualifications: \n  To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. \n \n \n Education/Experience: \n  Bachelor\u2019s degree (B.A.) from four-year college or university; or one to two years of internship experience and/or training; or equivalent combination of education and experience. \n \n  A minimum requirement for this position is the ability to work legally in the United States. No visa sponsorship/support is available for this position, including for any type of U.S. permanent residency (green card) process.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "ab76eabfab7148ce": {
        "terms": [
            "data science",
            "data engineer"
        ],
        "salary_min": 118813.57,
        "salary_max": 150444.45,
        "title": "Data Engineer-Contract",
        "company": "Sia Partners",
        "desc": "Company Description\n   Sia Partners is a next-generation consulting firm focused on delivering superior value and tangible results to its clients as they navigate the digital revolution. Our global footprint and expertise in more than 40 sectors and services allow us to enhance our clients\u2019 businesses worldwide. We guide their projects and initiatives in strategy, business transformation, IT & digital strategy, and Data Science. \n \n \n \n Job Description\n   We are currently seeking a Data Engineer with experience in collaborating with cross-functional teams to identify compliance-related data requirements and translate them into actionable insights on behalf of one of our premier banking clients. \n  Location: Remote/PST Time Zone Perferred \n  Project Length: 4 months \n  Responsibilities: \n \n  Collaborate with cross-functional teams to identify compliance-related data requirements and translate them into actionable insights. \n  Conduct comprehensive analysis of complex data sets to identify trends, anomalies, and potential compliance risks. \n  Heavy use of Excel spreadsheets, Power BI or other visualization software. \n  Design and implement efficient data pipelines, integrating data from various sources. \n  Ensure data quality, accuracy, and consistency by implementing data cleansing, validation, and transformation processes. \n  Collaborate with IT teams to optimize data storage, access, and retrieval for compliance reporting and monitoring. \n  Write complex SQL queries to extract, transform, and load data into relevant tables for analysis. \n  Utilize SQL queries to perform in-depth analysis, identify trends, discrepancies, potential issues, or problems related to compliance data. \n  Develop and maintain SQL scripts for routine data processing and reporting tasks. \n  Experience and familiarity with compliance software such as Verafin, and Actimize. \n  Ability to leverage knowledge of compliance tools to enhance data analysis, monitoring, and reporting processes. \n  Collaborate with IT and compliance teams to integrate and leverage these tools effectively. \n  Generate ad hoc reports from Core system and Fraud detection software as requested. \n  Maintain thorough documentation of data sources, methodologies, and processes to support audit and regulatory inquiries. \n  Identify opportunities to streamline compliance processes through automation and innovative use of technology. \n  Work closely with stakeholders to understand their needs and pain points, and propose data-driven solutions to enhance compliance efficiency. \n  Engage in effective communication with team members, management, and stakeholders to share insights, findings, and progress on compliance initiatives. \n \n \n \n \n Qualifications\n  \n \n  Bachelor's degree in Business, Finance, Computer Science, or a related field. \n  Proven experience (7+ years) as a Business Analyst, Data Engineer, or similar role within the financial industry, with a strong focus on compliance and regulatory matters. \n  MUST have prior banking/financial industry experience-BSA/AML is highly desirable. \n  Proficiency in writing complex SQL queries to extract, transform, and load data, as well as perform detailed analysis for trends, discrepancies, and potential compliance issues. \n  Hands-on experience with data visualization tools (e.g. Power BI) to create meaningful reports and dashboards as needed. \n  MUST have familiarity with compliance software (Verafin, Actimize) is desirable. \n  Understanding of cloud platforms (Azure, GCP) for data storage, processing, and analysis is a plus. \n  Scripting languages (Powershell, Power Automate, Python \n  Knowledge of cloud platforms (Azure, GCP) for data analysis and management is a plus. Familiarity with regulatory frameworks and requirements in the financial sector. \n  Strong problem-solving skills and an analytical mindset, coupled with the ability to translate complex data into actionable insights. \n  Excellent communication skills, both written and verbal, to effectively interact with technical and non-technical stakeholders. \n  Ease in leading presentations to stakeholders in a remote environment through Teams or Zoo \n \n  Additional Information\n   Our Commitment to Diversity \n  Diversity, equity, inclusion, and belonging (DEIB) are part of Sia Partners\u2019 DNA. Thanks to our expertise in several sectors and our international growth, our teams include a variety of experiences and cultures. We\u2019re confident that promoting DEIB creates an environment in which everyone can reach their full potential. \n  Our global network, DEIB@Sia Partners, brings together our people worldwide to facilitate local and global progress, focused on the following areas: \n \n  Gender equality (global Gender Equality Index score of 91/100 for FY19-20) \n  LGBTQ+ \n  Race & Ethnicity \n  Working Parents \n  Disabilities \n \n  Sia Partners is an equal opportunity employer. All aspects of employment, including hiring, promotion, remuneration, or discipline, are based solely on performance, competence, conduct, or business needs.    To learn more about our mission, values, and business sectors, please visit our website. \n \n  Sia Partners is an equal opportunity employer. All aspects of employment, including hiring, promotion, remuneration, or discipline, are based solely on performance, competence, conduct, or business needs.",
        "cleaned_desc": "  Conduct comprehensive analysis of complex data sets to identify trends, anomalies, and potential compliance risks. \n  Heavy use of Excel spreadsheets, Power BI or other visualization software. \n  Design and implement efficient data pipelines, integrating data from various sources. \n  Ensure data quality, accuracy, and consistency by implementing data cleansing, validation, and transformation processes. \n  Collaborate with IT teams to optimize data storage, access, and retrieval for compliance reporting and monitoring. \n  Write complex SQL queries to extract, transform, and load data into relevant tables for analysis. \n  Utilize SQL queries to perform in-depth analysis, identify trends, discrepancies, potential issues, or problems related to compliance data. \n  Develop and maintain SQL scripts for routine data processing and reporting tasks. \n  Experience and familiarity with compliance software such as Verafin, and Actimize. \n  Ability to leverage knowledge of compliance tools to enhance data analysis, monitoring, and reporting processes. \n  Collaborate with IT and compliance teams to integrate and leverage these tools effectively. \n  Generate ad hoc reports from Core system and Fraud detection software as requested.    Proven experience (7+ years) as a Business Analyst, Data Engineer, or similar role within the financial industry, with a strong focus on compliance and regulatory matters. \n  MUST have prior banking/financial industry experience-BSA/AML is highly desirable. \n  Proficiency in writing complex SQL queries to extract, transform, and load data, as well as perform detailed analysis for trends, discrepancies, and potential compliance issues. \n  Hands-on experience with data visualization tools (e.g. Power BI) to create meaningful reports and dashboards as needed. \n  MUST have familiarity with compliance software (Verafin, Actimize) is desirable. \n  Understanding of cloud platforms (Azure, GCP) for data storage, processing, and analysis is a plus. \n  Scripting languages (Powershell, Power Automate, Python \n  Knowledge of cloud platforms (Azure, GCP) for data analysis and management is a plus. Familiarity with regulatory frameworks and requirements in the financial sector. \n  Strong problem-solving skills and an analytical mindset, coupled with the ability to translate complex data into actionable insights. \n  Excellent communication skills, both written and verbal, to effectively interact with technical and non-technical stakeholders. \n  Ease in leading presentations to stakeholders in a remote environment through Teams or Zoo \n ",
        "techs": [
            "excel spreadsheets",
            "power bi",
            "visualization software",
            "data pipelines",
            "data cleansing",
            "data validation",
            "data transformation",
            "sql queries",
            "compliance software (verafin",
            "actimize)",
            "core system",
            "fraud detection software",
            "business analyst",
            "data engineer",
            "sql",
            "data visualization tools (power bi)",
            "cloud platforms (azure",
            "gcp)",
            "scripting languages (powershell",
            "power automate",
            "python)",
            "regulatory frameworks",
            "problem-solving skills",
            "analytical mindset",
            "communication skills",
            "presentations"
        ],
        "cleaned_techs": [
            "excel",
            "powerbi",
            "visualization software",
            "data pipelines",
            "data cleansing",
            "data validation",
            "data transformation",
            "compliance software (verafin",
            "actimize)",
            "core system",
            "fraud detection software",
            "data engineer",
            "sql",
            "data visualization tools (power bi)",
            "cloud platforms (azure",
            "gcp",
            "scripting languages (powershell",
            "power automate",
            "python",
            "analytical mindset",
            "presentations"
        ]
    },
    "51c92c1e604e0abd": {
        "terms": [
            "data science"
        ],
        "salary_min": 120000.0,
        "salary_max": 135000.0,
        "title": "Economist - Health Researcher (Remote Eligible)",
        "company": "Mathematica Policy Research",
        "desc": "Position Description:     \n About the opportunity \n  Mathematica economists and health researchers collaborate with staff to design rigorous methods for evaluating programs and policies, conduct analyses, draft reports, present findings to policy and professional audiences, and publish in professional journals. A qualified researcher should have strong analytic and quantitative skills and possess a Ph.D. in economics or a related field by Spring 2024. They should also have a strong interest in working in a collaborative, multidisciplinary environment that emphasizes quality, rigor, critical thinking, objectivity, diversity and inclusion, equity, and professional development. Excellent written and oral communication skills are essential. Experience in policy research is a plus. \n \n \n \n Position Requirements:     \n \n Ph.D. or equivalent in economics, public health, epidemiology, public policy, health services research, social sciences, or other relevant discipline. \n  Strong foundation in quantitative research methods and a broad understanding of health policy issues. \n  Excellent written and oral communication skills, including an ability to translate research findings for a policy audience. \n  Ability to work well in teams. \n \n  To Apply for the Health Economist Position    A cover letter, CV, and writing sample and/or job market paper must be submitted at the time of application via our online application system.     Letters of reference should be emailed to HumanResources@mathematica-mpr.com. \n  Application Submission Deadline: November 27th, 2023 @ 12PM EST     Complete application packages that are submitted before 12pm EST on November 27th, 2023 will be considered.    Mathematica will be conducting virtual interviews starting December 11th 2023. \n  Additional information \n  This position offers an anticipated base salary of $120,000 - $135,000 annually. This position is eligible for an annual bonus based on company and individual performance.    Available locations: Washington, DC; Princeton, NJ; Cambridge, MA; Chicago, IL; Oakland, CA; Remote    We welcome applications from candidates who wish to work remotely/virtually full-time.   \n About Mathematica    Mathematica applies expertise at the intersection of data, methods, policy, and practice to improve well-being around the world. We collaborate closely with public- and private-sector partners to translate big questions into deep insights that improve programs, refine strategies, and enhance understanding using data science and analytics. Our work yields actionable information to guide decisions in wide-ranging policy areas, from health, education, early childhood, and family support to nutrition, employment, disability, and international development. Mathematica offers our employees competitive salaries, and a comprehensive benefits package, as well as the advantages of being 100 percent employee owned. As an employee stock owner, you will experience financial benefits of ESOP holdings that have increased in tandem with the company\u2019s growth and financial strength. You will also be part of an independent, employee-owned firm that is able to define and further our mission, enhance our quality and accountability, and steadily grow our financial strength. Read more about our benefits here: https://www.mathematica.org/career-opportunities/benefits-at-a-glance   \n \n \n \n We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "28c42433320651d6": {
        "terms": [
            "data science"
        ],
        "salary_min": 73240.61,
        "salary_max": 92738.94,
        "title": "Manager, Project Training and Quality",
        "company": "Ashfield Nordic AB",
        "desc": "Inizio Engage has a long-standing partnership with a leading Biotechnology company, across Commercial, Patient Solutions and Medical Affairs businesses.\n  \n \n \n   Assist with client-specific QA initiatives including training, monitoring quality review including analysis of aggregate quality/performance data, maintenance of SOPs as well as creation/updates to training materials based on quality reviews, etc. Assist with project specific or company-wide QA work such as management of employee training documentation, audit preparation, document review/editing and filing. Responsible for identifying training needs, developing procedures and training Inizio staff and management, including ongoing refresher training and project specific training.\n  \n \n \n   This is your opportunity to join Inizio Engage and represent a top biotechnology company!\n  \n \n \n   What\u2019s in it for you?\n  \n \n \n  Competitive compensation \n  Excellent Benefits \u2013 accrued time off, medical, dental, vision, 401k, disability & life insurance, paid maternity and bonding time benefits, employee discounts/promotions \n  Generous performance-driven Incentive Compensation package \n  Competitive environment with company wide recognition, contests, and coveted awards \n  Exceptional company culture \n  Recognized as a Top Workplace USA 2021 \n  Awarded a \u201cGreat Place to Work\u201d award in 2022 and 2023 \n  Fortune Best Workplaces in Biopharma 2022 \n \n \n \n   What will you be doing?\n  \n \n \n  Work with the Project team, Client Account Management Team and Quality Assurance departments to develop and enhance client trainings resulting in improved customer satisfaction, quality of service and compliance with Inizio and Client standards of excellence. \n  Perform ongoing call quality monitoring and scoring in coordination with the Client Account Management Team \n  Define and document training plans, schedules and requirements. Design, develop and revise training and instructional materials for classroom use, ad-hoc and/or self-administered training. Provide ongoing and refresher training for project team. \n  Make recommendations on the best methodology and implementation methods for training programs. Formulate teaching outline and determine instructional methods such as individual training, group instruction, lectures, demonstrations, conferences, meetings and workshops. \n  Test trainees to measure progress and to evaluate effectiveness of training. \n  Review and interpret documents such as Client program procedure manuals and training modules. Interpret and translate to staff instructions furnished in written, oral, diagram, or schedule form. \n  Perform monitoring of services for assigned project and/or Quality Assurance Department. Provide constructive coaching feedback to staff with goal of improving overall customer experience. \n  Coordinate quality review calibration sessions with Client Account Management Team, Project team and Client, if applicable. \n  Compile QA data and prepare reports as necessary; analyze results and make recommendations including revisions to procedural documents and training documents as applicable. \n  Assist with annual review and ongoing updates for Client Standard Operating Procedure (SOP). \n  Assist with internal and external client audits as dictated in the Inizio Quality Management Plan. \n  Assist with any/all quality activities and reporting as requested by the Client, Business Unit Director, Vice President, Operational Excellence & Quality Assurance and/or the Manager, Quality Monitoring. \n  Perform project training certifications and complete appropriate documentation. \n  Manage QMS training records. \n  File training materials in an organized manner for efficient access by staff. \n  Perform general clerical duties. \n  Must safeguard patient privacy and confidentiality by following the guidelines set forth in the Privacy and Security Rules of the Health Insurance Portability and Accountability Act (HIPAA). \n \n \n \n  What do you need for this position?\n  \n \n \n  Bachelor\u2019s degree is required. \n  Minimum of 1-2 years relevant experience in a healthcare setting is required. \n  Ability to read and understand data and file layouts. \n  Proficient in Microsoft Outlook, Word, Excel and PowerPoint. \n  Ability to deliver feedback to employees in a constructive manner. \n  Strong organizational and analytical skills, as well as critical thinking and problem-solving skills. \n  Ability to multitask. \n  Critical thinking and problem-solving skills. \n  Detail oriented. \n  Ability to develop and proof training materials. \n  Ability to speak effectively in interpersonal situations and before groups of employees. \n  Ability to work as a team in a supportive environment to achieve shared objectives. \n  Ability to function in a leadership capacity and as a positive role model. \n  Excellent listening skills in order to identify and anticipate training needs. \n  Proven presentation and facilitation skills. \n \n \n \n  About Inizio Engage\n  \n \n \n  Inizio Engage is a strategic, commercial, and creative engagement partner that specializes in healthcare. Our passionate, global workforce augments local expertise and diverse mix of skills with data, science, and technology to deliver bespoke engagement solutions that help clients reimagine how they engage with their patients, payers, people and providers to improve treatment outcomes. Our mission is to partner with our clients, improving lives by helping healthcare professionals and patients get the medicines, knowledge and support they need.\n  \n \n \n   To learn more about Inizio Engage, visit us at: \n   \n   https://inizio.health/\n   \n \n \n \n   We believe in our values: We empower everyone/We rise to the challenge/We work as one/We ask what if/We do the right thing, and we will ask you how your personal values align to them.\n  \n \n \n   Inizio Engage is proud to be an equal opportunity employer. Individuals seeking employment at Inizio are considered without regards to age, ancestry, color, gender, gender identity or expression, genetic information, marital status, medical condition (including pregnancy, childbirth, or related medical conditions), mental or physical disability, national origin, protected family care or medical leave status, race, religion (including beliefs and practices or the absence thereof), sexual orientation, military or veteran status, or any other characteristic protected by federal, state, or local laws. Further, pursuant to applicable local ordinances, Inizio will consider for employment qualified applicants with arrest and conviction records.\n  \n \n \n   Inizio Engage is an equal opportunity employer M/F/V/D. We appreciate your interest in our company, however, only qualified candidates will be considered.",
        "cleaned_desc": "  Ability to read and understand data and file layouts. \n  Proficient in Microsoft Outlook, Word, Excel and PowerPoint. \n  Ability to deliver feedback to employees in a constructive manner. \n  Strong organizational and analytical skills, as well as critical thinking and problem-solving skills. \n  Ability to multitask. \n  Critical thinking and problem-solving skills. \n  Detail oriented. \n  Ability to develop and proof training materials. \n  Ability to speak effectively in interpersonal situations and before groups of employees. \n  Ability to work as a team in a supportive environment to achieve shared objectives. \n  Ability to function in a leadership capacity and as a positive role model. \n  Excellent listening skills in order to identify and anticipate training needs. \n  Proven presentation and facilitation skills. \n \n \n \n  About Inizio Engage\n  \n ",
        "techs": [
            "ability to read and understand data and file layouts",
            "microsoft outlook",
            "word",
            "excel and powerpoint",
            "strong organizational and analytical skills",
            "critical thinking and problem-solving skills",
            "multitasking",
            "detail-oriented",
            "ability to develop and proof training materials",
            "ability to speak effectively in interpersonal situations and before groups of employees",
            "ability to work as a team",
            "leadership capacity",
            "positive role model",
            "excellent listening skills",
            "proven presentation and facilitation skills."
        ],
        "cleaned_techs": [
            "microsoft outlook",
            "word",
            "excel",
            "multitasking",
            "detail-oriented",
            "leadership capacity",
            "positive role model"
        ]
    },
    "4eb3da80458c4c7f": {
        "terms": [
            "data science",
            "data engineer"
        ],
        "salary_min": 100000.0,
        "salary_max": 200000.0,
        "title": "Forward Deployed Data Engineer - Remote",
        "company": "Reality Defender",
        "desc": "** No firms - we cannot work with firms due to regulatory reasons.** \n \n \n \n  Reality Defender seeks a forward deployed data engineer to join the Data Engineering team. You would work on product-oriented data infrastructure development for in-the-wild deepfake media detection, with an emphasis on engaging directly with clients and facilitating communication between technical and non-technical teams.\n  \n \n \n  #LI-Remote\n  \n Responsibilities \n \n  Building scalable robust infrastructure for data ingestion, storage, and sampling. \n  Communicate complex technical concepts effectively to client executives, ensuring alignment between technical implementations and organizational objectives. \n  Develop custom data tools tailored to meet specific client requirements, including adapting internally developed solutions to meet clients' needs. \n  Create and maintain comprehensive technical documentation, including APIs, algorithms, and system architecture. \n  Provide technical support to resolve complex issues escalated from customer support teams. Collaborate with cross-functional teams to diagnose and troubleshoot production incidents, and report results back to the customer in clear non-technical language. \n \n  Requirements \n \n  We encourage candidates who may not meet all the specified requirements to still apply. We value diverse perspectives and skills, and believe that unique experiences can contribute significantly to our team. If you are passionate about the role and confident in your ability to make a meaningful impact, we welcome your application. Your enthusiasm, adaptability, and potential for growth are equally important to us. Please use your cover letter to elaborate on how your background and experience make you an ideal fit for this role! \n \n \n \n  Required \n \n \n  3+ years of professional experience in software/data science and a bachelor's or master's degree in computer science, engineering, math, or STEM discipline. \n  Strong communication skills. \n  Proficiency in Python, NodeJs, Typescript, with a strong emphasis on adapting scalable software solutions to customer needs. \n  Database experience, particularly NoSQL databases (MongoDB, DynamoDB, etc). \n \n \n \n  Nice to have \n \n \n  Interest in data exploration, visualization, cleaning, and analytics for real-world data modeling. \n  Solid understanding of linear algebra, statistics and deep learning concepts. \n  Experience working with audio, visual, and/or text datasets and models. \n  Experience with AWS, Google Cloud, Azure, and On-Premises. \n  Experience working with very large databases and deep learning APIs, including Pandas, PyTorch, PySpark, etc.  \n Highly organized, detail-oriented, and possess a proven ability to thrive under deadline pressure. \n \n \n \n  Additional Requirements \n \n \n  Willing to work extended hours when needed. \n  Willing to occasionally work from or travel to client\u2019s location.",
        "cleaned_desc": "  Database experience, particularly NoSQL databases (MongoDB, DynamoDB, etc). \n \n \n \n  Nice to have \n \n \n  Interest in data exploration, visualization, cleaning, and analytics for real-world data modeling. \n  Solid understanding of linear algebra, statistics and deep learning concepts. \n  Experience working with audio, visual, and/or text datasets and models.    Experience with AWS, Google Cloud, Azure, and On-Premises. \n  Experience working with very large databases and deep learning APIs, including Pandas, PyTorch, PySpark, etc.  \n Highly organized, detail-oriented, and possess a proven ability to thrive under deadline pressure. \n \n \n \n  Additional Requirements \n \n \n  Willing to work extended hours when needed. ",
        "techs": [
            "nosql databases (mongodb",
            "dynamodb)\naws",
            "google cloud",
            "azure\npandas",
            "pytorch",
            "pyspark"
        ],
        "cleaned_techs": [
            "nosql",
            "dynamodb)\naws",
            "gcp",
            "azure",
            "pytorch",
            "pyspark"
        ]
    },
    "ff26a54c3c85993f": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 109085.59,
        "salary_max": 138126.67,
        "title": "Generative Artificial Intelligence engineer",
        "company": "RNXT CORPORATION",
        "desc": "Position: Generative Artificial Intelligence engineer \n Location: Atlanta, GA (Remote) \n Duration: Long Term Contract \n Responsibilities: \n \u00b7 Collaborate closely with customer stakeholders to understand their requirements, goals, and expectations for generative AI solutions. \n \u00b7 Design, develop, and implement generative AI architectures, models, and solutions that meet customer needs and align with industry best practices. \n \u00b7 Work cross-functionally with other teams, including data engineers, software developers, and project managers, to ensure the successful delivery of end-to-end AI projects. \n \u00b7 Lead the decision-making process for technical and architectural choices, ensuring that solutions are scalable, maintainable, and cost-effective. \n \u00b7 Communicate effectively with both technical and non-technical stakeholders, translating complex AI concepts into clear, understandable language. \n \u00b7 Provide expert guidance and advice as a consultant to help customers maximize the value of their generative AI investments. \n \u00b7 Monitor and evaluate the performance of generative AI models, identify areas for improvement, and implement strategies to optimize solutions. \n \u00b7 Stay current with the latest advancements in generative AI, machine learning, and related technologies, and incorporate new ideas and techniques into the team's work. \n \u00b7 Mentor and guide junior team members in adopting generative AI technologies and best practices. \n Required Skills: \n \u00b7 Experience in a customer-facing role or in a role requiring close collaboration with clients. \n \u00b7 Familiarity with Databricks, ML Flow, Driver H20 and Azure cloud ecosystem. \n \u00b7 Strong expertise in generative AI techniques, such as GANs, VAEs, and Transformer models. \n \u00b7 Proficiency in popular AI/ML frameworks and libraries, such as TensorFlow, PyTorch, Keras, and scikit-learn. \n \u00b7 Experience in designing, developing, and implementing end-to-end AI solutions for real-world applications. \n \u00b7 Excellent communication and interpersonal skills, with the ability to work effectively with diverse stakeholders. \n \u00b7 Strong decision-making and problem-solving abilities, with a focus on pragmatic and efficient solutions. \n \u00b7 Experience in consulting, with a proven track record of providing actionable advice and guidance to customers. \n \u00b7 A bachelor's degree in computer science, engineering, or a related field. A master's degree or higher is preferred. \n Nice-to-Have Skills: \n \u00b7 Knowledge of Agile/Scrum methodologies and project management practices. \n Job Type: Contract \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n Vision insurance \n \n Work Location: Remote",
        "cleaned_desc": " \u00b7 Work cross-functionally with other teams, including data engineers, software developers, and project managers, to ensure the successful delivery of end-to-end AI projects. \n \u00b7 Lead the decision-making process for technical and architectural choices, ensuring that solutions are scalable, maintainable, and cost-effective. \n \u00b7 Communicate effectively with both technical and non-technical stakeholders, translating complex AI concepts into clear, understandable language. \n \u00b7 Provide expert guidance and advice as a consultant to help customers maximize the value of their generative AI investments. \n \u00b7 Monitor and evaluate the performance of generative AI models, identify areas for improvement, and implement strategies to optimize solutions. \n \u00b7 Stay current with the latest advancements in generative AI, machine learning, and related technologies, and incorporate new ideas and techniques into the team's work.   \u00b7 Mentor and guide junior team members in adopting generative AI technologies and best practices. \n Required Skills: \n \u00b7 Experience in a customer-facing role or in a role requiring close collaboration with clients. \n \u00b7 Familiarity with Databricks, ML Flow, Driver H20 and Azure cloud ecosystem. \n \u00b7 Strong expertise in generative AI techniques, such as GANs, VAEs, and Transformer models. \n \u00b7 Proficiency in popular AI/ML frameworks and libraries, such as TensorFlow, PyTorch, Keras, and scikit-learn.   \u00b7 Experience in designing, developing, and implementing end-to-end AI solutions for real-world applications. \n \u00b7 Excellent communication and interpersonal skills, with the ability to work effectively with diverse stakeholders. \n \u00b7 Strong decision-making and problem-solving abilities, with a focus on pragmatic and efficient solutions. \n \u00b7 Experience in consulting, with a proven track record of providing actionable advice and guidance to customers. \n \u00b7 A bachelor's degree in computer science, engineering, or a related field. A master's degree or higher is preferred. \n Nice-to-Have Skills: ",
        "techs": [
            "databricks",
            "ml flow",
            "driver h20",
            "azure cloud ecosystem",
            "tensorflow",
            "pytorch",
            "keras",
            "scikit-learn"
        ],
        "cleaned_techs": [
            "databricks",
            "ml flow",
            "driver h20",
            "azure",
            "tensorflow",
            "pytorch",
            "keras",
            "scikit-learn"
        ]
    },
    "44d756c604d503df": {
        "terms": [
            "data science"
        ],
        "salary_min": 75.0,
        "salary_max": 81.0,
        "title": "Machine Learning Developer",
        "company": "Real Soft, Inc.",
        "desc": "Job Description:  \n \n Experience in Python Development. Integration with APIs and Databases. \n AI/ML coding expertise, developing applications and APIs leverage data & AI models. \n LLM and GenAI is a plus \n \n #IND123 \n Job Types: Contract, Full-time \n Pay: $75.00 - $81.00 per hour \n Expected hours: 40 per week \n Schedule: \n \n 8 hour shift \n Day shift \n Monday to Friday \n \n Experience: \n \n Python: 3 years (Required) \n Machine learning: 5 years (Required) \n artificial intelligence: 1 year (Required) \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "a84efc431d16e17f": {
        "terms": [
            "data science"
        ],
        "salary_min": 72254.4,
        "salary_max": 91490.164,
        "title": "Manager, Project Training and Quality",
        "company": "Inizio Engage",
        "desc": "Inizio Engage has a long-standing partnership with a leading Biotechnology company, across Commercial, Patient Solutions and Medical Affairs businesses.\n  \n \n \n   Assist with client-specific QA initiatives including training, monitoring quality review including analysis of aggregate quality/performance data, maintenance of SOPs as well as creation/updates to training materials based on quality reviews, etc. Assist with project specific or company-wide QA work such as management of employee training documentation, audit preparation, document review/editing and filing. Responsible for identifying training needs, developing procedures and training Inizio staff and management, including ongoing refresher training and project specific training.\n  \n \n \n   This is your opportunity to join Inizio Engage and represent a top biotechnology company!\n  \n \n \n   What\u2019s in it for you?\n  \n \n \n  Competitive compensation \n  Excellent Benefits \u2013 accrued time off, medical, dental, vision, 401k, disability & life insurance, paid maternity and bonding time benefits, employee discounts/promotions \n  Generous performance-driven Incentive Compensation package \n  Competitive environment with company wide recognition, contests, and coveted awards \n  Exceptional company culture \n  Recognized as a Top Workplace USA 2021 \n  Awarded a \u201cGreat Place to Work\u201d award in 2022 and 2023 \n  Fortune Best Workplaces in Biopharma 2022 \n \n \n \n   What will you be doing?\n  \n \n \n  Work with the Project team, Client Account Management Team and Quality Assurance departments to develop and enhance client trainings resulting in improved customer satisfaction, quality of service and compliance with Inizio and Client standards of excellence. \n  Perform ongoing call quality monitoring and scoring in coordination with the Client Account Management Team \n  Define and document training plans, schedules and requirements. Design, develop and revise training and instructional materials for classroom use, ad-hoc and/or self-administered training. Provide ongoing and refresher training for project team. \n  Make recommendations on the best methodology and implementation methods for training programs. Formulate teaching outline and determine instructional methods such as individual training, group instruction, lectures, demonstrations, conferences, meetings and workshops. \n  Test trainees to measure progress and to evaluate effectiveness of training. \n  Review and interpret documents such as Client program procedure manuals and training modules. Interpret and translate to staff instructions furnished in written, oral, diagram, or schedule form. \n  Perform monitoring of services for assigned project and/or Quality Assurance Department. Provide constructive coaching feedback to staff with goal of improving overall customer experience. \n  Coordinate quality review calibration sessions with Client Account Management Team, Project team and Client, if applicable. \n  Compile QA data and prepare reports as necessary; analyze results and make recommendations including revisions to procedural documents and training documents as applicable. \n  Assist with annual review and ongoing updates for Client Standard Operating Procedure (SOP). \n  Assist with internal and external client audits as dictated in the Inizio Quality Management Plan. \n  Assist with any/all quality activities and reporting as requested by the Client, Business Unit Director, Vice President, Operational Excellence & Quality Assurance and/or the Manager, Quality Monitoring. \n  Perform project training certifications and complete appropriate documentation. \n  Manage QMS training records. \n  File training materials in an organized manner for efficient access by staff. \n  Perform general clerical duties. \n  Must safeguard patient privacy and confidentiality by following the guidelines set forth in the Privacy and Security Rules of the Health Insurance Portability and Accountability Act (HIPAA). \n \n \n \n  What do you need for this position?\n  \n \n \n  Bachelor\u2019s degree is required. \n  Minimum of 1-2 years relevant experience in a healthcare setting is required. \n  Ability to read and understand data and file layouts. \n  Proficient in Microsoft Outlook, Word, Excel and PowerPoint. \n  Ability to deliver feedback to employees in a constructive manner. \n  Strong organizational and analytical skills, as well as critical thinking and problem-solving skills. \n  Ability to multitask. \n  Critical thinking and problem-solving skills. \n  Detail oriented. \n  Ability to develop and proof training materials. \n  Ability to speak effectively in interpersonal situations and before groups of employees. \n  Ability to work as a team in a supportive environment to achieve shared objectives. \n  Ability to function in a leadership capacity and as a positive role model. \n  Excellent listening skills in order to identify and anticipate training needs. \n  Proven presentation and facilitation skills. \n \n \n \n  About Inizio Engage\n  \n \n \n  Inizio Engage is a strategic, commercial, and creative engagement partner that specializes in healthcare. Our passionate, global workforce augments local expertise and diverse mix of skills with data, science, and technology to deliver bespoke engagement solutions that help clients reimagine how they engage with their patients, payers, people and providers to improve treatment outcomes. Our mission is to partner with our clients, improving lives by helping healthcare professionals and patients get the medicines, knowledge and support they need.\n  \n \n \n   To learn more about Inizio Engage, visit us at: \n   \n   https://inizio.health/\n   \n \n \n \n   We believe in our values: We empower everyone/We rise to the challenge/We work as one/We ask what if/We do the right thing, and we will ask you how your personal values align to them.\n  \n \n \n   Inizio Engage is proud to be an equal opportunity employer. Individuals seeking employment at Inizio are considered without regards to age, ancestry, color, gender, gender identity or expression, genetic information, marital status, medical condition (including pregnancy, childbirth, or related medical conditions), mental or physical disability, national origin, protected family care or medical leave status, race, religion (including beliefs and practices or the absence thereof), sexual orientation, military or veteran status, or any other characteristic protected by federal, state, or local laws. Further, pursuant to applicable local ordinances, Inizio will consider for employment qualified applicants with arrest and conviction records.\n  \n \n \n   Inizio Engage is an equal opportunity employer M/F/V/D. We appreciate your interest in our company, however, only qualified candidates will be considered.",
        "cleaned_desc": "  Ability to read and understand data and file layouts. \n  Proficient in Microsoft Outlook, Word, Excel and PowerPoint. \n  Ability to deliver feedback to employees in a constructive manner. \n  Strong organizational and analytical skills, as well as critical thinking and problem-solving skills. \n  Ability to multitask. \n  Critical thinking and problem-solving skills. \n  Detail oriented. \n  Ability to develop and proof training materials. \n  Ability to speak effectively in interpersonal situations and before groups of employees. \n  Ability to work as a team in a supportive environment to achieve shared objectives. \n  Ability to function in a leadership capacity and as a positive role model. \n  Excellent listening skills in order to identify and anticipate training needs. \n  Proven presentation and facilitation skills. \n \n \n \n  About Inizio Engage\n  \n ",
        "techs": [
            "ability to read and understand data and file layouts",
            "microsoft outlook",
            "word",
            "excel and powerpoint",
            "strong organizational and analytical skills",
            "critical thinking and problem-solving skills",
            "multitasking ability",
            "detail-oriented",
            "ability to develop and proof training materials",
            "ability to speak effectively in interpersonal situations and before groups of employees",
            "ability to work as a team",
            "ability to function in a leadership capacity and as a positive role model",
            "excellent listening skills",
            "proven presentation and facilitation skills."
        ],
        "cleaned_techs": [
            "microsoft outlook",
            "word",
            "excel",
            "multitasking ability",
            "detail-oriented"
        ]
    },
    "7fbc55056826972d": {
        "terms": [
            "data science"
        ],
        "salary_min": 17.0,
        "salary_max": 17.0,
        "title": "Welcome Specialist",
        "company": "Inizio Engage",
        "desc": "Inizio Engage has a long-standing partnership with a leading Biotechnology company, across Commercial, Patient Solutions and Medical Affairs businesses.\n  \n \n \n \n    This is your opportunity to join Ashfield and represent a top Patient Engagement Project on a temporary basis.\n   \n \n    Project Length: 2 Months\n   \n \n    Salary: $17/hr\n   \n \n \n    What\u2019s in it for you?\n   \n \n \n  Competitive compensation \n  Excellent Benefits \u2013 accrued time off, medical, dental, vision, 401k, disability & life insurance, paid maternity and bonding time benefits, employee discounts/promotions \n  Generous performance-driven Incentive Compensation package \n  Competitive environment with company wide recognition, contests, and coveted awards \n  Exceptional company culture \n  Recognized as a Top Workplace USA 2021 \n  Awarded a \u201cGreat Place to Work\u201d award in 2022 and 2023 \n  Fortune Best Workplaces in Biopharma 2022 \n \n \n \n  What will you be doing?\n   \n \n \n  Maintain excellent quality standards for all client programs; adhere to program scripts and guidelines. Accurately collect information required by individual programs and correctly capture in specific program databases. \n  Exhibit effective communication and tele-management skills. \n  Converse with callers in an empathetic manner and facilitate the callers in their ability to understand medical terminology, as needed. \n  Possess effective organizational skills, including working with multiple projects simultaneously. \n  Adhere to all company policies and Standard Operating Procedures. \n  Display flexibility within department to maximize utilization, including performing administrative and non-telecommunication duties as needed. \n  Must safeguard patient privacy and confidentiality by following the guidelines set forth in the Privacy and Security Rules of the Health Insurance Portability and Accountability Act (HIPAA). \n \n \n \n  What do you need for this position?\n   \n \n \n  High School Diploma, or equivalent work-related experience required. \n  Excellent verbal, written and listening communication skills. \n  Competency with a computer keyboard and mouse. \n  Pleasant telephone manner. \n  All Amgen Welcome specialists are expected to consistently maintain the ability to join frequent meetings and calls without disruption and actively participate. \n  Must have a designated separate home office space that is quiet and away from distractions \n \n \n \n  About Inizio Engage\n   \n \n \n  Inizio Engage is a strategic, commercial, and creative engagement partner that specializes in healthcare. Our passionate, global workforce augments local expertise and diverse mix of skills with data, science, and technology to deliver bespoke engagement solutions that help clients reimagine how they engage with their patients, payers, people and providers to improve treatment outcomes. Our mission is to partner with our clients, improving lives by helping healthcare professionals and patients get the medicines, knowledge and support they need.\n   \n \n \n    To learn more about Inizio Engage, visit us at: \n    \n    https://inizio.health/\n    \n \n \n \n    We believe in our values: We empower everyone/We rise to the challenge/We work as one/We ask what if/We do the right thing, and we will ask you how your personal values align to them.\n   \n \n \n    Inizio Engage is proud to be an equal opportunity employer. Individuals seeking employment at Inizio are considered without regards to age, ancestry, color, gender, gender identity or expression, genetic information, marital status, medical condition (including pregnancy, childbirth, or related medical conditions), mental or physical disability, national origin, protected family care or medical leave status, race, religion (including beliefs and practices or the absence thereof), sexual orientation, military or veteran status, or any other characteristic protected by federal, state, or local laws. Further, pursuant to applicable local ordinances, Inizio will consider for employment qualified applicants with arrest and conviction records.\n   \n \n \n    Inizio Engage is an equal opportunity employer M/F/V/D. We appreciate your interest in our company, however, only qualified candidates will be considered.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "3d85e33ea693d217": {
        "terms": [
            "data science"
        ],
        "salary_min": 100000.0,
        "salary_max": 200000.0,
        "title": "Forward Deployment AI Engineer - Remote",
        "company": "Reality Defender",
        "desc": "About The Role\n  \n \n   Reality Defender seeks an AI engineer to work on product-oriented cutting-edge deep learning approaches for audio or computer vision generative deepfake media detection.\n  \n \n \n  Responsibilities\n  \n \n Work on deepfake detection and classification problems. \n \n \n   - Independently implement and deploy deep learning solutions on modern deep learning stack - Python, PyTorch, and GPU-enabled cloud compute, like AWS.\n  \n \n Collaborate with scientists and engineers across the organization. \n \n \n \n  About You\n  \n \n MS or equivalent experience in computer science, or a related field. \n In-depth understanding of deep learning research in audio synthesis or computer vision and deep learning using neural networks CNNs, Transformers, etc. \n You have implemented papers from top research venues CVPR, InterSpeech, etc. \n Excellent software engineering skills. \n Team player with a positive attitude and good communication skills. \n \n \n \n  #LI-Remote",
        "cleaned_desc": " \n   - Independently implement and deploy deep learning solutions on modern deep learning stack - Python, PyTorch, and GPU-enabled cloud compute, like AWS.\n  \n \n Collaborate with scientists and engineers across the organization. \n ",
        "techs": [
            "python",
            "pytorch",
            "aws"
        ],
        "cleaned_techs": [
            "python",
            "pytorch",
            "aws"
        ]
    },
    "f585ca18b3263352": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 85000.0,
        "salary_max": 130000.0,
        "title": "Software Engineer, Machine Learning",
        "company": "Packback Inc",
        "desc": "Packback is looking for a Software Engineer to support our mission to awaken and fuel the lifelong curiosity in every student. As a software engineer at Packback, you will be building features that empower students and professors to have a better learning experience. \n \n  Packback\u2019s A.I.-powered platform is used by educators in K-12 and higher education to help their students fall in love with the subject matter, drive personalized learning, and most importantly, quantify and improve student critical thinking skills. \n  Key job duties include communicating well, providing thoughtful feedback to teammates, pairing, actively improving our team knowledge-base, and of course, writing code. You\u2019ll be improving our Python APIs that power Packback\u2019s AI, supporting the integration of machine learning models in our web application, and incrementally improving our infrastructure and CI/CD pipeline. \n  Why You Should Work at Packback \n  Reach  - Our platform, Packback Questions, is used by more than 10 thousand educators and 1.5 million students, who collectively author more than 10 million posts a year. You will be a part of building a platform that has a huge impact on inspiring curiosity in students. \n  Training  - We offer opportunities for learning and mentorship. We value people who like to wear many hats. You can get involved with the front end, back end, infrastructure and data functions. \n  Ownership  - Packback is a rapidly growing company. You will have responsibility for bringing innovative features to market while working closely with the product team. \n  Want to learn more about engineering at Packback? Check out our docs repo on Github. \n  Requirements \n  We\u2019re looking for somebody who is excited to work on our backend, infrastructure, and data science codebases. To succeed, you should have solid experience in backend engineering within a modern web application (We use Django and focus on NLP, but care mainly that you are a great developer). \n  Additionally, we\u2019re looking for: \n \n A strong grasp on Python fundamentals, experience writing both functional and object oriented code with an emphasis on performance \n  Demonstrated experience doing backend web development using a modern web framework such as Django (or some other equivalent MVC framework) \n  Extensive experience writing thorough unit and integration tests in Python \n  2+ years of software engineering experience, especially with web-based products. However, transferable experience is more important than years of experience. \n \n It's great if you have \n \n Strong SQL skills \n  Experience building, validating, and deploying machine learning models in a production environment (NLP experience is a bonus) \n  Experience working on highly scalable cloud infrastructures \n  Comfort with Linux/UNIX systems \n \n \n Comfort with Infrastructure as Code tools such as Terraform \n \n \n  Startup or small company experience \n \n  Our commitment to diversity \n  Working in the Education Technology space, it is an ethical necessity for us to build a diverse and inclusive team in order to better consider the needs of our audience\u2019s wide range of backgrounds and educational experiences. We provide regular training on topics of diversity, equity, and inclusion to all employees. \n  Employees of color are invited to participate in a mentorship program with members of our executive team to build career skills and to help with career progression. \n  We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. \n  Perks of working at Packback \n  A culture that you can be proud to build : We work hard at building an inclusive culture of curiosity and continuous learning at Packback. In any role at Packback, being a good steward of our values and using them to inform decisions and communication can make an enormous impact on the business. \n  Work-life balance : Packback offers an unlimited vacation policy. Team members are encouraged to take time off for volunteer opportunities. Our engineering team is fully remote, and provides flexibility and support for working wherever makes the most sense for you. \n  Competitive Salary and Benefits : The salary range for this position is  $85k-130k annually + bonus . We set clear expectations for professional growth and offer an annual learning and development stipend. \n  Benefits \n  Health & Wellness \n \n Medical Insurance \n  Dental Insurance \n  Vision Insurance \n  401(k) with a 50% employer match \n  Stock options \n  Disability Insurance \n  Life Insurance \n  Commuter Benefits \n  Generous Parental Leave up to 12 weeks \n  Family Medical Leave \n  Unlimited Time Off \n \n Additional Perks: \n \n Access to premium membership to One Medical \n  Calm subscription \n  Monthly Dashpass subscription by DoorDash",
        "cleaned_desc": "  Additionally, we\u2019re looking for: \n \n A strong grasp on Python fundamentals, experience writing both functional and object oriented code with an emphasis on performance \n  Demonstrated experience doing backend web development using a modern web framework such as Django (or some other equivalent MVC framework) \n  Extensive experience writing thorough unit and integration tests in Python \n  2+ years of software engineering experience, especially with web-based products. However, transferable experience is more important than years of experience. \n \n It's great if you have \n \n Strong SQL skills \n  Experience building, validating, and deploying machine learning models in a production environment (NLP experience is a bonus) ",
        "techs": [
            "python",
            "django",
            "mvc framework",
            "sql",
            "machine learning",
            "nlp"
        ],
        "cleaned_techs": [
            "python",
            "django",
            "mvc framework",
            "sql",
            "nlp"
        ]
    },
    "61c4f3a405a9db4c": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 119345.19,
        "salary_max": 151117.6,
        "title": "AI Automation Engineer - 100% Remote - US",
        "company": "Worldwide Clinical Trials",
        "desc": "Requisition Number \n 7210 \n \n \n  Employment Type \n : \n Regular \n \n \n \n \n \n \n \n \n  Who we are \n Worldwide Clinical Trials (Worldwide), a leading global contract research organization (CRO), works in partnership with biotechnology and pharmaceutical companies to create customized solutions that advance new medications \u2013 from discovery to reality. Anchored in our company\u2019s scientific heritage, our dedicated therapeutic focus on cardiovascular, metabolic, neuroscience, oncology, and rare diseases, is applied to develop flexible plans and solve problems quickly for our customers.  \n Our talented team of 3,000+ professionals spans 60+ countries. We are united in a cause with our customers to improve the lives of patients through new and innovative therapies. \n Why Worldwide \n We believe everyone plays an important role in making a world of difference for patients and their caregivers. From our hands-on, accessible leaders, to our cohesive and supportive teams, we are committed to enabling professionals from all backgrounds and experiences to succeed. We prioritize cultivating a diverse and inclusive environment that continues to promote collaboration and creativity. We are proud to be a workplace where people thrive by being themselves and are inspired to do their best work every day. Join us! \n What the AI Automation Developer Does at Worldwide \n The AI Automation Developer will work with the team to design, develop, and implement AI-powered solutions to enhance Worldwide's services and improve the efficiency of existing business processes. They will leverage their expertise in coding, analysis, and language translation to create innovative and effective solutions.     What you will do:   Tasks may include but are not limited to: \n \n Collaborate with cross-functional teams to identify business needs and translate them into AI solutions. \n Develop, test, and deploy AI models using programming languages such as Python, R, and Java. \n Perform data analysis and manipulation to prepare data for use in AI models. \n Implement premade Natural Language Processing (NLP) and Machine Learning (ML) algorithms to solve complex business problems such as ChatGPT from OpenAI. \n Optimize and improve the performance of existing prompts (prompt engineering). \n Stay up-to-date with the latest developments in AI, prompt engineering, and identify new opportunities for application. \n Translate technical concepts and findings into easy-to-understand language for non-technical stakeholders. \n Provide training and support to end-users on AI-related tools and technologies. \n Create comprehensive documentation for AI models, code, and processes to facilitate knowledge sharing and troubleshooting. \n Engage with stakeholders, including business leaders and clients, to gather feedback, understand requirements, and align AI solutions with business goals. \n Design AI solutions with scalability in mind, ensuring they can handle increasing data volumes and user loads. \n Investigate and resolve issues related to AI model performance or system functionality. \n Ensure compliance with relevant AI-related regulations and standards. \n \n Perform other duties as assigned. The duties and responsibilities listed above are representative of the nature and level of work assigned and are not necessarily all-inclusive. \n What you bring to the role \n \n Strong knowledge and skills in Python, UI/UX development, Java, and/or SQL. \n Experience integrating with NLP and ML algorithms. \n Familiarity with AI frameworks and knowledge of data analysis and visualization tools. \n Familiarity with cloud-based AI services such as AWS, Azure, and Google Cloud. \n Excellent written and verbal communication skills, with the ability to explain complex technical concepts to non-technical stakeholders. \n Strong problem-solving skills and ability to work independently or in a team environment. \n \n Your experience \n \n Bachelor's degree in Computer Science, Data Science, or a related field. \n At least 3 years of experience in AI development and deployment. \n Experience in implementing NLP and ML algorithms for applications such as chatbots. \n Strong analytical and conceptual thinking skills. \n Willingness to manage business-critical emergencies during non-business hours. \n Exceptional proficiency in written and spoken English. \n \n \n \n \n \n \n \n \n \n    Worldwide is an equal opportunity employer that is committed to enabling professionals from all backgrounds and experiences to succeed and, to that end, we prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and creativity. We provide equal employment opportunities to all employees and applicants regardless of race, color, ethnicity, ancestry, religion, national origin, gender, sex, gender identity or expression, sexual orientation, age, citizenship, marital or parental status, disability, military status, or other class protected by applicable law. Worldwide is committed to working with and providing reasonable accommodations to applicants with disabilities. We are proud to be an equal opportunity workplace where people thrive by being themselves and are inspired to do their best work every day.",
        "cleaned_desc": " Develop, test, and deploy AI models using programming languages such as Python, R, and Java. \n Perform data analysis and manipulation to prepare data for use in AI models. \n Implement premade Natural Language Processing (NLP) and Machine Learning (ML) algorithms to solve complex business problems such as ChatGPT from OpenAI. \n Optimize and improve the performance of existing prompts (prompt engineering). \n Stay up-to-date with the latest developments in AI, prompt engineering, and identify new opportunities for application. \n Translate technical concepts and findings into easy-to-understand language for non-technical stakeholders. \n Provide training and support to end-users on AI-related tools and technologies. \n Create comprehensive documentation for AI models, code, and processes to facilitate knowledge sharing and troubleshooting. \n Engage with stakeholders, including business leaders and clients, to gather feedback, understand requirements, and align AI solutions with business goals. \n Design AI solutions with scalability in mind, ensuring they can handle increasing data volumes and user loads. \n Investigate and resolve issues related to AI model performance or system functionality. \n Ensure compliance with relevant AI-related regulations and standards.   \n Perform other duties as assigned. The duties and responsibilities listed above are representative of the nature and level of work assigned and are not necessarily all-inclusive. \n What you bring to the role \n \n Strong knowledge and skills in Python, UI/UX development, Java, and/or SQL. \n Experience integrating with NLP and ML algorithms. \n Familiarity with AI frameworks and knowledge of data analysis and visualization tools. \n Familiarity with cloud-based AI services such as AWS, Azure, and Google Cloud. \n Excellent written and verbal communication skills, with the ability to explain complex technical concepts to non-technical stakeholders. \n Strong problem-solving skills and ability to work independently or in a team environment. \n \n Your experience   \n Bachelor's degree in Computer Science, Data Science, or a related field. \n At least 3 years of experience in AI development and deployment. \n Experience in implementing NLP and ML algorithms for applications such as chatbots. \n Strong analytical and conceptual thinking skills. \n Willingness to manage business-critical emergencies during non-business hours. \n Exceptional proficiency in written and spoken English. \n \n \n \n \n ",
        "techs": [
            "python",
            "r",
            "java",
            "natural language processing (nlp)",
            "machine learning (ml)",
            "chatgpt",
            "prompt engineering",
            "ui/ux development",
            "sql",
            "ai frameworks",
            "data analysis and visualization tools",
            "aws",
            "azure",
            "google cloud",
            "computer science",
            "data science",
            "bachelor's degree."
        ],
        "cleaned_techs": [
            "python",
            "r",
            "java",
            "nlp",
            "machine learning (ml)",
            "chatgpt",
            "prompt engineering",
            "ui/ux development",
            "sql",
            "ai",
            "data analysis and visualization tools",
            "aws",
            "azure",
            "gcp",
            "computer science",
            "data science"
        ]
    },
    "7315958edb3747e4": {
        "terms": [
            "data science"
        ],
        "salary_min": 146188.16,
        "salary_max": 185106.78,
        "title": "VP, AI",
        "company": "Clario",
        "desc": "ESSENTIAL DUTIES AND RESPONSIBILITIES:\n  \n \n  Strategic Leadership:\n    \n  Set the vision and strategy for the adoption of AI technologies across the clinical trial endpoint data collection spectrum. \n  Collaborate with C-level executives to align AI capabilities with the company\u2019s strategic objectives. \n \n  Research and Development:\n    \n  Oversee the research and development of AI-powered tools and platforms that enhance data collection, analysis, and decision-making in clinical trials. \n  Lead the development and deployment of advanced AI models to enhance user experience, safety, and outcomes across the entire product funnel. This includes ideation, model development, validation, and implementation. \n  Stay updated with the latest advancements in AI and machine learning to ensure the company remains at the forefront of technology in the industry. \n  Implement AI tools to optimize operational efficiency across the organization, working closely with cross-functional teams to understand their needs and develop AI solutions that drive improvement. Foster a data-driven culture within the organization, promoting the use of AI in decision-making processes. \n \n  Operational Excellence:\n    \n  Ensure the seamless integration of AI-driven technologies into existing systems and workflows. \n  Establish performance metrics and monitor the success of AI initiatives, ensuring ROI. \n \n  Stakeholder Collaboration:\n    \n  Collaborate with clinical, regulatory, and data management teams to understand their requirements and develop AI solutions tailored to their needs. \n  Engage with external stakeholders, partners, and vendors to ensure that the company's AI initiatives are externally recognized and are industry leading. \n  Collaborates closely with the engineering, user experience, architecture, and cross-functional teams to ensure a wide portfolio of products are delivered on time, within budget, and at the highest level of quality. \n \n  Risk Management:\n    \n  Establish governance and protocols for the ethical use of AI, ensuring data privacy and regulatory compliance. \n  Proactively address technical and operational challenges, ensuring minimal disruption to ongoing clinical trials. \n \n  Team Leadership:\n    \n  Hires, leads, mentors, and expands the AI organization ensuring the team is high-performing, innovative, and aligned with business goals. \n  Partners with Talent Acquisition to attract and retain top AI talent. \n  Employs a strong focus on Employee Engagement and Talent Development. \n  Effectively manages all annual people-related processes. \n  Proactively manages employee performance, providing timely and ongoing feedback. \n \n \n \n \n   QUALIFICATIONS AND SKILLS NEEDED:\n  \n \n   (Key wording should include if degree is needed, any travel requirements, special qualifications needed, skills, etc.)\n  \n \n \n  Develops and monitors budgets and allocates resources within budget constraints to maximize budgeted resources. \n \n \n \n   Basic Experience:\n  \n \n \n  15 or more years of work experience with a Bachelor\u2019s Degree or at least 12 years of work experience with an Advanced degree (e.g. Masters/MBA/ JD/MD) or a minimum of 10 years of work experience with a PhD. \n \n \n \n   Preferred Experience:\n  \n \n  18 or more years of experience with an Advanced Degree (e.g. Masters, MBA, JD, MD, PhD) \n  Minimum of 15+ years\u2019 direct experience in AI and ML, with a focus on guiding business strategy through technological innovation. \n  Deep knowledge of the clinical trial process and challenges associated with endpoint data collection. \n  A strong research background in AI and ML, evidenced by publications in top-tier conferences or journals. \n  Professional certifications in AI, ML, Data Science, or related fields a plus. \n  Demonstrable experience in employing LLMs and GAI in a business context. \n  Strong technical acumen with an understanding of programming languages such as Python, R, or Java. \n  Familiarity with AI & ML platforms, tools and libraries, and comfort with adopting new technologies as they emerge. \n  Proficiency in cloud-based AI solutions and big data technologies is highly desired. \n  Proven experience designing and deploying successful AI-driven solutions in complex environments. \n  Exceptional communication skills with a knack for translating complex technical jargon into understandable language for non-technical stakeholders. \n  A firm grasp of data governance and privacy regulations is essential in the clinical trial industry. \n  Ability to prioritize competing opportunities and priorities, balance stakeholder needs with business priorities, and drive detailed trade-offs. \n  Outstanding collaboration skills, ability to establish common ground while managing conflicting points of view and articulate rationale behind decisions. \n  Demonstrated technical proficiency and effectiveness working closely with engineers and IT departments. \n  Strong analytical and problem-solving skills, with the ability to interpret complex data and make strategic recommendations. \n \n \n  The Department Head has the discretion to hire personnel with a combination of experience and education, which may vary from the above listed qualifications. \n \n \n \n   EEO Statement\n    Clario is an equal opportunity employer. Clario evaluates qualified applicants without regard to race, color, religion, gender, national origin, age, sexual orientation, gender identity or expression, protected veteran status, disability/handicap status, or any other legally protected characteristic.",
        "cleaned_desc": "ESSENTIAL DUTIES AND RESPONSIBILITIES:\n  \n \n  Strategic Leadership:\n    \n  Set the vision and strategy for the adoption of AI technologies across the clinical trial endpoint data collection spectrum. \n  Collaborate with C-level executives to align AI capabilities with the company\u2019s strategic objectives. \n \n  Research and Development:\n    \n  Oversee the research and development of AI-powered tools and platforms that enhance data collection, analysis, and decision-making in clinical trials. \n  Lead the development and deployment of advanced AI models to enhance user experience, safety, and outcomes across the entire product funnel. This includes ideation, model development, validation, and implementation. \n  Stay updated with the latest advancements in AI and machine learning to ensure the company remains at the forefront of technology in the industry. \n  Implement AI tools to optimize operational efficiency across the organization, working closely with cross-functional teams to understand their needs and develop AI solutions that drive improvement. Foster a data-driven culture within the organization, promoting the use of AI in decision-making processes. \n \n  Operational Excellence:\n      \n \n   Basic Experience:\n  \n \n \n  15 or more years of work experience with a Bachelor\u2019s Degree or at least 12 years of work experience with an Advanced degree (e.g. Masters/MBA/ JD/MD) or a minimum of 10 years of work experience with a PhD. \n \n \n \n   Preferred Experience:\n  \n \n  18 or more years of experience with an Advanced Degree (e.g. Masters, MBA, JD, MD, PhD) \n  Minimum of 15+ years\u2019 direct experience in AI and ML, with a focus on guiding business strategy through technological innovation. \n  Deep knowledge of the clinical trial process and challenges associated with endpoint data collection. \n  A strong research background in AI and ML, evidenced by publications in top-tier conferences or journals.    Professional certifications in AI, ML, Data Science, or related fields a plus. \n  Demonstrable experience in employing LLMs and GAI in a business context. \n  Strong technical acumen with an understanding of programming languages such as Python, R, or Java. \n  Familiarity with AI & ML platforms, tools and libraries, and comfort with adopting new technologies as they emerge. \n  Proficiency in cloud-based AI solutions and big data technologies is highly desired. \n  Proven experience designing and deploying successful AI-driven solutions in complex environments. \n  Exceptional communication skills with a knack for translating complex technical jargon into understandable language for non-technical stakeholders. \n  A firm grasp of data governance and privacy regulations is essential in the clinical trial industry. \n  Ability to prioritize competing opportunities and priorities, balance stakeholder needs with business priorities, and drive detailed trade-offs. \n  Outstanding collaboration skills, ability to establish common ground while managing conflicting points of view and articulate rationale behind decisions. \n  Demonstrated technical proficiency and effectiveness working closely with engineers and IT departments. \n  Strong analytical and problem-solving skills, with the ability to interpret complex data and make strategic recommendations. \n \n \n  The Department Head has the discretion to hire personnel with a combination of experience and education, which may vary from the above listed qualifications. \n \n ",
        "techs": [
            "python",
            "r",
            "java"
        ],
        "cleaned_techs": [
            "python",
            "r",
            "java"
        ]
    },
    "ec9e3aaf5be1ab52": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 71600.0,
        "salary_max": 87947.0,
        "title": "Sr. Business Data Analyst \u2013 Third-Party Management",
        "company": "Flagstar Bank",
        "desc": "Position Title\n   Sr. Business Data Analyst \u2013 Third-Party Management\n  \n \n   Location\n   Work From Home United States\n  \n \n   Job Summary\n   The Sr. Business Data Analyst will be responsible for gathering and analyzing data, creating and maintaining one or more business management tools, presenting information and recommendations to senior management, managing projects, and process enhancement recommendations for the Corporate Support Services Third-Party Management function.\n   Develop and perform/deliver vendor spend capture, analysis, model, and reporting in support of Sourcing, Third-party Management and Corporate Support Services.\n  \n  Work with businesses and Finance/Accounting to coordinate the migration of reports/analyses/tools\n  \n  Recommend new reporting, modeling and analyses in support of emerging trends and/or new strategic initiatives\n   Pay Range: $71,600.00 - $87,947.00 - $132,600.00\n  \n \n   Job Responsibilities:\n  \n \n  Develop and perform/deliver vendor spend capture, analysis, model, and reporting in support of Sourcing, Third-party Management and Corporate Support Services. \n  Prepare weekly/monthly/quarterly analyses of results, including actual savings projections, continuously evolving metrics and variance analysis including output from specific modeling and projections. \n  Prepare long-term model of vendor spend and metrics incorporating variables and multiple factor inputs. \n  This role is heavily involved with data, systems, data storage, information systems, etc. including utilization of the Coupa platform \n  Special projects as assigned. Monitor project progress ensuring proper use of reports/data; creating presentations, presenting findings/recommendations to management. \n  Ensures compliance with applicable federal, state and local laws and regulations. Completes all required compliance training. Maintains knowledge of and adhere to Flagstar\u2019s internal compliance policies and procedures. \n \n \n \n   Job Requirements:\n  \n \n  High School Diploma, GED, or foreign equivalent required. \n  Bachelor\u2019s degree or 4-6 years of comparable work experience. \n  Strong experience with Microsoft Office; Multiple relevant years of data mining and creating tools requiring the management of multiple data sources; independent worker. \n  6+ years data analysis, data modeling, data integrations and tool/model development. \n  4+ years financial services experience, preferably in procure-to-pay/vendor risk and working on complex projects \n  Exceptional analytical and problem solving skills with an ability to think quickly under pressure. \n  Must have extremely strong listening, requirements elicitation, analysis and problem solving skills. \n  Must have extremely strong documentation and oral communications skills. \n  Must be a self-starter and work productively with minimal direction. \n  Must learn quickly and produce under pressure and tight deadlines. \n  Must have strong Excel, PowerPoint, MS Word and MS Access knowledge. \n  Strong knowledge and utilization of data querying tools is a plus. \n  Relevant financial services experience is a strong plus",
        "cleaned_desc": "  6+ years data analysis, data modeling, data integrations and tool/model development. \n  4+ years financial services experience, preferably in procure-to-pay/vendor risk and working on complex projects \n  Exceptional analytical and problem solving skills with an ability to think quickly under pressure. \n  Must have extremely strong listening, requirements elicitation, analysis and problem solving skills. \n  Must have extremely strong documentation and oral communications skills. \n  Must be a self-starter and work productively with minimal direction. \n  Must learn quickly and produce under pressure and tight deadlines. \n  Must have strong Excel, PowerPoint, MS Word and MS Access knowledge. \n  Strong knowledge and utilization of data querying tools is a plus. ",
        "techs": [
            "data analysis",
            "data modeling",
            "data integrations",
            "tool/model development",
            "financial services experience",
            "procure-to-pay/vendor risk",
            "complex projects",
            "analytical skills",
            "problem solving skills",
            "listening skills",
            "requirements elicitation",
            "documentation skills",
            "oral communications skills",
            "self-starter",
            "productivity skills",
            "quick learning",
            "working under pressure",
            "tight deadlines",
            "excel",
            "powerpoint",
            "ms word",
            "ms access",
            "data querying tools"
        ],
        "cleaned_techs": [
            "data integrations",
            "tool/model development",
            "financial services experience",
            "procure-to-pay/vendor risk",
            "complex projects",
            "requirements elicitation",
            "self-starter",
            "quick learning",
            "working under pressure",
            "tight deadlines",
            "excel",
            "powerpoint",
            "microsoft",
            "ms access",
            "data querying tools"
        ]
    },
    "6ab29e7efb9bcf3e": {
        "terms": [
            "data science"
        ],
        "salary_min": 100000.0,
        "salary_max": 135000.0,
        "title": "Principal Analytics Analyst: Procurement & Financial Shared Service",
        "company": "Vail Resorts",
        "desc": "As a leading mountain resort operator with over 40 resorts in sixteen states and four countries. We exist to create an  Experience of a Lifetime  for our employees, so they can, in turn, provide and  Experience of a Lifetime  for our guests. We are looking for leaders, innovators, creators, and ambitious professionals to join our talented team. If you\u2019re ready to pursue your fullest potential, we want to get to know you! \n  Many of our Corporate function teams can now live and work in any of the states in which Vail Resorts currently operates* \u2013 enabling flexible remote work alongside a commitment to building and maintaining strong culture both in person and virtually. If you\u2019re ready to pursue your fullest potential, we want to get to know you. Find your purpose with us at www.vailresortscareers.com. \n \n  Job Summary: \n  The Vail Resorts Procurement & Financial Shared Services Team is committed to Building Leaders and Driving Value. We are creating a world class procurement and financial shared services organization in our corporate headquarters to support a growing company of 41 resorts, 55,000+ employees and a market capitalization of over $9.5 billion. We are transforming our organization to bring best-in-class S2C, P2P, OTC, R2R, Payroll, and analytical tools to enable data-driven decision making at Vail Resorts \u2013 the ski industry\u2019s global leader. \n  Our team will be driven by top-tier talent, state-of-the-art systems and tools, and strategic process management to identify and deliver against the Company\u2019s biggest value opportunities. We are creating a sustainable high-performing team that will develop talent and prioritize career growth through accelerated opportunities and progression. This is an opportunity to join the Procurement and Financial Shared Services team at a critical inflection point and shape how we create value into the future. \n \n  The Principal Analytics Analyst of Financial Shared Services and Procurement is responsible for driving value and leading innovation that will use deep analytical capabilities to strategically inform decision making for the highest priority spend management and revenue preservation opportunities and risks impacting the enterprise. S/he will be responsible for performing in-depth spend and cost impact analysis, including benchmarking and trending to inform enterprise insights, target-setting, budgeting and forecasting processes. The role will have significant senior leadership exposure, particularly with the Operations SLT and FP&A team of Vail Resorts. \n \n  The Principal Analytics Analyst of Financial Shared Services and Procurement will have the opportunity to analyze the key issues arising across our enterprise wide spend, payroll and revenue preservation and have a significant impact on decision making that impacts the bottom line. S/he will use financial acumen, strategic synthesis and data-driven insights to advise senior leaders and will gain great perspective on key business and operations drivers, while working on our most interesting and challenging business questions. \n \n  Job Specifications: \n \n  Expected Pay Range: $100,000 - $135,000 + Annual Bonus \n  Shift & Schedule Availability: Full Time, Year Round \n \n \n  Job Responsibilities: \n \n \n \n  Possesses strong business acumen to partner with business leaders to build and deploy best in class financial service analytics including: order to cash reporting, payroll analysis, third party spend, category analytics, supplier performance management, market and cost intelligence \n  Leads efforts to frame spend and revenue preservation issues and questions with data-driven approaches to problem solving, including selecting the right metrics, interpreting the data and the ability to communicate complex quantitative analysis in a clear, precise, and actionable manner. \n  Serves as a thought partner with the Financial Shared Services and Procurement Leadership Team to identify business challenges. Use fact based analysis to help influence changes to operations, process or policies. \n  Maintains and ensures quality assurance of key data sets, reports and metrics that are relevant and insightful and highlight key trends in market dynamics, collaborating with subject matter experts across FP&A and IT to promote data governance. \n  Drive partnerships with Finance IT team and vendors to deliver necessary data management tools, capabilities and system solutions. \n  Leads Financial Shared Services specific program evaluation and program outcomes analyses. \n  Actively participates in external professional organizations and builds a powerful network to understand and shape the emerging analytical trends. \n \n \n  Job Requirements: \n \n \n \n  Bachelor\u2019s degree in Finance, Supply Chain, STEM \n  MBA or MS in Data Science is strongly preferred \n  6+ years\u2019 experience in analytics, with demonstrated success in managing analytical talent, cost modeling, and analysis. \n  Outstanding analytical skills with ability to synthesize information, develop insights and communicate effectively in presentations and in-person meetings. \n  Deep curiosity and passion for understanding and analyzing financial results in the context of creating shareholder value. \n  Excellent communication skills with ability to develop the \u201cstory\u201d and form recommendations. \n  Ability to operate in a fast-paced environment with strong initiative and ability to multi-task. \n  Superb attention to detail balanced by ability to focus on the \"big picture.\" \n  Effectively manage and build capabilities and culture for high performing professional team. \n  Preferred skills:\n    \n  High intellect and ambition. \n  Unquestioned ethics and integrity. \n  Excellent listener, open to feedback, and communicates with candor and respect. \n  Outstanding organizational, analytical and project management skills. \n  Connects well with others and highly collaborative team approach to work. \n  Excellent individual initiative and objective-oriented drive. \n  Ability to handle difficult situations with a high-degree of diplomacy and composure \n  Expert in Excel, PowerPoint and experience with Coupa, PeopleSoft, Power BI and Tableau is a plus \n \n \n \n  The expected Total Compensation for this role is $100,000 - $135,000 + Annual Bonus. Individual compensation decisions are based on a variety of factors. \n  The perks include a free ski pass, and a set of benefits including... \n \n  Medical, Dental, Vision insurance, and a 401(k) retirement plan \n  Hourly employees are generally eligible for accrued Paid Time Off (PTO) and Sick Time. Salaried employees are generally eligible for Flexible Time Off (FTO) \n  Paid Parental Leave for eligible mothers and fathers \n  Healthcare & Dependent Care Flexible Spending Accounts \n  Life, AD&D, and disability insurance \n \n \n  Reach Your Peak at Vail Resorts.  At Vail Resorts, our team is made whole by the brave, passionate individuals who ambitiously push boundaries and challenge the status quo. Whether you\u2019re looking for seasonal work or the career of a lifetime, join us today to reach your peak. \n \n   Remote work is currently permitted from British Columbia and the 16 U.S. states in which we currently operate. This includes: California, Colorado, Indiana, Michigan, Minnesota, Missouri, New Hampshire, New York, Nevada, Ohio, Pennsylvania, Utah, Vermont, Washington State, Wisconsin, and Wyoming. Please note that the ability to work remotely, and the particulars related to such work, are subject to change at any time; and, accordingly, the Company reserves the right to change its policies and/or require in-person/in-office work at any time in its sole discretion. \n \n \n  Vail Resorts is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability, protected veteran status or any other status protected by applicable law. \n \n  Requisition ID 498598   Reference Date: 10/17/2023   Job Code Function:",
        "cleaned_desc": " \n \n  Job Requirements: \n \n \n \n  Bachelor\u2019s degree in Finance, Supply Chain, STEM \n  MBA or MS in Data Science is strongly preferred \n  6+ years\u2019 experience in analytics, with demonstrated success in managing analytical talent, cost modeling, and analysis. \n  Outstanding analytical skills with ability to synthesize information, develop insights and communicate effectively in presentations and in-person meetings. \n  Deep curiosity and passion for understanding and analyzing financial results in the context of creating shareholder value. \n  Excellent communication skills with ability to develop the \u201cstory\u201d and form recommendations. \n  Ability to operate in a fast-paced environment with strong initiative and ability to multi-task. \n  Superb attention to detail balanced by ability to focus on the \"big picture.\"    Effectively manage and build capabilities and culture for high performing professional team. \n  Preferred skills:\n    \n  High intellect and ambition. \n  Unquestioned ethics and integrity. \n  Excellent listener, open to feedback, and communicates with candor and respect. \n  Outstanding organizational, analytical and project management skills. \n  Connects well with others and highly collaborative team approach to work. \n  Excellent individual initiative and objective-oriented drive. \n  Ability to handle difficult situations with a high-degree of diplomacy and composure \n  Expert in Excel, PowerPoint and experience with Coupa, PeopleSoft, Power BI and Tableau is a plus \n \n \n ",
        "techs": [
            "excel",
            "powerpoint",
            "coupa",
            "peoplesoft",
            "power bi",
            "tableau"
        ],
        "cleaned_techs": [
            "excel",
            "powerpoint",
            "coupa",
            "peoplesoft",
            "powerbi",
            "tableau"
        ]
    },
    "814edb5947a6ddd9": {
        "terms": [
            "data science",
            "data engineer"
        ],
        "salary_min": 108681.336,
        "salary_max": 137614.78,
        "title": "Senior Data Engineer",
        "company": "Analytica",
        "desc": "ANALYTICA is seeking a  Senior  Data Engineer  to support a federal government client in the DC metro area (Note - your work location is REMOTE). In this assignment, you will be a team member serving the client in advancing the customers use data, metadata, as well as explore new technologies to better meet those needs.    This is a mission that takes some serious smarts, intense curiosity and a background in developing data solutions across the data lifecycle.    Analytica has been recognized by Inc. Magazine as the fastest-growing private US small business. We work with U.S. government customers in health, civilian, and national security missions. As a core member you\u2019ll work with a diverse team of professionals to solution matters, architect nuisances, and come up with alternatives. We offer competitive compensation with opportunities for bonuses, employer paid health care, training and development funds, and 401k match.     Responsibilities include (But Are Not Necessarily Limited To): \n \n  Research, design, build, optimize and maintain reliable, efficient, and accessible data models, systems and pipelines/APIs etc. \n  Support, with guidance, the analytic and/or operational use of data. \n  Align closely with Enterprise partners in data science, architecture, governance, infrastructure, and security to apply standards and optimize production environments and practices. \n  Collaborate with business owners to optimize data collection, movement, storage, and usage to data process and data quality. \n  Convert concepts & ideas into workable prototypes (custom or COTS products) for client reviews and acceptance. \n  Translate business needs into:\n    \n  data architecture solutions development within supported data systems. \n  data orchestration pipelines (source to target analysis & recommendations), data sourcing, cleansing, augmentation and quality control processes within supported data systems. \n  Prototype, test and integrate new data tools (i.e. data features and functionality) as defined by the product owners and business teams \n \n \n  Competency and skill set will determine level of placement within the posted job family.     Qualifications: \n \n  Bachelor\u2019s degree in computer science, information systems management or similarly related degree. \n  7+ years of professional data solutions development and implementation experience with:\n    \n  AWS (Glue, Athena, API Gateway) \n  SQL, NoSQL \n  Data developments with modeling tools such as Neo4J, Erwin, Embarcadero, transforming logical, physical, conceptual, reverse engineering & forward engineering. \n  Development with Alation and/or EASparx \n  Data Movement tools such as Informatica & others\u2026 \n  Unit testing \n  RESTful API Development \n  Desire and willingness to learn new data tools \n \n  Has an Agile mindset and iterative development process background\n    \n  Help promote a culture of diversity and inclusion within the department and the larger organization \n  Value different ideas and opinions \n  Listen courageously and remain curious in all that you do \n \n  CMS data experience a must \n  CMS Public Trust clearance, EUA highly preferred \n \n  Valuable Experience: \n \n  AWS CDK and/or other AWS services (or comparable cloud data solutioning tools) \n  Experience with Git and CICD pipelines \n  Relational database design \n  Microservices / Containers (Docker, Kubernetes) \n  Informatica Intelligent Cloud Services (IICS) \n  Prior experience with CMS, preferably within clinical quality or standards area \n \n  About  ANALYTICA : Analytica is a leading consulting and information technology solutions provider to public sector organizations supporting health, civilian, and national security missions. Founded in 2009 and headquartered in Bethesda, MD., the company is an established 8(a) small business that has been recognized by  Inc. Magazine  each of the past three years as one of the 250 fastest-growing companies in the U.S. Analytica specializes in providing software and systems engineering, information management, analytics & visualization, agile project management, and management consulting services. The company is appraised by the Software Engineering Institute (SEI) at CMMI\u00ae Maturity Level 3 and is an ISO 9001:2008 certified provider.    As a federal contractor, Analytica is required to verify that all employees are fully vaccinated against COVID-19. If you receive an offer and are unable to get vaccinated for religious or medical reasons, you may request a reasonable accommodation.   \n   \n vR3cn1Uzfh",
        "cleaned_desc": "  data architecture solutions development within supported data systems. \n  data orchestration pipelines (source to target analysis & recommendations), data sourcing, cleansing, augmentation and quality control processes within supported data systems. \n  Prototype, test and integrate new data tools (i.e. data features and functionality) as defined by the product owners and business teams \n \n \n  Competency and skill set will determine level of placement within the posted job family.     Qualifications: \n \n  Bachelor\u2019s degree in computer science, information systems management or similarly related degree. \n  7+ years of professional data solutions development and implementation experience with:     \n  AWS (Glue, Athena, API Gateway) \n  SQL, NoSQL \n  Data developments with modeling tools such as Neo4J, Erwin, Embarcadero, transforming logical, physical, conceptual, reverse engineering & forward engineering. \n  Development with Alation and/or EASparx \n  Data Movement tools such as Informatica & others\u2026 \n  Unit testing \n  RESTful API Development \n  Desire and willingness to learn new data tools   \n  Valuable Experience: \n \n  AWS CDK and/or other AWS services (or comparable cloud data solutioning tools) \n  Experience with Git and CICD pipelines \n  Relational database design \n  Microservices / Containers (Docker, Kubernetes) \n  Informatica Intelligent Cloud Services (IICS) \n  Prior experience with CMS, preferably within clinical quality or standards area ",
        "techs": [
            "aws glue",
            "athena",
            "api gateway",
            "sql",
            "nosql",
            "neo4j",
            "erwin",
            "embarcadero",
            "alation",
            "easparx",
            "informatica",
            "aws cdk",
            "git",
            "cicd pipelines",
            "docker",
            "kubernetes",
            "informatica intelligent cloud services (iics)",
            "cms"
        ],
        "cleaned_techs": [
            "aws",
            "athena",
            "api gateway",
            "sql",
            "nosql",
            "neo4j",
            "erwin",
            "embarcadero",
            "alation",
            "easparx",
            "informatica",
            "git",
            "cicd pipelines",
            "docker",
            "kubernetes",
            "informatica intelligent cloud services (iics)",
            "cms"
        ]
    },
    "d23ab35087b6804b": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Senior Product Manager, Data",
        "company": "Chartboost",
        "desc": "Who we are: \n  Chartboost is the leading in-app monetization and programmatic advertising platform. We reach a global audience of over 700 million monthly active users and process over 2.7 trillion monthly advertising auctions. The Chartboost SDK is one the most widely integrated mobile ad SDKs and through the Chartboost Exchange, Ad Network, DSP and other services, we empower mobile app developers to build businesses, while connecting advertisers to highly engaged audiences. \n \n Impact You Will Make: \n \n Work with data scientists, data engineers, machine learning engineers and analysts to empower data-driven decision-making in the full lifecycle of product development. \n Enable data to play an instrumental role in ad campaign planning, execution, optimization, attribution and analytics. \n Building and adopting identity, attribution, targeting and analytic solutions for the Chartboost DSP, Marketplace and Mediation Publisher platform. \n Work with engineers and PMs within the organization to ensure that our data infrastructure reliably connects data across our products and services \n Work closely with Legal to ensure our solutions are adhering to regulatory compliance requirements \n Define, prioritize and deliver product roadmap and product features based on business requirements \n \n Who you are: \n \n 5 years of strong product management experience, ideally with 3 years in digital advertising \n Good understanding of quantitative online advertising metrics. \n Understanding of data science and machine learning principles, and other related concepts. \n Experience working with data engineers, data scientists, product managers, legal and business groups \n Strong problem-solving and analytical skills and comfort with navigating ambiguity in managing cross-functional initiatives across technical and non-technical teams \n Bachelor's degree in either data science, data analytics, engineering, product management, or any related field. \n \n \n Perks: \n \n Comprehensive medical, dental and vision insurance \n Restricted Stock Units (RSUs) - you will have the potential of RSUs depending on the level/role \n 401(k) plan with match through Fidelity \n Catered lunches and fully stocked kitchens \n Commuter Program \n Flex Vacation \u2013 personal time to refresh your mind/body/soul, spend time with loved ones and celebrate life events. There is no accrual or specific limit to the amount of time an employee may use \n \n \n More about us: \n  We are proud of the product we've built and appreciate the impact it has on other people's businesses and lives. We want to be surrounded by people who are always finding opportunities to try something new and grow. We love data and anything that helps drive intelligent decisions and always design with the user in mind. Sounds like a fit? Join us, and be part of the team that will change the future of mobile gaming! \n  We are an equal opportunity employer \u2014 we celebrate diversity and are committed to creating an inclusive environment for all employees and make our hiring decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. \n  California Residents, please review the Chartboost California Employment Candidate Privacy Notice before submitting any personal information. \n \n The pay range for this position in  California  at the start of employment is expected to be between  $177,840.00   and  $222,300.00   per year.  For applicants based in  New York City  and  New Jersey  at the start of employment is expected to be between  $177,840.00  and  $222,300.00  per year. Furthermore, th e pay range for this position for applicants based in  Washington  at the start of employment is expected to be between  $158,080.00  and  $197,600.00   per year.  \n However, base pay offered is based on market location, and may vary further depending on individualized factors for job candidates, such as job-related knowledge, skills, experience, and other objective business considerations.  \n Subject to those same considerations, the total compensation package for this position may also include other elements, including a bonus and/or equity awards and eligibility to participate in our 401(K) plan, in addition to a full range of medical, dental, vision, and basic life insurance. Employees will also receive 13 paid holidays per calendar year, unlimited discretionary time off, and will receive 10 sick days per calendar year. Details of participation in these benefit plans will be provided if an employee receives an offer of employment. If hired, employee will be in an \"at-will position\" and the Company reserves the right to modify base salary (as well as any other discretionary payment or compensation or benefit program) at any time, including for reasons related to individual performance, Company or individual department/team performance, and market factors.",
        "cleaned_desc": " 5 years of strong product management experience, ideally with 3 years in digital advertising \n Good understanding of quantitative online advertising metrics. \n Understanding of data science and machine learning principles, and other related concepts. \n Experience working with data engineers, data scientists, product managers, legal and business groups \n Strong problem-solving and analytical skills and comfort with navigating ambiguity in managing cross-functional initiatives across technical and non-technical teams \n Bachelor's degree in either data science, data analytics, engineering, product management, or any related field. \n ",
        "techs": [
            "none"
        ],
        "cleaned_techs": []
    },
    "b6b4e46652446243": {
        "terms": [
            "data science"
        ],
        "salary_min": 227500.0,
        "salary_max": 292500.0,
        "title": "Director, Data Science and Analytics",
        "company": "Circle",
        "desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  Circle is looking for a Director, Data Science & Analytics to work closely with the Business, Product, and Engineering to produce analysis, deep research, and scalable data practices. This role has the opportunity to significantly impact internal data consumption and decision making. We are a passionate team with a deeply analytical approach, and your work will support us in our mission to be a world-class company driven by data. \n  What you'll work on: \n \n Build road maps, prioritize and drive data science and analytics efforts, communicate cross-functionally, and be a domain expert \n Support the individual and career growth of team members to minimize attrition and enhance output \n Partner with product and operations teams to identify and resolve analytical problems at scale in a variety of domains, including crypto ecosystem understanding, developers, accounting and financial processes, fraud detection, and risk management \n Help your team ideate and complete the right analysis, models, and stories \n Become an expert on data sources and flows at Circle \n Evangelize the power of data science to understand and improve our business and operations. \n \n You will aspire to our four core values: \n \n Multistakeholder -  you have dedication and commitment to our customers, shareholders, employees and families and local communities. \n Mindful -  you seek to be respectful, an active listener and to pay attention to detail. \n Driven by Excellence -  you are driven by our mission and our passion for customer success which means you relentlessly pursue excellence, that you do not tolerate mediocrity and you work intensely to achieve your goals. \n High Integrity -  you seek open and honest communication, and you hold yourself to very high moral and ethical standards. You reject manipulation, dishonesty and intolerance. \n \n What you'll bring to Circle: \n \n 12+ years of industry experience working with and analyzing large data sets \n 5+ years of experience with technical leadership and people management \n Knowledge of a scientific computing language (Python) and SQL \n Theoretical and applied expertise in statistics, experimental design, and analysis \n Experience building reporting systems and dashboards \n Strong communicator who can take complex ideas and methodologies, and simplify them for non-technical audiences \n Ability to understand complex business problems and break down analytics projects into a structured approach \n Track record of managing data scientists and analysts, both individual contributors and managers \n Experience managing remote teams \n \n Additional Information: \n \n This position is eligible for day-one PERM sponsorship for qualified candidates. \n \n Circle is on a mission to create an inclusive financial future, with transparency at our core. We consider a wide variety of elements when crafting our compensation ranges and total compensation packages. \n  Starting pay is determined by various factors, including but not limited to: relevant experience, skill set, qualifications, and other business and organizational needs. Please note that compensation ranges may differ for candidates in other locations. \n  Base Pay Range: $227,500 - $292,500 \n  Annual Bonus Target: 20% \n  Also Included: Equity & Benefits (including medical, dental, vision and 401(k)). Circle has a discretionary vacation policy. We also provide 10 days of paid sick leave per year and 11 paid holidays per year in the U.S. \n \n  We are an  equal opportunity employer  and value diversity at Circle. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Additionally, Circle participates in the  E-Verify Program  in certain locations, as required by law. \n  #LI-Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "334af16420b57c82": {
        "terms": [
            "data science",
            "data engineer"
        ],
        "salary_min": 58.0,
        "salary_max": 68.0,
        "title": "Sr. Data Engineer (Contract/W2 Only/ No Vendor C2C)",
        "company": "SCIGON Solution",
        "desc": "Skills: \n \n Extensive experience as a Data Engineer or similar role, with a focus on Scala, Java, and Python programming languages. \n Proven expertise in Apache Spark, HBase, and Hive, with the ability to process and manipulate large datasets effectively. \n Familiarity with AWS services (e.g., EMR, S3, Redshift) is a plus. \n Experience with data migration from on-premises to cloud environments is desirable. \n A bachelor's degree in Computer Science, Data Science, or a related field (a master's degree is a plus). \n Strong problem-solving skills and attention to detail. \n Excellent communication and teamwork abilities. \n \n Responsibilities: \n \n Develop Data Processing Solutions: Leverage your expertise in Scala (60%), Java, and Python to design, develop, and maintain data processing solutions that operate at scale, ensuring the efficiency, reliability, and performance of data workflows. \n Big Data Mastery: Utilize your in-depth knowledge of Big Data technologies, including Apache Spark, HBase, and Hive, to process and manipulate large datasets efficiently. \n Cloud Expertise: If you have experience with AWS, contribute to the migration of data processing systems from on-premises to the cloud, ensuring seamless and secure operations. \n Data Migration: Collaborate on data migration initiatives, playing a pivotal role in transitioning data processing and handling systems to modern cloud-based platforms. \n Data Handling: Employ best practices in data handling, ensuring the integrity, security, and accessibility of data assets while complying with relevant regulations. \n \n Job Type: Contract \n Pay: $58.00 - $68.00 per hour \n Experience level: \n \n 5 years \n 6 years \n \n Schedule: \n \n Monday to Friday \n \n Application Question(s): \n \n Due to numerous fraudulent applications, we require candidates to show any valid IDs at the beginning of the video interview stage (We only need to see your name and photo, you can cover the rest of the details). Are you willing to provide it? (Yes/No): \n \n Education: \n \n Bachelor's (Preferred) \n \n Experience: \n \n Data Engineering: 5 years (Preferred) \n Scala: 3 years (Preferred) \n Java: 3 years (Preferred) \n Python: 3 years (Preferred) \n Apache Spark: 3 years (Preferred) \n HBase, and Hive: 3 years (Preferred) \n AWS Services: S3, Redshift: 3 years (Preferred) \n data migration from on-premises to cloud environment: 3 years (Preferred) \n AWS EMR: 3 years (Preferred) \n AWS Airflow: 3 years (Preferred) \n Industry: 5 years (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": "Skills: \n \n Extensive experience as a Data Engineer or similar role, with a focus on Scala, Java, and Python programming languages. \n Proven expertise in Apache Spark, HBase, and Hive, with the ability to process and manipulate large datasets effectively. \n Familiarity with AWS services (e.g., EMR, S3, Redshift) is a plus. \n Experience with data migration from on-premises to cloud environments is desirable. \n A bachelor's degree in Computer Science, Data Science, or a related field (a master's degree is a plus). \n Strong problem-solving skills and attention to detail. \n Excellent communication and teamwork abilities. \n   Responsibilities: \n \n Develop Data Processing Solutions: Leverage your expertise in Scala (60%), Java, and Python to design, develop, and maintain data processing solutions that operate at scale, ensuring the efficiency, reliability, and performance of data workflows. \n Big Data Mastery: Utilize your in-depth knowledge of Big Data technologies, including Apache Spark, HBase, and Hive, to process and manipulate large datasets efficiently. \n Cloud Expertise: If you have experience with AWS, contribute to the migration of data processing systems from on-premises to the cloud, ensuring seamless and secure operations. \n Data Migration: Collaborate on data migration initiatives, playing a pivotal role in transitioning data processing and handling systems to modern cloud-based platforms. \n Data Handling: Employ best practices in data handling, ensuring the integrity, security, and accessibility of data assets while complying with relevant regulations. \n \n Job Type: Contract \n Pay: $58.00 - $68.00 per hour ",
        "techs": [
            "scala",
            "java",
            "python",
            "apache spark",
            "hbase",
            "hive",
            "aws (emr",
            "s3",
            "redshift)",
            "on-premises",
            "cloud",
            "data migration",
            "computer science",
            "data science",
            "problem-solving",
            "communication",
            "teamwork"
        ],
        "cleaned_techs": [
            "scala",
            "java",
            "python",
            "apache spark",
            "hbase",
            "hive",
            "aws",
            "s3",
            "redshift)",
            "on-premises",
            "cloud",
            "data migration",
            "computer science",
            "data science",
            "problem-solving",
            "communication",
            "teamwork"
        ]
    },
    "c1d4278a1faa31b3": {
        "terms": [
            "data science"
        ],
        "salary_min": 227500.0,
        "salary_max": 292500.0,
        "title": "Director, Data Science and Analytics",
        "company": "Circle",
        "desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  Circle is looking for a Director, Data Science & Analytics to work closely with the Business, Product, and Engineering to produce analysis, deep research, and scalable data practices. This role has the opportunity to significantly impact internal data consumption and decision making. We are a passionate team with a deeply analytical approach, and your work will support us in our mission to be a world-class company driven by data. \n  What you'll work on: \n \n Build road maps, prioritize and drive data science and analytics efforts, communicate cross-functionally, and be a domain expert \n Support the individual and career growth of team members to minimize attrition and enhance output \n Partner with product and operations teams to identify and resolve analytical problems at scale in a variety of domains, including crypto ecosystem understanding, developers, accounting and financial processes, fraud detection, and risk management \n Help your team ideate and complete the right analysis, models, and stories \n Become an expert on data sources and flows at Circle \n Evangelize the power of data science to understand and improve our business and operations. \n \n You will aspire to our four core values: \n \n Multistakeholder -  you have dedication and commitment to our customers, shareholders, employees and families and local communities. \n Mindful -  you seek to be respectful, an active listener and to pay attention to detail. \n Driven by Excellence -  you are driven by our mission and our passion for customer success which means you relentlessly pursue excellence, that you do not tolerate mediocrity and you work intensely to achieve your goals. \n High Integrity -  you seek open and honest communication, and you hold yourself to very high moral and ethical standards. You reject manipulation, dishonesty and intolerance. \n \n What you'll bring to Circle: \n \n 12+ years of industry experience working with and analyzing large data sets \n 5+ years of experience with technical leadership and people management \n Knowledge of a scientific computing language (Python) and SQL \n Theoretical and applied expertise in statistics, experimental design, and analysis \n Experience building reporting systems and dashboards \n Strong communicator who can take complex ideas and methodologies, and simplify them for non-technical audiences \n Ability to understand complex business problems and break down analytics projects into a structured approach \n Track record of managing data scientists and analysts, both individual contributors and managers \n Experience managing remote teams \n \n Additional Information: \n \n This position is eligible for day-one PERM sponsorship for qualified candidates. \n \n Circle is on a mission to create an inclusive financial future, with transparency at our core. We consider a wide variety of elements when crafting our compensation ranges and total compensation packages. \n  Starting pay is determined by various factors, including but not limited to: relevant experience, skill set, qualifications, and other business and organizational needs. Please note that compensation ranges may differ for candidates in other locations. \n  Base Pay Range: $227,500 - $292,500 \n  Annual Bonus Target: 20% \n  Also Included: Equity & Benefits (including medical, dental, vision and 401(k)). Circle has a discretionary vacation policy. We also provide 10 days of paid sick leave per year and 11 paid holidays per year in the U.S. \n \n  We are an  equal opportunity employer  and value diversity at Circle. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Additionally, Circle participates in the  E-Verify Program  in certain locations, as required by law. \n  #LI-Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "79915f96f14a11c0": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 0.0,
        "salary_max": 85000.0,
        "title": "Delivery Engineer (US)",
        "company": "Kalibrate",
        "desc": "Kalibrate \n  We are the technology company whose software platforms provides microlocal insight so organizations can make location critical business decisions with confidence \n  We exist to help organizations make better decisions \u2013 so they can identify opportunities, understand risk, invest smarter, boost profits, and outperform the competition. \n \n  With the power of sophisticated data science, machine learning, and AI, we analyse countless data sources to identify the information that matters \u2013 enabling our customers to truly know their market and answer their most critical business questions. \n  We want to support a world without guesswork \u2013 where every organization has access to the insights that drive economic growth and shape successful communities, today and tomorrow. \n  The Kalibrate team work across the globe, tirelessly supporting 300+ customers in 70+ countries. \n \n  Role \n  The Senior Delivery Engineer is responsible for the delivery and continual improvement of Kalibrate software implementation services. The team also provides engineering services for a wide range of highly available technologies which underpin the delivery of Kalibrate\u2019s retail planning applications. \n \n  A core focus of the role is the configuration and delivery of client-specific software solutions within our multi-tenant hosting environment. The role includes data loading and automation, software configuration and design, and troubleshooting and maintenance on Technical Delivery team projects. \n \n \n  In this varied and exciting role, you will be the \u2018go-to' person who will be responsible for providing technical advice and planning to our internal teams and customers. Working autonomously, you help plan and configure a range of technical solutions liaising closely with Data Science, Product Development, and Project teams as well as other key stakeholders both within the business and directly with our customers. \n  To be successful in this role you will be a proactive and motivated individual who is passionate about our customers, software, have strong technical skills with good analytical and problem-solving skills. Above all else you are a team player who can work in co-operation with colleagues efficiently and productively. \n \n  The salary for this role is up to $85K annually plus a nice benefits package including health/dental/vision insurance benefits, paid maternity/paternity leave and 401K . \n    We are offering a fully remote opportunity, but if you live near one of our office locations then you are welcome there as well. \n \n \n \n SQL Server (T-SQL, Administration, and Implementation). \n \n \n Database modelling and structure. \n \n \n Advanced concepts such as Trigger, View, and Stored Procedure. \n \n \n Understanding of Optimization and Scaling Approaches and ability to translate business requirements into technical solutions. \n \n \n A good understanding of GitHub, PowerShell/Python Scripting, and GIS/Spatial Analysis is a big plus. \n \n \n Ability and willingness to mentor/guide more junior staff members on best practices. \n \n \n Experience working in a Change-controlled environment. \n \n \n  If this is you, apply today!!",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "2034ea1a7a57f5c7": {
        "terms": [
            "data science"
        ],
        "salary_min": 131598.64,
        "salary_max": 166633.2,
        "title": "AI/ML Lead (W2 Only)",
        "company": "ALTA IT Services",
        "desc": "AI/ML Lead US citizenship required 100% remote \u2013 East Coast candidates preferred Must be able to obtain a Public Trust clearance W2 ONLY As an AI/ML Lead, you\u2019ll analyze complex datasets to assess performance or find new patterns and apply machine learning techniques to data sets related to immigration, with the goal to make an impact across the federal government. What you\u2019ll do: \u2022 Lead architectural design, technical support, and advisement services to ensure identity management system technologies are integrated and meeting the appropriate security requirements \u2022 Present results to a diverse audience in presentation or report form and support leadership who engage with senior-level executives at a public-facing Federal agency and provide subject matter expertise in security architecture and other key domain areas. \u2022 You'll analyze complex datasets to assess performance or find new patterns \u2022 You'll apply machine learning techniques to data sets related to immigration \u2022 You'll present results to a diverse audience in presentation or report form \u2022 You'll lead architectural design, technical support, and advisement services to ensure identity management system technologies are integrated and meeting the appropriate security requirements \u2022 You\u2019ll support leadership who engage with senior level executives at a public facing Federal agency and provide subject matter expertise in security architecture and other key domain areas What you\u2019ll need to succeed: \u2022 A minimum of 10 years of IT experience, focusing on enterprise data architecture and management. \u2022 (10) Relational and Dimensional Data Modeling. \u2022 At least 8 years of experience in Conceptual/Logical/Physical data modeling. \u2022 Experience in modeling solutions in AWS that us AI/ML algorithms and in in cloud architecture, specifically AWS, as it relates to data processing (i.e., EC2, S3, Redshift, etc.). \u2022 At least 10 years of proven expertise in Relational and Dimensional Data Modeling. \u2022 Ability to define & maintain BI/Data Warehouse methodologies, standards, and industry best practices. \u2022 Experience leading and architecting enterprise-wide initiatives, specifically system integration, data migration, transformation, data warehouse build, data mart build, data lakes implementation/support, as well as O&M etc. for a large enterprise. \u2022 Expertise in large-scale database requirements supporting diverse data types and experience briefing the benefits and constraints of technology solutions to technology partners, stakeholders, team members, and senior levels of management. \u2022 A bachelor\u2019s degree (Data Science, Statistics, Computer Science, Information Technology Management or Engineering, or other comparable degree or experience) and the ability to obtain and maintain a DHS Suitability. \n \n \n AI/ML Lead \n \n US citizenship required \n \n 100% remote \u2013 East Coast candidates preferred \n \n Must be able to obtain a Public Trust clearance \n \n W2 ONLY \n \n  As an AI/ML Lead, you\u2019ll analyze complex datasets to assess performance or find new patterns and apply machine learning techniques to data sets related to immigration, with the goal to make an impact across the federal government. \n  \n \n What you\u2019ll do: \n \n \n Lead architectural design, technical support, and advisement services to ensure identity management system technologies are integrated and meeting the appropriate security requirements  \n Present results to a diverse audience in presentation or report form and support leadership who engage with senior-level executives at a public-facing Federal agency and provide subject matter expertise in security architecture and other key domain areas.  \n You'll analyze complex datasets to assess performance or find new patterns  \n You'll apply machine learning techniques to data sets related to immigration  \n You'll present results to a diverse audience in presentation or report form  \n You'll lead architectural design, technical support, and advisement services to ensure identity management system technologies are integrated and meeting the appropriate security requirements  \n You\u2019ll support leadership who engage with senior level executives at a public facing Federal agency and provide subject matter expertise in security architecture and other key domain areas  \n \n \n What you\u2019ll need to succeed: \n \n \n A minimum of 10 years of IT experience, focusing on enterprise data architecture and management.  \n (10) Relational and Dimensional Data Modeling.  \n At least 8 years of experience in Conceptual/Logical/Physical data modeling.  \n Experience in modeling solutions in AWS that us AI/ML algorithms and in in cloud architecture, specifically AWS, as it relates to data processing (i.e., EC2, S3, Redshift, etc.).  \n At least 10 years of proven expertise in Relational and Dimensional Data Modeling.  \n Ability to define & maintain BI/Data Warehouse methodologies, standards, and industry best practices.  \n Experience leading and architecting enterprise-wide initiatives, specifically system integration, data migration, transformation, data warehouse build, data mart build, data lakes implementation/support, as well as O&M etc. for a large enterprise.  \n Expertise in large-scale database requirements supporting diverse data types and experience briefing the benefits and constraints of technology solutions to technology partners, stakeholders, team members, and senior levels of management.  \n A bachelor\u2019s degree (Data Science, Statistics, Computer Science, Information Technology Management or Engineering, or other comparable degree or experience) and the ability to obtain and maintain a DHS Suitability. \n \n \n \n  BA",
        "cleaned_desc": "AI/ML Lead US citizenship required 100% remote \u2013 East Coast candidates preferred Must be able to obtain a Public Trust clearance W2 ONLY As an AI/ML Lead, you\u2019ll analyze complex datasets to assess performance or find new patterns and apply machine learning techniques to data sets related to immigration, with the goal to make an impact across the federal government. What you\u2019ll do: \u2022 Lead architectural design, technical support, and advisement services to ensure identity management system technologies are integrated and meeting the appropriate security requirements \u2022 Present results to a diverse audience in presentation or report form and support leadership who engage with senior-level executives at a public-facing Federal agency and provide subject matter expertise in security architecture and other key domain areas. \u2022 You'll analyze complex datasets to assess performance or find new patterns \u2022 You'll apply machine learning techniques to data sets related to immigration \u2022 You'll present results to a diverse audience in presentation or report form \u2022 You'll lead architectural design, technical support, and advisement services to ensure identity management system technologies are integrated and meeting the appropriate security requirements \u2022 You\u2019ll support leadership who engage with senior level executives at a public facing Federal agency and provide subject matter expertise in security architecture and other key domain areas What you\u2019ll need to succeed: \u2022 A minimum of 10 years of IT experience, focusing on enterprise data architecture and management. \u2022 (10) Relational and Dimensional Data Modeling. \u2022 At least 8 years of experience in Conceptual/Logical/Physical data modeling. \u2022 Experience in modeling solutions in AWS that us AI/ML algorithms and in in cloud architecture, specifically AWS, as it relates to data processing (i.e., EC2, S3, Redshift, etc.). \u2022 At least 10 years of proven expertise in Relational and Dimensional Data Modeling. \u2022 Ability to define & maintain BI/Data Warehouse methodologies, standards, and industry best practices. \u2022 Experience leading and architecting enterprise-wide initiatives, specifically system integration, data migration, transformation, data warehouse build, data mart build, data lakes implementation/support, as well as O&M etc. for a large enterprise. \u2022 Expertise in large-scale database requirements supporting diverse data types and experience briefing the benefits and constraints of technology solutions to technology partners, stakeholders, team members, and senior levels of management. \u2022 A bachelor\u2019s degree (Data Science, Statistics, Computer Science, Information Technology Management or Engineering, or other comparable degree or experience) and the ability to obtain and maintain a DHS Suitability. \n \n \n AI/ML Lead \n \n US citizenship required \n \n 100% remote \u2013 East Coast candidates preferred   (10) Relational and Dimensional Data Modeling.  \n At least 8 years of experience in Conceptual/Logical/Physical data modeling.  \n Experience in modeling solutions in AWS that us AI/ML algorithms and in in cloud architecture, specifically AWS, as it relates to data processing (i.e., EC2, S3, Redshift, etc.).  \n At least 10 years of proven expertise in Relational and Dimensional Data Modeling.  \n Ability to define & maintain BI/Data Warehouse methodologies, standards, and industry best practices.  \n Experience leading and architecting enterprise-wide initiatives, specifically system integration, data migration, transformation, data warehouse build, data mart build, data lakes implementation/support, as well as O&M etc. for a large enterprise.  \n Expertise in large-scale database requirements supporting diverse data types and experience briefing the benefits and constraints of technology solutions to technology partners, stakeholders, team members, and senior levels of management.  \n A bachelor\u2019s degree (Data Science, Statistics, Computer Science, Information Technology Management or Engineering, or other comparable degree or experience) and the ability to obtain and maintain a DHS Suitability. ",
        "techs": [
            "aws",
            "ec2",
            "s3",
            "redshift"
        ],
        "cleaned_techs": [
            "aws",
            "ec2",
            "s3",
            "redshift"
        ]
    },
    "fc2a1fcacc97b117": {
        "terms": [
            "data science"
        ],
        "salary_min": 83905.62,
        "salary_max": 106243.21,
        "title": "Brokerage Ops Specialist",
        "company": "Afterpay",
        "desc": "Company Description \n \n \n \n     It all started with an idea at Block in 2013. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic ecosystem, developing unique financial products, including Afterpay/Clearpay, to provide a better way to send, spend, invest, borrow and save to our 47 million monthly active customers. We want to redefine the world\u2019s relationship with money to make it more relatable, instantly available, and universally accessible.\n     \n  Today, Cash App has thousands of employees working globally across office and remote locations, with a culture geared toward innovation, collaboration and impact. We\u2019ve been a distributed team since day one, and many of our roles can be done remotely from the countries where Cash App operates. No matter the location, we tailor our experience to ensure our employees are creative, productive, and happy.\n     \n  Check out our locations, benefits, and more at cash.app/careers.\n    \n \n \n \n \n  Job Description \n \n \n  We've recently introduced Cash App Investing and now you can instantly buy stock in your favorite companies with as little as $1 using our free fractional trading feature! We're looking for a world class talent to join our broker-dealer subsidiary, Cash App Investing LLC. The ideal candidate for this role is someone who has deep experience in brokerage operations. \n  You will: \n \n  This role is within the account operations team at Cash App Investing and reports to the brokerage operations accounts lead. \n  Provide subject matter expertise on strategic initiatives related to brokerage functions. \n  Document standard operating procedures and job aids and update as needed. \n  Identify areas for process improvement and work toward implementation with respective teams. \n  Scale processes to operate broker-dealer. \n  Willing to work and get comfortable with ambiguity in a fast paced environment. \n  Works closely with peers to provide support in functional areas of operation and provides feedback \n  Reviews and actions accounts in accordance with firm policy and procedure. \n  Assist in establish controls, metrics, and data in partnership with Data Science for Brokerage operational use. \n  Collaborates with lead, peers, and cross functional teams to identify areas of opportunity and risks. \n  Performs and completes daily operational processing functions and maintains records in accordance with firms Written Supervisory Procedures and operational processes. \n  High-level understanding of SEC / FINRA regulations that pertain to the subject matter. \n  Collaborates with engineering, support, and product teams to facilitate improvements and increase efficiency within the current back office structure for the broker-dealer\u2019s risk operation. \n \n \n \n \n \n  Qualifications \n \n \n  You have: \n \n  5+ years of experience in brokerage operations. \n  Active FINRA Licenses: Series 7 & 63 required. \n  Fundamental SQL knowledge/experience \n  Functional experience with Looker / Tableau or other data analytics tools. \n  Brokerage operations generalist, you have worked in various functions of a brokerage operations team which may include accounts, risk, fraud, trading, etc. \n  Knowledge and respect for SEC/FINRA regulatory and compliance rules and regulations. \n  Well versed in collaborating with peer disciplines such as Product, Engineering, Data Science, Compliance etc \n  Technical experience scaling processes or managing projects. \n  Highly organized and detail oriented. \n  Someone who thrives in a highly collaborative and fast-paced environment. \n  Excellent verbal and written communication skills. \n  A passion for our mission of economic empowerment through serving the underserved \n \n \n \n \n \n  Additional Information \n \n \n  Block takes a market-based approach to pay, and pay may vary depending on your location. U.S. locations are categorized into one of four zones based on a cost of labor index for that geographic area. The successful candidate\u2019s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. These ranges may be modified in the future.    Zone A: USD $94,400 - USD $115,400  Zone B: USD $87,800 - USD $107,400  Zone C: USD $80,300 - USD $98,100  Zone D: USD $70,800 - USD $86,600 \n \n  To find a location\u2019s zone designation, please refer to this resource. If a location of interest is not listed, please speak with a recruiter for additional information. \n  Full-time employee benefits include the following: \n \n  Healthcare coverage (Medical, Vision and Dental insurance) \n  Health Savings Account and Flexible Spending Account \n  Retirement Plans including company match \n  Employee Stock Purchase Program \n  Wellness programs, including access to mental health, 1:1 financial planners, and a monthly wellness allowance \n  Paid parental and caregiving leave \n  Paid time off (including 12 paid holidays) \n  Paid sick leave (1 hour per 26 hours worked (max 80 hours per calendar year to the extent legally permissible) for non-exempt employees and covered by our Flexible Time Off policy for exempt employees) \n  Learning and Development resources \n  Paid Life insurance, AD&D, and disability benefits \n  Additional Perks such as WFH reimbursements and free access to caregiving, legal, and discounted resources \n \n  These benefits are further detailed in Block's policies. This role is also eligible to participate in Block's equity plan subject to the terms of the applicable plans and policies, and may be eligible for a sign-on bonus. Sales roles may be eligible to participate in a commission plan subject to the terms of the applicable plans and policies. Pay and benefits are subject to change at any time, consistent with the terms of any applicable compensation or benefit plans. \n  US and Canada EEOC Statement \n  We\u2019re working to build a more inclusive economy where our customers have equal access to opportunity, and we strive to live by these same values in building our workplace. Block is a proud equal opportunity employer. We work hard to evaluate all employees and job applicants consistently, without regard to race, color, religion, gender, national origin, age, disability, pregnancy, gender expression or identity, sexual orientation, citizenship, or any other legally protected class. \n  We believe in being fair, and are committed to an inclusive interview experience, including providing reasonable accommodations to disabled applicants throughout the recruitment process. We encourage applicants to share any needed accommodations with their recruiter, who will treat these requests as confidentially as possible.  Want to learn more about what we\u2019re doing to build a workplace that is fair and square? \n  Additionally, we consider qualified applicants with criminal histories for employment on our team, and always assess candidates on an individualized basis. \n \n \n  Block, Inc. (NYSE: SQ) is a global technology company with a focus on financial services. Made up of Square, Cash App, Spiral, TIDAL, and TBD, we build tools to help more people access the economy. Square helps sellers run and grow their businesses with its integrated ecosystem of commerce solutions, business software, and banking services. With Cash App, anyone can easily send, spend, or invest their money in stocks or Bitcoin. Spiral (formerly Square Crypto) builds and funds free, open-source Bitcoin projects. Artists use TIDAL to help them succeed as entrepreneurs and connect more deeply with fans. TBD is building an open developer platform to make it easier to access Bitcoin and other blockchain technologies without having to go through an institution.",
        "cleaned_desc": " \n \n \n \n  Qualifications \n \n \n  You have: \n \n  5+ years of experience in brokerage operations. \n  Active FINRA Licenses: Series 7 & 63 required. \n  Fundamental SQL knowledge/experience \n  Functional experience with Looker / Tableau or other data analytics tools. \n  Brokerage operations generalist, you have worked in various functions of a brokerage operations team which may include accounts, risk, fraud, trading, etc. \n  Knowledge and respect for SEC/FINRA regulatory and compliance rules and regulations. \n  Well versed in collaborating with peer disciplines such as Product, Engineering, Data Science, Compliance etc \n  Technical experience scaling processes or managing projects. ",
        "techs": [
            "fundamental sql knowledge/experience",
            "functional experience with looker/tableau or other data analytics tools"
        ],
        "cleaned_techs": [
            "fundamental sql knowledge/experience",
            "functional experience with looker/tableau or other data analytics tools"
        ]
    },
    "210f7e4f8bb86bff": {
        "terms": [
            "data science"
        ],
        "salary_min": 227500.0,
        "salary_max": 292500.0,
        "title": "Director, Data Science and Analytics",
        "company": "Circle",
        "desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  Circle is looking for a Director, Data Science & Analytics to work closely with the Business, Product, and Engineering to produce analysis, deep research, and scalable data practices. This role has the opportunity to significantly impact internal data consumption and decision making. We are a passionate team with a deeply analytical approach, and your work will support us in our mission to be a world-class company driven by data. \n  What you'll work on: \n \n Build road maps, prioritize and drive data science and analytics efforts, communicate cross-functionally, and be a domain expert \n Support the individual and career growth of team members to minimize attrition and enhance output \n Partner with product and operations teams to identify and resolve analytical problems at scale in a variety of domains, including crypto ecosystem understanding, developers, accounting and financial processes, fraud detection, and risk management \n Help your team ideate and complete the right analysis, models, and stories \n Become an expert on data sources and flows at Circle \n Evangelize the power of data science to understand and improve our business and operations. \n \n You will aspire to our four core values: \n \n Multistakeholder -  you have dedication and commitment to our customers, shareholders, employees and families and local communities. \n Mindful -  you seek to be respectful, an active listener and to pay attention to detail. \n Driven by Excellence -  you are driven by our mission and our passion for customer success which means you relentlessly pursue excellence, that you do not tolerate mediocrity and you work intensely to achieve your goals. \n High Integrity -  you seek open and honest communication, and you hold yourself to very high moral and ethical standards. You reject manipulation, dishonesty and intolerance. \n \n What you'll bring to Circle: \n \n 12+ years of industry experience working with and analyzing large data sets \n 5+ years of experience with technical leadership and people management \n Knowledge of a scientific computing language (Python) and SQL \n Theoretical and applied expertise in statistics, experimental design, and analysis \n Experience building reporting systems and dashboards \n Strong communicator who can take complex ideas and methodologies, and simplify them for non-technical audiences \n Ability to understand complex business problems and break down analytics projects into a structured approach \n Track record of managing data scientists and analysts, both individual contributors and managers \n Experience managing remote teams \n \n Additional Information: \n \n This position is eligible for day-one PERM sponsorship for qualified candidates. \n \n Circle is on a mission to create an inclusive financial future, with transparency at our core. We consider a wide variety of elements when crafting our compensation ranges and total compensation packages. \n  Starting pay is determined by various factors, including but not limited to: relevant experience, skill set, qualifications, and other business and organizational needs. Please note that compensation ranges may differ for candidates in other locations. \n  Base Pay Range: $227,500 - $292,500 \n  Annual Bonus Target: 20% \n  Also Included: Equity & Benefits (including medical, dental, vision and 401(k)). Circle has a discretionary vacation policy. We also provide 10 days of paid sick leave per year and 11 paid holidays per year in the U.S. \n \n  We are an  equal opportunity employer  and value diversity at Circle. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Additionally, Circle participates in the  E-Verify Program  in certain locations, as required by law. \n  #LI-Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "a72204e73484d77b": {
        "terms": [
            "data science"
        ],
        "salary_min": 93300.0,
        "salary_max": 212000.0,
        "title": "Innovation Lead",
        "company": "Booz Allen Hamilton",
        "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Reston,VA,US \n         \n \n \n \n         Remote Work: \n         \n \n         Hybrid \n         \n \n \n \n         Job Number: \n         \n \n         R0182354\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Innovation Lead\n           The Opportunity: \n  Are you at the nexus of systems design, architecture, facilitation, and collaboration? Are you passionate about learning and researching industry trends to orchestrate introduction of new technology into a large technical enterprise. You are an innovation lead! You\u2019ve evolved your skills into strategy through a long path of software development or architecture accomplishments and the curiosity to understand how all the pieces of an IT ecosystem fit together. Are you ready to use your combination of knowledge, skill, and experience to take on the present elegant solutions to complex problems in national security? \n \n  As an Innovation Lead on our team, you'll facilitate technology insertion and partnership, working with clients, an immensely talented and driven team, and industry. Through your leadership, we\u2019ll help transform the way client uses technology including cloud migration, integrating advanced technology, and modernizing legacy systems. And, what do you do next in a career where you\u2019ve reached this level? You facilitate and orchestrate partnerships with industry and firm leading capabilities to launch new technology, processes for mission impact. As a technical leader, you\u2019ll shape the digital solutions business and identify opportunities for growth. \n \n  Work with us and build the future of technology national security for the better. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  5+ years of experience with solutions architecture, enterprise architecture, or technical lead \n  3+ years of experience with project or product management \n  Experience with evaluating technologies, conducting gap analysis, and performing analysis of alternatives \n  Experience in working and collaborating with clients, technical staff, and engineers, including pitching new technologies, ideas, and concepts \n  Experience with maintaining industry relationships via conferences, meetups, and evaluating and establishing vendor agreements, including SLAs, License Agreements, or User Agreements \n  Experience with writing technology whitepapers or strategy documents surrounding technology insertion \n  Knowledge of industry leading technologies and processes, including Cloud, Container Orchestration, Microservices, Lakehouse and Data Lake, Data Science, and Agile methodologies \n  Ability to author presentations and technology roadmaps, facilitate client discussions surrounding technology insertion, learn and apply new technologies quickly in a fast-paced client environment, maintain a working knowledge of industry and firm technologies, and facilitate discussions with senior program and government staff \n  Top Secret clearance \n  Bachelor's degree \n \n \n  Nice If You Have: \n \n  Experience with software development and integration \n  Experience with data engineering or data science \n  Experience with working on research and development software efforts and initiatives \n  Experience with performing software engineering in support of DoD or IC agencies \n  Experience with Organizational Transformation and Design \n  Experience with the Systems Development Life Cycle (SDLC) \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Top Secret clearance is required. \n  Create Your Career: \n  Grow With Us  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll build your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $93,300.00 to $212,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",
        "cleaned_desc": "  3+ years of experience with project or product management \n  Experience with evaluating technologies, conducting gap analysis, and performing analysis of alternatives \n  Experience in working and collaborating with clients, technical staff, and engineers, including pitching new technologies, ideas, and concepts \n  Experience with maintaining industry relationships via conferences, meetups, and evaluating and establishing vendor agreements, including SLAs, License Agreements, or User Agreements \n  Experience with writing technology whitepapers or strategy documents surrounding technology insertion \n  Knowledge of industry leading technologies and processes, including Cloud, Container Orchestration, Microservices, Lakehouse and Data Lake, Data Science, and Agile methodologies \n  Ability to author presentations and technology roadmaps, facilitate client discussions surrounding technology insertion, learn and apply new technologies quickly in a fast-paced client environment, maintain a working knowledge of industry and firm technologies, and facilitate discussions with senior program and government staff \n  Top Secret clearance \n  Bachelor's degree \n \n \n  Nice If You Have: \n \n  Experience with software development and integration \n  Experience with data engineering or data science \n  Experience with working on research and development software efforts and initiatives \n  Experience with performing software engineering in support of DoD or IC agencies \n  Experience with Organizational Transformation and Design \n  Experience with the Systems Development Life Cycle (SDLC) \n \n ",
        "techs": [
            "project or product management",
            "evaluating technologies",
            "conducting gap analysis",
            "performing analysis of alternatives",
            "working and collaborating with clients",
            "technical staff",
            "and engineers",
            "maintaining industry relationships",
            "evaluating and establishing vendor agreements",
            "writing technology whitepapers",
            "strategy documents",
            "cloud",
            "container orchestration",
            "microservices",
            "lakehouse",
            "data lake",
            "data science",
            "agile methodologies",
            "authoring presentations",
            "technology roadmaps",
            "facilitating client discussions",
            "learning and applying new technologies quickly",
            "maintaining a working knowledge of industry and firm technologies",
            "facilitating discussions with senior program and government staff",
            "top secret clearance",
            "bachelor's degree",
            "software development and integration",
            "data engineering",
            "data science",
            "working on research and development software efforts and initiatives",
            "performing software engineering in support of dod or ic agencies",
            "organizational transformation and design",
            "systems development life cycle (sdlc)"
        ],
        "cleaned_techs": [
            "project or product management",
            "evaluating technologies",
            "conducting gap analysis",
            "performing analysis of alternatives",
            "technical staff",
            "and engineers",
            "maintaining industry relationships",
            "evaluating and establishing vendor agreements",
            "writing technology whitepapers",
            "strategy documents",
            "cloud",
            "container orchestration",
            "microservices",
            "lakehouse",
            "data lake",
            "data science",
            "agile methodologies",
            "authoring presentations",
            "technology roadmaps",
            "facilitating client discussions",
            "learning and applying new technologies quickly",
            "maintaining a working knowledge of industry and firm technologies",
            "facilitating discussions with senior program and government staff",
            "top secret clearance",
            "software development and integration",
            "working on research and development software efforts and initiatives",
            "performing software engineering in support of dod or ic agencies",
            "organizational transformation and design",
            "systems development life cycle (sdlc)"
        ]
    },
    "f8b36c2ed479faa8": {
        "terms": [
            "data science"
        ],
        "salary_min": 227500.0,
        "salary_max": 292500.0,
        "title": "Director, Data Science and Analytics",
        "company": "Circle",
        "desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  Circle is looking for a Director, Data Science & Analytics to work closely with the Business, Product, and Engineering to produce analysis, deep research, and scalable data practices. This role has the opportunity to significantly impact internal data consumption and decision making. We are a passionate team with a deeply analytical approach, and your work will support us in our mission to be a world-class company driven by data. \n  What you'll work on: \n \n Build road maps, prioritize and drive data science and analytics efforts, communicate cross-functionally, and be a domain expert \n Support the individual and career growth of team members to minimize attrition and enhance output \n Partner with product and operations teams to identify and resolve analytical problems at scale in a variety of domains, including crypto ecosystem understanding, developers, accounting and financial processes, fraud detection, and risk management \n Help your team ideate and complete the right analysis, models, and stories \n Become an expert on data sources and flows at Circle \n Evangelize the power of data science to understand and improve our business and operations. \n \n You will aspire to our four core values: \n \n Multistakeholder -  you have dedication and commitment to our customers, shareholders, employees and families and local communities. \n Mindful -  you seek to be respectful, an active listener and to pay attention to detail. \n Driven by Excellence -  you are driven by our mission and our passion for customer success which means you relentlessly pursue excellence, that you do not tolerate mediocrity and you work intensely to achieve your goals. \n High Integrity -  you seek open and honest communication, and you hold yourself to very high moral and ethical standards. You reject manipulation, dishonesty and intolerance. \n \n What you'll bring to Circle: \n \n 12+ years of industry experience working with and analyzing large data sets \n 5+ years of experience with technical leadership and people management \n Knowledge of a scientific computing language (Python) and SQL \n Theoretical and applied expertise in statistics, experimental design, and analysis \n Experience building reporting systems and dashboards \n Strong communicator who can take complex ideas and methodologies, and simplify them for non-technical audiences \n Ability to understand complex business problems and break down analytics projects into a structured approach \n Track record of managing data scientists and analysts, both individual contributors and managers \n Experience managing remote teams \n \n Additional Information: \n \n This position is eligible for day-one PERM sponsorship for qualified candidates. \n \n Circle is on a mission to create an inclusive financial future, with transparency at our core. We consider a wide variety of elements when crafting our compensation ranges and total compensation packages. \n  Starting pay is determined by various factors, including but not limited to: relevant experience, skill set, qualifications, and other business and organizational needs. Please note that compensation ranges may differ for candidates in other locations. \n  Base Pay Range: $227,500 - $292,500 \n  Annual Bonus Target: 20% \n  Also Included: Equity & Benefits (including medical, dental, vision and 401(k)). Circle has a discretionary vacation policy. We also provide 10 days of paid sick leave per year and 11 paid holidays per year in the U.S. \n \n  We are an  equal opportunity employer  and value diversity at Circle. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Additionally, Circle participates in the  E-Verify Program  in certain locations, as required by law. \n  #LI-Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "ab52012039dea724": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 165408.58,
        "salary_max": 209444.11,
        "title": "Software Engineer, Machine Learning SDK - US (Remote)",
        "company": "Weights & Biases",
        "desc": "At Weights & Biases, our mission is to build the best developer tools for machine learning. Weights & Biases is a series C company with $250 million in funding and a rapidly growing user base. Our platform is an essential piece of the daily work for machine learning engineers, from academic research institutions like FAIR and UC Berkeley to massive enterprise teams including iRobot, OpenAI, Toyota Research Institute, Samsung, NVIDIA, Salesforce, Blue Cross Blue Shield, Lyft, and more.\n  \n \n \n  The Machine Learning Software Engineer, reporting to the SDK Team Manager, will be responsible for building the software development kit (SDK) which helps our users accelerate their machine learning projects and build better models faster. The role involves exploring the pain points experienced by Machine Learning Engineers who are building state-of-the-art models, designing solutions to address these issues, and implementing efficient and intuitive interfaces which integrate cleanly into the latest Machine Learning frameworks. The role involves working at the intersection of software development, machine learning, and novel product development.\n  \n Responsibilities \n \n  Collaborate with senior engineers to design and build a multi-platform / multi-language Machine Learning SDK in a public github repository \n  Build out support for advanced machine learning workflows, such as distributed training \n  Build, extend, and enhance a highly reliable and performant data ingest SDK \n  Design thoughtful solutions to capture user issues in different client setups, and capture the pertinent info for debugging \n  Creatively improve on current features, and seek out ways to simplify the API and streamline the user experience \n  Improve CLI and SDK interfaces, implement new integrations with popular ML frameworks as they're released \n  Keep up with the latest trends in the ML world and leverage existing tools and frameworks whenever necessary \n \n  Requirements \n \n  Communication and collaboration on cross-functional projects \n  Creative problem solving, and a willingness to dig into details \n  4+ years of professional software development, especially in Python \n  Experience contributing to architecture and systems design \n  Experience with ML frameworks such as PyTorch or TensorFlow \n \n  Our Benefits  \n \n \\uD83C\\uDFDD\ufe0f Flexible time off  \n \\uD83E\\uDE7A Medical, Dental, and Vision for employees and Family Coverage \n  \\uD83C\\uDFE0 Remote first culture with in-office flexibility in San Francisco \n  \\uD83D\\uDCB5 Home office budget with a new high-powered laptop \n  \\uD83E\\uDD47 Truly competitive salary and equity \n  \\uD83D\\uDEBC 12 weeks of Parental leave (U.S. specific) \n  \\uD83D\\uDCC8 401(k) (U.S. specific) \n  Supplemental benefits may be available depending on your location  \n Explore benefits by country \n \n \n   We encourage you to apply even if your experience doesn't perfectly align with the job description as we seek out diverse and creative perspectives. Team members who love to learn and collaborate in an inclusive environment will flourish with us. We are an equal opportunity employer and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. If you need additional accommodations to feel comfortable during your interview process, reach out at careers@wandb.com.\n  \n \n \n  #LI-Remote\n  \n \n \n  We encourage you to apply even if your experience doesn't perfectly align with the job description as we seek out diverse and creative perspectives. Team members who love to learn and collaborate in an inclusive environment will flourish with us. We are an equal opportunity employer and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. If you need additional accommodations to feel comfortable during your interview process, reach out at careers@wandb.com.\n  \n \n \n  #LI-Remote",
        "cleaned_desc": "At Weights & Biases, our mission is to build the best developer tools for machine learning. Weights & Biases is a series C company with $250 million in funding and a rapidly growing user base. Our platform is an essential piece of the daily work for machine learning engineers, from academic research institutions like FAIR and UC Berkeley to massive enterprise teams including iRobot, OpenAI, Toyota Research Institute, Samsung, NVIDIA, Salesforce, Blue Cross Blue Shield, Lyft, and more.\n  \n \n \n  The Machine Learning Software Engineer, reporting to the SDK Team Manager, will be responsible for building the software development kit (SDK) which helps our users accelerate their machine learning projects and build better models faster. The role involves exploring the pain points experienced by Machine Learning Engineers who are building state-of-the-art models, designing solutions to address these issues, and implementing efficient and intuitive interfaces which integrate cleanly into the latest Machine Learning frameworks. The role involves working at the intersection of software development, machine learning, and novel product development.\n  \n Responsibilities \n \n  Collaborate with senior engineers to design and build a multi-platform / multi-language Machine Learning SDK in a public github repository    Build out support for advanced machine learning workflows, such as distributed training \n  Build, extend, and enhance a highly reliable and performant data ingest SDK \n  Design thoughtful solutions to capture user issues in different client setups, and capture the pertinent info for debugging \n  Creatively improve on current features, and seek out ways to simplify the API and streamline the user experience \n  Improve CLI and SDK interfaces, implement new integrations with popular ML frameworks as they're released \n  Keep up with the latest trends in the ML world and leverage existing tools and frameworks whenever necessary \n \n  Requirements \n ",
        "techs": [
            "multi-platform / multi-language machine learning sdk",
            "distributed training support",
            "data ingest sdk",
            "cli",
            "sdk interfaces",
            "integrations with popular ml frameworks"
        ],
        "cleaned_techs": [
            "multi-platform / multi-language machine learning sdk",
            "distributed training support",
            "data ingest sdk",
            "cli",
            "sdk interfaces",
            "integrations with popular ml frameworks"
        ]
    },
    "c41c14c5c2c43e9e": {
        "terms": [
            "data science"
        ],
        "salary_min": 147500.0,
        "salary_max": 195000.0,
        "title": "Senior Data Engineer",
        "company": "Circle",
        "desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  As a member of the Data Engineering - Business ETL team, you own the ETL/ELT pipelines and data warehouse that is used for financial and regulatory reporting. Your work powers Circle business functions, including the Compliance, Finance, Accounting, and Analytics teams for experimentation, operational excellence, and actionable insights, so as to fuel and accelerate business growth. High integrity to data accuracy and quality is crucial. Your work will directly impact Circle's transparency, trust, and accountability needs. \n  What you'll work on: \n \n Collaborating with business teams on the design, deployment and continuous improvement of the scalable data platform that ingests, stores, and aggregates various datasets, including data pipelines, platforms, and warehouses, and surfacing data to both internal and customer-facing applications. \n Being a domain expert on data modeling, data pipelines, data quality and data warehousing. \n Designing, building and maintaining data ETL/ELT pipelines to source and aggregate the required data for various data analyses and reporting needs, as well as to continually improve the operations, monitoring and performance of the data warehouse. \n Developing integrations with third party systems to source, qualify and ingest various datasets. \n Providing data analytics and visualization tools to extract valuable insights from the data to enable data-driven decisions. \n Working closely with across groups, such as the product, engineering, data science, compliance, and security teams, for data modeling, general management of data life cycle, data governance and processes for meeting regulatory and legal requirements. \n \n You will aspire to our four core values: \n \n Multistakeholder - you have dedication and commitment to our customers, shareholders, employees and families and local communities. \n Mindful - you seek to be respectful, an active listener and to pay attention to detail. \n Driven by Excellence - you are driven by our mission and our passion for customer success which means you relentlessly pursue excellence, that you do not tolerate mediocrity and you work intensely to achieve your goals. \n High Integrity - you seek open and honest communication, and you hold yourself to very high moral and ethical standards. You reject manipulation, dishonesty and intolerance. \n \n What you'll bring to Circle: \n  For Senior Data Engineer (III) \n \n 4+ years of professional data engineering experience. \n Proficient in one or more programming languages (Java, Scala, Python). \n Advanced experience in SQL in big data warehouse systems such as Snowflake, BigQuery, Databricks, etc. \n Experience in SQL and NoSQL, such as MySQL, PostgreSQL, Cassandra, HBase, Redis, DynamoDB, Neo4j, etc. \n Experience with workflow orchestration management engines such as Airflow, Dagster, DBT, etc \n Experience with Cloud Services (AWS, Google Cloud, Microsoft Azure, etc). \n Experience in building scalable infrastructure to support batch, micro-batch or stream data processing for large volumes of data. \n Experience with financial or compliance data, bonus if in similar business domains, such as payment systems, credit cards, bank transfers, blockchains, etc. \n Experience in data provenance and governance. \n Internal knowledge of open source or related big data technologies. \n Ability to tackle complex and ambiguous problems. \n Self-starter who takes ownership, gets results, and enjoys moving at a fast pace. \n Excellent communication skills, able to collaborate with across remote teams, share ideas and present concepts effectively. \n \n For Staff Data Engineer (IV) \n  All the requirements of above and: \n \n 7+ years of professional data engineering experience. \n Led teams (>5) technically on architecture and system design. \n Expert in one of the domains of ETL/ELT pipelines, feature engineering, data modeling and architecture, or data ingestion. \n Experience working autonomously and able to identify large impactful projects to pursue with minimal guidance. \n Deep understanding/experience with: \n \n Data warehouse architecture and design \n Integration of the data stack to other tools/services \n Extensive knowledge with implementing data quality checks \n \n \n Additional Information: \n \n This position is eligible for day-one PERM sponsorship for qualified candidates. \n \n Circle is on a mission to create an inclusive financial future, with transparency at our core. We consider a wide variety of elements when crafting our compensation ranges and total compensation packages. \n  Starting pay is determined by various factors, including but not limited to: relevant experience, skill set, qualifications, and other business and organizational needs. Please note that compensation ranges may differ for candidates in other locations. \n  Senior Data Engineer (III) \n  Base Pay Range: $147,500 - $195,000 \n  Annual Bonus Target: 12.5% \n  Staff Data Engineer (IV) \n  Base Pay Range: $172,500 - $227,500 \n  Annual Bonus Target: 15% \n  Also Included: Equity & Benefits (including medical, dental, vision and 401(k)). Circle has a discretionary vacation policy. We also provide 10 days of paid sick leave per year and 11 paid holidays per year in the U.S. \n \n  We are an  equal opportunity employer  and value diversity at Circle. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Additionally, Circle participates in the  E-Verify Program  in certain locations, as required by law. \n  #LI-Remote",
        "cleaned_desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  As a member of the Data Engineering - Business ETL team, you own the ETL/ELT pipelines and data warehouse that is used for financial and regulatory reporting. Your work powers Circle business functions, including the Compliance, Finance, Accounting, and Analytics teams for experimentation, operational excellence, and actionable insights, so as to fuel and accelerate business growth. High integrity to data accuracy and quality is crucial. Your work will directly impact Circle's transparency, trust, and accountability needs. \n  What you'll work on: \n \n Collaborating with business teams on the design, deployment and continuous improvement of the scalable data platform that ingests, stores, and aggregates various datasets, including data pipelines, platforms, and warehouses, and surfacing data to both internal and customer-facing applications. \n Being a domain expert on data modeling, data pipelines, data quality and data warehousing. \n Designing, building and maintaining data ETL/ELT pipelines to source and aggregate the required data for various data analyses and reporting needs, as well as to continually improve the operations, monitoring and performance of the data warehouse. \n Developing integrations with third party systems to source, qualify and ingest various datasets. \n Providing data analytics and visualization tools to extract valuable insights from the data to enable data-driven decisions.   Proficient in one or more programming languages (Java, Scala, Python). \n Advanced experience in SQL in big data warehouse systems such as Snowflake, BigQuery, Databricks, etc. \n Experience in SQL and NoSQL, such as MySQL, PostgreSQL, Cassandra, HBase, Redis, DynamoDB, Neo4j, etc. \n Experience with workflow orchestration management engines such as Airflow, Dagster, DBT, etc \n Experience with Cloud Services (AWS, Google Cloud, Microsoft Azure, etc). \n Experience in building scalable infrastructure to support batch, micro-batch or stream data processing for large volumes of data. \n Experience with financial or compliance data, bonus if in similar business domains, such as payment systems, credit cards, bank transfers, blockchains, etc. \n Experience in data provenance and governance. \n Internal knowledge of open source or related big data technologies. \n Ability to tackle complex and ambiguous problems. \n Self-starter who takes ownership, gets results, and enjoys moving at a fast pace. \n Excellent communication skills, able to collaborate with across remote teams, share ideas and present concepts effectively. \n   For Staff Data Engineer (IV) \n  All the requirements of above and: \n \n 7+ years of professional data engineering experience. \n Led teams (>5) technically on architecture and system design. \n Expert in one of the domains of ETL/ELT pipelines, feature engineering, data modeling and architecture, or data ingestion. \n Experience working autonomously and able to identify large impactful projects to pursue with minimal guidance. \n Deep understanding/experience with: \n \n Data warehouse architecture and design \n Integration of the data stack to other tools/services \n Extensive knowledge with implementing data quality checks \n ",
        "techs": [
            "circle",
            "usdc",
            "blockchain",
            "data engineering",
            "etl/elt pipelines",
            "data warehouse",
            "compliance",
            "finance",
            "accounting",
            "analytics",
            "data modeling",
            "data quality",
            "data warehousing",
            "data etl/elt pipelines",
            "sql",
            "snowflake",
            "bigquery",
            "databricks",
            "mysql",
            "postgresql",
            "cassandra",
            "hbase",
            "redis",
            "dynamodb",
            "neo4j",
            "airflow",
            "dagster",
            "dbt",
            "cloud services",
            "aws",
            "google cloud",
            "microsoft azure",
            "batch processing",
            "micro-batch processing",
            "stream processing",
            "financial data",
            "compliance data",
            "open source technologies",
            "data provenance",
            "data governance"
        ],
        "cleaned_techs": [
            "circle",
            "usdc",
            "blockchain",
            "etl/elt pipelines",
            "data warehouse",
            "compliance",
            "finance",
            "accounting",
            "data quality",
            "data warehousing",
            "data etl/elt pipelines",
            "sql",
            "snowflake",
            "bigquery",
            "databricks",
            "mysql",
            "postgresql",
            "cassandra",
            "hbase",
            "redis",
            "dynamodb",
            "neo4j",
            "airflow",
            "dagster",
            "dbt",
            "cloud services",
            "aws",
            "gcp",
            "microsoft azure",
            "batch processing",
            "micro-batch processing",
            "stream processing",
            "financial data",
            "compliance data",
            "open source technologies",
            "data provenance",
            "data governance"
        ]
    },
    "f5df7096cfbdd58f": {
        "terms": [
            "data science"
        ],
        "salary_min": 227500.0,
        "salary_max": 292500.0,
        "title": "Director, Data Science and Analytics",
        "company": "Circle",
        "desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  Circle is looking for a Director, Data Science & Analytics to work closely with the Business, Product, and Engineering to produce analysis, deep research, and scalable data practices. This role has the opportunity to significantly impact internal data consumption and decision making. We are a passionate team with a deeply analytical approach, and your work will support us in our mission to be a world-class company driven by data. \n  What you'll work on: \n \n Build road maps, prioritize and drive data science and analytics efforts, communicate cross-functionally, and be a domain expert \n Support the individual and career growth of team members to minimize attrition and enhance output \n Partner with product and operations teams to identify and resolve analytical problems at scale in a variety of domains, including crypto ecosystem understanding, developers, accounting and financial processes, fraud detection, and risk management \n Help your team ideate and complete the right analysis, models, and stories \n Become an expert on data sources and flows at Circle \n Evangelize the power of data science to understand and improve our business and operations. \n \n You will aspire to our four core values: \n \n Multistakeholder -  you have dedication and commitment to our customers, shareholders, employees and families and local communities. \n Mindful -  you seek to be respectful, an active listener and to pay attention to detail. \n Driven by Excellence -  you are driven by our mission and our passion for customer success which means you relentlessly pursue excellence, that you do not tolerate mediocrity and you work intensely to achieve your goals. \n High Integrity -  you seek open and honest communication, and you hold yourself to very high moral and ethical standards. You reject manipulation, dishonesty and intolerance. \n \n What you'll bring to Circle: \n \n 12+ years of industry experience working with and analyzing large data sets \n 5+ years of experience with technical leadership and people management \n Knowledge of a scientific computing language (Python) and SQL \n Theoretical and applied expertise in statistics, experimental design, and analysis \n Experience building reporting systems and dashboards \n Strong communicator who can take complex ideas and methodologies, and simplify them for non-technical audiences \n Ability to understand complex business problems and break down analytics projects into a structured approach \n Track record of managing data scientists and analysts, both individual contributors and managers \n Experience managing remote teams \n \n Additional Information: \n \n This position is eligible for day-one PERM sponsorship for qualified candidates. \n \n Circle is on a mission to create an inclusive financial future, with transparency at our core. We consider a wide variety of elements when crafting our compensation ranges and total compensation packages. \n  Starting pay is determined by various factors, including but not limited to: relevant experience, skill set, qualifications, and other business and organizational needs. Please note that compensation ranges may differ for candidates in other locations. \n  Base Pay Range: $227,500 - $292,500 \n  Annual Bonus Target: 20% \n  Also Included: Equity & Benefits (including medical, dental, vision and 401(k)). Circle has a discretionary vacation policy. We also provide 10 days of paid sick leave per year and 11 paid holidays per year in the U.S. \n \n  We are an  equal opportunity employer  and value diversity at Circle. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Additionally, Circle participates in the  E-Verify Program  in certain locations, as required by law. \n  #LI-Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "c031d6618edf761a": {
        "terms": [
            "data science"
        ],
        "salary_min": 67896.0,
        "salary_max": 134849.0,
        "title": "Senior Quality Analyst (Remote)",
        "company": "CareFirst BlueCross BlueShield",
        "desc": "Resp & Qualifications   \n PURPOSE:   We are looking for an experienced professional to work remotely from within the greater Baltimore / Washington, DC metropolitan area. The incumbent will be expected to come into a CareFirst location periodically for meetings, training and/or other business related activities. This position will support the Federal Employee Program (FEP) line of business.  \n The Senior Quality Analyst is responsible for the most complex work of the team in defining, measuring, analyzing, and evaluating population health, while prioritizing, developing, and operationalizing innovative initiatives to improve the quality of care and experience, resulting in industry-leading outcomes at a population level. Independently responsible and accountable for ensuring that their work aligns with and helps to achieve the organization's vision as it relates to population health, quality, and member experience. Serves as peer mentor within the team.     ESSENTIAL FUNCTIONS: \n \n  Act as the organizations subject matter expert in population health, measurement science, accreditation, and quality improvement for the FEP line of business. Utilizes the framework of NCQA Accreditation to accomplish and document the work products. \n  Define, measure, and document the performance of the health plan in facilitating quality healthcare, positive outcomes, and excellent experience for FEP members. \n  Analyze and evaluate health plan performance using qualitative and quantitative methodologies, producing actionable and insightful reports and visualizations addressing population health quality opportunities.  \n Prioritize, develop, and operationalize these opportunities in collaboration with other areas of the organization into innovative Clinical Quality, Customer Service and Resource Use (QCR) programs and Quality related Performance Improvement programs.  \n Mentor team members and provides guidance on most complex work efforts. Assist with special projects and/or department initiatives that require thought leadership and subject matter expertise in a consultative manner. \n \n  QUALIFICATIONS:     Education Level:  Bachelor's Degree in Population Health, Public Health, Healthcare Administration, Business Administration, Health Policy, Economics, Statistics, Mathematics, Data Science, or a related field OR in lieu of a Bachelor's degree, an additional 4 years of relevant work experience is required in addition to the required work experience. \n  Licenses/Certifications  RN-BC - Certified General Nursing Practice Preferred.\n  \n \n Experience:  5 years professional experience in a business environment (public health, health insurance, management consulting fields preferred); evidence of progressing levels of responsibility.     Preferred Qualifications: \n \n  Certification in Quality or Process Improvement Methods. \n  Direct experience with accreditation, HEDIS, CAHPS and other quality related activities a healthcare related environment and/or payor organization, specifically for FEP line of business.  Data analytics experience working with large data sets to answer clinical, operational, or business questions; prior experience with healthcare data expected. \n  \n \n Knowledge, Skills and Abilities (KSAs) \n \n  Expertise in qualitative and quantitative data analyses and presentations. \n  End-to-end experience designing, developing, and implementing innovative strategies to improve population health. \n  Experience self-managing multiple projects and provide regular status reports. \n  Ability to conduct advanced analytics using SQL, Python, R, or similar. \n  Fluent in the use of Microsoft tools including Excel, Word, Power Point and Outlook. \n  Expertise with healthcare claims, survey, clinical, and health data. \n  Ability to mentor and guide other team members and lead initiatives in a matrix environment.  Must be able to meet established deadlines and handle multiple customer service demands from internal and external customers, within set expectations for service excellence. Must be able to effectively communicate and provide positive customer service to every internal and external customer, including customers who may be demanding or otherwise challenging.   \n \n   Salary Range:  $67,896 - $134,849 \n  Salary Range Disclaimer   \n The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the work is being performed. This compensation range is specific and considers factors such as (but not limited to) the scope and responsibilites of the position, the candidate's work experience, education/training, internal peer equity, and market and business consideration. It is not typical for an individual to be hired at the top of the range, as compensation decisions depend on each case's facts and circumstances, including but not limited to experience, internal equity, and location. In addition to your compensation, CareFirst offers a comprehensive benefits package, various incentive programs/plans, and 401k contribution programs/plans (all benefits/incentives are subject to eligibility requirements). \n  Department   \n Department:  Quality \n  Equal Employment Opportunity   \n CareFirst BlueCross BlueShield is an Equal Opportunity (EEO) employer. It is the policy of the Company to provide equal employment opportunities to all qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, protected veteran or disabled status, or genetic information. \n  Where To Apply   \n Please visit our website to apply: www.carefirst.com/careers \n  Federal Disc/Physical Demand   \n Note: The incumbent is required to immediately disclose any debarment, exclusion, or other event that makes him/her ineligible to perform work directly or indirectly on Federal health care programs. \n  PHYSICAL DEMANDS: \n  The associate is primarily seated while performing the duties of the position. Occasional walking or standing is required. The hands are regularly used to write, type, key and handle or feel small controls and objects. The associate must frequently talk and hear. Weights up to 25 pounds are occasionally lifted. \n  Sponsorship in US   \n Must be eligible to work in the U.S. without Sponsorship \n  #LI-CT1",
        "cleaned_desc": "  \n \n Knowledge, Skills and Abilities (KSAs) \n \n  Expertise in qualitative and quantitative data analyses and presentations. \n  End-to-end experience designing, developing, and implementing innovative strategies to improve population health. \n  Experience self-managing multiple projects and provide regular status reports. \n  Ability to conduct advanced analytics using SQL, Python, R, or similar. \n  Fluent in the use of Microsoft tools including Excel, Word, Power Point and Outlook. ",
        "techs": [
            "sql",
            "python",
            "r",
            "excel",
            "word",
            "power point",
            "outlook"
        ],
        "cleaned_techs": [
            "sql",
            "python",
            "r",
            "excel",
            "word",
            "power point",
            "outlook"
        ]
    },
    "5aef63a1622223bb": {
        "terms": [
            "data science"
        ],
        "salary_min": 227500.0,
        "salary_max": 292500.0,
        "title": "Director, Data Science and Analytics",
        "company": "Circle",
        "desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  Circle is looking for a Director, Data Science & Analytics to work closely with the Business, Product, and Engineering to produce analysis, deep research, and scalable data practices. This role has the opportunity to significantly impact internal data consumption and decision making. We are a passionate team with a deeply analytical approach, and your work will support us in our mission to be a world-class company driven by data. \n  What you'll work on: \n \n Build road maps, prioritize and drive data science and analytics efforts, communicate cross-functionally, and be a domain expert \n Support the individual and career growth of team members to minimize attrition and enhance output \n Partner with product and operations teams to identify and resolve analytical problems at scale in a variety of domains, including crypto ecosystem understanding, developers, accounting and financial processes, fraud detection, and risk management \n Help your team ideate and complete the right analysis, models, and stories \n Become an expert on data sources and flows at Circle \n Evangelize the power of data science to understand and improve our business and operations. \n \n You will aspire to our four core values: \n \n Multistakeholder -  you have dedication and commitment to our customers, shareholders, employees and families and local communities. \n Mindful -  you seek to be respectful, an active listener and to pay attention to detail. \n Driven by Excellence -  you are driven by our mission and our passion for customer success which means you relentlessly pursue excellence, that you do not tolerate mediocrity and you work intensely to achieve your goals. \n High Integrity -  you seek open and honest communication, and you hold yourself to very high moral and ethical standards. You reject manipulation, dishonesty and intolerance. \n \n What you'll bring to Circle: \n \n 12+ years of industry experience working with and analyzing large data sets \n 5+ years of experience with technical leadership and people management \n Knowledge of a scientific computing language (Python) and SQL \n Theoretical and applied expertise in statistics, experimental design, and analysis \n Experience building reporting systems and dashboards \n Strong communicator who can take complex ideas and methodologies, and simplify them for non-technical audiences \n Ability to understand complex business problems and break down analytics projects into a structured approach \n Track record of managing data scientists and analysts, both individual contributors and managers \n Experience managing remote teams \n \n Additional Information: \n \n This position is eligible for day-one PERM sponsorship for qualified candidates. \n \n Circle is on a mission to create an inclusive financial future, with transparency at our core. We consider a wide variety of elements when crafting our compensation ranges and total compensation packages. \n  Starting pay is determined by various factors, including but not limited to: relevant experience, skill set, qualifications, and other business and organizational needs. Please note that compensation ranges may differ for candidates in other locations. \n  Base Pay Range: $227,500 - $292,500 \n  Annual Bonus Target: 20% \n  Also Included: Equity & Benefits (including medical, dental, vision and 401(k)). Circle has a discretionary vacation policy. We also provide 10 days of paid sick leave per year and 11 paid holidays per year in the U.S. \n \n  We are an  equal opportunity employer  and value diversity at Circle. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Additionally, Circle participates in the  E-Verify Program  in certain locations, as required by law. \n  #LI-Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "1dec500afa07ad6a": {
        "terms": [
            "data science"
        ],
        "salary_min": 227500.0,
        "salary_max": 292500.0,
        "title": "Director, Data Science and Analytics",
        "company": "Circle",
        "desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  Circle is looking for a Director, Data Science & Analytics to work closely with the Business, Product, and Engineering to produce analysis, deep research, and scalable data practices. This role has the opportunity to significantly impact internal data consumption and decision making. We are a passionate team with a deeply analytical approach, and your work will support us in our mission to be a world-class company driven by data. \n  What you'll work on: \n \n Build road maps, prioritize and drive data science and analytics efforts, communicate cross-functionally, and be a domain expert \n Support the individual and career growth of team members to minimize attrition and enhance output \n Partner with product and operations teams to identify and resolve analytical problems at scale in a variety of domains, including crypto ecosystem understanding, developers, accounting and financial processes, fraud detection, and risk management \n Help your team ideate and complete the right analysis, models, and stories \n Become an expert on data sources and flows at Circle \n Evangelize the power of data science to understand and improve our business and operations. \n \n You will aspire to our four core values: \n \n Multistakeholder -  you have dedication and commitment to our customers, shareholders, employees and families and local communities. \n Mindful -  you seek to be respectful, an active listener and to pay attention to detail. \n Driven by Excellence -  you are driven by our mission and our passion for customer success which means you relentlessly pursue excellence, that you do not tolerate mediocrity and you work intensely to achieve your goals. \n High Integrity -  you seek open and honest communication, and you hold yourself to very high moral and ethical standards. You reject manipulation, dishonesty and intolerance. \n \n What you'll bring to Circle: \n \n 12+ years of industry experience working with and analyzing large data sets \n 5+ years of experience with technical leadership and people management \n Knowledge of a scientific computing language (Python) and SQL \n Theoretical and applied expertise in statistics, experimental design, and analysis \n Experience building reporting systems and dashboards \n Strong communicator who can take complex ideas and methodologies, and simplify them for non-technical audiences \n Ability to understand complex business problems and break down analytics projects into a structured approach \n Track record of managing data scientists and analysts, both individual contributors and managers \n Experience managing remote teams \n \n Additional Information: \n \n This position is eligible for day-one PERM sponsorship for qualified candidates. \n \n Circle is on a mission to create an inclusive financial future, with transparency at our core. We consider a wide variety of elements when crafting our compensation ranges and total compensation packages. \n  Starting pay is determined by various factors, including but not limited to: relevant experience, skill set, qualifications, and other business and organizational needs. Please note that compensation ranges may differ for candidates in other locations. \n  Base Pay Range: $227,500 - $292,500 \n  Annual Bonus Target: 20% \n  Also Included: Equity & Benefits (including medical, dental, vision and 401(k)). Circle has a discretionary vacation policy. We also provide 10 days of paid sick leave per year and 11 paid holidays per year in the U.S. \n \n  We are an  equal opportunity employer  and value diversity at Circle. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Additionally, Circle participates in the  E-Verify Program  in certain locations, as required by law. \n  #LI-Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "6031429d00273282": {
        "terms": [
            "data science"
        ],
        "salary_min": 227500.0,
        "salary_max": 292500.0,
        "title": "Director, Data Science and Analytics",
        "company": "Circle",
        "desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  Circle is looking for a Director, Data Science & Analytics to work closely with the Business, Product, and Engineering to produce analysis, deep research, and scalable data practices. This role has the opportunity to significantly impact internal data consumption and decision making. We are a passionate team with a deeply analytical approach, and your work will support us in our mission to be a world-class company driven by data. \n  What you'll work on: \n \n Build road maps, prioritize and drive data science and analytics efforts, communicate cross-functionally, and be a domain expert \n Support the individual and career growth of team members to minimize attrition and enhance output \n Partner with product and operations teams to identify and resolve analytical problems at scale in a variety of domains, including crypto ecosystem understanding, developers, accounting and financial processes, fraud detection, and risk management \n Help your team ideate and complete the right analysis, models, and stories \n Become an expert on data sources and flows at Circle \n Evangelize the power of data science to understand and improve our business and operations. \n \n You will aspire to our four core values: \n \n Multistakeholder -  you have dedication and commitment to our customers, shareholders, employees and families and local communities. \n Mindful -  you seek to be respectful, an active listener and to pay attention to detail. \n Driven by Excellence -  you are driven by our mission and our passion for customer success which means you relentlessly pursue excellence, that you do not tolerate mediocrity and you work intensely to achieve your goals. \n High Integrity -  you seek open and honest communication, and you hold yourself to very high moral and ethical standards. You reject manipulation, dishonesty and intolerance. \n \n What you'll bring to Circle: \n \n 12+ years of industry experience working with and analyzing large data sets \n 5+ years of experience with technical leadership and people management \n Knowledge of a scientific computing language (Python) and SQL \n Theoretical and applied expertise in statistics, experimental design, and analysis \n Experience building reporting systems and dashboards \n Strong communicator who can take complex ideas and methodologies, and simplify them for non-technical audiences \n Ability to understand complex business problems and break down analytics projects into a structured approach \n Track record of managing data scientists and analysts, both individual contributors and managers \n Experience managing remote teams \n \n Additional Information: \n \n This position is eligible for day-one PERM sponsorship for qualified candidates. \n \n Circle is on a mission to create an inclusive financial future, with transparency at our core. We consider a wide variety of elements when crafting our compensation ranges and total compensation packages. \n  Starting pay is determined by various factors, including but not limited to: relevant experience, skill set, qualifications, and other business and organizational needs. Please note that compensation ranges may differ for candidates in other locations. \n  Base Pay Range: $227,500 - $292,500 \n  Annual Bonus Target: 20% \n  Also Included: Equity & Benefits (including medical, dental, vision and 401(k)). Circle has a discretionary vacation policy. We also provide 10 days of paid sick leave per year and 11 paid holidays per year in the U.S. \n \n  We are an  equal opportunity employer  and value diversity at Circle. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Additionally, Circle participates in the  E-Verify Program  in certain locations, as required by law. \n  #LI-Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "fdd1d18770845207": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 125000.0,
        "salary_max": 150000.0,
        "title": "Sr. Data Engineer",
        "company": "INADEV",
        "desc": "******CANDIDATES MUST ANSWER ALL SCREENING QUESTIONS FOR APPLICATIONS TO BE CONSIDERED****** \n Formed in 2011, INADEV is focused on its founding principle to build innovative customer-centric solutions incredibly fast, secure, and at scale. We deliver world-class digital experiences to some of the largest federal agencies and commercial companies. Our technical expertise and innovations are comprised of codeless automation, identity intelligence, immersive technology, artificial intelligence/machine learning (AI/ML), virtualization, and digital transformation. \n POSITION DESCRIPTION: \n \n Prepare data migration strategy, Integration plans, DB Performance, business sign-off plan, Live Confidence Plan (LCT plan - all data is migrated successfully). \n Provide support for data migration, data engineering, and integration of existing systems. \n Developing and integrating multiple data types across a range of data sets and sources. \n Performing day-to-day operations of systems that depend on data, ensuring data is properly processed and securely transferred to its appropriate location, in a timely manner. \n Evaluate current system designs and identify areas for improvement to create a system that is highly available and has low data latency. \n Plan and design the integration of various source systems and the migration of data between systems. \n Build and implement the source system integration and data migration plan. \n Developing, managing, manipulating, storing and parsing data across a data pipeline for variety of target sources and data consumers \n Writing code to ensure the performance and reliability of data extraction and processing \n Supporting continuous process automation for data ingestion \n Assisting with the maintenance of applications and tools that reside on the data driven systems (upgrades, patches, configuration changes, etc.) \n Working with program management and engineers to implement and document complex and evolving requirements \n Actively and collaboratively participating as a member of a cross-functional Agile/Scrum team while following all Agile/Scrum best practices \n Advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing \n Helping cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork \n Demonstrating significant technical competence and ownership to broad audiences while driving progress on company strategic objectives at multiple levels. \n Generating and articulating technical strategy to diverse audiences, both technical and non-technical. \n \n NON-TECHNICAL REQUIREMENTS: \n \n Ability to pass a 7 year background check and have the ability to obtain a U.S. Government clearance. \n Must have been a resident of the continental U.S. for at least the last 3 years. \n Must be willing to work in Eastern Standard Business hours. \n Must possess good communication (written/verbal) skills. \n \n MANDATORY REQUIREMENTS: \n \n Must have a Bachelor's Degree in a technical discipline and 10+ years pertinent experience with the design, management, and solutioning of large, complex data sets and models. \n Must have at least 2+ years of experience working with/in public cloud environments. \n Must have proven experience leading data migration project from on-prem to cloud. \n Must have extensive experience/knowledge of data integration. \n Must have experience with Cloud Native databases \n Experience with Enterprise Architecture & Distributed Systems \n \n DESIRED SKILLS: \n \n Experience with AWS DMS/MGN \n Technical knowledge of Datalake/DeltaLake/Lakehouse \n \n PHYSICAL DEMANDS: \n \n Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions \n \n INADEV Corporation does not discriminate against qualified individuals based on their status as protected veterans or individuals with disabilities and prohibits discrimination against all individuals based on their race, color, religion, sex, sexual orientation/gender identity, or national origin. \n Job Type: Full-time \n Pay: $125,000.00 - $150,000.00 per year \n Benefits: \n \n 401(k) matching \n Dental insurance \n Flexible spending account \n Health insurance \n Referral program \n Vision insurance \n \n Compensation package: \n \n Yearly pay \n \n Experience level: \n \n 10 years \n 7 years \n 8 years \n 9 years \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Application Question(s): \n \n This position requires the ability to obtain/maintain a U.S. Government Clearance and pass a 7 year employment background check. Do you meet these mandatory requirements? \n Are you open to working on a Permanent/W2 basis? \n This position requires that all candidates being considered MUST have resided in the Continental United States for at least the last 3 years and be able/willing to work on East Standard Business hours. Do you meet these mandatory requirements? \n Do you have a Bachelor's Degree in a Technical Discipline (i.e. Computer Science, Computer Engineering, Information Technology, Information Systems)? \n Do you have at least 7 years of professional experience as a Data Engineer? \n Do have professional experience leading data migration projects from on-prem to cloud? \n Do you have at least 7 years of professional experience in Data Manipulation working specifically with Python? \n Do you have at least 7 years of professional ETL experience? \n \n Work Location: Remote",
        "cleaned_desc": "******CANDIDATES MUST ANSWER ALL SCREENING QUESTIONS FOR APPLICATIONS TO BE CONSIDERED****** \n Formed in 2011, INADEV is focused on its founding principle to build innovative customer-centric solutions incredibly fast, secure, and at scale. We deliver world-class digital experiences to some of the largest federal agencies and commercial companies. Our technical expertise and innovations are comprised of codeless automation, identity intelligence, immersive technology, artificial intelligence/machine learning (AI/ML), virtualization, and digital transformation. \n POSITION DESCRIPTION: \n \n Prepare data migration strategy, Integration plans, DB Performance, business sign-off plan, Live Confidence Plan (LCT plan - all data is migrated successfully). \n Provide support for data migration, data engineering, and integration of existing systems. \n Developing and integrating multiple data types across a range of data sets and sources. \n Performing day-to-day operations of systems that depend on data, ensuring data is properly processed and securely transferred to its appropriate location, in a timely manner. \n Evaluate current system designs and identify areas for improvement to create a system that is highly available and has low data latency. \n Plan and design the integration of various source systems and the migration of data between systems. \n Build and implement the source system integration and data migration plan. \n Developing, managing, manipulating, storing and parsing data across a data pipeline for variety of target sources and data consumers \n Writing code to ensure the performance and reliability of data extraction and processing \n Supporting continuous process automation for data ingestion \n Assisting with the maintenance of applications and tools that reside on the data driven systems (upgrades, patches, configuration changes, etc.) \n Working with program management and engineers to implement and document complex and evolving requirements \n Actively and collaboratively participating as a member of a cross-functional Agile/Scrum team while following all Agile/Scrum best practices   Advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing \n Helping cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork \n Demonstrating significant technical competence and ownership to broad audiences while driving progress on company strategic objectives at multiple levels. \n Generating and articulating technical strategy to diverse audiences, both technical and non-technical. \n \n NON-TECHNICAL REQUIREMENTS: \n \n Ability to pass a 7 year background check and have the ability to obtain a U.S. Government clearance. \n Must have been a resident of the continental U.S. for at least the last 3 years. \n Must be willing to work in Eastern Standard Business hours. \n Must possess good communication (written/verbal) skills. \n \n MANDATORY REQUIREMENTS: \n \n Must have a Bachelor's Degree in a technical discipline and 10+ years pertinent experience with the design, management, and solutioning of large, complex data sets and models. \n Must have at least 2+ years of experience working with/in public cloud environments. \n Must have proven experience leading data migration project from on-prem to cloud. ",
        "techs": [
            "codeless automation",
            "identity intelligence",
            "immersive technology",
            "artificial intelligence/machine learning (ai/ml)",
            "virtualization",
            "digital transformation",
            "data migration strategy",
            "integration plans",
            "db performance",
            "business sign-off plan",
            "live confidence plan (lct plan)",
            "data engineering",
            "integration of existing systems",
            "data types",
            "data sets",
            "data sources",
            "system designs",
            "source systems integration",
            "data migration plan",
            "data pipeline",
            "data extraction",
            "data processing",
            "continuous process automation",
            "applications maintenance",
            "program management",
            "api-first design",
            "simple design",
            "continuous integration",
            "version control",
            "automated testing",
            "technical strategy",
            "7 year background check",
            "u.s. government clearance",
            "communication skills",
            "bachelor's degree",
            "public cloud environments",
            "data migration project"
        ],
        "cleaned_techs": [
            "codeless automation",
            "identity intelligence",
            "immersive technology",
            "ai",
            "virtualization",
            "digital transformation",
            "data migration strategy",
            "integration plans",
            "db performance",
            "business sign-off plan",
            "live confidence plan (lct plan)",
            "integration of existing systems",
            "data types",
            "data sets",
            "data sources",
            "system designs",
            "source systems integration",
            "data migration plan",
            "data pipeline",
            "data extraction",
            "continuous process automation",
            "program management",
            "api-first design",
            "simple design",
            "continuous integration",
            "version control",
            "automated testing",
            "technical strategy",
            "7 year background check",
            "u.s. government clearance",
            "public cloud environments",
            "data migration project"
        ]
    },
    "47d267da2a6db363": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 160000.0,
        "salary_max": 180000.0,
        "title": "Sr. Data Scientist",
        "company": "Cognizant Technology Solutions",
        "desc": "This is a remote position open to any qualified applicant in the United States. \n  We are Cognizant Artificial Intelligence \n  Digital technologies, including analytics and AI, give companies a once-in-a-generation opportunity to perform orders of magnitude better than ever before. However, clients need new business models built from analyzing customers and business operations at every angle to really understand them. \n  With the power to apply artificial intelligence and data science to business decisions via enterprise data management solutions, we help leading companies prototype, refine, validate, and scale the most desirable products and delivery models to enterprise scale within weeks. \n  *  You must be legally authorized to work in United States without the need of employer sponsorship, now or at any time in the future * \n  Job Title:  Sr. Data Scientist \n  Roles and Responsibilities: \n  \u00a7 Prompt Engineering: Engineer prompts and optimize few-shot techniques to enhance LLMs performance on specific tasks e.g. personalized recommendations. \n  \u00a7 Model Evaluation & Optimization: Evaluate LLMs zero-shot and few-shot capabilities fine-tuning hyperparameters ensuring task generalization and exploring model interpretability for robust web app integration. \n  \u00a7 Response Quality: Collaborate with ML and Integration engineers to leverage LLMs pre-trained potential delivering contextually appropriate responses in a user-friendly web app. \n  \u00a7 Responsibility: Collaborating with cross-functional teams to define AI project requirements and ensuring alignment with overall business goals. \n  \u00a7 Conducting research to stay up to date with the latest advancements in generative AI machine learning and deep learning techniques and identify opportunities to integrate them into our products and services. \n  \u00a7 Optimizing existing generative AI models for improved performance scalability and efficiency. \n  Required Qualifications: \n  \u00a7 Proficient in Python and have experience working with machine learning and NLP processing techniques and tools. \n  \u00a7 Worked on NoSQL databases and Vector DB \n  \u00a7 Solid experience developing and implementing generative AI models with a strong understanding of deep learning techniques such as GPT VAE and GANs. \n  \u00a7 Proficient in Langchain LLM \n  \u00a7 Strong knowledge of data structures algorithms and software engineering principles. \n \n \n  Salary and Other Compensation : \n  The annual salary for this position is between $160,000.00 \u2013 $180,000.00 depending on experience and other qualifications of the successful candidate. \n  This position is also eligible for Cognizant\u2019s discretionary annual incentive program, based on performance and subject to the terms of Cognizant\u2019s applicable plans. \n  Benefits : Cognizant offers the following benefits for this position, subject to applicable eligibility requirements: \n \n Medical/Dental/Vision/Life Insurance \n Paid holidays plus Paid Time Off \n 401(k) plan and contributions \n Long-term/Short-term Disability \n Paid Parental Leave \n Employee Stock Purchase Plan \n \n Disclaimer:  The salary, other compensation, and benefits information is accurate as of the date of this posting. Cognizant reserves the right to modify this information at any time, subject to applicable law. \n  Cognizant is an Equal Opportunity Employer M/F/D/V. Cognizant is committed to ensuring that all current and prospective associates are afforded equal opportunities and treatment and a work environment free of harassment. \n  Cognizant is recognized as a Military Friendly Employer and is a coalition member of the Veteran Jobs Mission. Our Cognizant Veterans Network Assists Veterans in building and growing a career at Cognizant that allows them to leverage the leadership, loyalty, integrity, and commitment to excellence instilled in them through participation in military service. \n \n \n  #LI-KV1 #CB #Ind123 \n  Employee Status :  Full Time Employee \n  Shift :  Day Job \n  Travel :  No \n  Job Posting :  Oct 17 2023 \n \n \n  About Cognizant \n  Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @USJobsCognizant.\n  \n  Applicants may be required to attend interviews in person or by video conference. In addition, candidates may be required to present their current state or government issued ID during each interview. \n \n  Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law. \n  If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, please email CareersNA2@cognizant.com with your request and contact information.",
        "cleaned_desc": "  \u00a7 Responsibility: Collaborating with cross-functional teams to define AI project requirements and ensuring alignment with overall business goals. \n  \u00a7 Conducting research to stay up to date with the latest advancements in generative AI machine learning and deep learning techniques and identify opportunities to integrate them into our products and services. \n  \u00a7 Optimizing existing generative AI models for improved performance scalability and efficiency. \n  Required Qualifications: \n  \u00a7 Proficient in Python and have experience working with machine learning and NLP processing techniques and tools. \n  \u00a7 Worked on NoSQL databases and Vector DB \n  \u00a7 Solid experience developing and implementing generative AI models with a strong understanding of deep learning techniques such as GPT VAE and GANs. \n  \u00a7 Proficient in Langchain LLM \n  \u00a7 Strong knowledge of data structures algorithms and software engineering principles. \n ",
        "techs": [
            "python",
            "nosql databases",
            "vector db",
            "gpt",
            "vae",
            "gans",
            "langchain llm"
        ],
        "cleaned_techs": [
            "python",
            "nosql",
            "vector db",
            "gpt",
            "vae",
            "gans",
            "langchain llm"
        ]
    },
    "9d09c0d4f96ff75d": {
        "terms": [
            "data science"
        ],
        "salary_min": 151109.5,
        "salary_max": 191338.31,
        "title": "Distinguished Engineer - AI/ML",
        "company": "Cisco Systems",
        "desc": "Who We Are   \n \n \n \n \n  We are a part of the Outshift Group focused on identifying breakthrough emerging solutions that create new markets and businesses for Cisco. We incubate these new opportunities in partnership with our business groups, partners and other startups. The team also continues to progress Cisco\u2019s important work with Standards bodies and manage research partnerships with leading-edge Universities. \n  \n \n  Our organization is anticipating high growth. We are seeking talent with the agility and creativity to explore opportunities and fill in needs as they arise across our teams. Applicants should be seeking a flexible role, in which they not only provide leadership in their primary function, but also contribute in meaningful ways to other projects. We are looking for individuals who are excited about pivoting quickly to different domains that may be outside of their normal scope of responsibilities.\n   \n \n \n \n \n  Learn more about us at https://eti.cisco.com/\n   \n \n \n \n \n Who You'll Work With   \n \n \n \n \n  The Outshift team is a highly visible team within Cisco. Outshift focuses on the next wave of innovation by anticipating, investing in, and incubating new technologies and business ventures. You will be part of the incubation team to develop new products and bring them to market in a startup-like environment.\n   \n \n \n \n \n What You'll Do   \n \n \n \n \n  In your role as a Distinguished Engineer, you will guide Outshift from the front on AI/ML technologies for products and products for AI enablement and help build a pipeline of talent and shape up Cisco\u2019s AI strategies for the next decade.\n   \n \n \n \n \n  You will be driving multi-functional engagements to architect, design, build, validate, deliver and successfully deploy new products.\n   \n \n \n \n \n  Lead a diverse community of engineers and ensure alignment across all functions of the team.\n   \n \n \n \n \n  Take ambiguous technical problems, Customer challenges and refine that to a clear solution with architecture and design. Ensure the solution gets deployed successfully.\n   \n \n \n \n \n  Synthesize manual-on experience into feedback to Product Engineering Leadership.\n  \n \n \n  Build and present executive level collateral on the business value of technology.\n   \n \n \n \n \n The Impact You\u2019ll Make   \n \n \n \n \n  If you want the challenge of fast-paced growth, the satisfaction of seeing your thoughtful ideas come to life, and the pride in helping grow a best-in-class AI team, this is the place for you.\n   \n \n \n \n \n Your Responsibilities Will Include   \n \n \n \n \n Drive technology strategy for the AI/ML products.  \n Drive multi-functional engagements to architect, design, build and validate end-to-end generative AI driven products.  \n Lead a diverse community of engineers and ensure alignment across all functions of the team.  \n Work with peer leaders in Outshift and wider Cisco Senior Tech Talent community (PE, DE, Fellows) from other business groups to align strategies and collaborate on AI/ML platforms and capabilities. \n Lead due diligence and selection of AI technology platforms including LLMs.  \n Take ambiguous technical problems, customer challenges and refine that to a clear solution with architecture and design. Ensure the solution gets deployed successfully.  \n Stay up to date with the latest advancements in the field of AI and guide teams to apply them to develop innovative solutions.  \n Conduct research and develop ideas to enable adoption of innovative AI models using state-of-the-art techniques and tools.  \n Build and present executive level collateral on the business value of technology. \n \n \n \n  Minimum Requirements   \n \n \n \n \n Seasoned engineer and a team leader with degree and corresponding engineering experience (below) with a consistent track record of developing and delivering complex, distributed, enterprise class software, and creating successful business outcomes.  \n Expert in Software Engineering principles, System Architecture.  \n Expert knowledge and practical experience in programming languages like C, C++, Python.  \n 5+ years of experience in core ML/AI technologies with deep understanding of ML/AI application development. Knowledge of deep learning frameworks is preferred.  \n Ability to lead and mentor engineers globally, be an advocate for creative technical trends. Acknowledged for driving decisions collaboratively, resolving challenges and ensuring follow through.   \n \n \n \n \n  Bachelors degree 17+ yrs engineering experience OR\n  \n \n   Masters degree with 14+ yrs engineering experience OR\n  \n \n   PhD with 10+ yrs engineering experience\n  \n \n \n  Preferred Requirements   \n \n \n \n \n Visibility (eg: conference speaker, publications) and strong personal network across ML/AI industry ecosystem.  \n Extraordinarily resourceful & rigorous, you can operate successfully among forward-thinking and charismatic people.  \n Equally comfortable and capable of interacting with technologists as with business executives.  \n Excellent verbal and written communication skills.  \n Strong problem-solving skills and ability to work independently or in a team.   \n \n \n \n \n Why Cisco?   \n \n \n \n \n  #WeAreCisco. We are all unique, but collectively we bring our talents to work as a team, to develop innovative technology and power a more inclusive, digital future for everyone. How do we do it? Well, for starters \u2013 with people like you! \n  \n \n  Nearly every internet connection around the world touches Cisco. We\u2019re the Internet\u2019s optimists. Our technology makes sure the data travelling at light speed across connections does so securely, yet it\u2019s not what we make but what we make happen which marks us out. We\u2019re helping those who work in the health service to connect with patients and each other; schools, colleges, and universities to teach in even the most challenging of times. We\u2019re helping businesses of all shapes and size to connect with their employees and customers in new ways, providing people with access to the digital skills they need and connecting the most remote parts of the world \u2013 whether through 5G, or otherwise.\n   \n \n \n \n \n  We tackle whatever challenges come our way. We have each other\u2019s backs, we recognize our accomplishments, and we grow together. We celebrate and support one another \u2013 from big and small things in life to big career moments. And giving back is in our DNA (we get 10 days off each year to do just that).\n   \n \n \n \n \n  We know that powering an inclusive future starts with us. Because without diversity and a dedication to equality, there is no moving forward. Our 30 Inclusive Communities, that bring people together around commonalities or passions, are leading the way. Together we\u2019re committed to learning, listening, caring for our communities, whilst supporting the most vulnerable with a collective effort to make this world a better place either with technology, or through our actions. \n  \n \n  So, you have colorful hair? Don\u2019t care. Tattoos? Show off your ink. Like polka dots? That\u2019s cool. Pop culture geek? Many of us are. Passion for technology and world changing? Be you, with us! #WeAreCisco\n   \n \n \n \n \n  #LI-TA2 \n  \n \n  #LI-Remote\n  \n \n \n \n \n Message to applicants applying to work in the U.S.: \n \n \n \n  When available, the salary range posted for this position reflects the projected hiring range for new hire, full-time salaries in U.S. locations, not including equity or benefits. For non-sales roles the hiring ranges reflect base salary only; employees are also eligible to receive annual bonuses. Hiring ranges for sales positions include base and incentive compensation target. Individual pay is determined by the candidate's hiring location and additional factors, including but not limited to skillset, experience, and relevant education, certifications, or training. Applicants may not be eligible for the full salary range based on their U.S. hiring location. The recruiter can share more details about compensation for the role in your location during the hiring process.\n  \n \n  U.S. employees have \n   access  to quality medical, dental and vision insurance, a 401(k) plan with a Cisco matching contribution, short and long-term disability coverage, basic life insurance and numerous wellbeing offerings. Employees receive up to twelve paid holidays per calendar year, which includes one floating holiday, plus a day off for their birthday. Employees accrue up to 20 days of Paid Time Off (PTO) each year and have access to paid time away to deal with critical or emergency issues without tapping into their PTO. We offer additional paid time to volunteer and give back to the community. Employees are also able to purchase company stock through our Employee Stock Purchase Program.\n  \n \n  Employees on sales plans earn performance-based incentive pay on top of their base salary, which is split between quota and non-quota components. For quota-based incentive pay, Cisco pays at the standard rate of 1% of incentive target for each 1% revenue attainment against the quota up to 100%. Once performance exceeds 100% quota attainment, incentive rates may increase up to five times the standard rate with no cap on incentive compensation. For non-quota-based sales performance elements such as strategic sales objectives, Cisco may pay up to 125% of target. Cisco sales plans do not have a minimum threshold of performance for sales incentive compensation to be paid.",
        "cleaned_desc": " \n  If you want the challenge of fast-paced growth, the satisfaction of seeing your thoughtful ideas come to life, and the pride in helping grow a best-in-class AI team, this is the place for you.\n   \n \n \n \n \n Your Responsibilities Will Include   \n \n \n \n \n Drive technology strategy for the AI/ML products.  \n Drive multi-functional engagements to architect, design, build and validate end-to-end generative AI driven products.  \n Lead a diverse community of engineers and ensure alignment across all functions of the team.  \n Work with peer leaders in Outshift and wider Cisco Senior Tech Talent community (PE, DE, Fellows) from other business groups to align strategies and collaborate on AI/ML platforms and capabilities. \n Lead due diligence and selection of AI technology platforms including LLMs.  \n Take ambiguous technical problems, customer challenges and refine that to a clear solution with architecture and design. Ensure the solution gets deployed successfully.  \n Stay up to date with the latest advancements in the field of AI and guide teams to apply them to develop innovative solutions.  \n Conduct research and develop ideas to enable adoption of innovative AI models using state-of-the-art techniques and tools.  \n Build and present executive level collateral on the business value of technology. \n \n \n \n  Minimum Requirements   \n \n \n \n \n Seasoned engineer and a team leader with degree and corresponding engineering experience (below) with a consistent track record of developing and delivering complex, distributed, enterprise class software, and creating successful business outcomes.  \n Expert in Software Engineering principles, System Architecture.  \n Expert knowledge and practical experience in programming languages like C, C++, Python.  \n 5+ years of experience in core ML/AI technologies with deep understanding of ML/AI application development. Knowledge of deep learning frameworks is preferred.  \n Ability to lead and mentor engineers globally, be an advocate for creative technical trends. Acknowledged for driving decisions collaboratively, resolving challenges and ensuring follow through.   \n \n \n ",
        "techs": [
            "c",
            "c++",
            "python"
        ],
        "cleaned_techs": [
            "c",
            "c++",
            "python"
        ]
    },
    "dbeb1cfb48325d6b": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 112.0,
        "salary_max": 112.0,
        "title": "Senior Manager of Data Engineering",
        "company": "Vail Resorts",
        "desc": "As a leading mountain resort operator with over 40 resorts in sixteen states and four countries. We exist to create an  Experience of a Lifetime  for our employees, so they can, in turn, provide and  Experience of a Lifetime  for our guests. We are looking for leaders, innovators, creators, and ambitious professionals to join our talented team. If you\u2019re ready to pursue your fullest potential, we want to get to know you! \n  Many of our Corporate function teams can now live and work in any of the states in which Vail Resorts currently operates* \u2013 enabling flexible remote work alongside a commitment to building and maintaining strong culture both in person and virtually. If you\u2019re ready to pursue your fullest potential, we want to get to know you. Find your purpose with us at www.vailresortscareers.com. \n \n  Job Summary: \n  We are looking for a passionate and driven leader to become an important part of our fast-paced, high-energy, and innovative culture. The Senior Manager of Data Engineering plays a key leadership role in the evolution of our Data Driven journey. The Senior Manager will work with a team of developers, principle architects, and specialists to provide leadership and direction in the digital transformation to a data driven organization. This position will partner with and support many lines of business across a fast-paced and highly collaborative environment, working closely with Project Managers and Business Analysts to ensure the on-time and quality delivery of complex programs. We are looking for an articulate leader that is highly collaborative, driven, and detail oriented. \n   \n A successful candidate will excel in the following areas: Leadership and development of data engineers and technology professionals, building and managing stakeholder partnerships, Business Intelligence and cloud platforms, data warehousing and data sourcing architecture, data pipeline architecture, data quality management, data governance, and KPIs. Previous experience managing people who are designing, building, operating and maintaining an engineering team. This position reports to the Director of Data Engineering and Data Enablement. \n \n  Job Specifications: \n \n  Outlet: Corporate / Remote \n  Shift & Schedule Availability: Year Round / Full Time \n  The budgeted range starts at $112,00 - $190,000 + annual bonus. Actual pay will be adjusted based on experience. \n \n \n  Job Responsibilities: \n \n  Develop a high performing team by increasing the high-potential employee mix, ensuring solid succession planning, and maintaining long-term organizational strategic designs. \n  Partner with multiple stakeholder groups (Data Engineers, Data Scientists, Infrastructure, Marketing, Hospitality, etc...) to consistently improve our data, data architecture, and the products that rely on. \n  Collaborating with our business and technology partners to educate our business and advance our data driven road map and associated investments \n  Coordinate with program management leadership to assess and prioritize strategic initiatives and timelines to ensure deliverables are met. \n  Act as the escalation point for business and staff issues with regards to technical delivery. \n  Translating business needs into data projects and data projects into business implications \n  Partnering with business and technology leadership to execute on the following initiatives: \n  Migration from traditional batch based on-premise to cloud based rapid data deployment \n  Identify improvement areas across people, process and technology \n  Research and implementation of new data-enabled strategies and capabilities \n  Implement a robust and agile information architecture \n \n \n  Job Requirements: \n \n  Bachelor\u2019s degree in Computer Science, data science, IS, mathematics, or related field, or equivalent work experience. \n  7+ years of experience in data engineering or related roles \n  2+ years of experience in managing or leading data engineering teams  \n Experience building modern Lakehouse solutions using Azure Databricks \n  Experience implementing CI/CD pipelines in Azure Databricks \n  Proficient in Python, Spark (Scala or Python), SQL and other scripting languages and has experience training team members on the use of these technologies \n  Experience in working with Azure cloud services such as Azure Data Lake, Azure Data Factory, Azure Databricks, Azure DevOps, Event Hubs/Service Bus, Function Apps, Container Apps, Kubernetes  \n Experience in building modern data warehouse solutions using Azure stack or similar technologies  \n Experience in working with various data formats such as JSON, XML, CSV, Parquet, etc.  \n Experience in working with relational databases such as SQL Server, Oracle, MySQL, etc. and NoSQL databases such as Redis, MongoDB, Cosmos DB, etc.  \n Experience in using various ETL tools such as SSIS, Informatica, Data Stage, etc.  \n Knowledge of machine learning, statistical modeling and data visualization techniques is a plus  \n Excellent communication, problem-solving and analytical skills  \n Ability to work independently and as part of a team \n \n \n  The expected Total Compensation for this role is $112,00 - $190,000 + annual bonus. Individual compensation decisions are based on a variety of factors. \n  The perks include a free ski pass, and a set of benefits including... \n \n  Medical, Dental, Vision insurance, and a 401(k) retirement plan \n  Hourly employees are generally eligible for accrued Paid Time Off (PTO) and Sick Time. Salaried employees are generally eligible for Flexible Time Off (FTO) \n  Paid Parental Leave for eligible mothers and fathers \n  Healthcare & Dependent Care Flexible Spending Accounts \n  Life, AD&D, and disability insurance \n \n \n  Reach Your Peak at Vail Resorts.  At Vail Resorts, our team is made whole by the brave, passionate individuals who ambitiously push boundaries and challenge the status quo. Whether you\u2019re looking for seasonal work or the career of a lifetime, join us today to reach your peak. \n \n   Remote work is currently permitted from British Columbia and the 16 U.S. states in which we currently operate. This includes: California, Colorado, Indiana, Michigan, Minnesota, Missouri, New Hampshire, New York, Nevada, Ohio, Pennsylvania, Utah, Vermont, Washington State, Wisconsin, and Wyoming. Please note that the ability to work remotely, and the particulars related to such work, are subject to change at any time; and, accordingly, the Company reserves the right to change its policies and/or require in-person/in-office work at any time in its sole discretion. \n \n \n  Vail Resorts is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability, protected veteran status or any other status protected by applicable law. \n \n  Requisition ID 498602   Reference Date: 10/17/2023   Job Code Function: Data Warehouse/Business Intel",
        "cleaned_desc": "  Research and implementation of new data-enabled strategies and capabilities \n  Implement a robust and agile information architecture \n \n \n  Job Requirements: \n \n  Bachelor\u2019s degree in Computer Science, data science, IS, mathematics, or related field, or equivalent work experience. \n  7+ years of experience in data engineering or related roles \n  2+ years of experience in managing or leading data engineering teams  \n Experience building modern Lakehouse solutions using Azure Databricks \n  Experience implementing CI/CD pipelines in Azure Databricks \n  Proficient in Python, Spark (Scala or Python), SQL and other scripting languages and has experience training team members on the use of these technologies \n  Experience in working with Azure cloud services such as Azure Data Lake, Azure Data Factory, Azure Databricks, Azure DevOps, Event Hubs/Service Bus, Function Apps, Container Apps, Kubernetes    Experience in building modern data warehouse solutions using Azure stack or similar technologies  \n Experience in working with various data formats such as JSON, XML, CSV, Parquet, etc.  \n Experience in working with relational databases such as SQL Server, Oracle, MySQL, etc. and NoSQL databases such as Redis, MongoDB, Cosmos DB, etc.  \n Experience in using various ETL tools such as SSIS, Informatica, Data Stage, etc.  \n Knowledge of machine learning, statistical modeling and data visualization techniques is a plus  \n Excellent communication, problem-solving and analytical skills  \n Ability to work independently and as part of a team \n \n \n  The expected Total Compensation for this role is $112,00 - $190,000 + annual bonus. Individual compensation decisions are based on a variety of factors. \n  The perks include a free ski pass, and a set of benefits including... \n \n  Medical, Dental, Vision insurance, and a 401(k) retirement plan ",
        "techs": [
            "azure databricks",
            "python",
            "spark",
            "scala",
            "sql",
            "azure data lake",
            "azure data factory",
            "azure databricks",
            "azure devops",
            "azure stack",
            "json",
            "xml",
            "csv",
            "parquet",
            "sql server",
            "oracle",
            "mysql",
            "redis",
            "mongodb",
            "cosmos db",
            "ssis",
            "informatica",
            "data stage"
        ],
        "cleaned_techs": [
            "azure",
            "python",
            "spark",
            "scala",
            "sql",
            "json",
            "xml",
            "csv",
            "parquet",
            "oracle",
            "mysql",
            "redis",
            "mongodb",
            "cosmos db",
            "ssis",
            "informatica",
            "data stage"
        ]
    },
    "41e1feac923d979f": {
        "terms": [
            "data science"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Manager, Product Management (Remote)",
        "company": "Capital One",
        "desc": "Locations: US Remote, United States of America\n   Manager, Product Management (Remote)\n  \n  Capital One has been a pioneer through our tech journey as the first large bank to go all in on the public cloud, while operating in a complex and highly regulated business environment. We have built out a large engineering organization, moved to the cloud, re-architected our applications and data platforms, and embraced machine learning at scale. Our AI/ML capabilities are now at the forefront of what\u2019s possible in banking. (e.g., Capital One Eno). \n \n  Our teams have built and battle tested new capabilities to meet those needs. We\u2019ve open sourced several of the software tools we built (e.g., Cloud Custodian, Hygieia) and forged new partnerships with other digital leaders (e.g., Microsoft, MSFT). \n \n  Through this journey, we've developed a suite of internal solutions uniquely designed to meet the challenges of a digital-first, cloud-first business at scale. We also recognize that many other businesses are facing similar data management needs as they accelerate their cloud and data journeys, and are exploring how best to bring some of the tools to market as enterprise B2B software solutions. \n \n  Capital One Software is seeking a Manager of Product Management who is passionate about marrying innovation with emerging technologies. As a Capital One Manager of Product Management you\u2019ll have the opportunity to be on the forefront of driving a major transformation within Capital One. \n \n  Product Management \n  Product Management at Capital One is a booming, vibrant craft that requires reimagining the status quo, finding value creation opportunities, and driving innovative and sustainable customer experiences through technology. \n  We believe our portfolio of businesses and investments in growth and transformation will result in a company with the scale, brand, capabilities, talent, and values to succeed as the digital revolution transforms our society and our industry. \n  Do you dream of well-designed and intuitive products and customer experiences? Do you want to be the one who introduces change to help tens of millions of customers make smarter financial choices? Do you want to change the way people manage their money? If you answered yes to all of these questions, then product management at Capital One may be a fit for you \n \n  In this role, you\u2019ll be expected to demonstrate proficiency in five key areas \n \n  Human Centered \n \n  You\u2019ll define clear and actionable problem statements to help teams deliver results while displaying a comprehensive understanding of iterative software delivery, capable of thin-slice MVP grooming \n  You\u2019ll leverage customer insights to influence priorities and roadmap feature development while advocating for and driving alignment between stakeholders in the development of acceptance criteria \n  You\u2019ll obsess over UX/UI patterns and seek to create world class, omni-channel experiences \n \n \n \n  Business Focused \n \n  You\u2019ll own and prioritize the near-term product roadmap to deliver on business outcomes, quickly identifying points of leverage in complex problems or systems, and utilizing data effectively to define success metrics and measurable outcomes \n  You\u2019ll utilize balanced judgment in decisions about risks of both actions taken and not taken while innovating on ways to iterate faster in a well-managed way for the immediate team \n \n \n \n  Technology Driven \n \n  You\u2019ll understand and leverage technology and end-state architecture vision to partner with technology team to drive comprehensive design decisions out of white space technical problems \n  You\u2019ll share business strategy and roadmap with Tech partners to establish context while also leading and facilitating agile ceremonies alongside Tech Lead \n  You\u2019ll deliver value by creating reusable, extensible and resilient capabilities and proactively identify opportunities when key metrics on security, resilience and performance are not performing \n \n  Integrated Problem Solving \n \n  Develop and champion a bold vision that drives meaningful outcomes by embracing the art of the possible \n  Build frameworks for complex decision making that enable effective debate and accelerate getting to the right answer \n \n  Transformational Leadership \n \n  You\u2019ll develop and communicate a 6-month vision to senior stakeholders and partner teams with accurate details and transparency on risks and impediments, and proactively build relationships with those outside of your immediate team resulting in horizontal influence \n  You\u2019ll Contribute to team culture and recruiting by leading activities to attract and retain top talent and mentoring and developing junior product associates \n \n \n \n  We want you if you are: \n \n  Intellectually Curious . You ask why, you explore, you're not afraid to blurt out your crazy idea or follow an email chain for weeks to find someone with an answer. Comfortable with ambiguity, a hunger to learn and a seeker of new challenges. \n  Communicator & Influencer . You can communicate complex ideas clearly regardless of your audience. Our team knows their priorities and why they\u2019re doing what they\u2019re doing. You always can rally associates to work with you. \n  Do-er . You\u2019re biased toward action, you try things and sometimes you fail. You can get around roadblocks and stay focused on your goals. You\u2019re well organized, able to multitask and able to prioritize your work. \n  Passionate & Customer Focus . You care about growing others and bringing them together around what\u2019s possible. You get a thrill from the journey of building and shipping products, and you have a desire and ability to connect with our external or internal customers to fully understand their needs. \n  Learner . You have an appetite to learn new things or new technologies all while exhibiting humbleness when the time comes to ask for help. \n  Team Player . You enjoy working with diverse people and driving the team toward a common goal. You have the ability to put the team before yourself and establish long-lasting relationships. \n \n \n  Basic Qualifications: \n \n  Bachelor\u2019s Degree or military experience \n  At least 3 years of product management experience or at least 3 years of experience in product design, agile delivery, business analysis, data science, or software engineering \n \n \n  Preferred Qualifications: \n \n  Bachelor\u2019s Degree in Computer Science or Engineering \n  MBA or Master\u2019s degree \n  2+ years of experience in Agile product management \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.  \n \n Remote (Regardless of Location): $135,700 - $154,900 for Graduate Product Development Program  \n \n Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter.  \n \n This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan. \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n  No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "b003c4d2414994aa": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 81.43,
        "salary_max": 81.86,
        "title": "Machine Learning Engineer",
        "company": "Plaxonic Technologies Inc.",
        "desc": "Role: AL ML Developer \n Location: Charlotte, NC (Hybrid role {5-6 Days On Site in a Month}) \n Duration: Long Term \n Job Description:- \n Key Responsibilities and Duties \n \n Assessing the technical viability of emerging products and technologies. \n Working with developers and infrastructure specialists to test and evaluate new technologies. \n Participating in the development of business cases and obtaining approvals for capital expenditures. \n Monitoring and analyzing new technology product performance and resolving issues regarding potential improvements or modifications to complex situations, as needed. \n \n Educational Requirements \n \n University (Degree) Preferred \n \n Work Experience \n \n 5+ Years Required; 7+ Years Preferred \n \n Additional Information For Posting \n Experience in Python Development. Integration with APIs and Databases. AI/ML coding expertise, developing applications and APIs leverage data & AI models. LLM and GenAI is a plus \n Job Type: Contract \n Salary: $81.43 - $81.86 per hour \n Compensation package: \n \n Hourly pay \n \n Experience level: \n \n 11+ years \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n Python: 8 years (Preferred) \n Machine learning: 10 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "088e8f8500d5014a": {
        "terms": [
            "data science"
        ],
        "salary_min": 227500.0,
        "salary_max": 292500.0,
        "title": "Director, Data Science and Analytics",
        "company": "Circle",
        "desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  Circle is looking for a Director, Data Science & Analytics to work closely with the Business, Product, and Engineering to produce analysis, deep research, and scalable data practices. This role has the opportunity to significantly impact internal data consumption and decision making. We are a passionate team with a deeply analytical approach, and your work will support us in our mission to be a world-class company driven by data. \n  What you'll work on: \n \n Build road maps, prioritize and drive data science and analytics efforts, communicate cross-functionally, and be a domain expert \n Support the individual and career growth of team members to minimize attrition and enhance output \n Partner with product and operations teams to identify and resolve analytical problems at scale in a variety of domains, including crypto ecosystem understanding, developers, accounting and financial processes, fraud detection, and risk management \n Help your team ideate and complete the right analysis, models, and stories \n Become an expert on data sources and flows at Circle \n Evangelize the power of data science to understand and improve our business and operations. \n \n You will aspire to our four core values: \n \n Multistakeholder -  you have dedication and commitment to our customers, shareholders, employees and families and local communities. \n Mindful -  you seek to be respectful, an active listener and to pay attention to detail. \n Driven by Excellence -  you are driven by our mission and our passion for customer success which means you relentlessly pursue excellence, that you do not tolerate mediocrity and you work intensely to achieve your goals. \n High Integrity -  you seek open and honest communication, and you hold yourself to very high moral and ethical standards. You reject manipulation, dishonesty and intolerance. \n \n What you'll bring to Circle: \n \n 12+ years of industry experience working with and analyzing large data sets \n 5+ years of experience with technical leadership and people management \n Knowledge of a scientific computing language (Python) and SQL \n Theoretical and applied expertise in statistics, experimental design, and analysis \n Experience building reporting systems and dashboards \n Strong communicator who can take complex ideas and methodologies, and simplify them for non-technical audiences \n Ability to understand complex business problems and break down analytics projects into a structured approach \n Track record of managing data scientists and analysts, both individual contributors and managers \n Experience managing remote teams \n \n Additional Information: \n \n This position is eligible for day-one PERM sponsorship for qualified candidates. \n \n Circle is on a mission to create an inclusive financial future, with transparency at our core. We consider a wide variety of elements when crafting our compensation ranges and total compensation packages. \n  Starting pay is determined by various factors, including but not limited to: relevant experience, skill set, qualifications, and other business and organizational needs. Please note that compensation ranges may differ for candidates in other locations. \n  Base Pay Range: $227,500 - $292,500 \n  Annual Bonus Target: 20% \n  Also Included: Equity & Benefits (including medical, dental, vision and 401(k)). Circle has a discretionary vacation policy. We also provide 10 days of paid sick leave per year and 11 paid holidays per year in the U.S. \n \n  We are an  equal opportunity employer  and value diversity at Circle. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Additionally, Circle participates in the  E-Verify Program  in certain locations, as required by law. \n  #LI-Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "69367ead0238ca43": {
        "terms": [
            "data science",
            "data engineer"
        ],
        "salary_min": 125000.0,
        "salary_max": 140000.0,
        "title": "Data Engineer (OLTP)",
        "company": "Cognizant Technology Solutions",
        "desc": "We are Cognizant Artificial Intelligence \n  Digital technologies, including analytics and AI, give companies a once-in-a-generation opportunity to perform orders of magnitude better than ever before. But clients need new business models built from analyzing customers and business operations at every angle to really understand them. \n  With the power to apply artificial intelligence and data science to business decisions via enterprise data management solutions, we help leading companies prototype, refine, validate and scale the most desirable products and delivery models to enterprise scale within weeks. \n  * You must be legally authorized to work in United States without the need of employer sponsorship, now or at any time in the future * \n  This is a  remote position  open to any qualified applicant in the United States  \n Job Title:  Data Engineer (OLTP ) \n  Requirement is for a Data Engineer (OLTP) who would be working on Data Engineering Database Design Data Modelling ETL/ELT pipeline Data Migration for OLTP Application.  \n \n  Understand existing data model & create target data models for cloud applications as part of modernization efforts.  \n \n \n  Developing Spark/Scala jobs for large Application Services in the Big Data and Data Warehouse space.  \n \n \n  Collaborate and review new data models with application architects application teams and leadership for execution.  \n \n \n  Responsible for the resolution of technical issues Design unit test cases and perform unit testing support SIT/UAT activities. \n \n \n Experience : 6 to 9yrs. \n \n \n Technical Skills : Data Engineering (OLTP)   Data Modelling (OLTP)   Dimensional modeling   Database Design   Data Migration Domain, ETL Validation, Databricks \n \n \n Roles & Responsibilities :  \n \n \n  Design and development of solution for extraction transformation and loading of data in new database  \n \n \n  Create transition state data strategy for dual system (transition state)  \n \n \n  Design develop enhance and integrate PBM data subjects into a normalize relational model \n \n \n  Deploy and maintain OLTP Relational and Data Warehouses/Data Marts Models \n \n \n  Strong understanding and experience building ETL/ETL solutions for both structured and unstructured data sets  \n \n \n  Experience in SQL and NoSQL databases  \n \n \n  Experience in data migration programs from legacy to Cloud big data applications. \n \n \n   Experience with Healthcare or Pharmacy business domain   \n \n \n  6+ years Data Engineering Enterprise Data Architecture Data Modeling Solutions Designing Data Analysis and BI Solutions Delivery Data Warehouse implementation \n \n \n  6+ years in conducting Data Analysis Data Profiling and Data Discovery on dispersed operational source systems \n \n  Salary and Other Compensation :  \n The annual salary for this position is between $125,000.00 \u2013 $140,000.00 depending on experience and other qualifications of the successful candidate. \n  This position is also eligible for Cognizant\u2019s discretionary annual incentive program, based on performance and subject to the terms of Cognizant\u2019s applicable plans. \n  Benefits : Cognizant offers the following benefits for this position, subject to applicable eligibility requirements:  \n \n Medical/Dental/Vision/Life Insurance \n Paid holidays plus Paid Time Off \n 401(k) plan and contributions \n Long-term/Short-term Disability \n Paid Parental Leave \n Employee Stock Purchase Plan \n \n Disclaimer:  The salary, other compensation, and benefits information is accurate as of the date of this posting. Cognizant reserves the right to modify this information at any time, subject to applicable law.  \n #LI-DC1 #CB #Ind123 \n  Employee Status :  Full Time Employee \n  Shift :  Day Job \n  Travel :  No \n  Job Posting :  Oct 17 2023 \n \n \n  About Cognizant \n  Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @USJobsCognizant.\n  \n  Applicants may be required to attend interviews in person or by video conference. In addition, candidates may be required to present their current state or government issued ID during each interview. \n \n  Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law. \n  If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, please email CareersNA2@cognizant.com with your request and contact information.",
        "cleaned_desc": "We are Cognizant Artificial Intelligence \n  Digital technologies, including analytics and AI, give companies a once-in-a-generation opportunity to perform orders of magnitude better than ever before. But clients need new business models built from analyzing customers and business operations at every angle to really understand them. \n  With the power to apply artificial intelligence and data science to business decisions via enterprise data management solutions, we help leading companies prototype, refine, validate and scale the most desirable products and delivery models to enterprise scale within weeks. \n  * You must be legally authorized to work in United States without the need of employer sponsorship, now or at any time in the future * \n  This is a  remote position  open to any qualified applicant in the United States  \n Job Title:  Data Engineer (OLTP ) \n  Requirement is for a Data Engineer (OLTP) who would be working on Data Engineering Database Design Data Modelling ETL/ELT pipeline Data Migration for OLTP Application.  \n \n  Understand existing data model & create target data models for cloud applications as part of modernization efforts.  \n \n \n  Developing Spark/Scala jobs for large Application Services in the Big Data and Data Warehouse space.  \n \n \n  Collaborate and review new data models with application architects application teams and leadership for execution.  \n   \n  Responsible for the resolution of technical issues Design unit test cases and perform unit testing support SIT/UAT activities. \n \n \n Experience : 6 to 9yrs. \n \n \n Technical Skills : Data Engineering (OLTP)   Data Modelling (OLTP)   Dimensional modeling   Database Design   Data Migration Domain, ETL Validation, Databricks \n \n \n Roles & Responsibilities :  \n \n \n  Design and development of solution for extraction transformation and loading of data in new database  \n \n    Create transition state data strategy for dual system (transition state)  \n \n \n  Design develop enhance and integrate PBM data subjects into a normalize relational model \n \n \n  Deploy and maintain OLTP Relational and Data Warehouses/Data Marts Models \n \n \n  Strong understanding and experience building ETL/ETL solutions for both structured and unstructured data sets  \n \n \n  Experience in SQL and NoSQL databases  \n \n \n  Experience in data migration programs from legacy to Cloud big data applications. ",
        "techs": [
            "analytics",
            "ai",
            "artificial intelligence",
            "data science",
            "enterprise data management",
            "prototype",
            "refine",
            "validate",
            "scale",
            "spark",
            "scala",
            "big data",
            "data warehouse",
            "data models",
            "data engineering",
            "oltp",
            "etl/elt",
            "data migration",
            "dimensional modeling",
            "database design",
            "etl validation",
            "databricks",
            "pbm data subjects",
            "relational model",
            "sql",
            "nosql",
            "cloud big data applications"
        ],
        "cleaned_techs": [
            "ai",
            "data science",
            "enterprise data management",
            "prototype",
            "refine",
            "validate",
            "scale",
            "spark",
            "scala",
            "big data",
            "data warehouse",
            "data models",
            "oltp",
            "etl/elt",
            "data migration",
            "dimensional modeling",
            "database design",
            "etl validation",
            "databricks",
            "pbm data subjects",
            "relational model",
            "sql",
            "nosql"
        ]
    },
    "12c63f4cfd807863": {
        "terms": [
            "data science"
        ],
        "salary_min": 90000.0,
        "salary_max": 120000.0,
        "title": "Senior Manager - Data Mining - Healthcare",
        "company": "EXL",
        "desc": "EXL Health is seeking an experienced and self-motivated Data Mining Subject Matter Experts \u2013 Data Mining with medical claims experience. This is a Home Office Opportunity. \n The Data Mining SME position is to assist EXL clients in controlling healthcare costs by identifying concepts and performing audit reviews to determine if correct payments were made to providers. The Data Mining SME is a senior position responsible for reviewing the output of queries to identify overpayments as well as develop and validate new overpayment concepts and act as a subject matter expert when called upon. \n Responsibilities: \n \n Owns the development and deployment of audit concepts for his/her client, from idea conception through steady state production. \n Develops deep knowledge of his/her client\u2019s data sets, Adjudication and other systems, policies, geography, provider contracts, provider behavior, workflows, file exchanges, speed analysis, competitive intelligence, stakeholder decision-making behavior etc.,. \n Responsible for ongoing maintenance of deployed content, i.e., query size, auditor efficiency, profitability, competitor behavior etc.,. \n Works closely with other content development SME\u2019s to extract/apply new content from the library \n Acquires and maintains access to client systems. Learns navigation, trains new users (auditors), documents process steps etc.,. \n Maintains feedback loops to put learned info back into the queries, workflows, content library etc.,. \n Accurately reprice complex claims utilizing multiple client claims systems to perform the tasks. \n Identify work files to be reviewed through a query process. \n Review provider contracts/fee schedules, to determine correct payment methodology. \n Documentation of audit concepts and creation of whitepapers to be shared with clients for approval \n Serve as a resource for junior auditors and new employees \n Serve as a client and program specific SME when called upon in both internal and external settings \n Evaluate current procedures for efficiency and accuracy as well as recommend solutions for process improvements. \n Other duties as assigned \n \n Qualifications: \n \n Minimum 10+ years medical claims experience, Particularly in claims adjudication, \n Experience in handling appeals, claims reworks, recovery projects are added advantage. \n Expert knowledge of Client systems / applications ( CAS , MTV , PAAG , CIS , BCOP search , Mentor , CIS Pro , APEX , eHub ,CRM, HOWIE Certificate, Search Humana Image, View Station IPAR Tracking tool , PMDM Provider Search ) \n Good verbal and written communication skills \n \n Knowledge and Skills: \n \n Knowledge of CMS Guidelines for Inpatient hospital, SNF, Home health, LTCH, Outpatient and physician claims. Knowledge of Coding Methodologies. \n Should have extensive knowledge in different types of reimbursement methodologies available in Medicare and in commercial market. \n Should be able to read and understand the provider contracts. Should be able to identify the mistakes in contract system and there by the incorrectly priced claims. Should have already worked in provider contract related areas and claims adjudication. \n Sound knowledge of ICD-9, ICD-10, CPT and HCPCS coding guidelines. \n Experience with processing complex medical health claims. \n Experience with encoder tools and industry systems (FACETS, NASCO, Encoder Pro, TrueCode, 3M, Webtrat, Pricers). \n Experience with MS Office programs such as: Excel, PowerPoint, Outlook, and Word \n Sound analytical mindset, capable of finding solutions to problems encountered. \n \n Team Collaboration & Synergies \n \n Training in the functionality of the new SMEs on board. \n Should possess strong interpersonal skills to be able to work well with other teams \n Ability to drive, to innovate and optimize the use of available resources. \n Work cohesively with Analytics and technology, Operations and Quality teams. \n Completely aligned with program goals and objectives \n \n Compliance & Administrative \n \n Adhering to compliance policies \n 40 hours work week. \n \n What We Offer: \n \n EXL Health offers an exciting, fast paced and innovative environment, which brings together a group of sharp and entrepreneurial professionals who are eager to influence business decisions. \n From your very first day, you get an opportunity to work closely with highly experienced, world class Healthcare consultants. \n You can expect to learn many aspects of businesses that our clients engage in. You will also learn effective teamwork and time-management skills - key aspects for personal and professional growth. \n We provide guidance/ coaching to every employee through our mentoring program wherein every junior level employee is assigned a senior level professional as advisors. \n Sky is the limit for our team members. The unique experiences gathered at EXL Health sets the stage for further growth and development in our company and beyond. \n \n Job Type: Full-time \n Pay: $90,000.00 - $120,000.00 per year \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n Paid time off \n Vision insurance \n \n Compensation package: \n \n Bonus opportunities \n Employee stock purchase plan \n \n Experience level: \n \n 10 years \n \n Schedule: \n \n 8 hour shift \n Day shift \n Monday to Friday \n \n Work Location: Remote",
        "cleaned_desc": " Experience with processing complex medical health claims. \n Experience with encoder tools and industry systems (FACETS, NASCO, Encoder Pro, TrueCode, 3M, Webtrat, Pricers). \n Experience with MS Office programs such as: Excel, PowerPoint, Outlook, and Word \n Sound analytical mindset, capable of finding solutions to problems encountered. \n \n Team Collaboration & Synergies \n \n Training in the functionality of the new SMEs on board. \n Should possess strong interpersonal skills to be able to work well with other teams \n Ability to drive, to innovate and optimize the use of available resources. \n Work cohesively with Analytics and technology, Operations and Quality teams. \n Completely aligned with program goals and objectives \n \n Compliance & Administrative \n \n Adhering to compliance policies ",
        "techs": [
            "facets",
            "nasco",
            "encoder pro",
            "truecode",
            "3m",
            "webtrat",
            "pricers",
            "excel",
            "powerpoint",
            "outlook",
            "word"
        ],
        "cleaned_techs": [
            "facets",
            "nasco",
            "encoder pro",
            "truecode",
            "3m",
            "webtrat",
            "pricers",
            "excel",
            "powerpoint",
            "outlook",
            "word"
        ]
    },
    "69fea28597c201a7": {
        "terms": [
            "data science"
        ],
        "salary_min": 227500.0,
        "salary_max": 292500.0,
        "title": "Director, Data Science and Analytics",
        "company": "Circle",
        "desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  Circle is looking for a Director, Data Science & Analytics to work closely with the Business, Product, and Engineering to produce analysis, deep research, and scalable data practices. This role has the opportunity to significantly impact internal data consumption and decision making. We are a passionate team with a deeply analytical approach, and your work will support us in our mission to be a world-class company driven by data. \n  What you'll work on: \n \n Build road maps, prioritize and drive data science and analytics efforts, communicate cross-functionally, and be a domain expert \n Support the individual and career growth of team members to minimize attrition and enhance output \n Partner with product and operations teams to identify and resolve analytical problems at scale in a variety of domains, including crypto ecosystem understanding, developers, accounting and financial processes, fraud detection, and risk management \n Help your team ideate and complete the right analysis, models, and stories \n Become an expert on data sources and flows at Circle \n Evangelize the power of data science to understand and improve our business and operations. \n \n You will aspire to our four core values: \n \n Multistakeholder -  you have dedication and commitment to our customers, shareholders, employees and families and local communities. \n Mindful -  you seek to be respectful, an active listener and to pay attention to detail. \n Driven by Excellence -  you are driven by our mission and our passion for customer success which means you relentlessly pursue excellence, that you do not tolerate mediocrity and you work intensely to achieve your goals. \n High Integrity -  you seek open and honest communication, and you hold yourself to very high moral and ethical standards. You reject manipulation, dishonesty and intolerance. \n \n What you'll bring to Circle: \n \n 12+ years of industry experience working with and analyzing large data sets \n 5+ years of experience with technical leadership and people management \n Knowledge of a scientific computing language (Python) and SQL \n Theoretical and applied expertise in statistics, experimental design, and analysis \n Experience building reporting systems and dashboards \n Strong communicator who can take complex ideas and methodologies, and simplify them for non-technical audiences \n Ability to understand complex business problems and break down analytics projects into a structured approach \n Track record of managing data scientists and analysts, both individual contributors and managers \n Experience managing remote teams \n \n Additional Information: \n \n This position is eligible for day-one PERM sponsorship for qualified candidates. \n \n Circle is on a mission to create an inclusive financial future, with transparency at our core. We consider a wide variety of elements when crafting our compensation ranges and total compensation packages. \n  Starting pay is determined by various factors, including but not limited to: relevant experience, skill set, qualifications, and other business and organizational needs. Please note that compensation ranges may differ for candidates in other locations. \n  Base Pay Range: $227,500 - $292,500 \n  Annual Bonus Target: 20% \n  Also Included: Equity & Benefits (including medical, dental, vision and 401(k)). Circle has a discretionary vacation policy. We also provide 10 days of paid sick leave per year and 11 paid holidays per year in the U.S. \n \n  We are an  equal opportunity employer  and value diversity at Circle. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Additionally, Circle participates in the  E-Verify Program  in certain locations, as required by law. \n  #LI-Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "8baee8cb684bbc8a": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 150000.0,
        "salary_max": 225000.0,
        "title": "Senior/First Data Engineer",
        "company": "Sleeper",
        "desc": "Position Summary \n  The Senior/First Data Engineer will play a crucial role in building, maintaining, and enhancing ETL processes that drive our analytics and machine learning platforms. This individual will be responsible for developing actionable insights from complex data sets, and work closely with various business units to inform strategy and decision-making. \n  You will be the first hire in this function. \n \n  Location \n \n  SF Bay Area, NYC, or Remote \n \n \n  Key Responsibilities \n \n  ETL & Backend Development: \n \n \n  Design and optimize ETL pipelines. \n  Develop robust backend systems for large-scale data processing using Elixir and database solutions like Cassandra/ScyllaDB. \n \n \n  Data Architecture: \n \n \n  Design scalable and efficient data models for Cassandra and ScyllaDB. \n  Ensure data integrity, quality, and security. \n \n \n  Data Science Support: \n \n \n  Collaborate with data scientists, providing them with clean and reliable datasets. \n  Assist in implementing and scaling data science models. \n \n \n  Innovation & Research: \n \n \n  Stay abreast of latest technologies. \n  Recommend technical improvements for data processing and storage. \n \n \n  Qualifications \n  Required \n \n  Bachelor\u2019s or Master\u2019s degree in Computer Science, Engineering, or a related technical field. \n  5+ years of experience in backend development, with a strong focus on data engineering. \n \n  Technical skills: Expertise in Python, Java, Scala, and Elixer for backend and ETL processes. \n  Mastery of ETL tools/frameworks (e.g. Apache Kafka, Apache Airflow). \n  Deep knowledge of SQL/NoSQL databases, including Cassandra and ScyllaDB, and data warehousing solutions (e.g., Redshift, BigQueary, Snowflake). \n  Proficiency in cloud platforms (AWS, GCP, Azure) and distributed systems. \n  Familiarity with data science concepts, tools, and libraries (e.g. Pandas, Scikit-learn). \n  Soft Skills: Exceptional problem-solving skills. \n  Strong communication for technical and non-technical discussions. \n \n \n  Nice-to-have \n \n  Experience with cloud platforms like AWS, GCP, or Azure. \n  Exceptional communication skills, both verbal and written. \n  Expertise in machine learning algorithms and frameworks (e.g., TensorFlow, PyTorch, scikit-learn). \n \n \n  Benefits \n \n  Competitive salary ($150,000-$225,000/year) and stock options \n  Comprehensive health, dental, and vision plans \n  401(k) \n  Flexible working hours and remote work options \n  Regular team building events and activities",
        "cleaned_desc": " \n  Design and optimize ETL pipelines. \n  Develop robust backend systems for large-scale data processing using Elixir and database solutions like Cassandra/ScyllaDB. \n \n \n  Data Architecture: \n \n \n  Design scalable and efficient data models for Cassandra and ScyllaDB. \n  Ensure data integrity, quality, and security. \n \n \n  Data Science Support:   \n \n  Collaborate with data scientists, providing them with clean and reliable datasets. \n  Assist in implementing and scaling data science models. \n \n \n  Innovation & Research: \n \n \n  Stay abreast of latest technologies. \n  Recommend technical improvements for data processing and storage. \n \n    Qualifications \n  Required \n \n  Bachelor\u2019s or Master\u2019s degree in Computer Science, Engineering, or a related technical field. \n  5+ years of experience in backend development, with a strong focus on data engineering. \n \n  Technical skills: Expertise in Python, Java, Scala, and Elixer for backend and ETL processes. \n  Mastery of ETL tools/frameworks (e.g. Apache Kafka, Apache Airflow). \n  Deep knowledge of SQL/NoSQL databases, including Cassandra and ScyllaDB, and data warehousing solutions (e.g., Redshift, BigQueary, Snowflake). \n  Proficiency in cloud platforms (AWS, GCP, Azure) and distributed systems. \n  Familiarity with data science concepts, tools, and libraries (e.g. Pandas, Scikit-learn). \n  Soft Skills: Exceptional problem-solving skills. \n  Strong communication for technical and non-technical discussions. ",
        "techs": [
            "etl pipelines",
            "elixir",
            "cassandra/scylladb",
            "data models",
            "data integrity",
            "data quality",
            "data security",
            "data science support",
            "clean datasets",
            "data science models",
            "latest technologies",
            "technical improvements",
            "python",
            "java",
            "scala",
            "etl tools/frameworks",
            "apache kafka",
            "apache airflow",
            "sql/nosql databases",
            "cassandra",
            "scylladb",
            "redshift",
            "bigquery",
            "snowflake",
            "cloud platforms",
            "aws",
            "gcp",
            "azure",
            "distributed systems",
            "data science concepts",
            "pandas",
            "scikit-learn",
            "problem-solving skills",
            "communication"
        ],
        "cleaned_techs": [
            "etl pipelines",
            "elixir",
            "cassandra/scylladb",
            "data models",
            "data integrity",
            "data quality",
            "data science support",
            "clean datasets",
            "data science models",
            "latest technologies",
            "technical improvements",
            "python",
            "java",
            "scala",
            "etl tools/frameworks",
            "apache kafka",
            "apache airflow",
            "sql",
            "cassandra",
            "scylladb",
            "redshift",
            "bigquery",
            "snowflake",
            "cloud platforms",
            "aws",
            "gcp",
            "azure",
            "distributed systems",
            "data science concepts",
            "pandas",
            "scikit-learn",
            "communication"
        ]
    },
    "f392427ebfded120": {
        "terms": [
            "data science"
        ],
        "salary_min": 96928.0,
        "salary_max": -1.0,
        "title": "Configuration Management Process and Technology Manager",
        "company": "Ascension",
        "desc": "Details \n \n \n \n \n Department:  Technology Business Operations \n  Schedule:  Full time \n  Location:  Remote \n \n  Benefits  \n \n  Paid time off (PTO)\n    Various health insurance options & wellness plans\n    Retirement benefits including employer match plans\n    Long-term & short-term disability\n    Employee assistance programs (EAP)\n    Parental leave & adoption assistance\n    Tuition reimbursement\n    Ways to give back to your community\n  \n \n \n  As a military friendly organization, Ascension promotes career flexibility and offers many benefits to help support the well-being of our military families, spouses, veterans and reservists. Our associates are empowered to apply their military experience and unique perspective to their civilian career with Ascension.\n  \n \n \n   Please note, benefits and benefits eligibility can vary by position, exclusions may apply for some roles (for example: PRN, Short-Term Option, etc.). Connect with your Talent Advisor today for additional specifics. \n \n \n  Responsibilities  \n As a member of the Service Asset and Configuration Management team, the  Configuration Management Process and Technology Manager  plays a crucial role in our operational excellence strategy and is the process owner responsible for configuration management processes, services and capabilities. Leverage your experience to partner with cross-functional ITSM and technical professionals to continuously improve and deliver critical foundational solutions across the Ascension IT landscape. \n  Has the ability and authority to deliver the strategic roadmap and the daily end-to-end Service, Asset and Configuration Management (SACM) services in accordance with the SACM Plan. \n  Responsibilities \n \n  Establish and maintain the Service, Asset and Configuration Management Strategy and Roadmap based on business, service and operational customers needs and strategies \n  Establish and maintain Asset and CMDB architectural standards in alignment with the ServiceNow Common Service Data Model (CSDM) and provide prescriptive guidance on service modeling within the Asset and CMDB in support of scalability, automation, and time to value of the Now Platform \n  Provide direction for the work of 1-2 Configuration Management Analysts and mentor the organization on CM services, concepts, policies and procedures, compliance and resolution/escalation of issues. \n  Oversee CMDB support services, to include requests to provision and deprovision CI\u2019s, and regular maintenance work such as CI discovery, identification and control, status accounting and reporting. \n  Has the ability and authority to deliver the strategic roadmap and the daily end-to-end Service, Asset and Configuration Management (SACM) services in accordance with the SACM Plan. \n  Develop and maintain Ascension\u2019s configuration models for services, assets, applications and infrastructure to enable key processes such as impact and cause of incident and problems, change planning and design and change risk and impact assessment, planning tech refreshes, software upgrades, optimize asset utilization by understanding which CI\u2019s make up a service, enable service health reporting via service mapping \n  Establish and build relationships with other ITIL process owners, applicable tool owners and stakeholders to understand business objectives, data structure, and how CMDB and Asset Management processes will best support the enterprise and process specific objectives. \n  Facilitate communication and engage business and IT management to support SACM efforts and value proposition. \n  Act as subject matter expert to support service design and service transition methodologies while engaging with strategic projects to ensure SACM can deliver required functionality within project timeframe \n  Continually improve process execution using automated means wherever possible and clearly document responsibilities and expectations of Service Owners or other stakeholders where manual maintenance is necessary. \n  Inform the day-to-day activities of the process, including establishing priorities and work assignments \n  Facilitate SACM annual maturity assessments \n  Review critical incident outage resolution results and responses and dispositions of failed changes due to Configuration Management System (CMS) related issues \n  Reviews and approves all changes to the CMS application and/or infrastructure where applicable \n  Reviews significant IT infrastructure changes to ensure impacts to configuration management data are properly addressed \n  Collaborate with ServiceNow platform management team to establish and support integration points such as Ascension Data lake, financial systems, IT Service Continuity systems, SolarWinds and capacity planning for the ServiceNow platform. \n  Provides or reviews all requirements, use cases, user stories, etc. in support of new or improving functionality of the Asset and Configuration Management systems \n  Reviews and publishes configuration management reporting. \n  Oversee and support asset and configuration management system testing activities \n  Experience integrating and operating Software License Management platforms such as Flexera preferred \n \n  Requirements  \n \n  Licensure / Certification / Registration:\n  \n \n  Certification credentialed from the International Association of Information Technology Asset Managers preferred. \n \n \n   Education:\n  \n \n  High School diploma equivalency with 3 years of cumulative experience OR Associate's  degree/Bachelor's degree with 2 years of cumulative experience OR 7 years of applicable cumulative job specific experience required. \n  3 years of leadership or management experience preferred. \n \n  Additional Preferences  \n \n 10 years progressive experience in IT in relevant fields \n  At least 4 years of experience leading CDMB deployment and operations in Global Information Technology environment or large enterprise with diverse infrastructures and application portfolios. \n  5+ years leadership minimum \n  Experience with ServiceNow platform, or similar tool, certifications strongly preferred \n  Proven ability to provide thought leadership and design data structures across multiple domains and a system of management controls to maintain correctness, completeness and compliance \n  Experience delivering measurable outcomes, performance consistency and reporting results to key process partners and stakeholders \n  Demonstrate ability to measure and show value creation to the business through process efficiency, automation and ITSM process integration \n  ITIL V3/V4 Foundation preferred with at least 6 years\u2019 experience leveraging ITSM and ITOM best practices supported by a Configuration Management System \n  Understanding of SDLC and various development and project methodologies such as Waterfall, Agile, DevOps, CI/CD, etc. \n  Bachelor Degree in Computer Science, Information Systems, Data Science or equivalent preferred \n \n \n \n  #LI-Remote #AscensionTechnologies\n  \n  Why Join Our Team  \n \n  When you join Ascension, you join a team of over 150,000 individuals across the country committed to a Mission of serving others and providing compassionate, personalized care to all. Our inclusive culture, continuing education programs, career coaches and benefit offerings are just a few of the resources and tools that team members can use to create a rewarding career path. In fact, Ascension spent nearly $46 million in tuition assistance alone to support associate growth and development. If you are looking for a career where you can grow and make a difference in your community, we invite you to join our team today.\n  \n  Equal Employment Opportunity Employer  \n \n  Ascension will provide equal employment opportunities (EEO) to all associates and applicants for employment regardless of race, color, religion, national origin, citizenship, gender, sexual orientation, gender identification or expression, age, disability, marital status, amnesty, genetic information, carrier status or any other legally protected status or status as a covered veteran in accordance with applicable federal, state and local laws.\n  \n \n \n  For further information, view the EEO Know Your Rights (English) poster or EEO Know Your Rights (Spanish) poster.\n  \n \n \n  Pay Non-Discrimination Notice\n  \n \n \n  Please note that Ascension will make an offer of employment only to individuals who have applied for a position using our official application. Be on alert for possible fraudulent offers of employment. Ascension will not solicit money or banking information from applicants.\n  \n  E-Verify Statement  \n \n  This employer participates in the Electronic Employment Verification Program. Please click the E-Verify link below for more information.\n   \n  E-Verify",
        "cleaned_desc": "  High School diploma equivalency with 3 years of cumulative experience OR Associate's  degree/Bachelor's degree with 2 years of cumulative experience OR 7 years of applicable cumulative job specific experience required. \n  3 years of leadership or management experience preferred. \n \n  Additional Preferences  \n \n 10 years progressive experience in IT in relevant fields \n  At least 4 years of experience leading CDMB deployment and operations in Global Information Technology environment or large enterprise with diverse infrastructures and application portfolios. \n  5+ years leadership minimum \n  Experience with ServiceNow platform, or similar tool, certifications strongly preferred \n  Proven ability to provide thought leadership and design data structures across multiple domains and a system of management controls to maintain correctness, completeness and compliance \n  Experience delivering measurable outcomes, performance consistency and reporting results to key process partners and stakeholders \n  Demonstrate ability to measure and show value creation to the business through process efficiency, automation and ITSM process integration \n  ITIL V3/V4 Foundation preferred with at least 6 years\u2019 experience leveraging ITSM and ITOM best practices supported by a Configuration Management System \n  Understanding of SDLC and various development and project methodologies such as Waterfall, Agile, DevOps, CI/CD, etc. \n  Bachelor Degree in Computer Science, Information Systems, Data Science or equivalent preferred \n \n \n \n  #LI-Remote #AscensionTechnologies\n  \n  Why Join Our Team  \n ",
        "techs": [
            "high school diploma equivalency",
            "associate's degree",
            "bachelor's degree",
            "leadership",
            "management",
            "it",
            "cdmb deployment",
            "global information technology environment",
            "large enterprise",
            "infrastructures",
            "application portfolios",
            "servicenow platform",
            "certifications",
            "thought leadership",
            "data structures",
            "management controls",
            "correctness",
            "completeness",
            "compliance",
            "measurable outcomes",
            "performance consistency",
            "reporting results",
            "process efficiency",
            "automation",
            "itsm process integration",
            "itil v3/v4 foundation",
            "configuration management system",
            "sdlc",
            "development methodologies",
            "project methodologies",
            "waterfall",
            "agile",
            "devops",
            "ci/cd",
            "computer science",
            "information systems",
            "data science"
        ],
        "cleaned_techs": [
            "high school diploma equivalency",
            "leadership",
            "management",
            "it",
            "cdmb deployment",
            "global information technology environment",
            "large enterprise",
            "infrastructures",
            "application portfolios",
            "servicenow platform",
            "certifications",
            "thought leadership",
            "data structures",
            "management controls",
            "correctness",
            "completeness",
            "compliance",
            "measurable outcomes",
            "performance consistency",
            "reporting results",
            "process efficiency",
            "automation",
            "itsm process integration",
            "itil v3/v4 foundation",
            "configuration management system",
            "sdlc",
            "development methodologies",
            "project methodologies",
            "waterfall",
            "agile",
            "devops",
            "ci/cd",
            "computer science",
            "information systems",
            "data science"
        ]
    },
    "c444a8da46dd1ff7": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 79237.766,
        "salary_max": 100332.67,
        "title": "Senior Data Analyst",
        "company": "Horace Mann",
        "desc": "This is a remote position. \n  The  Senior Data Analyst  is responsible for the design, development, and analysis of complex reports, queries, and data extracts from multiple data sources to support strategic initiatives and enable leadership to efficiently measure performance. \n  Responsibilities: \n \n Act as subject matter expert on core data assets including quote, rating, exposures, and claims performance data. \n Develop and maintain data pipelines in support of various analyses across Marketing, Field Operations, Product Development, and Pricing functions. \n Develop and maintain methods to organize and compare disparate data sets from various data structures including, but not limited to databases, flat files, XML, JSON, etc. \n Develop and maintain proprietary packages to support ETL, storage, access, and analysis operations used for prototyping and product deployment. \n Under the supervision of the Director of Third Party Data and Vendor Management, coordinate with internal and external stakeholders to administer retrovalidations, including vendor identification, communication, and analysis \n Review vendor agreements to ensure alignment with business objectives \n Work with the Director of Third Party Data and Vendor Management to establish a clear, communicable value for the data components of each product line's expense ratio. \n Collaborate closely with Horace Mann's Data Science, Marketing Analytics, Pricing, and Product Management teams to support key current year objectives while setting the runway for long term strategies. \n \n Qualifications \n \n A Bachelor's Degree in statistics, math, engineering, computer science, economics, business, or a related technical field, Master's Degree preferred. \n 3-5 years of overall data analyst experience, preferably in the insurance industry \n Background in direct support of a predictive modeling team. \n Excellent data analysis and communication skills. \n Expertise in SQL (postgres, MS SQL Server, etc.), R, and/or Python. \n Expertise on both Windows and Linux operating systems. \n Experience developing and maintaining ETL and/or modeling data pipelines. \n Experience adhering to a rigorous software development practice including, but not limited to, version control systems (git preferred), style guides, and documentation in a Kanban workstream. \n Experience with statistical modeling and data visualization tools, Qlik preferred. \n Working understanding of an insurance industry, highly preferred. \n Experience solving real-world data problems with code. \n Demonstrates problem solving, decision-making, and process-improvement skills. \n Strong intellectual curiosity and capabilities. \n Familiarity and experience with competitive analysis, and communicating to a diverse audience of stakeholders. \n Ability to manage deliverables and expectations across multiple key stakeholders. \n \n \n \n  Work location is flexible if approved by the Company except that the position may not be performed remotely from New York City. \n  Must be able to work in the United States without Employer Sponsorship \n  #VIZI# \n \n  Horace Mann was founded in 1945 by two Springfield, Illinois, teachers who saw a need for quality, affordable auto insurance for teachers. Since then, we've broadened our mission to helping all educators protect what they have today and prepare for a successful tomorrow. And with our broadened mission has come corporate growth: We serve more than 4,100 school districts nationwide, we're publicly traded on the New York Stock Exchange (symbol: HMN) and we have more than $12 billion in assets. \n  We're motivated by the fact that educators take care of our children's future, and we believe they deserve someone to look after theirs. We help educators identify their financial goals and develop plans to achieve them. This includes insurance to protect what they have today and financial products to help them prepare for their future. Our tailored offerings include special rates and benefits for educators. \n  EOE/Minorities/Females/Veterans/Disabled. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status \n  For applicants that are California residents, please review our California Consumer Privacy Notice \n  All applicants should review our Horace Mann Privacy Policy",
        "cleaned_desc": "This is a remote position. \n  The  Senior Data Analyst  is responsible for the design, development, and analysis of complex reports, queries, and data extracts from multiple data sources to support strategic initiatives and enable leadership to efficiently measure performance. \n  Responsibilities: \n \n Act as subject matter expert on core data assets including quote, rating, exposures, and claims performance data. \n Develop and maintain data pipelines in support of various analyses across Marketing, Field Operations, Product Development, and Pricing functions. \n Develop and maintain methods to organize and compare disparate data sets from various data structures including, but not limited to databases, flat files, XML, JSON, etc. \n Develop and maintain proprietary packages to support ETL, storage, access, and analysis operations used for prototyping and product deployment.   3-5 years of overall data analyst experience, preferably in the insurance industry \n Background in direct support of a predictive modeling team. \n Excellent data analysis and communication skills. \n Expertise in SQL (postgres, MS SQL Server, etc.), R, and/or Python. \n Expertise on both Windows and Linux operating systems. \n Experience developing and maintaining ETL and/or modeling data pipelines. \n Experience adhering to a rigorous software development practice including, but not limited to, version control systems (git preferred), style guides, and documentation in a Kanban workstream. \n Experience with statistical modeling and data visualization tools, Qlik preferred.   Working understanding of an insurance industry, highly preferred. \n Experience solving real-world data problems with code. \n Demonstrates problem solving, decision-making, and process-improvement skills. \n Strong intellectual curiosity and capabilities. \n Familiarity and experience with competitive analysis, and communicating to a diverse audience of stakeholders. \n Ability to manage deliverables and expectations across multiple key stakeholders. \n \n ",
        "techs": [
            "sql",
            "r",
            "python",
            "postgres",
            "ms sql server",
            "windows",
            "linux",
            "etl",
            "kanban",
            "qlik"
        ],
        "cleaned_techs": [
            "sql",
            "r",
            "python",
            "postgres",
            "ms sql server",
            "windows",
            "linux",
            "etl",
            "kanban",
            "qlik"
        ]
    },
    "cb1d5408f8f7d013": {
        "terms": [
            "data science",
            "mlops"
        ],
        "salary_min": 153000.0,
        "salary_max": 191300.0,
        "title": "AI Engineering Manager",
        "company": "Agilon Health",
        "desc": "Company:\n   AHI agilon health, inc.\n  \n \n   Job Posting Location:\n   Remote - USA\n  \n \n   Job Title: \n  AI Engineering Manager\n  \n \n   Job Description: \n  \n \n  agilon health is transforming healthcare by empowering community-based physicians with the resources and expertise they need to innovate the payment and delivery of care for seniors.\n  \n \n \n   The agilon health Total Care Model is powered by our purpose-built platform and frees physicians from the constraints of the traditional fee-for-service reimbursement model, all enabled through a growing national network of like-minded physician partners.\n  \n \n \n   With agilon health, physicians are able to practice team-based, coordinated care to serve the individual needs of their senior patients and to transition to a sustainable and predictable, long-term business model.\n  \n \n \n   As you might imagine, analytics and insights are the heart of how we support our physician partners and is agilon\u2019s special sauce. We have a strong team in place already and are looking for someone to help lead the AI team in solving some of the hardest problems in healthcare.\n  \n \n \n   The team builds traditional predictive and learning ML models across many different business problems to drive targeted and actionable insights and is also looking to apply LLMs to solve our strategic needs, so you will gain exposure to and will be able to make an impact in a large number of domains.\n  \n \n \n   You will coach the team, engage with stakeholders, and have the opportunity to make your own contributions with direct line of sight to improving patient outcomes and reducing medical waste. Come join the team and help make a meaningful impact in our senior members\u2019 lives!\n  \n \n \n   More about this role:\n  \n \n \n Lead an agile AI team in designing, training, and deploying models to support a wide range of health care use cases. \n Build strong collaborations with agilon\u2019s leadership and many different cross-functional teams, including UX, Product, Technology, Clinical, Medical Programs, Finance, and Operations. \n Drive successful project execution and clinical and business value delivery. \n Mentor data scientists to grow and live up to their full potential, and coach high-performing engineering teams. \n Provide guidance to your team on code quality, model training, and MLOps workflows in production. \n \n \n \n   Qualifications:\n  \n \n \n Advanced degree (PhD, MS, MBA, MD) and at least five years of experience working in production environments. \n Strong record of delivering value from machine learning projects. \n Proven experience leading teams and collaborating with stakeholders in an agile setting. \n Three years of experience with machine learning and deep learning models, ideally with hands-on experience with large language models (LLMs) or other forms of generative AI. \n Fluent with Python and SQL. \n Comfortable with AWS and hands-on experience with AWS managed services \n Ability to consistently achieve results, even under tough circumstances. \n Excellent communicator and a nimble learner. \n \n \n \n   If you have an entrepreneurial spirit, a record of leading successful machine learning projects, and are excited about leveraging technology to have a meaningful impact on doctors and patients, we would love to hear from you.\n  \n \n   Location: \n  Remote - MA\n  \n \n   Pay Range: \n  $153,000.00 - $191,300.00\n  \n \n   Salary range shown is a guideline. Individual compensation packages can vary based on factors unique to each candidate, such as skill set, experience, and qualifications.",
        "cleaned_desc": " Drive successful project execution and clinical and business value delivery. \n Mentor data scientists to grow and live up to their full potential, and coach high-performing engineering teams. \n Provide guidance to your team on code quality, model training, and MLOps workflows in production. \n \n \n \n   Qualifications:\n  \n \n \n Advanced degree (PhD, MS, MBA, MD) and at least five years of experience working in production environments. \n Strong record of delivering value from machine learning projects. \n Proven experience leading teams and collaborating with stakeholders in an agile setting. \n Three years of experience with machine learning and deep learning models, ideally with hands-on experience with large language models (LLMs) or other forms of generative AI. \n Fluent with Python and SQL. ",
        "techs": [
            "python",
            "sql"
        ],
        "cleaned_techs": [
            "python",
            "sql"
        ]
    },
    "1c8ed1f4148b5c4c": {
        "terms": [
            "data science"
        ],
        "salary_min": 61803.035,
        "salary_max": 78256.414,
        "title": "Sector Specialist - HYBRID",
        "company": "Inclusively",
        "desc": "Inclusively is partnering with a multinational financial services company to hire a Sector Specialist - HYBRID. \n ABOUT INCLUSIVELY: \n Inclusively is a digital tech platform that connects candidates with disabilities, who may benefit from workplace accommodations, to inclusive employers. This includes all disabilities under the ADA, including mental health conditions (e.g. anxiety, depression, PTSD), chronic illnesses (e.g. diabetes, Long COVID), and neurodivergence (e.g. autism, ADHD).  Applicants with one or more of these conditions are encouraged to apply; Inclusively does not require applicants to disclose their specific disability. \n Job Description: \n The Department \n Equity Division is responsible for managing more than 130 diversified mutual funds and over 60 industry specific funds. Assets under management total more than $1 Trillion. The department consists of over 200 Portfolio Managers, Research Analysts, Research Associates, and Sector Specialists. \n The Position \n We are currently recruiting for a sector specialist to join our Sector Specialist Team in Equity Research Department. In this position, you will play a vital role in contributing to the investment performance of the team by working closely with the analysts, associates, and portfolio managers across the department, reporting directly to the Director of Sector Research. \n Responsibilities \n \n Provide general research support to the equity research analysts and associates \n Bring together and analyze industry data \n Graph industry trends and analytical results \n Streamline data collection and data management \n Conduct a variety of analyses across the fundamental, quantitative, and data science disciplines \n Interpret the results, form conclusions, and make recommendations based on the analyses conducted \n Work closely with analysts and associates on various projects to support stock-specific and industry presentations \n Collaborate with other sector specialists globally, industry sources, Wall Street contacts, and internal groups (technology data and systems support, market data, our data scientists, and research services) in order to gain important insight, knowledge, and tools to support and positively influence the research process \n \n Qualifications \n Qualified prospects will have a Bachelor\u2019s degree and at least 1-2 years of work experience, preferably in areas related to security investing, financial statement analysis, accounting, valuation, economics or statistics. A graduate degree in a financial or investment related discipline, a hard science, mathematics, or a CFA charter, are a plus. \n We are seeking someone who has: \n \n Strong Microsoft Excel/VBA skills and an aptitude for technology and working with (and presenting) data \n Proficiency with R and/or Python languages \n Experience with financial databases like Bloomberg and FactSet \n Exhibited experience/interest/skill in fundamental security analysis \n Exhibited experience/interest/skill in quantitative analysis \n Exhibited experience/interest/skill in data science \n Excellent communication, presentation and writing skills and is able to clearly articulate research findings \n A commitment to the integrity of the scientific method \n \n Job Type: Full-time \n Weekly day range: \n \n Monday to Friday \n \n Work setting: \n \n Remote \n \n Work Location: Remote",
        "cleaned_desc": " Work closely with analysts and associates on various projects to support stock-specific and industry presentations \n Collaborate with other sector specialists globally, industry sources, Wall Street contacts, and internal groups (technology data and systems support, market data, our data scientists, and research services) in order to gain important insight, knowledge, and tools to support and positively influence the research process \n \n Qualifications \n Qualified prospects will have a Bachelor\u2019s degree and at least 1-2 years of work experience, preferably in areas related to security investing, financial statement analysis, accounting, valuation, economics or statistics. A graduate degree in a financial or investment related discipline, a hard science, mathematics, or a CFA charter, are a plus. \n We are seeking someone who has: \n \n Strong Microsoft Excel/VBA skills and an aptitude for technology and working with (and presenting) data   Proficiency with R and/or Python languages \n Experience with financial databases like Bloomberg and FactSet \n Exhibited experience/interest/skill in fundamental security analysis \n Exhibited experience/interest/skill in quantitative analysis \n Exhibited experience/interest/skill in data science \n Excellent communication, presentation and writing skills and is able to clearly articulate research findings \n A commitment to the integrity of the scientific method \n ",
        "techs": [
            "microsoft excel/vba",
            "r",
            "python",
            "bloomberg",
            "factset"
        ],
        "cleaned_techs": [
            "excel",
            "r",
            "python",
            "bloomberg",
            "factset"
        ]
    },
    "fa055232f5e4f4ed": {
        "terms": [
            "data science"
        ],
        "salary_min": 96903.46,
        "salary_max": 122701.38,
        "title": "Project Lead, Data Solutions (Remote)",
        "company": "Crum & Forster",
        "desc": "Crum & Forster Company Overview: \n   Crum & Forster (C&F)  Crum & Forster (C&F), with a proud history dating to 1822, provides specialty and standard commercial lines insurance products through our admitted and surplus lines insurance companies. C&F enjoys a financial strength rating of \"A\" (Excellent) by AM Best and is proud of our superior customer service platform. Our claims and risk engineering services are recognized as among the best in the industry.  \n Our most valuable asset is our people: more than 2000 employees in locations throughout the United States. The company is increasingly winning recognition as a great place to work, earning several workplace and wellness awards, including the  October 2022 Great Place to Work \u00ae  Award  for our employee-first focus and our steadfast commitment to diversity, equity and Inclusion.  \n C&F is part of Fairfax Financial Holdings, a global, billion dollar organization. For more information about Crum & Forster, please visit our website: www.cfins.com. \n \n  Job Description:\n  \n  Crum & Forster provides specialty and standard commercial lines insurance products through our admitted and surplus lines insurance companies. Operating out of our corporate offices in Morristown, New Jersey, and ten regional offices, we distribute our products through approximately 1,500 authorized retail and wholesale brokers across the United States. \n  We are looking for innovative, talented, and self-motivated individuals who are interested in working with a cross-functional team focused on production support of our Data & Analytics team. \n \n  We\u2019re seeking an experienced Project Lead/Data Analyst to join our dynamic Data Team. The ideal candidate will have a unique blend of project management skills and a deep understanding of data analytics within the P&C insurance domain. \n \n  What you will do: \n \n  Manage and lead data-driven projects from inception to completion, ensuring alignment with business objectives and timely delivery.  \n Collaborate with stakeholders to define project scopes, objectives, deliverables, and transform requirements into technical specifications.  \n Analyze complex datasets to derive actionable insights, identify trends, and make recommendations. \n  Develop and maintain KPIs, dashboards, and regular reports to monitor project progress and data insights.  \n Interface with the IT and software development teams to integrate and manage insurance data sources and solutions.  \n Ensure data quality and integrity across all projects. \n  Provide mentorship and training to junior team members. \n  Define and oversee data architecture, standards, and governance for P&C insurance initiatives.  \n Design and implement data models optimized for reporting and analytics. \n  Oversee the ETL processes from various data sources.  \n Conduct regular data audits and reconciliation. \n  Stay updated with the latest trends and technologies in data analytics and P&C insurance.  \n Provide solutions to complex data-related problems. \n  Document and maintain architecture blueprints, data dictionaries, and process workflows.  \n Work closely with business teams to understand and predict emerging needs. \n  Evaluate and recommend new tools and technologies for data analytics. \n  Ensure compliance with regulatory standards related to data handling in the P&C domain.  \n Plan and manage data migration projects when necessary. \n  Lead and participate in meetings, providing data-driven insights and recommendations.  \n Work with external vendors or consultants as required. \n \n  What you will bring to C&F: \n \n \n  Bachelor's or Master's degree in Data Science, Computer Science, or a related field such as Data Analytics, Business, or Insurance.  \n Minimum of 8 years of experience (10+ preferred) in leading project and data analytics, preferably in the Property & Casualty (P&C) insurance domain.  \n Proven experience in the P&C insurance domain, with a strong understanding of insurance products, claims, and underwriting processes.  \n Proven ability to manage multiple projects simultaneously and meet tight deadlines. \n  Strong Proficiency in data querying languages like SQL. \n  Strong Expertise in database management systems like SQL Server, Oracle, or MySQL. \n  Strong expertise with ETL (Extract, Transform, Load) tools such as Snowflake, Informatica, or SSIS (SQL Server Integration Services).  \n Strong Knowledge of data modeling tools like ER/Studio or ERwin. \n  Proficiency in MS Excel and equivalent Data Analysis tools \n  Experience with Big Data technologies like Snowflake is good. \n  Deliver projects in a agile environment. \n  Exceptional communication skills, both written and verbal. \n  Demonstrated ability to work independently as well as collaboratively in a team environment. \n  Familiarity with cloud platforms such as AWS (Amazon Web Services), Azure. \n  Knowledge of data visualization tools such as Tableau or Power BI. \n  An innate sense of learning, curiosity and the passion to try and deliver the best. Open to learning new data integration tools. \n \n \n   #LI-MS\n  \n \n \n  #LI-REMOTE\n   What C&F will bring to you: \n  \n Competitive compensation package \n  Generous 401K employer match \n  Employee Stock Purchase plan with employer matching \n  Generous Paid Time Off \n  Excellent benefits that go beyond health, dental & vision. Our programs are focused on your whole family\u2019s wellness, including your physical, mental and financial wellbeing \n  A core C&F tenet is owning your career development, so we provide a wealth of ways for you to keep learning, including tuition reimbursement, industry-related certifications and professional training to keep you progressing on your chosen path \n  A dynamic, ambitious, fun and exciting work environment \n  We believe you do well by doing good and want to encourage a spirit of social and community responsibility, matching donation program, volunteer opportunities, and an employee-driven corporate giving program that lets you participate and support your community \n \n \n   At C&F you will BELONG\n  \n \n \n  If you require special accommodations, please let us know.We value inclusivity and diversity. We are committed to equal employment opportunity and welcome everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require special accommodations, please let us know\n  \n \n \n  Crum & Forster is committed to ensuring a workplace free from discriminatory pay disparities and complying with applicable pay equity laws. Salary ranges are available for all positions at this location, taking into account roles with a comparable level of responsibility and impact in the relevant labor market and these salary ranges are regularly reviewed and adjusted in accordance with prevailing market conditions. The annualized base pay for the advertised position, located in the specified area, ranges from a minimum of $105,800 to a maximum of 176,300. The actual compensation is determined by various factors, including but not limited to the market pay for the jobs at each level, the responsibilities and skills required for each job, and the employee\u2019s contribution (performance) in that role. To be considered within market range, a salary is at or above the minimum of the range. You may also have the opportunity to participate in discretionary equity (stock) based compensation and/or performance-based variable pay programs.",
        "cleaned_desc": " Analyze complex datasets to derive actionable insights, identify trends, and make recommendations. \n  Develop and maintain KPIs, dashboards, and regular reports to monitor project progress and data insights.  \n Interface with the IT and software development teams to integrate and manage insurance data sources and solutions.  \n Ensure data quality and integrity across all projects. \n  Provide mentorship and training to junior team members. \n  Define and oversee data architecture, standards, and governance for P&C insurance initiatives.  \n Design and implement data models optimized for reporting and analytics. \n  Oversee the ETL processes from various data sources.  \n Conduct regular data audits and reconciliation. \n  Stay updated with the latest trends and technologies in data analytics and P&C insurance.  \n Provide solutions to complex data-related problems. \n  Document and maintain architecture blueprints, data dictionaries, and process workflows.  \n Work closely with business teams to understand and predict emerging needs. \n  Evaluate and recommend new tools and technologies for data analytics. \n  Ensure compliance with regulatory standards related to data handling in the P&C domain.  \n Plan and manage data migration projects when necessary.    Lead and participate in meetings, providing data-driven insights and recommendations.  \n Work with external vendors or consultants as required. \n \n  What you will bring to C&F: \n \n \n  Bachelor's or Master's degree in Data Science, Computer Science, or a related field such as Data Analytics, Business, or Insurance.  \n Minimum of 8 years of experience (10+ preferred) in leading project and data analytics, preferably in the Property & Casualty (P&C) insurance domain.  \n Proven experience in the P&C insurance domain, with a strong understanding of insurance products, claims, and underwriting processes.  \n Proven ability to manage multiple projects simultaneously and meet tight deadlines. \n  Strong Proficiency in data querying languages like SQL. \n  Strong Expertise in database management systems like SQL Server, Oracle, or MySQL. \n  Strong expertise with ETL (Extract, Transform, Load) tools such as Snowflake, Informatica, or SSIS (SQL Server Integration Services).  \n Strong Knowledge of data modeling tools like ER/Studio or ERwin. \n  Proficiency in MS Excel and equivalent Data Analysis tools \n  Experience with Big Data technologies like Snowflake is good.    Deliver projects in a agile environment. \n  Exceptional communication skills, both written and verbal. \n  Demonstrated ability to work independently as well as collaboratively in a team environment. \n  Familiarity with cloud platforms such as AWS (Amazon Web Services), Azure. \n  Knowledge of data visualization tools such as Tableau or Power BI. \n  An innate sense of learning, curiosity and the passion to try and deliver the best. Open to learning new data integration tools. \n \n \n   #LI-MS\n  \n \n \n  #LI-REMOTE\n   What C&F will bring to you: \n  \n Competitive compensation package ",
        "techs": [
            "snowflake",
            "informatica",
            "ssis",
            "er/studio",
            "erwin",
            "sql server",
            "oracle",
            "mysql",
            "tableau",
            "power bi",
            "aws",
            "azure"
        ],
        "cleaned_techs": [
            "snowflake",
            "informatica",
            "ssis",
            "er/studio",
            "erwin",
            "sql",
            "oracle",
            "mysql",
            "tableau",
            "powerbi",
            "aws",
            "azure"
        ]
    },
    "75eebfd87f152acc": {
        "terms": [
            "data science"
        ],
        "salary_min": 150000.0,
        "salary_max": 185000.0,
        "title": "Senior Manager, Data Engineering (Remote)",
        "company": "Abercrombie and Fitch Co.",
        "desc": "Company Description\n   Job Description \n  The primary responsibility of the data engineering manager is to work with data engineering team driving the design, build, launching of new data models and data pipeliles utilizing modern data engineering standards, design patterns and practices. Their mission is to build high performing teams driving delivery, onboarding of new data and data quality for trusted data that is easy to access, understand, and derive value. The role requires forward thinking with a focus on transforming existing incumbent solutions into sustainable and scalable solutions on modern cloud data technology. \n  The data engineering manager will facilitate the adoption of modern data standards, engineering practices, devops, test driven development, and simplification of data engineering within the organization. They will work with engineering teams and architects to design solutions which meet enterprise standards. \n  Besides, the Data Engineering Manager will be responsible for identifying/promoting emerging technology trends in data engineering space to ensure the company is leveraging them when appropriate to increase efficiency, drive business agility, reduce costs, and drive value. \n  What Will You Be Doing? \n \n  Team up  with our engineering and enterprise architecture teams to define and create data engineering principles, standards, and design patterns related to metadata management, data integration, data storage, data security, data modeling, data quality, and data access control \n  Promote best practice  and provide guidance to our Data Engineering and Data Science teams to facilitate the buildout of data products that drive business value \n  Partner with the engineering and business teams   to serve as an evangelist in promoting the use of event streams, cloud-based data solutions, Data Ownership, Data Stewardship, and self-service \n  Support the migration of  1000+ integrations and data pipelines  from diverse on-prem technologies to cloud-based integration tools and technology \n  Collaborate with project portfolio management team and technology stakeholders on integrations solutions design ensuring data engineering standards and practices building scalable and flexible solution \n  Partner with the infrastructure and security teams  on data engineering, solutions design, centralized logging/monitoring, and transformation efforts to ensure proper scope, resources and costs allocated for needs \n  Serve as an evangelist in promoting and adopting modern data engineering standards and practices across IT \n  Ensure that all application development initiatives are well managed and delivered to meet expectations on functionality, timeliness, and cost. \n  Lead and/or participate on technical user groups, task forces, and committees \n \n  What Do You Need To Bring? \n \n  Able to manage a team thru major/complex data transformation to event driven architecture (Kafka) and modern cloud data architecture (Azure, Databricks, Snowflake, Power BI) \n  Provide leadership and management to build high-performing teams and continuously upskill team members to keep them current thru professional development programs \n  Ability to prioritize personal and team responsibilities to meet organizational objectives \n  Drive the cultural changes necessary to enable a continuous delivery model, modern data engineering standards, and foster a strong focus on automation and agile delivery methods. \n  Willingness to learn new things and adapt quickly to a team and enterprise undergoing positive transformation \n  High interpersonal skills to operate in a large, distributed, and diverse global technology team \n  Success working as a technical leader in a large enterprise organization \n  Sets team goals to ensure the success of the department in accordance with milestones developed by IT Senior Management \n  Develop and retain high caliber data engineering talent \n  Ability to foster a culture of transparency and a sense of purpose among the team and create clear accountabilities and metrics. \n  Bachelor\u2019s degree in Computer Science or related field and  10-15 years' experience  in various roles of technical leadership within a large-scale organization \n  Personal Attributes: Self-starter, Collaborative, Curious, Strong work ethic, Highly motivated, Team oriented \n  Successfully led data engineering and delivery of complex business technology solutions into production that have achieved or surpassed business goals. \n  Experience with modern data engineering development and design concepts; software development lifecycle; project management; advanced and systems administration practices and principles; planning, design, and problem resolution \n  Experience with management and supervisory practices leading people; human resource practices \n  Experience in leading data engineering team in delivering quality software solutions leveraging Azure cloud, Databricks, Snowflake, Power BI, API/micro services, and Kafka event driven technologies. \n  Demonstrated ability in developing a culture that embraces innovation, and challenges existing paradigms. \n \n  Our Company \n  Abercrombie & Fitch Co. (A&F Co.) is a global retailer of five iconic, omnichannel lifestyle brands catering to the kid through millennial customer: Abercrombie & Fitch, abercrombie kids, Hollister, Gilly Hicks and Social Tourist. At A&F Co., we\u2019re here for our associates, customers and communities on the journey to being and becoming who they are \u2013 and because no journey is the same, we strive to create an inclusive culture, where everyone is free to share ideas. \n  Our Values \n  We lead with purpose and always put our people first, which is evidenced by our Great Place to Work\u2122 Certification, as well as being a 2021 recipient of Fortune\u2019s Best Workplaces in Retail, and named a Best Place to Work for LGBTQ+ Equality by the Human Rights Campaign for 16 consecutive years. We\u2019re proud to offer equitable compensation and benefits, including flexibility and competitive Paid Time Off, as well as education and engagement events, including various Associate Resource Groups, volunteer opportunities and additional time off to give back to our global communities. \n  What You'll Get \n  As an Abercrombie & Fitch Co. (A&F Co.) associate, you\u2019ll be eligible to participate in a variety of benefit programs designed to fit you and your lifestyle. A&F is committed to providing simple, competitive, and comprehensive benefits that align with our Company\u2019s culture and values, but most importantly \u2013 with you! We also provide competitive incentives to reward the commitment our associates have for moving our global business forward: \n \n  Incentive Bonus Program \n  Paid Time Off and Work From Anywhere Flexibility \n  Paid Volunteer Day per Year, allowing you to give back to your community \n  Merchandise Discount \n  Medical, Dental and Vision Insurance Available \n  Life and Disability Insurance \n  Associate Assistance Program \n  Paid Parental and Adoption Leave \n  Access to Carrot to support your unique parenthood journey \n  Access to Headspace dedicated to creating healthier, happier lives from the inside out \n  401(K) Savings Plan with Company Match \n  Opportunities for Career Advancement, we believe in promoting from within \n  A Global Team of People Who'll Celebrate you for Being YOU \n \n \n \n \n Additional Information\n   ABERCROMBIE & FITCH CO. IS AN EQUAL OPPORTUNITY EMPLOYER \n  Notice (For Colorado, New York, California and Washington): The recruiting pay range for this position is $150,000 - $185,000. Factors that may be used to determine your actual salary may include your specific skills, your years of experience, your work location, comparison to other employees in similar or related roles, or market demands. The range may be modified in the future.",
        "cleaned_desc": "Company Description\n   Job Description \n  The primary responsibility of the data engineering manager is to work with data engineering team driving the design, build, launching of new data models and data pipeliles utilizing modern data engineering standards, design patterns and practices. Their mission is to build high performing teams driving delivery, onboarding of new data and data quality for trusted data that is easy to access, understand, and derive value. The role requires forward thinking with a focus on transforming existing incumbent solutions into sustainable and scalable solutions on modern cloud data technology. \n  The data engineering manager will facilitate the adoption of modern data standards, engineering practices, devops, test driven development, and simplification of data engineering within the organization. They will work with engineering teams and architects to design solutions which meet enterprise standards. \n  Besides, the Data Engineering Manager will be responsible for identifying/promoting emerging technology trends in data engineering space to ensure the company is leveraging them when appropriate to increase efficiency, drive business agility, reduce costs, and drive value. \n  What Will You Be Doing? \n \n  Team up  with our engineering and enterprise architecture teams to define and create data engineering principles, standards, and design patterns related to metadata management, data integration, data storage, data security, data modeling, data quality, and data access control \n  Promote best practice  and provide guidance to our Data Engineering and Data Science teams to facilitate the buildout of data products that drive business value \n  Partner with the engineering and business teams   to serve as an evangelist in promoting the use of event streams, cloud-based data solutions, Data Ownership, Data Stewardship, and self-service \n  Support the migration of  1000+ integrations and data pipelines  from diverse on-prem technologies to cloud-based integration tools and technology \n  Collaborate with project portfolio management team and technology stakeholders on integrations solutions design ensuring data engineering standards and practices building scalable and flexible solution    Partner with the infrastructure and security teams  on data engineering, solutions design, centralized logging/monitoring, and transformation efforts to ensure proper scope, resources and costs allocated for needs \n  Serve as an evangelist in promoting and adopting modern data engineering standards and practices across IT \n  Ensure that all application development initiatives are well managed and delivered to meet expectations on functionality, timeliness, and cost. \n  Lead and/or participate on technical user groups, task forces, and committees \n \n  What Do You Need To Bring? \n \n  Able to manage a team thru major/complex data transformation to event driven architecture (Kafka) and modern cloud data architecture (Azure, Databricks, Snowflake, Power BI) \n  Provide leadership and management to build high-performing teams and continuously upskill team members to keep them current thru professional development programs \n  Ability to prioritize personal and team responsibilities to meet organizational objectives \n  Drive the cultural changes necessary to enable a continuous delivery model, modern data engineering standards, and foster a strong focus on automation and agile delivery methods. \n  Willingness to learn new things and adapt quickly to a team and enterprise undergoing positive transformation    High interpersonal skills to operate in a large, distributed, and diverse global technology team \n  Success working as a technical leader in a large enterprise organization \n  Sets team goals to ensure the success of the department in accordance with milestones developed by IT Senior Management \n  Develop and retain high caliber data engineering talent \n  Ability to foster a culture of transparency and a sense of purpose among the team and create clear accountabilities and metrics. \n  Bachelor\u2019s degree in Computer Science or related field and  10-15 years' experience  in various roles of technical leadership within a large-scale organization \n  Personal Attributes: Self-starter, Collaborative, Curious, Strong work ethic, Highly motivated, Team oriented \n  Successfully led data engineering and delivery of complex business technology solutions into production that have achieved or surpassed business goals. \n  Experience with modern data engineering development and design concepts; software development lifecycle; project management; advanced and systems administration practices and principles; planning, design, and problem resolution \n  Experience with management and supervisory practices leading people; human resource practices \n  Experience in leading data engineering team in delivering quality software solutions leveraging Azure cloud, Databricks, Snowflake, Power BI, API/micro services, and Kafka event driven technologies. \n  Demonstrated ability in developing a culture that embraces innovation, and challenges existing paradigms. ",
        "techs": [
            "event streams",
            "cloud-based data solutions",
            "data ownership",
            "data stewardship",
            "self-service",
            "on-prem technologies",
            "cloud-based integration tools",
            "kafka",
            "azure",
            "databricks",
            "snowflake",
            "power bi",
            "centralized logging/monitoring",
            "automation",
            "agile delivery methods",
            "transparency",
            "computer science"
        ],
        "cleaned_techs": [
            "event streams",
            "cloud-based data solutions",
            "data ownership",
            "data stewardship",
            "self-service",
            "on-prem technologies",
            "cloud-based integration tools",
            "kafka",
            "azure",
            "databricks",
            "snowflake",
            "powerbi",
            "centralized logging/monitoring",
            "automation",
            "agile delivery methods",
            "transparency",
            "computer science"
        ]
    },
    "da36bc301acf1248": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 118757.766,
        "salary_max": 150373.8,
        "title": "FamilySearch Artificial Intelligence/Machine Learning Engineer (US-based, Remote Optional)",
        "company": "The Church of Jesus Christ of Latter-day Saints",
        "desc": "As an Artificial Intelligence/Machine Learning Engineer at FamilySearch.org, you will be at the forefront of developing and implementing advanced algorithms, models, and data-driven solutions that enhance the search capabilities, accuracy, and user experience of our platform. Working in close collaboration with a team of talented engineers, data scientists, and domain experts, you will help create and refine the AI-driven features that enable millions of users worldwide to make remarkable discoveries about their ancestors and family history.  \n We are looking for a passionate and dedicated candidate who shares our vision of advancing the Lord's work. You will have the opportunity to use cutting-edge technologies, access high-performance computing resources, and collaborate with highly skilled peers. This is a rare and rewarding chance to grow your career and personal skills while making a positive impact.  \n Why Join FamilySearch.org?  \n \n Impactful Mission: Be part of a meaningful mission to help individuals discover their family history and create lasting connections.  \n Cutting-Edge Technology: Work with state-of-the-art AI and machine learning technologies to push the boundaries of genealogical research.  \n Collaborative Environment: Join a team of passionate engineers, data scientists, and domain experts who value collaboration, innovation, and knowledge sharing.  \n Continuous Growth: Engage in professional development opportunities, attend conferences, and stay at the forefront of AI advancements.  \n Work-Life Balance: FamilySearch.org values work-life balance and promotes a flexible and supportive work environment.  \n \n If you're a highly motivated and creative thinker who is excited to make a tangible impact in the world of artificial intelligence and family history, we would love to hear from you! Join us at FamilySearch.org and be part of a transformative journey that connects generations and unlocks the power of AI to bring the past to life. \n \n \n \n Responsibilities:  \n \n Design, develop, and deploy AI and machine learning models that improve data quality, search relevance, and user engagement on FamilySearch.org.  \n Conduct research and experimentation to identify innovative approaches for leveraging AI technologies in genealogical research.  \n Collaborate with cross-functional teams to understand business requirements and translate them into actionable AI solutions.  \n Build scalable and efficient data pipelines for processing and analyzing large-scale genealogical data.  \n Perform data exploration, feature engineering, and model evaluation to identify optimal solutions for complex problems.  \n Stay up-to-date with the latest advancements in AI and machine learning techniques and proactively explore their potential applications to enhance FamilySearch.org. \n \n \n \n \n Required:  \n Education:  \n \n Bachelor\u2019s degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field.  \n \n Work Experience:  \n \n 8+ years of industry-recognized, progressive, and relevant professional experience \n    \n Significant experience designing, training, testing, and deploying deep learning models in Computer Vision and Natural Language Processing domains. Experience with Speech Recognition is a plus.  \n \n \n Demonstrated Skills & Abilities:  \n \n Solid understanding of deep learning concepts and practices.  \n Solid programming skills in Python on the Linux platform.  \n Solid Java programming skills.  \n Excellent communication skills including the ability to create, communicate, and direct work toward accomplishing an overall technical vision.  \n Demonstrated ability to mentor and train peers.  \n Keen interest in foreign languages, scripts, and historical documents. Fluency in at least one foreign language desired. Candidates must also be eager to dive into unfamiliar languages/scripts and learn enough to get the job done.  \n Excellent data manipulation skills using tools on the Linux platform (grep, sed, awk, NumPy, etc.).  \n Solid command of TensorFlow and/or PyTorch deep learning frameworks.  \n Ability to think about human language structurally.  \n Familiarity with cloud compute environments such as AWS.  \n Track record of self-teaching significant new concepts.  \n Proven ability to work effectively with people of various educational levels and backgrounds. Comfortable conversing with scientists, executives, engineers, and end users alike.  \n Ability to self-direct and work independently for extended periods as required.  \n \n Preferred Qualifications:  \n \n Master\u2019s or PhD in Computer Science or a related field desired.  \n \n #LI-KS1 \n \n \n \n \n  Church employees find joy and satisfaction in using their unique talents and abilities to further the Lord\u2019s work. From the IT professional who develops an app that sends the gospel message worldwide, to the facilities manager who maintains our buildings\u2014 giving Church members places to worship, teach, learn, and receive sacred ordinances\u2014our employees seek innovative ways to share the gospel of Jesus Christ with the world. They are literally working in His kingdom. \n  \n \n  Only members of the Church who are worthy of a temple recommend qualify for employment. Apart from this, the Church is an equal opportunity employer and does not discriminate in its employment decisions on any basis that would violate U.S. or local law. \n  \n \n  Qualified applicants will be considered for employment without regard to race, national origin, color, gender, pregnancy, marital status, age, disability, genetic information, veteran status, or other legally protected categories that apply to the Church. The Church will make reasonable accommodations for qualified individuals with known disabilities.",
        "cleaned_desc": " \n Responsibilities:  \n \n Design, develop, and deploy AI and machine learning models that improve data quality, search relevance, and user engagement on FamilySearch.org.  \n Conduct research and experimentation to identify innovative approaches for leveraging AI technologies in genealogical research.  \n Collaborate with cross-functional teams to understand business requirements and translate them into actionable AI solutions.  \n Build scalable and efficient data pipelines for processing and analyzing large-scale genealogical data.  \n Perform data exploration, feature engineering, and model evaluation to identify optimal solutions for complex problems.  \n Stay up-to-date with the latest advancements in AI and machine learning techniques and proactively explore their potential applications to enhance FamilySearch.org. \n \n \n \n   Required:  \n Education:  \n \n Bachelor\u2019s degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field.  \n \n Work Experience:  \n \n 8+ years of industry-recognized, progressive, and relevant professional experience \n    \n Significant experience designing, training, testing, and deploying deep learning models in Computer Vision and Natural Language Processing domains. Experience with Speech Recognition is a plus.  \n \n \n Demonstrated Skills & Abilities:    \n Solid understanding of deep learning concepts and practices.  \n Solid programming skills in Python on the Linux platform.  \n Solid Java programming skills.  \n Excellent communication skills including the ability to create, communicate, and direct work toward accomplishing an overall technical vision.  \n Demonstrated ability to mentor and train peers.  \n Keen interest in foreign languages, scripts, and historical documents. Fluency in at least one foreign language desired. Candidates must also be eager to dive into unfamiliar languages/scripts and learn enough to get the job done.  \n Excellent data manipulation skills using tools on the Linux platform (grep, sed, awk, NumPy, etc.).  \n Solid command of TensorFlow and/or PyTorch deep learning frameworks.  \n Ability to think about human language structurally.  \n Familiarity with cloud compute environments such as AWS.  \n Track record of self-teaching significant new concepts.  \n Proven ability to work effectively with people of various educational levels and backgrounds. Comfortable conversing with scientists, executives, engineers, and end users alike.  ",
        "techs": [
            "python",
            "linux",
            "java",
            "tensorflow",
            "pytorch",
            "aws"
        ],
        "cleaned_techs": [
            "python",
            "linux",
            "java",
            "tensorflow",
            "pytorch",
            "aws"
        ]
    },
    "5d0efe3958819034": {
        "terms": [
            "data science"
        ],
        "salary_min": 230000.0,
        "salary_max": 325000.0,
        "title": "VP, Head of Accounting",
        "company": "Sears Home Services",
        "desc": "JOB SCOPE: \n  The Head of Accounting is a pivotal leadership role responsible for overseeing all aspects of the accounting function within the organization. Reporting to the Chief Financial Officer (CFO) of Sears Home Services, this role plays a critical role in shaping the financial health and strategic direction of the company. The Head of Accounting leads a team of accounting professionals, driving accuracy, compliance, and efficiency in financial operations\n     \n \n JOB SUMMARY:  \n  The Head of Accounting for Sears Home Services is a leadership role that involves overseeing all aspects of accounting operations while leveraging data science techniques to enhance financial insights, optimize processes, and drive strategic decision-making.\n     \n \n SUPERVISION: \n  Direct:1 - Sr Dir, Corporate Accounting\n     \n \n REPORTS TO: \n  Chief Financial Officer\n    \n \n \n Responsibilities/Skills/Experience Requirements \n \n JOB DUTIES/RESPONSIBILITIES: \n \n  Leads and manages the Sears Home Services accounting department, including financial reporting, general ledger management, accounts payable and receivable, tax compliance, and audits \n  Collaborates with the executive team to develop and implement financial strategies aligned with the company's growth objectives and profitability goals \n  Utilizes data science techniques to analyze financial data, identify trends, and generate actionable insights that inform strategic business decisions \n  Develops accurate financial forecasts and budgets, incorporating data-driven projections to guide resource allocation and investment decisions \n  Identifies opportunities to streamline accounting processes, automate routine tasks, and enhance overall efficiencies using data-driven methodologies \n  Assesses financial risks and implements strategies to mitigate potential vulnerabilities while ensuring compliance with relevant regulations and standards \n  Designs and executes advanced data analytics projects to uncover opportunities for cost savings, revenue growth, and improved operational efficiency \n  Collaborates with other Home Services departments such as Operations, Marketing, and IT to provide financial insights that support their decision-making processes \n  Prepares and presents financial reports, analysis, and recommendations to the executive team and board of directors \n  Mentors, coaches, and develops accounting and data science teams to foster a culture of continuous learning, growth, and excellence \n  Performs supervisory functions, including but not limited to, making employment decisions regarding hiring, promoting, demoting and terminating, conducting performance appraisals and coaching and developing associates \n \n  JOB REQUIREMENTS: \n \n  Bachelors Degree \n  Over 10 years of related experience \n  Up to 25% travel \n  18 years of age or older \n \n  REQUIRED SKILLS: \n \n  Strong background in both accounting principles and data science methodologies \n  Bachelor's degree in Accounting, Finance, Data Science, or a related field \n  Proven track record of at least 10 years in accounting roles, with a minimum of 5 years in a leadership or managerial capacity \n  Strong background in data science, including experience with statistical analysis, machine learning, data visualization, and predictive modeling \n  Proficiency in accounting software and ERP systems & experience with data analysis tools (e.g., Python, R, SQL, Tableau) \n  Exceptional analytical and problem-solving skills, with a demonstrated ability to translate data into strategic insights \n  Excellent communication and presentation abilities, with the capacity to convey complex financial concepts to non-technical stakeholders \n  Strategic mindset with the ability to align financial goals with broader business objectives \n  Strong leadership qualities, including the ability to inspire and motivate cross-functional teams \n  Up-to-date knowledge of accounting standards, regulations, and industry best practices \n \n  PREFERRED SKILLS: \n \n  Master's degree in Accounting, Finance, Data Science, or a related field \n  Experience in the Home Warranty space is strongly preferred \n  CPA (Certified Public Accountant) qualification is strongly preferred \n \n \n \n \n Years Experience \n \n    10 - 15 Years Experience\n    \n \n \n Travel Requirements \n \n    Moderate (15-30%) \n    \n \n \n Country \n \n    United States \n    \n \n \n Work-In Address 1 \n \n    REMOTE\n    \n \n \n Work-In City \n \n    REMOTE\n    \n \n \n Work-In State \n \n    REMOTE\n    \n \n \n Work-In Postal Code \n \n    REMOTE\n    \n \n \n Business \n \n    Transformco Home Services - Support \n    \n \n \n Job Function \n \n    Finance/Accounting \n    \n \n \n Employment Category \n \n    Regular, Full-time \n    \n \n \n Compensation Range \n \n    230k - 325k\n    \n \n \n Additional Compensation Explanation \n \n    N/A \n    \n \n \n EEO/EOE Footer \n \n    Equal Opportunity Employer / Disability / Vet.\n    \n \n \n Posting Tags \n \n    #HSCorporate \n    \n \n \n Company Brand \n \n    Sears Home Services \n    \n \n \n Location City \n \n    Hoffman Estates",
        "cleaned_desc": "  Mentors, coaches, and develops accounting and data science teams to foster a culture of continuous learning, growth, and excellence \n  Performs supervisory functions, including but not limited to, making employment decisions regarding hiring, promoting, demoting and terminating, conducting performance appraisals and coaching and developing associates \n \n  JOB REQUIREMENTS: \n \n  Bachelors Degree \n  Over 10 years of related experience \n  Up to 25% travel \n  18 years of age or older \n \n  REQUIRED SKILLS: \n \n  Strong background in both accounting principles and data science methodologies \n  Bachelor's degree in Accounting, Finance, Data Science, or a related field \n  Proven track record of at least 10 years in accounting roles, with a minimum of 5 years in a leadership or managerial capacity \n  Strong background in data science, including experience with statistical analysis, machine learning, data visualization, and predictive modeling \n  Proficiency in accounting software and ERP systems & experience with data analysis tools (e.g., Python, R, SQL, Tableau) \n  Exceptional analytical and problem-solving skills, with a demonstrated ability to translate data into strategic insights \n  Excellent communication and presentation abilities, with the capacity to convey complex financial concepts to non-technical stakeholders \n  Strategic mindset with the ability to align financial goals with broader business objectives \n  Strong leadership qualities, including the ability to inspire and motivate cross-functional teams \n  Up-to-date knowledge of accounting standards, regulations, and industry best practices \n \n  PREFERRED SKILLS: \n \n  Master's degree in Accounting, Finance, Data Science, or a related field \n  Experience in the Home Warranty space is strongly preferred \n  CPA (Certified Public Accountant) qualification is strongly preferred \n \n ",
        "techs": [
            "coaches",
            "data science teams",
            "continuous learning",
            "growth",
            "excellence",
            "employment decisions",
            "performance appraisals",
            "coaching",
            "developing associates",
            "bachelors degree",
            "10 years of related experience",
            "25% travel",
            "18 years of age or older",
            "accounting principles",
            "data science methodologies",
            "bachelor's degree in accounting",
            "finance",
            "data science",
            "related field",
            "10 years in accounting roles",
            "leadership or managerial capacity",
            "statistical analysis",
            "machine learning",
            "data visualization",
            "predictive modeling",
            "accounting software",
            "erp systems",
            "data analysis tools (python",
            "r",
            "sql",
            "tableau)",
            "analytical skills",
            "problem-solving skills",
            "data into strategic insights",
            "communication abilities",
            "presentation abilities",
            "financial concepts",
            "strategic mindset",
            "financial goals",
            "business objectives",
            "leadership qualities",
            "cross-functional teams",
            "accounting standards",
            "regulations",
            "industry best practices",
            "master's degree in accounting",
            "finance",
            "data science",
            "related field",
            "home warranty space",
            "cpa qualification"
        ],
        "cleaned_techs": [
            "coaches",
            "data science teams",
            "continuous learning",
            "growth",
            "excellence",
            "employment decisions",
            "performance appraisals",
            "coaching",
            "developing associates",
            "10 years of related experience",
            "25% travel",
            "18 years of age or older",
            "accounting principles",
            "data science methodologies",
            "finance",
            "data science",
            "related field",
            "10 years in accounting roles",
            "leadership or managerial capacity",
            "statistical analysis",
            "data visualization",
            "predictive modeling",
            "accounting software",
            "erp systems",
            "data analysis tools (python",
            "r",
            "sql",
            "tableau)",
            "data into strategic insights",
            "communication abilities",
            "presentation abilities",
            "financial concepts",
            "strategic mindset",
            "financial goals",
            "business objectives",
            "leadership qualities",
            "cross-functional teams",
            "accounting standards",
            "regulations",
            "home warranty space",
            "cpa qualification"
        ]
    },
    "60677b735b935e09": {
        "terms": [
            "data science"
        ],
        "salary_min": 110441.57,
        "salary_max": 139843.64,
        "title": "Senior RWE/SAS Programmer",
        "company": "PHASTAR",
        "desc": "Overview: \n   THE COMPANY \n \n  Phastar is a multiple award-winning global biometric Contract Research Organization (CRO) that is accredited as an outstanding company to work for by Best Companies. We partner with pharmaceutical, biotechnology and medical device organizations to provide the expertise and processes to manage and deliver on time, quality biostatistics, programming, data management and data science services. With offices across the UK, US, Germany, Denmark, Kenya, Australia, India, China and Japan, Phastar is the second largest specialized biometrics provider globally, and the largest in the UK. \n \n  Our unique approach to data analysis, \u201cThe Phastar Discipline\u201d, has led us to build a reputation for outstanding quality. With this as our core focus, we\u2019re looking for talented individuals who share our passion for quality and technical expertise to join our team. \n \n  WHY PHASTAR \n \n  Accredited as an outstanding company to work for, Phastar is committed to employee engagement, workplace satisfaction and ensuring a healthy work-life balance. We offer flexible working, part-time hours, involvement in developing company-wide initiatives, structured training and development plans, and a truly supportive, fun and friendly environment. \n \n  What\u2019s more, when you join our team, Phastar will plant a tree in your honour, as one of our Environmental, Social and Governance (ESG) initiatives. So, not only would you get your dream job, you\u2019ll also be helping to save the planet! \n \n  THE ROLE \n \n  Demand for our Functional Service Provision is growing, therefore we are looking for a passionate and driven Senior RWE/SAS Programmer to join our FSP team to support one of our reputable pharmaceutical clients. \n \n  The successful candidate should have 5+ years of experience within clinical trial programming, must have publication programming/reporting experience and have experience in programming efficacy analyses, such as efficacy endpoints and possibly multiple imputation techniques. \n \n  As a Senior RWE/SAS Programmer on clinical and non-clinical trials; the successful candidate will be responsible for producing complex datasets and outputs to excellent quality whilst adhering to deliverable timelines. They should have a good knowledge of CDISC SDTM and ADaM implementation guidelines; producing, reviewing and updating complex data specifications; creating and debugging complex macros; understanding Statistical Analysis Plans (SAPs) and output shells for day-to-day programming activities. The ideal candidate will have an excellent teamwork ethos, willingness to help others and learn new skills from working in a team environment. \n \n  This is a fantastic opportunity to work for a growing CRO that is recognized for its continuous learning and development opportunities, whilst also gaining direct experience of working within a pharmaceutical environment.  Responsibilities: \n  \n Program and validate datasets and SDTMs, including complex efficacy, labs, etc. \n  Program complex non efficacy outputs/figures \n  Perform Senior Review and Deliver QC of non- statistical output \n  Develop and debug complex macros \n  Become involved in developing the standard macro library and take responsibility to implement standard macros within a study \n  Create, QC and update complex dataset specifications (including efficacy) for single/ multiple studies, ISS/ISEs, etc. \n  Review more complex study design SAP without supervision \n  Review all shells without supervision and provide feedback \n  Knowledge, interpretation and implementation of current SDTM, ADAM standards \n  Knowledge of FDA CRT requirements including define.xml and define.pdf \n  Lead team and be responsible for creation of CRT packages \n  Become familiar with and follow study documentation \n  Lead a team for furthering programming development \n  Ensure the principles in the PHASTAR checklist are followed rigorously \n  Archive study documentation following instructions in supplied SOPs \n  Act as a Lead programmer on multiple studies under same project, ensuring quality and timely delivery \n  Liaise with Study Statistician and Project Manager regarding resourcing and deliverables \n  Responsible for study level resources \n  Attend and input to company resourcing meeting \n  Point of contact for programming issues for the team, proactively ensuring everything is working cohesively \n  Persuade stakeholders to follow best practice within a trial \n  Develop and deliver company-wide training as and when required \n  Create, review and update processes and SOPs \n  Take responsibility for study compliance with SOPs and processes \n  Qualifications: \n  \n BSc or above in Computer Science, Mathematics or a Science related discipline \n  SAS Programming experience within a clinical trials environment (CRO, pharma or academia) \n  Experience of programming to SDTM and ADaM standards (CDISC) \n  Good awareness of clinical trial issues, design, and implementation \n  Familiarity with GCP and regulatory requirements \n  Excellent written and verbal communication skills \n \n \n  APPLY NOW \n \n  With the world\u2019s eyes focused on clinical trial data, this is a fantastic time to join an award-winning specialized biometric CRO that is renowned for its technical expertise, outstanding quality and cutting-edge data science techniques. We offer flexible working, part-time hours, structured training and development plans, continuous learning opportunities, and a competitive salary and benefits package. We\u2019re committed to ensuring our employees achieve a healthy work-life balance, within a supportive, fun and friendly working environment. \n \n  Should you feel that you have the right skill set and motivations for this position, please apply! Please note that we are considering candidates located anywhere in the US or Canada as this role can be carried out remotely. \n \n  Phastar is committed to the principles and practices of equal opportunities and to encouraging the establishment of a diverse workforce. It is our policy to employ individuals on the basis of their suitability for the work to be performed and their potential for development, regardless of age, sex, race, colour, nationality, ethnic or national origin, disability, marital status, pregnancy or maternity, sexual orientation, gender reassignment, religion, or belief. This includes creating a culture that fully reflects our commitment to equal opportunities for all. \n \n  Important notice to Employment businesses/ Agencies \n \n  Phastar does not accept referrals from employment businesses and/or employment agencies in respect of the vacancies posted on this site. All employment businesses/agencies are required to contact Phastar's Head of Talent Acquisition to obtain prior written authorization before referring any candidates to Phastar. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business/ agency and Phastar. In the absence of such written authorization being obtained any actions undertaken by the employment business/agency shall be deemed to have been performed without the consent or contractual agreement of Phastar. Phastar shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses/agencies in respect of the vacancies posted on this site.",
        "cleaned_desc": "  THE ROLE \n \n  Demand for our Functional Service Provision is growing, therefore we are looking for a passionate and driven Senior RWE/SAS Programmer to join our FSP team to support one of our reputable pharmaceutical clients. \n \n  The successful candidate should have 5+ years of experience within clinical trial programming, must have publication programming/reporting experience and have experience in programming efficacy analyses, such as efficacy endpoints and possibly multiple imputation techniques. \n \n  As a Senior RWE/SAS Programmer on clinical and non-clinical trials; the successful candidate will be responsible for producing complex datasets and outputs to excellent quality whilst adhering to deliverable timelines. They should have a good knowledge of CDISC SDTM and ADaM implementation guidelines; producing, reviewing and updating complex data specifications; creating and debugging complex macros; understanding Statistical Analysis Plans (SAPs) and output shells for day-to-day programming activities. The ideal candidate will have an excellent teamwork ethos, willingness to help others and learn new skills from working in a team environment. \n \n  This is a fantastic opportunity to work for a growing CRO that is recognized for its continuous learning and development opportunities, whilst also gaining direct experience of working within a pharmaceutical environment.  Responsibilities: \n  \n Program and validate datasets and SDTMs, including complex efficacy, labs, etc. \n  Program complex non efficacy outputs/figures \n  Perform Senior Review and Deliver QC of non- statistical output ",
        "techs": [
            "sas programmer",
            "cdisc sdtm",
            "adam implementation guidelines",
            "macros",
            "statistical analysis plans (saps)",
            "cro"
        ],
        "cleaned_techs": [
            "sas",
            "cdisc sdtm",
            "adam implementation guidelines",
            "macros",
            "statistical analysis plans (saps)",
            "cro"
        ]
    },
    "75e755a8e43ed743": {
        "terms": [
            "data science"
        ],
        "salary_min": 88150.29,
        "salary_max": 111617.914,
        "title": "VP Business Planning - Provider - Remote",
        "company": "Sharecare",
        "desc": "Job Description:\n  \n \n   Sharecare is the leading digital health company that helps people \u2013 no matter where they are in their health journey \u2013 unify and manage all their health in one place. Our comprehensive and data-driven virtual health platform is designed to help people, providers, employers, health plans, government organizations, and communities optimize individual and population-wide well-being by driving positive behavior change. Driven by our philosophy that we are all together better, at Sharecare, we are committed to supporting each individual through the lens of their personal health and making high-quality care more accessible and affordable for everyone. To learn more, visit \n   \n   www.sharecare.com\n   .\n  \n \n \n   Job Summary:\n  \n \n \n   As the Vice President of Business Planning for the Health Insights and Data Solutions (HIDS) and Carelinx Business Units at Sharecare, reporting directly to the SVP and General Manager, you will play a pivotal role in orchestrating workforce management and operational excellence opportunities.\n   \n  You will collaborate with Senior Vice Presidents and leaders at Sharecare to ensure efficient resource deployment, guide strategic planning, and offer data-driven insights to shape the future strategy of the Business Unit.\n  \n \n \n   Essential Job Functions:\n  \n \n \n \n     Team Leadership: Build, Lead, and oversee the Workforce Management team within the HIDS Business Unit.\n    \n \n \n     Strategic Planning: Develop and implement strategic business planning and workflow models that support both short and long-term hiring plans at macro and team/process levels.\n    \n \n \n     Workflow Optimization: Collaborate with operations leadership to develop and refine comprehensive workflows, ensuring efficiency.\n    \n \n \n     Resource Allocation: Partner with department heads to allocate resources effectively, aligning projects with strategic priorities.\n    \n \n \n     Footprint Optimization: Work closely with operations leadership to ensure a clear understanding of footprint optimization and resource migration plans.\n    \n \n \n     Technology Integration: Collaborate with operations and IT teams to deploy new capabilities aimed at automating and enhancing productivity across payer services functions.\n    \n \n \n     Innovation: Drive innovation in analytical solutions to optimize performance against established KPIs.\n    \n \n \n     System Enhancements: Coordinate with IT and Operations teams to identify and prioritize system enhancements aligned with productivity initiatives.\n    \n \n \n     Scheduling Solutions: Introduce new scheduling capabilities for retrieval channel distribution.\n    \n \n \n     Data Analysis: Analyze progressive and adverse trends, proposing data-driven solutions.\n    \n \n \n     Measurement Strategies: Develop robust measurement strategies to assess the impact of process enhancements.\n    \n \n \n     Continuous Improvement: Scrutinize performance trends to uncover opportunities for continual improvement.\n    \n \n \n     Best Practices: Instill leading best practices and utilize advanced tools to streamline business operations S&OP processes across various departments.\n    \n \n \n     Workflow Management: Oversee operational workflow distribution and resolve arising issues to meet production objectives.\n    \n \n \n \n   Specific Skills/Attributes:\n  \n \n \n \n     Innovative Problem Solver: Recognized as an outstanding creator and initiator of solutions, with proficient operational and optimization capabilities.\n    \n \n \n     Operational Expertise: Immersed in operations, possessing in-depth familiarity with workflows across various business areas and the ability to transform data and processes.\n    \n \n \n     Stakeholder Focus: Attuned to the needs, challenges, and insights of stakeholders, skilled at transforming these elements into innovative solutions and procedural enhancements.\n    \n \n \n     Effective Leader: Exceptional leadership skills, with a unique flair for coaching and influencing diverse functional teams.\n    \n \n \n     Communication Excellence: A world-class communicator who can articulate compelling business propositions through conversations and presentations.\n    \n \n \n     Relationship Management: Exemplary relationship management capabilities, emphasizing engagement, motivation, communication, and execution.\n    \n \n \n     Emotional Intelligence: High emotional intelligence, excelling in conflict resolution and unifying divergent goals.\n    \n \n \n     Collaborative Approach: Embraces a collaborative approach, values humility, and prioritizes organizational partnership.\n    \n \n \n     Collective Focus: Prefers collective achievements over individual accolades.\n    \n \n \n     Strategic Thinker: Pragmatic and clear thinker capable of simplifying complex scenarios into actionable opportunities.\n    \n \n \n     Analytical Prowess: Demonstrated achievements reflect capabilities in large-scale analytical planning paired with technical prowess, ideally within engineering, statistics, or data science.\n    \n \n \n     Business Acumen: Proven proficiency in business planning, process management, improvement, and transformation.\n    \n \n \n \n   Qualifications:\n  \n \n \n \n     Minimum of 5 years experience as a member of a senior operational leadership team with enterprise-level accountabilities.\n    \n \n \n     Minimum of 10 years experience in healthcare information technology and services.\n    \n \n \n     Bachelor\u2019s degree, Graduate Level education preferred.\n    \n \n \n \n   Sharecare and its subsidiaries are Equal Opportunity Employers and E-Verify users. Qualified applicants will receive consideration for employment without regard to race, color, sex, national origin, sexual orientation, gender identity, religion, age, equal pay, disability, genetic information, protected veteran status, or other status protected under applicable law.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "69c6cc499a9fe183": {
        "terms": [
            "data science"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Sr Workday Reporting Analyst",
        "company": "Teladoc Health",
        "desc": "Teladoc Health is a global, whole person care company made up of a diverse community of people dedicated to transforming the healthcare experience. As an employee, you\u2019re empowered to show up every day as your most authentic self and be a part of something bigger \u2013 thriving both personally and professionally. Together, let\u2019s empower people everywhere to live their healthiest lives.  \n \n Sr Workday Reporting Analyst  : This position is located in Poland.  \n \n The Senior Workday Reporting Analyst utilizes HR and people data to create reports, metrics, dashboards, data sources, and visualizations, allowing end users to make informed business decisions backed by data. As a Workday Reporting/Prism Analyst, you\u2019ll be part of our People Data and Analytics team.  \n \n Core Responsibilities:  \n Report Development and Maintenance:  \n \n Design, develop, test, deploy, and maintain custom Workday reports, dashboards, and data sources.  \n Build and maintain custom reporting structures, including calculated fields and BIRT reporting.  \n Ensure data accuracy and consistency in all generated reports.  \n Analyze complex data sets, identify trends and patterns, and create appealing visualizations for effective communication.  \n \n \n Stakeholder Collaboration:  \n \n Collaborate with cross-functional teams to gather data requirements and align reporting solutions with business goals.  \n Support, research, resolve reporting issues, and assist in training initiatives.  \n Partner with extended teams to ensure data, calculations, and security consistency across all reporting platforms.  \n \n \n Training and Documentation:  \n \n Document business requirements and convert them into report design documentation.  \n Develop training materials and conduct training sessions for end-users.  \n Create and maintain comprehensive documentation for reporting processes, configuration, and data models.  \n \n \n Compliance and Security:  \n \n Ensure compliance with data privacy regulations and organizational data security policies in all reporting activities.  \n Implement and maintain proper access controls and permissions to safeguard sensitive data.  \n Perform reporting audits to ensure accuracy and compliance.  \n \n \n System Optimization and Enhancement:  \n \n Act as the lead subject matter expert (SME) on People Analytics Module implementation.  \n Continuously improve report performance and efficiency by optimizing existing reporting solutions.  \n Propose enhancements to Workday systems and reporting processes to streamline operations and enhance user experience.  \n \n \n Qualifications:  \n Our Senior Workday Reporting Analyst should possess a blend of technical expertise, analytical thinking, effective communication, and collaboration skills to succeed in this role and drive impactful reporting solutions for the organization, including:  \n Workday Experience:  \n \n 5+ years of relevant experience as a Workday report developer.  \n Strong understanding of Workday data models, data sources, and report-building capabilities.  \n Experience in Workday report development using EIB, BIRT, and Workday Studio.  \n Experience in various Workday report types and calculated fields.  \n \n \n Knowledge and Skills:  \n \n In-depth knowledge of Workday reporting capabilities and data architecture.  \n Experience in multiple areas such as Recruiting, Onboarding, Core HCM, Absence Management, Compensation, etc.  \n Workday Reporting Certification is a plus.  \n Data visualization and dashboard design experience (e.g., Prism, Tableau, Power BI).  \n Proficiency in SQL, XML, and relevant programming languages for data manipulation and reporting is a plus.  \n Prototyping and testing experience.  \n \n \n Communication and Adaptability:  \n \n Outstanding communication skills, both technical and non-technical.  \n Demonstrated consulting, presentation skills, and ability to influence.  \n Ability to adapt to changing technologies, tools, and reporting requirements within the Workday ecosystem.  \n \n \n Time Management and Analytical Skills:  \n \n Effective time management and prioritization skills to meet deadlines and manage multiple projects.  \n Ability to identify issues and troubleshoot problems in reporting and data analysis effectively.  \n Analytical mindset to produce business insights and data-driven recommendations.  \n \n Education:  \n \n Bachelor\u2019s degree in computer science, MIS, Computer Engineering, or related discipline. Relevant experience may be considered instead of a degree.  \n \n \n Why Join Teladoc Health?   \n  A New Category in Healthcare: Teladoc Health is transforming the healthcare experience and empowering people everywhere to live healthier lives.     Our Work Truly Matters: Recognized as the world leader in whole-person virtual care, Teladoc Health uses proprietary health signals and personalized interactions to drive better health outcomes across the full continuum of care, at every stage in a person\u2019s health journey.     Make an Impact: In more than 175 countries and ranked Best in KLAS for Virtual Care Platforms in 2020, Teladoc Health leverages more than a decade of expertise and data-driven insights to meet the growing virtual care needs of consumers and healthcare professionals.     Focus on PEOPLE: Teladoc Health has been recognized as a top employer by numerous media and professional organizations. Talented, passionate individuals make the difference, in this fast-moving, collaborative, and inspiring environment.     Diversity and Inclusion: At Teladoc Health we believe that personal and professional diversity is the key to innovation. We hire based solely on your strengths and qualifications, and the way in which those strengths can directly contribute to your success in your new position.     Growth and Innovation: We\u2019ve already made healthcare yet remain on the threshold of very big things. Come grow with us and support our mission to make a tangible difference in the lives of our Members.   \n \n As an Equal Opportunity Employer, we never have and never will discriminate against any job candidate or employee due to age, race, religion, color, ethnicity, national origin, gender, gender identity/expression, sexual orientation, membership in an employee organization, medical condition, family history, genetic information, veteran status, marital status, parental status or pregnancy.",
        "cleaned_desc": " Strong understanding of Workday data models, data sources, and report-building capabilities.  \n Experience in Workday report development using EIB, BIRT, and Workday Studio.  \n Experience in various Workday report types and calculated fields.  \n \n \n Knowledge and Skills:  \n \n In-depth knowledge of Workday reporting capabilities and data architecture.  \n Experience in multiple areas such as Recruiting, Onboarding, Core HCM, Absence Management, Compensation, etc.  \n Workday Reporting Certification is a plus.  \n Data visualization and dashboard design experience (e.g., Prism, Tableau, Power BI).  \n Proficiency in SQL, XML, and relevant programming languages for data manipulation and reporting is a plus.  \n Prototyping and testing experience.  \n \n \n Communication and Adaptability:    \n Outstanding communication skills, both technical and non-technical.  \n Demonstrated consulting, presentation skills, and ability to influence.  \n Ability to adapt to changing technologies, tools, and reporting requirements within the Workday ecosystem.  \n \n \n Time Management and Analytical Skills:  \n \n Effective time management and prioritization skills to meet deadlines and manage multiple projects.  \n Ability to identify issues and troubleshoot problems in reporting and data analysis effectively.  \n Analytical mindset to produce business insights and data-driven recommendations.  \n \n Education:  \n \n Bachelor\u2019s degree in computer science, MIS, Computer Engineering, or related discipline. Relevant experience may be considered instead of a degree.  \n ",
        "techs": [
            "workday",
            "eib",
            "birt",
            "workday studio",
            "prism",
            "tableau",
            "power bi",
            "sql",
            "xml"
        ],
        "cleaned_techs": [
            "workday",
            "eib",
            "birt",
            "workday studio",
            "prism",
            "tableau",
            "powerbi",
            "sql",
            "xml"
        ]
    },
    "82eaa85fcaf28fa0": {
        "terms": [
            "data science"
        ],
        "salary_min": 139000.0,
        "salary_max": 174000.0,
        "title": "Lead Analytics Engineer",
        "company": "iController",
        "desc": "What You'll Do: \n  As the Lead Analytics Engineer, you will be responsible for aggregating all data across the enterprise, managing that data, and leveraging it to service internal teams and external clients to provide insights and make better business decisions. You will utilize your passion for data to evolve our efforts for ETL processes, data warehousing, and data movement. You will work closely with and learn from other data professionals skilled in BI, data science, and data warehousing. \n \n \n Source system recommendations related to the creation of insights or adjustments to a data warehouse or mart structures \n Write SQL for reports and data aggregation \n Research gaps within data and develop opportunities for improving the upstream systems/processes \n Manage identified issues through data interpretation and analysis \n Constructs and performs testing of data processes for compliance and data quality \n Assist in identifying and designing attributes for ETL processes \n Contribute to ensuring security is a priority of data movement \n Examine complex data and turn it into information and insight to inform business decisions \n Produce BI dashboards for internal departments \n Build internal and external BI and operational reports for multiple stakeholder groups \n Plans, designs, develops and performs quality assessments on data elements and structures to document and evaluate integrity, completeness, and quality \n Translate business needs into technical data solutions \n Other duties as assigned \n \n What You'll Bring to the Team: \n \n 7+ years of relevant analytics experience \n Excellent problem-solving skills around data access and structured data \n A demonstrated understanding of data engineering and data aggregation \n Experience leveraging commercial ETL tools like SSIS or similar, or creating jobs in Python or similar \n Strong understanding of SQL, relational data, and non-relational data \n Ability to leverage data visualization tools, such as PowerBI or Looker \n Experience with Modern Data Stack tools like Fivetran, dbt, and similar \n Strong understanding of data models and ability to enhance metadata for data models \n Experience with some of the following is a nice-to-have: SQL Server, MySQL, MongoDB, DynamoDB, AWS, Azure, Redshift, Snowflake \n Understanding of Agile, Scrum and Kanban techniques nice-to-have \n Ability to collaborate cross-functionally, and work well in a distributed, team-oriented environment \n Experience in a SaaS, software, product-centric or payments business nice-to-have \n An attitude where no technical challenge is too great \n Bachelor degree in Computer Science, Data Analytics or related discipline (or equivalent experience) \n \n Base Compensation: $139,000.00 - $174,000.00 + (bonus offered in addition to base compensation)  Please note that the compensation information is a good faith estimate and is provided pursuant to Equal Pay Laws. Billtrust intends to offer the selected candidate base pay dependent on job-related, non-discriminatory factors such as experience. Our Talent Acquisition team will provide more information about the total compensation package for this position during the interview process. \n \n Don't meet every single requirement? Studies have shown that women and people of color are less likely to apply to jobs unless they meet every single qualification. At Billtrust, we celebrate and support diversity and are committed to creating an inclusive environment for all employees. So, if your experience aligns but doesn't exactly match each and every qualification, apply anyway. You may be exactly what we are looking for! \n What You'll Get: \n \n Work from Anywhere:  Our state of the art office, your home, a company paid WeWork.... you decide! \n A Culture that Lives its Values:  Our values are not just words or window dressing, they guide our decisions - big and small - each and every day. \n Flexible   Working Hours : We support your lifestyle- the results are what count. \n Open PTO:  Work-life balance is important. We believe in giving our employees time to truly relax and recharge. \n Sabbatical:  A paid leave to reward longevity and commitment to Billtrust. \n Paid Parental Leave:  To promote parent-child bonding and increase gender equity at home and in the workplace. \n Opportunities for Growth:  Professional development can take many shapes. Join one of our seven ERGs or participate in our Mentor-Mentee, Leadership, and High-Potential Programs- we foster an environment where all employees can grow. \n Recognition:  From Billtrust Bucks and Gongings to Culture Champion and Founders Awards, our employees are recognized for hard work and outcomes achieved. \n Benefits:  Medical, dental, vision, 401(k) with company match, short-term and long-term disability, flexible spending accounts, HSA, and life, cancer, and AD&D insurance. \n Minimal Bureaucracy:  An entrepreneurial environment of ownership and accountability allows you to get work done. \n \n Who We Are: \n  Billtrust is a leading provider of cloud-based software and integrated payment processing solutions that simplify and automate B2B commerce. Accounts receivable is broken and relies on conventional processes that are outdated, inefficient, manual and largely paper based. Billtrust is at the forefront of the digital transformation of AR, providing mission-critical solutions that span credit decisioning and monitoring, online ordering, invoice delivery, payments and remittance capture, invoicing, cash application and collections. Our platform has processed $1 trillion+ invoice dollars and we have seen 28% year-over-year software & payments revenue growth (2021). With more than 2,400 customers, we have helped companies like GlobalTranz, United Rentals, Acushnet and Ferguson Enterprises get paid faster and more efficiently. \n  For more than 20 years, we have achieved remarkable success and we attribute our growth to our people and culture. We encourage employees to have autonomy, think creatively, share ideas - even with our CEO - and to challenge the status quo every day.#LI-Remote",
        "cleaned_desc": "What You'll Do: \n  As the Lead Analytics Engineer, you will be responsible for aggregating all data across the enterprise, managing that data, and leveraging it to service internal teams and external clients to provide insights and make better business decisions. You will utilize your passion for data to evolve our efforts for ETL processes, data warehousing, and data movement. You will work closely with and learn from other data professionals skilled in BI, data science, and data warehousing. \n \n \n Source system recommendations related to the creation of insights or adjustments to a data warehouse or mart structures \n Write SQL for reports and data aggregation \n Research gaps within data and develop opportunities for improving the upstream systems/processes \n Manage identified issues through data interpretation and analysis \n Constructs and performs testing of data processes for compliance and data quality \n Assist in identifying and designing attributes for ETL processes   7+ years of relevant analytics experience \n Excellent problem-solving skills around data access and structured data \n A demonstrated understanding of data engineering and data aggregation \n Experience leveraging commercial ETL tools like SSIS or similar, or creating jobs in Python or similar \n Strong understanding of SQL, relational data, and non-relational data \n Ability to leverage data visualization tools, such as PowerBI or Looker \n Experience with Modern Data Stack tools like Fivetran, dbt, and similar \n Strong understanding of data models and ability to enhance metadata for data models \n Experience with some of the following is a nice-to-have: SQL Server, MySQL, MongoDB, DynamoDB, AWS, Azure, Redshift, Snowflake \n Understanding of Agile, Scrum and Kanban techniques nice-to-have ",
        "techs": [
            "ssis",
            "python",
            "powerbi",
            "looker",
            "fivetran",
            "dbt",
            "sql server",
            "mysql",
            "mongodb",
            "dynamodb",
            "aws",
            "azure",
            "redshift",
            "snowflake"
        ],
        "cleaned_techs": [
            "ssis",
            "python",
            "powerbi",
            "looker",
            "fivetran",
            "dbt",
            "sql",
            "mysql",
            "mongodb",
            "dynamodb",
            "aws",
            "azure",
            "redshift",
            "snowflake"
        ]
    },
    "5e7450e7286e3db9": {
        "terms": [
            "data science"
        ],
        "salary_min": 106200.0,
        "salary_max": 242000.0,
        "title": "Data Scientist, Lead",
        "company": "Booz Allen Hamilton",
        "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Bethesda,MD,US \n         \n \n \n \n         Remote Work: \n         \n \n         Yes \n         \n \n \n \n         Job Number: \n         \n \n         R0182465\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Data Scientist, Lead\n           The Opportunity: \n  As a data scientist, you\u2019re excited at the prospect of unlocking the secrets held by a data set, and you\u2019re fascinated by the possibilities presented by IoT, machine learning, and artificial intelligence. In an increasingly connected world, massive amounts of structured and unstructured data open new opportunities. As a data scientist at Booz Allen, you can turn these complex data sets into useful information to solve global challenges. Across private and public sectors\u2014from fraud detection to cancer research to national intelligence\u2014we need a seasoned data scientist like you to help find the answers in the data. \n \n  On our team, you\u2019ll use your leadership skills and data science expertise to create real-world impact. You\u2019ll work closely with clients to understand their questions and needs, and then dig into their data-rich environments to find the pieces of their information puzzle. You\u2019ll guide and mentor your team as you oversee the development of algorithms and systems. You\u2019ll use the right combination of tools and frameworks to turn sets of disparate data points into objective answers to advise your clients as they make informed decisions. As a technical leader, you\u2019ll identify new opportunities to use data science solutions to help your clients meet their toughest challenges. Ultimately, you\u2019ll provide a deep understanding of the data, what it all means, and how it can be used. \n \n  Work with us as we use data science for good. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  8+ years of experience with data exploration, data cleaning, data analysis, data visualization, or data mining \n  8+ years of experience with statistical and general-purpose programming languages for data analysis \n  8+ years of experience with analyzing structured and unstructured data sources \n  Experience with developing predictive data models, quantitative analyses, and visualization of targeted data sources \n  Experience with leading a team, including projects and deliverables \n  Experience with leading the development of solutions to complex programs \n  Experience with natural language processing, text mining, or machine learning techniques \n  Bachelor\u2019s degree \n \n \n  Nice If You Have: \n \n  Experience with the development of algorithms leveraging Java, R, Python, or SQL/NoSQL \n  Experience with distributed data and computing tools, including MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL \n  Experience with Machine Learning, AI, or NLP \n  Experience with visualization packages, including Plotly, Seaborn, or ggplot2 \n \n \n  Create Your Career: \n \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll develop your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $106,200.00 to $242,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law. \n  #LI-Remote",
        "cleaned_desc": "  8+ years of experience with statistical and general-purpose programming languages for data analysis \n  8+ years of experience with analyzing structured and unstructured data sources \n  Experience with developing predictive data models, quantitative analyses, and visualization of targeted data sources \n  Experience with leading a team, including projects and deliverables \n  Experience with leading the development of solutions to complex programs \n  Experience with natural language processing, text mining, or machine learning techniques \n  Bachelor\u2019s degree \n \n \n  Nice If You Have: \n \n  Experience with the development of algorithms leveraging Java, R, Python, or SQL/NoSQL \n  Experience with distributed data and computing tools, including MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL \n  Experience with Machine Learning, AI, or NLP \n  Experience with visualization packages, including Plotly, Seaborn, or ggplot2 \n \n \n  Create Your Career: \n \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. ",
        "techs": [
            "statistical programming languages",
            "general-purpose programming languages",
            "data analysis",
            "structured data",
            "unstructured data",
            "predictive data models",
            "quantitative analysis",
            "visualization",
            "leading a team",
            "natural language processing",
            "text mining",
            "machine learning techniques",
            "algorithms",
            "java",
            "r",
            "python",
            "sql/nosql",
            "distributed data",
            "computing tools",
            "mapreduce",
            "hadoop",
            "hive",
            "emr",
            "kafka",
            "spark",
            "gurobi",
            "mysql",
            "machine learning",
            "ai",
            "nlp",
            "visualization packages",
            "plotly",
            "seaborn",
            "ggplot2",
            "professional development",
            "leadership development",
            "upskilling programs",
            "tuition reimbursement",
            "mentoring",
            "firm-sponsored networking."
        ],
        "cleaned_techs": [
            "statistical programming languages",
            "general-purpose programming languages",
            "structured data",
            "unstructured data",
            "predictive data models",
            "quantitative analysis",
            "visualization",
            "leading a team",
            "nlp",
            "text mining",
            "machine learning techniques",
            "algorithms",
            "java",
            "r",
            "python",
            "sql",
            "distributed data",
            "computing tools",
            "mapreduce",
            "hadoop",
            "hive",
            "emr",
            "kafka",
            "spark",
            "gurobi",
            "mysql",
            "ai",
            "visualization packages",
            "plotly",
            "seaborn",
            "ggplot2",
            "professional development",
            "leadership development",
            "upskilling programs",
            "tuition reimbursement",
            "mentoring",
            "firm-sponsored networking."
        ]
    },
    "4cd0e662ce4a93fe": {
        "terms": [
            "data science"
        ],
        "salary_min": 118362.0,
        "salary_max": 177948.0,
        "title": "Lead Google Analytics Software Engineer - Remote",
        "company": "Caterpillar",
        "desc": "Career Area:  Digital \n  Job Description:  \n Your Work Shapes the World at Caterpillar Inc.  \n When you join Caterpillar, you're joining a global team who cares not just about the work we do \u2013 but also about each other. We are the makers, problem solvers, and future world builders who are creating stronger, more sustainable communities. We don't just talk about progress and innovation here \u2013 we make it happen, with our customers, where we work and live. Together, we are building a better world, so we can all enjoy living in it.  \n At Caterpillar, we\u2019re delighted to be making a significant investment in our team that focuses on Google Analytics implementation and reporting capabilities. We have an exciting and challenging opportunity for a Lead Software Engineer. The Lead Software Engineer provides technical leadership in solution development, implementation, and support for Caterpillar\u2019s Google Marketing & Analytics Platforms. This position will implement world class capabilities to support a wide range of digital applications while delivering against the common department goals in line with CAT Digital Strategy.      JOB DUTIES:   \n \n  This role is responsible for delivering Google oversight, solution design, implementation, reporting, dashboards, and insights in support of Caterpillar\u2019s digital strategy. The mandate includes partnering with digital channel owners as well as internal data science, customer service, marketing, legal and technology teams to ensure the organization understands and can act on insights derived from our customers\u2019 on-site digital behavior. \n    Additional responsibilities include training the organization on the access and use of digital analytics data, supporting campaign tracking & a/b testing. In support of these goals, this role will team lead and train a small team of talented digital analysts and implementation specialists. Other responsibilities include: \n   \n  1. Conduct reporting and analyses on all 500+ digital properties to provide data to drive decisions that will enhance user experiences, optimize campaign performance, and provide recommendations to the organization in relation to the behavioral data for each property. \n    2. Work with Product Owners, Stakeholders, Designers, and Developers to implement measurement plans that enable future reporting and analysis. \n    3. Oversee, create, and automate tools and dashboards to effectively manage requests from stakeholders with varying levels of technical capability. \n    4. Foster a team with high levels of relevant skills (analytics, story-telling, data visualization, etc.) and knowledge (an understanding of tagging, marketing technologies and methods, quantitative and qualitative research methods) \n    5. QA and troubleshoot, data collection on digital properties using JavaScript and the developer console \n    6. Document reporting and implementation requirements to meet business and site reporting plans \n   \n  The position manages the completion of its own work assignments and coordinates work with others. Based on past experiences and knowledge, the incumbent normally works within a team environment, with minimal management input and review of end results. \n   \n  Typical customers include dealers, other external companies who support Caterpillar as well as internal business unit and/or service center groups. The position is challenged to quickly and correctly identify problems that may not be obvious. The incumbent solves problems by determining the best course of action, within departmental guidelines, from many existing solutions. The incumbent sets priorities with Product Management team direction and establishes a work plan in order to complete broadly defined assignments and achieve desired results. The position participates in brainstorming sessions focused on developing approaches to meeting required deliverables. \n   \n \n Basic qualifications:  \n \n \n \n Position requires a Bachelor\u2019s degree in analytics, statistics, marketing, or other related field.  \n 5+ years experience implementing Google Analytics 360 or GA4 via Google Tag Manager  \n Google Analytics Individual Qualification  \n Proficiency with HTML, CSS, JavaScript and the document object model related to analytics tagging with Google Tag Manager  \n Knowledge of SQL for query writing for analysis and reporting  \n Cookie consent management experience related to Google marketing platform data collection  \n Experience demonstrating analytical capabilities to various levels of leadership.  \n Experience with Digital Marketing technologies, including campaign tracking and Salesforce Sales Cloud and Marketing Cloud Google Analytics integrations  \n \n \n Top candidates will also have:  \n \n \n \n A foundational knowledge of Google Analytics for Firebase or GA4  \n Ability to translate data analysis into business and marketing optimization recommendations  \n Strong analytical skills, proficient with GCP BigQuery, Microsoft Excel, Tableau Software, Power BI Looker, and data analysis methodologies and execution  \n Experience with implementing quality control procedures for analysis, reporting and data visualization  \n Effective team management, time management and project management skills  \n Experience with Azure DevOps.  \n Experience in a fast paced, technology arena.  \n \n \n Hiring Requirements  \n \n Skill Descriptors   Decision Making and Critical Thinking: Knowledge of the decision-making process and associated tools and techniques; ability to accurately analyze situations and reach productive decisions based on informed judgment.   \n \n Level Working Knowledge:  \n \n \n Applies an assigned technique for critical thinking in a decision-making process.  \n Identifies, obtains, and organizes relevant data and ideas.  \n Participates in documenting data, ideas, players, stakeholders, and processes.  \n Recognizes, clarifies, and prioritizes concerns.  \n Assists in assessing risks, benefits and consideration of alternatives.  \n \n \n Effective Communications  : Understanding of effective communication concepts, tools and techniques; ability to effectively transmit, receive, and accurately interpret ideas, information, and needs through the application of appropriate communication behaviors.   \n \n Level Working Knowledge:  \n \n \n Delivers helpful feedback that focuses on behaviors without offending the recipient.  \n Listens to feedback without defensiveness and uses it for own communication effectiveness.  \n Makes oral presentations and writes reports needed for own work.  \n Avoids technical jargon when inappropriate.  \n Looks for and considers non-verbal cues from individuals and groups.  \n \n \n Software Development:  Knowledge of software development tools and activities; ability to produce software products or systems in line with product requirements.   \n \n Level Extensive Experience:  \n \n \n Conducts walkthroughs and monitors effectiveness and quality of the development activities.  \n Elaborates on multiple-development toolkits for traditional and web-based software.  \n Has participated in development of multiple or large software products.  \n Contrasts advantages and drawbacks of different development languages and tools.  \n Estimates and monitors development costs based on functional and technical requirements.  \n Provides consulting on both selection and utilization of developers' workbench tools.  \n \n \n Software Development Life Cycle:  Knowledge of software development life cycle; ability to use a structured methodology for delivering and managing new or enhanced software products to the marketplace.   \n \n Level Working Knowledge:  \n \n \n Describes similarities and differences of life cycle for new product development vs. new release.  \n Identifies common issues, problems, and considerations for each phase of the life cycle.  \n Works with a formal life cycle methodology.  \n Explains phases, activities, dependencies, deliverables, and key decision points.  \n Interprets product development plans and functional documentation. \n \n \n \n Software Integration Engineering:  Knowledge of software integration processes and functions; ability to design, develop and maintain interfaces and linkage to alternative platforms and software packages.   \n \n Level Working Knowledge:  \n \n \n Has experience with designing data exchange interfaces to and from software product.  \n Describes tools and techniques for extraction, transformation and loading of electronic data.  \n Cites examples of common linkage requirements for software products and vendors.  \n Works with integrating software into the customer or partner framework and infrastructure.  \n Participates in the development of technology interfaces and bridges.  \n Software Product Design/Architecture: Knowledge of software product design; ability to convert market requirements into the software product design. \n    Level Extensive Experience: \n   \n \n Demonstrates experience with the architecture and design of major or multiple products.  \n Describes major software architecture alternatives and considerations.  \n Explains design considerations for commercial database systems, operating systems and web.  \n Displays experience in estimating the cost of a specific design of a proposed product.  \n Facilitates design reviews and walkthroughs.  \n Analyzes benefits and drawbacks of specific software designs and architecture.  \n \n \n Software Product Technical Knowledge  : Knowledge of technical aspects of a software products; ability to design, configure and integrate technical aspects of software products.   \n \n Level Working Knowledge:  \n \n \n Maintains and utilizes data related to install base configurations and environments.  \n Solicits customer feedback; reports and monitors bugs and implementation issues.  \n Participates in defining and conducting technical acceptance tests.  \n Participates in creating technical requirements for software development and deployment.  \n Explains basic environment and product configuration options.  \n \n \n Software Product Testing:  Knowledge of software product testing; ability to design, plan, and execute testing strategies and tactics to ensure software product quality and adherence to stated requirements.   \n \n Level Working Knowledge:  \n \n \n Participates in test readiness reviews, functional, volume, and load testing.  \n Describes key features and aspects of a specific testing discipline or methodology.  \n Tests software components for compliance with functional requirements and design specifications.  \n Explains procedures for documenting test activities and results (e.g. errors, non-conformance, etc.)  \n Conducts functional and performance testing on aspects of assigned products.  \n \n \n The preferred location is Peoria, IL, Chicago, IL, Westminster, CO, or Dallas, TX, but remote work within the United States is available for the right candidate.  \n #BI-Remote  \n #LI-Remote  \n Compensation & Benefits:  \n Base salary for this role ranges from $118,362 to $177,948 Actual salary will be based on experience. The total rewards package, beyond base salary includes:  \n \n Annual incentive bonus plan*  \n Medical, dental and vision coverage starting day 1  \n Paid time off plan (Vacation, Holiday, Volunteer, Etc.)  \n 401(K) Savings Plan including company match  \n Health savings account (HSA)  \n Flexible spending accounts (FSA)  \n Short and long term disability coverage  \n Life insurance  \n Paid parental leave  \n Healthy Lifestyle Programs  \n Employee Assistance Programs  \n Voluntary Benefits and Employee Discounts (Ex: Accident, Identity Theft Protection)  \n Career Development  \n \n \n Subject to annual eligibility and incentive plan guidelines  \n Visa Sponsorship is not available for this position. This employer is not currently hiring foreign national applicants that require or will require sponsorship tied to a specific employer, such as, H, L, TN, F, J, E, O. As a global company, Caterpillar offers many job opportunities outside of the U.S which can be found through our employment website at www.caterpillar.com/careers. \n  EEO/AA Employer. All qualified individuals - Including minorities, females, veterans and individuals with disabilities - are encouraged to apply.  \n Not ready to apply? Join our Talent Community .",
        "cleaned_desc": "Career Area:  Digital \n  Job Description:  \n Your Work Shapes the World at Caterpillar Inc.  \n When you join Caterpillar, you're joining a global team who cares not just about the work we do \u2013 but also about each other. We are the makers, problem solvers, and future world builders who are creating stronger, more sustainable communities. We don't just talk about progress and innovation here \u2013 we make it happen, with our customers, where we work and live. Together, we are building a better world, so we can all enjoy living in it.  \n At Caterpillar, we\u2019re delighted to be making a significant investment in our team that focuses on Google Analytics implementation and reporting capabilities. We have an exciting and challenging opportunity for a Lead Software Engineer. The Lead Software Engineer provides technical leadership in solution development, implementation, and support for Caterpillar\u2019s Google Marketing & Analytics Platforms. This position will implement world class capabilities to support a wide range of digital applications while delivering against the common department goals in line with CAT Digital Strategy.      JOB DUTIES:   \n \n  This role is responsible for delivering Google oversight, solution design, implementation, reporting, dashboards, and insights in support of Caterpillar\u2019s digital strategy. The mandate includes partnering with digital channel owners as well as internal data science, customer service, marketing, legal and technology teams to ensure the organization understands and can act on insights derived from our customers\u2019 on-site digital behavior. \n    Additional responsibilities include training the organization on the access and use of digital analytics data, supporting campaign tracking & a/b testing. In support of these goals, this role will team lead and train a small team of talented digital analysts and implementation specialists. Other responsibilities include: \n   \n  1. Conduct reporting and analyses on all 500+ digital properties to provide data to drive decisions that will enhance user experiences, optimize campaign performance, and provide recommendations to the organization in relation to the behavioral data for each property. \n    2. Work with Product Owners, Stakeholders, Designers, and Developers to implement measurement plans that enable future reporting and analysis. \n    3. Oversee, create, and automate tools and dashboards to effectively manage requests from stakeholders with varying levels of technical capability. \n    4. Foster a team with high levels of relevant skills (analytics, story-telling, data visualization, etc.) and knowledge (an understanding of tagging, marketing technologies and methods, quantitative and qualitative research methods) \n    5. QA and troubleshoot, data collection on digital properties using JavaScript and the developer console \n    6. Document reporting and implementation requirements to meet business and site reporting plans \n   \n  The position manages the completion of its own work assignments and coordinates work with others. Based on past experiences and knowledge, the incumbent normally works within a team environment, with minimal management input and review of end results. \n   \n  Typical customers include dealers, other external companies who support Caterpillar as well as internal business unit and/or service center groups. The position is challenged to quickly and correctly identify problems that may not be obvious. The incumbent solves problems by determining the best course of action, within departmental guidelines, from many existing solutions. The incumbent sets priorities with Product Management team direction and establishes a work plan in order to complete broadly defined assignments and achieve desired results. The position participates in brainstorming sessions focused on developing approaches to meeting required deliverables. \n   \n \n Basic qualifications:  \n \n \n \n Position requires a Bachelor\u2019s degree in analytics, statistics, marketing, or other related field.  \n 5+ years experience implementing Google Analytics 360 or GA4 via Google Tag Manager  \n Google Analytics Individual Qualification  \n Proficiency with HTML, CSS, JavaScript and the document object model related to analytics tagging with Google Tag Manager  \n Knowledge of SQL for query writing for analysis and reporting  \n Cookie consent management experience related to Google marketing platform data collection  \n Experience demonstrating analytical capabilities to various levels of leadership.  \n Experience with Digital Marketing technologies, including campaign tracking and Salesforce Sales Cloud and Marketing Cloud Google Analytics integrations  \n   \n Top candidates will also have:  \n \n \n \n A foundational knowledge of Google Analytics for Firebase or GA4  \n Ability to translate data analysis into business and marketing optimization recommendations  \n Strong analytical skills, proficient with GCP BigQuery, Microsoft Excel, Tableau Software, Power BI Looker, and data analysis methodologies and execution  \n Experience with implementing quality control procedures for analysis, reporting and data visualization  \n Effective team management, time management and project management skills  \n Experience with Azure DevOps.  \n Experience in a fast paced, technology arena.  \n \n \n Hiring Requirements  \n \n Skill Descriptors   Decision Making and Critical Thinking: Knowledge of the decision-making process and associated tools and techniques; ability to accurately analyze situations and reach productive decisions based on informed judgment.   \n \n Level Working Knowledge:  \n \n \n Applies an assigned technique for critical thinking in a decision-making process.  \n Identifies, obtains, and organizes relevant data and ideas.  \n Participates in documenting data, ideas, players, stakeholders, and processes.  \n Recognizes, clarifies, and prioritizes concerns.  \n Assists in assessing risks, benefits and consideration of alternatives.  \n \n \n Effective Communications  : Understanding of effective communication concepts, tools and techniques; ability to effectively transmit, receive, and accurately interpret ideas, information, and needs through the application of appropriate communication behaviors.   \n \n Level Working Knowledge:  \n \n \n Delivers helpful feedback that focuses on behaviors without offending the recipient.    Listens to feedback without defensiveness and uses it for own communication effectiveness.  \n Makes oral presentations and writes reports needed for own work.  \n Avoids technical jargon when inappropriate.  \n Looks for and considers non-verbal cues from individuals and groups.  \n \n \n Software Development:  Knowledge of software development tools and activities; ability to produce software products or systems in line with product requirements.   \n \n Level Extensive Experience:  \n \n \n Conducts walkthroughs and monitors effectiveness and quality of the development activities.  \n Elaborates on multiple-development toolkits for traditional and web-based software.  \n Has participated in development of multiple or large software products.  \n Contrasts advantages and drawbacks of different development languages and tools.  \n Estimates and monitors development costs based on functional and technical requirements.  \n Provides consulting on both selection and utilization of developers' workbench tools.  \n \n \n Software Development Life Cycle:  Knowledge of software development life cycle; ability to use a structured methodology for delivering and managing new or enhanced software products to the marketplace.   \n \n Level Working Knowledge:  \n \n \n Describes similarities and differences of life cycle for new product development vs. new release.  \n Identifies common issues, problems, and considerations for each phase of the life cycle.  \n Works with a formal life cycle methodology.  \n Explains phases, activities, dependencies, deliverables, and key decision points.  \n Interprets product development plans and functional documentation. \n \n \n \n Software Integration Engineering:  Knowledge of software integration processes and functions; ability to design, develop and maintain interfaces and linkage to alternative platforms and software packages.   \n   Level Working Knowledge:  \n \n \n Has experience with designing data exchange interfaces to and from software product.  \n Describes tools and techniques for extraction, transformation and loading of electronic data.  \n Cites examples of common linkage requirements for software products and vendors.  \n Works with integrating software into the customer or partner framework and infrastructure.  \n Participates in the development of technology interfaces and bridges.  \n Software Product Design/Architecture: Knowledge of software product design; ability to convert market requirements into the software product design. \n    Level Extensive Experience: \n   \n \n Demonstrates experience with the architecture and design of major or multiple products.  \n Describes major software architecture alternatives and considerations.  \n Explains design considerations for commercial database systems, operating systems and web.  \n Displays experience in estimating the cost of a specific design of a proposed product.  \n Facilitates design reviews and walkthroughs.  \n Analyzes benefits and drawbacks of specific software designs and architecture.  \n \n \n Software Product Technical Knowledge  : Knowledge of technical aspects of a software products; ability to design, configure and integrate technical aspects of software products.   \n \n Level Working Knowledge:  \n \n \n Maintains and utilizes data related to install base configurations and environments.  \n Solicits customer feedback; reports and monitors bugs and implementation issues.  \n Participates in defining and conducting technical acceptance tests.  \n Participates in creating technical requirements for software development and deployment.  \n Explains basic environment and product configuration options.  \n \n \n Software Product Testing:  Knowledge of software product testing; ability to design, plan, and execute testing strategies and tactics to ensure software product quality and adherence to stated requirements.   \n ",
        "techs": [
            "google analytics",
            "google tag manager",
            "javascript",
            "sql",
            "google marketing platform",
            "salesforce sales cloud",
            "marketing cloud",
            "google analytics for firebase",
            "gcp bigquery",
            "microsoft excel",
            "tableau software",
            "power bi looker",
            "azure devops"
        ],
        "cleaned_techs": [
            "google analytics",
            "google tag manager",
            "javascript",
            "sql",
            "google marketing platform",
            "salesforce sales cloud",
            "marketing cloud",
            "google analytics for firebase",
            "gcp",
            "excel",
            "tableau software",
            "powerbi",
            "azure"
        ]
    },
    "750fd90b59b68d35": {
        "terms": [
            "data science"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Senior Technical Project Manager \u2013 Data and Analytics - Digital Velocity",
        "company": "CDW",
        "desc": "Work in CDW\u2019s Digital Velocity organization (DV). The Sr. Technical Project Manager manages all phases of service delivery including: analysis and design, configuration and build, testing and training, and deployment of solutions and will be accountable for all aspects of project management including all project resources (including partners/subcontractors), project planning, scheduling, timeline, budget, risk management, scope management, internal and external communications, status reporting, and resource management (internal and partners). To be successful as a Technical Project Manager you must be highly organized and able to manage multiple initiatives. \n  The DV Data and Analytics Sr. Technical Project Manager has \u201cbig data\u201d experience leading complex data specific engagements. Our customers need a Sr. Technical Project Manager that is capable of providing consultative support as well as executing project plans. The candidate must have experience with cloud data warehousing & engineering, security and business analytics while leading project resources in a distributed environment. \n \n Key Areas of Responsibility \n \n Working with DV/CDW customers as a billable Agile Technical Project Manager  \n Documentation development to support customer projects (Process, Plans, Presentations, Customer Deliverables)  \n Support Sales and Engineering teams providing clear support and direction, identifying resources and constraints through careful project planning  \n Partners with our sales, solutions and services teams to serve clients  \n Ensures the project adheres to budget and time frame guidelines. Oversees the implementation process include setting goals, planning, and monitoring progress to completion  \n Support the delivery of quality solutions to customers exceeding expectations  \n Ensures projects are being managed effectively, establishing deliverables, milestones and risk identification/mitigation  \n Meets with customers and partners during key phases of basic and complex projects  \n Continually seeks and build upon opportunities to increase customer satisfaction and deepen client relationships  \n Executes PMO Operational Duties, including: Status Reporting, Financial Program Management, Escalation engagement, Sales Cycle engagement  \n Proven track record of building effective delivery teams \n Ensures projects are managed with a vision and purpose \n Comfortable managing customer expectations \n Travel Estimated up to 10%  \n Internal Projects as required \n \n   \n Education and/or Skill-Set Qualifications \n \n Bachelor\u2019s degree in MIS, computer science or related field, or equivalent work experience  \n 7+ years of experience in Project Management focusing in one or more of the following, Software defined Lifecycle (SDLC), Infrastructure, or any other related technical environments \n 5+ years of experience in managing Agile software and cloud development projects  \n Knowledge and skill level in identified competencies meet minimum requirements for role  \n Previous direct customer consulting experience or equivalent understanding of role responsibilities \n \n Required Qualifications \n \n An expert in project/program team management including dynamics of virtual teams, matrix reporting relationships and cross-functional resource identification and allocation  \n 7+ years of experience leading Agile Enterprise Data Engineering implementations \n Previous experience leading a team providing Data Governance, Data Engineering, Data Quality, Business Analytics initiatives to customers for large projects \n Previous experience developing Data Governance, Data Science or Data Engineering solutions. \n Previous experience leading delivery team 10+ FTEs \n Experience managing contractors and vendors \n Previous remote work experience \n \n Preferred Qualifications \n \n Previous consulting experience  \n Previous experience with Collaboration Solutions  \n Previous experience with software development engagements  \n Previous experience in Management Consulting \n PMI Agile Certified Practitioner  \n Certified Scrum Master  \n SAFe Scaled Agilist",
        "cleaned_desc": "Work in CDW\u2019s Digital Velocity organization (DV). The Sr. Technical Project Manager manages all phases of service delivery including: analysis and design, configuration and build, testing and training, and deployment of solutions and will be accountable for all aspects of project management including all project resources (including partners/subcontractors), project planning, scheduling, timeline, budget, risk management, scope management, internal and external communications, status reporting, and resource management (internal and partners). To be successful as a Technical Project Manager you must be highly organized and able to manage multiple initiatives. \n  The DV Data and Analytics Sr. Technical Project Manager has \u201cbig data\u201d experience leading complex data specific engagements. Our customers need a Sr. Technical Project Manager that is capable of providing consultative support as well as executing project plans. The candidate must have experience with cloud data warehousing & engineering, security and business analytics while leading project resources in a distributed environment. \n \n Key Areas of Responsibility \n \n Working with DV/CDW customers as a billable Agile Technical Project Manager  \n Documentation development to support customer projects (Process, Plans, Presentations, Customer Deliverables)  \n Support Sales and Engineering teams providing clear support and direction, identifying resources and constraints through careful project planning  \n Partners with our sales, solutions and services teams to serve clients    Travel Estimated up to 10%  \n Internal Projects as required \n \n   \n Education and/or Skill-Set Qualifications \n \n Bachelor\u2019s degree in MIS, computer science or related field, or equivalent work experience  \n 7+ years of experience in Project Management focusing in one or more of the following, Software defined Lifecycle (SDLC), Infrastructure, or any other related technical environments \n 5+ years of experience in managing Agile software and cloud development projects  ",
        "techs": [
            "cdw",
            "digital velocity",
            "sr. technical project manager",
            "analysis and design",
            "configuration and build",
            "testing and training",
            "deployment of solutions",
            "project management",
            "project resources",
            "partners/subcontractors",
            "project planning",
            "scheduling",
            "timeline",
            "budget",
            "risk management",
            "scope management",
            "internal communications",
            "external communications",
            "status reporting",
            "resource management",
            "technical project manager",
            "multiple initiatives",
            "data and analytics sr. technical project manager",
            "big data",
            "cloud data warehousing",
            "engineering",
            "security",
            "business analytics",
            "project resources",
            "distributed environment",
            "billable agile technical project manager",
            "documentation development",
            "support sales and engineering teams",
            "project planning",
            "sales",
            "solutions and services teams",
            "clients",
            "travel",
            "internal projects",
            "education",
            "skill-set qualifications",
            "bachelor\u2019s degree in mis",
            "computer science",
            "project management",
            "software defined lifecycle",
            "infrastructure",
            "managing agile software",
            "cloud development projects"
        ],
        "cleaned_techs": [
            "cdw",
            "digital velocity",
            "sr. technical project manager",
            "analysis and design",
            "configuration and build",
            "testing and training",
            "deployment of solutions",
            "project management",
            "project resources",
            "partners/subcontractors",
            "project planning",
            "scheduling",
            "timeline",
            "budget",
            "risk management",
            "scope management",
            "internal communications",
            "external communications",
            "status reporting",
            "resource management",
            "technical project manager",
            "multiple initiatives",
            "data and analytics sr. technical project manager",
            "big data",
            "cloud data warehousing",
            "engineering",
            "business analytics",
            "distributed environment",
            "billable agile technical project manager",
            "support sales and engineering teams",
            "sales",
            "solutions and services teams",
            "clients",
            "travel",
            "internal projects",
            "education",
            "skill-set qualifications",
            "computer science",
            "infrastructure",
            "managing agile software",
            "cloud development projects"
        ]
    },
    "99ccd9504aac94f6": {
        "terms": [
            "data science",
            "machine learning engineer",
            "mlops"
        ],
        "salary_min": 65.0,
        "salary_max": 70.0,
        "title": "ML/Ops Engineer",
        "company": "Broadmind INC",
        "desc": "Location: 100% Remote \n Role: MLOps Engineer \n \n Required skills: \n Must have MLOps experience\u2026 not just Data Science or Data Engineering \n Data Engineering \u2013 Azure based \n Azure \u2013 Required \n Azure Databricks, ADO, etc \n \n \n Machine Learning / Data Science \u2013 Python is must have \n Devops/Kubernetes \u2013 at least a self-rating of 6 of 10 on experience, 10 being expert \n Spark- Required \n Have deployed and worked with any of these tools: Jupterhub/ mlflow/ databricks/ kubeflow \n \n Must Haves: \n \n 8+ years of experience in  Data and DevOps  Engineering \n Prior experience in MLOps Engineering \n Strong hands-on experience in Kubernetes (5+ years) \n Strong hands-on experience in Python (5+ years) \n \n Job Details: \n Location: 100% Remote \n Role: ML/Ops Engineer \n \n Team is developing an AI/ML Model Inferencing Pipeline that would automate the extraction of all data elements from the Document or from Source Streaming Data, this will leverage the elastic nature of cloud for cost optimize for different use cases. \n \n Tasks: \n \n You will assist in design, development, test, deploy, maintain, and enhance Machine Learning Pipelines using K8s/AKS based Argo Workflow Orchestration solutions. \n Participate and contribute to design reviews with platform engineering team to decide the design, technologies, project priorities, deadlines, and deliverables. \n You will work closely with Data Lake and Data Science team to understand their data structure and machine learning algorithms. \n Understanding of ETL pipelines, and ingress / egress methodologies and design patterns \n Implement real time Argo workflow pipelines, integrate pipelines with machine learning models, and translate data and model results into business stakeholders Data Lake \n Develop distributed Machine Learning Pipeline for training & inferencing using Argo, Spark & AKS \n Build highly scalable backend REST APIs to collect data from Data Lake and other use-cases / scenarios. \n Deploy Application in Azure Kubernetes Service using GitLab CICD, Jenkins, Docker, Kubectl, Helm and Mainfest \n Experience in branching, tagging and maintaining the versions across the different environments in GitLab. \n Review code developed by other developers and provide a feedback to ensure best practices (e.g., checking code in, accuracy, testability, and efficiency) \n Debug/track/resolve by analyzing the sources of issues and the impact on application, network, or service operations and quality. \n Functional, benchmark & performance testing and tuning for the built workflows. \n Assess, design & optimize the resources capacities (e.g .Memory, GPU etc.) for ML based resource intensive workloads \n \n ESSENTIAL FUNCTIONS \n \n Designs and writes complex code in several languages relevant to our existing product stack, with a focus on automation \n Configures, tunes, maintains and installs applications systems and validates system functionality \n Monitors and fine tunes applications system to achieve optimum performance levels and works with hardware teams to resolve issues with hardware and software \n Develops and maintains department's knowledge database containing enterprise issues and possible resolutions. \n Develops models of task problem domain for which a system will be designed or built. \n Uses models, hypotheses, and cognitive analysis techniques to elicit real problem-solving knowledge from the experts \n Mediates between the expert and knowledge base; encodes for the knowledge base \n Acts as subject matter expert for difficult or complex application problems requiring interpretation of AI tools and principles \n Researches and prepares reports and studies on various aspects of knowledge acquisition, modeling, management, and presentation \n Develops and maintains processes, procedures, models, and templates for collecting and organizing knowledge into specialized knowledge representation programs \n Acts as vendor liaison for products and services to support development tools \n Maintains the definition, documentation, training, testing, and activation of Disaster Recovery/Business Continuity Planning to meet compliance standards \n Maintains a comprehensive operating system hardware and software configuration database/library of all supporting documentation to ensure data integrity \n Acts to improve the overall reliability of systems and to increase efficiency \n Works collaboratively with cross functional teams, using Agile / DevOps principles to bring products to life, achieve business objectives and serve customer needs \n \n What skills/technologies are required: \n \n Bachelor\u2019s/Master\u2019s degree in Computer Science or Data Science \n 5 to 8 years of experience in software development and with data structures/algorithms \n 5 to 7 years of experience with programming language Python \n Strong understanding and experience with Kubernetes for availability and scalability of the application in Azure Kubernetes Service \n 5 years of experience in developing large-scale infrastructure, distributed systems or networks, experience with compute technologies, storage architecture \n 5 years of experience with Unit and Functional test cases using PyTest, UnitTest and Mocking External Services for functional and non-functional requirements \n Experience with cloud tools like Azure and Google Cloud Platform \n Strong understanding of microservices architecture and experience with building and deploying RestAPI\u2019s using Python, Flask and Django \n Experience in building and deploying applications with Azure, using third-party tools (e.g., Docker, Kubernetes and Terraform) \n Experience with development tools, CI/CD pipelines such as GitLab CI/CD, Artifactory, Cloudbees and Jenkins \n \n Job Type: Contract \n Salary: $65.00 - $70.00 per hour \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n Paid time off \n \n Schedule: \n \n 8 hour shift \n \n Work Location: Remote",
        "cleaned_desc": " 8+ years of experience in  Data and DevOps  Engineering \n Prior experience in MLOps Engineering \n Strong hands-on experience in Kubernetes (5+ years) \n Strong hands-on experience in Python (5+ years) \n \n Job Details: \n Location: 100% Remote \n Role: ML/Ops Engineer \n \n Team is developing an AI/ML Model Inferencing Pipeline that would automate the extraction of all data elements from the Document or from Source Streaming Data, this will leverage the elastic nature of cloud for cost optimize for different use cases. \n \n Tasks: \n \n You will assist in design, development, test, deploy, maintain, and enhance Machine Learning Pipelines using K8s/AKS based Argo Workflow Orchestration solutions. \n Participate and contribute to design reviews with platform engineering team to decide the design, technologies, project priorities, deadlines, and deliverables. \n You will work closely with Data Lake and Data Science team to understand their data structure and machine learning algorithms. \n Understanding of ETL pipelines, and ingress / egress methodologies and design patterns   Implement real time Argo workflow pipelines, integrate pipelines with machine learning models, and translate data and model results into business stakeholders Data Lake \n Develop distributed Machine Learning Pipeline for training & inferencing using Argo, Spark & AKS \n Build highly scalable backend REST APIs to collect data from Data Lake and other use-cases / scenarios. \n Deploy Application in Azure Kubernetes Service using GitLab CICD, Jenkins, Docker, Kubectl, Helm and Mainfest \n Experience in branching, tagging and maintaining the versions across the different environments in GitLab. \n Review code developed by other developers and provide a feedback to ensure best practices (e.g., checking code in, accuracy, testability, and efficiency) \n Debug/track/resolve by analyzing the sources of issues and the impact on application, network, or service operations and quality. \n Functional, benchmark & performance testing and tuning for the built workflows. \n Assess, design & optimize the resources capacities (e.g .Memory, GPU etc.) for ML based resource intensive workloads \n \n ESSENTIAL FUNCTIONS \n \n Designs and writes complex code in several languages relevant to our existing product stack, with a focus on automation \n Configures, tunes, maintains and installs applications systems and validates system functionality \n Monitors and fine tunes applications system to achieve optimum performance levels and works with hardware teams to resolve issues with hardware and software \n Develops and maintains department's knowledge database containing enterprise issues and possible resolutions. \n Develops models of task problem domain for which a system will be designed or built.   Uses models, hypotheses, and cognitive analysis techniques to elicit real problem-solving knowledge from the experts \n Mediates between the expert and knowledge base; encodes for the knowledge base \n Acts as subject matter expert for difficult or complex application problems requiring interpretation of AI tools and principles \n Researches and prepares reports and studies on various aspects of knowledge acquisition, modeling, management, and presentation \n Develops and maintains processes, procedures, models, and templates for collecting and organizing knowledge into specialized knowledge representation programs \n Acts as vendor liaison for products and services to support development tools \n Maintains the definition, documentation, training, testing, and activation of Disaster Recovery/Business Continuity Planning to meet compliance standards \n Maintains a comprehensive operating system hardware and software configuration database/library of all supporting documentation to ensure data integrity \n Acts to improve the overall reliability of systems and to increase efficiency \n Works collaboratively with cross functional teams, using Agile / DevOps principles to bring products to life, achieve business objectives and serve customer needs \n \n What skills/technologies are required: \n \n Bachelor\u2019s/Master\u2019s degree in Computer Science or Data Science \n 5 to 8 years of experience in software development and with data structures/algorithms \n 5 to 7 years of experience with programming language Python \n Strong understanding and experience with Kubernetes for availability and scalability of the application in Azure Kubernetes Service   5 years of experience in developing large-scale infrastructure, distributed systems or networks, experience with compute technologies, storage architecture \n 5 years of experience with Unit and Functional test cases using PyTest, UnitTest and Mocking External Services for functional and non-functional requirements \n Experience with cloud tools like Azure and Google Cloud Platform \n Strong understanding of microservices architecture and experience with building and deploying RestAPI\u2019s using Python, Flask and Django \n Experience in building and deploying applications with Azure, using third-party tools (e.g., Docker, Kubernetes and Terraform) \n Experience with development tools, CI/CD pipelines such as GitLab CI/CD, Artifactory, Cloudbees and Jenkins \n \n Job Type: Contract \n Salary: $65.00 - $70.00 per hour \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n Paid time off \n \n Schedule: ",
        "techs": [
            "kubernetes",
            "python",
            "argo workflow orchestration",
            "aks",
            "spark",
            "gitlab ci/cd",
            "jenkins",
            "docker",
            "kubectl",
            "helm",
            "manifest",
            "gitlab",
            "azure kubernetes service",
            "pytest",
            "unittest",
            "mocking external services",
            "azure",
            "google cloud platform",
            "flask",
            "django",
            "terraform",
            "artifactory",
            "cloudbees"
        ],
        "cleaned_techs": [
            "kubernetes",
            "python",
            "argo workflow orchestration",
            "aks",
            "spark",
            "gitlab ci/cd",
            "jenkins",
            "docker",
            "kubectl",
            "helm",
            "manifest",
            "gitlab",
            "azure",
            "pytest",
            "unittest",
            "mocking external services",
            "gcp",
            "flask",
            "django",
            "terraform",
            "artifactory",
            "cloudbees"
        ]
    },
    "2d892c28d9c58795": {
        "terms": [
            "data science"
        ],
        "salary_min": 132292.25,
        "salary_max": 167511.47,
        "title": "Principal IS Analyst - R&D Generative AI",
        "company": "Amgen",
        "desc": "HOW MIGHT YOU DEFY IMAGINATION? \n  If you feel like you\u2019re part of something bigger, it\u2019s because you are. At Amgen, our shared mission\u2014to serve patients\u2014drives all that we do. It is key to our becoming one of the world\u2019s leading biotechnology companies. We are global collaborators who achieve together\u2014researching, manufacturing, and delivering ever-better products that reach over 10 million patients worldwide. It\u2019s time for a career you can be proud of. \n \n  Principal IS Analyst - R&D Generative AI \n  Live \n  What you will do \n  Let\u2019s do this. Let\u2019s change the world. In this vital role you will work with our Research and Development (R&D) Digital Technology and Innovation (DTI) group supporting R&D\u2019s Global Regulatory Affairs & Strategy (GRAAS) function in alignment with our business and DTI strategy. \n  As a Principal IS Business Systems Analyst at Amgen, you will provide strategic leadership and guidance in analyzing business requirements and designing information systems solutions. You will collaborate with multi-functional teams to understand business needs, identify system enhancements, and drive system implementation projects. Your extensive experience in business analysis, system design, and project management will enable you to deliver innovative and effective solutions that align with the company's strategic goals. \n  Responsibilities: \n \n  Serve as a client facing partner and / or product owner working with business and DTI team members to implement and support the Generative AI and Structured Content Management/Authoring initiatives \n  Responsibilities include technical product ownership, process and systems analysis, requirements elicitation, articulating system solutions and approaches for addressing business needs \n  Provide an expert-level understanding of GRAAS business models, processes, and procedures \n  Engage with key vendors and platform owners to understand functionality and how those platforms can be used to tackle the business problems \n  Meet regulatory requirements and adhere to DTI standards including following GxP Quality and SDLC processes \n  The position is located in our offices in Thousand Oaks, CA, or Tampa, FL or we can also consider remote applicants in a United States. \n \n  Win \n  What we expect of you \n  We are all different, yet we all use our unique contributions to serve patients. The strategic professional we seek is a critical thinker with these qualifications. \n  Basic Qualifications: \n \n  Doctorate degree and 2 years of Information Systems experience \n  OR Master\u2019s degree and 6 years of Information Systems experience \n  OR Bachelor\u2019s degree and 8 years of Information Systems experience \n  OR Associate\u2019s degree and 10 years of Information Systems experience \n  OR High School Diploma /GED and 12 years of Information Systems experience \n \n  Preferred Qualifications: \n \n  At least 5 years of domain knowledge in health and/or life sciences combined with Information Technology \n  Ability to set expectations with business partners and optimally use governance for a positive business partner experience \n  Strong communications skills in writing, speaking, presenting and time management skills \n  Applied experience and knowledge in the application of Generative AI in the submission/CTD document drafting \n  Understanding, and preferably applied experience and knowledge in the application of Structured Content Management/Authoring in the submission/CTD document space \n  Expert understanding of GRAAS/Regulatory Affairs, and preferably other R&D processes \n  Experience in Agile product development \n  7+ years customer-facing technical consulting experience \n  Experience defining technical roadmaps and driving adoption \n  Either 7+ years of experience with integration architecture, design, and development for geographically distributed enterprise/cloud software or document/content management systems OR development experience with one of the following languages \u2013 Java, .NET, Python, C#, or C++, or database development \n \n  Thrive \n  What you can expect of us \n  As we work to develop treatments that take care of others, we also work to care for our teammates\u2019 professional and personal growth and well-being. \n  Amgen offers a Total Rewards Plan comprising health and welfare plans for staff and eligible dependents, financial plans with opportunities to save towards retirement or other goals, work/life balance, and career development opportunities including: \n \n  Comprehensive employee benefits package, including a Retirement and Savings Plan with generous company contributions, group medical, dental and vision coverage, life and disability insurance, and flexible spending accounts. \n  A discretionary annual bonus program, or for field sales representatives, a sales-based incentive plan \n  Stock-based long-term incentives \n  Award-winning time-off plans and bi-annual company-wide shutdowns \n  Flexible work models, including remote work arrangements, where possible \n \n  Apply now \n  for a career that defies imagination \n  Objects in your future are closer than they appear. Join us. \n  careers.amgen.com \n \n  Join Us\n  \n  If you're seeking a career where you can truly make a difference in the lives of others, a career where you can work at the absolute forefront of biotechnology with the top minds in the field, you'll find it at Amgen.\n  \n  Amgen, a biotechnology pioneer, discovers, develops and delivers innovative human therapeutics. Our medicines have helped millions of patients in the fight against cancers, kidney disease, rheumatoid arthritis and other serious illnesses.\n  \n  As an organization dedicated to improving the quality of life for people around the world, Amgen fosters an inclusive environment of diverse, ethical, committed and highly accomplished people who respect each other but compete intensely to win. Together, we live the Amgen values as we continue advancing science to serve patients.\n  \n  Amgen is an Equal Opportunity employer and will consider all qualified applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.\n  \n  We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.",
        "cleaned_desc": "  OR High School Diploma /GED and 12 years of Information Systems experience \n \n  Preferred Qualifications: \n \n  At least 5 years of domain knowledge in health and/or life sciences combined with Information Technology \n  Ability to set expectations with business partners and optimally use governance for a positive business partner experience \n  Strong communications skills in writing, speaking, presenting and time management skills \n  Applied experience and knowledge in the application of Generative AI in the submission/CTD document drafting \n  Understanding, and preferably applied experience and knowledge in the application of Structured Content Management/Authoring in the submission/CTD document space \n  Expert understanding of GRAAS/Regulatory Affairs, and preferably other R&D processes \n  Experience in Agile product development \n  7+ years customer-facing technical consulting experience \n  Experience defining technical roadmaps and driving adoption ",
        "techs": [
            "generative ai",
            "structured content management/authoring",
            "graas/regulatory affairs",
            "r&d processes",
            "agile product development",
            "technical consulting"
        ],
        "cleaned_techs": [
            "generative ai",
            "structured content management/authoring",
            "r&d processes",
            "agile product development",
            "technical consulting"
        ]
    },
    "575ad25dfd4b1b3c": {
        "terms": [
            "data science"
        ],
        "salary_min": 102218.79,
        "salary_max": 129431.76,
        "title": "Business Development Specialist",
        "company": "TritonWear",
        "desc": "Our Mission \n  We empower swimmers and coaches to produce faster swimming through education and innovative technology. \n  From our competitive swimming and engineering roots to the entire sports industry, TritonWear is committed to making sports science accessible to everyone, driving success through education and innovative technology. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n The TritonWear Advantage \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Accuracy \n  We strive to deliver the most accurate metrics and analytics tools for swimmers around the world. \n \n \n \n \n \n \n \n \n \n \n \n Competitive Edge \n  We aim to provide every swimmer an edge over their competition, by helping them discover their own hidden potential, and to understand the technical side of the sport. \n \n \n \n \n \n \n \n \n \n \n \n Leading Tech \n  We commit to equipping every coach with groundbreaking tools, so they can focus on what really matters, instead of stopwatches. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n How to Apply \n \n email: \n   \n apply@tritonwear.com \n \n \n Subject line:  Job title || your name\n             \n \n             Include your geographic region, competitive swimming experience, why this position is right for you, and your resume.\n             \n \n             Only applications meeting these requirements will be considered.\n             \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Sales  \n Team Sales Manager  \n Remote - US Full Time  \n \n \n \n \n \n About you \n  You have a deep background and network in competitive swimming as a coach, and you are experienced in selling to Competitive Swim Teams in Canada. You love sales and thrive in a fast-paced growth environment to exceed your targets. \n  You are ambitious, driven, and organized, ensuring you always have a full pipeline to keep ahead of your numbers constantly. You enjoy finding creative ways to hunt for new customers and build your business. You love making new friends and building relationships to help broaden your network and strengthen your trust in the global swimming community. \n  Finally, you are passionate about start-up growth, love autonomy and thrive as a self-starter. You know you can help over-deliver on team sales, being a crucial part of exceeding TritonWear\u2019s overall growth targets. \n  About the Role \n  As a Team Sales Manager at TritonWear, you will be responsible for helping us exceed our sales targets in our Team Sales vertical, specifically targeting teams within your assigned territory. \n  In this role, you will be selling to all levels of teams, including Clubs, High Schools, Colleges / Universities, ISL Teams, and provincial and National groups. You will also be fed international inbound leads to support your sales pipeline but will ultimately be responsible for the success of your own business and targets. Finding creative ways to build your lead pool will also be required to ensure you consistently hit or exceed your targets. \n  This Team Sales Manager role will be a remote position, and sales can be done virtually, in-field, at conferences, or in any other way proven to drive the best results. Team sales are a crucial part of TritonWear\u2019s business, so this will be vital to the organization. \n  Responsibilities \n \n Achieve agreed-upon personal and team sales targets and outcomes \n Work inbound leads from upsell mining, and marketing campaigns \n Build outbound pipeline through personal network activation activities, including strategic calling, networking and social media \n Run a tight sales process to maintain a healthy pipeline for accurate forecasting and planning \n Forecast sales, and prepare and present reports on weekly, monthly, quarterly and annual progress \n Travel to potential and existing customer training facilities to demonstrate products and services \n Attend conferences and other events to represent TritonWear and expand your contact list to build pipeline \n Prepare and deliver appropriate documentation and presentations on products and services \n Identify, present, and develop \u201cout of the box\u201d sales strategies/models and evaluate their effectiveness \n \n Requirements \n \n 3+ Years in a Team Sales role in the Competitive Swimming Industry with an extensive personal network in the sport in the US \n Strong background as a Competitive Swimming coach \n Highly motivated and target-driven with a proven track record in achieving and/or exceeding sales targets \n Strong closing, communication, and negotiation skills with experience in outbound sales and pipeline building \n Experience in sales process management, pipeline management and forecasting through a CRM (i.e. Hubspot, Salesforce, etc.) with a strong understanding of sales performance metrics \n BSc degree in Marketing, Business Administration or equivalent work experience \n \n \n \n \n \n \n \n \n \n \n \n \n Sales  \n Business Development Specialist  \n Remote -US Full Time  \n \n \n \n \n \n About you \n  You have a deep background in competitive swimming as an athlete and/or coach and are experienced in selling to Competitive Swim Teams. You love sales and thrive in a fast-paced growth environment.    You are ambitious, charismatic, and organized. You are competitive by nature and thrive on exceeding targets. You enjoy a good challenge and are creative in finding new ways to hunt for new prospects and business. You love making new friends and building relationships quickly to help broaden your network and strengthen your trust in the global swimming community.    Finally, you are passionate about start-up growth, love autonomy, and thrive as a self-starter. You know you can help over-deliver on team sales leads, which is crucial to crushing TritonWear\u2019s growth targets. You also are hungry for self-growth and have a palpable personal goal of becoming a seasoned sales professional. \n \n  About the Role \n  As a Business Development Specialist at TritonWear, you will extend our global reach through expert discovery and exploration of new and untapped business opportunities and relationships.    In this role, you will be prospecting all levels of teams within your assigned territory, including Clubs, YMCAs, High Schools, and Colleges or Universities. You will work through our CRM and with our Team Sales Managers to strategically target outbound leads. Finding creative ways to build a high-quality lead pool is critical to achieving your lead handover targets.    This remote role offers the freedom to chase leads virtually, in-field, at conferences, or in any other way proven to drive the best results. Highly skilled in sales and business operations, this person will join and inspire a team of like-minded go-getters to achieve our company vision. At TritonWear, we strongly believe in the value of mentorship and skill development, so we are looking for a candidate who wants to grow into more senior sales roles. \n  Responsibilities \n \n Identify trends and customer needs, building a short/medium/long-term sales pipeline based on target numbers \n Generate new leads, identify and contact decision-makers, screen potential business opportunities and hand off qualified leads for closing \n Build outbound pipeline through personal network activation activities, including strategic calling, networking and social media \n Run a tight sales process to build a healthy pipeline \n Prepare and present reports on lead generation targets detailing weekly, monthly, quarterly and annual progress \n Prepare and deliver appropriate documentation and presentations on products and services \n Identify, present, and develop \u201cout of the box\u201d sales strategies/models and evaluate their effectiveness \n Maintain and share professional knowledge through education, networking, events, and presentations \n \n Requirements \n \n 1+ Years in a growth-focused sales role \n Experience in cold-calling and early-stage pipeline building \n Strong background as an elite competitive swimmer or competitive swimming coach \n Highly motivated and target-driven with a proven track record in exceeding KPIs \n Strong verbal and written communication skills \n Working knowledge of sales techniques and sales performance metrics \n Proficiency with data analysis, forecasting, and budgeting \n \n \n \n \n \n \n \n \n \n \n Digital  \n Software Architect  \n Toronto - Remote Full Time  \n \n \n \n \n \n About Us \n  At TritonWear, we are the #1 swimming analytics platform helping coaches coach better, and swimmers swim faster. Our patented wearable devices and AI-coaching tools guide swim teams on precisely what they need to do to improve. We\u2019ve started with the swimming vertical and will continue to focus here until we exhaust the market and perfect our offering. However, the long-term vision is to utilize our AI-coaching platform to consume data collected by any wearable and provide much-needed feedback to athletes across any sport. \n  Using swimming as our $16B beachhead into the market, our products are being used by thousands of athletes globally in over 60 countries ranging from grassroots beginners up to Olympic Gold Medalists \u2013 including 30+ National Olympic Federations heading into the Tokyo 2024 Olympics. \n  TritonWear is an established startup backed by top-tier Canadian VC firms. We have experienced strong growth, including being recognized as one of the CIX Top 20 Companies in Canada. Our passionate and highly experienced team of former coaches and competitive athletes, as well as product experts, is headquartered out of Toronto, ON, but dispersed throughout North America. \n  About You \n  Are you a passionate Software Architect experienced in building and scaling complex platforms? Join our team if you have a love for sports and sports science, with bonus points if you enjoy swimming. As a customer-first product person, you take pride in delivering world-class solutions. With exceptional communication skills, you thrive in collaborative environments. As a strong coach and mentor, you're dedicated to growing your team and the company. In a fast-paced startup setting, you excel in agile environments. Join us to make a remarkable impact in the sports technology world. \n  About The Role \n  We're seeking an experienced Software Architect to help shape the future of our organization. As a visionary, you'll make high-level decisions that drive our software development and create innovative architectural approaches. Delivering a world-class software experience for our users is your primary focus, fueling usage, retention, and expansion. Working closely with our leadership team, you'll develop software strategies aligned with our business objectives, ensuring we stay ahead. As a vital member of the TritonWear leadership team, you'll have a voice at the table and the responsibility of delivering a world-class product. Managing and training our development team, you'll execute your plan to perfection including planning and executing sprints on schedule. If you're ready to shape industry-leading software and inspire a skilled team, join us at TritonWear and define the future. \n  Responsibilities: \n \n Lead software solution design, development, and execution to maintain our industry-leading status   \n Provide technical leadership and architectural blueprints to the Digital Team   \n Collaborate with R&D, Growth, QA, and end users for cutting-edge software solutions   \n Translate business requirements into actionable tasks and address business needs   \n Assess and recommend tools, technologies, and processes for a high-quality product platform   \n Define technology, workflow, and coding standards for development   \n Manage and train front-end developers, backend developers, and QA resources   \n Communicate concepts and guidelines effectively to the development team   \n Troubleshoot code-level problems quickly and efficiently   \n Monitor development progress for alignment with the initial design   \n Ensure compliance with quality, security, and software requirements   \n Finalize product approval before launch   \n \n Requirements: \n \n M.A.Sc./M.Eng in Software Engineering or equivalent   \n Proven experience as software architect: Experience working on complex software projects with a track record and proven ability to build and manage a full platform   \n Outstanding communication and presentation abilities   \n 3+ years leading software teams   \n 10+ years of experience in Javascript   \n 5+ years of experience in Typescript   \n 5+ years AWS including microservices, email services, database design and execution, and SQL experience   \n 5+ years developing native Android / iOS   \n 2+ years of experience interfacing apps with BLE hardware   \n \n Nice to have skills: \n \n Experience in algorithm development/implementation   \n Data Science / Analytics experience   \n A huge sports enthusiast with experience in sports science and an interest in improving athletic performance using data - a big plus if you used to be a competitive swimmer!   \n An understanding of machine learning concepts, theories and algorithms   \n Google Analytics 4 experience   \n Produce 1st party advertising data sets   \n \n Our stack \n \n Infrastructure - AWS (EC2, RDS, S3, SQS, Lambda)   \n Front End - AngularJS, React   \n Back End - Node, Python   \n Database - MySQL   \n Mobile - Hybrid (Ionic), Native (iOS / Android) \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Business Development Specialist \n \n \n \n \n About you \n  You have a deep background in competitive swimming as an athlete and/or coach and are experienced in selling to Competitive Swim Teams. You love sales and thrive in a fast-paced growth environment.    You are ambitious, charismatic, and organized. You are competitive by nature and thrive on exceeding targets. You enjoy a good challenge and are creative in finding new ways to hunt for new prospects and business. You love making new friends and building relationships quickly to help broaden your network and strengthen your trust in the global swimming community.    Finally, you are passionate about start-up growth, love autonomy, and thrive as a self-starter. You know you can help over-deliver on team sales leads, which is crucial to crushing TritonWear\u2019s growth targets. You also are hungry for self-growth and have a palpable personal goal of becoming a seasoned sales professional. \n \n  About the Role \n  As a Business Development Specialist at TritonWear, you will extend our global reach through expert discovery and exploration of new and untapped business opportunities and relationships.    In this role, you will be prospecting all levels of teams within your assigned territory, including Clubs, YMCAs, High Schools, and Colleges or Universities. You will work through our CRM and with our Team Sales Managers to strategically target outbound leads. Finding creative ways to build a high-quality lead pool is critical to achieving your lead handover targets.    This remote role offers the freedom to chase leads virtually, in-field, at conferences, or in any other way proven to drive the best results. Highly skilled in sales and business operations, this person will join and inspire a team of like-minded go-getters to achieve our company vision. At TritonWear, we strongly believe in the value of mentorship and skill development, so we are looking for a candidate who wants to grow into more senior sales roles. \n  Responsibilities \n \n Identify trends and customer needs, building a short/medium/long-term sales pipeline based on target numbers \n Generate new leads, identify and contact decision-makers, screen potential business opportunities and hand off qualified leads for closing \n Build outbound pipeline through personal network activation activities, including strategic calling, networking and social media \n Run a tight sales process to build a healthy pipeline \n Prepare and present reports on lead generation targets detailing weekly, monthly, quarterly and annual progress \n Prepare and deliver appropriate documentation and presentations on products and services \n Identify, present, and develop \u201cout of the box\u201d sales strategies/models and evaluate their effectiveness \n Maintain and share professional knowledge through education, networking, events, and presentations \n \n Requirements \n \n 1+ Years in a growth-focused sales role \n Experience in cold-calling and early-stage pipeline building \n Strong background as an elite competitive swimmer or competitive swimming coach \n Highly motivated and target-driven with a proven track record in exceeding KPIs \n Strong verbal and written communication skills \n Working knowledge of sales techniques and sales performance metrics \n Proficiency with data analysis, forecasting, and budgeting",
        "cleaned_desc": " \n Identify trends and customer needs, building a short/medium/long-term sales pipeline based on target numbers \n Generate new leads, identify and contact decision-makers, screen potential business opportunities and hand off qualified leads for closing \n Build outbound pipeline through personal network activation activities, including strategic calling, networking and social media \n Run a tight sales process to build a healthy pipeline \n Prepare and present reports on lead generation targets detailing weekly, monthly, quarterly and annual progress \n Prepare and deliver appropriate documentation and presentations on products and services \n Identify, present, and develop \u201cout of the box\u201d sales strategies/models and evaluate their effectiveness \n Maintain and share professional knowledge through education, networking, events, and presentations \n \n Requirements \n \n 1+ Years in a growth-focused sales role \n Experience in cold-calling and early-stage pipeline building \n Strong background as an elite competitive swimmer or competitive swimming coach \n Highly motivated and target-driven with a proven track record in exceeding KPIs \n Strong verbal and written communication skills \n Working knowledge of sales techniques and sales performance metrics \n Proficiency with data analysis, forecasting, and budgeting \n \n \n \n \n \n \n \n \n \n \n Digital  \n Software Architect  \n Toronto - Remote Full Time  \n \n \n \n \n \n About Us \n  At TritonWear, we are the #1 swimming analytics platform helping coaches coach better, and swimmers swim faster. Our patented wearable devices and AI-coaching tools guide swim teams on precisely what they need to do to improve. We\u2019ve started with the swimming vertical and will continue to focus here until we exhaust the market and perfect our offering. However, the long-term vision is to utilize our AI-coaching platform to consume data collected by any wearable and provide much-needed feedback to athletes across any sport. \n  Using swimming as our $16B beachhead into the market, our products are being used by thousands of athletes globally in over 60 countries ranging from grassroots beginners up to Olympic Gold Medalists \u2013 including 30+ National Olympic Federations heading into the Tokyo 2024 Olympics. \n  TritonWear is an established startup backed by top-tier Canadian VC firms. We have experienced strong growth, including being recognized as one of the CIX Top 20 Companies in Canada. Our passionate and highly experienced team of former coaches and competitive athletes, as well as product experts, is headquartered out of Toronto, ON, but dispersed throughout North America. \n  About You \n  Are you a passionate Software Architect experienced in building and scaling complex platforms? Join our team if you have a love for sports and sports science, with bonus points if you enjoy swimming. As a customer-first product person, you take pride in delivering world-class solutions. With exceptional communication skills, you thrive in collaborative environments. As a strong coach and mentor, you're dedicated to growing your team and the company. In a fast-paced startup setting, you excel in agile environments. Join us to make a remarkable impact in the sports technology world. \n  About The Role \n  We're seeking an experienced Software Architect to help shape the future of our organization. As a visionary, you'll make high-level decisions that drive our software development and create innovative architectural approaches. Delivering a world-class software experience for our users is your primary focus, fueling usage, retention, and expansion. Working closely with our leadership team, you'll develop software strategies aligned with our business objectives, ensuring we stay ahead. As a vital member of the TritonWear leadership team, you'll have a voice at the table and the responsibility of delivering a world-class product. Managing and training our development team, you'll execute your plan to perfection including planning and executing sprints on schedule. If you're ready to shape industry-leading software and inspire a skilled team, join us at TritonWear and define the future. \n  Responsibilities: \n \n Lead software solution design, development, and execution to maintain our industry-leading status   \n Provide technical leadership and architectural blueprints to the Digital Team   \n Collaborate with R&D, Growth, QA, and end users for cutting-edge software solutions   \n Translate business requirements into actionable tasks and address business needs   \n Assess and recommend tools, technologies, and processes for a high-quality product platform   \n Define technology, workflow, and coding standards for development   \n Manage and train front-end developers, backend developers, and QA resources   \n Communicate concepts and guidelines effectively to the development team   \n Troubleshoot code-level problems quickly and efficiently   \n Monitor development progress for alignment with the initial design   \n Ensure compliance with quality, security, and software requirements   \n Finalize product approval before launch   \n \n Requirements: \n \n M.A.Sc./M.Eng in Software Engineering or equivalent   \n Proven experience as software architect: Experience working on complex software projects with a track record and proven ability to build and manage a full platform   \n Outstanding communication and presentation abilities   \n 3+ years leading software teams   \n 10+ years of experience in Javascript   \n 5+ years of experience in Typescript   \n 5+ years AWS including microservices, email services, database design and execution, and SQL experience   ",
        "techs": [
            "none"
        ],
        "cleaned_techs": []
    },
    "2c026534cfc8d80f": {
        "terms": [
            "data science"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Director of Product Management",
        "company": "Raytheon Technologies Corporate Headquarters",
        "desc": "Date Posted:  2023-06-21\n   Country:  United States of America\n   Location:  UTNY1: UT-NY-Remote Remote Location, Remote City, NY, 10001 USA\n   Position Role Type:  Remote\n   RTX Corporation is an Aerospace and Defense company that provides advanced systems and services for commercial, military and government customers worldwide. It comprises three industry-leading businesses \u2013 Collins Aerospace Systems, Pratt & Whitney, and Raytheon. Its 185,000 employees enable the company to operate at the edge of known science as they imagine and deliver solutions that push the boundaries in quantum physics, electric propulsion, directed energy, hypersonics, avionics and cybersecurity. The company, formed in 2020 through the combination of Raytheon Company and the United Technologies Corporation aerospace businesses, is headquartered in Arlington, VA. \n \n  To realize our full potential, RTX is committed to creating a company where all employees are respected, valued and supported in the pursuit of their goals. We know companies that embrace diversity in all its forms not only deliver stronger business results, but also become a force for good, fueling stronger business performance and greater opportunity for employees, partners, investors and communities to succeed. \n \n  The following position is to join our RTX Corporate, Enterprise Services, Research Center or BBN team: \n  Director of Product Management \u2013 Enterprise Data Services (EDX) \n \n  Overview: \n  We are seeking a Product Management leader to oversee and grow the Product Management team within RTX\u2019s Enterprise Data Services unit (\u2018the EDX\u2019). In addition to serving as the day-to-day Director of the discipline, this leader will also drive the roadmap and business outcomes for Xeta, RTX\u2019s suite of enterprise productivity tools. \n \n  Xeta comprises three tools that deliver critical capabilities to RTX\u2019s teams. XetaAnalytics is RTX\u2019s enterprise data platform, which provides data practitioners (business analysts, data scientists) easy access to data management and analysis capabilities while also accelerating time-to-insight for RTX\u2019s decision makers. XetaDev is RTX\u2019s DevSecOps offering, providing software development teams with the tools they need to release high-quality code faster. Xeta Cloud is RTX\u2019s enterprise cloud offering; moving to the cloud is a major component of RTX\u2019s Digital Transformation strategy. While this role will primarily focus on product management oversight for XetaAnalytics, this leader will also lead the effort to harmonize the user experience across all three components of the Xeta portfolio. \n \n  The role will require deep and effective collaboration with leaders from the EDX\u2019s other disciplines: Design, Program Management, Software Engineering, and Applied Data. \n \n  Raytheon Technologies is in the midst of a multi-year digital and data transformation. In addition to responsibilities at the EDX, this role will entail engagement with executive stakeholders and leaders from across our business units. As the Director of Product Management, you will evangelize a \u2018product mindset\u2019 across the enterprise, helping business leaders appreciate the business value of contemporary product development frameworks centered on continuous product optimization. \n \n  Reporting to the VP of Data, Strategy & Products, the successful candidate will have strong communication skills, a passion for mentoring and growing a team, and the ability to navigate the complexities of a large, Fortune 50 global enterprise. \n \n  Job Responsibilities: \n \n  Ensure that the XetaAnalytics platform and other EDX products deliver business outcomes that align with Raytheon Technologies\u2019 overall business strategy. \n \n \n  Work across EDX teams and stakeholders to continuously evolve the vision for XetaAnalytics to strengthen stakeholder support and buy-in. \n  Lead the harmonization of the user experience across the Xeta Portolio (XetaAnalytics, XetaDev, XetaCloud). \n  Drive collaboration across the EDX disciplines to achieve alignment on the XetaAnalytics vision and roadmap. \n  Lead the definition and execution of the go-to-market strategy for XetaAnalytics with the intent of driving adoption and accelerating business outcomes. \n  Oversee the EDX\u2019s Product Management team, providing mentoring to all members and helping them chart a course for their own professional development. \n  Establish best practices and set standards for all product management deliverables including product visions, product roadmaps, backlog prioritization, measurement strategies, go-to-market strategies, and ROI projections and analysis. \n \n \n  Basic Qualifications: \n \n  15+ years of experience in software product development. \n  An established leader with a proven track record of leading teams and influencing executive decision makers. \n  Significant experience with modern data platforms: setting the platform vision and scaling up to achieve the desired business value. \n  Given that XetaAnalytics incorporates several COTS tools, deep familiarity with applications such as Databricks, Snowflake, Kobai, Jupyter, is required. \n  Expertise in practices related to understanding customer needs and market opportunity including user interviews, observational research, surveys, prototype testing, A/B testing, and opportunity sizing. \n  Expertise in Agile software delivery practices and expectations. \n \n \n  Proven ability to translate market and user needs into product strategies that deliver target business outcomes. \n  Expert working knowledge of financial analysis methodologies, including NPV, IRR, ROI and cash flow. \n  Experience with building business cases for multi-year investments in enterprise platforms and software products. \n  Ability to communicate clearly and effectively to influence multi-disciplinary teams and develop strong partnerships across functions to drive measurable operational results. \n  U.S. citizenship is required, as only U.S. citizens are authorized to access information under this program/contract. \n \n \n  Preferred Qualifications: \n \n  Possesses strong interpersonal skills to interact effectively at all levels within the company. \n  Ability to excel in a fast-paced and entrepreneurial environment with high degree of autonomy and accountability. \n  Ideal candidate is a highly technical, collaborative, detail-oriented, reliable individual who strives to deliver the highest quality products. \n  Experience within the Aerospace and Defense industry a plus. \n \n \n  Location: \n \n  Hybrid (preferred) or fully Remote options available for this role. \n \n  (Candidates local to the greater New York office will be expected to support a Hybrid work arrangement working both onsite and offsite as needed.) \n \n  Education: \n \n  Bachelor's degree in a related discipline. \n  Advanced degree in Computer Science or Data Science is a plus. \n  MBA is a plus. \n \n \n  Typically requires: \n \n  A University Degree or equivalent experience and minimum 14 years prior relevant experience, or An Advanced Degree in a related field and minimum 12 years\u2019 experience. \n \n \n  Engineering/Other Technical Positions:  \n \n Typically requires a degree in Science, Technology, Engineering or Mathematics (STEM) and a minimum of 14 years of prior relevant experience unless prohibited by local laws/regulations. \n \n \n  Requires: \n \n  Advanced business knowledge, general management and \n \n  leadership capability to lead business or functional teams. \n  The salary range for this role is 165,000 USD - 331,000 USD; however, Raytheon Technologies considers several factors when extending an offer, including but not limited to, the role and associated responsibilities, a candidate\u2019s work experience, location, education/training, and key skills. Hired applicants may be eligible for benefits, including but not limited to, medical, dental, vision, life insurance, short-term disability, long-term disability, 401(k) match, flexible spending accounts, flexible work schedules, employee assistance program, Employee Scholar Program, parental leave, paid time off, and holidays. Specific benefits are dependent upon the specific business unit as well as whether or not the position is covered by a collective-bargaining agreement. Hired applicants may be eligible for annual short-term and/or long-term incentive compensation programs depending on the level of the position and whether or not it is covered by a collective-bargaining agreement. Payments under these annual programs are not guaranteed and are dependent upon a variety of factors including, but not limited to, individual performance, business unit performance, and/or the company\u2019s performance.\n   RTX is An Equal  Opportunity/Affirmative  Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status, age or any other federally protected class. \n  Privacy Policy and Terms: \n  Click on this link to read the Policy and Terms",
        "cleaned_desc": " \n  15+ years of experience in software product development. \n  An established leader with a proven track record of leading teams and influencing executive decision makers. \n  Significant experience with modern data platforms: setting the platform vision and scaling up to achieve the desired business value. \n  Given that XetaAnalytics incorporates several COTS tools, deep familiarity with applications such as Databricks, Snowflake, Kobai, Jupyter, is required. \n  Expertise in practices related to understanding customer needs and market opportunity including user interviews, observational research, surveys, prototype testing, A/B testing, and opportunity sizing. \n  Expertise in Agile software delivery practices and expectations. \n \n \n  Proven ability to translate market and user needs into product strategies that deliver target business outcomes. \n  Expert working knowledge of financial analysis methodologies, including NPV, IRR, ROI and cash flow. \n  Experience with building business cases for multi-year investments in enterprise platforms and software products. \n  Ability to communicate clearly and effectively to influence multi-disciplinary teams and develop strong partnerships across functions to drive measurable operational results. \n  U.S. citizenship is required, as only U.S. citizens are authorized to access information under this program/contract. \n \n \n  Preferred Qualifications: \n ",
        "techs": [
            "databricks",
            "snowflake",
            "kobai",
            "jupyter"
        ],
        "cleaned_techs": [
            "databricks",
            "snowflake",
            "kobai",
            "jupyter"
        ]
    },
    "3f745a3ea04acaab": {
        "terms": [
            "data science"
        ],
        "salary_min": 120363.016,
        "salary_max": 152406.39,
        "title": "Deep Learning Engineer",
        "company": "Cyberjin",
        "desc": "Hybrid/Remote role \n  Multiple Locations \n  We're looking for a Deep Learning Engineer to join us as part of the founding engineering team. You will have the opportunity to work closely with the CEO to build new features and roll out new products - all in the deep learning on mobile space. \n \n  Ideal candidate traits \n  Enjoys significant ownership over user-facing product \n  \u200d Can work independently \n  Is comfortable turning research papers into product \n  Has 2 - 10 years experience with deep learning or has a PhD in a STEM field \n  Builds with a product-first approach. You ship code quickly and care about the real world impact of your code. \n  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred \n   \n owsC5Yyyj1",
        "cleaned_desc": "  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred ",
        "techs": [
            "python",
            "deep learning",
            "tensorflow"
        ],
        "cleaned_techs": [
            "python",
            "tensorflow"
        ]
    },
    "96b157c2c406383e": {
        "terms": [
            "data science"
        ],
        "salary_min": 120363.016,
        "salary_max": 152406.39,
        "title": "Deep Learning Engineer",
        "company": "Cyberjin",
        "desc": "Hybrid/Remote role \n  Locations in multiple States \n  We're looking for a Deep Learning Engineer to join Dyneti as part of the founding engineering team. You will have the opportunity to work closely with the CEO to build new features and roll out new products - all in the deep learning on mobile space. \n \n  Ideal candidate traits \n  Enjoys significant ownership over user-facing product \n  \u200d Can work independently \n  Is comfortable turning research papers into product \n  Has 2 - 10 years experience with deep learning or has a PhD in a STEM field \n  Builds with a product-first approach. You ship code quickly and care about the real world impact of your code. \n  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred \n   \n qiBU6ZmDFz",
        "cleaned_desc": "  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred ",
        "techs": [
            "python",
            "deep learning",
            "tensorflow"
        ],
        "cleaned_techs": [
            "python",
            "tensorflow"
        ]
    },
    "8c2d8bd464c9e1f8": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 110000.0,
        "salary_max": 120000.0,
        "title": "Sr. AWS Data Engineer (Remote)",
        "company": "Cognizant Technology Solutions",
        "desc": "We are Cognizant Artificial Intelligence \n  Digital technologies, including analytics and AI, give companies a once-in-a-generation opportunity to perform orders of magnitude better than ever before. But clients need new business models built from analyzing customers and business operations at every angle to really understand them. \n  With the power to apply artificial intelligence and data science to business decisions via enterprise data management solutions, we help leading companies prototype, refine, validate and scale the most desirable products and delivery models to enterprise scale within weeks \n \n \n  Role and Responsibilities: \n \n 5+ years of industry experience in software development data engineering or a related field with a solid track record of building services for manipulating processing datasets \n Hands-on experience and advanced knowledge of AWS DataOps (i.e. IAM Lambda Step Functions EMR/Glue and DynamoDB) \n Hands-on experience and advanced knowledge of SQL/Non-relational Data Modeling \n Experience working with data streaming technologies (Kafka Spark Streaming etc.) \n \n \n Designing and implementing complex ingestion and processing pipelines through orchestration \n Design and implement API interfaces for engineering teams to interact with ingestion/processing pipelines \n Design implement and support scalable multi-tenant service and data infrastructure solutions to integrate with multi heterogeneous data sources aggregate and retrieve data in a fast and secure mode curate data that can be used in reporting analysis machine learning models and ad-hoc data requests \n Interface with other engineering and ML teams to extract transform and load data from a wide variety of data sources \n Work with business product owners to understand gather and analyze their processing and extraction needs to solve problems \n \n \n \n  Salary and Other Compensation \n  The annual salary for this position is between USD ($110kp/a \u2013 $120kp/a) depending on experience and other qualifications of the successful candidate. \n  This position is also eligible for Cognizant\u2019s discretionary annual incentive program, based on performance and subject to the terms of Cognizant\u2019s applicable plans. \n  Benefits: Cognizant offers the following benefits for this position, subject to applicable eligibility requirements: \n \n Medical/Dental/Vision/Life Insurance \n Paid holidays plus Paid Time Off \n 401(k) plan and contributions \n Long-term/Short-term Disability \n Paid Parental Leave \n Employee Stock Purchase Plan \n \n Disclaimer: The salary, other compensation, and benefits information is accurate as of the date of this posting. Cognizant reserves the right to modify this information at any time, subject to applicable law. \n \n \n  #LI-JL1 \n  #CB \n  #IND123 \n \n  Employee Status :  Full Time Employee \n  Shift :  Day Job \n  Travel :  No \n  Job Posting :  Oct 17 2023 \n \n \n  About Cognizant \n  Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @USJobsCognizant.\n  \n  Applicants may be required to attend interviews in person or by video conference. In addition, candidates may be required to present their current state or government issued ID during each interview. \n \n  Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law. \n  If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, please email CareersNA2@cognizant.com with your request and contact information.",
        "cleaned_desc": "We are Cognizant Artificial Intelligence \n  Digital technologies, including analytics and AI, give companies a once-in-a-generation opportunity to perform orders of magnitude better than ever before. But clients need new business models built from analyzing customers and business operations at every angle to really understand them. \n  With the power to apply artificial intelligence and data science to business decisions via enterprise data management solutions, we help leading companies prototype, refine, validate and scale the most desirable products and delivery models to enterprise scale within weeks \n \n \n  Role and Responsibilities: \n \n 5+ years of industry experience in software development data engineering or a related field with a solid track record of building services for manipulating processing datasets \n Hands-on experience and advanced knowledge of AWS DataOps (i.e. IAM Lambda Step Functions EMR/Glue and DynamoDB) \n Hands-on experience and advanced knowledge of SQL/Non-relational Data Modeling   Experience working with data streaming technologies (Kafka Spark Streaming etc.) \n \n \n Designing and implementing complex ingestion and processing pipelines through orchestration \n Design and implement API interfaces for engineering teams to interact with ingestion/processing pipelines \n Design implement and support scalable multi-tenant service and data infrastructure solutions to integrate with multi heterogeneous data sources aggregate and retrieve data in a fast and secure mode curate data that can be used in reporting analysis machine learning models and ad-hoc data requests \n Interface with other engineering and ML teams to extract transform and load data from a wide variety of data sources \n Work with business product owners to understand gather and analyze their processing and extraction needs to solve problems \n \n ",
        "techs": [
            "cognizant artificial intelligence",
            "analytics",
            "ai",
            "business models",
            "enterprise data management solutions",
            "artificial intelligence",
            "data science",
            "aws dataops",
            "iam",
            "lambda",
            "step functions",
            "emr",
            "glue",
            "dynamodb",
            "sql",
            "non-relational data modeling",
            "data streaming technologies",
            "kafka",
            "spark streaming",
            "complex ingestion pipelines",
            "processing pipelines",
            "orchestration",
            "api interfaces",
            "scalable multi-tenant service",
            "data infrastructure solutions",
            "multi heterogeneous data sources",
            "reporting analysis",
            "machine learning models",
            "ad-hoc data requests",
            "engineering teams",
            "ml teams",
            "wide variety of data sources",
            "business product owners"
        ],
        "cleaned_techs": [
            "cognizant artificial intelligence",
            "ai",
            "business models",
            "enterprise data management solutions",
            "data science",
            "aws",
            "iam",
            "lambda",
            "step functions",
            "emr",
            "glue",
            "dynamodb",
            "sql",
            "non-relational data modeling",
            "data streaming technologies",
            "kafka",
            "spark streaming",
            "complex ingestion pipelines",
            "processing pipelines",
            "orchestration",
            "api interfaces",
            "scalable multi-tenant service",
            "data infrastructure solutions",
            "multi heterogeneous data sources",
            "reporting analysis",
            "ad-hoc data requests",
            "engineering teams",
            "ml teams",
            "wide variety of data sources",
            "business product owners"
        ]
    },
    "1de819ce8dbdf2b5": {
        "terms": [
            "data science",
            "data engineer"
        ],
        "salary_min": 147500.0,
        "salary_max": 195000.0,
        "title": "Senior Data Engineer",
        "company": "Circle",
        "desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  As a member of the Data Engineering - Business ETL team, you own the ETL/ELT pipelines and data warehouse that is used for financial and regulatory reporting. Your work powers Circle business functions, including the Compliance, Finance, Accounting, and Analytics teams for experimentation, operational excellence, and actionable insights, so as to fuel and accelerate business growth. High integrity to data accuracy and quality is crucial. Your work will directly impact Circle's transparency, trust, and accountability needs. \n  What you'll work on: \n \n Collaborating with business teams on the design, deployment and continuous improvement of the scalable data platform that ingests, stores, and aggregates various datasets, including data pipelines, platforms, and warehouses, and surfacing data to both internal and customer-facing applications. \n Being a domain expert on data modeling, data pipelines, data quality and data warehousing. \n Designing, building and maintaining data ETL/ELT pipelines to source and aggregate the required data for various data analyses and reporting needs, as well as to continually improve the operations, monitoring and performance of the data warehouse. \n Developing integrations with third party systems to source, qualify and ingest various datasets. \n Providing data analytics and visualization tools to extract valuable insights from the data to enable data-driven decisions. \n Working closely with across groups, such as the product, engineering, data science, compliance, and security teams, for data modeling, general management of data life cycle, data governance and processes for meeting regulatory and legal requirements. \n \n You will aspire to our four core values: \n \n Multistakeholder - you have dedication and commitment to our customers, shareholders, employees and families and local communities. \n Mindful - you seek to be respectful, an active listener and to pay attention to detail. \n Driven by Excellence - you are driven by our mission and our passion for customer success which means you relentlessly pursue excellence, that you do not tolerate mediocrity and you work intensely to achieve your goals. \n High Integrity - you seek open and honest communication, and you hold yourself to very high moral and ethical standards. You reject manipulation, dishonesty and intolerance. \n \n What you'll bring to Circle: \n  For Senior Data Engineer (III) \n \n 4+ years of professional data engineering experience. \n Proficient in one or more programming languages (Java, Scala, Python). \n Advanced experience in SQL in big data warehouse systems such as Snowflake, BigQuery, Databricks, etc. \n Experience in SQL and NoSQL, such as MySQL, PostgreSQL, Cassandra, HBase, Redis, DynamoDB, Neo4j, etc. \n Experience with workflow orchestration management engines such as Airflow, Dagster, DBT, etc \n Experience with Cloud Services (AWS, Google Cloud, Microsoft Azure, etc). \n Experience in building scalable infrastructure to support batch, micro-batch or stream data processing for large volumes of data. \n Experience with financial or compliance data, bonus if in similar business domains, such as payment systems, credit cards, bank transfers, blockchains, etc. \n Experience in data provenance and governance. \n Internal knowledge of open source or related big data technologies. \n Ability to tackle complex and ambiguous problems. \n Self-starter who takes ownership, gets results, and enjoys moving at a fast pace. \n Excellent communication skills, able to collaborate with across remote teams, share ideas and present concepts effectively. \n \n For Staff Data Engineer (IV) \n  All the requirements of above and: \n \n 7+ years of professional data engineering experience. \n Led teams (>5) technically on architecture and system design. \n Expert in one of the domains of ETL/ELT pipelines, feature engineering, data modeling and architecture, or data ingestion. \n Experience working autonomously and able to identify large impactful projects to pursue with minimal guidance. \n Deep understanding/experience with: \n \n Data warehouse architecture and design \n Integration of the data stack to other tools/services \n Extensive knowledge with implementing data quality checks \n \n \n Additional Information: \n \n This position is eligible for day-one PERM sponsorship for qualified candidates. \n \n Circle is on a mission to create an inclusive financial future, with transparency at our core. We consider a wide variety of elements when crafting our compensation ranges and total compensation packages. \n  Starting pay is determined by various factors, including but not limited to: relevant experience, skill set, qualifications, and other business and organizational needs. Please note that compensation ranges may differ for candidates in other locations. \n  Senior Data Engineer (III) \n  Base Pay Range: $147,500 - $195,000 \n  Annual Bonus Target: 12.5% \n  Staff Data Engineer (IV) \n  Base Pay Range: $172,500 - $227,500 \n  Annual Bonus Target: 15% \n  Also Included: Equity & Benefits (including medical, dental, vision and 401(k)). Circle has a discretionary vacation policy. We also provide 10 days of paid sick leave per year and 11 paid holidays per year in the U.S. \n \n  We are an  equal opportunity employer  and value diversity at Circle. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Additionally, Circle participates in the  E-Verify Program  in certain locations, as required by law. \n  #LI-Remote",
        "cleaned_desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  As a member of the Data Engineering - Business ETL team, you own the ETL/ELT pipelines and data warehouse that is used for financial and regulatory reporting. Your work powers Circle business functions, including the Compliance, Finance, Accounting, and Analytics teams for experimentation, operational excellence, and actionable insights, so as to fuel and accelerate business growth. High integrity to data accuracy and quality is crucial. Your work will directly impact Circle's transparency, trust, and accountability needs. \n  What you'll work on: \n \n Collaborating with business teams on the design, deployment and continuous improvement of the scalable data platform that ingests, stores, and aggregates various datasets, including data pipelines, platforms, and warehouses, and surfacing data to both internal and customer-facing applications. \n Being a domain expert on data modeling, data pipelines, data quality and data warehousing. \n Designing, building and maintaining data ETL/ELT pipelines to source and aggregate the required data for various data analyses and reporting needs, as well as to continually improve the operations, monitoring and performance of the data warehouse. \n Developing integrations with third party systems to source, qualify and ingest various datasets. \n Providing data analytics and visualization tools to extract valuable insights from the data to enable data-driven decisions.   Proficient in one or more programming languages (Java, Scala, Python). \n Advanced experience in SQL in big data warehouse systems such as Snowflake, BigQuery, Databricks, etc. \n Experience in SQL and NoSQL, such as MySQL, PostgreSQL, Cassandra, HBase, Redis, DynamoDB, Neo4j, etc. \n Experience with workflow orchestration management engines such as Airflow, Dagster, DBT, etc \n Experience with Cloud Services (AWS, Google Cloud, Microsoft Azure, etc). \n Experience in building scalable infrastructure to support batch, micro-batch or stream data processing for large volumes of data. \n Experience with financial or compliance data, bonus if in similar business domains, such as payment systems, credit cards, bank transfers, blockchains, etc. \n Experience in data provenance and governance. \n Internal knowledge of open source or related big data technologies. \n Ability to tackle complex and ambiguous problems. \n Self-starter who takes ownership, gets results, and enjoys moving at a fast pace. \n Excellent communication skills, able to collaborate with across remote teams, share ideas and present concepts effectively. \n   For Staff Data Engineer (IV) \n  All the requirements of above and: \n \n 7+ years of professional data engineering experience. \n Led teams (>5) technically on architecture and system design. \n Expert in one of the domains of ETL/ELT pipelines, feature engineering, data modeling and architecture, or data ingestion. \n Experience working autonomously and able to identify large impactful projects to pursue with minimal guidance. \n Deep understanding/experience with: \n \n Data warehouse architecture and design \n Integration of the data stack to other tools/services \n Extensive knowledge with implementing data quality checks \n ",
        "techs": [
            "circle",
            "usdc",
            "blockchain-based dollar",
            "data engineering",
            "etl/elt pipelines",
            "data warehouse",
            "compliance",
            "finance",
            "accounting",
            "analytics",
            "data pipelines",
            "data modeling",
            "data quality",
            "data warehousing",
            "etl/elt pipelines",
            "third party systems",
            "data analytics",
            "visualization tools",
            "programming languages (java",
            "scala",
            "python)",
            "sql",
            "snowflake",
            "bigquery",
            "databricks",
            "mysql",
            "postgresql",
            "cassandra",
            "hbase",
            "redis",
            "dynamodb",
            "neo4j",
            "workflow orchestration management engines",
            "airflow",
            "dagster",
            "dbt",
            "cloud services (aws",
            "google cloud",
            "microsoft azure)",
            "batch processing",
            "micro-batch processing",
            "stream data processing",
            "financial data",
            "compliance data",
            "data provenance",
            "data governance",
            "open source big data technologies",
            "complex problem solving",
            "communication skills",
            "staff data engineer",
            "architecture and system design",
            "etl/elt pipelines",
            "feature engineering",
            "data modeling",
            "data ingestion",
            "data warehouse architecture and design",
            "data stack integration",
            "data quality checks"
        ],
        "cleaned_techs": [
            "circle",
            "usdc",
            "blockchain-based dollar",
            "etl/elt pipelines",
            "data warehouse",
            "compliance",
            "finance",
            "accounting",
            "data pipelines",
            "data quality",
            "data warehousing",
            "third party systems",
            "data analytics",
            "visualization tools",
            "programming languages (java",
            "scala",
            "python",
            "sql",
            "snowflake",
            "bigquery",
            "databricks",
            "mysql",
            "postgresql",
            "cassandra",
            "hbase",
            "redis",
            "dynamodb",
            "neo4j",
            "workflow orchestration management engines",
            "airflow",
            "dagster",
            "dbt",
            "cloud services (aws",
            "gcp",
            "microsoft azure)",
            "batch processing",
            "micro-batch processing",
            "stream data processing",
            "financial data",
            "compliance data",
            "data provenance",
            "data governance",
            "open source big data technologies",
            "complex problem solving",
            "staff data engineer",
            "architecture and system design",
            "feature engineering",
            "data ingestion",
            "data warehouse architecture and design",
            "data stack integration",
            "data quality checks"
        ]
    },
    "de7ac14b354056fb": {
        "terms": [
            "data science",
            "data engineer"
        ],
        "salary_min": 147500.0,
        "salary_max": 195000.0,
        "title": "Senior Data Engineer",
        "company": "Circle",
        "desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  As a member of the Data Engineering - Business ETL team, you own the ETL/ELT pipelines and data warehouse that is used for financial and regulatory reporting. Your work powers Circle business functions, including the Compliance, Finance, Accounting, and Analytics teams for experimentation, operational excellence, and actionable insights, so as to fuel and accelerate business growth. High integrity to data accuracy and quality is crucial. Your work will directly impact Circle's transparency, trust, and accountability needs. \n  What you'll work on: \n \n Collaborating with business teams on the design, deployment and continuous improvement of the scalable data platform that ingests, stores, and aggregates various datasets, including data pipelines, platforms, and warehouses, and surfacing data to both internal and customer-facing applications. \n Being a domain expert on data modeling, data pipelines, data quality and data warehousing. \n Designing, building and maintaining data ETL/ELT pipelines to source and aggregate the required data for various data analyses and reporting needs, as well as to continually improve the operations, monitoring and performance of the data warehouse. \n Developing integrations with third party systems to source, qualify and ingest various datasets. \n Providing data analytics and visualization tools to extract valuable insights from the data to enable data-driven decisions. \n Working closely with across groups, such as the product, engineering, data science, compliance, and security teams, for data modeling, general management of data life cycle, data governance and processes for meeting regulatory and legal requirements. \n \n You will aspire to our four core values: \n \n Multistakeholder - you have dedication and commitment to our customers, shareholders, employees and families and local communities. \n Mindful - you seek to be respectful, an active listener and to pay attention to detail. \n Driven by Excellence - you are driven by our mission and our passion for customer success which means you relentlessly pursue excellence, that you do not tolerate mediocrity and you work intensely to achieve your goals. \n High Integrity - you seek open and honest communication, and you hold yourself to very high moral and ethical standards. You reject manipulation, dishonesty and intolerance. \n \n What you'll bring to Circle: \n  For Senior Data Engineer (III) \n \n 4+ years of professional data engineering experience. \n Proficient in one or more programming languages (Java, Scala, Python). \n Advanced experience in SQL in big data warehouse systems such as Snowflake, BigQuery, Databricks, etc. \n Experience in SQL and NoSQL, such as MySQL, PostgreSQL, Cassandra, HBase, Redis, DynamoDB, Neo4j, etc. \n Experience with workflow orchestration management engines such as Airflow, Dagster, DBT, etc \n Experience with Cloud Services (AWS, Google Cloud, Microsoft Azure, etc). \n Experience in building scalable infrastructure to support batch, micro-batch or stream data processing for large volumes of data. \n Experience with financial or compliance data, bonus if in similar business domains, such as payment systems, credit cards, bank transfers, blockchains, etc. \n Experience in data provenance and governance. \n Internal knowledge of open source or related big data technologies. \n Ability to tackle complex and ambiguous problems. \n Self-starter who takes ownership, gets results, and enjoys moving at a fast pace. \n Excellent communication skills, able to collaborate with across remote teams, share ideas and present concepts effectively. \n \n For Staff Data Engineer (IV) \n  All the requirements of above and: \n \n 7+ years of professional data engineering experience. \n Led teams (>5) technically on architecture and system design. \n Expert in one of the domains of ETL/ELT pipelines, feature engineering, data modeling and architecture, or data ingestion. \n Experience working autonomously and able to identify large impactful projects to pursue with minimal guidance. \n Deep understanding/experience with: \n \n Data warehouse architecture and design \n Integration of the data stack to other tools/services \n Extensive knowledge with implementing data quality checks \n \n \n Additional Information: \n \n This position is eligible for day-one PERM sponsorship for qualified candidates. \n \n Circle is on a mission to create an inclusive financial future, with transparency at our core. We consider a wide variety of elements when crafting our compensation ranges and total compensation packages. \n  Starting pay is determined by various factors, including but not limited to: relevant experience, skill set, qualifications, and other business and organizational needs. Please note that compensation ranges may differ for candidates in other locations. \n  Senior Data Engineer (III) \n  Base Pay Range: $147,500 - $195,000 \n  Annual Bonus Target: 12.5% \n  Staff Data Engineer (IV) \n  Base Pay Range: $172,500 - $227,500 \n  Annual Bonus Target: 15% \n  Also Included: Equity & Benefits (including medical, dental, vision and 401(k)). Circle has a discretionary vacation policy. We also provide 10 days of paid sick leave per year and 11 paid holidays per year in the U.S. \n \n  We are an  equal opportunity employer  and value diversity at Circle. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Additionally, Circle participates in the  E-Verify Program  in certain locations, as required by law. \n  #LI-Remote",
        "cleaned_desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  As a member of the Data Engineering - Business ETL team, you own the ETL/ELT pipelines and data warehouse that is used for financial and regulatory reporting. Your work powers Circle business functions, including the Compliance, Finance, Accounting, and Analytics teams for experimentation, operational excellence, and actionable insights, so as to fuel and accelerate business growth. High integrity to data accuracy and quality is crucial. Your work will directly impact Circle's transparency, trust, and accountability needs. \n  What you'll work on: \n \n Collaborating with business teams on the design, deployment and continuous improvement of the scalable data platform that ingests, stores, and aggregates various datasets, including data pipelines, platforms, and warehouses, and surfacing data to both internal and customer-facing applications. \n Being a domain expert on data modeling, data pipelines, data quality and data warehousing. \n Designing, building and maintaining data ETL/ELT pipelines to source and aggregate the required data for various data analyses and reporting needs, as well as to continually improve the operations, monitoring and performance of the data warehouse. \n Developing integrations with third party systems to source, qualify and ingest various datasets. \n Providing data analytics and visualization tools to extract valuable insights from the data to enable data-driven decisions.   Proficient in one or more programming languages (Java, Scala, Python). \n Advanced experience in SQL in big data warehouse systems such as Snowflake, BigQuery, Databricks, etc. \n Experience in SQL and NoSQL, such as MySQL, PostgreSQL, Cassandra, HBase, Redis, DynamoDB, Neo4j, etc. \n Experience with workflow orchestration management engines such as Airflow, Dagster, DBT, etc \n Experience with Cloud Services (AWS, Google Cloud, Microsoft Azure, etc). \n Experience in building scalable infrastructure to support batch, micro-batch or stream data processing for large volumes of data. \n Experience with financial or compliance data, bonus if in similar business domains, such as payment systems, credit cards, bank transfers, blockchains, etc. \n Experience in data provenance and governance. \n Internal knowledge of open source or related big data technologies. \n Ability to tackle complex and ambiguous problems. \n Self-starter who takes ownership, gets results, and enjoys moving at a fast pace. \n Excellent communication skills, able to collaborate with across remote teams, share ideas and present concepts effectively. \n   For Staff Data Engineer (IV) \n  All the requirements of above and: \n \n 7+ years of professional data engineering experience. \n Led teams (>5) technically on architecture and system design. \n Expert in one of the domains of ETL/ELT pipelines, feature engineering, data modeling and architecture, or data ingestion. \n Experience working autonomously and able to identify large impactful projects to pursue with minimal guidance. \n Deep understanding/experience with: \n \n Data warehouse architecture and design \n Integration of the data stack to other tools/services \n Extensive knowledge with implementing data quality checks \n ",
        "techs": [
            "circle",
            "usdc",
            "blockchain-based dollar",
            "data engineering",
            "etl/elt pipelines",
            "data warehouse",
            "financial reporting",
            "compliance",
            "finance",
            "accounting",
            "analytics",
            "data platform",
            "data modeling",
            "data quality",
            "data warehousing",
            "data etl/elt pipelines",
            "third party systems",
            "data analytics",
            "data visualization",
            "programming languages (java",
            "scala",
            "python)",
            "sql",
            "big data warehouse systems (snowflake",
            "bigquery",
            "databricks)",
            "sql and nosql databases (mysql",
            "postgresql",
            "cassandra",
            "hbase",
            "redis",
            "dynamodb",
            "neo4j)",
            "workflow orchestration management engines (airflow",
            "dagster",
            "dbt)",
            "cloud services (aws",
            "google cloud",
            "microsoft azure)",
            "batch processing",
            "micro-batch processing",
            "stream processing",
            "financial data",
            "compliance data",
            "data provenance",
            "data governance",
            "open source technologies",
            "big data technologies",
            "complex problem-solving",
            "communication skills."
        ],
        "cleaned_techs": [
            "circle",
            "usdc",
            "blockchain-based dollar",
            "etl/elt pipelines",
            "data warehouse",
            "financial reporting",
            "compliance",
            "finance",
            "accounting",
            "data platform",
            "data quality",
            "data warehousing",
            "data etl/elt pipelines",
            "third party systems",
            "data analytics",
            "data visualization",
            "programming languages (java",
            "scala",
            "python",
            "sql",
            "big data warehouse systems (snowflake",
            "bigquery",
            "databricks)",
            "postgresql",
            "cassandra",
            "hbase",
            "redis",
            "dynamodb",
            "neo4j)",
            "workflow orchestration management engines (airflow",
            "dagster",
            "dbt)",
            "cloud services (aws",
            "gcp",
            "microsoft azure)",
            "batch processing",
            "micro-batch processing",
            "stream processing",
            "financial data",
            "compliance data",
            "data provenance",
            "data governance",
            "open source technologies",
            "big data technologies",
            "complex problem-solving"
        ]
    },
    "5a5515f8db0ad214": {
        "terms": [
            "data science",
            "data engineer"
        ],
        "salary_min": 147500.0,
        "salary_max": 195000.0,
        "title": "Senior Data Engineer",
        "company": "Circle",
        "desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  As a member of the Data Engineering - Business ETL team, you own the ETL/ELT pipelines and data warehouse that is used for financial and regulatory reporting. Your work powers Circle business functions, including the Compliance, Finance, Accounting, and Analytics teams for experimentation, operational excellence, and actionable insights, so as to fuel and accelerate business growth. High integrity to data accuracy and quality is crucial. Your work will directly impact Circle's transparency, trust, and accountability needs. \n  What you'll work on: \n \n Collaborating with business teams on the design, deployment and continuous improvement of the scalable data platform that ingests, stores, and aggregates various datasets, including data pipelines, platforms, and warehouses, and surfacing data to both internal and customer-facing applications. \n Being a domain expert on data modeling, data pipelines, data quality and data warehousing. \n Designing, building and maintaining data ETL/ELT pipelines to source and aggregate the required data for various data analyses and reporting needs, as well as to continually improve the operations, monitoring and performance of the data warehouse. \n Developing integrations with third party systems to source, qualify and ingest various datasets. \n Providing data analytics and visualization tools to extract valuable insights from the data to enable data-driven decisions. \n Working closely with across groups, such as the product, engineering, data science, compliance, and security teams, for data modeling, general management of data life cycle, data governance and processes for meeting regulatory and legal requirements. \n \n You will aspire to our four core values: \n \n Multistakeholder - you have dedication and commitment to our customers, shareholders, employees and families and local communities. \n Mindful - you seek to be respectful, an active listener and to pay attention to detail. \n Driven by Excellence - you are driven by our mission and our passion for customer success which means you relentlessly pursue excellence, that you do not tolerate mediocrity and you work intensely to achieve your goals. \n High Integrity - you seek open and honest communication, and you hold yourself to very high moral and ethical standards. You reject manipulation, dishonesty and intolerance. \n \n What you'll bring to Circle: \n  For Senior Data Engineer (III) \n \n 4+ years of professional data engineering experience. \n Proficient in one or more programming languages (Java, Scala, Python). \n Advanced experience in SQL in big data warehouse systems such as Snowflake, BigQuery, Databricks, etc. \n Experience in SQL and NoSQL, such as MySQL, PostgreSQL, Cassandra, HBase, Redis, DynamoDB, Neo4j, etc. \n Experience with workflow orchestration management engines such as Airflow, Dagster, DBT, etc \n Experience with Cloud Services (AWS, Google Cloud, Microsoft Azure, etc). \n Experience in building scalable infrastructure to support batch, micro-batch or stream data processing for large volumes of data. \n Experience with financial or compliance data, bonus if in similar business domains, such as payment systems, credit cards, bank transfers, blockchains, etc. \n Experience in data provenance and governance. \n Internal knowledge of open source or related big data technologies. \n Ability to tackle complex and ambiguous problems. \n Self-starter who takes ownership, gets results, and enjoys moving at a fast pace. \n Excellent communication skills, able to collaborate with across remote teams, share ideas and present concepts effectively. \n \n For Staff Data Engineer (IV) \n  All the requirements of above and: \n \n 7+ years of professional data engineering experience. \n Led teams (>5) technically on architecture and system design. \n Expert in one of the domains of ETL/ELT pipelines, feature engineering, data modeling and architecture, or data ingestion. \n Experience working autonomously and able to identify large impactful projects to pursue with minimal guidance. \n Deep understanding/experience with: \n \n Data warehouse architecture and design \n Integration of the data stack to other tools/services \n Extensive knowledge with implementing data quality checks \n \n \n Additional Information: \n \n This position is eligible for day-one PERM sponsorship for qualified candidates. \n \n Circle is on a mission to create an inclusive financial future, with transparency at our core. We consider a wide variety of elements when crafting our compensation ranges and total compensation packages. \n  Starting pay is determined by various factors, including but not limited to: relevant experience, skill set, qualifications, and other business and organizational needs. Please note that compensation ranges may differ for candidates in other locations. \n  Senior Data Engineer (III) \n  Base Pay Range: $147,500 - $195,000 \n  Annual Bonus Target: 12.5% \n  Staff Data Engineer (IV) \n  Base Pay Range: $172,500 - $227,500 \n  Annual Bonus Target: 15% \n  Also Included: Equity & Benefits (including medical, dental, vision and 401(k)). Circle has a discretionary vacation policy. We also provide 10 days of paid sick leave per year and 11 paid holidays per year in the U.S. \n \n  We are an  equal opportunity employer  and value diversity at Circle. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Additionally, Circle participates in the  E-Verify Program  in certain locations, as required by law. \n  #LI-Remote",
        "cleaned_desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  As a member of the Data Engineering - Business ETL team, you own the ETL/ELT pipelines and data warehouse that is used for financial and regulatory reporting. Your work powers Circle business functions, including the Compliance, Finance, Accounting, and Analytics teams for experimentation, operational excellence, and actionable insights, so as to fuel and accelerate business growth. High integrity to data accuracy and quality is crucial. Your work will directly impact Circle's transparency, trust, and accountability needs. \n  What you'll work on: \n \n Collaborating with business teams on the design, deployment and continuous improvement of the scalable data platform that ingests, stores, and aggregates various datasets, including data pipelines, platforms, and warehouses, and surfacing data to both internal and customer-facing applications. \n Being a domain expert on data modeling, data pipelines, data quality and data warehousing. \n Designing, building and maintaining data ETL/ELT pipelines to source and aggregate the required data for various data analyses and reporting needs, as well as to continually improve the operations, monitoring and performance of the data warehouse. \n Developing integrations with third party systems to source, qualify and ingest various datasets. \n Providing data analytics and visualization tools to extract valuable insights from the data to enable data-driven decisions.   Proficient in one or more programming languages (Java, Scala, Python). \n Advanced experience in SQL in big data warehouse systems such as Snowflake, BigQuery, Databricks, etc. \n Experience in SQL and NoSQL, such as MySQL, PostgreSQL, Cassandra, HBase, Redis, DynamoDB, Neo4j, etc. \n Experience with workflow orchestration management engines such as Airflow, Dagster, DBT, etc \n Experience with Cloud Services (AWS, Google Cloud, Microsoft Azure, etc). \n Experience in building scalable infrastructure to support batch, micro-batch or stream data processing for large volumes of data. \n Experience with financial or compliance data, bonus if in similar business domains, such as payment systems, credit cards, bank transfers, blockchains, etc. \n Experience in data provenance and governance. \n Internal knowledge of open source or related big data technologies. \n Ability to tackle complex and ambiguous problems. \n Self-starter who takes ownership, gets results, and enjoys moving at a fast pace. \n Excellent communication skills, able to collaborate with across remote teams, share ideas and present concepts effectively. \n   For Staff Data Engineer (IV) \n  All the requirements of above and: \n \n 7+ years of professional data engineering experience. \n Led teams (>5) technically on architecture and system design. \n Expert in one of the domains of ETL/ELT pipelines, feature engineering, data modeling and architecture, or data ingestion. \n Experience working autonomously and able to identify large impactful projects to pursue with minimal guidance. \n Deep understanding/experience with: \n \n Data warehouse architecture and design \n Integration of the data stack to other tools/services \n Extensive knowledge with implementing data quality checks \n ",
        "techs": [
            "circle",
            "usdc",
            "blockchain-based dollar",
            "etl/elt pipelines",
            "data warehouse",
            "compliance",
            "finance",
            "accounting",
            "analytics",
            "data pipelines",
            "data platforms",
            "data warehousing",
            "third party systems",
            "data analytics",
            "data visualization",
            "java",
            "scala",
            "python",
            "sql",
            "snowflake",
            "bigquery",
            "databricks",
            "mysql",
            "postgresql",
            "cassandra",
            "hbase",
            "redis",
            "dynamodb",
            "neo4j",
            "airflow",
            "dagster",
            "dbt",
            "cloud services (aws",
            "google cloud",
            "microsoft azure)",
            "batch processing",
            "micro-batch processing",
            "stream processing",
            "financial data",
            "compliance data",
            "open source technologies"
        ],
        "cleaned_techs": [
            "circle",
            "usdc",
            "blockchain-based dollar",
            "etl/elt pipelines",
            "data warehouse",
            "compliance",
            "finance",
            "accounting",
            "data pipelines",
            "data platforms",
            "data warehousing",
            "third party systems",
            "data analytics",
            "data visualization",
            "java",
            "scala",
            "python",
            "sql",
            "snowflake",
            "bigquery",
            "databricks",
            "mysql",
            "postgresql",
            "cassandra",
            "hbase",
            "redis",
            "dynamodb",
            "neo4j",
            "airflow",
            "dagster",
            "dbt",
            "cloud services (aws",
            "gcp",
            "microsoft azure)",
            "batch processing",
            "micro-batch processing",
            "stream processing",
            "financial data",
            "compliance data",
            "open source technologies"
        ]
    },
    "268ab4b960b4a784": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 50.0,
        "salary_max": 55.0,
        "title": "Senior Machine Learning Engineer",
        "company": "Tech Matrix Software Solutions Pvt. Ltd",
        "desc": "Role: Senior Machine Learning Engineer/AI Engineer \n Location: Remote \n Job Description \n \n position: \u2002this\u2002for\u2002responsibilities\u20025-10\u2002Top \n platforms\u2002AIML\u2002developing\u2002Experience&cloud. \u2002native\u2002and\u2002Kubernetes\u2002on\u2002preferably\u2002programming),\u2002distributed/parallel\u2002inferencing,\u2002training,\u2002model\u2002as\u2002such\u2002offerings\u2002core\u2002(including\u2002frameworks \n languages \u2002programming\u2002JAVA\u2002or\u2002Python\u2002with\u2002skilled\u2002Highly \n SQL\u2002like\u2002languages\u2002database\u2002with\u2002skilled\u2002Highly&NoSQL \n languages. \u2002other\u2002and\u2002Python\u2002using\u2002applications\u2002distributed\u2002testable\u2002and\u2002extensible,\u2002maintainable,\u2002highly\u2002deploying\u2002and\u2002developing,\u2002designing,\u2002Experience \n Django \u2002or\u2002Flask\u2002using\u2002Python\u2002in\u2002APIs\u2002REST\u2002and\u2002pipelines\u2002ETL\u2002developing\u2002Experience \n CI/CD\u2002and\u2002tools,\u2002orchestration\u2002Workflow\u2002Notebooks,\u2002Charts,\u2002Helm\u2002Kubernetes,\u2002including\u2002technologies/frameworks\u2002with\u2002Experienced&frameworks. \u2002monitoring \n Skills: \u2002/\u2002Qualifications\u2002Preferred \n TensorFlow \u2002Pytorch,\u2002Spark,\u2002Argo,\u2002Jupyter,\u2002using\u2002datasets\u2002large\u2002in\u2002projects\u2002open-source\u2002AI/ML\u2002with\u2002Experience \n UnitTest \u2002PyTest,\u2002using\u2002cases\u2002test\u2002Functional\u2002and\u2002Unit\u2002creating\u2002Experience \n Learning \u2002Machine\u2002in\u2002models\u2002tuning\u2002and\u2002training\u2002with\u2002Experience \n Hub \u2002Jupyter\u2002with\u2002working\u2002Experience \n PostgreSQL \u2002like\u2002system\u2002management\u2002DB\u2002with\u2002Experience \n Splunk/Kibana \u2002using\u2002logs\u2002analyzing\u2002and\u2002monitoring,\u2002searching,\u2002in\u2002Experience \n knowledge \u2002implementation\u2002GraphQL/Swagger \n Service \u2002Kubernetes\u2002Azure\u2002in\u2002applications\u2002of\u2002scalability\u2002and\u2002availability\u2002for\u2002Kubernetes\u2002with\u2002experience\u2002and\u2002understanding\u2002Strong \n Gitlab \u2002and\u2002Charts\u2002Helm\u2002Kubernetes,\u2002Artifactory,\u2002Docker,\u2002Jenkins,\u2002Cloudbees\u2002using\u2002pipelines\u2002CI/CD\u2002building\u2002Experience \n Kafka \u2002Spark,\u2002Apache\u2002Scikit,\u2002TensorFlow,\u2002MLFlow,\u2002Kubeflow,\u2002Hub,\u2002Jupyter\u2002like\u2002tools\u2002with\u2002Experience \n workflows \u2002Argo\u2002Airflow,\u2002Apache\u2002as\u2002such\u2002tools\u2002orchestration\u2002workflow\u2002with\u2002Experience \n builds \u2002package\u2002Node.js\u2002and\u2002PyPi,\u2002Conda,\u2002with\u2002Familiarity \n \n Job Type: Contract \n Salary: $50.00 - $55.00 per hour \n Experience level: \n \n 8 years \n \n Schedule: \n \n 8 hour shift \n \n Application Question(s): \n \n Are you comfortable to work on W2 contract, we need only W2 candidates only? \n \n Experience: \n \n Machine learning: 8 years (Preferred) \n TransFlow: 4 years (Preferred) \n Pytorch: 5 years (Preferred) \n Spark: 4 years (Preferred) \n Kubernetes: 4 years (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": "Role: Senior Machine Learning Engineer/AI Engineer \n Location: Remote \n Job Description \n \n position: \u2002this\u2002for\u2002responsibilities\u20025-10\u2002Top \n platforms\u2002AIML\u2002developing\u2002Experience&cloud. \u2002native\u2002and\u2002Kubernetes\u2002on\u2002preferably\u2002programming),\u2002distributed/parallel\u2002inferencing,\u2002training,\u2002model\u2002as\u2002such\u2002offerings\u2002core\u2002(including\u2002frameworks \n languages \u2002programming\u2002JAVA\u2002or\u2002Python\u2002with\u2002skilled\u2002Highly \n SQL\u2002like\u2002languages\u2002database\u2002with\u2002skilled\u2002Highly&NoSQL \n languages. \u2002other\u2002and\u2002Python\u2002using\u2002applications\u2002distributed\u2002testable\u2002and\u2002extensible,\u2002maintainable,\u2002highly\u2002deploying\u2002and\u2002developing,\u2002designing,\u2002Experience   Django \u2002or\u2002Flask\u2002using\u2002Python\u2002in\u2002APIs\u2002REST\u2002and\u2002pipelines\u2002ETL\u2002developing\u2002Experience \n CI/CD\u2002and\u2002tools,\u2002orchestration\u2002Workflow\u2002Notebooks,\u2002Charts,\u2002Helm\u2002Kubernetes,\u2002including\u2002technologies/frameworks\u2002with\u2002Experienced&frameworks. \u2002monitoring \n Skills: \u2002/\u2002Qualifications\u2002Preferred \n TensorFlow \u2002Pytorch,\u2002Spark,\u2002Argo,\u2002Jupyter,\u2002using\u2002datasets\u2002large\u2002in\u2002projects\u2002open-source\u2002AI/ML\u2002with\u2002Experience \n UnitTest \u2002PyTest,\u2002using\u2002cases\u2002test\u2002Functional\u2002and\u2002Unit\u2002creating\u2002Experience \n Learning \u2002Machine\u2002in\u2002models\u2002tuning\u2002and\u2002training\u2002with\u2002Experience \n Hub \u2002Jupyter\u2002with\u2002working\u2002Experience \n PostgreSQL \u2002like\u2002system\u2002management\u2002DB\u2002with\u2002Experience \n Splunk/Kibana \u2002using\u2002logs\u2002analyzing\u2002and\u2002monitoring,\u2002searching,\u2002in\u2002Experience   knowledge \u2002implementation\u2002GraphQL/Swagger \n Service \u2002Kubernetes\u2002Azure\u2002in\u2002applications\u2002of\u2002scalability\u2002and\u2002availability\u2002for\u2002Kubernetes\u2002with\u2002experience\u2002and\u2002understanding\u2002Strong \n Gitlab \u2002and\u2002Charts\u2002Helm\u2002Kubernetes,\u2002Artifactory,\u2002Docker,\u2002Jenkins,\u2002Cloudbees\u2002using\u2002pipelines\u2002CI/CD\u2002building\u2002Experience \n Kafka \u2002Spark,\u2002Apache\u2002Scikit,\u2002TensorFlow,\u2002MLFlow,\u2002Kubeflow,\u2002Hub,\u2002Jupyter\u2002like\u2002tools\u2002with\u2002Experience \n workflows \u2002Argo\u2002Airflow,\u2002Apache\u2002as\u2002such\u2002tools\u2002orchestration\u2002workflow\u2002with\u2002Experience \n builds \u2002package\u2002Node.js\u2002and\u2002PyPi,\u2002Conda,\u2002with\u2002Familiarity \n \n Job Type: Contract \n Salary: $50.00 - $55.00 per hour ",
        "techs": [
            "aiml",
            "kubernetes",
            "java",
            "python",
            "sql",
            "nosql",
            "django",
            "flask",
            "rest",
            "etl",
            "ci/cd",
            "helm",
            "tensorflow",
            "pytorch",
            "spark",
            "argo",
            "jupyter",
            "unittest",
            "machine learning",
            "hub",
            "postgresql",
            "splunk",
            "kibana",
            "graphql",
            "swagger",
            "service",
            "azure",
            "gitlab",
            "charts",
            "artifactory",
            "docker",
            "jenkins",
            "cloudbees",
            "kafka",
            "scikit",
            "mlflow",
            "kubeflow",
            "argo",
            "airflow",
            "node.js",
            "pypi",
            "conda"
        ],
        "cleaned_techs": [
            "aiml",
            "kubernetes",
            "java",
            "python",
            "sql",
            "nosql",
            "django",
            "flask",
            "rest",
            "etl",
            "ci/cd",
            "helm",
            "tensorflow",
            "pytorch",
            "spark",
            "argo",
            "jupyter",
            "unittest",
            "hub",
            "postgresql",
            "splunk",
            "kibana",
            "graphql",
            "swagger",
            "service",
            "azure",
            "gitlab",
            "charts",
            "artifactory",
            "docker",
            "jenkins",
            "cloudbees",
            "kafka",
            "scikit",
            "mlflow",
            "kubeflow",
            "airflow",
            "node.js",
            "pypi",
            "conda"
        ]
    },
    "d9b9e4aee5a0cdc2": {
        "terms": [
            "data science"
        ],
        "salary_min": 0.0,
        "salary_max": 120000.0,
        "title": "Sr Project Manager",
        "company": "Maximus",
        "desc": "Job Introduction: \n  \n   Maximus is currently looking for a remote Sr Manager Project/Program. This opportunity requires working hours to be performed on Eastern or Central Standard time. This position is responsible for overseeing the Project Management team at a senior level. The incumbent will work closely with business development and sales groups, and develop and implement strategies for upcoming and existing product lines.\n   Job Summary: \n  \n   Essential Duties and Responsibilities:\n   \n \n Develop strategies and tactical implementation of new products and improvements to existing product lines. \n Work closely with business development and sales groups to identify upcoming needs. \n Develop a detailed plan for implementation and roll out. \n Follow up by evaluating product performance. \n \n  Minimum Requirements:\n  \n \n Bachelor's degree with 7+ years of project management experience. \n Delivers multiple small and large projects with high values and high risk. \n Provides leadership for the project team to ensure that the project is delivered to specifications, on time and within budget. \n Develops innovative methodologies, techniques, and criteria for projects. \n Advanced knowledge of workflows and project mapping. \n Facilitates the tracking and resolution of issues impacting projects. \n  Education and Experience Requirements: \n  \n   Bachelor's degree or equivalent combination of education, technical training or work experience considered in lieu of degree with 7+ years of experience\n  \n \n \n \n  Manage a huge analytics content repository for major internal and external customers. \n Manage expectations regarding project schedule and scope, as well as budget and financial impact. \n Lead talks with data analysts and business stakeholders to explore opportunities for applying data analytics concepts to real-world business problems. \n Mentor and coach new and advanced data analytics teammates in the development of their abilities and the resolution of challenging business problems. \n Demonstrate a creative ability to recommend data visualizations that enable key company stakeholders to easily digest complex information and swiftly find significant insights. \n \n \n \n  Experience Preferred:\n  \n \n \n  Bachelor\u2019s degree in Data Analytics, Business Analytics, Data Science, Computer Science, Computer Information Systems, or other relevant engineering/technical field preferred.  \n Master\u2019s degree in Data Analytics, Business Analytics, Data Science, Computer Science, Computer Information Systems, or other relevant engineering/technical field preferred. \n Project management and related experience preferred \n Project Management Professional (PMP) certification plus \n Leadership experience preferred. \n Familiarity with programming languages central to data analytics (e.g. SQL, Python, R, DAX) preferred. \n Background of advising both immediate team and broader organization on solutions preferred.  \n Familiar with development & utilization of applications and process automation tools to improve analytics processes (e.g. Power Apps, Power Automate) a plus  \n Experience with project management tools & framework (e.g. scrum and agile frameworks) preferred. \n Experience/advanced in data governance concepts including the need for documented definitions, calculations, sources, lineage, etc. preferred. \n Experience leading a team and peers through end-to-end data analytics projects (e.g. from problem and requirements definition to code/model validation and reporting deployment) preferred.  \n Knowledge and experience in business intelligence and analytics platforms (e.g. Power BI, Tableau) a plus.  \n Familiar with common data analysis processes (e.g. data transformation, cleansing, modeling, relational database concepts) preferred \n Verbal and written communication skills, including presentation skills. \n Advanced data analysis skills \n Data visualization and design expertise. \n Experience creating and presenting data-driven insights. \n Initiative to solve complex problems; takes an outside in perspective to identify innovative solutions. \n \n \n \n \n  This position is fully remote and will require a home office.\n  \n \n  Home office requirements:\n  \n \n   Reliable high-speed internet service\n    Minimum 25 Mpbs download speeds/50 Mpbs for shared internet connectivity\n    Minimum 5 Mpbs upload speeds\"\n  \n \n \n  This position requires working hours to be performed in Eastern or Central Standard Time.\n  \n \n \n  This position has the potential to work weekends and holidays based on business needs.\n  \n \n \n  The 6 month time in position rule can be waived for CCO employees under the following circumstances : employees who were in an acting role and have returned to their home base position, employees who are currently in an acting/limited-service role applying to the same role that is RFT, employees who were unable to return to a homebase position at the end of their acting role, or limited-service employees that are unable to secure a lateral or promotional position for continued employment at the end of their limited assignment.\n   MAXIMUS Introduction: Since 1975, Maximus has operated under its founding mission of Helping Government Serve the People, enabling citizens around the globe to successfully engage with their governments at all levels and across a variety of health and human services programs. Maximus delivers innovative business process management and technology solutions that contribute to improved outcomes for citizens and higher levels of productivity, accuracy, accountability and efficiency of government-sponsored programs. With more than 30,000 employees worldwide, Maximus is a proud partner to government agencies in the United States, Australia, Canada, Saudi Arabia, Singapore and the United Kingdom. For more information, visit https://www.maximus.com. EEO Statement: EEO Statement: Active military service members, their spouses, and veteran candidates often embody the core competencies MAXIMUS deems essential, and bring a resiliency and dependability that greatly enhances our workforce. We recognize your unique skills and experiences, and want to provide you with a career path that allows you to continue making a difference for our country. We\u2019re proud of our connections to organizations dedicated to serving veterans and their families. If you are transitioning from military to civilian life, have prior service, are a retired veteran or a member of the National Guard or Reserves, or a spouse of an active military service member, we have challenging and rewarding career opportunities available for you. A committed and diverse workforce is our most important resource. MAXIMUS is an Affirmative Action/Equal Opportunity Employer. MAXIMUS provides equal employment opportunities to all qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status or disabled status. Pay Transparency: Maximus compensation is based on various factors including but not limited to job location, a candidate's education, training, experience, expected quality and quantity of work, required travel (if any), external market and internal value analysis including seniority and merit systems, as well as internal pay alignment. Annual salary is just one component of Maximus's total compensation package. Other rewards may include short- and long-term incentives as well as program-specific awards. Additionally, Maximus provides a variety of benefits to employees, including health insurance coverage, life and disability insurance, a retirement savings plan, paid holidays and paid time off. Compensation ranges may differ based on contract value but will be commensurate with job duties and relevant work experience. An applicant's salary history will not be used in determining compensation. Maximus will comply with regulatory minimum wage rates and exempt salary thresholds in all instances. Posted Max: USD $120,000.00/Yr. Posted Min: USD $63,100.00/Yr.",
        "cleaned_desc": " Bachelor's degree with 7+ years of project management experience. \n Delivers multiple small and large projects with high values and high risk. \n Provides leadership for the project team to ensure that the project is delivered to specifications, on time and within budget. \n Develops innovative methodologies, techniques, and criteria for projects. \n Advanced knowledge of workflows and project mapping. \n Facilitates the tracking and resolution of issues impacting projects. \n  Education and Experience Requirements: \n  \n   Bachelor's degree or equivalent combination of education, technical training or work experience considered in lieu of degree with 7+ years of experience\n  \n \n \n \n  Manage a huge analytics content repository for major internal and external customers. \n Manage expectations regarding project schedule and scope, as well as budget and financial impact. \n Lead talks with data analysts and business stakeholders to explore opportunities for applying data analytics concepts to real-world business problems.   Mentor and coach new and advanced data analytics teammates in the development of their abilities and the resolution of challenging business problems. \n Demonstrate a creative ability to recommend data visualizations that enable key company stakeholders to easily digest complex information and swiftly find significant insights. \n \n \n \n  Experience Preferred:\n  \n \n \n  Bachelor\u2019s degree in Data Analytics, Business Analytics, Data Science, Computer Science, Computer Information Systems, or other relevant engineering/technical field preferred.  \n Master\u2019s degree in Data Analytics, Business Analytics, Data Science, Computer Science, Computer Information Systems, or other relevant engineering/technical field preferred. \n Project management and related experience preferred \n Project Management Professional (PMP) certification plus \n Leadership experience preferred. \n Familiarity with programming languages central to data analytics (e.g. SQL, Python, R, DAX) preferred. \n Background of advising both immediate team and broader organization on solutions preferred.    Familiar with development & utilization of applications and process automation tools to improve analytics processes (e.g. Power Apps, Power Automate) a plus  \n Experience with project management tools & framework (e.g. scrum and agile frameworks) preferred. \n Experience/advanced in data governance concepts including the need for documented definitions, calculations, sources, lineage, etc. preferred. \n Experience leading a team and peers through end-to-end data analytics projects (e.g. from problem and requirements definition to code/model validation and reporting deployment) preferred.  \n Knowledge and experience in business intelligence and analytics platforms (e.g. Power BI, Tableau) a plus.  \n Familiar with common data analysis processes (e.g. data transformation, cleansing, modeling, relational database concepts) preferred \n Verbal and written communication skills, including presentation skills. \n Advanced data analysis skills \n Data visualization and design expertise. \n Experience creating and presenting data-driven insights. \n Initiative to solve complex problems; takes an outside in perspective to identify innovative solutions. \n \n \n \n \n  This position is fully remote and will require a home office.",
        "techs": [
            "bachelor's degree",
            "project management experience",
            "workflows",
            "project mapping",
            "analytics content repository",
            "data analysts",
            "business stakeholders",
            "data visualizations",
            "data analytics",
            "business analytics",
            "data science",
            "computer science",
            "computer information systems",
            "engineering/technical field",
            "project management professional (pmp) certification",
            "programming languages (sql",
            "python",
            "r",
            "dax)",
            "development & utilization of applications",
            "process automation tools",
            "project management tools & framework",
            "data governance concepts",
            "data analysis processes",
            "business intelligence and analytics platforms (power bi",
            "tableau)",
            "verbal and written communication skills",
            "data analysis skills",
            "data visualization and design expertise",
            "remote work."
        ],
        "cleaned_techs": [
            "project management experience",
            "workflows",
            "project mapping",
            "analytics content repository",
            "data analysts",
            "business stakeholders",
            "data visualizations",
            "data analytics",
            "business analytics",
            "data science",
            "computer science",
            "computer information systems",
            "engineering/technical field",
            "project management professional (pmp) certification",
            "programming languages (sql",
            "python",
            "r",
            "dax)",
            "process automation tools",
            "project management tools & framework",
            "data governance concepts",
            "data analysis processes",
            "business intelligence and analytics platforms (power bi",
            "tableau)",
            "data visualization and design expertise",
            "remote work."
        ]
    },
    "ea5fa4de8d1e5a10": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 130264.83,
        "salary_max": 164944.3,
        "title": "Senior Marketing Data Engineer",
        "company": "Samsara",
        "desc": "Who we are \n  Samsara (NYSE: IOT) is the pioneer of the Connected Operations\u2122 Cloud, which is a platform that enables organizations that depend on physical operations to harness Internet of Things (IoT) data to develop actionable insights and improve their operations. At Samsara, we are helping improve the safety, efficiency and sustainability of the physical operations that power our global economy. Representing more than 40% of global GDP, these industries are the infrastructure of our planet, including agriculture, construction, field services, transportation, and manufacturing \u2014 and we are excited to help digitally transform their operations at scale. \n  Working at Samsara means you'll help define the future of physical operations and be on a team that's shaping an exciting array of product solutions, including Video-Based Safety, Vehicle Telematics, Apps and Driver Workflows, Equipment Monitoring, and Site Visibility. As part of a recently public company, you'll have the autonomy and support to make an impact as we build for the long term. \n  Recent awards we've won include: \n  Glassdoor's Highest-Rated Tech Companies for Culture and Values 2023 \n  Great Place To Work Certified\u2122 2023 \n  Best Place to Work by Built In 2023 \n  Financial Times The Americas' Fastest Growing Companies 2023 \n  Deloitte Fast 500 Companies \n  We see a profound opportunity for data to improve the safety, efficiency, and sustainability of operations, and hope you consider joining us on this exciting journey. \n \n  About the team: \n  Data and Analytics is a critical team within Marketing. Our mission is to enable revenue performance by providing marketing and sales teams with the insights, tools, infrastructure and consultation to make data driven judgements. We are a scrappy and growing team that loves all things data! The team will be composed of data engineers, analytics managers and data scientists. We are passionate about leveraging world class data and analytics to deliver a great customer experience. \n  Our team promotes an agile, collaborative, supportive environment where diverse thinking, innovative design, and experimentation is welcomed and encouraged. \n  You should apply if: \n \n You want to impact the industries that run our world:  Your efforts will result in real-world impact\u2014helping to keep the lights on, get food into grocery stores, reduce emissions, and most importantly, ensure workers return home safely. \n You want to build for scale:  With over 2.3 million IoT devices deployed to our global customers, you will work on a range of new and mature technologies driving scalable innovation for customers across industries driving the world's physical operations. \n You are a team player:  Working on our partners requires a mix of independent effort and collaboration. Motivated by our mission, we're all racing toward our connected operations vision, and we intend to win\u2014together. \n You are a life-long learner:  We have ambitious goals. Every Samsarian has a growth mindset as we work with a wide range of technologies, challenges, and customers that push us to learn on the go. \n \n Click here  to learn about what we value at Samsara. \n  In this role, you will: \n \n Develop and maintain marketing databases, datasets, pipelines and Samsara's Customer Data Platform (CDP) to enable advanced segmentation, targeting, automation and analytics. \n Manage critical data pipelines to enable our growth initiatives and advanced analytics. Manage the SLAs for those data pipelines and constantly improve efficiency and data quality. \n Facilitate data integration and transformation requirements for moving data between applications; ensuring interoperability of applications with data mart and CDP environments. \n Develop and improve the current data architecture, data quality, monitoring and data availability. \n Identify data needs from broad stakeholders, understand requirements for metrics and analysis, and build efficient and scalable data products to enable a data-driven marketing approach. \n Write sophisticated yet optimized data transformations in SQL/Python to generate data products consumed by customer systems and Analytics, Marketing Operations, Sales Operations teams. \n Champion, role model, and embed Samsara's cultural principles (Obsess Over the Customer, Build for the Long Term, Growth Mindset) as we scale globally and across new offices \n \n Minimum requirements for the role: \n \n 5+ years of working experience in a growth, software or data engineering role \n Excellent SQL and Python knowledge with strong hands-on data modeling \n Experience with data warehouse technical architectures, infrastructure components, ETL/ ELT and reporting/analytic tools. \n Hands-on experience working with modern data technologies stack such as Databricks, Google Big Query, Redshift, RDS, Snowflake or similar solutions \n Experience with development lifecycle tools such as Github, TFS, etc. \n Comfort in working with business customers to gather requirements and gain a deep understanding of varied datasets. \n Familiarity with customer, marketing and/or web data \n Experience integrating data from core Sales and Marketing platforms (e.g. Marketing Automation, CRM, and web analytics) \n Self-starter, motivated, responsible, innovative and technology-driven candidate who performs well both unsupervised and as a team member \n A proactive problem solver and have good communication as well as project management skills to relay your findings and solutions across technical and non technical audiences \n \n An ideal candidate also has: \n \n Knowledge of Marketo, Salesforce.com and Google Analytics \n Experience working with CDPs such as Segment, Blueshift, Lytics or Adobe Real-time CDP \n Experience with data visualization tools and packages (e.g. Looker, Domo, Tableau, MixPanel) \n Familiarity with Marketing Technologies (MarTech stacks) \n Experience coding with Scala, R or Pandas \n Data Science, machine learning or predictive analytics experience \n \n \n \n Samsara\u2019s Compensation Philosophy : Samsara\u2019s compensation program is designed to deliver total compensation (based on role, level, and geography) that is above market. We do this through our base salary + bonus/variable + restricted stock unit awards (RSUs). A new hire RSU award is awarded at the time of hire, and additional RSU refresh grants may be awarded annually. \n     We pay for performance, and top performers are eligible to receive above target equity refresh awards which allow employees to achieve higher market positioning. \n \n  The range of annual base salary for full-time employees for this position is below. Please note that base pay offered may vary depending on factors including your city of residence, job-related knowledge, skills, and experience. \n \n    $122,400\u2014$180,000 USD\n   \n \n \n  At Samsara, we welcome everyone regardless of their background, race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, etc. We depend on the unique approaches of our team members to help us solve complex problems. We are committed to increasing diversity across our team and ensuring that Samsara is a place where people from all backgrounds can make an impact. \n  Accommodations \n  Samsara is an inclusive work environment, and we are committed to ensuring equal opportunity in employment for qualified persons with disabilities. Please email accessibleinterviewing@samsara.com or click here if you require any reasonable accommodations throughout the recruiting process. \n  Benefits \n  Full time employees receive an above market total compensation package along with employee-led remote and flexible working, health benefits, Samsara for Good charity fund, and much, much more. Take a look at our Benefits site to learn more. \n  Flexible Working \n  At Samsara, we have adopted a flexible way of working, enabling teams and individuals to do their best work, regardless of where they're based. We value in-person collaboration and know a change of scenery and quiet space to work is welcomed from time to time, but also appreciate that the world of work has changed. Our offices remain open for those who prefer to collaborate or work in-office, but we also encourage fully remote applicants. As most roles are not required to be in the office, we are able to hire remotely where Samsara has an established presence. If a role is required to be in a certain location and candidates do not have work authorization for that location, Samsara will conduct an immigration assessment. If the role is not required to be in a specific location, Samsara will move forward with the remote location that works best for the business. All offers of employment are contingent upon an individual's ability to secure and maintain the legal right to work at the company. \n \n \n  Please note: Samsara does not accept agency resumes and is not responsible for any fees related to unsolicited resumes. Please do not forward resumes to Samsara employees.",
        "cleaned_desc": " Identify data needs from broad stakeholders, understand requirements for metrics and analysis, and build efficient and scalable data products to enable a data-driven marketing approach. \n Write sophisticated yet optimized data transformations in SQL/Python to generate data products consumed by customer systems and Analytics, Marketing Operations, Sales Operations teams. \n Champion, role model, and embed Samsara's cultural principles (Obsess Over the Customer, Build for the Long Term, Growth Mindset) as we scale globally and across new offices \n \n Minimum requirements for the role: \n \n 5+ years of working experience in a growth, software or data engineering role \n Excellent SQL and Python knowledge with strong hands-on data modeling \n Experience with data warehouse technical architectures, infrastructure components, ETL/ ELT and reporting/analytic tools. \n Hands-on experience working with modern data technologies stack such as Databricks, Google Big Query, Redshift, RDS, Snowflake or similar solutions \n Experience with development lifecycle tools such as Github, TFS, etc. \n Comfort in working with business customers to gather requirements and gain a deep understanding of varied datasets. \n Familiarity with customer, marketing and/or web data \n Experience integrating data from core Sales and Marketing platforms (e.g. Marketing Automation, CRM, and web analytics)   Self-starter, motivated, responsible, innovative and technology-driven candidate who performs well both unsupervised and as a team member \n A proactive problem solver and have good communication as well as project management skills to relay your findings and solutions across technical and non technical audiences \n \n An ideal candidate also has: \n \n Knowledge of Marketo, Salesforce.com and Google Analytics \n Experience working with CDPs such as Segment, Blueshift, Lytics or Adobe Real-time CDP \n Experience with data visualization tools and packages (e.g. Looker, Domo, Tableau, MixPanel) \n Familiarity with Marketing Technologies (MarTech stacks) \n Experience coding with Scala, R or Pandas \n Data Science, machine learning or predictive analytics experience \n \n \n ",
        "techs": [
            "sql",
            "python",
            "data modeling",
            "data warehouse",
            "etl/elt",
            "reporting/analytic tools",
            "databricks",
            "google big query",
            "redshift",
            "rds",
            "snowflake",
            "github",
            "tfs",
            "customer",
            "marketing",
            "web data",
            "marketo",
            "salesforce.com",
            "google analytics",
            "cdps",
            "segment",
            "blueshift",
            "lytics",
            "adobe real-time cdp",
            "data visualization tools",
            "looker",
            "domo",
            "tableau",
            "mixpanel",
            "martech stacks",
            "scala",
            "r",
            "pandas",
            "data science",
            "machine learning",
            "predictive analytics"
        ],
        "cleaned_techs": [
            "sql",
            "python",
            "data warehouse",
            "etl/elt",
            "reporting/analytic tools",
            "databricks",
            "google big query",
            "redshift",
            "rds",
            "snowflake",
            "github",
            "tfs",
            "customer",
            "marketing",
            "web data",
            "marketo",
            "salesforce.com",
            "google analytics",
            "cdps",
            "segment",
            "blueshift",
            "lytics",
            "adobe",
            "data visualization tools",
            "looker",
            "domo",
            "tableau",
            "mixpanel",
            "martech stacks",
            "scala",
            "r",
            "pandas",
            "data science",
            "predictive analytics"
        ]
    },
    "7b5b2e4c774ce416": {
        "terms": [
            "data science",
            "data engineer"
        ],
        "salary_min": 147500.0,
        "salary_max": 195000.0,
        "title": "Senior Data Engineer",
        "company": "Circle",
        "desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  As a member of the Data Engineering - Business ETL team, you own the ETL/ELT pipelines and data warehouse that is used for financial and regulatory reporting. Your work powers Circle business functions, including the Compliance, Finance, Accounting, and Analytics teams for experimentation, operational excellence, and actionable insights, so as to fuel and accelerate business growth. High integrity to data accuracy and quality is crucial. Your work will directly impact Circle's transparency, trust, and accountability needs. \n  What you'll work on: \n \n Collaborating with business teams on the design, deployment and continuous improvement of the scalable data platform that ingests, stores, and aggregates various datasets, including data pipelines, platforms, and warehouses, and surfacing data to both internal and customer-facing applications. \n Being a domain expert on data modeling, data pipelines, data quality and data warehousing. \n Designing, building and maintaining data ETL/ELT pipelines to source and aggregate the required data for various data analyses and reporting needs, as well as to continually improve the operations, monitoring and performance of the data warehouse. \n Developing integrations with third party systems to source, qualify and ingest various datasets. \n Providing data analytics and visualization tools to extract valuable insights from the data to enable data-driven decisions. \n Working closely with across groups, such as the product, engineering, data science, compliance, and security teams, for data modeling, general management of data life cycle, data governance and processes for meeting regulatory and legal requirements. \n \n You will aspire to our four core values: \n \n Multistakeholder - you have dedication and commitment to our customers, shareholders, employees and families and local communities. \n Mindful - you seek to be respectful, an active listener and to pay attention to detail. \n Driven by Excellence - you are driven by our mission and our passion for customer success which means you relentlessly pursue excellence, that you do not tolerate mediocrity and you work intensely to achieve your goals. \n High Integrity - you seek open and honest communication, and you hold yourself to very high moral and ethical standards. You reject manipulation, dishonesty and intolerance. \n \n What you'll bring to Circle: \n  For Senior Data Engineer (III) \n \n 4+ years of professional data engineering experience. \n Proficient in one or more programming languages (Java, Scala, Python). \n Advanced experience in SQL in big data warehouse systems such as Snowflake, BigQuery, Databricks, etc. \n Experience in SQL and NoSQL, such as MySQL, PostgreSQL, Cassandra, HBase, Redis, DynamoDB, Neo4j, etc. \n Experience with workflow orchestration management engines such as Airflow, Dagster, DBT, etc \n Experience with Cloud Services (AWS, Google Cloud, Microsoft Azure, etc). \n Experience in building scalable infrastructure to support batch, micro-batch or stream data processing for large volumes of data. \n Experience with financial or compliance data, bonus if in similar business domains, such as payment systems, credit cards, bank transfers, blockchains, etc. \n Experience in data provenance and governance. \n Internal knowledge of open source or related big data technologies. \n Ability to tackle complex and ambiguous problems. \n Self-starter who takes ownership, gets results, and enjoys moving at a fast pace. \n Excellent communication skills, able to collaborate with across remote teams, share ideas and present concepts effectively. \n \n For Staff Data Engineer (IV) \n  All the requirements of above and: \n \n 7+ years of professional data engineering experience. \n Led teams (>5) technically on architecture and system design. \n Expert in one of the domains of ETL/ELT pipelines, feature engineering, data modeling and architecture, or data ingestion. \n Experience working autonomously and able to identify large impactful projects to pursue with minimal guidance. \n Deep understanding/experience with: \n \n Data warehouse architecture and design \n Integration of the data stack to other tools/services \n Extensive knowledge with implementing data quality checks \n \n \n Additional Information: \n \n This position is eligible for day-one PERM sponsorship for qualified candidates. \n \n Circle is on a mission to create an inclusive financial future, with transparency at our core. We consider a wide variety of elements when crafting our compensation ranges and total compensation packages. \n  Starting pay is determined by various factors, including but not limited to: relevant experience, skill set, qualifications, and other business and organizational needs. Please note that compensation ranges may differ for candidates in other locations. \n  Senior Data Engineer (III) \n  Base Pay Range: $147,500 - $195,000 \n  Annual Bonus Target: 12.5% \n  Staff Data Engineer (IV) \n  Base Pay Range: $172,500 - $227,500 \n  Annual Bonus Target: 15% \n  Also Included: Equity & Benefits (including medical, dental, vision and 401(k)). Circle has a discretionary vacation policy. We also provide 10 days of paid sick leave per year and 11 paid holidays per year in the U.S. \n \n  We are an  equal opportunity employer  and value diversity at Circle. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Additionally, Circle participates in the  E-Verify Program  in certain locations, as required by law. \n  #LI-Remote",
        "cleaned_desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  As a member of the Data Engineering - Business ETL team, you own the ETL/ELT pipelines and data warehouse that is used for financial and regulatory reporting. Your work powers Circle business functions, including the Compliance, Finance, Accounting, and Analytics teams for experimentation, operational excellence, and actionable insights, so as to fuel and accelerate business growth. High integrity to data accuracy and quality is crucial. Your work will directly impact Circle's transparency, trust, and accountability needs. \n  What you'll work on: \n \n Collaborating with business teams on the design, deployment and continuous improvement of the scalable data platform that ingests, stores, and aggregates various datasets, including data pipelines, platforms, and warehouses, and surfacing data to both internal and customer-facing applications. \n Being a domain expert on data modeling, data pipelines, data quality and data warehousing. \n Designing, building and maintaining data ETL/ELT pipelines to source and aggregate the required data for various data analyses and reporting needs, as well as to continually improve the operations, monitoring and performance of the data warehouse. \n Developing integrations with third party systems to source, qualify and ingest various datasets. \n Providing data analytics and visualization tools to extract valuable insights from the data to enable data-driven decisions.   Proficient in one or more programming languages (Java, Scala, Python). \n Advanced experience in SQL in big data warehouse systems such as Snowflake, BigQuery, Databricks, etc. \n Experience in SQL and NoSQL, such as MySQL, PostgreSQL, Cassandra, HBase, Redis, DynamoDB, Neo4j, etc. \n Experience with workflow orchestration management engines such as Airflow, Dagster, DBT, etc \n Experience with Cloud Services (AWS, Google Cloud, Microsoft Azure, etc). \n Experience in building scalable infrastructure to support batch, micro-batch or stream data processing for large volumes of data. \n Experience with financial or compliance data, bonus if in similar business domains, such as payment systems, credit cards, bank transfers, blockchains, etc. \n Experience in data provenance and governance. \n Internal knowledge of open source or related big data technologies. \n Ability to tackle complex and ambiguous problems. \n Self-starter who takes ownership, gets results, and enjoys moving at a fast pace. \n Excellent communication skills, able to collaborate with across remote teams, share ideas and present concepts effectively. \n   For Staff Data Engineer (IV) \n  All the requirements of above and: \n \n 7+ years of professional data engineering experience. \n Led teams (>5) technically on architecture and system design. \n Expert in one of the domains of ETL/ELT pipelines, feature engineering, data modeling and architecture, or data ingestion. \n Experience working autonomously and able to identify large impactful projects to pursue with minimal guidance. \n Deep understanding/experience with: \n \n Data warehouse architecture and design \n Integration of the data stack to other tools/services \n Extensive knowledge with implementing data quality checks \n ",
        "techs": [
            "circle",
            "usdc",
            "blockchain-based dollar",
            "etl/elt pipelines",
            "data warehouse",
            "compliance",
            "finance",
            "accounting",
            "analytics",
            "data platform",
            "data pipelines",
            "data quality",
            "data warehousing",
            "integrations",
            "third party systems",
            "data analytics",
            "visualization tools",
            "programming languages (java",
            "scala",
            "python)",
            "sql",
            "big data warehouse systems (snowflake",
            "bigquery",
            "databricks)",
            "sql and nosql databases (mysql",
            "postgresql",
            "cassandra",
            "hbase",
            "redis",
            "dynamodb",
            "neo4j)",
            "workflow orchestration management engines (airflow",
            "dagster",
            "dbt)",
            "cloud services (aws",
            "google cloud",
            "microsoft azure)",
            "scalable infrastructure",
            "batch processing",
            "micro-batch processing",
            "stream data processing",
            "financial data",
            "compliance data",
            "data provenance",
            "data governance",
            "open source technologies",
            "complex problem solving",
            "communication skills",
            "staff data engineer (iv)",
            "data engineering experience",
            "team leadership",
            "system design",
            "etl/elt pipelines",
            "feature engineering",
            "data modeling",
            "data ingestion",
            "data warehouse architecture",
            "data stack integration",
            "data quality checks."
        ],
        "cleaned_techs": [
            "circle",
            "usdc",
            "blockchain-based dollar",
            "etl/elt pipelines",
            "data warehouse",
            "compliance",
            "finance",
            "accounting",
            "data platform",
            "data pipelines",
            "data quality",
            "data warehousing",
            "integrations",
            "third party systems",
            "data analytics",
            "visualization tools",
            "programming languages (java",
            "scala",
            "python",
            "sql",
            "big data warehouse systems (snowflake",
            "bigquery",
            "databricks)",
            "postgresql",
            "cassandra",
            "hbase",
            "redis",
            "dynamodb",
            "neo4j)",
            "workflow orchestration management engines (airflow",
            "dagster",
            "dbt)",
            "cloud services (aws",
            "gcp",
            "microsoft azure)",
            "scalable infrastructure",
            "batch processing",
            "micro-batch processing",
            "stream data processing",
            "financial data",
            "compliance data",
            "data provenance",
            "data governance",
            "open source technologies",
            "complex problem solving",
            "staff data engineer (iv)",
            "data engineering experience",
            "team leadership",
            "system design",
            "feature engineering",
            "data ingestion",
            "data warehouse architecture",
            "data stack integration",
            "data quality checks."
        ]
    },
    "06f8409cf2489c01": {
        "terms": [
            "data science",
            "data engineer"
        ],
        "salary_min": 147500.0,
        "salary_max": 195000.0,
        "title": "Senior Data Engineer",
        "company": "Circle",
        "desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  As a member of the Data Engineering - Business ETL team, you own the ETL/ELT pipelines and data warehouse that is used for financial and regulatory reporting. Your work powers Circle business functions, including the Compliance, Finance, Accounting, and Analytics teams for experimentation, operational excellence, and actionable insights, so as to fuel and accelerate business growth. High integrity to data accuracy and quality is crucial. Your work will directly impact Circle's transparency, trust, and accountability needs. \n  What you'll work on: \n \n Collaborating with business teams on the design, deployment and continuous improvement of the scalable data platform that ingests, stores, and aggregates various datasets, including data pipelines, platforms, and warehouses, and surfacing data to both internal and customer-facing applications. \n Being a domain expert on data modeling, data pipelines, data quality and data warehousing. \n Designing, building and maintaining data ETL/ELT pipelines to source and aggregate the required data for various data analyses and reporting needs, as well as to continually improve the operations, monitoring and performance of the data warehouse. \n Developing integrations with third party systems to source, qualify and ingest various datasets. \n Providing data analytics and visualization tools to extract valuable insights from the data to enable data-driven decisions. \n Working closely with across groups, such as the product, engineering, data science, compliance, and security teams, for data modeling, general management of data life cycle, data governance and processes for meeting regulatory and legal requirements. \n \n You will aspire to our four core values: \n \n Multistakeholder - you have dedication and commitment to our customers, shareholders, employees and families and local communities. \n Mindful - you seek to be respectful, an active listener and to pay attention to detail. \n Driven by Excellence - you are driven by our mission and our passion for customer success which means you relentlessly pursue excellence, that you do not tolerate mediocrity and you work intensely to achieve your goals. \n High Integrity - you seek open and honest communication, and you hold yourself to very high moral and ethical standards. You reject manipulation, dishonesty and intolerance. \n \n What you'll bring to Circle: \n  For Senior Data Engineer (III) \n \n 4+ years of professional data engineering experience. \n Proficient in one or more programming languages (Java, Scala, Python). \n Advanced experience in SQL in big data warehouse systems such as Snowflake, BigQuery, Databricks, etc. \n Experience in SQL and NoSQL, such as MySQL, PostgreSQL, Cassandra, HBase, Redis, DynamoDB, Neo4j, etc. \n Experience with workflow orchestration management engines such as Airflow, Dagster, DBT, etc \n Experience with Cloud Services (AWS, Google Cloud, Microsoft Azure, etc). \n Experience in building scalable infrastructure to support batch, micro-batch or stream data processing for large volumes of data. \n Experience with financial or compliance data, bonus if in similar business domains, such as payment systems, credit cards, bank transfers, blockchains, etc. \n Experience in data provenance and governance. \n Internal knowledge of open source or related big data technologies. \n Ability to tackle complex and ambiguous problems. \n Self-starter who takes ownership, gets results, and enjoys moving at a fast pace. \n Excellent communication skills, able to collaborate with across remote teams, share ideas and present concepts effectively. \n \n For Staff Data Engineer (IV) \n  All the requirements of above and: \n \n 7+ years of professional data engineering experience. \n Led teams (>5) technically on architecture and system design. \n Expert in one of the domains of ETL/ELT pipelines, feature engineering, data modeling and architecture, or data ingestion. \n Experience working autonomously and able to identify large impactful projects to pursue with minimal guidance. \n Deep understanding/experience with: \n \n Data warehouse architecture and design \n Integration of the data stack to other tools/services \n Extensive knowledge with implementing data quality checks \n \n \n Additional Information: \n \n This position is eligible for day-one PERM sponsorship for qualified candidates. \n \n Circle is on a mission to create an inclusive financial future, with transparency at our core. We consider a wide variety of elements when crafting our compensation ranges and total compensation packages. \n  Starting pay is determined by various factors, including but not limited to: relevant experience, skill set, qualifications, and other business and organizational needs. Please note that compensation ranges may differ for candidates in other locations. \n  Senior Data Engineer (III) \n  Base Pay Range: $147,500 - $195,000 \n  Annual Bonus Target: 12.5% \n  Staff Data Engineer (IV) \n  Base Pay Range: $172,500 - $227,500 \n  Annual Bonus Target: 15% \n  Also Included: Equity & Benefits (including medical, dental, vision and 401(k)). Circle has a discretionary vacation policy. We also provide 10 days of paid sick leave per year and 11 paid holidays per year in the U.S. \n \n  We are an  equal opportunity employer  and value diversity at Circle. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Additionally, Circle participates in the  E-Verify Program  in certain locations, as required by law. \n  #LI-Remote",
        "cleaned_desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  As a member of the Data Engineering - Business ETL team, you own the ETL/ELT pipelines and data warehouse that is used for financial and regulatory reporting. Your work powers Circle business functions, including the Compliance, Finance, Accounting, and Analytics teams for experimentation, operational excellence, and actionable insights, so as to fuel and accelerate business growth. High integrity to data accuracy and quality is crucial. Your work will directly impact Circle's transparency, trust, and accountability needs. \n  What you'll work on: \n \n Collaborating with business teams on the design, deployment and continuous improvement of the scalable data platform that ingests, stores, and aggregates various datasets, including data pipelines, platforms, and warehouses, and surfacing data to both internal and customer-facing applications. \n Being a domain expert on data modeling, data pipelines, data quality and data warehousing. \n Designing, building and maintaining data ETL/ELT pipelines to source and aggregate the required data for various data analyses and reporting needs, as well as to continually improve the operations, monitoring and performance of the data warehouse. \n Developing integrations with third party systems to source, qualify and ingest various datasets. \n Providing data analytics and visualization tools to extract valuable insights from the data to enable data-driven decisions.   Proficient in one or more programming languages (Java, Scala, Python). \n Advanced experience in SQL in big data warehouse systems such as Snowflake, BigQuery, Databricks, etc. \n Experience in SQL and NoSQL, such as MySQL, PostgreSQL, Cassandra, HBase, Redis, DynamoDB, Neo4j, etc. \n Experience with workflow orchestration management engines such as Airflow, Dagster, DBT, etc \n Experience with Cloud Services (AWS, Google Cloud, Microsoft Azure, etc). \n Experience in building scalable infrastructure to support batch, micro-batch or stream data processing for large volumes of data. \n Experience with financial or compliance data, bonus if in similar business domains, such as payment systems, credit cards, bank transfers, blockchains, etc. \n Experience in data provenance and governance. \n Internal knowledge of open source or related big data technologies. \n Ability to tackle complex and ambiguous problems. \n Self-starter who takes ownership, gets results, and enjoys moving at a fast pace. \n Excellent communication skills, able to collaborate with across remote teams, share ideas and present concepts effectively. \n   For Staff Data Engineer (IV) \n  All the requirements of above and: \n \n 7+ years of professional data engineering experience. \n Led teams (>5) technically on architecture and system design. \n Expert in one of the domains of ETL/ELT pipelines, feature engineering, data modeling and architecture, or data ingestion. \n Experience working autonomously and able to identify large impactful projects to pursue with minimal guidance. \n Deep understanding/experience with: \n \n Data warehouse architecture and design \n Integration of the data stack to other tools/services \n Extensive knowledge with implementing data quality checks \n ",
        "techs": [
            "circle is a financial technology company",
            "usdc",
            "blockchain-based dollar",
            "data engineering",
            "etl/elt pipelines",
            "data warehouse",
            "compliance",
            "finance",
            "accounting",
            "analytics",
            "data modeling",
            "data quality",
            "data warehousing",
            "data etl/elt pipelines",
            "programming languages",
            "sql",
            "big data warehouse systems",
            "snowflake",
            "bigquery",
            "databricks",
            "mysql",
            "postgresql",
            "cassandra",
            "hbase",
            "redis",
            "dynamodb",
            "neo4j",
            "workflow orchestration management engines",
            "airflow",
            "dagster",
            "dbt",
            "cloud services",
            "aws",
            "google cloud",
            "microsoft azure",
            "batch data processing",
            "micro-batch data processing",
            "stream data processing",
            "financial data",
            "compliance data",
            "payment systems",
            "credit cards",
            "bank transfers",
            "blockchains",
            "data provenance",
            "data governance",
            "open source",
            "big data technologies",
            "complex problem-solving",
            "communication skills",
            "staff data engineer",
            "architecture and system design",
            "etl/elt pipelines",
            "feature engineering",
            "data modeling",
            "data ingestion",
            "data warehouse architecture",
            "integration of the data stack",
            "data quality checks."
        ],
        "cleaned_techs": [
            "circle is a financial technology company",
            "usdc",
            "blockchain-based dollar",
            "etl/elt pipelines",
            "data warehouse",
            "compliance",
            "finance",
            "accounting",
            "data quality",
            "data warehousing",
            "data etl/elt pipelines",
            "programming languages",
            "sql",
            "big data warehouse systems",
            "snowflake",
            "bigquery",
            "databricks",
            "mysql",
            "postgresql",
            "cassandra",
            "hbase",
            "redis",
            "dynamodb",
            "neo4j",
            "workflow orchestration management engines",
            "airflow",
            "dagster",
            "dbt",
            "cloud services",
            "aws",
            "gcp",
            "microsoft azure",
            "batch data processing",
            "micro-batch data processing",
            "stream data processing",
            "financial data",
            "compliance data",
            "payment systems",
            "credit cards",
            "bank transfers",
            "blockchains",
            "data provenance",
            "data governance",
            "open source",
            "big data technologies",
            "complex problem-solving",
            "staff data engineer",
            "architecture and system design",
            "feature engineering",
            "data ingestion",
            "data warehouse architecture",
            "integration of the data stack",
            "data quality checks."
        ]
    },
    "a19b2f325cbf745c": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 156453.0,
        "salary_max": 197802.0,
        "title": "Sr. Machine Learning Engineer",
        "company": "AMP Robotics",
        "desc": "AMP Robotics is a pioneer and industry leader in artificial intelligence and robotics for the recycling industry. We're reimagining and actively modernizing the world's recycling infrastructure. Headquartered and with manufacturing operations in Louisville, Colorado, we build and deploy technology that solves many of the central challenges of recycling and shifts the economics of the industry to make it more efficient, cost-effective, scalable, and sustainable.  \n With more than 270 systems installed across North America, Japan, and Europe, we're increasing the value that can be extracted from recyclable material through superior separation, purity enhancement, and identification of new end markets for reuse and recycling. Our diverse, growing team of environmentalists, engineers, and other professionals shares a passion for the promise technology holds to transform the way we recycle. With backing from top-tier investors including Sequoia Capital and recognition including Fast Company's Most Innovative Companies and Forbes' most promising artificial intelligence companies in America, we're always seeking ways to better our operations, raising the bar on innovation, and looking to collaborate and improve each day in what we do. Learn more at AMPRobotics.com. \n  AMP Robotics is hiring a Sr Machine Learning Engineer,  reporting to the  Sr. Manager of AI . This position can be  remote  in the United States. \n  AMP doesn't just do machine learning, we are driven forward by it. Our core technology revolves around deep-learned models applied to robotics domains, and we are always striving to extend our performance. In pursuit of this, AMP is looking for a highly skilled individual to join our machine learning team and aid in building out cutting edge computer vision technology. In this role, you would be an individual contributor on our deep learning modeling team, working on research and development projects to help us implement state of the art deep learning techniques. In this senior role, you would additionally have the opportunity to mentor the existing team, and contribute to R&D strategy for the company. You would aid in bringing models from ideation all the way through to production, and help us to maintain our technological edge. \n  As our Sr Machine Learning Engineer, you will work to:  \n \n Experiment with modern neural network architectures or techniques driven by research publications \n Design and implement deep learned computer vision solutions in new domains \n Design and execute experiments to validate R&D deep learning approaches \n Assist in productionizing experimental approaches proven to work \n Mentor and collaborate with small teams of ML modeling engineers, ML infrastructure engineers, and AI Data Project Managers \n Help us support and improve our ML infrastructure \n \n The successful candidate will have: \n  Required:  \n \n Master's degree in Computer Science/Machine Learning or similar, or equivalent combination of technical education and work experience. \n 2-4 years experience writing production-level code in python. \n 4+ years of experience implementing statistical models in production environments \n Proficiency with professional software engineering practices; including coding standards, code reviews, source control management, build processes, testing, and operations. \n Ability to work on a small team and self-manage. \n Strong familiarity with either Tensorflow or PyTorch. \n Research fluency with a deep learning domain. \n \n Preferred:  \n \n 3+ years of experience with deep learning, particularly computer vision \n Familiarity and interest in research-level mathematics. \n Future interest in management of a small, technical team. \n Proficiency working with SQL databases and data pipelines. \n Startup ready mentality \n Passion for recycling, robotics and changing the world \n \n Bonus:  \n \n Production RL experience \n CV experience in a scaled company \n \n Physical environment / physical demands: \n \n The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. \n While performing the duties of this job, the employee is frequently required to stand, walk, use hands and fingers, handle or feel, reach with hands and arms, climb or balance, stoop, kneel, crouch, or crawl and talk and hear. \n The employee must occasionally lift and/or move up to 45 pounds. \n Specific vision abilities required by this job include close vision, peripheral vision, depth perception and ability to adjust focus, and ability to accurately see and label color. \n \n Working Location(s): \n \n Remote, United States \n \n Travel Requirements: \n \n Occasional travel, quarterly basis possible \n \n AMP provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. \n  Applicants who identify with a historically underrepresented group are encouraged to apply. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. \n  Other duties: \n  Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice. \n  Salary & Compensation Information : $156,453 - $197,802 per year \n  Equity Grant:  The candidate selected for this role will be recommended for a stock option grant commensurate with the position and the candidate's qualifications. \n  Benefits Information: \n \n Medical - The company covers up 85% to 100% of the premium for Cigna medical healthcare plans depending on the selection. Employees pay the difference in premium if they select a more expensive plan. Up to 75% for dependents. \n Dental, Vision, Short and Long Term Disability \n Life Insurance: The company covers the cost of Basic Life / AD&D 1 x Salary, option to purchase additional through New York Life \n Benefits start the day you start \n HSA Eligible Health Plans \n 401(k) retirement plan (non-matching) \n FTO - Flexible Time Off \n 6 Accrued Sick Days \n Eight (8) paid holidays \n \n #LI-Remote",
        "cleaned_desc": "  Required:  \n \n Master's degree in Computer Science/Machine Learning or similar, or equivalent combination of technical education and work experience. \n 2-4 years experience writing production-level code in python. \n 4+ years of experience implementing statistical models in production environments \n Proficiency with professional software engineering practices; including coding standards, code reviews, source control management, build processes, testing, and operations. \n Ability to work on a small team and self-manage. \n Strong familiarity with either Tensorflow or PyTorch. \n Research fluency with a deep learning domain. \n \n Preferred:  \n \n 3+ years of experience with deep learning, particularly computer vision \n Familiarity and interest in research-level mathematics. ",
        "techs": [
            "python",
            "statistical models",
            "tensorflow",
            "pytorch",
            "deep learning",
            "computer vision",
            "mathematics"
        ],
        "cleaned_techs": [
            "python",
            "statistical models",
            "tensorflow",
            "pytorch",
            "computer vision",
            "mathematics"
        ]
    },
    "a92bb69a76078f14": {
        "terms": [
            "data science",
            "data engineer"
        ],
        "salary_min": 147500.0,
        "salary_max": 195000.0,
        "title": "Senior Data Engineer",
        "company": "Circle",
        "desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  As a member of the Data Engineering - Business ETL team, you own the ETL/ELT pipelines and data warehouse that is used for financial and regulatory reporting. Your work powers Circle business functions, including the Compliance, Finance, Accounting, and Analytics teams for experimentation, operational excellence, and actionable insights, so as to fuel and accelerate business growth. High integrity to data accuracy and quality is crucial. Your work will directly impact Circle's transparency, trust, and accountability needs. \n  What you'll work on: \n \n Collaborating with business teams on the design, deployment and continuous improvement of the scalable data platform that ingests, stores, and aggregates various datasets, including data pipelines, platforms, and warehouses, and surfacing data to both internal and customer-facing applications. \n Being a domain expert on data modeling, data pipelines, data quality and data warehousing. \n Designing, building and maintaining data ETL/ELT pipelines to source and aggregate the required data for various data analyses and reporting needs, as well as to continually improve the operations, monitoring and performance of the data warehouse. \n Developing integrations with third party systems to source, qualify and ingest various datasets. \n Providing data analytics and visualization tools to extract valuable insights from the data to enable data-driven decisions. \n Working closely with across groups, such as the product, engineering, data science, compliance, and security teams, for data modeling, general management of data life cycle, data governance and processes for meeting regulatory and legal requirements. \n \n You will aspire to our four core values: \n \n Multistakeholder - you have dedication and commitment to our customers, shareholders, employees and families and local communities. \n Mindful - you seek to be respectful, an active listener and to pay attention to detail. \n Driven by Excellence - you are driven by our mission and our passion for customer success which means you relentlessly pursue excellence, that you do not tolerate mediocrity and you work intensely to achieve your goals. \n High Integrity - you seek open and honest communication, and you hold yourself to very high moral and ethical standards. You reject manipulation, dishonesty and intolerance. \n \n What you'll bring to Circle: \n  For Senior Data Engineer (III) \n \n 4+ years of professional data engineering experience. \n Proficient in one or more programming languages (Java, Scala, Python). \n Advanced experience in SQL in big data warehouse systems such as Snowflake, BigQuery, Databricks, etc. \n Experience in SQL and NoSQL, such as MySQL, PostgreSQL, Cassandra, HBase, Redis, DynamoDB, Neo4j, etc. \n Experience with workflow orchestration management engines such as Airflow, Dagster, DBT, etc \n Experience with Cloud Services (AWS, Google Cloud, Microsoft Azure, etc). \n Experience in building scalable infrastructure to support batch, micro-batch or stream data processing for large volumes of data. \n Experience with financial or compliance data, bonus if in similar business domains, such as payment systems, credit cards, bank transfers, blockchains, etc. \n Experience in data provenance and governance. \n Internal knowledge of open source or related big data technologies. \n Ability to tackle complex and ambiguous problems. \n Self-starter who takes ownership, gets results, and enjoys moving at a fast pace. \n Excellent communication skills, able to collaborate with across remote teams, share ideas and present concepts effectively. \n \n For Staff Data Engineer (IV) \n  All the requirements of above and: \n \n 7+ years of professional data engineering experience. \n Led teams (>5) technically on architecture and system design. \n Expert in one of the domains of ETL/ELT pipelines, feature engineering, data modeling and architecture, or data ingestion. \n Experience working autonomously and able to identify large impactful projects to pursue with minimal guidance. \n Deep understanding/experience with: \n \n Data warehouse architecture and design \n Integration of the data stack to other tools/services \n Extensive knowledge with implementing data quality checks \n \n \n Additional Information: \n \n This position is eligible for day-one PERM sponsorship for qualified candidates. \n \n Circle is on a mission to create an inclusive financial future, with transparency at our core. We consider a wide variety of elements when crafting our compensation ranges and total compensation packages. \n  Starting pay is determined by various factors, including but not limited to: relevant experience, skill set, qualifications, and other business and organizational needs. Please note that compensation ranges may differ for candidates in other locations. \n  Senior Data Engineer (III) \n  Base Pay Range: $147,500 - $195,000 \n  Annual Bonus Target: 12.5% \n  Staff Data Engineer (IV) \n  Base Pay Range: $172,500 - $227,500 \n  Annual Bonus Target: 15% \n  Also Included: Equity & Benefits (including medical, dental, vision and 401(k)). Circle has a discretionary vacation policy. We also provide 10 days of paid sick leave per year and 11 paid holidays per year in the U.S. \n \n  We are an  equal opportunity employer  and value diversity at Circle. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Additionally, Circle participates in the  E-Verify Program  in certain locations, as required by law. \n  #LI-Remote",
        "cleaned_desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  As a member of the Data Engineering - Business ETL team, you own the ETL/ELT pipelines and data warehouse that is used for financial and regulatory reporting. Your work powers Circle business functions, including the Compliance, Finance, Accounting, and Analytics teams for experimentation, operational excellence, and actionable insights, so as to fuel and accelerate business growth. High integrity to data accuracy and quality is crucial. Your work will directly impact Circle's transparency, trust, and accountability needs. \n  What you'll work on: \n \n Collaborating with business teams on the design, deployment and continuous improvement of the scalable data platform that ingests, stores, and aggregates various datasets, including data pipelines, platforms, and warehouses, and surfacing data to both internal and customer-facing applications. \n Being a domain expert on data modeling, data pipelines, data quality and data warehousing. \n Designing, building and maintaining data ETL/ELT pipelines to source and aggregate the required data for various data analyses and reporting needs, as well as to continually improve the operations, monitoring and performance of the data warehouse. \n Developing integrations with third party systems to source, qualify and ingest various datasets. \n Providing data analytics and visualization tools to extract valuable insights from the data to enable data-driven decisions.   Proficient in one or more programming languages (Java, Scala, Python). \n Advanced experience in SQL in big data warehouse systems such as Snowflake, BigQuery, Databricks, etc. \n Experience in SQL and NoSQL, such as MySQL, PostgreSQL, Cassandra, HBase, Redis, DynamoDB, Neo4j, etc. \n Experience with workflow orchestration management engines such as Airflow, Dagster, DBT, etc \n Experience with Cloud Services (AWS, Google Cloud, Microsoft Azure, etc). \n Experience in building scalable infrastructure to support batch, micro-batch or stream data processing for large volumes of data. \n Experience with financial or compliance data, bonus if in similar business domains, such as payment systems, credit cards, bank transfers, blockchains, etc. \n Experience in data provenance and governance. \n Internal knowledge of open source or related big data technologies. \n Ability to tackle complex and ambiguous problems. \n Self-starter who takes ownership, gets results, and enjoys moving at a fast pace. \n Excellent communication skills, able to collaborate with across remote teams, share ideas and present concepts effectively. \n   For Staff Data Engineer (IV) \n  All the requirements of above and: \n \n 7+ years of professional data engineering experience. \n Led teams (>5) technically on architecture and system design. \n Expert in one of the domains of ETL/ELT pipelines, feature engineering, data modeling and architecture, or data ingestion. \n Experience working autonomously and able to identify large impactful projects to pursue with minimal guidance. \n Deep understanding/experience with: \n \n Data warehouse architecture and design \n Integration of the data stack to other tools/services \n Extensive knowledge with implementing data quality checks \n ",
        "techs": [
            "circle",
            "usdc",
            "blockchain-based dollar",
            "etl/elt pipelines",
            "data warehouse",
            "compliance",
            "finance",
            "accounting",
            "analytics teams",
            "data modeling",
            "data quality",
            "data warehousing",
            "data etl/elt pipelines",
            "third party systems integration",
            "data analytics",
            "visualization tools",
            "programming languages (java",
            "scala",
            "python)",
            "sql (snowflake",
            "bigquery",
            "databricks)",
            "sql and nosql databases (mysql",
            "postgresql",
            "cassandra",
            "hbase",
            "redis",
            "dynamodb",
            "neo4j)",
            "workflow orchestration management engines (airflow",
            "dagster",
            "dbt)",
            "cloud services (aws",
            "google cloud",
            "microsoft azure)",
            "batch",
            "micro-batch",
            "and stream data processing",
            "financial or compliance data",
            "data provenance and governance",
            "open source big data technologies",
            "complex problem solving",
            "communication skills",
            "staff data engineer (iv)",
            "data engineering experience",
            "architecture and system design",
            "etl/elt pipelines",
            "feature engineering",
            "data modeling and architecture",
            "data ingestion",
            "data warehouse architecture and design",
            "data stack integration",
            "data quality checks"
        ],
        "cleaned_techs": [
            "circle",
            "usdc",
            "blockchain-based dollar",
            "etl/elt pipelines",
            "data warehouse",
            "compliance",
            "finance",
            "accounting",
            "analytics teams",
            "data quality",
            "data warehousing",
            "data etl/elt pipelines",
            "third party systems integration",
            "data analytics",
            "visualization tools",
            "programming languages (java",
            "scala",
            "python",
            "sql",
            "bigquery",
            "databricks)",
            "postgresql",
            "cassandra",
            "hbase",
            "redis",
            "dynamodb",
            "neo4j)",
            "workflow orchestration management engines (airflow",
            "dagster",
            "dbt)",
            "cloud services (aws",
            "gcp",
            "microsoft azure)",
            "batch",
            "micro-batch",
            "and stream data processing",
            "financial or compliance data",
            "data provenance and governance",
            "open source big data technologies",
            "complex problem solving",
            "staff data engineer (iv)",
            "data engineering experience",
            "architecture and system design",
            "feature engineering",
            "data modeling and architecture",
            "data ingestion",
            "data warehouse architecture and design",
            "data stack integration",
            "data quality checks"
        ]
    },
    "6b08d71c5f140905": {
        "terms": [
            "data science",
            "data engineer"
        ],
        "salary_min": 147500.0,
        "salary_max": 195000.0,
        "title": "Senior Data Engineer",
        "company": "Circle",
        "desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  As a member of the Data Engineering - Business ETL team, you own the ETL/ELT pipelines and data warehouse that is used for financial and regulatory reporting. Your work powers Circle business functions, including the Compliance, Finance, Accounting, and Analytics teams for experimentation, operational excellence, and actionable insights, so as to fuel and accelerate business growth. High integrity to data accuracy and quality is crucial. Your work will directly impact Circle's transparency, trust, and accountability needs. \n  What you'll work on: \n \n Collaborating with business teams on the design, deployment and continuous improvement of the scalable data platform that ingests, stores, and aggregates various datasets, including data pipelines, platforms, and warehouses, and surfacing data to both internal and customer-facing applications. \n Being a domain expert on data modeling, data pipelines, data quality and data warehousing. \n Designing, building and maintaining data ETL/ELT pipelines to source and aggregate the required data for various data analyses and reporting needs, as well as to continually improve the operations, monitoring and performance of the data warehouse. \n Developing integrations with third party systems to source, qualify and ingest various datasets. \n Providing data analytics and visualization tools to extract valuable insights from the data to enable data-driven decisions. \n Working closely with across groups, such as the product, engineering, data science, compliance, and security teams, for data modeling, general management of data life cycle, data governance and processes for meeting regulatory and legal requirements. \n \n You will aspire to our four core values: \n \n Multistakeholder - you have dedication and commitment to our customers, shareholders, employees and families and local communities. \n Mindful - you seek to be respectful, an active listener and to pay attention to detail. \n Driven by Excellence - you are driven by our mission and our passion for customer success which means you relentlessly pursue excellence, that you do not tolerate mediocrity and you work intensely to achieve your goals. \n High Integrity - you seek open and honest communication, and you hold yourself to very high moral and ethical standards. You reject manipulation, dishonesty and intolerance. \n \n What you'll bring to Circle: \n  For Senior Data Engineer (III) \n \n 4+ years of professional data engineering experience. \n Proficient in one or more programming languages (Java, Scala, Python). \n Advanced experience in SQL in big data warehouse systems such as Snowflake, BigQuery, Databricks, etc. \n Experience in SQL and NoSQL, such as MySQL, PostgreSQL, Cassandra, HBase, Redis, DynamoDB, Neo4j, etc. \n Experience with workflow orchestration management engines such as Airflow, Dagster, DBT, etc \n Experience with Cloud Services (AWS, Google Cloud, Microsoft Azure, etc). \n Experience in building scalable infrastructure to support batch, micro-batch or stream data processing for large volumes of data. \n Experience with financial or compliance data, bonus if in similar business domains, such as payment systems, credit cards, bank transfers, blockchains, etc. \n Experience in data provenance and governance. \n Internal knowledge of open source or related big data technologies. \n Ability to tackle complex and ambiguous problems. \n Self-starter who takes ownership, gets results, and enjoys moving at a fast pace. \n Excellent communication skills, able to collaborate with across remote teams, share ideas and present concepts effectively. \n \n For Staff Data Engineer (IV) \n  All the requirements of above and: \n \n 7+ years of professional data engineering experience. \n Led teams (>5) technically on architecture and system design. \n Expert in one of the domains of ETL/ELT pipelines, feature engineering, data modeling and architecture, or data ingestion. \n Experience working autonomously and able to identify large impactful projects to pursue with minimal guidance. \n Deep understanding/experience with: \n \n Data warehouse architecture and design \n Integration of the data stack to other tools/services \n Extensive knowledge with implementing data quality checks \n \n \n Additional Information: \n \n This position is eligible for day-one PERM sponsorship for qualified candidates. \n \n Circle is on a mission to create an inclusive financial future, with transparency at our core. We consider a wide variety of elements when crafting our compensation ranges and total compensation packages. \n  Starting pay is determined by various factors, including but not limited to: relevant experience, skill set, qualifications, and other business and organizational needs. Please note that compensation ranges may differ for candidates in other locations. \n  Senior Data Engineer (III) \n  Base Pay Range: $147,500 - $195,000 \n  Annual Bonus Target: 12.5% \n  Staff Data Engineer (IV) \n  Base Pay Range: $172,500 - $227,500 \n  Annual Bonus Target: 15% \n  Also Included: Equity & Benefits (including medical, dental, vision and 401(k)). Circle has a discretionary vacation policy. We also provide 10 days of paid sick leave per year and 11 paid holidays per year in the U.S. \n \n  We are an  equal opportunity employer  and value diversity at Circle. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Additionally, Circle participates in the  E-Verify Program  in certain locations, as required by law. \n  #LI-Remote",
        "cleaned_desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  As a member of the Data Engineering - Business ETL team, you own the ETL/ELT pipelines and data warehouse that is used for financial and regulatory reporting. Your work powers Circle business functions, including the Compliance, Finance, Accounting, and Analytics teams for experimentation, operational excellence, and actionable insights, so as to fuel and accelerate business growth. High integrity to data accuracy and quality is crucial. Your work will directly impact Circle's transparency, trust, and accountability needs. \n  What you'll work on: \n \n Collaborating with business teams on the design, deployment and continuous improvement of the scalable data platform that ingests, stores, and aggregates various datasets, including data pipelines, platforms, and warehouses, and surfacing data to both internal and customer-facing applications. \n Being a domain expert on data modeling, data pipelines, data quality and data warehousing. \n Designing, building and maintaining data ETL/ELT pipelines to source and aggregate the required data for various data analyses and reporting needs, as well as to continually improve the operations, monitoring and performance of the data warehouse. \n Developing integrations with third party systems to source, qualify and ingest various datasets. \n Providing data analytics and visualization tools to extract valuable insights from the data to enable data-driven decisions.   Proficient in one or more programming languages (Java, Scala, Python). \n Advanced experience in SQL in big data warehouse systems such as Snowflake, BigQuery, Databricks, etc. \n Experience in SQL and NoSQL, such as MySQL, PostgreSQL, Cassandra, HBase, Redis, DynamoDB, Neo4j, etc. \n Experience with workflow orchestration management engines such as Airflow, Dagster, DBT, etc \n Experience with Cloud Services (AWS, Google Cloud, Microsoft Azure, etc). \n Experience in building scalable infrastructure to support batch, micro-batch or stream data processing for large volumes of data. \n Experience with financial or compliance data, bonus if in similar business domains, such as payment systems, credit cards, bank transfers, blockchains, etc. \n Experience in data provenance and governance. \n Internal knowledge of open source or related big data technologies. \n Ability to tackle complex and ambiguous problems. \n Self-starter who takes ownership, gets results, and enjoys moving at a fast pace. \n Excellent communication skills, able to collaborate with across remote teams, share ideas and present concepts effectively. \n   For Staff Data Engineer (IV) \n  All the requirements of above and: \n \n 7+ years of professional data engineering experience. \n Led teams (>5) technically on architecture and system design. \n Expert in one of the domains of ETL/ELT pipelines, feature engineering, data modeling and architecture, or data ingestion. \n Experience working autonomously and able to identify large impactful projects to pursue with minimal guidance. \n Deep understanding/experience with: \n \n Data warehouse architecture and design \n Integration of the data stack to other tools/services \n Extensive knowledge with implementing data quality checks \n ",
        "techs": [
            "circle",
            "usdc",
            "blockchain-based dollar",
            "etl/elt pipelines",
            "data warehouse",
            "compliance",
            "finance",
            "accounting",
            "analytics teams",
            "data modeling",
            "data quality",
            "data warehousing",
            "data etl/elt pipelines",
            "third party systems",
            "data analytics",
            "visualization tools",
            "programming languages (java",
            "scala",
            "python)",
            "sql",
            "big data warehouse systems (snowflake",
            "bigquery",
            "databricks)",
            "sql and nosql databases (mysql",
            "postgresql",
            "cassandra",
            "hbase",
            "redis",
            "dynamodb",
            "neo4j)",
            "workflow orchestration management engines (airflow",
            "dagster",
            "dbt)",
            "cloud services (aws",
            "google cloud",
            "microsoft azure)",
            "batch processing",
            "micro-batch processing",
            "stream data processing",
            "financial data",
            "compliance data",
            "data provenance",
            "data governance",
            "open source big data technologies",
            "staff data engineer"
        ],
        "cleaned_techs": [
            "circle",
            "usdc",
            "blockchain-based dollar",
            "etl/elt pipelines",
            "data warehouse",
            "compliance",
            "finance",
            "accounting",
            "analytics teams",
            "data quality",
            "data warehousing",
            "data etl/elt pipelines",
            "third party systems",
            "data analytics",
            "visualization tools",
            "programming languages (java",
            "scala",
            "python",
            "sql",
            "big data warehouse systems (snowflake",
            "bigquery",
            "databricks)",
            "postgresql",
            "cassandra",
            "hbase",
            "redis",
            "dynamodb",
            "neo4j)",
            "workflow orchestration management engines (airflow",
            "dagster",
            "dbt)",
            "cloud services (aws",
            "gcp",
            "microsoft azure)",
            "batch processing",
            "micro-batch processing",
            "stream data processing",
            "financial data",
            "compliance data",
            "data provenance",
            "data governance",
            "open source big data technologies",
            "staff data engineer"
        ]
    },
    "a80142a16c0f91c1": {
        "terms": [
            "data science",
            "data engineer"
        ],
        "salary_min": 147500.0,
        "salary_max": 195000.0,
        "title": "Senior Data Engineer",
        "company": "Circle",
        "desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  As a member of the Data Engineering - Business ETL team, you own the ETL/ELT pipelines and data warehouse that is used for financial and regulatory reporting. Your work powers Circle business functions, including the Compliance, Finance, Accounting, and Analytics teams for experimentation, operational excellence, and actionable insights, so as to fuel and accelerate business growth. High integrity to data accuracy and quality is crucial. Your work will directly impact Circle's transparency, trust, and accountability needs. \n  What you'll work on: \n \n Collaborating with business teams on the design, deployment and continuous improvement of the scalable data platform that ingests, stores, and aggregates various datasets, including data pipelines, platforms, and warehouses, and surfacing data to both internal and customer-facing applications. \n Being a domain expert on data modeling, data pipelines, data quality and data warehousing. \n Designing, building and maintaining data ETL/ELT pipelines to source and aggregate the required data for various data analyses and reporting needs, as well as to continually improve the operations, monitoring and performance of the data warehouse. \n Developing integrations with third party systems to source, qualify and ingest various datasets. \n Providing data analytics and visualization tools to extract valuable insights from the data to enable data-driven decisions. \n Working closely with across groups, such as the product, engineering, data science, compliance, and security teams, for data modeling, general management of data life cycle, data governance and processes for meeting regulatory and legal requirements. \n \n You will aspire to our four core values: \n \n Multistakeholder - you have dedication and commitment to our customers, shareholders, employees and families and local communities. \n Mindful - you seek to be respectful, an active listener and to pay attention to detail. \n Driven by Excellence - you are driven by our mission and our passion for customer success which means you relentlessly pursue excellence, that you do not tolerate mediocrity and you work intensely to achieve your goals. \n High Integrity - you seek open and honest communication, and you hold yourself to very high moral and ethical standards. You reject manipulation, dishonesty and intolerance. \n \n What you'll bring to Circle: \n  For Senior Data Engineer (III) \n \n 4+ years of professional data engineering experience. \n Proficient in one or more programming languages (Java, Scala, Python). \n Advanced experience in SQL in big data warehouse systems such as Snowflake, BigQuery, Databricks, etc. \n Experience in SQL and NoSQL, such as MySQL, PostgreSQL, Cassandra, HBase, Redis, DynamoDB, Neo4j, etc. \n Experience with workflow orchestration management engines such as Airflow, Dagster, DBT, etc \n Experience with Cloud Services (AWS, Google Cloud, Microsoft Azure, etc). \n Experience in building scalable infrastructure to support batch, micro-batch or stream data processing for large volumes of data. \n Experience with financial or compliance data, bonus if in similar business domains, such as payment systems, credit cards, bank transfers, blockchains, etc. \n Experience in data provenance and governance. \n Internal knowledge of open source or related big data technologies. \n Ability to tackle complex and ambiguous problems. \n Self-starter who takes ownership, gets results, and enjoys moving at a fast pace. \n Excellent communication skills, able to collaborate with across remote teams, share ideas and present concepts effectively. \n \n For Staff Data Engineer (IV) \n  All the requirements of above and: \n \n 7+ years of professional data engineering experience. \n Led teams (>5) technically on architecture and system design. \n Expert in one of the domains of ETL/ELT pipelines, feature engineering, data modeling and architecture, or data ingestion. \n Experience working autonomously and able to identify large impactful projects to pursue with minimal guidance. \n Deep understanding/experience with: \n \n Data warehouse architecture and design \n Integration of the data stack to other tools/services \n Extensive knowledge with implementing data quality checks \n \n \n Additional Information: \n \n This position is eligible for day-one PERM sponsorship for qualified candidates. \n \n Circle is on a mission to create an inclusive financial future, with transparency at our core. We consider a wide variety of elements when crafting our compensation ranges and total compensation packages. \n  Starting pay is determined by various factors, including but not limited to: relevant experience, skill set, qualifications, and other business and organizational needs. Please note that compensation ranges may differ for candidates in other locations. \n  Senior Data Engineer (III) \n  Base Pay Range: $147,500 - $195,000 \n  Annual Bonus Target: 12.5% \n  Staff Data Engineer (IV) \n  Base Pay Range: $172,500 - $227,500 \n  Annual Bonus Target: 15% \n  Also Included: Equity & Benefits (including medical, dental, vision and 401(k)). Circle has a discretionary vacation policy. We also provide 10 days of paid sick leave per year and 11 paid holidays per year in the U.S. \n \n  We are an  equal opportunity employer  and value diversity at Circle. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Additionally, Circle participates in the  E-Verify Program  in certain locations, as required by law. \n  #LI-Remote",
        "cleaned_desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  As a member of the Data Engineering - Business ETL team, you own the ETL/ELT pipelines and data warehouse that is used for financial and regulatory reporting. Your work powers Circle business functions, including the Compliance, Finance, Accounting, and Analytics teams for experimentation, operational excellence, and actionable insights, so as to fuel and accelerate business growth. High integrity to data accuracy and quality is crucial. Your work will directly impact Circle's transparency, trust, and accountability needs. \n  What you'll work on: \n \n Collaborating with business teams on the design, deployment and continuous improvement of the scalable data platform that ingests, stores, and aggregates various datasets, including data pipelines, platforms, and warehouses, and surfacing data to both internal and customer-facing applications. \n Being a domain expert on data modeling, data pipelines, data quality and data warehousing. \n Designing, building and maintaining data ETL/ELT pipelines to source and aggregate the required data for various data analyses and reporting needs, as well as to continually improve the operations, monitoring and performance of the data warehouse. \n Developing integrations with third party systems to source, qualify and ingest various datasets. \n Providing data analytics and visualization tools to extract valuable insights from the data to enable data-driven decisions.   Proficient in one or more programming languages (Java, Scala, Python). \n Advanced experience in SQL in big data warehouse systems such as Snowflake, BigQuery, Databricks, etc. \n Experience in SQL and NoSQL, such as MySQL, PostgreSQL, Cassandra, HBase, Redis, DynamoDB, Neo4j, etc. \n Experience with workflow orchestration management engines such as Airflow, Dagster, DBT, etc \n Experience with Cloud Services (AWS, Google Cloud, Microsoft Azure, etc). \n Experience in building scalable infrastructure to support batch, micro-batch or stream data processing for large volumes of data. \n Experience with financial or compliance data, bonus if in similar business domains, such as payment systems, credit cards, bank transfers, blockchains, etc. \n Experience in data provenance and governance. \n Internal knowledge of open source or related big data technologies. \n Ability to tackle complex and ambiguous problems. \n Self-starter who takes ownership, gets results, and enjoys moving at a fast pace. \n Excellent communication skills, able to collaborate with across remote teams, share ideas and present concepts effectively. \n   For Staff Data Engineer (IV) \n  All the requirements of above and: \n \n 7+ years of professional data engineering experience. \n Led teams (>5) technically on architecture and system design. \n Expert in one of the domains of ETL/ELT pipelines, feature engineering, data modeling and architecture, or data ingestion. \n Experience working autonomously and able to identify large impactful projects to pursue with minimal guidance. \n Deep understanding/experience with: \n \n Data warehouse architecture and design \n Integration of the data stack to other tools/services \n Extensive knowledge with implementing data quality checks \n ",
        "techs": [
            "circle",
            "usdc",
            "blockchain-based dollar",
            "etl/elt pipelines",
            "data warehouse",
            "compliance",
            "finance",
            "accounting",
            "analytics",
            "data platform",
            "data pipelines",
            "data quality",
            "data warehousing",
            "third party systems",
            "data analytics",
            "visualization tools",
            "programming languages",
            "sql",
            "big data warehouse systems",
            "mysql",
            "postgresql",
            "cassandra",
            "hbase",
            "redis",
            "dynamodb",
            "neo4j",
            "workflow orchestration management engines",
            "cloud services",
            "batch processing",
            "micro-batch processing",
            "stream data processing",
            "financial data",
            "compliance data",
            "data provenance",
            "governance",
            "open source",
            "big data technologies",
            "complex problem-solving",
            "communication skills",
            "staff data engineer",
            "data engineering experience",
            "architecture and system design",
            "etl/elt pipeline",
            "feature engineering",
            "data modeling",
            "data ingestion",
            "data warehouse architecture",
            "data stack integration",
            "data quality checks."
        ],
        "cleaned_techs": [
            "circle",
            "usdc",
            "blockchain-based dollar",
            "etl/elt pipelines",
            "data warehouse",
            "compliance",
            "finance",
            "accounting",
            "data platform",
            "data pipelines",
            "data quality",
            "data warehousing",
            "third party systems",
            "data analytics",
            "visualization tools",
            "programming languages",
            "sql",
            "big data warehouse systems",
            "mysql",
            "postgresql",
            "cassandra",
            "hbase",
            "redis",
            "dynamodb",
            "neo4j",
            "workflow orchestration management engines",
            "cloud services",
            "batch processing",
            "micro-batch processing",
            "stream data processing",
            "financial data",
            "compliance data",
            "data provenance",
            "governance",
            "open source",
            "big data technologies",
            "complex problem-solving",
            "staff data engineer",
            "data engineering experience",
            "architecture and system design",
            "etl/elt pipeline",
            "feature engineering",
            "data ingestion",
            "data warehouse architecture",
            "data stack integration",
            "data quality checks."
        ]
    },
    "76ac08572cd2fb1e": {
        "terms": [
            "data science",
            "data engineer"
        ],
        "salary_min": 147500.0,
        "salary_max": 195000.0,
        "title": "Senior Data Engineer",
        "company": "Circle",
        "desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  As a member of the Data Engineering - Business ETL team, you own the ETL/ELT pipelines and data warehouse that is used for financial and regulatory reporting. Your work powers Circle business functions, including the Compliance, Finance, Accounting, and Analytics teams for experimentation, operational excellence, and actionable insights, so as to fuel and accelerate business growth. High integrity to data accuracy and quality is crucial. Your work will directly impact Circle's transparency, trust, and accountability needs. \n  What you'll work on: \n \n Collaborating with business teams on the design, deployment and continuous improvement of the scalable data platform that ingests, stores, and aggregates various datasets, including data pipelines, platforms, and warehouses, and surfacing data to both internal and customer-facing applications. \n Being a domain expert on data modeling, data pipelines, data quality and data warehousing. \n Designing, building and maintaining data ETL/ELT pipelines to source and aggregate the required data for various data analyses and reporting needs, as well as to continually improve the operations, monitoring and performance of the data warehouse. \n Developing integrations with third party systems to source, qualify and ingest various datasets. \n Providing data analytics and visualization tools to extract valuable insights from the data to enable data-driven decisions. \n Working closely with across groups, such as the product, engineering, data science, compliance, and security teams, for data modeling, general management of data life cycle, data governance and processes for meeting regulatory and legal requirements. \n \n You will aspire to our four core values: \n \n Multistakeholder - you have dedication and commitment to our customers, shareholders, employees and families and local communities. \n Mindful - you seek to be respectful, an active listener and to pay attention to detail. \n Driven by Excellence - you are driven by our mission and our passion for customer success which means you relentlessly pursue excellence, that you do not tolerate mediocrity and you work intensely to achieve your goals. \n High Integrity - you seek open and honest communication, and you hold yourself to very high moral and ethical standards. You reject manipulation, dishonesty and intolerance. \n \n What you'll bring to Circle: \n  For Senior Data Engineer (III) \n \n 4+ years of professional data engineering experience. \n Proficient in one or more programming languages (Java, Scala, Python). \n Advanced experience in SQL in big data warehouse systems such as Snowflake, BigQuery, Databricks, etc. \n Experience in SQL and NoSQL, such as MySQL, PostgreSQL, Cassandra, HBase, Redis, DynamoDB, Neo4j, etc. \n Experience with workflow orchestration management engines such as Airflow, Dagster, DBT, etc \n Experience with Cloud Services (AWS, Google Cloud, Microsoft Azure, etc). \n Experience in building scalable infrastructure to support batch, micro-batch or stream data processing for large volumes of data. \n Experience with financial or compliance data, bonus if in similar business domains, such as payment systems, credit cards, bank transfers, blockchains, etc. \n Experience in data provenance and governance. \n Internal knowledge of open source or related big data technologies. \n Ability to tackle complex and ambiguous problems. \n Self-starter who takes ownership, gets results, and enjoys moving at a fast pace. \n Excellent communication skills, able to collaborate with across remote teams, share ideas and present concepts effectively. \n \n For Staff Data Engineer (IV) \n  All the requirements of above and: \n \n 7+ years of professional data engineering experience. \n Led teams (>5) technically on architecture and system design. \n Expert in one of the domains of ETL/ELT pipelines, feature engineering, data modeling and architecture, or data ingestion. \n Experience working autonomously and able to identify large impactful projects to pursue with minimal guidance. \n Deep understanding/experience with: \n \n Data warehouse architecture and design \n Integration of the data stack to other tools/services \n Extensive knowledge with implementing data quality checks \n \n \n Additional Information: \n \n This position is eligible for day-one PERM sponsorship for qualified candidates. \n \n Circle is on a mission to create an inclusive financial future, with transparency at our core. We consider a wide variety of elements when crafting our compensation ranges and total compensation packages. \n  Starting pay is determined by various factors, including but not limited to: relevant experience, skill set, qualifications, and other business and organizational needs. Please note that compensation ranges may differ for candidates in other locations. \n  Senior Data Engineer (III) \n  Base Pay Range: $147,500 - $195,000 \n  Annual Bonus Target: 12.5% \n  Staff Data Engineer (IV) \n  Base Pay Range: $172,500 - $227,500 \n  Annual Bonus Target: 15% \n  Also Included: Equity & Benefits (including medical, dental, vision and 401(k)). Circle has a discretionary vacation policy. We also provide 10 days of paid sick leave per year and 11 paid holidays per year in the U.S. \n \n  We are an  equal opportunity employer  and value diversity at Circle. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Additionally, Circle participates in the  E-Verify Program  in certain locations, as required by law. \n  #LI-Remote",
        "cleaned_desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  As a member of the Data Engineering - Business ETL team, you own the ETL/ELT pipelines and data warehouse that is used for financial and regulatory reporting. Your work powers Circle business functions, including the Compliance, Finance, Accounting, and Analytics teams for experimentation, operational excellence, and actionable insights, so as to fuel and accelerate business growth. High integrity to data accuracy and quality is crucial. Your work will directly impact Circle's transparency, trust, and accountability needs. \n  What you'll work on: \n \n Collaborating with business teams on the design, deployment and continuous improvement of the scalable data platform that ingests, stores, and aggregates various datasets, including data pipelines, platforms, and warehouses, and surfacing data to both internal and customer-facing applications. \n Being a domain expert on data modeling, data pipelines, data quality and data warehousing. \n Designing, building and maintaining data ETL/ELT pipelines to source and aggregate the required data for various data analyses and reporting needs, as well as to continually improve the operations, monitoring and performance of the data warehouse. \n Developing integrations with third party systems to source, qualify and ingest various datasets. \n Providing data analytics and visualization tools to extract valuable insights from the data to enable data-driven decisions.   Proficient in one or more programming languages (Java, Scala, Python). \n Advanced experience in SQL in big data warehouse systems such as Snowflake, BigQuery, Databricks, etc. \n Experience in SQL and NoSQL, such as MySQL, PostgreSQL, Cassandra, HBase, Redis, DynamoDB, Neo4j, etc. \n Experience with workflow orchestration management engines such as Airflow, Dagster, DBT, etc \n Experience with Cloud Services (AWS, Google Cloud, Microsoft Azure, etc). \n Experience in building scalable infrastructure to support batch, micro-batch or stream data processing for large volumes of data. \n Experience with financial or compliance data, bonus if in similar business domains, such as payment systems, credit cards, bank transfers, blockchains, etc. \n Experience in data provenance and governance. \n Internal knowledge of open source or related big data technologies. \n Ability to tackle complex and ambiguous problems. \n Self-starter who takes ownership, gets results, and enjoys moving at a fast pace. \n Excellent communication skills, able to collaborate with across remote teams, share ideas and present concepts effectively. \n   For Staff Data Engineer (IV) \n  All the requirements of above and: \n \n 7+ years of professional data engineering experience. \n Led teams (>5) technically on architecture and system design. \n Expert in one of the domains of ETL/ELT pipelines, feature engineering, data modeling and architecture, or data ingestion. \n Experience working autonomously and able to identify large impactful projects to pursue with minimal guidance. \n Deep understanding/experience with: \n \n Data warehouse architecture and design \n Integration of the data stack to other tools/services \n Extensive knowledge with implementing data quality checks \n ",
        "techs": [
            "circle",
            "usdc",
            "blockchain",
            "etl",
            "elt",
            "data warehouse",
            "compliance",
            "finance",
            "accounting",
            "analytics",
            "data platform",
            "data modeling",
            "data pipelines",
            "data quality",
            "data warehousing",
            "etl/elt pipelines",
            "data analyses",
            "integrations",
            "third party systems",
            "data analytics",
            "visualization tools",
            "programming languages (java",
            "scala",
            "python)",
            "sql",
            "big data warehouse systems (snowflake",
            "bigquery",
            "databricks)",
            "sql and nosql databases (mysql",
            "postgresql",
            "cassandra",
            "hbase",
            "redis",
            "dynamodb",
            "neo4j)",
            "workflow orchestration management engines (airflow",
            "dagster",
            "dbt)",
            "cloud services (aws",
            "google cloud",
            "microsoft azure)",
            "scalable infrastructure",
            "batch processing",
            "micro-batch processing",
            "stream data processing",
            "financial data",
            "compliance data",
            "data provenance",
            "data governance",
            "open source big data technologies",
            "complex problem solving",
            "communication skills",
            "staff data engineer",
            "data engineering experience",
            "team leadership",
            "architecture and system design",
            "etl/elt pipelines",
            "feature engineering",
            "data modeling",
            "data architecture",
            "data ingestion",
            "data warehouse architecture and design",
            "data stack integration",
            "data quality checks."
        ],
        "cleaned_techs": [
            "circle",
            "usdc",
            "blockchain",
            "etl",
            "elt",
            "data warehouse",
            "compliance",
            "finance",
            "accounting",
            "data platform",
            "data pipelines",
            "data quality",
            "data warehousing",
            "etl/elt pipelines",
            "data analyses",
            "integrations",
            "third party systems",
            "data analytics",
            "visualization tools",
            "programming languages (java",
            "scala",
            "python",
            "sql",
            "big data warehouse systems (snowflake",
            "bigquery",
            "databricks)",
            "postgresql",
            "cassandra",
            "hbase",
            "redis",
            "dynamodb",
            "neo4j)",
            "workflow orchestration management engines (airflow",
            "dagster",
            "dbt)",
            "cloud services (aws",
            "gcp",
            "microsoft azure)",
            "scalable infrastructure",
            "batch processing",
            "micro-batch processing",
            "stream data processing",
            "financial data",
            "compliance data",
            "data provenance",
            "data governance",
            "open source big data technologies",
            "complex problem solving",
            "staff data engineer",
            "data engineering experience",
            "team leadership",
            "architecture and system design",
            "feature engineering",
            "data architecture",
            "data ingestion",
            "data warehouse architecture and design",
            "data stack integration",
            "data quality checks."
        ]
    },
    "0d4d8b66459b4edd": {
        "terms": [
            "data science"
        ],
        "salary_min": 70.0,
        "salary_max": 75.0,
        "title": "Data Manager",
        "company": "Compass Solutions LLC",
        "desc": "This position is primarily remote, but the resource will be required to report on-site at times during the engagement in Harrisburg PA. \n The contractor will be required to: \n \n Engage with program leaders and data stewards to document descriptions of datasets, data assets, dashboards, and reports. \n \n \n Create a dashboard to track programs of the inventory and descriptions of data assets. \n \n \n Review systems and feeds for data quality process sufficiency feeding Enterprise sources and recommend changes. \n \n \n Create a dashboard to track data quality process evaluation and progress. \n \n \n Document specific data flows when relevant to the enterprise view of metrics and data including using appropriate tools for lineage and profiling to improve data quality. \n \n \n Review program requirements and understand the impact on the Enterprise view of data. \n \n \n Document decisions that impact the enterprise view of data. \n \n \n Engage in reviewing metrics to ensure adequate privacy. \n \n \n Drive adoption of data governance policies and participate in data governance meetings and follow up items. \n \n \n Drive compliance with established policies. \n \n \n Document external data to assist in combining third party data with first party data to create relevant derivative / second party data for analysis. \n \n \n Participate in the creation of dashboards and reports to track progress of Data Governance activities. \n \n \n Managing and prioritizing the product backlog. \n \n \n Serving as a liaison between product and development. \n \n \n Ensuring the product backlog is transparent, visible, and understood by DMI stakeholders. \n \n CONTRACTOR SKILLS AND EXPERIENCE REQUIREMENTS \n This position requires a high degree of skill, leadership, ability to take initiative, and dedication. Bachelor\u2019s or graduate degree in Health Informatics, Public Health, Data Science, Epidemiology, Biostatistics, Public Policy, Health Policy, Health Services Research, Health Information Sciences, Computer Science, or a closely related field. \n 3-5 years of relevant experience in leading data governance efforts and managing data sharing related projects, including experience functioning in the role of an Agile Product Owner. \n Experience setting up an enterprise-wide data governance structure, knowledge of data lakes and data maturity models preferred. Familiarity and experience with programs relative to health and human services is considered helpful. \n Job Types: Contract, Full-time \n Pay: $70.00 - $75.00 per hour \n Expected hours: 40 per week \n Schedule: \n \n 8 hour shift \n \n Education: \n \n Bachelor's (Preferred) \n \n Experience: \n \n leading data governance efforts and managing data sharing: 5 years (Required) \n functioning in the role of an Agile Product Owner: 5 years (Required) \n setting up an enterprise-wide data governance structure: 5 years (Required) \n data lakes and data maturity models: 1 year (Required) \n programs relative to health and human services: 1 year (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "fb29b2615b11ac90": {
        "terms": [
            "data science",
            "data engineer"
        ],
        "salary_min": 147500.0,
        "salary_max": 195000.0,
        "title": "Senior Data Engineer",
        "company": "Circle",
        "desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  As a member of the Data Engineering - Business ETL team, you own the ETL/ELT pipelines and data warehouse that is used for financial and regulatory reporting. Your work powers Circle business functions, including the Compliance, Finance, Accounting, and Analytics teams for experimentation, operational excellence, and actionable insights, so as to fuel and accelerate business growth. High integrity to data accuracy and quality is crucial. Your work will directly impact Circle's transparency, trust, and accountability needs. \n  What you'll work on: \n \n Collaborating with business teams on the design, deployment and continuous improvement of the scalable data platform that ingests, stores, and aggregates various datasets, including data pipelines, platforms, and warehouses, and surfacing data to both internal and customer-facing applications. \n Being a domain expert on data modeling, data pipelines, data quality and data warehousing. \n Designing, building and maintaining data ETL/ELT pipelines to source and aggregate the required data for various data analyses and reporting needs, as well as to continually improve the operations, monitoring and performance of the data warehouse. \n Developing integrations with third party systems to source, qualify and ingest various datasets. \n Providing data analytics and visualization tools to extract valuable insights from the data to enable data-driven decisions. \n Working closely with across groups, such as the product, engineering, data science, compliance, and security teams, for data modeling, general management of data life cycle, data governance and processes for meeting regulatory and legal requirements. \n \n You will aspire to our four core values: \n \n Multistakeholder - you have dedication and commitment to our customers, shareholders, employees and families and local communities. \n Mindful - you seek to be respectful, an active listener and to pay attention to detail. \n Driven by Excellence - you are driven by our mission and our passion for customer success which means you relentlessly pursue excellence, that you do not tolerate mediocrity and you work intensely to achieve your goals. \n High Integrity - you seek open and honest communication, and you hold yourself to very high moral and ethical standards. You reject manipulation, dishonesty and intolerance. \n \n What you'll bring to Circle: \n  For Senior Data Engineer (III) \n \n 4+ years of professional data engineering experience. \n Proficient in one or more programming languages (Java, Scala, Python). \n Advanced experience in SQL in big data warehouse systems such as Snowflake, BigQuery, Databricks, etc. \n Experience in SQL and NoSQL, such as MySQL, PostgreSQL, Cassandra, HBase, Redis, DynamoDB, Neo4j, etc. \n Experience with workflow orchestration management engines such as Airflow, Dagster, DBT, etc \n Experience with Cloud Services (AWS, Google Cloud, Microsoft Azure, etc). \n Experience in building scalable infrastructure to support batch, micro-batch or stream data processing for large volumes of data. \n Experience with financial or compliance data, bonus if in similar business domains, such as payment systems, credit cards, bank transfers, blockchains, etc. \n Experience in data provenance and governance. \n Internal knowledge of open source or related big data technologies. \n Ability to tackle complex and ambiguous problems. \n Self-starter who takes ownership, gets results, and enjoys moving at a fast pace. \n Excellent communication skills, able to collaborate with across remote teams, share ideas and present concepts effectively. \n \n For Staff Data Engineer (IV) \n  All the requirements of above and: \n \n 7+ years of professional data engineering experience. \n Led teams (>5) technically on architecture and system design. \n Expert in one of the domains of ETL/ELT pipelines, feature engineering, data modeling and architecture, or data ingestion. \n Experience working autonomously and able to identify large impactful projects to pursue with minimal guidance. \n Deep understanding/experience with: \n \n Data warehouse architecture and design \n Integration of the data stack to other tools/services \n Extensive knowledge with implementing data quality checks \n \n \n Additional Information: \n \n This position is eligible for day-one PERM sponsorship for qualified candidates. \n \n Circle is on a mission to create an inclusive financial future, with transparency at our core. We consider a wide variety of elements when crafting our compensation ranges and total compensation packages. \n  Starting pay is determined by various factors, including but not limited to: relevant experience, skill set, qualifications, and other business and organizational needs. Please note that compensation ranges may differ for candidates in other locations. \n  Senior Data Engineer (III) \n  Base Pay Range: $147,500 - $195,000 \n  Annual Bonus Target: 12.5% \n  Staff Data Engineer (IV) \n  Base Pay Range: $172,500 - $227,500 \n  Annual Bonus Target: 15% \n  Also Included: Equity & Benefits (including medical, dental, vision and 401(k)). Circle has a discretionary vacation policy. We also provide 10 days of paid sick leave per year and 11 paid holidays per year in the U.S. \n \n  We are an  equal opportunity employer  and value diversity at Circle. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Additionally, Circle participates in the  E-Verify Program  in certain locations, as required by law. \n  #LI-Remote",
        "cleaned_desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  As a member of the Data Engineering - Business ETL team, you own the ETL/ELT pipelines and data warehouse that is used for financial and regulatory reporting. Your work powers Circle business functions, including the Compliance, Finance, Accounting, and Analytics teams for experimentation, operational excellence, and actionable insights, so as to fuel and accelerate business growth. High integrity to data accuracy and quality is crucial. Your work will directly impact Circle's transparency, trust, and accountability needs. \n  What you'll work on: \n \n Collaborating with business teams on the design, deployment and continuous improvement of the scalable data platform that ingests, stores, and aggregates various datasets, including data pipelines, platforms, and warehouses, and surfacing data to both internal and customer-facing applications. \n Being a domain expert on data modeling, data pipelines, data quality and data warehousing. \n Designing, building and maintaining data ETL/ELT pipelines to source and aggregate the required data for various data analyses and reporting needs, as well as to continually improve the operations, monitoring and performance of the data warehouse. \n Developing integrations with third party systems to source, qualify and ingest various datasets. \n Providing data analytics and visualization tools to extract valuable insights from the data to enable data-driven decisions.   Proficient in one or more programming languages (Java, Scala, Python). \n Advanced experience in SQL in big data warehouse systems such as Snowflake, BigQuery, Databricks, etc. \n Experience in SQL and NoSQL, such as MySQL, PostgreSQL, Cassandra, HBase, Redis, DynamoDB, Neo4j, etc. \n Experience with workflow orchestration management engines such as Airflow, Dagster, DBT, etc \n Experience with Cloud Services (AWS, Google Cloud, Microsoft Azure, etc). \n Experience in building scalable infrastructure to support batch, micro-batch or stream data processing for large volumes of data. \n Experience with financial or compliance data, bonus if in similar business domains, such as payment systems, credit cards, bank transfers, blockchains, etc. \n Experience in data provenance and governance. \n Internal knowledge of open source or related big data technologies. \n Ability to tackle complex and ambiguous problems. \n Self-starter who takes ownership, gets results, and enjoys moving at a fast pace. \n Excellent communication skills, able to collaborate with across remote teams, share ideas and present concepts effectively. \n   For Staff Data Engineer (IV) \n  All the requirements of above and: \n \n 7+ years of professional data engineering experience. \n Led teams (>5) technically on architecture and system design. \n Expert in one of the domains of ETL/ELT pipelines, feature engineering, data modeling and architecture, or data ingestion. \n Experience working autonomously and able to identify large impactful projects to pursue with minimal guidance. \n Deep understanding/experience with: \n \n Data warehouse architecture and design \n Integration of the data stack to other tools/services \n Extensive knowledge with implementing data quality checks \n ",
        "techs": [
            "circle is the specific tool/technology mentioned in the text."
        ],
        "cleaned_techs": [
            "circle is the specific tool/technology mentioned in the text."
        ]
    },
    "cfdc4b02fb0d7c48": {
        "terms": [
            "data science"
        ],
        "salary_min": 111431.586,
        "salary_max": 141097.22,
        "title": "Director of Business Intelligence",
        "company": "Love in Faith",
        "desc": "This is a fully remote position within the United States. \n  About Love in Faith \n  Love in Faith is a thriving faith-based clothing and accessories startup. Here, we're not just a company; we're a team of enthusiasts, dreamers, and doers that strive to deliver exceptional products with a customer-focused experience you can trust. With fully remote positions, you can work from anywhere while contributing to our exciting growth story. \n  Here's why you should consider us: \n \n Rapid Growth: We're not your typical startup. Our exponential growth speaks volumes about the opportunities that await you. Be part of something big! \n Remote Flexibility: Enjoy the freedom to work from your preferred location, without sacrificing your career goals. \n Culture: Our team knows how to work hard and play harder. We value creativity, innovation, and a positive work environment. Join us in celebrating successes, big and small. \n \n \n \n About the Role \n  Love in Faith is seeking a Director of Business Intelligence to lead our efforts in gathering, analyzing, and transforming data into actionable insights. The Director of Business Intelligence will play a crucial role in helping the company make data-driven decisions and will proactively identify opportunities for omni business performance insights. If you are a strategic thinker with a passion for data and analytics, we invite you to join our team. \n  Responsibilities: \n \n Business Intelligence Strategy: \n \n Proactively identify value-add opportunities for omni business performance insights based on guidance from senior management and ongoing dialogue with cross-functional business users. \n Define the vision and strategic direction for the Business Intelligence function to align with the company's goals and objectives. \n \n Data Management and Governance: \n \n Establish and maintain data governance principles, ensuring data quality, accuracy, and consistency. \n Oversee data integration, data warehousing, and data architecture to support BI initiatives. \n \n Reporting and Analysis: \n \n Define appropriate timelines and cadences of business reporting within the company's data sharing principles. \n Develop and maintain a comprehensive suite of reports and dashboards to monitor key performance indicators (KPIs) and provide insights to stakeholders. \n \n Team Leadership: \n \n Manage a team of BI analysts and data scientists, providing leadership, coaching, and mentorship. \n Delegate responsibilities, set performance goals, and conduct regular performance reviews. \n \n Project Management: \n \n Develop concrete strategies and project plans for the team to execute business requests, data analysis, and reporting initiatives. \n Ensure projects are delivered on time, within budget, and meet quality standards. \n \n Cross-Functional Collaboration: \n \n Collaborate with various departments to understand their data and reporting needs. \n Establish strong working relationships with stakeholders to ensure that BI solutions align with business goals. \n \n Continuous Improvement: \n \n Stay current with industry best practices, emerging technologies, and trends in business intelligence. \n Drive innovation and improvement in BI tools, methodologies, and processes. \n \n \n Requirements \n \n Bachelor's degree in Business, Computer Science, Data Science, or a related field (Master's degree preferred). \n Proven experience in business intelligence, data analysis, and data-driven decision-making, preferably in the retail or fashion industry. \n Strong leadership and team management skills. \n Proficiency in data visualization tools (e.g., Tableau, Power BI) and data warehousing. \n Experience with SQL and database management. \n Excellent analytical and problem-solving abilities. \n Effective communication and presentation skills. \n Strong project management skills and the ability to manage multiple initiatives simultaneously. \n \n \n \n Physical Demands \n  While performing the duties of this job, the employee routinely is required to sit; walk; talk and hear; use hands to keyboard, finger, handle, and feel; stoop, kneel, crouch, twist, reach, and stretch. Speaking and hearing ability sufficient to communicate in person, over the telephone, and/or via video conference. \n \n The ability to stand, walk, and sit in a computer chair for long periods of time. \n The ability to see and respond to dangerous situations. \n Speaking and hearing ability sufficient to communicate in person, over the telephone and/or via video conferences. \n Sufficient hand, arm, and finger dexterity to operate a computer keyboard and other office equipment. \n \n Emotional Demands \n \n Data analysis & interpretation. You will have to process and review a lot of information from a variety of sources, understand how data is collected, assess data quality, and how to use the information. \n Communication skills. You need to have advanced communication skills in both oral and written form. Emails and written communication with colleagues and external partners, written reports for senior executives. Able to communicate complex financial information to people outside of the finance department. \n Comfortable with technology. Able to navigate data through computers, mobile, software, databases. Stay up to date with technology advances. \n Oriented to detail. Financial forecasts rely on projections which can be impacted by even minor changes in sales patterns, consumer sentiment, economic shifts, competitor changes, etc. You will need to be attuned to small changes in all streams of data. \n Confident decision-making skills. You will need to review data and make sound decisions on what actions to take and make confident recommendations to senior management. You may need to make decisions quickly with limited amounts of information in urgent situations. \n \n \n \n For Applicants with Disabilities \n  Reasonable accommodation will be made for those that qualified during application process. If you need accommodations during the hiring process, please let us know when you submit your application, and we\u2019ll do our very best to adjust as needed. \n  Benefits \n \n Medical, Dental, Vision \n Health Savings (HSA) & Flexible Spending Account (FSA) \n Company Paid Life Insurance \n Supplemental Benefits Available\n    \n Accident Insurance \n Critical Illness Insurance \n \n Unlimited PTO Policy \n Paid Parental Leave \n Other Company Perks\n    \n Monthly Utility Stipend \n Team Meetings Coffee/Food Stipend \n Health & Wellness Stipend \n Education & Professional Development Stipend \n Charitable Gift Matching",
        "cleaned_desc": " Data Management and Governance: \n \n Establish and maintain data governance principles, ensuring data quality, accuracy, and consistency. \n Oversee data integration, data warehousing, and data architecture to support BI initiatives. \n \n Reporting and Analysis: \n \n Define appropriate timelines and cadences of business reporting within the company's data sharing principles. \n Develop and maintain a comprehensive suite of reports and dashboards to monitor key performance indicators (KPIs) and provide insights to stakeholders. \n \n Team Leadership: \n \n Manage a team of BI analysts and data scientists, providing leadership, coaching, and mentorship. \n Delegate responsibilities, set performance goals, and conduct regular performance reviews. \n \n Project Management: \n \n Develop concrete strategies and project plans for the team to execute business requests, data analysis, and reporting initiatives. \n Ensure projects are delivered on time, within budget, and meet quality standards. \n   Cross-Functional Collaboration: \n \n Collaborate with various departments to understand their data and reporting needs. \n Establish strong working relationships with stakeholders to ensure that BI solutions align with business goals. \n \n Continuous Improvement: \n \n Stay current with industry best practices, emerging technologies, and trends in business intelligence. \n Drive innovation and improvement in BI tools, methodologies, and processes. \n \n \n Requirements \n \n Bachelor's degree in Business, Computer Science, Data Science, or a related field (Master's degree preferred). \n Proven experience in business intelligence, data analysis, and data-driven decision-making, preferably in the retail or fashion industry. \n Strong leadership and team management skills. \n Proficiency in data visualization tools (e.g., Tableau, Power BI) and data warehousing. \n Experience with SQL and database management. \n Excellent analytical and problem-solving abilities. \n Effective communication and presentation skills.   Strong project management skills and the ability to manage multiple initiatives simultaneously. \n \n \n \n Physical Demands \n  While performing the duties of this job, the employee routinely is required to sit; walk; talk and hear; use hands to keyboard, finger, handle, and feel; stoop, kneel, crouch, twist, reach, and stretch. Speaking and hearing ability sufficient to communicate in person, over the telephone, and/or via video conference. \n \n The ability to stand, walk, and sit in a computer chair for long periods of time. \n The ability to see and respond to dangerous situations. \n Speaking and hearing ability sufficient to communicate in person, over the telephone and/or via video conferences. \n Sufficient hand, arm, and finger dexterity to operate a computer keyboard and other office equipment. \n \n Emotional Demands \n \n Data analysis & interpretation. You will have to process and review a lot of information from a variety of sources, understand how data is collected, assess data quality, and how to use the information. \n Communication skills. You need to have advanced communication skills in both oral and written form. Emails and written communication with colleagues and external partners, written reports for senior executives. Able to communicate complex financial information to people outside of the finance department. \n Comfortable with technology. Able to navigate data through computers, mobile, software, databases. Stay up to date with technology advances. \n Oriented to detail. Financial forecasts rely on projections which can be impacted by even minor changes in sales patterns, consumer sentiment, economic shifts, competitor changes, etc. You will need to be attuned to small changes in all streams of data. \n Confident decision-making skills. You will need to review data and make sound decisions on what actions to take and make confident recommendations to senior management. You may need to make decisions quickly with limited amounts of information in urgent situations. \n ",
        "techs": [
            "tableau",
            "power bi",
            "sql",
            "database management"
        ],
        "cleaned_techs": [
            "tableau",
            "powerbi",
            "sql",
            "database management"
        ]
    },
    "d588b85f17ac264c": {
        "terms": [
            "data science"
        ],
        "salary_min": 100000.0,
        "salary_max": 158000.0,
        "title": "Senior Sales Analytics and Insights Analyst",
        "company": "Rippling",
        "desc": "About Rippling \n \n \n   Rippling gives businesses one place to run HR, IT, and Finance. It brings together all of the workforce systems that are normally scattered across a company, like payroll, expenses, benefits, and computers. For the first time ever, you can manage and automate every part of the employee lifecycle in a single system.\n  \n \n \n  Take onboarding, for example. With Rippling, you can hire a new employee anywhere in the world and set up their payroll, corporate card, computer, benefits, and even third-party apps like Slack and Microsoft 365\u2014all within 90 seconds.\n  \n \n \n  Based in San Francisco, CA, Rippling has raised $1.2B from the world\u2019s top investors\u2014including Kleiner Perkins, Founders Fund, Sequoia, Greenoaks, and Bedrock\u2014and was named one of America's best startup employers by Forbes.\n  \n \n \n  About the role \n \n \n \n  Rippling is looking for a standout Senior Sales Analyst to develop visualizations and uncover insights that support the growth of the company and sales team. You\u2019ll work closely with colleagues to provide visibility into the performance of the business, identify key trends, and meet our analytics needs as the organization grows. You\u2019ll also collaborate closely with strategy, sales leadership and other key cross-functional partners to define, build, and track KPIs.\n  \n \n \n  The ideal candidate will have worked in fast-paced environments before, ideally at a multi-product SaaS company and will have made a measurable impact to the sales organization. You should also be comfortable tackling ambiguous and challenging problems and working independently as well as part of a team. This is an opportunity to work on high-visibility strategic initiatives in a rapidly growing sales organization.\n  \n \n \n  What you will do \n \n \n  Partner with Sales Development & Sales teams to understand their work. Use your understanding to define, document and own actionable metrics to help guide decision-making at Rippling. \n  Develop and own critical reporting and self-serve dashboards that provide insights into Rippling\u2019s business performance. \n  Collaborate with partners within data science and data engineering to build, document, and manage our core data tables for Sales Analytics. \n  Individually own and drive analyses, workstreams, and high priority projects. \n  Proactively provide insights on sales performance and business processes. \n \n \n \n  What you will need \n \n \n  3+ years working with data, ideally partnering with GTM orgs (Marketing, Sales, Customer Success) \n  Ability to write complex SQL and build data pipelines, ideally within Snowflake and DBT \n  You have a \u201cget it done\u201d attitude and want to build something that lasts. Not only do you have the ability and the desire to architect the high level strategy, you want to operationalize it and have high attention to detail \n  Proficiency in data visualization, with expertise with tools like Tableau, Snowflake, DBT, Github \n  Adept at tailoring presentations to executives, managers, and individual contributors within the organization. \n  Experience in developing definitional documentation, as well as leading educational sessions for business teams on dashboards and analytical insights. \n  Experience with Python or R a plus \n \n \n \n  Additional Information \n \n \n   Rippling is an equal opportunity employer. We are committed to building a diverse and inclusive workforce and do not discriminate based on race, religion, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, age, sexual orientation, veteran or military status, or any other legally protected characteristics, Rippling is committed to providing reasonable accommodations for candidates with disabilities who need assistance during the hiring process. To request a reasonable accommodation, please email accomodations@rippling.com\n  \n \n \n  Rippling highly values having employees working in-office to foster a collaborative work environment and company culture. For office-based employees (employees who live within a 40 mile radius of a Rippling office), Rippling considers working in the office, at least three days a week under current policy, to be an essential function of the employee's role.\n  \n \n \n  This role will receive a competitive salary + benefits + equity. The salary for US-based employees will be aligned with one of the ranges below based on location.\n  \n \n \n  A variety of factors are considered when determining someone\u2019s compensation\u2013including a candidate\u2019s professional background, experience, and location. Final offer amounts may vary from the amounts listed below.",
        "cleaned_desc": " \n \n  3+ years working with data, ideally partnering with GTM orgs (Marketing, Sales, Customer Success) \n  Ability to write complex SQL and build data pipelines, ideally within Snowflake and DBT \n  You have a \u201cget it done\u201d attitude and want to build something that lasts. Not only do you have the ability and the desire to architect the high level strategy, you want to operationalize it and have high attention to detail \n  Proficiency in data visualization, with expertise with tools like Tableau, Snowflake, DBT, Github \n  Adept at tailoring presentations to executives, managers, and individual contributors within the organization. \n  Experience in developing definitional documentation, as well as leading educational sessions for business teams on dashboards and analytical insights. \n  Experience with Python or R a plus \n \n \n \n  Additional Information ",
        "techs": [
            "snowflake",
            "dbt",
            "tableau",
            "github",
            "python",
            "r"
        ],
        "cleaned_techs": [
            "snowflake",
            "dbt",
            "tableau",
            "github",
            "python",
            "r"
        ]
    },
    "4c5b5ccfeab2c4ec": {
        "terms": [
            "data science"
        ],
        "salary_min": 144000.0,
        "salary_max": 216000.0,
        "title": "(USA) Senior Manager II, Advanced Analytics, WFS Operations",
        "company": "Walmart",
        "desc": "Position Summary... \n \n \n What you'll do... \n \n  +++Remote Work Opportunity++\n  \n  What You'll Do:\n  \n  If you want to position yourself in a highly impactful team that will help drive growth in key business areas for Walmart Fulfillment Services, this is the right team for you. The Senior Manager, Advanced Analytics is a tactical and thought-leadership role that will add value through strategic insights to help drive the acquisition and retention of the sellers on the WFS platform by ensuring we build the best in class supply chain capabilities. In this role, you will drive the growth of the WFS platform by partnering with the WFS Operations teams. \n  \n  You will identify, scope and measure opportunities across our supply chain from seller to the Walmart customer. Among other things, you will be responsible for bringing visibility to key seller, inventory, carrier, and fulfillment center operational trends, determine the right analytics strategies to implement & measure the impact of ongoing initiatives, develop scorecards to track the key success metrics, recommend new strategies to test by conducting in-depth analyses on supply chain trends, as well as partner with cross functional analytics stakeholders to help uncover impactful insights from relevant areas of the business. \n  \n  This is a highly visible and critical role where you will also help the team be less reactive and identify long term initiatives that can be quickly tested and then scaled for impact. The right candidate must be able to thrive and succeed in a startup environment. This role is built for a creative problem solver with at least 10 years industry experience in supply chain analytics with a strong command of tools for data extraction, manipulation, visualization and modelling, along with a solid understanding of measurement frameworks, segmentation, regression, propensity, classification etc. Communication and data storytelling will also be a crucial part of this role as you will work with Senior Leadership and cross functional stakeholders. This role is remote, so ability to proactively communicate and collaborate by building digital stakeholder relationships is key for success.\n  \n  You'll sweep us off our feet if... \n  \n \n \n You are a creative problem solver  \n \n \n \n You are someone who can operate with minimal direction once you get settled in.  \n \n \n \n You love Constantly monitoring the business and identifying opportunities and proposing solutions.  \n \n  - You ask the right questions and think about how to creatively solve the problem with limited resources available - knowing when to trade off long term outlook for short term wins and vice versa, as well as prioritizing speed over perfection, to enable business decisions. \n  \n \n \n You are comfortable with model development: With a strong analytics / data science background and a deep understanding of supply chain analytics, you will build and manage parts of the development and implementation of data models to devise analytical solutions to business problem. You'll be focusing on multiple cross functional projects within a business area to help drive proof of concept / prototype, implement algorithms, and  \n track and improve performance through continuous improvements. \n  \n \n \n You love data storytelling: You can tease through data to identify trends and patterns and help prepare and deliver simple, yet compelling data driven presentations to communicate analytical stories to cross-functional partners (e.g., account management, business operations, product) to gain buy-in. The typical audience for your work will be senior leadership in both analytics and business teams.  \n \n \n \n You are a champion collaborator: You help identify use cases through cross-functional collaborations across the organization and influence partners through strategic insights (e.g., seller support, supply chain operation, inventory management). You partner with senior leadership to develop and drive data driven strategies and drive your roadmap based on current and future needs of stakeholders. \n \n  Benefits & Perks: Beyond competitive pay, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more. \n  \n  Join Walmart and your work could help over 265 million global customers live better every week. Yes, we are the Fortune #1 company. But you'll quickly find we're a company who wants you to feel comfortable bringing your whole self to work. A career at Walmart is where the world's most complex challenges meet a kinder way of life. Our mission spreads far beyond the walls of our stores. Join us and you'll discover why we are a world leader in \n   diversity and inclusion, sustainability, and community involvement. From day one, you'll be empowered and equipped to do the best work of your life.\n  \n  At Walmart, we offer competitive pay as well as performance-based incentive awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.\n  \n  You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable. For information about PTO, see https://one.walmart.com/notices .\n  \n  Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.\n  \n  Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms. For information about benefits and eligibility, see One.Walmart at https://bit.ly/3iOOb1J .\n  \n  The annual salary range for this position is $144,000.00-$216,000.00\n  \n  Additional compensation includes annual or quarterly performance incentives.\n  \n  Additional compensation for certain positions may also include:\n  \n \n \n Regional Pay Zone (RPZ) (based on location) \n \n \n \n Stock equity incentives \n \n \n  Minimum Qualifications...  \n \n  Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.\n  \n  Bachelor's degree in Business, Finance, Accounting, Statistics, or related field and 4 years' experience in data analytics or related field OR 6 years'\n   experience in data analytics or related field.\n  \n \n Preferred Qualifications...  \n \n  Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.\n  \n  Certificate in business analytics, data mining, or statistical analysis, Statistical programming languages (for example, SAS, R)\n  \n  Masters: Business Administration, Masters: Information Systems, Masters: Statistics\n  \n \n Primary Location...  \n  1525 11th Avenue, Seattle, WA 98122, United States of America",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "5890dd194d241634": {
        "terms": [
            "data science"
        ],
        "salary_min": 120363.016,
        "salary_max": 152406.39,
        "title": "Deep Learning Engineer",
        "company": "Cyberjin",
        "desc": "Hybrid/Remote position \n  We're looking for a Deep Learning Engineer to join us as part of the founding engineering team. You will have the opportunity to work closely with the CEO to build new features and roll out new products - all in the deep learning on mobile space. \n \n  Ideal candidate traits \n  Enjoys significant ownership over user-facing product \n  \u200d Can work independently \n  Is comfortable turning research papers into product \n  Has 2 - 10 years experience with deep learning or has a PhD in a STEM field \n  Builds with a product-first approach. You ship code quickly and care about the real world impact of your code. \n  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred \n   \n 758QEUyVzN",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "99509a07979ff003": {
        "terms": [
            "data science"
        ],
        "salary_min": 70.0,
        "salary_max": 75.0,
        "title": "Cloud engineer",
        "company": "PeopleCaddie",
        "desc": "Job ID:  4500 \n   \n \n \n Pay rate range:  $70 - $75 \n   \n \n \n City:  Chicago \n   \n \n \n State:  Illinois \n   \n \n \n Duration:  10/29/2023 - 04/29/2024 \n   \n \n \n Job Type:  Contract \n   \n \n \n Job Description \n Senior Data Engineer (Cloud) \n \n  Location: Downtown Chicago \n \n  Duration: 6 months \n \n  $70-$75 / HR \n \n  Description: \n \n  The Senior Cloud Data Engineer will work directly with our product lead on multiple algorithmic data science products. design, code, test, and analyze software programs and applications. This includes researching, designing, documenting, and modifying software specifications throughout the production lifecycle. This role will also create business critical reports, analyze, and amend software errors in a timely and accurate fashion and provide status reports where required. The position responsibilities outlined below are not all encompassing. Other duties, responsibilities, and qualifications may be required and/or assigned as necessary. \n \n  Responsibilities: \n \n  Work with Product team to determine requirements and propose approaches to address users' needs \n  Analyze requirements to determine approach/proposed solution \n  Design and build solutions using relevant programming languages \n  Thoroughly test solutions using relevant approaches and tools \n  Conduct research into software-related issues and products \n  Bring out-of-box thinking and solutions to address challenging issues \n  Effectively prioritize and execute tasks in a fast-paced environment \n  Work both independently and in a team-oriented, collaborative environment \n  Flexible and adaptable to learning and understanding new technologies \n  Highly self-motivated and directed \n \n \n  Experience and Skills: \n \n  Experience in designing, developing, and maintaining data pipelines on AWS cloud platform \n  Experience in developing solutions using Snowflake database \n  Hands-on software troubleshooting experience \n  Proven analytical and problem-solving abilities \n  Experience with every phase of the software development life cycle including requirements gathering, requirements analysis, design, development, and testing \n  Work closely with the product leads to identify and prioritize data needs for the algorithmic data science products \n \n \n  Must have skills: \n \n  Hands on experience with AWS cloud architecture and development data pipelines using S3, Redshift, Athena, DynamoDB, Lambda, Glue, EMR, Kinesis, API Gateway, and other AWS technologies \n  Hands on experience is building and monitoring CloudWatch alarms \n  Hands on experience with AWS CICD suite (Code commit, Code pipeline, Cloud formation) \n  Hands on experience is using Python (intermediate/expert level) \n  Hands on experience using Spark (strongly preferred) \n  Hands on experience building solutions using Snowflake database \n  Hands on experience in trouble shooting complex SQL problems \n \n \n  #PCIT #LI-REMOTE",
        "cleaned_desc": "  Thoroughly test solutions using relevant approaches and tools \n  Conduct research into software-related issues and products \n  Bring out-of-box thinking and solutions to address challenging issues \n  Effectively prioritize and execute tasks in a fast-paced environment \n  Work both independently and in a team-oriented, collaborative environment \n  Flexible and adaptable to learning and understanding new technologies \n  Highly self-motivated and directed \n \n \n  Experience and Skills: \n \n  Experience in designing, developing, and maintaining data pipelines on AWS cloud platform \n  Experience in developing solutions using Snowflake database \n  Hands-on software troubleshooting experience    Proven analytical and problem-solving abilities \n  Experience with every phase of the software development life cycle including requirements gathering, requirements analysis, design, development, and testing \n  Work closely with the product leads to identify and prioritize data needs for the algorithmic data science products \n \n \n  Must have skills: \n \n  Hands on experience with AWS cloud architecture and development data pipelines using S3, Redshift, Athena, DynamoDB, Lambda, Glue, EMR, Kinesis, API Gateway, and other AWS technologies \n  Hands on experience is building and monitoring CloudWatch alarms \n  Hands on experience with AWS CICD suite (Code commit, Code pipeline, Cloud formation) \n  Hands on experience is using Python (intermediate/expert level) \n  Hands on experience using Spark (strongly preferred) \n  Hands on experience building solutions using Snowflake database \n  Hands on experience in trouble shooting complex SQL problems ",
        "techs": [
            "aws cloud platform",
            "snowflake database",
            "s3",
            "redshift",
            "athena",
            "dynamodb",
            "lambda",
            "glue",
            "emr",
            "kinesis",
            "api gateway",
            "cloudwatch",
            "code commit",
            "code pipeline",
            "cloud formation",
            "python",
            "spark"
        ],
        "cleaned_techs": [
            "aws",
            "snowflake database",
            "s3",
            "redshift",
            "athena",
            "dynamodb",
            "lambda",
            "glue",
            "emr",
            "kinesis",
            "api gateway",
            "cloudwatch",
            "code commit",
            "code pipeline",
            "cloud formation",
            "python",
            "spark"
        ]
    },
    "04bd1a99784deeb5": {
        "terms": [
            "data science"
        ],
        "salary_min": 95689.836,
        "salary_max": 121164.65,
        "title": "Team Sales Manager",
        "company": "TritonWear",
        "desc": "Our Mission \n  We empower swimmers and coaches to produce faster swimming through education and innovative technology. \n  From our competitive swimming and engineering roots to the entire sports industry, TritonWear is committed to making sports science accessible to everyone, driving success through education and innovative technology. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n The TritonWear Advantage \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Accuracy \n  We strive to deliver the most accurate metrics and analytics tools for swimmers around the world. \n \n \n \n \n \n \n \n \n \n \n \n Competitive Edge \n  We aim to provide every swimmer an edge over their competition, by helping them discover their own hidden potential, and to understand the technical side of the sport. \n \n \n \n \n \n \n \n \n \n \n \n Leading Tech \n  We commit to equipping every coach with groundbreaking tools, so they can focus on what really matters, instead of stopwatches. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n How to Apply \n \n email: \n   \n apply@tritonwear.com \n \n \n Subject line:  Job title || your name\n             \n \n             Include your geographic region, competitive swimming experience, why this position is right for you, and your resume.\n             \n \n             Only applications meeting these requirements will be considered.\n             \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Sales  \n Team Sales Manager  \n Remote - US Full Time  \n \n \n \n \n \n About you \n  You have a deep background and network in competitive swimming as a coach, and you are experienced in selling to Competitive Swim Teams in Canada. You love sales and thrive in a fast-paced growth environment to exceed your targets. \n  You are ambitious, driven, and organized, ensuring you always have a full pipeline to keep ahead of your numbers constantly. You enjoy finding creative ways to hunt for new customers and build your business. You love making new friends and building relationships to help broaden your network and strengthen your trust in the global swimming community. \n  Finally, you are passionate about start-up growth, love autonomy and thrive as a self-starter. You know you can help over-deliver on team sales, being a crucial part of exceeding TritonWear\u2019s overall growth targets. \n  About the Role \n  As a Team Sales Manager at TritonWear, you will be responsible for helping us exceed our sales targets in our Team Sales vertical, specifically targeting teams within your assigned territory. \n  In this role, you will be selling to all levels of teams, including Clubs, High Schools, Colleges / Universities, ISL Teams, and provincial and National groups. You will also be fed international inbound leads to support your sales pipeline but will ultimately be responsible for the success of your own business and targets. Finding creative ways to build your lead pool will also be required to ensure you consistently hit or exceed your targets. \n  This Team Sales Manager role will be a remote position, and sales can be done virtually, in-field, at conferences, or in any other way proven to drive the best results. Team sales are a crucial part of TritonWear\u2019s business, so this will be vital to the organization. \n  Responsibilities \n \n Achieve agreed-upon personal and team sales targets and outcomes \n Work inbound leads from upsell mining, and marketing campaigns \n Build outbound pipeline through personal network activation activities, including strategic calling, networking and social media \n Run a tight sales process to maintain a healthy pipeline for accurate forecasting and planning \n Forecast sales, and prepare and present reports on weekly, monthly, quarterly and annual progress \n Travel to potential and existing customer training facilities to demonstrate products and services \n Attend conferences and other events to represent TritonWear and expand your contact list to build pipeline \n Prepare and deliver appropriate documentation and presentations on products and services \n Identify, present, and develop \u201cout of the box\u201d sales strategies/models and evaluate their effectiveness \n \n Requirements \n \n 3+ Years in a Team Sales role in the Competitive Swimming Industry with an extensive personal network in the sport in the US \n Strong background as a Competitive Swimming coach \n Highly motivated and target-driven with a proven track record in achieving and/or exceeding sales targets \n Strong closing, communication, and negotiation skills with experience in outbound sales and pipeline building \n Experience in sales process management, pipeline management and forecasting through a CRM (i.e. Hubspot, Salesforce, etc.) with a strong understanding of sales performance metrics \n BSc degree in Marketing, Business Administration or equivalent work experience \n \n \n \n \n \n \n \n \n \n \n \n \n Sales  \n Business Development Specialist  \n Remote -US Full Time  \n \n \n \n \n \n About you \n  You have a deep background in competitive swimming as an athlete and/or coach and are experienced in selling to Competitive Swim Teams. You love sales and thrive in a fast-paced growth environment.    You are ambitious, charismatic, and organized. You are competitive by nature and thrive on exceeding targets. You enjoy a good challenge and are creative in finding new ways to hunt for new prospects and business. You love making new friends and building relationships quickly to help broaden your network and strengthen your trust in the global swimming community.    Finally, you are passionate about start-up growth, love autonomy, and thrive as a self-starter. You know you can help over-deliver on team sales leads, which is crucial to crushing TritonWear\u2019s growth targets. You also are hungry for self-growth and have a palpable personal goal of becoming a seasoned sales professional. \n \n  About the Role \n  As a Business Development Specialist at TritonWear, you will extend our global reach through expert discovery and exploration of new and untapped business opportunities and relationships.    In this role, you will be prospecting all levels of teams within your assigned territory, including Clubs, YMCAs, High Schools, and Colleges or Universities. You will work through our CRM and with our Team Sales Managers to strategically target outbound leads. Finding creative ways to build a high-quality lead pool is critical to achieving your lead handover targets.    This remote role offers the freedom to chase leads virtually, in-field, at conferences, or in any other way proven to drive the best results. Highly skilled in sales and business operations, this person will join and inspire a team of like-minded go-getters to achieve our company vision. At TritonWear, we strongly believe in the value of mentorship and skill development, so we are looking for a candidate who wants to grow into more senior sales roles. \n  Responsibilities \n \n Identify trends and customer needs, building a short/medium/long-term sales pipeline based on target numbers \n Generate new leads, identify and contact decision-makers, screen potential business opportunities and hand off qualified leads for closing \n Build outbound pipeline through personal network activation activities, including strategic calling, networking and social media \n Run a tight sales process to build a healthy pipeline \n Prepare and present reports on lead generation targets detailing weekly, monthly, quarterly and annual progress \n Prepare and deliver appropriate documentation and presentations on products and services \n Identify, present, and develop \u201cout of the box\u201d sales strategies/models and evaluate their effectiveness \n Maintain and share professional knowledge through education, networking, events, and presentations \n \n Requirements \n \n 1+ Years in a growth-focused sales role \n Experience in cold-calling and early-stage pipeline building \n Strong background as an elite competitive swimmer or competitive swimming coach \n Highly motivated and target-driven with a proven track record in exceeding KPIs \n Strong verbal and written communication skills \n Working knowledge of sales techniques and sales performance metrics \n Proficiency with data analysis, forecasting, and budgeting \n \n \n \n \n \n \n \n \n \n \n Digital  \n Software Architect  \n Toronto - Remote Full Time  \n \n \n \n \n \n About Us \n  At TritonWear, we are the #1 swimming analytics platform helping coaches coach better, and swimmers swim faster. Our patented wearable devices and AI-coaching tools guide swim teams on precisely what they need to do to improve. We\u2019ve started with the swimming vertical and will continue to focus here until we exhaust the market and perfect our offering. However, the long-term vision is to utilize our AI-coaching platform to consume data collected by any wearable and provide much-needed feedback to athletes across any sport. \n  Using swimming as our $16B beachhead into the market, our products are being used by thousands of athletes globally in over 60 countries ranging from grassroots beginners up to Olympic Gold Medalists \u2013 including 30+ National Olympic Federations heading into the Tokyo 2024 Olympics. \n  TritonWear is an established startup backed by top-tier Canadian VC firms. We have experienced strong growth, including being recognized as one of the CIX Top 20 Companies in Canada. Our passionate and highly experienced team of former coaches and competitive athletes, as well as product experts, is headquartered out of Toronto, ON, but dispersed throughout North America. \n  About You \n  Are you a passionate Software Architect experienced in building and scaling complex platforms? Join our team if you have a love for sports and sports science, with bonus points if you enjoy swimming. As a customer-first product person, you take pride in delivering world-class solutions. With exceptional communication skills, you thrive in collaborative environments. As a strong coach and mentor, you're dedicated to growing your team and the company. In a fast-paced startup setting, you excel in agile environments. Join us to make a remarkable impact in the sports technology world. \n  About The Role \n  We're seeking an experienced Software Architect to help shape the future of our organization. As a visionary, you'll make high-level decisions that drive our software development and create innovative architectural approaches. Delivering a world-class software experience for our users is your primary focus, fueling usage, retention, and expansion. Working closely with our leadership team, you'll develop software strategies aligned with our business objectives, ensuring we stay ahead. As a vital member of the TritonWear leadership team, you'll have a voice at the table and the responsibility of delivering a world-class product. Managing and training our development team, you'll execute your plan to perfection including planning and executing sprints on schedule. If you're ready to shape industry-leading software and inspire a skilled team, join us at TritonWear and define the future. \n  Responsibilities: \n \n Lead software solution design, development, and execution to maintain our industry-leading status   \n Provide technical leadership and architectural blueprints to the Digital Team   \n Collaborate with R&D, Growth, QA, and end users for cutting-edge software solutions   \n Translate business requirements into actionable tasks and address business needs   \n Assess and recommend tools, technologies, and processes for a high-quality product platform   \n Define technology, workflow, and coding standards for development   \n Manage and train front-end developers, backend developers, and QA resources   \n Communicate concepts and guidelines effectively to the development team   \n Troubleshoot code-level problems quickly and efficiently   \n Monitor development progress for alignment with the initial design   \n Ensure compliance with quality, security, and software requirements   \n Finalize product approval before launch   \n \n Requirements: \n \n M.A.Sc./M.Eng in Software Engineering or equivalent   \n Proven experience as software architect: Experience working on complex software projects with a track record and proven ability to build and manage a full platform   \n Outstanding communication and presentation abilities   \n 3+ years leading software teams   \n 10+ years of experience in Javascript   \n 5+ years of experience in Typescript   \n 5+ years AWS including microservices, email services, database design and execution, and SQL experience   \n 5+ years developing native Android / iOS   \n 2+ years of experience interfacing apps with BLE hardware   \n \n Nice to have skills: \n \n Experience in algorithm development/implementation   \n Data Science / Analytics experience   \n A huge sports enthusiast with experience in sports science and an interest in improving athletic performance using data - a big plus if you used to be a competitive swimmer!   \n An understanding of machine learning concepts, theories and algorithms   \n Google Analytics 4 experience   \n Produce 1st party advertising data sets   \n \n Our stack \n \n Infrastructure - AWS (EC2, RDS, S3, SQS, Lambda)   \n Front End - AngularJS, React   \n Back End - Node, Python   \n Database - MySQL   \n Mobile - Hybrid (Ionic), Native (iOS / Android) \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Team Sales Manager \n \n \n \n \n About you \n  You have a deep background and network in competitive swimming as a coach, and you are experienced in selling to Competitive Swim Teams in Canada. You love sales and thrive in a fast-paced growth environment to exceed your targets. \n  You are ambitious, driven, and organized, ensuring you always have a full pipeline to keep ahead of your numbers constantly. You enjoy finding creative ways to hunt for new customers and build your business. You love making new friends and building relationships to help broaden your network and strengthen your trust in the global swimming community. \n  Finally, you are passionate about start-up growth, love autonomy and thrive as a self-starter. You know you can help over-deliver on team sales, being a crucial part of exceeding TritonWear\u2019s overall growth targets. \n  About the Role \n  As a Team Sales Manager at TritonWear, you will be responsible for helping us exceed our sales targets in our Team Sales vertical, specifically targeting teams within your assigned territory. \n  In this role, you will be selling to all levels of teams, including Clubs, High Schools, Colleges / Universities, ISL Teams, and provincial and National groups. You will also be fed international inbound leads to support your sales pipeline but will ultimately be responsible for the success of your own business and targets. Finding creative ways to build your lead pool will also be required to ensure you consistently hit or exceed your targets. \n  This Team Sales Manager role will be a remote position, and sales can be done virtually, in-field, at conferences, or in any other way proven to drive the best results. Team sales are a crucial part of TritonWear\u2019s business, so this will be vital to the organization. \n  Responsibilities \n \n Achieve agreed-upon personal and team sales targets and outcomes \n Work inbound leads from upsell mining, and marketing campaigns \n Build outbound pipeline through personal network activation activities, including strategic calling, networking and social media \n Run a tight sales process to maintain a healthy pipeline for accurate forecasting and planning \n Forecast sales, and prepare and present reports on weekly, monthly, quarterly and annual progress \n Travel to potential and existing customer training facilities to demonstrate products and services \n Attend conferences and other events to represent TritonWear and expand your contact list to build pipeline \n Prepare and deliver appropriate documentation and presentations on products and services \n Identify, present, and develop \u201cout of the box\u201d sales strategies/models and evaluate their effectiveness \n \n Requirements \n \n 3+ Years in a Team Sales role in the Competitive Swimming Industry with an extensive personal network in the sport in the US \n Strong background as a Competitive Swimming coach \n Highly motivated and target-driven with a proven track record in achieving and/or exceeding sales targets \n Strong closing, communication, and negotiation skills with experience in outbound sales and pipeline building \n Experience in sales process management, pipeline management and forecasting through a CRM (i.e. Hubspot, Salesforce, etc.) with a strong understanding of sales performance metrics \n BSc degree in Marketing, Business Administration or equivalent work experience",
        "cleaned_desc": " \n Identify trends and customer needs, building a short/medium/long-term sales pipeline based on target numbers \n Generate new leads, identify and contact decision-makers, screen potential business opportunities and hand off qualified leads for closing \n Build outbound pipeline through personal network activation activities, including strategic calling, networking and social media \n Run a tight sales process to build a healthy pipeline \n Prepare and present reports on lead generation targets detailing weekly, monthly, quarterly and annual progress \n Prepare and deliver appropriate documentation and presentations on products and services \n Identify, present, and develop \u201cout of the box\u201d sales strategies/models and evaluate their effectiveness \n Maintain and share professional knowledge through education, networking, events, and presentations \n \n Requirements \n \n 1+ Years in a growth-focused sales role \n Experience in cold-calling and early-stage pipeline building \n Strong background as an elite competitive swimmer or competitive swimming coach \n Highly motivated and target-driven with a proven track record in exceeding KPIs \n Strong verbal and written communication skills \n Working knowledge of sales techniques and sales performance metrics \n Proficiency with data analysis, forecasting, and budgeting \n \n \n \n \n \n \n \n \n \n \n Digital  \n Software Architect  \n Toronto - Remote Full Time  \n \n \n \n \n \n About Us \n  At TritonWear, we are the #1 swimming analytics platform helping coaches coach better, and swimmers swim faster. Our patented wearable devices and AI-coaching tools guide swim teams on precisely what they need to do to improve. We\u2019ve started with the swimming vertical and will continue to focus here until we exhaust the market and perfect our offering. However, the long-term vision is to utilize our AI-coaching platform to consume data collected by any wearable and provide much-needed feedback to athletes across any sport. \n  Using swimming as our $16B beachhead into the market, our products are being used by thousands of athletes globally in over 60 countries ranging from grassroots beginners up to Olympic Gold Medalists \u2013 including 30+ National Olympic Federations heading into the Tokyo 2024 Olympics. \n  TritonWear is an established startup backed by top-tier Canadian VC firms. We have experienced strong growth, including being recognized as one of the CIX Top 20 Companies in Canada. Our passionate and highly experienced team of former coaches and competitive athletes, as well as product experts, is headquartered out of Toronto, ON, but dispersed throughout North America. \n  About You \n  Are you a passionate Software Architect experienced in building and scaling complex platforms? Join our team if you have a love for sports and sports science, with bonus points if you enjoy swimming. As a customer-first product person, you take pride in delivering world-class solutions. With exceptional communication skills, you thrive in collaborative environments. As a strong coach and mentor, you're dedicated to growing your team and the company. In a fast-paced startup setting, you excel in agile environments. Join us to make a remarkable impact in the sports technology world. \n  About The Role \n  We're seeking an experienced Software Architect to help shape the future of our organization. As a visionary, you'll make high-level decisions that drive our software development and create innovative architectural approaches. Delivering a world-class software experience for our users is your primary focus, fueling usage, retention, and expansion. Working closely with our leadership team, you'll develop software strategies aligned with our business objectives, ensuring we stay ahead. As a vital member of the TritonWear leadership team, you'll have a voice at the table and the responsibility of delivering a world-class product. Managing and training our development team, you'll execute your plan to perfection including planning and executing sprints on schedule. If you're ready to shape industry-leading software and inspire a skilled team, join us at TritonWear and define the future. \n  Responsibilities: \n \n Lead software solution design, development, and execution to maintain our industry-leading status   \n Provide technical leadership and architectural blueprints to the Digital Team   \n Collaborate with R&D, Growth, QA, and end users for cutting-edge software solutions   \n Translate business requirements into actionable tasks and address business needs   \n Assess and recommend tools, technologies, and processes for a high-quality product platform   \n Define technology, workflow, and coding standards for development   \n Manage and train front-end developers, backend developers, and QA resources   \n Communicate concepts and guidelines effectively to the development team   \n Troubleshoot code-level problems quickly and efficiently   \n Monitor development progress for alignment with the initial design   \n Ensure compliance with quality, security, and software requirements   \n Finalize product approval before launch   \n \n Requirements: \n \n M.A.Sc./M.Eng in Software Engineering or equivalent   \n Proven experience as software architect: Experience working on complex software projects with a track record and proven ability to build and manage a full platform   \n Outstanding communication and presentation abilities   \n 3+ years leading software teams   \n 10+ years of experience in Javascript   \n 5+ years of experience in Typescript   \n 5+ years AWS including microservices, email services, database design and execution, and SQL experience   ",
        "techs": [
            "tritonwear",
            "ai-coaching platform",
            "wearable devices",
            "swimming analytics platform",
            "ai-coaching tools",
            "tritonwear leadership team",
            "software architect",
            "software solution design",
            "r&d",
            "growth",
            "qa",
            "front-end developers",
            "backend developers",
            "qa resources",
            "m.a.sc./m.eng in software engineering",
            "javascript",
            "typescript",
            "aws."
        ],
        "cleaned_techs": [
            "tritonwear",
            "ai",
            "wearable devices",
            "swimming analytics platform",
            "tritonwear leadership team",
            "software architect",
            "software solution design",
            "r&d",
            "growth",
            "qa",
            "front-end developers",
            "backend developers",
            "qa resources",
            "m.a.sc./m.eng in software engineering",
            "javascript",
            "typescript",
            "aws"
        ]
    },
    "005038f45df743ac": {
        "terms": [
            "data science"
        ],
        "salary_min": 114434.47,
        "salary_max": 144899.53,
        "title": "Senior RWE/SAS Programmer",
        "company": "PHASTAR",
        "desc": "Overview: \n   THE COMPANY \n \n  Phastar is a multiple award-winning global biometric Contract Research Organization (CRO) that is accredited as an outstanding company to work for by Best Companies. We partner with pharmaceutical, biotechnology and medical device organizations to provide the expertise and processes to manage and deliver on time, quality biostatistics, programming, data management and data science services. With offices across the UK, US, Germany, Denmark, Kenya, Australia, India, China and Japan, Phastar is the second largest specialized biometrics provider globally, and the largest in the UK. \n \n  Our unique approach to data analysis, \u201cThe Phastar Discipline\u201d, has led us to build a reputation for outstanding quality. With this as our core focus, we\u2019re looking for talented individuals who share our passion for quality and technical expertise to join our team. \n \n  WHY PHASTAR \n \n  Accredited as an outstanding company to work for, Phastar is committed to employee engagement, workplace satisfaction and ensuring a healthy work-life balance. We offer flexible working, part-time hours, involvement in developing company-wide initiatives, structured training and development plans, and a truly supportive, fun and friendly environment. \n \n  What\u2019s more, when you join our team, Phastar will plant a tree in your honour, as one of our Environmental, Social and Governance (ESG) initiatives. So, not only would you get your dream job, you\u2019ll also be helping to save the planet! \n \n  THE ROLE \n \n  Demand for our Functional Service Provision is growing, therefore we are looking for a passionate and driven Senior RWE/SAS Programmer to join our FSP team to support one of our reputable pharmaceutical clients. \n \n  The successful candidate should have 5+ years of experience within clinical trial programming, must have publication programming/reporting experience and have experience in programming efficacy analyses, such as efficacy endpoints and possibly multiple imputation techniques. \n \n  As a Senior RWE/SAS Programmer on clinical and non-clinical trials; the successful candidate will be responsible for producing complex datasets and outputs to excellent quality whilst adhering to deliverable timelines. They should have a good knowledge of CDISC SDTM and ADaM implementation guidelines; producing, reviewing and updating complex data specifications; creating and debugging complex macros; understanding Statistical Analysis Plans (SAPs) and output shells for day-to-day programming activities. The ideal candidate will have an excellent teamwork ethos, willingness to help others and learn new skills from working in a team environment. \n \n  This is a fantastic opportunity to work for a growing CRO that is recognized for its continuous learning and development opportunities, whilst also gaining direct experience of working within a pharmaceutical environment.  Responsibilities: \n  \n Program and validate datasets and SDTMs, including complex efficacy, labs, etc. \n  Program complex non efficacy outputs/figures \n  Perform Senior Review and Deliver QC of non- statistical output \n  Develop and debug complex macros \n  Become involved in developing the standard macro library and take responsibility to implement standard macros within a study \n  Create, QC and update complex dataset specifications (including efficacy) for single/ multiple studies, ISS/ISEs, etc. \n  Review more complex study design SAP without supervision \n  Review all shells without supervision and provide feedback \n  Knowledge, interpretation and implementation of current SDTM, ADAM standards \n  Knowledge of FDA CRT requirements including define.xml and define.pdf \n  Lead team and be responsible for creation of CRT packages \n  Become familiar with and follow study documentation \n  Lead a team for furthering programming development \n  Ensure the principles in the PHASTAR checklist are followed rigorously \n  Archive study documentation following instructions in supplied SOPs \n  Act as a Lead programmer on multiple studies under same project, ensuring quality and timely delivery \n  Liaise with Study Statistician and Project Manager regarding resourcing and deliverables \n  Responsible for study level resources \n  Attend and input to company resourcing meeting \n  Point of contact for programming issues for the team, proactively ensuring everything is working cohesively \n  Persuade stakeholders to follow best practice within a trial \n  Develop and deliver company-wide training as and when required \n  Create, review and update processes and SOPs \n  Take responsibility for study compliance with SOPs and processes \n  Qualifications: \n  \n BSc or above in Computer Science, Mathematics or a Science related discipline \n  SAS Programming experience within a clinical trials environment (CRO, pharma or academia) \n  Experience of programming to SDTM and ADaM standards (CDISC) \n  Good awareness of clinical trial issues, design, and implementation \n  Familiarity with GCP and regulatory requirements \n  Excellent written and verbal communication skills \n \n \n  APPLY NOW \n \n  With the world\u2019s eyes focused on clinical trial data, this is a fantastic time to join an award-winning specialized biometric CRO that is renowned for its technical expertise, outstanding quality and cutting-edge data science techniques. We offer flexible working, part-time hours, structured training and development plans, continuous learning opportunities, and a competitive salary and benefits package. We\u2019re committed to ensuring our employees achieve a healthy work-life balance, within a supportive, fun and friendly working environment. \n \n  Should you feel that you have the right skill set and motivations for this position, please apply! Please note that we are considering candidates located anywhere in the US or Canada as this role can be carried out remotely. \n \n  Phastar is committed to the principles and practices of equal opportunities and to encouraging the establishment of a diverse workforce. It is our policy to employ individuals on the basis of their suitability for the work to be performed and their potential for development, regardless of age, sex, race, colour, nationality, ethnic or national origin, disability, marital status, pregnancy or maternity, sexual orientation, gender reassignment, religion, or belief. This includes creating a culture that fully reflects our commitment to equal opportunities for all. \n \n  Important notice to Employment businesses/ Agencies \n \n  Phastar does not accept referrals from employment businesses and/or employment agencies in respect of the vacancies posted on this site. All employment businesses/agencies are required to contact Phastar's Head of Talent Acquisition to obtain prior written authorization before referring any candidates to Phastar. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business/ agency and Phastar. In the absence of such written authorization being obtained any actions undertaken by the employment business/agency shall be deemed to have been performed without the consent or contractual agreement of Phastar. Phastar shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses/agencies in respect of the vacancies posted on this site.",
        "cleaned_desc": "  THE ROLE \n \n  Demand for our Functional Service Provision is growing, therefore we are looking for a passionate and driven Senior RWE/SAS Programmer to join our FSP team to support one of our reputable pharmaceutical clients. \n \n  The successful candidate should have 5+ years of experience within clinical trial programming, must have publication programming/reporting experience and have experience in programming efficacy analyses, such as efficacy endpoints and possibly multiple imputation techniques. \n \n  As a Senior RWE/SAS Programmer on clinical and non-clinical trials; the successful candidate will be responsible for producing complex datasets and outputs to excellent quality whilst adhering to deliverable timelines. They should have a good knowledge of CDISC SDTM and ADaM implementation guidelines; producing, reviewing and updating complex data specifications; creating and debugging complex macros; understanding Statistical Analysis Plans (SAPs) and output shells for day-to-day programming activities. The ideal candidate will have an excellent teamwork ethos, willingness to help others and learn new skills from working in a team environment. \n \n  This is a fantastic opportunity to work for a growing CRO that is recognized for its continuous learning and development opportunities, whilst also gaining direct experience of working within a pharmaceutical environment.  Responsibilities: \n  \n Program and validate datasets and SDTMs, including complex efficacy, labs, etc. \n  Program complex non efficacy outputs/figures \n  Perform Senior Review and Deliver QC of non- statistical output ",
        "techs": [
            "sas programmer",
            "rwe/sas programmer",
            "cdisc sdtm",
            "adam",
            "sdtm",
            "saps"
        ],
        "cleaned_techs": [
            "sas",
            "rwe/sas programmer",
            "cdisc sdtm",
            "adam",
            "sdtm",
            "saps"
        ]
    },
    "527a650c55c7a42d": {
        "terms": [
            "data science"
        ],
        "salary_min": 97123.27,
        "salary_max": 122979.71,
        "title": "Associate Manager, Consumer Marketplace Insights & Innovation",
        "company": "Altria",
        "desc": "Overview: \n  \n  Are you looking for an opportunity to join a Fortune 200 company where your consumer and analytics expertise will influence our dynamic sales and marketing organizations and help craft our future? Do you thrive on transforming data into insights? If so, we want to speak with you! \n \n \n  We are currently looking for an \n   Associate Manager, Consu \n mer Marketplace Insights & Innovation  to join us in\n    Richmond, VA,  or we are \n   open to remote work arrangements. \n \n \n  What you will be doing: \n \n \n Generate consumer and marketplace insights using a combination of analytical expertise and business knowledge to provide significant recommendations to our internal brand clients. \n Serve as a critical thinking partner for the brand team by anticipating business questions and opportunities and delivering learnings to the business in ways that make significant impact.  \n Integrate and analyze a variety of data sources (e.g., retail point-of-sale, consumer, shipments, financial) to proactively identify consumer centric insights and business opportunities  \n Synthesize, translate, and communicate analyses to inform and influence business decisions  \n Collaborate with a variety of internal and external partners to develop a holistic view of marketplace dynamics. \n \n \n \n  We want you to have: \n \n \n Bachelor\u2019s degree in Analytics, Marketing, Data Science, or a related field. Advanced degree preferred  \n 4+ years of relevant data analytics experience; working knowledge of consumer research is a plus  \n Demonstrated application of technical skills with consumer data sets: SQL, Python or R a plus  \n Working knowledge of introductory statistics \n Excellent written and verbal communication skills with demonstrated ability to communicate data and technical aspects to partners having varying technical and data knowledge  \n Demonstrated experience leading cross-functional teams and influencing others without authority  \n Demonstrated strategic and creative thinking skills  \n Previous experience in visualization tools such as Tableau, Power BI a plus Consultative skills, and the courage and confidence to share your point of view \n \n \n \n \n  In addition to the opportunity to apply and develop your skills toward key business objectives, we offer an excellent compensation package including a competitive base salary, comprehensive health/vision/dental insurance, participation in our deferred profit sharing and incentive compensation programs as well as a relocation assistance. \n  Sponsorship: Immigration Sponsorship is not available for this role. Company Overview: Altria has a leading portfolio of tobacco products for U.S. tobacco consumers 21+. Our tobacco companies \u2013 which have been the undisputed market leaders in the U.S. tobacco industry for decades \u2013 include some of the most enduring names in American business. In combustibles, we own Philip Morris USA, the maker of Marlboro cigarettes and John Middleton, manufacturer of Black & Mild cigars. Our smoke-free portfolio includes ownership of U.S. Smokeless Tobacco Company, the maker of Copenhagen and Skoal, and Helix Innovations, the maker of on! oral nicotine pouches. Additionally, we have a majority-owned joint venture with JT Group, Horizon Innovations, for the U.S. marketing and commercialization of heated tobacco stick products. Through a separate agreement with Philip Morris International, we have the exclusive U.S. commercialization rights to the IQOS* Tobacco Heating System\u00ae and Marlboro HeatSticks\u00ae through April 2024. Our equity investments include Anheuser-Busch InBev SA/NV, the world\u2019s largest brewer and Cronos Group, a leading Canadian cannabinoid company. Each Altria company is an equal opportunity employer. We are committed to providing individuals with criminal records, including formerly incarcerated individuals and individuals with conviction records, a fair chance at employment. Learn more about Altria at www.altria.com and follow us on Twitter, Facebook and LinkedIn",
        "cleaned_desc": " Demonstrated application of technical skills with consumer data sets: SQL, Python or R a plus  \n Working knowledge of introductory statistics \n Excellent written and verbal communication skills with demonstrated ability to communicate data and technical aspects to partners having varying technical and data knowledge  \n Demonstrated experience leading cross-functional teams and influencing others without authority  \n Demonstrated strategic and creative thinking skills  \n Previous experience in visualization tools such as Tableau, Power BI a plus Consultative skills, and the courage and confidence to share your point of view \n ",
        "techs": [
            "sql",
            "python",
            "r",
            "tableau",
            "power bi"
        ],
        "cleaned_techs": [
            "sql",
            "python",
            "r",
            "tableau",
            "powerbi"
        ]
    },
    "fc81bf17235d8fea": {
        "terms": [
            "data science"
        ],
        "salary_min": 110000.0,
        "salary_max": -1.0,
        "title": "Microsoft Business Intelligence Developer (Hybrid)",
        "company": "Wily Fox Technologies",
        "desc": "Wily Fox Technologies is looking for a Business Intelligence Developer to join our team. \n We are looking for motivated BI technologists with an interest in working on data science projects. \n Wily Fox Technologies is a well established and growing company. Our client service mentality is part of why our clients seek us out, we truly feel that we can make their business better with process improvement, realized through process change or custom software solutions. We feel the benefits we deliver come from an understanding of the businesses needs, and creating well designed solutions to address those needs. \n We value everyone in the company and fully recognizing that the success of Wily Fox depends on the talent we can attract and retain. Our flat reporting structure minimizes bureaucracy and creates an environment of collaboration, where everyone gets a chance to communicate their thoughts and be heard. Creating an atmosphere in which people can thrive and grow their skill set. \n You\u2019ll be happy you reached out to us, really\u2026 \n For our project that is hybrid with work in downtown Sacramento, we are looking for professionals that meet the following requirements. \n \n Seven years experience with Microsoft Business Intelligence (SSAS, SSIS, SSRS, Power BI) \n Ten years experience writing complex SQL \n At least one project with a CA State Department or Agency \n Three years working with Team Foundation Services \n Four years working with HP ALM or Jama \n Desired: 1 year experience working with  SQL Server Replication Services \n \n This position does require that the candidate live in the Sacramento, CA area as the work environment will be a hybrid one. The project may become fully remote, but initially there will be in person work requirements (~2 days per week). \n Job Type: Full-time \n Pay: From $110,000.00 per year \n Benefits: \n \n 401(k) \n Dental insurance \n Flexible schedule \n Health insurance \n Paid time off \n Parental leave \n Retirement plan \n Vision insurance \n \n Experience level: \n \n 10 years \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n SQL: 8 years (Required) \n SSRS/Power BI: 6 years (Required) \n \n Work Location: Hybrid remote in Sacramento, CA 95818",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "4483df8646b64d02": {
        "terms": [
            "data science"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Director Data Engineering",
        "company": "Providence",
        "desc": "Description \n This position is remote with some in person meetings required and can only be located in the states of WA, OR, or CA. \n Leads highly technical data engineers. Accountable for all aspects of the technical design and build of modern data-centric solutions and applications to support clinical and operational processes across all parts of the enterprise health system. These solutions leverage cloud, big data, data science, and modern software development methodologies (such as SAFe) and tools and services (such as Snowflake and Databricks in Azure). Responsible for the buildout of our data engineering center of excellence for the enterprise and a community of practice across teams. Collaborates on technical solutions with teams at the Providence Global Center at Hyderabad, India. \n Providence caregivers are not simply valued \u2013 they\u2019re invaluable. Join our team at Enterprise Information Services and thrive in our culture of patient-focused, whole-person care built on understanding, commitment, and mutual respect. Your voice matters here, because we know that to inspire and retain the best people, we must empower them. \n Required Qualifications: \n \n Bachelor's Degree - Computer Engineering, Computer Science, Mathematics, Engineering. Or equivalent educ/experience, \n 10 or more years - Related experience in engineering or development roles. \n 8 years Leadership experience leading teams in a complex and fast-paced moving environment. \n Experience in cloud computing and data warehousing, Linux, Hadoop, Spark, and other NoSQL platforms. \n Strong experience working with both the product and technical sides of issues. \n Practical solutions development experience in a data-centric domain. \n Strong experience in managing and coaching a team of technical resources. \n \n Preferred Qualifications: \n \n Bachelor's Degree in Computer Science and Engineering, Mathematics, Engineering and related technical fields. \n \n The salary range listed for this position MIN:$79.20 to MAX:$131.66 per hour is based upon the primary work location Renton, WA posted. This position is remote. Salary range and offers are determined by internal pay equity and geographic cost of living differences. Salary range will vary from State and region. Salary max is limited to 75% range in order to continue to offer internal pay growth. We welcome open and transparent discussions on salary at Providence. \n Why Join Providence? \n Our best-in-class benefits are uniquely designed to support you and your family in staying well, growing professionally, and achieving financial security. We take care of you, so you can focus on delivering our Mission of caring for everyone, especially the most vulnerable in our communities. \n About Providence \n At Providence, our strength lies in Our Promise of \u201cKnow me, care for me, ease my way.\u201d Working at our family of organizations means that regardless of your role, we\u2019ll walk alongside you in your career, supporting you so you can support others. We provide best-in-class benefits and we foster an inclusive workplace where diversity is valued, and everyone is essential, heard and respected. Together, our 120,000 caregivers (all employees) serve in over 50 hospitals, over 1,000 clinics and a full range of health and social services across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. As a comprehensive health care organization, we are serving more people, advancing best practices and continuing our more than 100-year tradition of serving the poor and vulnerable. \n The amounts listed are the base pay range; additional compensation may be available for this role, such as shift differentials, standby/on-call, overtime, premiums, extra shift incentives, or bonus opportunities. \n Check out our benefits page for more information about our Benefits and Rewards. \n About the Team \n Providence Shared Services is a service line within Providence that provides a variety of functional and system support services for our family of organizations across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. We are focused on supporting our Mission by delivering a robust foundation of services and sharing of specialized expertise. \n We are committed to the principle that every workforce member has the right to work in surroundings that are free from all forms of unlawful discrimination and harassment. \n We are committed to cultural diversity and equal employment for all individuals. It is our policy to recruit, hire, promote, compensate, transfer, train, retain, terminate, and make all other employment-related decisions without regard to race, color, religious creed (including religious dress and grooming practices), national origin (including certain language use restrictions), ancestry, disability (mental and physical including HIV and AIDS), medical condition (including cancer and genetic characteristics), genetic information, marital status, age, sex (which includes pregnancy, childbirth, breastfeeding and related medical conditions), gender, gender identity, gender expression, sexual orientation, genetic information, and military and veteran status or any other applicable legally protected status. We will also provide reasonable accommodation to known physical or mental limitations of an otherwise qualified caregiver or applicant for employment, unless the accommodation would impose undue hardship on the operation of our business. \n We are a community where all people, regardless of differences, are welcome, secure, and valued. We value respect, appreciation, collaboration, diversity, and a shared commitment to serving our communities. We expect that all workforce members in our community will act in ways which reflect a commitment to and accountability for, racial and social justice and equality in the workplace. As such, we will maintain a workplace free of discrimination and harassment based on any applicable legally protected status. We also expect that all workforce members will maintain a positive workplace free from any unacceptable conduct which creates an intimidating, hostile, or offensive work environment. \n Requsition ID:  226882  \n Company:  Providence Jobs  \n Job Category:  Development/Engineering  \n Job Function:  Information Technology  \n Job Schedule:  Full time  \n Job Shift:  Day  \n Career Track:  Leadership  \n Department:  4011 SS IS HI DP 3  \n Address:  WA Renton 1801 Lind Ave SW  \n Work Location:  Providence Valley Office Park-Renton  \n Pay Range:  $79.20 - $131.66  \n The amounts listed are the base pay range; additional compensation may be available for this role, such as shift differentials, standby/on-call, overtime, premiums, extra shift incentives, or bonus opportunities.  \n Check out our benefits page for more information about our Benefits and Rewards. \n Providence is proud to be an Equal Opportunity Employer. Providence does not discriminate on the basis of race, color, gender, disability, veteran, military status, religion, age, creed, national origin, sexual identity or expression, sexual orientation, marital status, genetic information, or any other basis prohibited by local, state, or federal law.",
        "cleaned_desc": " 8 years Leadership experience leading teams in a complex and fast-paced moving environment. \n Experience in cloud computing and data warehousing, Linux, Hadoop, Spark, and other NoSQL platforms. \n Strong experience working with both the product and technical sides of issues. \n Practical solutions development experience in a data-centric domain. \n Strong experience in managing and coaching a team of technical resources. \n \n Preferred Qualifications: \n ",
        "techs": [
            "cloud computing",
            "data warehousing",
            "linux",
            "hadoop",
            "spark",
            "nosql platforms"
        ],
        "cleaned_techs": [
            "cloud computing",
            "data warehousing",
            "linux",
            "hadoop",
            "spark",
            "nosql"
        ]
    },
    "6f3fba0c1078ceb2": {
        "terms": [
            "data science"
        ],
        "salary_min": 90.0,
        "salary_max": 95.0,
        "title": "Sr. Cogito Developer",
        "company": "TalentBurst, Inc.",
        "desc": "Job Title: Senior Cogito Developer \n \n Location: REMOTE (Local to Philadelphia PA candidates preferred) \n \n Duration: 6 months plus extension \n \n Pay Rate: $90/hr. - $95/hr. \n \n \n Job Requirements: \n \n Epic Cogito Fundamentals \n Epic Cogito Tools Administration \n \n Required Education: \n \n Bachelor's Degree in Health Science, Computer Science, Math, Engineering, Business, or related quantitative fields. \n \n Required Experience: \n \n Five (5) years of experience in analytics/business intelligence within a healthcare system using the Epic Systems electronic health record. \n \n Preferred Education: \n \n Master's degree \n \n Preferred Experience: \n \n Eight (8) years of experience in analytics/business intelligence \n Experience with data visualization tools preferred (Qlik, Tableau, Power BI, etc) \n Experience with  Epic's Cogito  product suite including SlicerDicer, Custom SQL Metrics, Crystal Reports, Radar, Reporting Workbench, CogitoSQL Templates \n Experience working as a data analyst within a healthcare setting \n Experience with clinical, access, and/or revenue Epic applications \n \n Preferred Licenses/certificates/registrations: \n \n \n Certification  in at least one of the following Data Models \n  \n Clinical Data Model \n Revenue Data Model \n Access Data Model \n Certification in at least one of the following other Cogito tools: \n SlicerDicer \n CogitoSQL Templates \n Radar SQL Metrics \n Implementing Cognitive Computing \n \n Job Description: \n \n The Senior Cogito Developer will join the Cogito Product team within the Data and Analytics team in the Center for Healthcare Quality and Analytics and will be responsible for empowering users with Epic-based data across the institution, providing a unique blend of clinical, business, technical, and analytical expertise. \n The Cogito Product team oversees the development and utilization of Epic reporting tools throughout the enterprise to drive strategic initiatives, improve safety & quality of care, and streamline operations. \n The team combines business knowledge with data and technology to empower decision-makers and believes that user-friendly, self-service, embedded analytics products can improve patient outcomes, optimize processes, and reduce costs. \n We believe in providing actionable insights which drive real, measurable, impact! \n The team is looking for creative problem solvers who are excited about joining a collaborative team to utilize data to transform the Client into a data-driven organization; one that practices data-driven decision-making and utilizes data to improve the experience of our patients, families, and staff. \n The Senior Cogito Developer is passionate about healthcare delivery in a patient care setting. \n A successful candidate is articulate, analytical, and a team player who understands the power of data storytelling to drive change. \n The developer enjoys coordinating with interdisciplinary teams to create solutions for improving operational and clinical decision-making. \n The developer learns quickly, works independently, and is relentless in overcoming technical, process, and organizational obstacles. \n \n Also: \n \n The Senior Cogito Developer will lead high-profile strategic projects and will be a reliable expert in translating clinical and business requirements into meaningful analysis within the  Epic Cogito  suite of tools. \n When necessary, the developer will appropriately apply data science techniques and other advanced analytics to solve problems as we expand into cognitive computing. \n The individual will need to build relationships with key stakeholders, be an expert in multiple Epic data sources, and implement sustainable solutions. \n The individual should bring project management experience and share best practices with the team. \n The analyst must be comfortable with mentorship and partnering with the Cogito Product and other teams within the Data and Analytics group. \n The position is fully remote, with the possibility of extension. The position is contract only at this time but could become temp to perm if needs align.\n  \n \n Job Responsibilities: \n \n  1. Individual Contributor \n  \n Guides clinical teams and business stakeholders on large-scope projects: gathering requirements, developing metrics, retrieving data, ensuring validity of results, and building out the appropriate Epic tool for the end-user. \n Proposes and creates innovative and appropriate data solutions (dashboards, reports, etc) for the measurement of processes and outcomes \n Adept at learning new information systems and how the data generated contributes to the data development lifecycle \n Advises on new SlicerDicer data models, testing frameworks, and documentation and build practices \n Works with the Cogito Product Team to periodically upgrade the Epic system \n Demonstrates excellent data storytelling skills through outstanding presentation and communication to share findings in an understandable and actionable manner tailored to the audience and customer's needs \n 2. Project Management \n  \n Responsible for the coordination and completion of assigned projects, including project definition, assignment of task responsibilities, setting deadlines, and all other aspects of project management. \n Independently identifies and works to remediate project obstacles. \n 3. Leadership \n  \n Identifies, defines, and implements new data-driven strategies and processes for the organization. \n Communicates work plans, progress, findings, and interpretations effectively with a continual focus on educating and developing the analytic capability of business customers and the organization overall. \n Trains and mentors team members \n Develops a \"trusted advisor\u201d reputation through expertise in data and the mentoring of others in the use of the Epic Cogito suite of tools \n \n Additional Technical Requirements: \n \n Experience with SQL \n Knowledge of relational database structures \n Experience in project management \n TB_HL",
        "cleaned_desc": " \n Five (5) years of experience in analytics/business intelligence within a healthcare system using the Epic Systems electronic health record. \n \n Preferred Education: \n \n Master's degree \n \n Preferred Experience: \n \n Eight (8) years of experience in analytics/business intelligence \n Experience with data visualization tools preferred (Qlik, Tableau, Power BI, etc) \n Experience with  Epic's Cogito  product suite including SlicerDicer, Custom SQL Metrics, Crystal Reports, Radar, Reporting Workbench, CogitoSQL Templates \n Experience working as a data analyst within a healthcare setting \n Experience with clinical, access, and/or revenue Epic applications \n \n Preferred Licenses/certificates/registrations: \n \n \n Certification  in at least one of the following Data Models    \n Clinical Data Model \n Revenue Data Model \n Access Data Model \n Certification in at least one of the following other Cogito tools: \n SlicerDicer \n CogitoSQL Templates \n Radar SQL Metrics \n Implementing Cognitive Computing \n \n Job Description: \n \n The Senior Cogito Developer will join the Cogito Product team within the Data and Analytics team in the Center for Healthcare Quality and Analytics and will be responsible for empowering users with Epic-based data across the institution, providing a unique blend of clinical, business, technical, and analytical expertise. \n The Cogito Product team oversees the development and utilization of Epic reporting tools throughout the enterprise to drive strategic initiatives, improve safety & quality of care, and streamline operations. \n The team combines business knowledge with data and technology to empower decision-makers and believes that user-friendly, self-service, embedded analytics products can improve patient outcomes, optimize processes, and reduce costs. \n We believe in providing actionable insights which drive real, measurable, impact! \n The team is looking for creative problem solvers who are excited about joining a collaborative team to utilize data to transform the Client into a data-driven organization; one that practices data-driven decision-making and utilizes data to improve the experience of our patients, families, and staff. \n The Senior Cogito Developer is passionate about healthcare delivery in a patient care setting. \n A successful candidate is articulate, analytical, and a team player who understands the power of data storytelling to drive change.   The developer enjoys coordinating with interdisciplinary teams to create solutions for improving operational and clinical decision-making. \n The developer learns quickly, works independently, and is relentless in overcoming technical, process, and organizational obstacles. \n \n Also: \n \n The Senior Cogito Developer will lead high-profile strategic projects and will be a reliable expert in translating clinical and business requirements into meaningful analysis within the  Epic Cogito  suite of tools. \n When necessary, the developer will appropriately apply data science techniques and other advanced analytics to solve problems as we expand into cognitive computing. \n The individual will need to build relationships with key stakeholders, be an expert in multiple Epic data sources, and implement sustainable solutions. \n The individual should bring project management experience and share best practices with the team. \n The analyst must be comfortable with mentorship and partnering with the Cogito Product and other teams within the Data and Analytics group. \n The position is fully remote, with the possibility of extension. The position is contract only at this time but could become temp to perm if needs align.\n  \n \n Job Responsibilities: \n \n  1. Individual Contributor \n  \n Guides clinical teams and business stakeholders on large-scope projects: gathering requirements, developing metrics, retrieving data, ensuring validity of results, and building out the appropriate Epic tool for the end-user. \n Proposes and creates innovative and appropriate data solutions (dashboards, reports, etc) for the measurement of processes and outcomes   Adept at learning new information systems and how the data generated contributes to the data development lifecycle \n Advises on new SlicerDicer data models, testing frameworks, and documentation and build practices \n Works with the Cogito Product Team to periodically upgrade the Epic system \n Demonstrates excellent data storytelling skills through outstanding presentation and communication to share findings in an understandable and actionable manner tailored to the audience and customer's needs \n 2. Project Management \n  \n Responsible for the coordination and completion of assigned projects, including project definition, assignment of task responsibilities, setting deadlines, and all other aspects of project management. \n Independently identifies and works to remediate project obstacles. \n 3. Leadership \n  \n Identifies, defines, and implements new data-driven strategies and processes for the organization. \n Communicates work plans, progress, findings, and interpretations effectively with a continual focus on educating and developing the analytic capability of business customers and the organization overall. \n Trains and mentors team members \n Develops a \"trusted advisor\u201d reputation through expertise in data and the mentoring of others in the use of the Epic Cogito suite of tools \n \n Additional Technical Requirements: \n \n Experience with SQL \n Knowledge of relational database structures ",
        "techs": [
            "epic systems electronic health record",
            "qlik",
            "tableau",
            "power bi",
            "epic's cogito product suite (slicerdicer",
            "custom sql metrics",
            "crystal reports",
            "radar",
            "reporting workbench",
            "cogitosql templates)",
            "clinical data model",
            "revenue data model",
            "access data model",
            "slicerdicer",
            "cogitosql templates",
            "radar sql metrics",
            "implementing cognitive computing",
            "sql",
            "relational database structures"
        ],
        "cleaned_techs": [
            "epic systems electronic health record",
            "qlik",
            "tableau",
            "powerbi",
            "epic's cogito product suite (slicerdicer",
            "custom sql metrics",
            "crystal reports",
            "radar",
            "reporting workbench",
            "cogitosql templates)",
            "clinical data model",
            "revenue data model",
            "access data model",
            "slicerdicer",
            "cogitosql templates",
            "radar sql metrics",
            "implementing cognitive computing",
            "sql",
            "relational database structures"
        ]
    },
    "e999a0eae23454c3": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 60.0,
        "salary_max": 67.0,
        "title": "NLP Data Scientist",
        "company": "Primary Talent Partners",
        "desc": "Primary Talent Partners has a contract opportunity with our great pharmaceutical client \n \n 100% Remote \n \n W2 Candidates only; not open for C2C \n \n \n Description :\n   We're seeking a talented and innovative NLP/Information Retrieval Scientist to join our team. In this role, you will play a pivotal part in enhancing Large Language Models (LLMs) to provide more accurate, context-aware, and creatively curated responses with real-world applications.\n   As an NLP/Information Retrieval Scientist, you will develop and improve the usability and creativity of our LLM responses. You will collaborate closely with our multidisciplinary team of researchers and engineers to not only advance the technical aspects but also bring real-world relevance and creativity into our language models.\n   The successful candidate will use the latest innovations in NLP and LLM to propose software solutions to improve customer experience. The Remote Sensing Data Scientist will design and test algorithms, conduct prototyping to evaluate possible scenarios leveraging computational and statistical techniques for the development of Client approaches for remotely sensed data.\n  \n \n Required Skills: \n \n MS with 5+ years\u2019 experience or Ph.D. with 3+ years' experience \n Computer Science, Electrical Engineering, Physics, Mathematics, Statistics, or an Analytics discipline. \n Expertise with NLP or Information \n Proficiency in Python or in another high-level programming language \n Experience in developing statistical, and machine learning models for environmental and agronomical applications \n Familiarity with LLM \n Experience analyzing and presenting complex data and proven problem-solving abilities \n Strong publication record in leading scientific journals \n \n Desired Skills: \n \n Experience working with agricultural/biological scientific data is highly desired \n Drive for translating business problems into research initiatives that deliver business value \n Creativity in defining challenging exploratory projects \n \n \n Primary Talent Partners is an Equal Opportunity / Affirmative Action employer committed to diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, age, national origin, disability, protected veteran status, gender identity, or any other factor protected by applicable federal, state, or local laws. \n \n  #PTPJobs",
        "cleaned_desc": " Proficiency in Python or in another high-level programming language \n Experience in developing statistical, and machine learning models for environmental and agronomical applications \n Familiarity with LLM \n Experience analyzing and presenting complex data and proven problem-solving abilities \n Strong publication record in leading scientific journals \n ",
        "techs": [
            "python",
            "llm"
        ],
        "cleaned_techs": [
            "python",
            "llm"
        ]
    },
    "318cd9c9f0c8af0e": {
        "terms": [
            "data science"
        ],
        "salary_min": 80.0,
        "salary_max": 90.0,
        "title": "Sr. Cogito Developer",
        "company": "MetaSense Inc",
        "desc": "Job Title:  Sr. Cogito Developer Location:  Philadelphia, PA 19104 Duration:  6 Months Duties: The Senior Cogito Developer will join the Cogito Product team within the Data and Analytics team in the Center for Healthcare Quality and Analytics, and will be responsible for empowering users with Epic-based data across the institution, providing a unique blend of clinical, business, technical, and analytical expertise. The Cogito Product team oversees the development and utilization of Epic reporting tools throughout the enterprise to drive strategic initiatives, improve safety & quality of care, and streamline operations. The team combines business knowledge with data and technology to empower decision makers and believes that user-friendly, self-service, embedded analytics products can improve patient outcomes, optimize processes, and reduce costs. We believe in providing actionable insights which drive real, measurable, impact! The team is looking for creative problem solvers who are excited about joining a collaborative team to utilize data to transform facility into a data-driven organization; one that practices data-driven decision making and utilizes data to improve the experience of our patients, families, and staff. The Senior Cogito Developer is passionate about healthcare delivery in a patient care setting. A successful candidate is articulate, analytical, and a team player who understands the power of data storytelling to drive change. The developer enjoys coordinating with interdisciplinary teams to create solutions for improving operational and clinical decision making. The developer learns quickly, works independently, and is relentless in overcoming technical, process, and organizational obstacles. \n The Senior Cogito Developer will lead high-profile strategic projects and will be a reliable expert in translating clinical and business requirements into meaningful analysis within the Epic Cogito suite of tools. When necessary, the developer will appropriately apply data science techniques and other advanced analytics to solve problems as we expand into cognitive computing. The individual will need to build relationships with key stakeholders, be an expert in multiple Epic data sources, and implement sustainable solutions. The individual should bring project management experience and share best practices with the team. The analyst must be comfortable with mentorship and partnering with the Cogito Product and other teams within the Data and Analytics group. \n Skills: Position is fully remote, with the possibility of extension. \n Position is contract only at this time, but could become temp to perm if needs align. \n Job Responsibilities: 1.Individual Contributor \u2022Guides clinical teams and business stakeholders on large scope projects: gathering requirements, developing metrics, retrieving data, ensuring validity of results, and building out the appropriate Epic tool for the end-user. \u2022Proposes and creates innovative and appropriate data solutions (dashboards, reports, etc.) for the measurement of processes and outcomes \u2022Adept at learning new information systems and how the data generated contributes to the data development lifecycle \u2022Advises on new SlicerDicer data models, testing frameworks, and documentation and build practices \u2022Works with Cogito Product Team to periodically upgrade the Epic system \u2022Demonstrates excellent data storytelling skills through outstanding presentation and communication to share findings in an understandable and actionable manner tailored to audience and customer's needs 2.Project Management \u2022Responsible for the coordination and completion of assigned projects, including project definition, assignment of task responsibilities, setting deadlines, and all other aspects of project management. \u2022Independently identifies and works to remediate project obstacles 3.Leadership \u2022Identifies, defines, and implements new data-driven strategies and processes for the organization. \u2022Communicates work plans, progress, findings, and interpretations effectively with a continual focus on educating and developing analytic capability of business customers and the organization overall. \u2022Trains and mentors team members \u2022Develops a \u00e2\u20ac\u0153trusted advisor\u00e2\u20ac\u009d reputation through expertise in data and the mentoring of others in the use of the Epic Cogito suite of tools Additional Technical Requirements \u2022Experience with SQL \u2022Knowledge of relational database structures \u2022Experience in project management \n Required Licenses, Certifications, Registrations: Epic Cogito Fundamentals Epic Cogito Tools Administration \n Required Education: \n Bachelor's Degree in Health Science, Computer Science, Math, Engineering, Business, or related quantitative fields. \n Required Experience: \n Five (5) years of experience in analytics / business intelligence within a healthcare system using the Epic Systems electronic health record. \n Preferred Education: \n Master's degree \n Preferred Experience:  Eight (8) years of experience in analytics / business intelligence Experience with data visualization tools preferred (Qlik, Tableau, Power BI, etc) Experience with Epic's Cogito product suite including SlicerDicer, Custom SQL Metrics, Crystal Reports, Radar, Reporting Workbench, CogitoSQL Templates Experience working as a data analyst within a healthcare setting Experience with clinical, access, and/or revenue Epic applications \n Preferred Licenses/certificates/registrations: Certification in at least one of the following Data Models: Clinical Data Model \n Revenue Data Model Access Data Model \n Certification in at least one of the following other Cogito tools: \u2022SlicerDicer \u2022CogitoSQL Templates \u2022Radar SQL Metrics \u2022Implementing Cognitive Computing #IND6 \n Job Type: Contract \n Pay: $80.00 - $90.00 per hour \n Schedule: \n \n 8 hour shift \n Day shift \n Monday to Friday \n \n Experience: \n \n Hospital: 8 years (Required) \n Business intelligence: 8 years (Required) \n Data visualization: 6 years (Required) \n Epic Cogito: 7 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": "Job Title:  Sr. Cogito Developer Location:  Philadelphia, PA 19104 Duration:  6 Months Duties: The Senior Cogito Developer will join the Cogito Product team within the Data and Analytics team in the Center for Healthcare Quality and Analytics, and will be responsible for empowering users with Epic-based data across the institution, providing a unique blend of clinical, business, technical, and analytical expertise. The Cogito Product team oversees the development and utilization of Epic reporting tools throughout the enterprise to drive strategic initiatives, improve safety & quality of care, and streamline operations. The team combines business knowledge with data and technology to empower decision makers and believes that user-friendly, self-service, embedded analytics products can improve patient outcomes, optimize processes, and reduce costs. We believe in providing actionable insights which drive real, measurable, impact! The team is looking for creative problem solvers who are excited about joining a collaborative team to utilize data to transform facility into a data-driven organization; one that practices data-driven decision making and utilizes data to improve the experience of our patients, families, and staff. The Senior Cogito Developer is passionate about healthcare delivery in a patient care setting. A successful candidate is articulate, analytical, and a team player who understands the power of data storytelling to drive change. The developer enjoys coordinating with interdisciplinary teams to create solutions for improving operational and clinical decision making. The developer learns quickly, works independently, and is relentless in overcoming technical, process, and organizational obstacles. \n The Senior Cogito Developer will lead high-profile strategic projects and will be a reliable expert in translating clinical and business requirements into meaningful analysis within the Epic Cogito suite of tools. When necessary, the developer will appropriately apply data science techniques and other advanced analytics to solve problems as we expand into cognitive computing. The individual will need to build relationships with key stakeholders, be an expert in multiple Epic data sources, and implement sustainable solutions. The individual should bring project management experience and share best practices with the team. The analyst must be comfortable with mentorship and partnering with the Cogito Product and other teams within the Data and Analytics group. \n Skills: Position is fully remote, with the possibility of extension. \n Position is contract only at this time, but could become temp to perm if needs align. \n Job Responsibilities: 1.Individual Contributor \u2022Guides clinical teams and business stakeholders on large scope projects: gathering requirements, developing metrics, retrieving data, ensuring validity of results, and building out the appropriate Epic tool for the end-user. \u2022Proposes and creates innovative and appropriate data solutions (dashboards, reports, etc.) for the measurement of processes and outcomes \u2022Adept at learning new information systems and how the data generated contributes to the data development lifecycle \u2022Advises on new SlicerDicer data models, testing frameworks, and documentation and build practices \u2022Works with Cogito Product Team to periodically upgrade the Epic system \u2022Demonstrates excellent data storytelling skills through outstanding presentation and communication to share findings in an understandable and actionable manner tailored to audience and customer's needs 2.Project Management \u2022Responsible for the coordination and completion of assigned projects, including project definition, assignment of task responsibilities, setting deadlines, and all other aspects of project management. \u2022Independently identifies and works to remediate project obstacles 3.Leadership \u2022Identifies, defines, and implements new data-driven strategies and processes for the organization. \u2022Communicates work plans, progress, findings, and interpretations effectively with a continual focus on educating and developing analytic capability of business customers and the organization overall. \u2022Trains and mentors team members \u2022Develops a \u00e2\u20ac\u0153trusted advisor\u00e2\u20ac\u009d reputation through expertise in data and the mentoring of others in the use of the Epic Cogito suite of tools Additional Technical Requirements \u2022Experience with SQL \u2022Knowledge of relational database structures \u2022Experience in project management \n Required Licenses, Certifications, Registrations: Epic Cogito Fundamentals Epic Cogito Tools Administration   Preferred Experience:  Eight (8) years of experience in analytics / business intelligence Experience with data visualization tools preferred (Qlik, Tableau, Power BI, etc) Experience with Epic's Cogito product suite including SlicerDicer, Custom SQL Metrics, Crystal Reports, Radar, Reporting Workbench, CogitoSQL Templates Experience working as a data analyst within a healthcare setting Experience with clinical, access, and/or revenue Epic applications \n Preferred Licenses/certificates/registrations: Certification in at least one of the following Data Models: Clinical Data Model \n Revenue Data Model Access Data Model \n Certification in at least one of the following other Cogito tools: \u2022SlicerDicer \u2022CogitoSQL Templates \u2022Radar SQL Metrics \u2022Implementing Cognitive Computing #IND6 \n Job Type: Contract \n Pay: $80.00 - $90.00 per hour ",
        "techs": [
            "sr. cogito developer",
            "epic-based data",
            "epic reporting tools",
            "data and technology",
            "self-service analytics products",
            "actionable insights",
            "patient outcomes",
            "data-driven organization",
            "data storytelling",
            "technical expertise",
            "data science techniques",
            "cognitive computing",
            "project management",
            "mentorship",
            "data solutions",
            "slicerdicer",
            "data visualization tools",
            "sql",
            "relational database structures",
            "project management",
            "epic cogito fundamentals",
            "epic cogito tools administration",
            "qlik",
            "tableau",
            "power bi",
            "crystal reports",
            "radar",
            "reporting workbench",
            "healthcare setting",
            "clinical",
            "access",
            "and/or revenue epic applications",
            "clinical data model",
            "revenue data model",
            "access data model",
            "slicerdicer",
            "cogitosql templates",
            "radar sql metrics",
            "implementing cognitive computing"
        ],
        "cleaned_techs": [
            "sr. cogito developer",
            "epic-based data",
            "epic reporting tools",
            "data and technology",
            "self-service analytics products",
            "actionable insights",
            "patient outcomes",
            "data-driven organization",
            "data storytelling",
            "technical expertise",
            "data science techniques",
            "cognitive computing",
            "project management",
            "mentorship",
            "data solutions",
            "slicerdicer",
            "data visualization tools",
            "sql",
            "relational database structures",
            "epic cogito fundamentals",
            "epic cogito tools administration",
            "qlik",
            "tableau",
            "powerbi",
            "crystal reports",
            "radar",
            "reporting workbench",
            "healthcare setting",
            "clinical",
            "access",
            "clinical data model",
            "revenue data model",
            "access data model",
            "cogitosql templates",
            "radar sql metrics",
            "implementing cognitive computing"
        ]
    },
    "6c101f8c048347fd": {
        "terms": [
            "data science"
        ],
        "salary_min": 103000.0,
        "salary_max": -1.0,
        "title": "Statistician",
        "company": "Windsor Group LLC, is a Maryland based company providing professional services and business solutions to both federal government and commercial entities.",
        "desc": "About us \n We are professional, customer-centric, supportive and our goal is to Create trusting, collaborative environments for project teams to work efficiently in and provide clear direction and communication to the team, so that we mitigate project risks and achieve the client's vision and project objectives.. \n Our work environment includes: \n \n Growth opportunities \n Safe work environment \n \n Responsibilities:  (read full job description and educational requirements prior to applying for this position) : \n Serves as a statistician with responsibility to design, approve, and monitor statistical studies involving surveys and health workforce supply and demand projections. \n \n Provides advice and is responsible for contributing to the design of complex national health workforce and policy issues related to health professions surveys, including sample design, data collection methods, instrument content and design, data processing protocols, editing and imputation procedures, weighting and estimation methods, quality assurance, and management of data collection. \n Consults on the application of advanced statistical analysis theory and methodology, including the most current advances. \n Collaborates with policy analysts, researchers, and other officials within the Office, in other components of the Agency, in other agencies of Federal, State, and local governments, and in other organizations. \n Develops and implements sample and instrument designs for surveys collecting data related to the health professions, utilizing the appropriate survey design theory and methods, effectively using the assigned budget, plans efficient use of available resources in implementing new sample designs, field procedures, questionnaires, and quality control systems. \n Utilizing secondary data to write a clear research question, select a study sample, utilize appropriate measurement, and sample weighting techniques and design a thoughtful analytic approach to answer high impact questions on health workforce issues. \n Develops studies of health professions programs, utilizing the appropriate statistical and epidemiologic theory and methods, effectively using the assigned budget, and considering precision criteria and the existence of non-sampling errors. \n Develops statistical analyses to produce unbiased population estimates and estimates of variances from complex sample designs. \n Uses analytic, and technical skills to make sound judgments that balance quality and cost/performance factors, with appropriate consideration of the consequences of such decisions. \n Evaluates health professions/workforce data from various sources and makes recommendations regarding technical policy in terms of limitations, validity, interpretation, release of data and usefulness of the data source as a tool in addressing health professions/workforce policy issues. \n Communication and collaboration with stakeholders across multifaceted organizations, identifying opportunities, communicating findings, and delivering actionable insights. \n \n Resume must show experience to qualify for this position. \n Individuals must possess Ph.D. or Masters with five (5) plus years of specialized experience. Specialized experience is defined as experience that is typically in or related to the work of the position to be filled, and has equipped you with the knowledge, skills, and abilities to successfully perform the duties of the position, and that is typically in or related to the work of the position to be filled. \n Qualifications and Education \n Degree: that included 15 semester hours in statistics (or in mathematics and statistics, provided at least 6 semester hours were in statistics), and 9 additional semester hours in one or more of the following: in the social sciences including demography, history, economics, social welfare, health sociology, political science, public administration, psychology, etc. Credit toward meeting statistical course requirements should be given for courses in which 50 percent of the course content appears to be statistical methods, e.g., courses that included studies in research methods in psychology or economics such as tests and measurements or business cycles, or courses in methods of processing mass statistical data such as tabulating methods or electronic data processing. \n OR \n Combination of education and experience - courses as shown above, plus appropriate experience or additional education. The experience should have included a full range of professional statistical work such a (a) sampling, (b) collecting, computing, and analyzing statistical data, and (c) applying statistical techniques such as measurement of central tendency, dispersion, skewness, sampling error, simple and multiple correlation, analysis of variance, and tests of significance. \n Job Type: Full-time \n Pay: From $103,000.00 per year \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Health insurance \n Life insurance \n Paid time off \n Vision insurance \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n Python: 3 years (Required) \n SQL: 3 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": " Evaluates health professions/workforce data from various sources and makes recommendations regarding technical policy in terms of limitations, validity, interpretation, release of data and usefulness of the data source as a tool in addressing health professions/workforce policy issues. \n Communication and collaboration with stakeholders across multifaceted organizations, identifying opportunities, communicating findings, and delivering actionable insights. \n \n Resume must show experience to qualify for this position. \n Individuals must possess Ph.D. or Masters with five (5) plus years of specialized experience. Specialized experience is defined as experience that is typically in or related to the work of the position to be filled, and has equipped you with the knowledge, skills, and abilities to successfully perform the duties of the position, and that is typically in or related to the work of the position to be filled. \n Qualifications and Education \n Degree: that included 15 semester hours in statistics (or in mathematics and statistics, provided at least 6 semester hours were in statistics), and 9 additional semester hours in one or more of the following: in the social sciences including demography, history, economics, social welfare, health sociology, political science, public administration, psychology, etc. Credit toward meeting statistical course requirements should be given for courses in which 50 percent of the course content appears to be statistical methods, e.g., courses that included studies in research methods in psychology or economics such as tests and measurements or business cycles, or courses in methods of processing mass statistical data such as tabulating methods or electronic data processing. \n OR \n Combination of education and experience - courses as shown above, plus appropriate experience or additional education. The experience should have included a full range of professional statistical work such a (a) sampling, (b) collecting, computing, and analyzing statistical data, and (c) applying statistical techniques such as measurement of central tendency, dispersion, skewness, sampling error, simple and multiple correlation, analysis of variance, and tests of significance. ",
        "techs": [
            "statistics",
            "mathematics",
            "social sciences",
            "demography",
            "history",
            "economics",
            "social welfare",
            "health sociology",
            "political science",
            "public administration",
            "psychology",
            "research methods",
            "tests and measurements",
            "business cycles",
            "methods of processing mass statistical data",
            "tabulating methods",
            "electronic data processing",
            "sampling",
            "collecting",
            "computing",
            "analyzing statistical data",
            "measurement of central tendency",
            "dispersion",
            "skewness",
            "sampling error",
            "simple correlation",
            "multiple correlation",
            "analysis of variance",
            "tests of significance"
        ],
        "cleaned_techs": [
            "statistics",
            "mathematics",
            "social sciences",
            "demography",
            "history",
            "economics",
            "social welfare",
            "health sociology",
            "political science",
            "public administration",
            "psychology",
            "research methods",
            "tests and measurements",
            "business cycles",
            "methods of processing mass statistical data",
            "tabulating methods",
            "electronic data processing",
            "sampling",
            "collecting",
            "computing",
            "analyzing statistical data",
            "measurement of central tendency",
            "dispersion",
            "skewness",
            "sampling error",
            "simple correlation",
            "multiple correlation",
            "analysis of variance",
            "tests of significance"
        ]
    },
    "ccebf87f8d6b9497": {
        "terms": [
            "data science"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Director Data Engineering",
        "company": "Providence",
        "desc": "Description \n This position is remote with some in person meetings required and can only be located in the states of WA, OR, or CA. \n Leads highly technical data engineers. Accountable for all aspects of the technical design and build of modern data-centric solutions and applications to support clinical and operational processes across all parts of the enterprise health system. These solutions leverage cloud, big data, data science, and modern software development methodologies (such as SAFe) and tools and services (such as Snowflake and Databricks in Azure). Responsible for the buildout of our data engineering center of excellence for the enterprise and a community of practice across teams. Collaborates on technical solutions with teams at the Providence Global Center at Hyderabad, India. \n Providence caregivers are not simply valued \u2013 they\u2019re invaluable. Join our team at Enterprise Information Services and thrive in our culture of patient-focused, whole-person care built on understanding, commitment, and mutual respect. Your voice matters here, because we know that to inspire and retain the best people, we must empower them. \n Required Qualifications: \n \n Bachelor's Degree - Computer Engineering, Computer Science, Mathematics, Engineering. Or equivalent educ/experience, \n 10 or more years - Related experience in engineering or development roles. \n 8 years Leadership experience leading teams in a complex and fast-paced moving environment. \n Experience in cloud computing and data warehousing, Linux, Hadoop, Spark, and other NoSQL platforms. \n Strong experience working with both the product and technical sides of issues. \n Practical solutions development experience in a data-centric domain. \n Strong experience in managing and coaching a team of technical resources. \n \n Preferred Qualifications: \n \n Bachelor's Degree in Computer Science and Engineering, Mathematics, Engineering and related technical fields. \n \n The salary range listed for this position MIN:$79.20 to MAX:$131.66 per hour is based upon the primary work location Renton, WA posted. This position is remote. Salary range and offers are determined by internal pay equity and geographic cost of living differences. Salary range will vary from State and region. Salary max is limited to 75% range in order to continue to offer internal pay growth. We welcome open and transparent discussions on salary at Providence. \n Why Join Providence? \n Our best-in-class benefits are uniquely designed to support you and your family in staying well, growing professionally, and achieving financial security. We take care of you, so you can focus on delivering our Mission of caring for everyone, especially the most vulnerable in our communities. \n About Providence \n At Providence, our strength lies in Our Promise of \u201cKnow me, care for me, ease my way.\u201d Working at our family of organizations means that regardless of your role, we\u2019ll walk alongside you in your career, supporting you so you can support others. We provide best-in-class benefits and we foster an inclusive workplace where diversity is valued, and everyone is essential, heard and respected. Together, our 120,000 caregivers (all employees) serve in over 50 hospitals, over 1,000 clinics and a full range of health and social services across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. As a comprehensive health care organization, we are serving more people, advancing best practices and continuing our more than 100-year tradition of serving the poor and vulnerable. \n The amounts listed are the base pay range; additional compensation may be available for this role, such as shift differentials, standby/on-call, overtime, premiums, extra shift incentives, or bonus opportunities. \n Check out our benefits page for more information about our Benefits and Rewards. \n About the Team \n Providence Shared Services is a service line within Providence that provides a variety of functional and system support services for our family of organizations across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. We are focused on supporting our Mission by delivering a robust foundation of services and sharing of specialized expertise. \n We are committed to the principle that every workforce member has the right to work in surroundings that are free from all forms of unlawful discrimination and harassment. \n We are committed to cultural diversity and equal employment for all individuals. It is our policy to recruit, hire, promote, compensate, transfer, train, retain, terminate, and make all other employment-related decisions without regard to race, color, religious creed (including religious dress and grooming practices), national origin (including certain language use restrictions), ancestry, disability (mental and physical including HIV and AIDS), medical condition (including cancer and genetic characteristics), genetic information, marital status, age, sex (which includes pregnancy, childbirth, breastfeeding and related medical conditions), gender, gender identity, gender expression, sexual orientation, genetic information, and military and veteran status or any other applicable legally protected status. We will also provide reasonable accommodation to known physical or mental limitations of an otherwise qualified caregiver or applicant for employment, unless the accommodation would impose undue hardship on the operation of our business. \n We are a community where all people, regardless of differences, are welcome, secure, and valued. We value respect, appreciation, collaboration, diversity, and a shared commitment to serving our communities. We expect that all workforce members in our community will act in ways which reflect a commitment to and accountability for, racial and social justice and equality in the workplace. As such, we will maintain a workplace free of discrimination and harassment based on any applicable legally protected status. We also expect that all workforce members will maintain a positive workplace free from any unacceptable conduct which creates an intimidating, hostile, or offensive work environment. \n Requsition ID:  226882  \n Company:  Providence Jobs  \n Job Category:  Development/Engineering  \n Job Function:  Information Technology  \n Job Schedule:  Full time  \n Job Shift:  Day  \n Career Track:  Leadership  \n Department:  4011 SS IS HI DP 3  \n Address:  WA Renton 1801 Lind Ave SW  \n Work Location:  Providence Valley Office Park-Renton  \n Pay Range:  $79.20 - $131.66  \n The amounts listed are the base pay range; additional compensation may be available for this role, such as shift differentials, standby/on-call, overtime, premiums, extra shift incentives, or bonus opportunities.  \n Check out our benefits page for more information about our Benefits and Rewards. \n Providence is proud to be an Equal Opportunity Employer. Providence does not discriminate on the basis of race, color, gender, disability, veteran, military status, religion, age, creed, national origin, sexual identity or expression, sexual orientation, marital status, genetic information, or any other basis prohibited by local, state, or federal law.",
        "cleaned_desc": " 8 years Leadership experience leading teams in a complex and fast-paced moving environment. \n Experience in cloud computing and data warehousing, Linux, Hadoop, Spark, and other NoSQL platforms. \n Strong experience working with both the product and technical sides of issues. \n Practical solutions development experience in a data-centric domain. \n Strong experience in managing and coaching a team of technical resources. \n \n Preferred Qualifications: \n ",
        "techs": [
            "cloud computing",
            "data warehousing",
            "linux",
            "hadoop",
            "spark",
            "nosql platforms"
        ],
        "cleaned_techs": [
            "cloud computing",
            "data warehousing",
            "linux",
            "hadoop",
            "spark",
            "nosql"
        ]
    },
    "3616a8258d4091d2": {
        "terms": [
            "data science"
        ],
        "salary_min": 94.5,
        "salary_max": 94.5,
        "title": "Sr. Cogito Developer REMOTE",
        "company": "Fourans LLC",
        "desc": "Job Summary: \n Position is fully remote, with the possibility of extension. Position is contract only at this time, but could become temp to perm if needs align. \n Duties: \n Top skillsets sought: Epic Cogito Fundamentals Certification, Epic Reporting Tools Administration Certification, Epic COGSQL Certification, Epic Data Model (Revenue Cycle, Access, or Clinical) Certification, SlicerDicer Custom Build Badge Certification, Radar SQL Metrics Certification \n The Senior Cogito Developer will join the Cogito Product team within the Data and Analytics team in the Center for Healthcare Quality and Analytics, and will be responsible for empowering users with Epic-based data across the institution, providing a unique blend of clinical, business, technical, and analytical expertise. The Cogito Product team oversees the development and utilization of Epic reporting tools throughout the enterprise to drive strategic initiatives, improve safety & quality of care, and streamline operations. The team combines business knowledge with data and technology to empower decision makers and believes that user-friendly, self-service, embedded analytics products can improve patient outcomes, optimize processes, and reduce costs. We believe in providing actionable insights which drive real, measurable, impact! The team is looking for creative problem solvers who are excited about joining a collaborative team to utilize data to transform into a data-driven organization; one that practices data-driven decision making and utilizes data to improve the experience of our patients, families, and staff. \n The Senior Cogito Developer is passionate about healthcare delivery in a patient care setting. A successful candidate is articulate, analytical, and a team player who understands the power of data storytelling to drive change. The developer enjoys coordinating with interdisciplinary teams to create solutions for improving operational and clinical decision making. The developer learns quickly, works independently, and is relentless in overcoming technical, process, and organizational obstacles. \n The Senior Cogito Developer will lead high-profile strategic projects and will be a reliable expert in translating clinical and business requirements into meaningful analysis within the Epic Cogito suite of tools. When necessary, the developer will appropriately apply data science techniques and other advanced analytics to solve problems as we expand into cognitive computing. The individual will need to build relationships with key stakeholders, be an expert in multiple Epic data sources, and implement sustainable solutions. The individual should bring project management experience and share best practices with the team. The analyst must be comfortable with mentorship and partnering with the Cogito Product and other teams within the Data and Analytics group. \n Job Responsibilities: \n 1.Individual Contributor \n \u2022Guides clinical teams and business stakeholders on large scope projects: gathering requirements, developing metrics, retrieving data, ensuring validity of results, and building out the appropriate Epic tool for the end-user. \n \u2022Proposes and creates innovative and appropriate data solutions (dashboards, reports, etc) for the measurement of processes and outcomes \n \u2022Adept at learning new information systems and how the data generated contributes to the data development lifecycle \n \u2022Advises on new SlicerDicer data models, testing frameworks, and documentation and build practices \n \u2022Works with Cogito Product Team to periodically upgrade the Epic system \n \u2022Demonstrates excellent data storytelling skills through outstanding presentation and communication to share findings in an understandable and actionable manner tailored to audience and customer's needs \n 2.Project Management \n \u2022Responsible for the coordination and completion of assigned projects, including project definition, assignment of task responsibilities, setting deadlines, and all other aspects of project management. \n \u2022Independently identifies and works to remediate project obstacles \n 3.Leadership \n \u2022Identifies, defines, and implements new data-driven strategies and processes for the organization. \n \u2022Communicates work plans, progress, findings, and interpretations effectively with a continual focus on educating and developing analytic capability of business customers and the organization overall. \n \u2022Trains and mentors team members \n \u2022Develops a \u201ctrusted advisor\u201d reputation through expertise in data and the mentoring of others in the use of the Epic Cogito suite of tools \n Skills: \n Required \n BACK END DEVELOPER \n Additional Technical Requirements \n \u2022Experience with SQL \n \u2022Knowledge of relational database structures \n \u2022Experience in project management \n Required Education: \n Bachelor's Degree in Health Science, Computer Science, Math, Engineering, Business, or related quantitative fields. \n Preferred Education: \n Master\u2019s degree \n Required Experience: \n Five (5) years of experience in analytics / business intelligence within a healthcare system using the Epic Systems electronic health record. \n Preferred Experience : \u2022Eight (8) years of experience in analytics / business intelligence \u2022Experience with data visualization tools preferred (Qlik, Tableau, Power BI, etc) \u2022Experience with Epic\u2019s Cogito product suite including SlicerDicer, Custom SQL Metrics, Crystal Reports, Radar, Reporting Workbench, CogitoSQL Templates \u2022Experience working as a data analyst within a healthcare setting \u2022Experience with clinical, access, and/or revenue Epic applications \n Required Licenses, Certifications, Registrations: Epic Cogito Fundamentals Epic Cogito Tools Administration \n Preferred Licenses/certificates/registrations:  Certification in at least one of the following Data Models: \u2022Clinical Data Model \u2022Revenue Data Model \u2022Access Data Model Certification in at least one of the following other Cogito tools: \u2022SlicerDicer \u2022CogitoSQL Templates \u2022Radar SQL Metrics \u2022Implementing Cognitive Computing \n Languages: \n English (Speak, Read, Write) \n Job Type: Contract \n Pay: $94.50 per hour \n Expected hours: 40 per week \n Schedule: \n \n Monday to Friday \n \n Education: \n \n Bachelor's (Required) \n \n Experience: \n \n Epic Systems electronic health record: 5 years (Required) \n Back-end development: 2 years (Required) \n SQL: 2 years (Required) \n relational database structures: 2 years (Required) \n Project management: 1 year (Required) \n Data analyst within a healthcare setting: 1 year (Required) \n Epic Cogito suite: 2 years (Required) \n \n License/Certification: \n \n Epic Cogito Fundamentals (Required) \n Epic Cogito Tools Administration (Required) \n Data Models certification (Required) \n \n Work Location: Remote",
        "cleaned_desc": "Job Summary: \n Position is fully remote, with the possibility of extension. Position is contract only at this time, but could become temp to perm if needs align. \n Duties: \n Top skillsets sought: Epic Cogito Fundamentals Certification, Epic Reporting Tools Administration Certification, Epic COGSQL Certification, Epic Data Model (Revenue Cycle, Access, or Clinical) Certification, SlicerDicer Custom Build Badge Certification, Radar SQL Metrics Certification \n The Senior Cogito Developer will join the Cogito Product team within the Data and Analytics team in the Center for Healthcare Quality and Analytics, and will be responsible for empowering users with Epic-based data across the institution, providing a unique blend of clinical, business, technical, and analytical expertise. The Cogito Product team oversees the development and utilization of Epic reporting tools throughout the enterprise to drive strategic initiatives, improve safety & quality of care, and streamline operations. The team combines business knowledge with data and technology to empower decision makers and believes that user-friendly, self-service, embedded analytics products can improve patient outcomes, optimize processes, and reduce costs. We believe in providing actionable insights which drive real, measurable, impact! The team is looking for creative problem solvers who are excited about joining a collaborative team to utilize data to transform into a data-driven organization; one that practices data-driven decision making and utilizes data to improve the experience of our patients, families, and staff. \n The Senior Cogito Developer is passionate about healthcare delivery in a patient care setting. A successful candidate is articulate, analytical, and a team player who understands the power of data storytelling to drive change. The developer enjoys coordinating with interdisciplinary teams to create solutions for improving operational and clinical decision making. The developer learns quickly, works independently, and is relentless in overcoming technical, process, and organizational obstacles. \n The Senior Cogito Developer will lead high-profile strategic projects and will be a reliable expert in translating clinical and business requirements into meaningful analysis within the Epic Cogito suite of tools. When necessary, the developer will appropriately apply data science techniques and other advanced analytics to solve problems as we expand into cognitive computing. The individual will need to build relationships with key stakeholders, be an expert in multiple Epic data sources, and implement sustainable solutions. The individual should bring project management experience and share best practices with the team. The analyst must be comfortable with mentorship and partnering with the Cogito Product and other teams within the Data and Analytics group. \n Job Responsibilities: \n 1.Individual Contributor \n \u2022Guides clinical teams and business stakeholders on large scope projects: gathering requirements, developing metrics, retrieving data, ensuring validity of results, and building out the appropriate Epic tool for the end-user. \n \u2022Proposes and creates innovative and appropriate data solutions (dashboards, reports, etc) for the measurement of processes and outcomes \n \u2022Adept at learning new information systems and how the data generated contributes to the data development lifecycle \n \u2022Advises on new SlicerDicer data models, testing frameworks, and documentation and build practices   \u2022Works with Cogito Product Team to periodically upgrade the Epic system \n \u2022Demonstrates excellent data storytelling skills through outstanding presentation and communication to share findings in an understandable and actionable manner tailored to audience and customer's needs \n 2.Project Management \n \u2022Responsible for the coordination and completion of assigned projects, including project definition, assignment of task responsibilities, setting deadlines, and all other aspects of project management. \n \u2022Independently identifies and works to remediate project obstacles \n 3.Leadership \n \u2022Identifies, defines, and implements new data-driven strategies and processes for the organization. \n \u2022Communicates work plans, progress, findings, and interpretations effectively with a continual focus on educating and developing analytic capability of business customers and the organization overall. \n \u2022Trains and mentors team members \n \u2022Develops a \u201ctrusted advisor\u201d reputation through expertise in data and the mentoring of others in the use of the Epic Cogito suite of tools \n Skills: \n Required \n BACK END DEVELOPER   Additional Technical Requirements \n \u2022Experience with SQL \n \u2022Knowledge of relational database structures \n \u2022Experience in project management \n Required Education: \n Bachelor's Degree in Health Science, Computer Science, Math, Engineering, Business, or related quantitative fields. \n Preferred Education: \n Master\u2019s degree \n Required Experience: \n Five (5) years of experience in analytics / business intelligence within a healthcare system using the Epic Systems electronic health record. \n Preferred Experience : \u2022Eight (8) years of experience in analytics / business intelligence \u2022Experience with data visualization tools preferred (Qlik, Tableau, Power BI, etc) \u2022Experience with Epic\u2019s Cogito product suite including SlicerDicer, Custom SQL Metrics, Crystal Reports, Radar, Reporting Workbench, CogitoSQL Templates \u2022Experience working as a data analyst within a healthcare setting \u2022Experience with clinical, access, and/or revenue Epic applications \n Required Licenses, Certifications, Registrations: Epic Cogito Fundamentals Epic Cogito Tools Administration \n Preferred Licenses/certificates/registrations:  Certification in at least one of the following Data Models: \u2022Clinical Data Model \u2022Revenue Data Model \u2022Access Data Model Certification in at least one of the following other Cogito tools: \u2022SlicerDicer \u2022CogitoSQL Templates \u2022Radar SQL Metrics \u2022Implementing Cognitive Computing ",
        "techs": [
            "epic cogito fundamentals certification",
            "epic reporting tools administration certification",
            "epic cogsql certification",
            "epic data model (revenue cycle",
            "access",
            "or clinical) certification",
            "slicerdicer custom build badge certification",
            "radar sql metrics certification",
            "sql",
            "qlik",
            "tableau",
            "power bi",
            "crystal reports",
            "reporting workbench",
            "cogitosql templates",
            "slicerdicer",
            "implementing cognitive computing"
        ],
        "cleaned_techs": [
            "epic cogito fundamentals certification",
            "epic reporting tools administration certification",
            "epic cogsql certification",
            "epic data model (revenue cycle",
            "access",
            "or clinical) certification",
            "slicerdicer custom build badge certification",
            "radar sql metrics certification",
            "sql",
            "qlik",
            "tableau",
            "powerbi",
            "crystal reports",
            "reporting workbench",
            "cogitosql templates",
            "slicerdicer",
            "implementing cognitive computing"
        ]
    },
    "4cf5d93af05f4317": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 42.0,
        "salary_max": 45.0,
        "title": "Data Analyst - Mid Level (3-5 yrs.)",
        "company": "The Judge Group",
        "desc": "Our client is currently seeking a Data Analyst\n  \n  Job Title: Data Analyst \n Location:  Fully Remote \n Contract:12+ Months (Contract to extend) \n \n \n Job Description:  \n Responsibilities: \n \n \n The client Enterprise Architecture (EA) team is looking for a talented and driven Data Analyst to join the Technical Debt Management System (TDMS) team building innovative and scalable technology solutions for technical debt integration, reporting, and remediation.  \n The TDMS team has created an ecosystem to define, measure, and monitor the risk of Technical Debt to ensure alignment with risk appetites through proactive enterprise visibility, allowing for efficient prioritization of remediation efforts.  \n We are looking for a Data Analyst to support the creation and maintenance of enterprise data assets, reporting, and data analytics for decision-making, regulatory reporting, and continuous process improvement.  \n As a member of this team, you will be responsible for analyzing, defining, and maintaining enterprise data by working with partners to assess data quality of source systems to meet the needs of client Business and IT.  \n Strong written and verbal communication skills are essential as you will be collaborating with a team of talented technologists and SMEs who bring energy, focus and fresh ideas that support our mission to provide value by seeing the world ?Through Clients' Eyes.? \n \n \n \n What You Are Good At  \n \n \n Establishing relationships with stakeholders to ensure alignment on data definitions and usage.  \n Developing data quality test plans based on previous data quality assessments and defined business rules.  \n Writing complex SQL queries, preparing data for analysis, and evaluating the results against the test plans.  \n Performing data analysis to assesses the quality and reliability of data relationships across source systems.  \n Developing and executing data quality improvement plans through various implementation options, including source system updates, normalization procedures, and mapping rules. \n \n \n \n What You Have  \n \n \n 5+ years of experience and a bachelor?s degree or equivalent in a STEM field such as Computer Science, Statistics / Mathematics or Engineering, Business Information Systems, or specialized post-secondary training in advanced data analytics, data science, or statistics.  \n Strong SQL skills gained through hands on experience with relational databases, such as Microsoft SQL Server, including experience writing complex SQL to identify data quality issues.  \n Being self-motivated who partners well with others to coordinate within and across IT as needed.  \n Prior experience with Flexera Technopedia, including the concepts of vendor support cycles, and Planview Enterprise Architecture is highly desired.  \n Understanding of Atlassian Jira and Confluence for Agile project management is beneficial.",
        "cleaned_desc": " \n \n What You Have  \n \n \n 5+ years of experience and a bachelor?s degree or equivalent in a STEM field such as Computer Science, Statistics / Mathematics or Engineering, Business Information Systems, or specialized post-secondary training in advanced data analytics, data science, or statistics.  \n Strong SQL skills gained through hands on experience with relational databases, such as Microsoft SQL Server, including experience writing complex SQL to identify data quality issues.  ",
        "techs": [
            "microsoft sql server"
        ],
        "cleaned_techs": [
            "microsoft sql server"
        ]
    },
    "332071d88d0146cd": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 5747.0,
        "salary_max": 6304.0,
        "title": "DATA EXTRACTION ANALYST, HEPATOLOGY",
        "company": "University of Washington",
        "desc": "Data Extraction Analyst, Hepatology \n \n \n \n \n \n \n \n \n \n        Req #:\n        \n \n        227891\n        \n \n \n \n \n        Department:\n        \n \n        INSTITUTE FOR HEALTH METRICS & EVALUATIONS (IHME)\n        \n \n \n \n \n        Job Location:\n        \n \n        Seattle - Other \n        \n \n \n \n \n        Job Location Detail:\n        \n \n        Office is located in Seattle; position is eligible to work fully remote within the U.S. (excluding U.S. territories)\n        \n \n \n \n \n        Posting Date:\n        \n \n        10/17/2023\n        \n \n \n \n \n        Closing Info:\n        \n \n        Closes On 10/31/2023\n        \n \n \n \n \n        Salary:\n        \n \n        $5,747 - $6,304 per month\n        \n \n \n \n \n        Other Compensation:\n        \n \n \n \n \n \n        Union Position:\n        \n \n        Yes\n        \n \n \n \n \n        Shift:\n        \n \n        First Shift \n        \n \n \n \n \n        Benefits:\n        \n \n        As a UW employee, you will enjoy generous benefits and work/life programs. \n        \n \n \n \n \n \n \n \n \n \n    As a UW employee, you have a unique opportunity to change lives on our campuses, in our state and around the world. UW employees offer their boundless energy, creative problem-solving skills and dedication to build stronger minds and a healthier world. \n     \n  UW faculty and staff also enjoy outstanding benefits, professional growth opportunities and unique resources in an environment noted for diversity, intellectual excitement, artistic pursuits and natural beauty. \n     \n  The Institute for Health Metrics and Evaluation (IHME) is an independent research center at the University of Washington. Its mission is to deliver to the world timely, relevant, and scientifically valid evidence to improve health policy and practice. IHME carries out its mission through a range of projects within different research areas including the Global Burden of Diseases, Injuries, and Risk Factors; Future Health Scenarios; Cost Effectiveness and Efficiency; Resource Tracking; and Impact Evaluations. Our vision is to provide policymakers, donors, and researchers with the highest-quality quantitative evidence base so all people live long lives in full health. \n     \n  IHME is committed to providing the evidence base necessary to help solve the world\u2019s most important health problems. This requires creativity and innovation, which are cultivated by an inclusive, diverse, and equitable environment that respects and appreciates differences, embraces collaboration, and invites the voices of all IHME team members. \n     \n \n IHME has an outstanding opportunity for a Data Extraction Analyst to join the Reproductive, Genitourinary, and Digestive disease estimation (RGUD) team within the Global Burden of Disease (GBD) study. \n \n \n POSITION PURPOSE \n  The Data Extraction Analyst will provide support to key research projects through data extraction and formatting, and providing inputs used in modeling, papers and presentations. The research areas include, but are not limited to, hepatitis and cirrhosis, gynecology, sexually transmitted infections, upper and lower digestive diseases, and infertility. This is an entry-level position for those who are interested in entering the field of global health or clinical medicine. The ideal candidate is a detailed-oriented, quantitative-minded individual with a passion for building their understanding of epidemiologic study design and the burden of major diseases within the RGUD research areas. \n     \n  The Data Extraction Analyst is expected to support the full scope of work across the research team\u2019s portfolio, while developing special expertise in viral hepatitis and related diseases. Consultation with other researchers and staff will be required. To create the array of indicators required, this position provides guidance on the extraction of all available relevant quantitative data from surveys, censuses, literature, and administrative records into central databases. This position will collate, clean, and extract data from survey, literature, vital registration, and other sources that have been identified. By doing so they will catalog a library of data that will add to the foundation of the Institute. Relevant data include those on mortality, epidemiology, and a range of diseases, injuries, and determinants. \n     \n  This position will work with dynamic teams of researchers and staff at all levels and will work alongside other research staff on complementary projects requiring a foundational knowledge of IHME\u2019s work, as well as core technical skills and collective problem-solving. The candidate must develop a strong command of a variety of research needs and analytic functions. The Data Extraction Analyst must be able to anticipate the needs of the research team. Overall, the Data Extraction Analyst will be a critical member of an agile, dynamic team. This position is contingent on funding availability. \n     \n \n DUTIES AND RESPONSIBILITIES \n  Research command \n     \n Become familiar with substantive areas of the RGUD disease portfolio to understand the dimensions and uses of health data and the analytic underpinnings of different research streams.    \n Work directly with researchers to trace back the source of data used in models and results, understand the context of the data, and ensure that they are relevant to the analyses themselves.     Data management and quality assessment    \n Support researchers conducting systematic reviews for viral hepatitis and related diseases.    \n Extract, format, and transform data from multiple sources according to set protocols in consultation with researchers to best meet their needs. Sources include literature, surveys, censuses, administrative records, vital registration systems, and disease registries, among others.    \n Develop and use protocols to identify problems with datasets and routine extraction processes, rectify issues, and systematize processes for future work.    \n Maintain, update, and interact with databases containing health data from multiple sources.    \n Perform quality assurance and routine diagnostics on data and databases.    \n Assess and contribute to decision making about the definitions of fields for extraction and the organization and storage of input data.    \n Perform literature reviews and other forms of data seeking.    \n Archive, catalog, and annotate datasets according to Institute standards to build a common library of materials for use by a wide set of researchers.    \n Document extraction processes to ensure consistency in extraction across research teams.    \n Improve extraction processes to save time or simplify the extraction process and/or improve the quality of extractions.     Publications, presentations, and data requests    \n Create text, tables, figures, and charts for presentations and publications.    \n Provide referencing and other support for publications and presentations.    \n Execute queries on databases to respond to the needs of senior researchers and external requests from collaborators, media, policymakers, donors, and other stakeholders.     General    \n Communicate clearly and effectively while contributing as a member of the Institute.    \n Work closely with other team members to assist with relevant tasks, facilitate learning new skills, and to help resolve emerging problems on different projects.    \n Attend relevant meetings, adhere to deadlines, and participate as a vital member to collectively advance team-level objectives.    \n Serve as a resource to others in explaining approaches to data management and extraction.    \n Participate in overall community of the Institute, carrying out duties as may be required for team members.      MINIMUM REQUIREMENTS     \n Bachelor\u2019s degree in sciences, global health, public health, or related field plus two years\u2019 related experience, or equivalent combination of education and experience    \n Demonstrated competence with analytic tasks. Demonstrated familiarity and ability to agilely assess, transform, and work with quantitative data from a range of sources.    \n Strong quantitative aptitude, desire to learn new skills, and ability to interpret complex analytic information.    \n Strong sense of focus and attention to detail.    \n Ability to learn new information quickly and understand complex information in a systematic way.    \n Interest in global health and/or population health research.    \n Demonstrated organizational skills, self-motivation, flexibility, and the ability to work and thrive in a fast-paced, energetic, highly creative, entrepreneurial environment.    \n Strong communication skills necessary.    \n A commitment to working to alongside others at IHME to illuminate the health impacts of systemic racism and to work within IHME to make our organization more diverse and inclusive. See IHME\u2019s DEI statement here: http://www.healthdata.org/get-involved/careers/dei      DESIRED QUALIFICATIONS     \n Experience analyzing and/or manipulating spatial data.    \n Coding experience including, but not limited to, use of R, Python, and/or SQL.      CONDITIONS OF EMPLOYMENT     \n Weekend and evening work is sometimes required.    \n This position is open to anyone authorized to work in the US. The UW is not able to sponsor visas for staff positions.    \n Office is located in Seattle, Washington. This position is eligible to work fully remote in the US; work schedule required to overlap 5 hours of IHME office hours, between 8 a.m. and 5 p.m. Pacific Time.      Application Process:  The application process may include completion of a variety of online assessments to obtain additional information that will be used in the evaluation process. These assessments may include Work Authorization, Cover Letter and/or others. Any assessments that you need to complete will appear on your screen as soon as you select \u201cApply to this position\u201d. Once you begin an assessment, it must be completed at that time; if you do not complete the assessment you will be prompted to do so the next time you access your \u201cMy Jobs\u201d page. If you select to take it later, it will appear on your \"My Jobs\" page to take when you are ready. Please note that your application will not be reviewed, and you will not be considered for this position until all required assessments have been completed.   \n \n \n \n \n \n \n Committed to attracting and retaining a diverse staff, the University of Washington will honor your experiences, perspectives and unique identity. Together, our community strives to create and maintain working and learning environments that are inclusive, equitable and welcoming. \n \n \n The University of Washington is an affirmative action and equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, gender expression, national origin, age, protected veteran or disabled status, or genetic information. \n To request disability accommodation in the application process, contact the Disability Services Office at 206-543-6450 or dso@uw.edu. \n \n \n Applicants considered for this position will be required to disclose if they are the subject of any substantiated findings or current investigations related to sexual misconduct at their current employment and past employment. Disclosure is required under Washington state law.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "14c7a2ec2451930b": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 65000.0,
        "salary_max": 95000.0,
        "title": "Salesforce Data Analyst",
        "company": "Fisker Inc",
        "desc": "About Fisker Inc.\n  \n \n \n   California-based Fisker Inc. is revolutionizing the automotive industry by developing the most emotionally desirable and eco-friendly electric vehicles on Earth. Passionately driven by a vision of a clean future for all, the company is on a mission to become the No. 1 e-mobility service provider with the world\u2019s most sustainable vehicles. To learn more, visit \n   \n   www.FiskerInc.com\n    \u2013 and enjoy exclusive content across Fisker\u2019s social media channels: \n   \n   Facebook\n   , \n   \n   Instagram\n   , \n   \n   Twitter\n   , \n   \n   YouTube\n    and \n   \n   LinkedIn\n   . Download the revolutionary new Fisker mobile app from the \n   \n   App Store\n    or \n   \n   Google Play\n    store.\n  \n \n \n   Role Overview\n  \n \n   As a Salesforce Architect specializing in Lists, Reports, and Dashboards, you will be a key player in our organization's data-driven decision-making process. Reporting directly to the CRM Campaign Manager, your primary responsibility will be designing, developing, and maintaining Salesforce campaign lists, reports, and dashboards. Your expertise in Salesforce architecture and data visualization will empower our teams with the insights they need to drive business success.\n  \n \n \n   Duties and Responsibilities\n  \n \n \n \n     Collaborate closely with stakeholders, including business analysts, to understand their data requirements and translate them into effective Salesforce lists, reports, and dashboards.\n    \n \n \n     Build various Salesforce Marketing Cloud automations via SQL to combine several customer data points into one campaign list for highly personalized communications.\n    \n \n \n     Lead the design and development of complex lists, reports, and interactive dashboards to provide actionable insights for different departments within the organization.\n    \n \n \n     Ensure data accuracy and integrity by implementing best practices in data modeling, validation rules, and data governance within the Salesforce platform.\n    \n \n \n     Utilize your deep knowledge of Salesforce reporting tools and features to create dynamic and user-friendly reports and dashboards that meet end-users' needs.\n    \n \n \n     Stay updated on the latest Salesforce enhancements and industry best practices related to data visualization and reporting, and apply this knowledge to continuously improve our reporting capabilities.\n    \n \n \n     Collaborate with Salesforce Developers and Marketers to ensure that data extraction, transformation, and loading processes align with reporting requirements.\n    \n \n \n     Assist in training and educating end-users on how to effectively use Salesforce lists, reports, and dashboards to drive informed decision-making.\n    \n \n \n \n   Minimum Qualifications\n  \n \n Possess 5+ years of Digital Marketing experience, accentuated by a specialization in Salesforce Marketing Cloud, Sales Cloud, & Commerce Cloud. \n Salesforce certifications, such as Salesforce Data Architect or Sharing and Visibility Architect. \n Bachelor\u2019s Degree or higher in Marketing, Communications, Computer Science, or a related field and/or equivalent work experience. \n \n \n \n   Expected Salary Range: $65000- 95000per year.\n  \n \n \n   Additional Compensation: Salary is one component of total compensation, which may include bonuses, equity awards as applicable, and benefits. Employee eligibility to participate in equity programs is subject to the rules governing such programs.\n  \n \n \n   Benefits: Fisker offers a comprehensive benefits package, including medical, dental, vision, and disability insurance coverage for eligible full-time employees, as well as their spouse or domestic partner and children up to age 26. Coverage begins on the first day of employment, with Fisker covering a significant portion of the premiums for employees.\n  \n \n \n   The salary offered may vary based on several individual factors, including location, job-specific knowledge, education/training, certifications, key skills, experience, internal peer equity, and business considerations. Fisker aims to provide a competitive salary within the listed range, taking into account the diverse factors mentioned above.\n  \n \n \n   Fisker is an Equal Opportunity Employer. Employment decisions at Fisker are based on merit, qualifications, and abilities. Fisker does not discriminate in employment opportunities or practices based on race, color, religion, gender, national origin/ethnicity, veteran status, disability status, age, sexual orientation, gender identity, marital status, mental or physical disability, or any other legally protected status.\n  \n \n \n   #LI-Remote\n  \n \n   #LI-LS1",
        "cleaned_desc": " \n \n     Collaborate closely with stakeholders, including business analysts, to understand their data requirements and translate them into effective Salesforce lists, reports, and dashboards.\n    \n \n \n     Build various Salesforce Marketing Cloud automations via SQL to combine several customer data points into one campaign list for highly personalized communications.\n    \n \n \n     Lead the design and development of complex lists, reports, and interactive dashboards to provide actionable insights for different departments within the organization.\n    \n \n \n     Ensure data accuracy and integrity by implementing best practices in data modeling, validation rules, and data governance within the Salesforce platform.\n    \n \n \n     Utilize your deep knowledge of Salesforce reporting tools and features to create dynamic and user-friendly reports and dashboards that meet end-users' needs.\n    \n ",
        "techs": [
            "salesforce lists",
            "reports",
            "dashboards",
            "salesforce marketing cloud",
            "sql",
            "data modeling",
            "validation rules",
            "data governance",
            "salesforce reporting tools",
            "features"
        ],
        "cleaned_techs": [
            "salesforce lists",
            "reports",
            "dashboards",
            "salesforce marketing cloud",
            "sql",
            "validation rules",
            "data governance",
            "salesforce reporting tools",
            "features"
        ]
    },
    "849f7df4e28f999e": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 25.0,
        "salary_max": 25.0,
        "title": "Hospital Data Research Assistant",
        "company": "Lown Institute",
        "desc": "Hospital Data Research Assistant \n Do you believe we need deep, structural changes in health care and want to devote your knowledge and passion to creating a better system? The Lown Institute seeks an energetic and thoughtful individual to join our team as we seek to catalyze transformation in the US health system. The Healthcare Data Scientist should have a passion for data, for improving the healthcare system, and for creating solutions that have impact. The successful candidate will spend time working both independently and as part of a highly collaborative team focused on specific deadlines. While this is an individual contributor role, the ideal candidate should be able to collaborate with others to solve complex problems. \n About the Lown Institute: Founded in 1973 by Nobel Peace Prize winner Bernard Lown, MD, the Lown Institute is a think tank that believes a radically better system of health is possible. We are known for: \n \u25cf The Lown Hospitals Index, the first ranking to assess the social responsibility of hospitals by applying measures never used before, like racial inclusivity and pay equity. \n \u25cf The Shkreli Awards, which \u201chonor\u201d the most egregious examples of profiteering and dysfunction in health care each year. \n \u25cf The Bernard Lown Award for Social Responsibility, given to a clinician who emulates the courage and humanitarian spirit of Dr. Bernard Lown. \n \u25cf Leadership in the field of low-value care, including groundbreaking research on hospital overuse and overmedication among older adults. \n About the Position \n The Lown Institute is embarking on an exciting project focusing on the development of a database housing data on hospitals\u2019 financial assistance policies. This is an opportunity for a detail-oriented, proactive individual to hone their data collection skills. The primary responsibility of the research assistant is to collect and verify hospital data regarding their financial assistance policies. The research assistant will be supervised by a member of our data science team leading the effort in building the database. This is a part-time position to run 18 months, or until the data collection process is complete, whichever is first. \n Required Qualifications \n \u25cf Undergraduate degree, preferably in information science, public health, or pre-med \u25cf Detail-oriented, proactive, excellent research skills, and good phone etiquette \n Core responsibilities and specific duties: \u25cf Collect data on hospital websites related to financial assistance policy \u25cf Enter data into existing database \u25cf Administer survey to confirm hospital data \u25cf Reach out to hospitals to confirm data through email and phone \n Compensation, Benefits, and Work Schedule: This is a part-time position at $25/hr, at 20 hours per week. \n To Apply: \n Please apply via Indeed. If you\u2019re excited to work with us but not sure if you fit the qualifications, please apply! We want to hear from you. \n The deadline to apply is October 31 or until the position is filled. Applications will be reviewed on a rolling basis. No phone calls please. We sincerely regret that we will not be able to respond to all applicants. \n As an organization working for a more equitable health system, we promote a diverse and inclusive working environment and value differences in identity and lived experience. \n We encourage applications from all qualified individuals without regard to race, color, religion, gender, sexual orientation, gender identity or expression, age, neurodiversity, national origin, marital status, citizenship, disability, veteran status, and record of arrest or conviction. The Lown Institute is an equal opportunity employer. \n Job Types: Contract, Part-time \n Pay: $25.00 per hour \n Expected hours: 20 per week \n Benefits: \n \n Flexible schedule \n Work from home \n \n Compensation package: \n \n 1099 contract \n Hourly pay \n \n Experience level: \n \n Under 1 year \n \n Schedule: \n \n Choose your own hours \n Monday to Friday \n \n Application Question(s): \n \n Why are you applying to this job -- what about the Lown Institute interests you? \n \n Education: \n \n Bachelor's (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "4e744d8371aeec65": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 0.0,
        "salary_max": 119318.86,
        "title": "Business Analyst",
        "company": "Genpact",
        "desc": "With a startup spirit and 90,000+ curious and courageous minds, we have the expertise to go deep with the world\u2019s biggest brands\u2014and we have fun doing it. Now, we\u2019re calling all you rule-breakers and risk-takers who see the world differently, and are bold enough to reinvent it. Come, transform with us. \n Transformation happens here! Come, be a part of our exciting journey! \n Are you the one we are looking for? \n We are looking for a Reporting Business Analyst to design, develop and implement reporting solutions involving data warehousing and reporting platform that will meet business needs and to support the Oracle ERP Cloud implementation. The Reporting Business Analyst\u2019s responsibilities include analyzing requirements and functional specifications, working closely with the BI Team Lead and developers and utilizing Oracle Fusion ERP Analytics and various Oracle ERP Cloud reporting tools to design efficient and executable solutions. The solution should provide roadmaps for the organization to transform from current reporting systems to future state system architecture. The solution should also consider data sources coming from multiple transactional systems. This person should also be able to regularly update the PMO and IT Leadership team as well as business counterparts on reporting development progress and deliverables. \n To be successful as a reporting business analyst, this person should be able to integrate any updated specifications and requirements into the systems requirements and clearly articulate to the developers as well as manage expectations from the business users. An outstanding business analyst should be able to explain complex problems to management in layman\u2019s terms. \n Business Analyst Responsibilities: \n \u00b7 Building a reporting and data warehousing strategy for all related information systems to meet the company\u2019s needs. \n \u00b7 Assessing the systems architecture currently in place and working with technical team to design a road map that leads to future state architecture, which includes solutions for interim transition period. \n \u00b7 Work closely with business users to turn business requirements into technical SPEC. \n \u00b7 Communicate effectively with development teams. \n \u00b7 Continually researching current and emerging technologies and proposing changes where needed. \n \u00b7 Manage stakeholders\u2019 expectation \n \u00b7 Assessing the business impact for prioritization \n \u00b7 Providing updates to stakeholders on product development processes, costs, and budgets. \n Business Analyst Requirements: \n \u00b7 Bachelor\u2019s degree in information technology, software engineering, computer science, or related field. \n \u00b7 Finance education/work experience strongly preferred \n \u00b7 Proven experience in reporting and data warehousing. \n \u00b7 At least 2 previous project involving Oracle ERP Cloud/Oracle Fusion ERP Analytics reporting solution design experience \n \u00b7 Knowledge of OTBI, Oracle ADW/FAW, FRS, BI Publisher a strong plus. \n \u00b7 Tableau Server integration implementation experience would be strongly preferred. \n \u00b7 Efficient communication skills. \n \u00b7 Strong organizational and leadership skills. \n Genpact is an Equal Opportunity Employer and considers applicants for all positions without regard to race, color, religion or belief, sex, age, national origin, citizenship status, marital status, military/veteran status, genetic information, sexual orientation, gender identity, physical or mental disability or any other characteristic protected by applicable laws. Genpact is committed to creating a dynamic work environment that values diversity and inclusion, respect and integrity, customer focus, and innovation. For more information, visitwww.genpact.com. Follow us on Twitter, Facebook, LinkedIn, and YouTube. \n Job Type: Full-time \n Salary: Up to $119,318.86 per year \n Benefits: \n \n Dental insurance \n Paid time off \n \n Schedule: \n \n 8 hour shift \n \n Work Location: Remote",
        "cleaned_desc": " Business Analyst Requirements: \n \u00b7 Bachelor\u2019s degree in information technology, software engineering, computer science, or related field. \n \u00b7 Finance education/work experience strongly preferred \n \u00b7 Proven experience in reporting and data warehousing. \n \u00b7 At least 2 previous project involving Oracle ERP Cloud/Oracle Fusion ERP Analytics reporting solution design experience \n \u00b7 Knowledge of OTBI, Oracle ADW/FAW, FRS, BI Publisher a strong plus. \n \u00b7 Tableau Server integration implementation experience would be strongly preferred. ",
        "techs": [
            "oracle erp cloud",
            "oracle fusion erp analytics",
            "otbi",
            "oracle adw/faw",
            "frs",
            "bi publisher",
            "tableau server"
        ],
        "cleaned_techs": [
            "oracle",
            "otbi",
            "frs",
            "bi publisher",
            "tableau server"
        ]
    },
    "1bf1b46bfda7e7d3": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 140000.0,
        "salary_max": 172000.0,
        "title": "Data Quality Analyst",
        "company": "Truveta",
        "desc": "Data Quality Analyst \n  Truveta is the world's first health provider led data platform with a vision of Saving Lives with Data. Our mission is to enable researchers to find cures faster, empower every clinician to be an expert, and help families make the most informed decisions about their care. Achieving Truveta' s ambitious vision requires an incredible team of talented and inspired people with a special combination of health, software and big data experience who share our company values. \n  Truveta was born in the Pacific Northwest, but we have employees who live across the country. Our team enjoys the flexibility of a hybrid model and working from anywhere. In person attendance is required for two weeks during the year for Truveta Planning Weeks. \n  For overall team productivity, we optimize meeting hours in the pacific time zone. We avoid scheduling recurring meetings that start after 3pm PT, however, ad hoc meetings occur between 8am-6pm Pacific time. \n  Who We Need \n  Truveta is rapidly building a talented and diverse team to tackle complex health and technical challenges. Beyond core capabilities, we are seeking problem solvers, passionate and collaborative teammates, and those willing to roll up their sleeves while making a difference. If you are interested in the opportunity to pursue purposeful work, join a mission-driven team, and build a rewarding career while having fun, Truveta may be the perfect fit for you. \n \n  This Opportunity \n \n \n   Visualizing and communicating data effectively is a critical task for any large dataset. Truveta is building a healthcare research platform suitable for medical research and advancing health knowledge. As a Data Quality Analyst, you will help define how people understand and make sense of the data in the Truveta Platform.\n  \n \n \n \n  Responsibilities \n \n \n Collaborate with engineering stakeholders to define metrics and measures that appropriately capture the behavior of our data across the pipeline. \n Design and implement dashboards and reports that enable a wide range of stakeholders, grounded in a consistent source of truth, from executives to front line engineers. \n Work with engineers, product management, clinical informaticists and other teammates to understand and refine questions and turn data into meaningful information. \n Partner with engineering to develop data models and relational schemas for telemetry and observability data that are efficient and appropriate. \n \n \n Key Qualifications \n \n \n Bachelor's degree in information systems, Computer Science, Data Analytics, or similar field \n 3+ years of experience creating reports and dashboards with BI tools (Power BI, Tableau, Looker, etc.) \n 3+ years of experience using SQL; Python is a plus. \n Proven track record of collaboration across stakeholder teams to drive data-informed solutioning and decision making. \n Subject matter expertise in Electronic Health Record or other Real World Data sources, and experience with clinical information systems such as Epic, Cerner, Allscripts, etc. is a strong plus. \n Knowledge and experience with relational databases \n Excellent written and verbal communication skills \n Start-up mindset that allows you to shift gears quickly. \n \n \n Why Truveta? \n \n  Be a part of building something special. Now is the perfect time to join Truveta. We have strong, established leadership with decades of success. We are well-funded. We are building a culture that prioritizes people and their passions across personal, professional and everything in between. Join us as we build an amazing company together. \n  We Offer: \n \n Interesting and meaningful work for every career stage \n Great benefits package \n Comprehensive benefits with strong medical, dental and vision insurance plans \n 401K plan \n Professional development & training opportunities for continuous learning \n Work/life autonomy via flexible work hours and flexible paid time off \n Generous parental leave \n Regular team activities (virtual and in-person as soon as we are able) \n The base pay for this position is $140,000 to $172,000. The pay range reflects the minimum and maximum target. Pay is based on several factors including location and may vary depending on job-related knowledge, skills, and experience. Certain roles are eligible for additional compensation such as incentive pay and stock options. \n \n If you are based in California, we encourage you to read this important information for California residents  linked   here. \n  Truveta is committed to creating a diverse, inclusive, and empowering workplace. We believe that having employees, interns, and contractors with diverse backgrounds enables Truveta to better meet our mission and serve patients and health communities around the world. We recognize that opportunities in technology historically excluded and continue to disproportionately exclude Black and Indigenous people, people of color, people from working class backgrounds, people with disabilities, and LGBTQIA+ people. We strongly encourage individuals with these identities to apply even if you don't meet all of the requirements.",
        "cleaned_desc": "   Visualizing and communicating data effectively is a critical task for any large dataset. Truveta is building a healthcare research platform suitable for medical research and advancing health knowledge. As a Data Quality Analyst, you will help define how people understand and make sense of the data in the Truveta Platform.\n  \n \n \n \n  Responsibilities \n \n \n Collaborate with engineering stakeholders to define metrics and measures that appropriately capture the behavior of our data across the pipeline. \n Design and implement dashboards and reports that enable a wide range of stakeholders, grounded in a consistent source of truth, from executives to front line engineers.   Work with engineers, product management, clinical informaticists and other teammates to understand and refine questions and turn data into meaningful information. \n Partner with engineering to develop data models and relational schemas for telemetry and observability data that are efficient and appropriate. \n \n \n Key Qualifications \n \n \n Bachelor's degree in information systems, Computer Science, Data Analytics, or similar field \n 3+ years of experience creating reports and dashboards with BI tools (Power BI, Tableau, Looker, etc.) \n 3+ years of experience using SQL; Python is a plus. ",
        "techs": [
            "bi tools (power bi",
            "tableau",
            "looker)",
            "sql",
            "python"
        ],
        "cleaned_techs": [
            "bi tools (power bi",
            "tableau",
            "looker)",
            "sql",
            "python"
        ]
    },
    "9d455150e2cf4cdd": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 110000.0,
        "salary_max": 115000.0,
        "title": "Data Analyst",
        "company": "Axonius",
        "desc": "As part of our rapid growth, we are looking for a Data Analyst to join our team. You'll be working cross functionally across the company to continue building out our BI stack, including our data warehouse (Snowflake) and Looker instance. As a true partner to internal teams, you'll design data models that enable self-service analytics across the company. In this role, you'll be a key contributor to building out the stable base that helps drive the continued rapid growth of the company. \n  In a typical week, you'll end up touching multiple projects, such as working with members of the BizOps team to analyze (and provide them with) data they need to make Axonius more efficient; adding data sources to Snowflake; refining data models to facilitate analysis of that data, and integrate it with other data sources; implementing data models using dbt and writing them into our Looker instance. \n  Responsibilities \n \n Build dashboards, analyze data, and provide actionable recommendations for teams across the company \n Lead cross-functional collaborations to answer business questions \n Identify data gaps and quality issues, and work with teams to rectify them \n Design data models for our data warehouse \n Transform raw data into the models using dbt \n Write LookML to empower self-service analytics across the company \n \n Requirements \n \n 3+ years of related experience \n Demonstrated experience building and maintaining data models \n Strong verbal and written communication skills \n Strong SQL skills \n Experience with BI tool(s), especially Looker \n Attention to detail: our warehouse must be the source of truth for data at Axonius \n \n Advantages \n \n Experience with Fivetran, Snowflake, dbt, git, and Looker \n Experience with Python/Pandas/Numpy \n Experience orchestrating data pipelines \n Background in statistical modeling \n \n \n \n  Axonius is committed to fair and equitable compensation packages. A candidate\u2019s salary will be based on qualifications and relevant experience. In addition to a competitive salary, our packages include stock options, attractive benefits, and an annual bonus \n \n  Annual Pay Range \n \n    $110,000\u2014$115,000 USD\n   \n \n \n  A little more about Axonius: \n  Axonius gives customers the confidence to control complexity by mitigating threats, navigating risk, automating response actions, and informing business-level strategy. With solutions for both cyber asset attack surface management (CAASM) and SaaS management, Axonius is deployed in minutes and integrates with hundreds of data sources to provide a comprehensive asset inventory, uncover gaps, and automatically validate and enforce policies. Cited as one of the fastest-growing cybersecurity startups, with accolades from CNBC, Forbes, and Fortune, Axonius covers millions of assets, including devices and cloud assets, user accounts, and SaaS applications, for customers around the world. \n  Headquartered in New York, New York, Axonius employs over 600 people worldwide. Axonius has been recognized with the Great Place to Work Certification\u2122 and was named to Dun's Best Start Up Companies to Work for Over 100 Employees. Most recently, Axonius was ranked #3 on the 2022 Deloitte Technology Fast 500 list as well as included on  Inc.  magazine's 2022 Best Workplaces list. Axonius has been cited as the fastest growing cybersecurity company in history by revenue. \n  At Axonius we support a diverse and inclusive workplace and believe in equal employment opportunity. We welcome people of different backgrounds, experiences, abilities and perspectives, regardless of race, color, ancestry, religion, age, sex, gender identity, national origin, sexual orientation, citizenship, marital status, disability, or Veteran status. \n  By submitting your application to us, you acknowledge that your personal data will be processed in accordance with our  Global Job Candidate Privacy Notice.",
        "cleaned_desc": "As part of our rapid growth, we are looking for a Data Analyst to join our team. You'll be working cross functionally across the company to continue building out our BI stack, including our data warehouse (Snowflake) and Looker instance. As a true partner to internal teams, you'll design data models that enable self-service analytics across the company. In this role, you'll be a key contributor to building out the stable base that helps drive the continued rapid growth of the company. \n  In a typical week, you'll end up touching multiple projects, such as working with members of the BizOps team to analyze (and provide them with) data they need to make Axonius more efficient; adding data sources to Snowflake; refining data models to facilitate analysis of that data, and integrate it with other data sources; implementing data models using dbt and writing them into our Looker instance. \n  Responsibilities \n \n Build dashboards, analyze data, and provide actionable recommendations for teams across the company \n Lead cross-functional collaborations to answer business questions \n Identify data gaps and quality issues, and work with teams to rectify them \n Design data models for our data warehouse   Transform raw data into the models using dbt \n Write LookML to empower self-service analytics across the company \n \n Requirements \n \n 3+ years of related experience \n Demonstrated experience building and maintaining data models \n Strong verbal and written communication skills   Strong SQL skills \n Experience with BI tool(s), especially Looker \n Attention to detail: our warehouse must be the source of truth for data at Axonius \n \n Advantages \n \n Experience with Fivetran, Snowflake, dbt, git, and Looker \n Experience with Python/Pandas/Numpy ",
        "techs": [
            "snowflake",
            "looker",
            "dbt",
            "fivetran",
            "git",
            "python",
            "pandas",
            "numpy"
        ],
        "cleaned_techs": [
            "snowflake",
            "looker",
            "dbt",
            "fivetran",
            "git",
            "python",
            "pandas",
            "numpy"
        ]
    },
    "ce617e9c5303b017": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 68397.33,
        "salary_max": 86606.25,
        "title": "Marketing Data Analyst",
        "company": "Outliant",
        "desc": "About us:  Outliant is a fully-remote, US-based, digital product development and startup consulting company, with a team of culturally diverse creators whose exceptional skills and talents help conceive seamless digital products. Our teams exhibit work-play energy that supports individual growth, as well as encourages the freedom of creativity and \u201cthinking outside the box.\u201d \n \n  Our Core Values:   Pursuit of Excellence:  We are extremely competitive, ambitious, and driven to be exceptional \u2013 as individuals, teams, and as an organization. There is no standard high enough and we will never settle. We aspire to attract, retain, and empower the very best people.   Startup Mentality:  Outliant began with 5 startup founders, and startup culture is deep in our DNA. It\u2019s a critical advantage that allows us to move faster, be more resourceful, and empower our team at all levels. We are in the early chapters of our journey.   World-Class Remote Collaboration:  Outliant is (and always has been) a 100% remote company \u2013 we have no offices and our teams are distributed around the world. Given the freedom and autonomy this provides, we require that our people excel in this remote structure. \n \n  About the role:  We\u2019re looking to hire a full-time remote Marketing Data Analyst. For this role, your primary focus will be playing a key role in transforming raw data into actionable insights, driving informed marketing decisions, optimizing campaigns, and enhancing overall business performance. \n  You\u2019ll have the opportunity to choose your hours and work and learn with a team of world-class engineers and designers, through a commitment to team collaboration, communication, and product quality. \n \n  Seniority Level:  Mid Level \n \n  Responsibilities: \n \n  Analyze complex data sets to identify trends, patterns, and insights that can be leveraged for marketing strategies. \n  Utilize statistical techniques and advanced analytical tools to interpret data and provide valuable insights into customer behavior, campaign effectiveness, and market trends. \n  Translate big data into actionable dashboards and data visualizations. \n  Design and interpret A/B and multivariate tests. \n  Collaborate with cross-functional teams to define data requirements, ensure data integrity, and establish best practices for data collection and analysis. \n  Design and interpret A/B testing methodologies and analyze results to optimize marketing campaigns, website performance, and customer experiences. \n  Provide actionable recommendations based on data analysis to enhance marketing strategies, improve customer engagement, and drive revenue growth. \n  Continuously monitor and evaluate marketing performance metrics, identifying areas for improvement and proposing solutions. \n  Stay current with industry trends, emerging technologies, and best practices in marketing analytics. \n  Collect and analyze complex data on the effectiveness of marketing initiatives \n  Forecast future marketing performance. \n \n \n  Requirements: \n \n  3+ years of proven experience as a Marketing Data Analyst or similar role, preferably in a digital marketing environment. \n  Proficiency in statistical analysis and marketing tools like Google Tag Manager and Segment. \n  Hands-on experience with marketing automation platforms, web analytics tools, and A/B testing platforms. \n  Exceptional analytical and problem-solving skills, with the ability to translate complex data into understandable insights. \n  Excellent communication skills, both written and verbal, with the ability to convey complex data findings to non-technical stakeholders. \n  Detail-oriented mindset and the ability to work collaboratively in a fast-paced environment. \n \n  Nice to have: \n \n  Experience with Hubspot and Mixpanel     \n \n What\u2019s in it for you?  As a full-time member of our team, you\u2019ll enjoy: \n \n  Flexible hours, work wherever you choose \n  Unlimited PTO \n  Non-working holidays per country of residence \n  Pro-rated 13th-month bonus in select regions \n  Salary increases and performance-based bonuses \n  Referral bonuses \n  Financial support for online courses \n  Mental health and well-being programs \n  Fun and casual work environment \n  Employee engagement activities and virtual gatherings \n  We are a diverse, global team! \n \n \n  Important Notice:  To ensure the legitimacy of jobs, we strongly advise to exclusively rely on positions posted here or on our official website: outliant.com/careers. Our recruitment team communicates solely through email using only @outliant.com email addresses and via LinkedIn.  \n \n Please be assured that we are fully committed to maintaining integrity in our hiring process.",
        "cleaned_desc": " \n  Analyze complex data sets to identify trends, patterns, and insights that can be leveraged for marketing strategies. \n  Utilize statistical techniques and advanced analytical tools to interpret data and provide valuable insights into customer behavior, campaign effectiveness, and market trends. \n  Translate big data into actionable dashboards and data visualizations. \n  Design and interpret A/B and multivariate tests. \n  Collaborate with cross-functional teams to define data requirements, ensure data integrity, and establish best practices for data collection and analysis. \n  Design and interpret A/B testing methodologies and analyze results to optimize marketing campaigns, website performance, and customer experiences. \n  Provide actionable recommendations based on data analysis to enhance marketing strategies, improve customer engagement, and drive revenue growth. \n  Continuously monitor and evaluate marketing performance metrics, identifying areas for improvement and proposing solutions. \n  Stay current with industry trends, emerging technologies, and best practices in marketing analytics. ",
        "techs": [
            "analyze complex data sets",
            "statistical techniques",
            "advanced analytical tools",
            "data visualizations",
            "a/b and multivariate tests",
            "data requirements",
            "data integrity",
            "a/b testing methodologies",
            "marketing performance metrics",
            "emerging technologies"
        ],
        "cleaned_techs": [
            "analyze complex data sets",
            "statistical techniques",
            "advanced analytical tools",
            "data visualizations",
            "a/b and multivariate tests",
            "data requirements",
            "data integrity",
            "a/b testing methodologies",
            "marketing performance metrics",
            "emerging technologies"
        ]
    },
    "d9b2bfc0ce24cf5b": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 70.0,
        "salary_max": 72.0,
        "title": "Data Informatics Analyst",
        "company": "ASA",
        "desc": "Data Informatics Analyst: Generates ad hoc reports and regular datasets or report information for end-users using system tools and database or data warehouse queries and scripts. \n Integrates data from multiple sources to produce requested or required data elements. \n Programs and maintains report forms and formats, information dashboards, data generators, canned reports and other end-user information portals or resources. \n May create specifications for reports based on business requests. \n May be internal operations-focused or external client-focused, working in conjunction with Professional Services and outsourcing functions. \n Skills \n 7-10 years of working experience as an analyst with 4+ of those years in designing and development data visualization and executive level dashboards. \n Must have expert level understanding of financial dashboard design and data visualization best practices. \n An understanding of cloud architecture, underlying markets and key market drivers, and global megatrends and the value of data & analytics in acting on external disruption and market trends. \n Must be able to work in fast paced environment and be able to adopt to changing requirements. \n Knowledge of SQL, Python and R. \n Proficient in Tableau, Tableau Prep \n Knowledge of Power BI and other BI analytics tools. \n Knowledge of ServiceNow Platform desired. \n Knowledge of Performance Analytics desired. \n Communication skills. \n Strong analytical skills. \n Interpersonal skills. \n Job Type: Contract \n Salary: $70.00 - $72.00 per hour \n Schedule: \n \n Monday to Friday \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "8a72da02b26328f1": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 72.0,
        "salary_max": 78.0,
        "title": "Manufacturing Business Analyst",
        "company": "Kaygen",
        "desc": "MES Lean Material Management Business Analyst \n Long term contract job \n Remote - US Based \n GENERAL FUNCTION: Will report to MES Business Partner and be primarily responsible for working with manufacturing sites implementing Dassault System Apriso Manufacturing Execution Systems (MES) for Lean Material Management. Working with sites will include designing system use, re-engineering local business processes, project planning and scheduling, assisting with master data, training, and consulting. Provide ERP (SAP) advice for site manufacturing related activities including master data, transaction processing, and data interface between ERP and MES. Work with Platform Solutions Team to coordinate their MES Interface activities and deliver MES Capabilities to  Client \u2019s Manufacturing plants. \n RESPONSIBILITIES: \n \n Work with MES Business Partner Team, Platform Solutions teams, MES deployment partners and Manufacturing Site teams to enable MES adoption and deliver business value. \n Assist with, or facilitate, to help Site MES teams understand the  Client  MES design and capabilities, to define process MES usage design. \n Work with site teams to plan, schedule, and execute implementations, expansions, and upgrades. \n Coach sites through their MES validation activities \n Must be willing to travel onsite. \n Assist in the evolution of  Client \u2019s MES design so it contains appropriate functionality to help sites achieve the company\u2019s manufacturing operation objectives. \n Support discrepancy analysis and resolution for sites who are in their PQ (Product qualification / User acceptance) test cycle. \n \n QUALIFICATIONS AND SKILLS: Required: \n \n Bachelor\u2019s degree in Business, Computer Science, or equivalent experience. \n Strong foundational knowledge of ERP (SAP) systems and usage in manufacturing: production planning, production execution, discrete vs continuous manufacturing, and materials management IM & WM. Must understand key concepts related to production order management, material movement codes, backflushing, order confirmations, goods receipts, control keys, and data exchange with subsystems. \n Experience in Manufacturing Execution Systems (MES): Inventory Management, and Production Order Processing, Machine Data Collection to automate material transactions. Understanding the design principles they employ, how they can add value and be integrated with ERP systems. \n Project Management experience that includes large IT related projects where people and hardware resources were successfully managed, and organizational change successfully implemented. \n Knowledge of FDA 21CFR Part 11, understanding of Software Development Life Cycle along with Computer Software Validation procedures: IQ, OQ, PQ and/or Computer Software Assurance principles. \n Strong written and verbal communication skills, enabling delivery of training and sharing of new concepts to facilitate change in the organization \n Ability to troubleshoot, analyzing problems, and offer intelligent insight and solutions. \n \n Thank you, Aftab Pathan|Associate Delivery Manager EXT (949) 203 5100 ext 207 I Cell: (949)- 419-6242 | Email: aftab.p at kaygen.com \n Find us on LinkedIn| Twitter| Facebook \n Job Type: Temporary \n Pay: $72.00 - $78.00 per hour \n Expected hours: 40 per week \n Schedule: \n \n Day shift \n \n Experience: \n \n Manufacturing Execution Systems: 2 years (Required) \n Material Management: 5 years (Required) \n Apriso Manufacturing Execution Systems: 2 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": " QUALIFICATIONS AND SKILLS: Required: \n \n Bachelor\u2019s degree in Business, Computer Science, or equivalent experience. \n Strong foundational knowledge of ERP (SAP) systems and usage in manufacturing: production planning, production execution, discrete vs continuous manufacturing, and materials management IM & WM. Must understand key concepts related to production order management, material movement codes, backflushing, order confirmations, goods receipts, control keys, and data exchange with subsystems. \n Experience in Manufacturing Execution Systems (MES): Inventory Management, and Production Order Processing, Machine Data Collection to automate material transactions. Understanding the design principles they employ, how they can add value and be integrated with ERP systems. \n Project Management experience that includes large IT related projects where people and hardware resources were successfully managed, and organizational change successfully implemented. \n Knowledge of FDA 21CFR Part 11, understanding of Software Development Life Cycle along with Computer Software Validation procedures: IQ, OQ, PQ and/or Computer Software Assurance principles. ",
        "techs": [
            "erp (sap) systems",
            "manufacturing execution systems (mes)",
            "inventory management",
            "production order processing",
            "machine data collection",
            "project management",
            "fda 21cfr part 11",
            "software development life cycle"
        ],
        "cleaned_techs": [
            "erp (sap) systems",
            "manufacturing execution systems (mes)",
            "inventory management",
            "production order processing",
            "machine data collection",
            "project management",
            "fda 21cfr part 11",
            "software development life cycle"
        ]
    },
    "0cc953d9bc5ed24e": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 39.0,
        "salary_max": 46.0,
        "title": "Data Analyst",
        "company": "PeopleCaddie",
        "desc": "Job ID:  4501 \n   \n \n \n Pay rate range:  $39 - $46 \n   \n \n \n City:  Dallas \n   \n \n \n State:  Texas \n   \n \n \n Duration:  10/22/2023 - 04/22/2024 \n   \n \n \n Job Type:  Contract to Hire \n   \n \n \n Job Description \n Our large consulting client is seeking an Operations Analyst to support their strategy & transformation team. This is a 100% REMOTE contract or contract-to-hire role supporting a high-growth PE-backed consulting firm. \n \n  RESPONSIBILITIES \n \n \n   \n Collaborates with management and service line leaders to identify and assess reporting needs impacting operational effectiveness.   \n Design and build reports related to:   \n \n Employee performance   \n Resource utilization   \n Project profitabilty   \n Revenue by project   \n QUALIFICATIONS \n \n   \n Bachelor's degree and at least 2 years in professional services or a consulting firm.   \n Strong excel and PowerBI skills building and designing dashboards   \n Substantial analysis of utilization, availability, performance and other related talent management data on a regular and ad-hoc basis.   \n Ability to interact effectively and collaboratively with other departments and line management.   \n Ability to influence senior leaders.   \n Proven success in building relationships   \n The ability to prioritize and manage multiple/large projects and responsibilities.   \n Excellent communication and executive presentation skills with the ability to adjust your tone and approach to different people.   \n The ability to articulate and break down complex information.   \n Adaptability and comfort in a dynamic, fast paced environment.   \n Transparency in your work - what\u2019s going well and what\u2019s not   \n Team player mentality with a can-do attitude   \n Ability to work in a fast paced, changing environment   \n Experience with Mavenlink/Kantata (nice to have) \n \n  About PeopleCaddie \n \n  PeopleCaddie is a digital talent marketplace focused exclusively on contract opportunities for highly skilled business professionals. Our talent cloud utilizes proprietary data and technology to help contractors find attractive job opportunities through PeopleCaddie\u2019s user-friendly mobile app while enjoying unparalleled visibility in pay rates and application status. With an established array of clients nationwide, including Fortune 500 companies spanning multiple industries, PeopleCaddie has quickly become one of the fastest-growing talent clouds. \n \n  #PCFA \n \n  #LI-Remote",
        "cleaned_desc": " Project profitabilty   \n Revenue by project   \n QUALIFICATIONS \n \n   \n Bachelor's degree and at least 2 years in professional services or a consulting firm.   \n Strong excel and PowerBI skills building and designing dashboards   \n Substantial analysis of utilization, availability, performance and other related talent management data on a regular and ad-hoc basis.   \n Ability to interact effectively and collaboratively with other departments and line management.   \n Ability to influence senior leaders.   \n Proven success in building relationships   \n The ability to prioritize and manage multiple/large projects and responsibilities.   ",
        "techs": [
            "powerbi",
            "excel"
        ],
        "cleaned_techs": [
            "powerbi",
            "excel"
        ]
    },
    "5c87f6b80f7bcd29": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 39.88,
        "salary_max": 47.14,
        "title": "Analyst Medical Data",
        "company": "NewYork-Presbyterian Hospital",
        "desc": "Location  New York, New York\n   Shift:  Day (United States of America)\n   Description: \n  Medical Data Analyst \u2013 Central Billing Office (Remote) \n \n  Join the patient-inspired team at New York-Presbyterian and bring new meaning to your career. See how the revenue cycle team in our Central Billing Office plays an active role in world-class care and caring. Thrive as a valued member of the team and feel the pride of mission-driven achievement. Here, putting patients first is our mission, which means we stay committed to excellence in all aspects of our organization, including maintaining the accuracy and integrity of our medical records. And as we look to the promising future ahead, we seek talented professionals like you to help drive our financial growth while building on our reputation for excellence as one of the nation\u2019s top-ranked hospitals. \n \n  Utilize your outstanding analytical skills and keen attention to detail to take on this important high performance role, responsible for performing varied and complex diagnostic and procedural coding for patient records. In this role, you will support the Central Billing Office with various crucial functions like ensuring the complete, accurate, and timely coding and APC assignment alongside a required daily productivity. This position plays a key role in the efficient and effective financial operations of the Medical Group and helps make a life-changing difference. \n \n  Preferred Criteria \n \n  College degree \n  CPC \n  EPIC \n  Understanding denials process \n  Microsoft office \n  Excel (basic) \n  Encoder \n \n \n  Required Criteria \n \n  High School Diploma \n  2-3 years demonstrated coding experience \n  Demonstrated knowledge of CPT, ICD-10CM, and HCPCS coding \n  Proficient computer skills, including experience with clinical information systems for accessing health information in an electronic environment \n  Professional interpersonal and communication skills throughout the Organization \n  Reviewing and extracting appropriate CPT, ICD-10CM, and/or HCPCS based off of documentation \n  Ability to work in a Team environment and independently \n \n \n  Join a healthcare system where employee engagement is at an all-time high. Here we foster a culture of respect, diversity, and inclusion. Enjoy comprehensive and competitive benefits that support you and your family in every aspect of life. Start your life-changing journey today.  __________________ \n \n  2021 \"Employees' Choice Awards: Best Places to Work\" -  Glassdoor \n  2021 \" Best Workplaces in Health Care & Biopharma\" -  Fortune \n  2020 \"America's Best Employers in New York State\" -  Forbes \n  2020 \"Working Mother 100 Best Companies\" -  Working Mother \n  2020 \"Best Companies for Multicultural Women\" -  Working Mother \n  2020 \"Best Workplace for Men in Nursing\" -  American Association for Men in Nursing \n  Discover why at: nyp.org/careers \n \n \n  NewYork-Presbyterian Hospital is an equal opportunity employer. \n \n  Salary Range: \n  $39.88-$47.14/Hourly\n  \n  It all begins with you. Our amazing compensation packages start with competitive base pay and include recognition for your experience, education, and licensure. Then we add our amazing benefits, countless  opportunities for personal and professional growth and a dynamic environment that embraces every person. Join our team and discover where amazing works.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "e9234f6669e8e6da": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 70000.0,
        "salary_max": 85000.0,
        "title": "Stata Data Analyst Consultant (CA, CO, TX, VA, WA)",
        "company": "Berger Consulting Group",
        "desc": "This position is open to candidates in California, Colorado, Texas, Virginia, and Washington. \n Description \n Berger Consulting Group provides statistical and economic consulting services, as well as expert testimony in litigation matters involving labor and employment, class actions, and other commercial disputes. With over a decade of experience serving clients, we have focused and sharpened our expertise in statistics, data management, and data analysis, specializing in the litigation process. \n We are seeking to fill the role of Stata Data Analyst, which places heavy emphasis on the use of complex data analysis and statistics. This role includes strong emphases on data wrangling and cleaning, data formatting and normalization, and analytics. The ideal candidate has excellent verbal and written communication skills, exceptional empirical skills, and passion for rigorous data analysis in the fast-paced and constantly changing litigation context. Analysts work as part of a team on challenging and complex projects in a work environment that promotes a company culture that believes in both doing good work and having time to experience the other important parts of life. \n Job Requirements \n \n Conduct independent data and statistical analyses utilizing Excel and Stata. \n Normalize data sets including but not limited to timekeeping and payroll data. \n Construct, manage, and manipulate small to large databases and perform data cleaning and analysis. \n Run Quality Assurance checks on the data. \n Prepare notes of findings, including salient examples from source documents for client use. \n Identify and clearly communicate trends, outliers, potential issues, shortcomings, and additional needs based on document review and analysis. \n Communicate with manager on a regular basis. \n \n Required Skills and Experience \n \n 2+ years of intensive experience working with large (~1M rows), complex, and potentially messy datasets. \n Expertise in Microsoft Excel and Stata (2+ years of regular Stata usage in the workplace). \n Expertise and use in work settings in complex equation building in Excel; including but not limited to nested logic, lookups (vlookup, hlookup, xlookup), match index, find, date/time functions, left/mid/right, sumifs, averageifs, shortcuts, sorting, pivot tables, etc. \n Excellent quantitative and analytical skills. \n Excellent verbal and written communication skills. \n Ability to work independently. \n Ability to manage caseload, including proactive planning, anticipating obstacles, and monitoring the progress of many cooccurring projects. \n Willingness to work on multiple projects with tight deadlines, including last minute requests and changes. \n Patience and attention to detail, with sharp focus on accuracy and problem solving. \n \n Remote Work \n Berger Consulting Group does not have a central office and all employees work remotely. Since employees are remote, they need to choose a permanent home office for their workplace upon hiring. Changes to your home office should be discussed with your manager prior to any relocation. \n Job Type: Full-time \n Pay: $70,000.00 - $85,000.00 per year \n Benefits: \n \n 401(k) \n 401(k) 3% Match \n Dental insurance \n Disability insurance \n Health insurance \n Paid holidays \n Paid time off \n Vision insurance \n Work from home \n \n Compensation package: \n \n Bonus opportunities \n \n Experience level: \n \n 1 year \n 2 years \n 3 years \n \n Schedule: \n \n 8 hour shift \n Day shift \n Monday to Friday \n No nights \n No weekends \n \n Application Question(s): \n \n Will you now or in the future require sponsorship for employment status (e.g. H1B visa status)? (Required for consideration) \n This role requires the daily use of Stata. Please provide any details about your Stata usage in a university or work setting. Additionally, please describe your use of Stata and Excel for cleaning large, messy, datasets, if any. (Required for consideration) \n Are you located in CA, CO, TX, VA, or WA? (Required for consideration) \n \n Experience: \n \n Stata: 2 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": "This position is open to candidates in California, Colorado, Texas, Virginia, and Washington. \n Description \n Berger Consulting Group provides statistical and economic consulting services, as well as expert testimony in litigation matters involving labor and employment, class actions, and other commercial disputes. With over a decade of experience serving clients, we have focused and sharpened our expertise in statistics, data management, and data analysis, specializing in the litigation process. \n We are seeking to fill the role of Stata Data Analyst, which places heavy emphasis on the use of complex data analysis and statistics. This role includes strong emphases on data wrangling and cleaning, data formatting and normalization, and analytics. The ideal candidate has excellent verbal and written communication skills, exceptional empirical skills, and passion for rigorous data analysis in the fast-paced and constantly changing litigation context. Analysts work as part of a team on challenging and complex projects in a work environment that promotes a company culture that believes in both doing good work and having time to experience the other important parts of life. \n Job Requirements \n \n Conduct independent data and statistical analyses utilizing Excel and Stata. \n Normalize data sets including but not limited to timekeeping and payroll data. \n Construct, manage, and manipulate small to large databases and perform data cleaning and analysis. \n Run Quality Assurance checks on the data. \n Prepare notes of findings, including salient examples from source documents for client use. \n Identify and clearly communicate trends, outliers, potential issues, shortcomings, and additional needs based on document review and analysis. \n Communicate with manager on a regular basis. \n   Required Skills and Experience \n \n 2+ years of intensive experience working with large (~1M rows), complex, and potentially messy datasets. \n Expertise in Microsoft Excel and Stata (2+ years of regular Stata usage in the workplace). \n Expertise and use in work settings in complex equation building in Excel; including but not limited to nested logic, lookups (vlookup, hlookup, xlookup), match index, find, date/time functions, left/mid/right, sumifs, averageifs, shortcuts, sorting, pivot tables, etc. \n Excellent quantitative and analytical skills. \n Excellent verbal and written communication skills. \n Ability to work independently. \n Ability to manage caseload, including proactive planning, anticipating obstacles, and monitoring the progress of many cooccurring projects. \n Willingness to work on multiple projects with tight deadlines, including last minute requests and changes. \n Patience and attention to detail, with sharp focus on accuracy and problem solving. \n \n Remote Work \n Berger Consulting Group does not have a central office and all employees work remotely. Since employees are remote, they need to choose a permanent home office for their workplace upon hiring. Changes to your home office should be discussed with your manager prior to any relocation. ",
        "techs": [
            "stata",
            "microsoft excel"
        ],
        "cleaned_techs": [
            "stata",
            "excel"
        ]
    },
    "bfb99ee056cd101b": {
        "terms": [
            "data analyst"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Data Visualization",
        "company": "JPMorgan Chase & Co",
        "desc": "JOB DESCRIPTION \n  DESCRIPTION: \n  Duties: Support lines of business or business units focused BI reporting and dashboards. Drive the set up and production of dashboards measuring KPIs for the business units. Work with engineers and data scientists to turn insights into self-service dashboards or data products. Build clean, actionable dashboards. Query Salesforce data and merge information from diverse data sources to create rich datasets that enable better decision-making. Evangelize the insights through storytelling. Create easy-to-consume media that inspires into action anyone from senior executives to fellow analysts. Drive automation of new and existing processes. Telecommuting is permitted up to 40% of the week. \n  QUALIFICATIONS: \n  Minimum education and experience required: Bachelor\u2019s degree in Electrical Engineering, Electronics Engineering, Computer Engineering, Computer Science, Information Systems, or related field of study plus 5 years of experience in the job offered or as Data Visualization, Data Analysts, Programmer, or related occupation. The employer will alternatively accept a Master\u2019s degree in Electrical Engineering, Electronics Engineering, Computer Engineering, Computer Science, Information Systems, or related field of study plus 3 years of experience in the job offered or as Data Visualization, Data Analysts, Programmer, or related occupation. \n  Skills Required: Requires experience in the following: SQL; Data Visualization such as Tableau or Power BI; ETL or Data Wrangling tool such as Alteryx; Database or Cloud systems such as MS Azure or SQL Server; Python; and Advanced Excel such as pivot table, lookup, or indexing. \n  Job Location: 8181 Communications Parkway, Plano, TX 75024. Telecommuting permitted up to 40% of the week. \n ABOUT US \n  Chase is a leading financial services firm, helping nearly half of America\u2019s households and small businesses achieve their financial goals through a broad range of financial products. Our mission is to create engaged, lifelong relationships and put our customers at the heart of everything we do. We also help small businesses, nonprofits and cities grow, delivering solutions to solve all their financial needs. \n  We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants\u2019 and employees\u2019 religious practices and beliefs, as well as any mental health or physical disability needs. \n  We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, discretionary incentive compensation which may be awarded in recognition of individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process. \n \n  Equal Opportunity Employer/Disability/Veterans \n \n \n \n ABOUT THE TEAM \n \n  Our Consumer & Community Banking division serves our Chase customers through a range of financial services, including personal banking, credit cards, mortgages, auto financing, investment advice, small business loans and payment processing. We\u2019re proud to lead the U.S. in credit card sales and deposit growth and have the most-used digital solutions \u2013 all while ranking first in customer satisfaction.",
        "cleaned_desc": "  QUALIFICATIONS: \n  Minimum education and experience required: Bachelor\u2019s degree in Electrical Engineering, Electronics Engineering, Computer Engineering, Computer Science, Information Systems, or related field of study plus 5 years of experience in the job offered or as Data Visualization, Data Analysts, Programmer, or related occupation. The employer will alternatively accept a Master\u2019s degree in Electrical Engineering, Electronics Engineering, Computer Engineering, Computer Science, Information Systems, or related field of study plus 3 years of experience in the job offered or as Data Visualization, Data Analysts, Programmer, or related occupation. \n  Skills Required: Requires experience in the following: SQL; Data Visualization such as Tableau or Power BI; ETL or Data Wrangling tool such as Alteryx; Database or Cloud systems such as MS Azure or SQL Server; Python; and Advanced Excel such as pivot table, lookup, or indexing. ",
        "techs": [
            "sql",
            "tableau",
            "power bi",
            "alteryx",
            "ms azure",
            "sql server",
            "python",
            "advanced excel"
        ],
        "cleaned_techs": [
            "sql",
            "tableau",
            "powerbi",
            "alteryx",
            "ms azure",
            "python",
            "advanced excel"
        ]
    },
    "a71cd7a1fe5bd58e": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 47.0,
        "salary_max": 51.0,
        "title": "Business Analyst (Contract to hire) - Health Insurer",
        "company": "Radost Solutions LLC",
        "desc": "Job Title: Business Analyst (Contract) - Health Insurer \n Department: Business Analytics \n Location: Remote \n About Us: \n At  Radost Solutions , we are committed to helping businesses thrive by bridging the gap between their strategic objectives and the talent they need to achieve them. We are currently seeking a talented Business Analyst for a contract role with our health insurer client's Strategic Initiatives Office (SIO). This is a fully remote position, catering to professionals passionate about healthcare optimization and business strategy alignment. \n Job Overview: \n We are in search of a dedicated and professional Business Analyst to become a pivotal part of the Business Analytics team within our client's SIO. The selected candidate will be instrumental in analyzing business requirements, recommending solutions, and ensuring the alignment of projects with business objectives. A sound understanding of health insurer operations, regulatory compliance, and business process improvement is crucial for this role. \n Responsibilities: \n 1. Elicit, gather, and document clear and detailed business requirements from various stakeholders. \n 2. Collaborate with project managers and other team members to define and prioritize business needs. \n 3. Evaluate current processes, pinpointing areas of inefficiency or areas for enhancement. \n 4. Use business intelligence tools and techniques to provide actionable insights for decision-makers. \n 5. Engage with IT teams to ensure system enhancements and solutions align with business needs. \n 6. Assist in the development, testing, and deployment of solutions that meet business objectives. \n 7. Contribute to change management and training initiatives to ensure successful project implementation. \n 8. Ensure compliance with healthcare industry regulations and standards in all project outputs. \n 9. Communicate effectively with stakeholders, presenting findings and recommendations. \n Qualifications: \n 1. Bachelor\u2019s degree in business administration, Healthcare Management, a related field, or equivalent experience. \n 2. Proven experience as a Business Analyst, preferably within the  healthcare or insurance industry. \n 3. Strong knowledge of business process modeling, data analysis, and project management methodologies. \n 4. Proficient in tools such as MS Office Suite, particularly Excel, and other tools. \n 5. Familiarity with healthcare regulations and compliance requirements. \n 6. Experience in utilizing BI tools for data visualization and reporting would be a plus. \n 7. Ability to engage constructively with multi-disciplinary teams. \n 8. Exceptional problem-solving abilities and analytical thinking. \n 9. Outstanding written and verbal communication skills. \n What We Offer: \n 1. Competitive compensation commensurate with experience. \n 2. Opportunities for professional development. \n 3. Engaging projects that directly impact healthcare delivery and optimization. \n 4. A team-oriented, collaborative environment. \n 5. Flexibility with a fully remote work arrangement. \n Equal Opportunity Employer: \n Radost is an Equal Opportunity Employer and does not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state, or local protected class. \n Please visit our website at www.radostsolutions.com \n Job Type: Contract \n Salary: $47.00 - $51.00 per hour \n Expected hours: 35 \u2013 45 per week \n Benefits: \n \n 401(k) \n Paid holidays \n Paid time off \n Vision insurance \n \n Compensation package: \n \n Hourly pay \n \n Experience level: \n \n 4 years \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Application Question(s): \n \n How many years of Health Insurer experience do you have? \n \n Experience: \n \n Business analysis: 3 years (Preferred) \n Business requirements: 3 years (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": " 6. Assist in the development, testing, and deployment of solutions that meet business objectives. \n 7. Contribute to change management and training initiatives to ensure successful project implementation. \n 8. Ensure compliance with healthcare industry regulations and standards in all project outputs. \n 9. Communicate effectively with stakeholders, presenting findings and recommendations. \n Qualifications: \n 1. Bachelor\u2019s degree in business administration, Healthcare Management, a related field, or equivalent experience. \n 2. Proven experience as a Business Analyst, preferably within the  healthcare or insurance industry. \n 3. Strong knowledge of business process modeling, data analysis, and project management methodologies. \n 4. Proficient in tools such as MS Office Suite, particularly Excel, and other tools. \n 5. Familiarity with healthcare regulations and compliance requirements. \n 6. Experience in utilizing BI tools for data visualization and reporting would be a plus. \n 7. Ability to engage constructively with multi-disciplinary teams. \n 8. Exceptional problem-solving abilities and analytical thinking. ",
        "techs": [
            "ms office suite",
            "excel",
            "bi tools"
        ],
        "cleaned_techs": [
            "microsoft",
            "excel",
            "bi tools"
        ]
    },
    "ad4dcaa1dcbeb436": {
        "terms": [
            "data analyst"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "HIM Data Analyst / Quality Auditor",
        "company": "Texas Health Resources",
        "desc": "HIM Data Analyst / Quality Auditor \n Are you looking for a rewarding career with family-friendly hours and top-notch benefits? We are looking for a qualified  HIM Data Analyst/Quality Auditor   like you to join our Texas Health family. \n Work location:  Remote \n Work hours:  Full Time (40 Hours) Monday through Friday: 8:00 am to 5:00 pm \n   \n \n HIMS Quality Audits and Reporting: \n \n \n  100% remote work \n \n \n  Flexible hours/scheduling \n \n \n  Terrific work/life balance \n \n  What You Will Need \n \n Education \n  Associate's Degree Health Information Management, Computer Science, Information Systems, Health Informatics, or related field \n   Required  \n  Bachelor's Degree Health Information Management, Computer Science, Information Systems, Health Informatics, or related field \n   Preferred \n \n \n Experience \n  1 Year Experience in data analysis and reporting \n   Required  and\n    1 Year Experience in a health care environment with and EMR\n    Preferred \n \n \n Licenses and Certifications \n  RHIT - Registered Health Information Technician Upon Hire \n   Highly Preferred  Or\n    RHIA - Registered Health Information Administrator Upon Hire \n   Preferred \n \n \n   \n \n \n Skills \n \n \n  Strong analytical, problem-solving skills, and attention to detail. Knowledgeable in pulling, compiling and reporting statistical data. Excellent computer skills with proficiency in input and extraction of information utilizing word processing, spreadsheet, database software. Intermediate skills in the use analytics tools such as Alteryx, Tableau, Excel, and Access. Ability to create data queries and build and edit reports. Experience creating and utilizing SharePoint for data sharing and project management. Knowledge of complex acute care hospital Health Information Management operations. Understanding of HIM processes in an electronic health record environment. Knowledge of Joint Commission, CMS and state medical record documentation regulations. Ability to interpret and apply regulatory requirements to audit, report and help facilitate organizational compliance. Able to employ effective problem-solving skills to make appropriate recommendations for process improvement and/or training opportunities. Ability to write detailed reports and/or presentations of findings and recommendations. Excellent interpersonal, verbal, and written communication skills both up and down the chain of leadership. Ability to develop and maintain positive relationships with providers and other stakeholders. Ability to work well independently and in a team environment. Able to manage multiple tasks, prioritize and meet deadlines.\n  \n \n   \n \n \n What You Will Do \n \n \n  Provides data analysis and auditing support for division functions. \n \n \n  Audit and confirm accuracy of health record analysis to ensure adherence to requirements by THR's Policies and Procedures, Medical Staff Rules and Regulations, and external regulatory agencies including The Joint Commission, Center for Medicaid and Medicare, Texas Administrative Code, etc. \n \n \n  Develops presentations and training/communications materials. \n \n \n   \n \n \n Additional perks of being a Texas Heath Supervisor \n \n \n  Benefits include 401k, PTO, medical, dental, Paid Parental Leave, flex spending, tuition reimbursement, Student Loan Repayment Program as well as several other benefits. \n \n \n  A supportive, team environment with outstanding opportunities for growth. \n \n   \n \n  At Texas Health Resources, our mission is \u201cto improve the health of the people in the communities we serve\u201d.\n  \n \n \n \n \n  Our award-winning culture is a tribute to our amazing employees. We\u2019re thrilled to be a 2023 FORTUNE Magazine\u2019s \u201c100 Best Companies to Work For\u00ae\u201d for the 9th year in a row!\n  \n \n \n \n \n  We strive to create an atmosphere of respect, integrity, compassion and excellence for all. We\u2019re committed to diversity in our workforce, and our mission to serve spreads across ethnic, cultural, economic and generational boundaries. Join us and to do your life\u2019s best work here!\n  \n \n \n \n Explore our Texas Health careers site for info like Benefits, Job Listings by Category, recent Awards we\u2019ve won and more. \n \n \n Do you still have questions or concerns?  Feel free to email your questions to recruitment@texashealth.org. \n   \n #LI-JT1",
        "cleaned_desc": " \n \n   \n \n \n Skills \n \n \n  Strong analytical, problem-solving skills, and attention to detail. Knowledgeable in pulling, compiling and reporting statistical data. Excellent computer skills with proficiency in input and extraction of information utilizing word processing, spreadsheet, database software. Intermediate skills in the use analytics tools such as Alteryx, Tableau, Excel, and Access. Ability to create data queries and build and edit reports. Experience creating and utilizing SharePoint for data sharing and project management. Knowledge of complex acute care hospital Health Information Management operations. Understanding of HIM processes in an electronic health record environment. Knowledge of Joint Commission, CMS and state medical record documentation regulations. Ability to interpret and apply regulatory requirements to audit, report and help facilitate organizational compliance. Able to employ effective problem-solving skills to make appropriate recommendations for process improvement and/or training opportunities. Ability to write detailed reports and/or presentations of findings and recommendations. Excellent interpersonal, verbal, and written communication skills both up and down the chain of leadership. Ability to develop and maintain positive relationships with providers and other stakeholders. Ability to work well independently and in a team environment. Able to manage multiple tasks, prioritize and meet deadlines.\n  \n \n   \n \n \n What You Will Do \n \n \n  Provides data analysis and auditing support for division functions. \n ",
        "techs": [
            "alteryx",
            "tableau",
            "excel",
            "access",
            "sharepoint"
        ],
        "cleaned_techs": [
            "alteryx",
            "tableau",
            "excel",
            "access",
            "sharepoint"
        ]
    },
    "5d998f26a01521c4": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 73875.17,
        "salary_max": 93542.44,
        "title": "Business Intelligence Analyst",
        "company": "EquipmentShare",
        "desc": "EquipmentShare is Hiring a Business Intelligence Analyst \n  EquipmentShare is searching for a Business Intelligence Analyst for our corporate office in Columbia, MO, to support our Business Analytics team as the department continues to grow.  This new team member may be based anywhere in the United States and offers a remote/hybrid work option, but must be able to meet with management in person at least quarterly. \n  EquipmentShare is seeking a  Business Intelligence Analyst.  As a BI Analyst, you will use your data expertise to help departments throughout the company with analytics needs. These projects are wide ranging and could include anything from finance and collections to telematics and fleet data. \n  Primary Responsibilities \n \n Become a technical data and reporting expert in a variety of areas to refine and troubleshoot reporting requirements working across teams and domains \n Build complex queries and data models based on reporting requirements with minimal errors \n Produce and support dashboards and reports used across the organization \n Use your strong development and analytical skills to ideate and solve business problems \n \n Why We're a Better Place to Work \n \n Competitive salary \n Health insurance and medical coverage benefits \n 401(k) and company match \n Unlimited paid time off \n Stocked breakroom and full kitchen, chef prepared meals daily (Corporate HQ) \n State of the art onsite gym (Corporate HQ)/Gym stipend for remote employees \n Volunteering and local charity initiatives that help you nurture and grow the communities you call home \n Opportunities for career and professional development with conferences, events, seminars and continued education. \n \n About You \n  Our mission to change an entire industry is not easily achieved, so we only hire people who are inspired by the goal and up for the challenge. In turn, our employees have every opportunity to grow with us, achieve personal and professional success and enjoy making a tangible difference in an industry that's long been resistant to change. \n  Skills & Qualifications \n \n Must be qualified to work in the United States - we are not sponsoring any candidates at this time. \n At least 2 years of experience programming in SQL \n At least 2 years of experience designing business intelligence reports (e.g. Looker, PowerBI, Tableau, Qlik, etc.) \n Strong attention to detail and quality assurance process \n Knowledge of an analytical language like Python or R is a plus \n Proven ability to independently approach complex problems with curiosity and an analytical mindset \n Ability to adapt quickly, manage competing projects and challenge the status quo \n A keen understanding of data interpretation and the ability to swiftly extract key insights \n \n About EquipmentShare \n  EquipmentShare is dedicated to creating a  connected jobsite for the modern contractor . We deliver user-friendly technology solutions that help contractors maximize their equipment uptime, reduce risk exposure and increase productivity. EquipmentShare's product offerings include an improved equipment rental experience, fleet tracking and asset management software, hardware security solutions and predictive service and maintenance applications. \n  EquipmentShare is the fastest-growing, independently owned construction equipment rental company in the country. We serve dozens of markets across the U.S. and are on track to create a national footprint in every major market in the country by the end of 2023. \n  Since our founding in 2014 and incorporation in 2015, we've had nationwide growth \u2014 and we're not stopping anytime soon. Ready to support our mission, invest in yourself and discover your potential? Then we'd love to meet you. Apply today. \n  EquipmentShare is committed to a diverse and inclusive workplace. EquipmentShare is an equal opportunity   employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation,   protected veteran status, disability, age, or other legally protected status. \n \n \n  #LI-Remote",
        "cleaned_desc": " \n Must be qualified to work in the United States - we are not sponsoring any candidates at this time. \n At least 2 years of experience programming in SQL \n At least 2 years of experience designing business intelligence reports (e.g. Looker, PowerBI, Tableau, Qlik, etc.) \n Strong attention to detail and quality assurance process \n Knowledge of an analytical language like Python or R is a plus \n Proven ability to independently approach complex problems with curiosity and an analytical mindset \n Ability to adapt quickly, manage competing projects and challenge the status quo ",
        "techs": [
            "sql",
            "looker",
            "powerbi",
            "tableau",
            "qlik",
            "python",
            "r"
        ],
        "cleaned_techs": [
            "sql",
            "looker",
            "powerbi",
            "tableau",
            "qlik",
            "python",
            "r"
        ]
    },
    "e6b9738450d6a7bb": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 55000.0,
        "salary_max": 65000.0,
        "title": "HR Operations Analyst",
        "company": "Alpine IQ",
        "desc": "Company Overview: \n  Join Alpine IQ, where innovation, collaboration, and a passion for excellence are at the core of everything we do. Our cutting-edge solutions empower organizations to achieve their goals, and our commitment to our employees ensures that we maintain a vibrant and inclusive workplace. If you are a data-driven HR professional with a knack for process improvement and a thirst for data analysis, we want you to be part of our People Operations team. \n  Position Overview: \n  Are you a master of HR data analysis, process optimization, and HR technology? Are you excited about the opportunity to make an impact on our people operations while working in a forward-thinking, fast-paced environment? We are seeking a People Operations Analyst who will play a key role in driving our HR strategies, ensuring data-driven decision-making, and enhancing the employee experience. \n  Key Responsibilities: \n \n Data-Driven Insights: Uncover valuable insights from HR data to drive informed decision-making. You'll be our data wizard, turning numbers into actionable strategies that optimize our HR processes and enhance our employee experience. \n Process Optimization: Identify and implement process improvements within our HR functions to ensure efficiency and compliance. We value your expertise in streamlining workflows and eliminating bottlenecks. \n Recruitment Analysis: Help us attract and retain top talent by analyzing recruitment data, including time-to-fill, sourcing channels, and candidate quality. Your insights will guide our recruitment strategies. \n Employee Relations: Collect and analyze data related to employee relations matters, providing insights that improve employee satisfaction and resolve workplace issues. \n Benefits & Compensation: Support the administration of our employee benefits and compensation programs. Stay ahead of market trends and provide recommendations for competitive compensation packages. \n Technology Management: Assist in implementing and maintaining our HR software and systems. You'll be the go-to person for ensuring our HR tech stack is user-friendly and efficient. \n \n Qualifications: \n \n Bachelor's degree in Human Resources, Business, Data Analytics, or related field. \n 2-4 years of HR or data analysis experience, preferably in a SaaS or tech company. \n Strong analytical skills and proficiency with data analysis tools and HRIS systems. \n Excellent communication and interpersonal skills. \n A keen understanding of HR policies, procedures, and employment laws. \n \n What We Offer: \n \n A dynamic and innovative work environment. \n Opportunities for professional growth and development. \n Competitive compensation and benefits package. \n The chance to work with a passionate and collaborative team. \n \n Are you ready to make a meaningful impact in a rapidly evolving SaaS company? If you are excited about leveraging data and process optimization to drive HR excellence, we want to hear from you. Please submit your resume and a cover letter explaining why you'd be a great fit for our People Operations Analyst position. \n \n  Join us in revolutionizing how we manage our people, data, and processes. Your expertise will drive our success, and together, we'll improve the workplace experience for everyone. \n  Alpine IQ is an equal opportunity employer and welcomes applicants from all backgrounds. We look forward to meeting you!",
        "cleaned_desc": " \n Qualifications: \n \n Bachelor's degree in Human Resources, Business, Data Analytics, or related field. \n 2-4 years of HR or data analysis experience, preferably in a SaaS or tech company. \n Strong analytical skills and proficiency with data analysis tools and HRIS systems. ",
        "techs": [
            "data analysis tools",
            "hris systems"
        ],
        "cleaned_techs": [
            "data analysis tools",
            "hris systems"
        ]
    },
    "f037a792d9816b8c": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 62600.0,
        "salary_max": 94000.0,
        "title": "Revenue Operations Analyst, Strategy and Analytics",
        "company": "Articulate",
        "desc": "The Revenue Operations Analyst is a critical role responsible for leveraging data to drive strategic business outcomes. This position involves performing in-depth data analysis and generating actionable insights for key stakeholders, including Sales, Success, Channel, Marketing, and Finance leaders. Additionally, the role focuses on streamlining RevOps reporting and models, enhancing automation, and ensuring clear documentation of team processes. \n  The ideal candidate possesses 2-4 years of experience in revenue operations or a similar data-oriented role, a bachelor's degree, and proficiency in tools like Google Sheets, Excel, and Salesforce. They should be analytical, adaptable, and an excellent communicator, capable of working both independently and collaboratively in a remote environment. \n  What you'll do: \n \n Perform data analysis and create actionable insights based on interpretation of the results. \n Create highly visual dashboards and reports to communicate insights to stakeholders, which includes Sales, Success, Channel, Marketing, and Finance leaders. \n Solicit and collaborate with business stakeholders to understand what data and cascading information is most helpful in aiding strategic business outcomes. \n Support strategic initiatives by evaluating the impact of revenue-driving programs and advising stakeholders accordingly. \n Drive automation and efficiency of RevOps\u2019 reporting and models by identifying bottlenecks and streamlining data collection. \n Document RevOps team processes and procedures, ensuring clarity and consistency.   \n \n What you should have: \n \n Minimum 2-4 years experience in revenue operations, sales operations reporting and analysis, or a similar data-oriented position \n A four-year college degree or equivalent experience is required \n A team player who is comfortable in a human-centered organization \n Proficiency with Google Sheets or Excel to perform complex data analysis and reporting \n Demonstrated skill in using data to identify trends, draw conclusions, and make strategic recommendations. \n Knowledge and experience in the use of Salesforce.com for revenue-generating teams, as well as building reports in Salesforce.com \n An analytical mind with the ability to tie business needs and desired outcomes to the data \n Self-starter motivated by intellectual curiosity, eager to learn and adapt to new tools and processes \n Excellent organizational and time management skills \n Self-motivated in a remote environment with the ability to work independently while also functioning and contributing as part of a team \n Skilled in building strong relationships across an organization and communicating complex information both written and verbally \n \n You're the ideal candidate if: \n \n Experience working for a SaaS organization, understanding PLG business models and best practices \n Experience with data visualization tools (Looker, Tableau) \n \n The pay range for this position is $62,600 to $94,000 for all US locations. Articulate takes into consideration a wide range of factors that are utilized in making compensation decisions including, but not limited to, skill sets, experience and training, licensure and certifications, qualifications and education, and other business and organizational needs. This position is also bonus eligible. Articulate also offers a robust suite of benefits, check out the website for a full list. \n  About us \n \n  Articulate Global, LLC, is the leading SaaS provider of creator platforms for online workplace training. Founded by Adam Schwartz in 2002, Articulate provides creator tools and services that make it simple for enterprises and SMBs to develop, deliver, and analyze online workplace training that\u2019s engaging and effective.\n  \n \n \n  Increasingly, organizations must reskill employees for ever-changing remote and hybrid work environments, create learning cultures that attract and retain employees in a tight labor market, and use training to build more equitable, empowering, and engaging workplaces. Articulate helps organizations address these critical business needs with its creator platform for workplace training. Articulate 360\u2014a suite of creator tools for online courses\u2014was named the 7th most-loved product in the world by TrustRadius in 2021. And Rise\u2014an all-in-one online training system that makes online training easy to create, enjoyable to take, and simple to manage\u2014is the first creator platform for SMBs and departments within the enterprise. Articulate has more than 118,000 customers in 170 countries and counts all 100 of the Fortune 100 companies as customers.\n  \n \n \n  Named one of Inc. Magazine\u2019s Best Workplaces 2022 and a leader in building a human-centered organization, Articulate is guided by a commitment to provide the best value to customers, do right by employees, and create an equitable, empowering workplace for all. As a human-centered organization, we honor people\u2019s humanity knowing that each person\u2019s unique history, vulnerabilities, and social location inform how we show up with one another. We embrace our connectedness, aware that what we do and say impacts others. We give each other grace because we are all works in progress, learning and evolving every day. And we take responsibility for ourselves and are serious about our accountability to each other. In all we do, we strive to create an equitable, sustainable, and empowering workplace while we drive results for the business and make a positive impact in the world. Read more about our values here.\n  \n \n \n  Articulate welcomes different voices and viewpoints and does not discriminate on the basis of race, religion, color, national origin, ancestry, physical and/or mental disability, medical condition, native language, pregnancy status, physical size, genetic information, marital status, sex, gender, gender identity, gender expression, transgender status, age, sexual orientation, and military or veteran status, or any other basis protected by law. We are an equal opportunity employer and invite applicants to voluntarily disclose their race and gender on our application form to help us create a diverse company. This voluntarily disclosed information will not be shared with any hiring manager and will be kept in confidence by the Articulate human resources department and executives who are not hiring for this position.\n  \n \n \n (For information about Articulate's privacy practices, please view our  Privacy Notice\n   )",
        "cleaned_desc": " \n What you should have: \n \n Minimum 2-4 years experience in revenue operations, sales operations reporting and analysis, or a similar data-oriented position \n A four-year college degree or equivalent experience is required \n A team player who is comfortable in a human-centered organization \n Proficiency with Google Sheets or Excel to perform complex data analysis and reporting \n Demonstrated skill in using data to identify trends, draw conclusions, and make strategic recommendations. \n Knowledge and experience in the use of Salesforce.com for revenue-generating teams, as well as building reports in Salesforce.com \n An analytical mind with the ability to tie business needs and desired outcomes to the data   Self-starter motivated by intellectual curiosity, eager to learn and adapt to new tools and processes \n Excellent organizational and time management skills \n Self-motivated in a remote environment with the ability to work independently while also functioning and contributing as part of a team \n Skilled in building strong relationships across an organization and communicating complex information both written and verbally \n \n You're the ideal candidate if: \n \n Experience working for a SaaS organization, understanding PLG business models and best practices \n Experience with data visualization tools (Looker, Tableau) \n ",
        "techs": [
            "google sheets",
            "excel",
            "salesforce.com",
            "looker",
            "tableau"
        ],
        "cleaned_techs": [
            "google sheets",
            "excel",
            "salesforce.com",
            "looker",
            "tableau"
        ]
    },
    "c342f6edd6478d60": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 120000.0,
        "salary_max": 120000.0,
        "title": "Strategy Analyst",
        "company": "Falconwood, Inc.",
        "desc": "Overview: \n  \n   Falconwood, Inc. is a woman/veteran-owned business providing executive level consultants and programmatic support to Department of Defense (DoD) Information Technology (IT) initiatives and programs. We have an immediate opening for a Strategy Analyst.\n  \n \n \n  The Strategy Analyst is a hybrid role designed to support the Program Control (PC) Manager and top leadership to include Program Manager and Deputy Program Manager in the areas of Strategic Planning, Performance Management, Survey Development, and Human Performance Improvement. This position requires active secret clearance.\n   Responsibilities: \n  \n Develop and manage yearly PC Strategic Plan to include goals, objectives, and initiatives. \n  Manage and drive critical operational and strategic initiatives across the organization. \n  Develop organizational surveys as required. \n  Prepare and present summaries and analyses of survey data, including tables, graphs, and brief slides that describe survey techniques and results. \n  Analyzes data using statistical methods and applications to evaluate workplace outcomes and effectiveness. \n  Performs planning, analyzing, and evaluating the effectiveness of operating programs.  \n Review performance objectives and identify areas of weakness. \n  Identify performance and process gaps and solution strategies. \n  Develop, manage, and evaluate the effectiveness of the Succession Plan. \n  Develop agenda and create instructional material and activities for offsite events. \n  Develop All-Hands slides, as required. \n  Coordinate and facilitate PC Automation Working Group.  \n Participates in meetings and projects with stakeholders, staff, project managers, etc., to render project activities into actionable solutions across business units and initiatives. \n  Develop constructive and cooperative working relationships with others and maintain them over time. \n  Analyze information and evaluate results to choose the best solution and solve problems. \n  Qualifications: \n  \n  Education and Qualifications: \n \n \n  Must have an active Secret Clearance \n  Master\u2019s Degree from an accredited program.  \n Twelve (12) years of related experience, including project management (e.g., Agile, PMBOK, etc.) \n \n  Preferred Skills \n \n  Knowledge of business and management principles involved in strategic planning, resource allocation, leadership technique, and coordination of people and resources. \n  Knowledge and application of change management methodologies. \n  Ability to work independently with minimal oversight. \n  Ability to think about a task or a problem in a new or different way. \n  Excellent oral and written skills \n  Identify complex problems and review related information to develop and evaluate options and implement solutions. \n  Strong data analysis skills with an ability to observe, receive, and otherwise obtain information from all relevant sources. \n \n \n  Pay Range: \n  \n   $120,000",
        "cleaned_desc": "  Knowledge and application of change management methodologies. \n  Ability to work independently with minimal oversight. \n  Ability to think about a task or a problem in a new or different way. \n  Excellent oral and written skills \n  Identify complex problems and review related information to develop and evaluate options and implement solutions. \n  Strong data analysis skills with an ability to observe, receive, and otherwise obtain information from all relevant sources. \n \n \n  Pay Range: ",
        "techs": [
            "change management methodologies",
            "independent work",
            "critical thinking",
            "oral and written skills",
            "problem identification and evaluation",
            "data analysis"
        ],
        "cleaned_techs": [
            "change management methodologies",
            "independent work",
            "critical thinking",
            "problem identification and evaluation"
        ]
    },
    "9f88e3a87a69903e": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 22.44,
        "salary_max": 24.64,
        "title": "EDI Analyst",
        "company": "Nava",
        "desc": "EDI Analyst \n Remote(Atlanta, GA) \n 12+ months, ongoing contract \n Job Requirements: \n \n 3+ years as an EDI Analyst with working knowledge of Order-to-Cash & Sales Order Processes and Transaction sets, including 850 \u2013 Purchase Order, 810 \u2013 Invoices, 855 \u2013 PO Confirmation) \n Experience with SAP iDOCs or Sterling Integrator would be a plus \n Ability to work part-time on as-needed basis (25-30 hours a week, regular work hours EST) \n Ability to work onsite in Atlanta would be a plus, not required \n \n Job Type: Part-time \n Pay: $22.44 - $24.64 per hour \n Expected hours: 25 \u2013 30 per week \n Experience level: \n \n 3 years \n \n Experience: \n \n EDI Analyst: 3 years (Preferred) \n Order-to-Cash & Sales Order Processes and Transaction sets: 3 years (Preferred) \n SAP iDOCs or Sterling Integrator: 1 year (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "6e895c9722d26137": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 70.0,
        "salary_max": -1.0,
        "title": "Sr Business Analyst- Local to Michigan - REMOTE",
        "company": "Sintra Technologies",
        "desc": "Role: Sr Business Analyst Location: Southfield, MI (Remote but local to MI only) Duration: Long Term \n Engagement Description: The Business Analyst Sr. is responsible for leading and/or supporting processes that ensure oversight and ongoing monitoring of Client Medicare Advantage and Part D programs. The primary duties of this role encompasses overseeing sales and enrollment processes to ensure compliance with CMS regulations for Medicare Advantage operations. Additionally, the position involves enhancing workflows and business processes to bolster controls, mitigate risk, and enhance overall quality and efficiency. Collaborating with both internal and external stakeholders, such as general agencies and professional associations, is a crucial aspect of this role. \n Responsibilities/Tasks: Compliance Monitoring: Ensure agents comply with CMS regulations and guidelines for selling and enrolling Medicare Advantage plans. \n Quality Assurance: Monitor and evaluate agent performance to ensure quality service and accurate information to potential beneficiaries. \n Policy Interpretation: Interpret and communicate Medicare policies and guidelines. \n Metric Tracking: Establish and track performance metrics to assess agent effectiveness and identify areas for improvement. \n Regulatory Updates: Stay informed about changes in Medicare policies and regulations to ensure agents remain compliant. \n Collaboration and Communication: Collaborate with cross-functional teams and communicate with stakeholders to ensure alignment and effectiveness in oversight. \n Documentation and Reporting: Maintain accurate records of agent activities, compliance efforts, and performance for reporting purposes. \n Process Improvement: Continuously identify and implement process improvements to enhance efficiency and effectiveness in oversight. \n Legal and Ethical Adherence: Ensure that agencies and agents adhere to legal and ethical standards in their interactions with beneficiaries. \n Risk Management: Identify and mitigate risks associated with agent activities to maintain compliance and protect the organization\u2019s reputation. \n This position description identifies the responsibilities and tasks typically associated with the performance of the position. Other relevant essential functions may be required. \n Top 3 Required Skills/Experience: \n Understanding of CMS regulations, policies and guidelines related to Medicare Advantage. \n Ability to provide constructive feedback and facilitate effective communication between agencies and various stakeholders. \n Excellent communication skills, both written and verbal, to effectively convey Medicare Advantage policies and guidelines to agencies, agents, and internal stakeholders. \n Required Skills/Experience \u2013 The rest of the required skills/experience. Include: Exhibits keen attention to detail. \n Skilled in utilizing current industry standard PC applications and systems (e.g., Access, Excel, Word, Teams, and Outlook). \n Proficiency in managing time and tasks effectively. \n Preferred Skills/Experience \u2013 Optional but preferred skills/experience. Include: Experience in monitoring and evaluating performance. \n Proficiency in working independently, collaboratively within a team, and adeptly managing multiple priorities. \n Proficiency in analyzing, consolidating, and effectively reporting information to both internal and external stakeholders. \n Education/Certifications \u2013 Include: \n Thanks and Regards, \n Mohammed Rayees \n Sr Recruiter, Urbane Systems LLC \n a: 13800 Coppermine Road, Herndon, VA - 20171 \n P: 5714177881 \n e: mohammed@urbanesystems.com \n s: www.urbanesystems.com \n Job Type: Contract \n Salary: From $70.00 per hour \n Experience level: \n \n 10 years \n \n Schedule: \n \n Monday to Friday \n \n Experience: \n \n Business Analyst: 10 years (Required) \n CMS: 5 years (Required) \n Medicare: 5 years (Required) \n stakeholders: 5 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "b68e2ee2ac58cb5f": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 56893.332,
        "salary_max": 72039.63,
        "title": "Data Visualization PowerPoint Specialist",
        "company": "Luminas",
        "desc": "Position \n  Data Visualization PowerPoint Specialist \n  We\u2019re looking for a talented and passionate visualization professional to join our virtual, growing team in the US as a Data Visualization PowerPoint Specialist. \n \n  Who we are: \n  Luminas, LLC is a full-service insights and market research company that helps to drive brands forward. We were founded in 2018 by a team of forward-thinking consultants. At Luminas, we pride ourselves on being a company where employee development, creativity, and kindness matter. Other benefits of joining our small and agile company include:  \n \n The opportunity to help influence and shape the company \n Access to company leadership \n A supportive close-knit culture \n \n \n \n  What we offer: \n \n Comprehensive benefits program (including medical, dental, and vision coverage) \n 401k program \n Unlimited vacation policy \n Company bonus program \n Full time remote working \n \n \n \n  Who we are looking for: \n \n  This position is responsible for transforming our Team\u2019s PowerPoint reports into impactful and visually engaging business presentations. We are seeking someone with a passion for visual design, attention to detail, and an eye for attractive and appealing layouts. Our growing Visualization Team has been recognized by our clients for their sleek and thoughtful designs. \n \n  Experience: \n \n \n \n Experience in designing PowerPoint presentations, preferably in a market research, analytics, or consulting firm \n Expert skill level designing and formatting charts in PowerPoint (along with basic knowledge of Excel)  \n Worked with videos (editing video, incorporating into PowerPoint) \n Skills in illustration with a working knowledge of Illustrator and Photoshop  \n Experience in animation, including 3D animation would be a plus  \n Excellent communication skills able to communicate complex ideas clearly and concisely \n Logically organize information and content \n High standards in terms of quality products and client service \n The ability to work proactively in a fast-paced virtual environment \n Enthusiastic, creative, proactive, and collaborative attitude \n \n \n \n   Job Responsibilities: \n \n \n \n  Responsible for designing, producing and updating PowerPoint presentations based on company style guidelines \n Produce client ready documents with minimal guidance. Includes interpretation of comments providing the right designs or layouts that ensure communication of messages  \n Transform and present data into charts and graphs \n Develop infographics \n Graphically streamline complex concepts \n Quality check documents thoroughly to ensure there are no errors in client deliverables \n Manage time effectively to meet deadlines  \n Accept feedback and make changes, updates, and improvements if required \n \n \n Contact :  To apply, submit your resume to JoinOurTeam@LuminasLLC.com \n \n \n  Luminas LLC is committed to diversity, equity, and inclusion and is an equal-opportunity employer. Applicants will be considered for employment, and all employment decisions will be made without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran, or disability status. Employment at Luminas is based solely on business needs, job requirements, and individual qualifications. We prohibit discrimination and harassment of any kind, live or virtual, in our workplace. This policy applies to all terms, conditions and privileges of employment, including recruitment, hiring, placement, compensation, promotion, discipline and termination.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "cf87bc729ea42b14": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 82943.586,
        "salary_max": 105025.055,
        "title": "BUSINESS ANALYST",
        "company": "Transition Technologies PSC Sp. z o. o.",
        "desc": "_ Business Analyst  \n \n \n \n _ What will you do? \n \n Responsibilities : \n  You will be a member of project team that implements ITSM solutions for external customers. The solution is based on third-party system and aligned with ITIL best practices. During the project you will combine the role of business analyst with ITSM specialist by: \n \n Working closely with external customers: identify needs, gather requirements and analyzing customer\u2019s expectations; \n Modeling business processes with focus on IT Service Management Area; \n Suggesting optimizations and areas for improvement; \n Hosting workshops and meetings with the customer, presenting solutions to stakeholders; \n Creating a concept of final solutions based on third-party vendors\u2019 systems; \n Participation in presales activities like assessing feasibility of the requirements and preparing content of the commercial offer; \n Close cooperation with technical teams; \n Verification whether delivered solution meets business needs; \n Collaboration within a team of business analysts. \n \n \n \n \n _ Who are we looking for? \n \n \n Requirements : \n \n Place of work: Poland \n At least 3 years of experience in IT Service Management (Service Manager, Service Delivery Manager, Service Desk Manager, Incident Manager, Asset Manager etc); \n Good knowledge of at least one of ITSM tool: ServiceNow, BMC, Atlassian/Jira, Manage Engine/Service Desk+; \n Very good understanding of ITIL concept, experience in working with ITIL best practices; \n Ability to suggest how to implement an ITIL-compliant processes in the organization; \n Strong communication and presentation skills; \n Ability to share knowledge, focus on learning new skills independently; \n Effective communication skills in English and Polish \u2013 at least (B2/C1) level; \n \n Nice to have : \n \n ITIL Certificate; \n Experience in Business Analysis or Project Management area; \n Technical IT background; \n Familiar with Jira and Confluence; \n Readiness to public presentations. \n \n \n \n \n \n \n \n \n _ Why is it worth it? \n \n \n What can we offer : \n \n Flexible forms of employment and working hours (CoE or B2B); \n An interesting, challenging job in the dynamically developing Capital Group company; \n Work on innovative projects using modern technologies; \n Direct impact on shaping the image of the Capital Group\u2019s companies on the market; \n Possibility to develop competences in a wide range; \n Attractive salary; \n Stability of employment and a friendly work atmosphere; \n Cool benefits, among others integration meetings, internal company competitions, fruit Tuesdays, sweet Thursdays and much more;",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "529b3e7ae357e873": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 70000.0,
        "salary_max": 130000.0,
        "title": "Sr. Business Analyst",
        "company": "Spatial Front, Inc.",
        "desc": "Description: \n   Project Overview: \n  The Sr. Business Analyst role is an integral team member who works with the various groups to support modernization efforts. For this role, the candidate will work directly with the customer and team members. They will be translating product strategy and roadmap into well-defined user stories, features, and enablers that will realize the product vision and improve the customer experience. Perform Scrum Master duties, meeting facilitation, and engage in bi-weekly testing of the completed user stories. \n  Agile/Scrum experience is a must have! \n  Primary responsibilities: \n \n  Analyze user needs to determine functional and cross-functional requirements throughout the standard development life cycle. \n  Collaborate with stakeholders and product teams to decompose large epic stories into features and user stories that can be understood and approved by members of the development team. \n  Document stories and manage backlog in Jira. \n  Provide product management support such as prioritization and backlog grooming \n  Provide analysis for associated tasks during the life cycle. \n  Coach the team to create better solutions, improve business results, and better their processes. \n  Facilitate team meetings, including Backlog Refinement / Iteration Planning / Daily Stand-Up / Iteration Review / Iteration Retrospective \n  Remove impediments and barriers to the team\u2019s progress. \n  Communicate and track agreed upon team metrics. \n  Support the Project Manager to communicate and coordinate meetings, presentations, and develop teamwork products. \n  Develop test cases. \n  Ensure requirements are tested and provide expected functionality. \n  Requirements: \n  \n Minimum of a bachelor\u2019s degree in related field. \n  At least five (5+) years of experience as Business Analyst and experience with User experience. \n  Minimum 2 years of experience managing IT software development as a Scrum Master. \n  Minimum 2 years of experience with application testing. \n  Must have experience working with Agile/Scrum. \n  Must have experience with Jira. \n  Strong work ethic, analytical and problem-solving skills with attention to detail. \n  Excellent communication skills. \n  SAFe Certification or equivalent Scrum Master Certification  preferred. \n \n  Additional Information: \n \n  In order to meet the clearance requirements for this opportunity, candidates must be a  US Citizen or Greencard Holder . \n  All candidates will be subject to a complete background check to include, but not limited to Criminal History, Education Verification, Professional Certification Verification, Verification of Previous Employment and Credit History. \n  Public Trust background investigations can take approximately four to eight weeks and requires fingerprinting. \n \n  Other Information: \n \n  The salary for this position is  $70,000 - $130,000  annually \n  For information on SFI's benefits please visit http://www.spatialfront.com/pages/career.html \n  This is a full-time W2 position. \n  Please no agencies, third parties, or corp-to-corp. \n  Spatial Front Inc. is an Equal-opportunity Employer, all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. \n  Spatial Front Inc. participates in E-Verify.",
        "cleaned_desc": "  Must have experience working with Agile/Scrum. \n  Must have experience with Jira. \n  Strong work ethic, analytical and problem-solving skills with attention to detail. \n  Excellent communication skills. \n  SAFe Certification or equivalent Scrum Master Certification  preferred. \n \n  Additional Information: \n ",
        "techs": [
            "agile/scrum",
            "jira",
            "safe certification",
            "scrum master certification"
        ],
        "cleaned_techs": [
            "agile/scrum",
            "jira",
            "safe certification",
            "scrum master certification"
        ]
    },
    "2d1c359b3439d3c3": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 62600.0,
        "salary_max": 94000.0,
        "title": "Revenue Operations Analyst, Strategy and Analytics",
        "company": "Articulate",
        "desc": "The Revenue Operations Analyst is a critical role responsible for leveraging data to drive strategic business outcomes. This position involves performing in-depth data analysis and generating actionable insights for key stakeholders, including Sales, Success, Channel, Marketing, and Finance leaders. Additionally, the role focuses on streamlining RevOps reporting and models, enhancing automation, and ensuring clear documentation of team processes. \n  The ideal candidate possesses 2-4 years of experience in revenue operations or a similar data-oriented role, a bachelor's degree, and proficiency in tools like Google Sheets, Excel, and Salesforce. They should be analytical, adaptable, and an excellent communicator, capable of working both independently and collaboratively in a remote environment. \n  What you'll do: \n \n Perform data analysis and create actionable insights based on interpretation of the results. \n Create highly visual dashboards and reports to communicate insights to stakeholders, which includes Sales, Success, Channel, Marketing, and Finance leaders. \n Solicit and collaborate with business stakeholders to understand what data and cascading information is most helpful in aiding strategic business outcomes. \n Support strategic initiatives by evaluating the impact of revenue-driving programs and advising stakeholders accordingly. \n Drive automation and efficiency of RevOps' reporting and models by identifying bottlenecks and streamlining data collection. \n Document RevOps team processes and procedures, ensuring clarity and consistency.   \n \n What you should have: \n \n Minimum 2-4 years experience in revenue operations, sales operations reporting and analysis, or a similar data-oriented position \n A four-year college degree or equivalent experience is required \n A team player who is comfortable in a human-centered organization \n Proficiency with Google Sheets or Excel to perform complex data analysis and reporting \n Demonstrated skill in using data to identify trends, draw conclusions, and make strategic recommendations. \n Knowledge and experience in the use of Salesforce.com for revenue-generating teams, as well as building reports in Salesforce.com \n An analytical mind with the ability to tie business needs and desired outcomes to the data \n Self-starter motivated by intellectual curiosity, eager to learn and adapt to new tools and processes \n Excellent organizational and time management skills \n Self-motivated in a remote environment with the ability to work independently while also functioning and contributing as part of a team \n Skilled in building strong relationships across an organization and communicating complex information both written and verbally \n \n You're the ideal candidate if: \n \n Experience working for a SaaS organization, understanding PLG business models and best practices \n Experience with data visualization tools (Looker, Tableau) \n \n The pay range for this position is $62,600 to $94,000 for all US locations. Articulate takes into consideration a wide range of factors that are utilized in making compensation decisions including, but not limited to, skill sets, experience and training, licensure and certifications, qualifications and education, and other business and organizational needs. This position is also bonus eligible. Articulate also offers a robust suite of benefits, check out the website for a full list. \n  About us \n \n  Articulate Global, LLC, is the leading SaaS provider of creator platforms for online workplace training. Founded by Adam Schwartz in 2002, Articulate provides creator tools and services that make it simple for enterprises and SMBs to develop, deliver, and analyze online workplace training that's engaging and effective.\n  \n \n \n  Increasingly, organizations must reskill employees for ever-changing remote and hybrid work environments, create learning cultures that attract and retain employees in a tight labor market, and use training to build more equitable, empowering, and engaging workplaces. Articulate helps organizations address these critical business needs with its creator platform for workplace training. Articulate 360\u2014a suite of creator tools for online courses\u2014was named the 7th most-loved product in the world by TrustRadius in 2021. And Rise\u2014an all-in-one online training system that makes online training easy to create, enjoyable to take, and simple to manage\u2014is the first creator platform for SMBs and departments within the enterprise. Articulate has more than 118,000 customers in 170 countries and counts all 100 of the Fortune 100 companies as customers.\n  \n \n \n  Named one of Inc. Magazine's Best Workplaces 2022 and a leader in building a human-centered organization, Articulate is guided by a commitment to provide the best value to customers, do right by employees, and create an equitable, empowering workplace for all. As a human-centered organization, we honor people's humanity knowing that each person's unique history, vulnerabilities, and social location inform how we show up with one another. We embrace our connectedness, aware that what we do and say impacts others. We give each other grace because we are all works in progress, learning and evolving every day. And we take responsibility for ourselves and are serious about our accountability to each other. In all we do, we strive to create an equitable, sustainable, and empowering workplace while we drive results for the business and make a positive impact in the world. Read more about our values here.\n  \n \n \n  Articulate welcomes different voices and viewpoints and does not discriminate on the basis of race, religion, color, national origin, ancestry, physical and/or mental disability, medical condition, native language, pregnancy status, physical size, genetic information, marital status, sex, gender, gender identity, gender expression, transgender status, age, sexual orientation, and military or veteran status, or any other basis protected by law. We are an equal opportunity employer and invite applicants to voluntarily disclose their race and gender on our application form to help us create a diverse company. This voluntarily disclosed information will not be shared with any hiring manager and will be kept in confidence by the Articulate human resources department and executives who are not hiring for this position.\n  \n \n \n (For information about Articulate's privacy practices, please view our  Privacy Notice\n   )",
        "cleaned_desc": " \n What you should have: \n \n Minimum 2-4 years experience in revenue operations, sales operations reporting and analysis, or a similar data-oriented position \n A four-year college degree or equivalent experience is required \n A team player who is comfortable in a human-centered organization \n Proficiency with Google Sheets or Excel to perform complex data analysis and reporting \n Demonstrated skill in using data to identify trends, draw conclusions, and make strategic recommendations. \n Knowledge and experience in the use of Salesforce.com for revenue-generating teams, as well as building reports in Salesforce.com \n An analytical mind with the ability to tie business needs and desired outcomes to the data   Self-starter motivated by intellectual curiosity, eager to learn and adapt to new tools and processes \n Excellent organizational and time management skills \n Self-motivated in a remote environment with the ability to work independently while also functioning and contributing as part of a team \n Skilled in building strong relationships across an organization and communicating complex information both written and verbally \n \n You're the ideal candidate if: \n \n Experience working for a SaaS organization, understanding PLG business models and best practices \n Experience with data visualization tools (Looker, Tableau) \n ",
        "techs": [
            "google sheets",
            "excel",
            "salesforce.com",
            "looker",
            "tableau"
        ],
        "cleaned_techs": [
            "google sheets",
            "excel",
            "salesforce.com",
            "looker",
            "tableau"
        ]
    },
    "748bdcb0f9557c4f": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 66300.0,
        "salary_max": 119850.0,
        "title": "Functional Business Analyst",
        "company": "Leidos",
        "desc": "Description   \n The Functional Business Analyst is expected to develop functional expertise in various aspects of the delivery lifecycle including: \n  This role is a fully telecommuting role - must currently reside in the US and have resided in the US for three consecutive years. \n  Requires US Citizen or US Person (Green Card Holder) and Ability to Obtain Public Trust clearance \n \n \n Participating in requirements sessions, creating general designs, performing assembly testing, and supporting development efforts for multiple functional areas within team \n Providing functional support to Developers and System Analysts \n Supporting the resolution of production issues and data cleanup efforts through functional analysis and testing \n \n \n  Required Experience: \n  BS degree and 4+ years of prior relevant experience. \n  4 yrs of additional experience can be considered in lieu of degree \n \n Experience with software development and maintenance practices and methodologies (especially requirements, design, and testing phases) \n Knowledge of information systems and current computer technology. \n Working as a member of an Agile development team. \n Experience with business analyst in support of software development projects \n Hands on experience with gathering & documenting requirements, facilitating discussion with Product Owners, managing requirement backlog, translating requirements into technical specifications, writing user stories, contributing to system design, and testing software releases \n Knowledge of information systems and current computer technology. \n Working as a member of an Agile development team. \n Experience with JIRA \n \n \n  Desired: \n  Previous experience working with Azure platform and tools \n  Experience working on cloud migration projects \n \n Knowledge of information systems and current computer technology a plus. \n Familiarity with SQL, XML, and Oracle environment a plus. \n Familiarity with web and reporting technology also a plus \n Experience in Public Health \n Familiarity with SQL environment a plus. \n Previous experience working at CDC or other HHS divisions \n \n  hhscdc \n \n  Pay Range:  Pay Range $66,300.00 - $119,850.00\n  \n  The Leidos pay range for this job level is a general guideline only and not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other law. \n  #Remote",
        "cleaned_desc": " Supporting the resolution of production issues and data cleanup efforts through functional analysis and testing \n \n \n  Required Experience: \n  BS degree and 4+ years of prior relevant experience. \n  4 yrs of additional experience can be considered in lieu of degree \n \n Experience with software development and maintenance practices and methodologies (especially requirements, design, and testing phases)   \n  Desired: \n  Previous experience working with Azure platform and tools \n  Experience working on cloud migration projects \n \n Knowledge of information systems and current computer technology a plus. \n Familiarity with SQL, XML, and Oracle environment a plus. \n Familiarity with web and reporting technology also a plus ",
        "techs": [
            "azure platform and tools",
            "sql",
            "xml",
            "oracle"
        ],
        "cleaned_techs": [
            "azure",
            "sql",
            "xml",
            "oracle"
        ]
    },
    "b90a635284c1ccfd": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 70000.0,
        "salary_max": 90000.0,
        "title": "Toast POS Sr. Analyst",
        "company": "The Placement Gurus",
        "desc": "Our client is a dynamic and fast-growing restaurant technology consulting firm dedicated to providing exceptional support to their restaurant clientele. They are currently seeking a skilled and detail-oriented Toast POS Sr. Analyst to join their team. As a Toast POS Sr. Analyst, you will play a crucial role in ensuring the smooth operation and optimization of the restaurants\u2019 Toast Point of Sale (POS) system and integration with Restaurant365, enabling our client to deliver top-notch service to their customers. \n KEY RESPONSIBILITIES: \n \n Configure and maintain Toast POS system to meet the specific needs of our restaurant(s). \n Ensure all menu items, pricing, and promotions are accurately reflected in the system. \n Regularly update software and firmware to ensure optimal performance and security. \n Provide technical support and training to restaurant staff on the proper use of the Toast POS system. \n Troubleshoot and resolve any issues related to the POS system promptly. \n Develop training materials and conduct training sessions for new employees. \n Utilize the POS system's reporting features to gather data on sales, customer preferences, and inventory levels. \n Analyze data to identify trends, optimize menu offerings, and enhance overall operational efficiency. \n Generate customized reports for management to aid in decision-making processes. \n Implement and maintain security protocols to safeguard customer data and payment information. \n Stay up-to-date with industry standards and regulations related to POS system security and compliance. \n Integrate the Toast POS system with other business applications, such as Restaurant 365. \n Collaborate with third-party vendors to customize and enhance system functionalities based on business requirements. \n Maintain comprehensive documentation of system configurations, troubleshooting procedures, and user guides. \n Document any system modifications or customizations for future reference. \n \n REQUIREMENTS: \n \n Proven experience as a Toast POS System Administrator or similar role in a restaurant or hospitality setting. \n Proficiency in configuring and maintaining Toast POS systems. \n Strong analytical and problem-solving skills. \n Excellent communication and interpersonal skills for providing user support and training. \n Strong knowledge of restaurant operations and workflow. \n Familiarity with security protocols and compliance standards related to POS systems. \n Ability to work collaboratively with cross-functional teams and third-party vendors. \n Attention to detail and strong organizational skills. \n \n Job Type: Full-time \n Pay: $70,000.00 - $90,000.00 per year \n Benefits: \n \n 401(k) \n 401(k) matching \n Employee discount \n Flexible schedule \n Life insurance \n Tuition reimbursement \n \n Schedule: \n \n Monday to Friday \n \n Work Location: Remote",
        "cleaned_desc": " \n REQUIREMENTS: \n \n Proven experience as a Toast POS System Administrator or similar role in a restaurant or hospitality setting. \n Proficiency in configuring and maintaining Toast POS systems. \n Strong analytical and problem-solving skills. \n Excellent communication and interpersonal skills for providing user support and training. \n Strong knowledge of restaurant operations and workflow. \n Familiarity with security protocols and compliance standards related to POS systems. ",
        "techs": [
            "toast pos system"
        ],
        "cleaned_techs": [
            "toast pos system"
        ]
    },
    "0cb91fdbe88a6e99": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 75113.39,
        "salary_max": 95110.28,
        "title": "Insurance Product Business Analyst",
        "company": "Cypress Property & Casualty Insurance Company",
        "desc": "Jacksonville, FL (or remote) \n \n \n Description: \n  This role can be filled as an Insurance Product Business Analyst or Senior Insurance Product Business Analyst, \n depending on experience. \n \n  We are seeking an Insurance Product Business Analyst with P&C industry expertise to support our \n Insurance Product Management Team. The Insurance Product Business Analyst will work closely \n with product managers, business analysts, compliance, and external departments on ensuring that \n new and current programs, features and processes scale efficiently. \n \n \n Responsibilities: \n \n \n Partners with multiple stakeholders to gather and document requirements for new product implementation and current product improvements. \n Assists with designing test cases and executing user acceptance testing, along with identifying and resolving defects when necessary. \n Assists with creation and maintenance of product specification documents for new and existing products. \n Tracks outstanding issues, implementation timelines and communicates project progression to stakeholders. \n Completes Post-Production review of implemented product changes along with regression testing of existing functionality. \n Assists with identifying system and workflow enhancements. \n Research new and emerging technologies and assist with providing recommendations to the Product Management Team. \n Assists with other projects as needed. \n \n Requirements: \n \n \n 2 or more years of experience as a business, compliance or product analyst in the insurance industry preferred \n 1 or more years of experience working with Homeowners LOB preferred \n Related insurance coursework (i.e., CPCU, AINS, etc) preferred \n Proficiency in Microsoft Applications \n Excellent written and verbal communication skills \n Passion for accuracy and close attention to detail \n Strong organizational and problem-solving skills \n Ability to work independently, escalating non-routine issues with recommendations for solutions \n Desire to learn and highly motivated self-starter",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "4d7ed7f3f70029c7": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 31.39,
        "salary_max": 45.0,
        "title": "Business Analyst on W2",
        "company": "Vortalsoft Inc",
        "desc": "Responsibilities: - Collaborate with stakeholders to gather and document business requirements - Analyze and translate business needs into functional requirements - Conduct data analysis and perform ETL (Extract, Transform, Load) processes - Develop and maintain project documentation, including business process flows, use cases, and user stories - Assist in the design and implementation of database structures and data models - Perform system testing and support user acceptance testing - Provide ongoing support and troubleshooting for business applications - Participate in Agile development methodologies and ceremonies - Utilize tools such as Visio, SQL, VBA, and other relevant software for data analysis and reporting \n Qualifications: - Bachelor's degree in Business Administration, Computer Science, or related field - Proven experience as a Business Analyst or similar role - Strong analytical skills with the ability to analyze complex business processes - Proficient in SQL for data analysis and querying databases - Familiarity with Agile methodologies and SDLC (Software Development Life Cycle) - Knowledge of ETL processes and database design principles - Experience with project management tools and techniques - Excellent communication skills with the ability to effectively collaborate with cross-functional teams \n We offer competitive compensation packages, including benefits such as health insurance, retirement plans, and professional development opportunities. Join our team of talented Business Analysts and contribute to the success of our organization. Apply now! \n Job Type: Contract \n Pay: $31.39 - $45.00 per hour \n Experience: \n \n .NET: 1 year (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": "Responsibilities: - Collaborate with stakeholders to gather and document business requirements - Analyze and translate business needs into functional requirements - Conduct data analysis and perform ETL (Extract, Transform, Load) processes - Develop and maintain project documentation, including business process flows, use cases, and user stories - Assist in the design and implementation of database structures and data models - Perform system testing and support user acceptance testing - Provide ongoing support and troubleshooting for business applications - Participate in Agile development methodologies and ceremonies - Utilize tools such as Visio, SQL, VBA, and other relevant software for data analysis and reporting   Qualifications: - Bachelor's degree in Business Administration, Computer Science, or related field - Proven experience as a Business Analyst or similar role - Strong analytical skills with the ability to analyze complex business processes - Proficient in SQL for data analysis and querying databases - Familiarity with Agile methodologies and SDLC (Software Development Life Cycle) - Knowledge of ETL processes and database design principles - Experience with project management tools and techniques - Excellent communication skills with the ability to effectively collaborate with cross-functional teams ",
        "techs": [
            "visio",
            "sql",
            "vba",
            "agile methodologies",
            "sdlc",
            "etl processes",
            "database design principles",
            "project management tools"
        ],
        "cleaned_techs": [
            "visio",
            "sql",
            "vba",
            "agile methodologies",
            "sdlc",
            "etl processes",
            "database design principles",
            "project management tools"
        ]
    },
    "e30c9a55a9e5ad6d": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 65189.64,
        "salary_max": 82544.61,
        "title": "Business Analyst (E-commerce)",
        "company": "Nagarro",
        "desc": "Full-time \n  Service Region: Eastern Europe \n \n \n \n \n \n  Company Description \n \n \n  We're Nagarro. \n  We are a digital product engineering company that is scaling in a big way! We build products, services, and experiences that inspire, excite, and delight. We work at scale \u2014 across all devices and digital mediums, and our people exist everywhere in the world (19,000+ experts across 35 countries, to be exact). Our work culture is dynamic and non-hierarchical. We're looking for great new colleagues. That's where you come in! \n  By this point in your career, it is not just about the tech you know or how well you can code. It is about what more you want to do with that knowledge. Can you help your teammates proceed in the right direction? Can you tackle the challenges our clients face while always looking to take our solutions one step further to succeed at an even higher level? Yes? You may be ready to join us. \n \n \n \n \n \n  Job Description \n \n \n \n  Works on RFP/RFI/RFQ responses to understand business needs \n  Works on projects as Product Owner or Proxy Product Owner \n  Clearly communicates business needs of the client to development teams \n  Clearly communicates solutions to business needs to client \n  Creates and maintains business needs documentation \n  Advocates and uses Business Analysis techniques. Educates the client and teams if required \n  Equally comfortably works in Agile and Waterfall project setups \n  Participates in project governance responsible for requirements traceability \n  Occasionally travels to client locations for sales pitches \n \n \n \n \n \n \n  Qualifications \n \n \n \n  University degree or equivalent \n  Experience working on B2B and B2C E-Commerce solutions as Business Analyst \n  Domain knowledge in one or more of the following is an advantage: Retail, Automotive, Telecom, CPG \n  Excellent written and verbal English. \n  German language is an advantage \n  Strong soft skills and ability to listen is a must \n \n \n \n \n \n \n  Domain certifications are an advantage",
        "cleaned_desc": " \n  University degree or equivalent \n  Experience working on B2B and B2C E-Commerce solutions as Business Analyst \n  Domain knowledge in one or more of the following is an advantage: Retail, Automotive, Telecom, CPG \n  Excellent written and verbal English. \n  German language is an advantage \n  Strong soft skills and ability to listen is a must \n \n \n ",
        "techs": [
            "university degree or equivalent",
            "b2b and b2c e-commerce solutions",
            "business analyst",
            "retail",
            "automotive",
            "telecom",
            "cpg",
            "excellent written and verbal english",
            "german language",
            "strong soft skills"
        ],
        "cleaned_techs": [
            "b2b and b2c e-commerce solutions",
            "retail",
            "automotive",
            "telecom",
            "cpg",
            "excellent written and verbal english",
            "german language"
        ]
    },
    "35aa4451914efec3": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 60.0,
        "salary_max": 65.0,
        "title": "Senior EDI Analyst",
        "company": "R4 Talent Solutions Inc",
        "desc": "Need 10+ Years Experience \n Mandatory Skill: Good knowledge on EDI 27x, 837, 835 \n Job Description: \n We are seeking a highly skilled and motivated EDI Analyst to join our team. The successful candidate will play a crucial role in ensuring the smooth operation of our EDI (Electronic Data Interchange) systems and processes, particularly within the healthcare industry. If you have a strong background in EDI, SQL, EDI transaction validation, and possess a good understanding of healthcare claims workflow, we encourage you to apply. \n Responsibilities: \n \n Perform analysis, design, development, testing, and implementation of EDI solutions within the healthcare domain. \n Collaborate with cross-functional teams to gather and document EDI requirements specific to healthcare operations. \n Monitor and maintain EDI transaction processes in the healthcare sector to ensure data accuracy and integrity. \n Troubleshoot and resolve EDI transaction issues related to healthcare data in a timely manner. \n Develop and optimize SQL queries to extract, manipulate, and validate healthcare-related data. \n Conduct thorough testing and validation of EDI transactions in the healthcare industry to meet business needs. \n Maintain EDI documentation for healthcare processes and provide training to end-users as needed. \n Stay up-to-date with industry standards and best practices related to EDI in healthcare. \n Assist in the design and implementation of EDI-related enhancements and improvements in healthcare settings. \n Participate in on-call support rotation as required. \n \n Qualifications: \n \n Bachelor's degree in Computer Science, Information Technology, or a related field preferred. \n Minimum 8 years of experience in EDI analysis and support within the healthcare sector. \n Proficiency in EDI standards and protocols, particularly in healthcare. \n Strong SQL skills for data extraction and manipulation. \n Good knowledge of claims and or eligibility workflow in the healthcare payer industry. \n Excellent problem-solving and analytical skills within healthcare contexts. \n Detail-oriented with a strong commitment to data accuracy in healthcare data. \n Effective communication and interpersonal skills. \n Ability to work independently and as part of a team. \n Relevant certifications or training related to healthcare EDI are a plus. \n \n Job Type: Contract \n Salary: $60.00 - $65.00 per hour \n Experience level: \n \n 10 years \n \n Experience: \n \n SQL: 1 year (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": " \n Qualifications: \n \n Bachelor's degree in Computer Science, Information Technology, or a related field preferred. \n Minimum 8 years of experience in EDI analysis and support within the healthcare sector. \n Proficiency in EDI standards and protocols, particularly in healthcare. \n Strong SQL skills for data extraction and manipulation. \n Good knowledge of claims and or eligibility workflow in the healthcare payer industry. ",
        "techs": [
            "edi analysis",
            "edi support",
            "healthcare sector",
            "edi standards",
            "edi protocols",
            "sql skills"
        ],
        "cleaned_techs": [
            "edi analysis",
            "edi support",
            "healthcare sector",
            "edi standards",
            "edi protocols"
        ]
    },
    "b497c66999433ca1": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 85874.88,
        "salary_max": 108736.74,
        "title": "SR. BUSINESS ANALYST - REMOTE POSITION",
        "company": "Agiliko",
        "desc": "Sr. Business Analyst \n 100% Remote Position \n U.S. Citizenship Required \n Agiliko is seeking a Sr. Business Analyst to join its team of professionals supporting one of our long-term Federal government clients whom we are responsible for developing and maintaining their enterprise applications, data analytics platform and internal and external websites. For this position we are seeking an experienced Sr. Business Analyst for the O&M phase of the agency\u2019s COTS-based Examination system. This opportunity is available for an experienced, motivated Sr. Business Analyst with experience in IT projects. Below is a sampling of the Sr. Business Analyst duties, responsibilities and requirements: \n Responsibilities: \n \u00b7 Lead project from prioritization through concept development and user story writing to supporting development and deployment. \n \u00b7 Work with government leads to manage scope of new project enhancement requests. \n \u00b7 Work with Product Owner and users to determine operational objectives of business needs and elicit requirements. \n \u00b7 Identify core business needs and decompose and document in concepts of operations, story maps, briefings, and user stories; document business rules and construct workflow diagrams. \n \u00b7 Effectively communicate and collaborate with system owners, software developers, and other stakeholders to understand product details and translate them to technical specifications. \n \u00b7 Conduct meetings with system owners, developers, and other stakeholders to gather necessary information for technical documentation. \n \u00b7 Work with government leads to manage scope of new project enhancement requests \n \u00b7 Work with Product Owner and users to determine operational objective of business needs and elicit requirements. \n \u00b7 Identify core business needs and decompose and document in concepts of operation, story maps, briefings and user stories; document business rules and construct workflow diagrams as needed. \n \u00b7 Presents formal and informal oral and written briefings to government managers. \n \u00b7 Review and revise documents to ensure clarity, consistency, and quality. \n \u00b7 Prioritize and manage multiple deliverables simultaneously while maintaining close attention to detail and meeting tight deadlines. \n \u00b7 Other duties as assigned by client. \n Job Requirements: \n \u00b7 Bachelor\u2019s degree in Computer Science, Information Science, Management Information Systems, Math, Statistics, Operations Research or Engineering \n \u00b7 Proven experience as a BA in the IT industry, preferably  with a focus on COTS applications  with a Federal Agency. \n \u00b7 8 + years of experience as a IT Business Analyst in  an application development environment . \n \u00b7 Experience leading projects from prioritization through concept development and user story writing to supporting development and deployment \n \u00b7 Ability to translate and present complex business processes into clear and actionable user stories with thorough acceptance criteria into clear, concise documentation for a variety of audiences. \n \u00b7 Able to present formal and informal oral and written briefings to government managers \n \u00b7 Strong organizational skills and ability to manage multiple tasks simultaneously. \n \u00b7 Proven ability to maintain high levels of accuracy and precision in fast-paced environments, demonstrating exceptional attention to detail. \n \u00b7 Demonstrated ability to proactively identify opportunities, take initiative, and implement solutions to drive organizational success. \n \u00b7 Strong analytical skills with a proven track record of effectively solving complex problems and implementing innovative solutions. \n \u00b7 Experience in an Agile application development environment is preferred. \n \u00b7 Experience with MetricStream is a plus. \n \u00b7  Excellent written and verbal English communication with exceptional grammar and punctuation skills. \n Location : This is a 100% remote position, however, you m ust be based in the U.S. and be willing and able to work 8 AM \u2013 5 PM Eastern, Monday through Friday. \n Other Requirements:  U.S. citizen (Sorry, we cannot consider H1-B\u2019s, Green Cards or dual citizenships)  must be able to obtain a U.S. Government Public Trust Clearance and pass a Credit Check. \n About Agiliko: \n In 2021 and 2022 we were named a Fastest Growing Company by The Washington Business Journal. This year, we are proud to have been named a Best Places to Work also by The Washington Business Journal. At Agiliko, we believe that of the many challenges facing executives today, paramount is the alignment of IT with business strategy & operations. With offices in Washington, DC and Alexandria, VA, we are a rapidly growing IT consulting HUBZone Certified small business that helps CIOs & IT executives build compelling strategy, establish transformational operations, and employ impactful software solutions. Our clients range from small businesses to large federal agencies and Fortune 50 corporations. We partner with IT executives to transform their teams into an agile, high performing organization through: Data Analytics, Application Development, Web and Mobile Solutions, IT Infrastructure, and Strategic IT Advisory Services. We provide a Customer/Employee centric culture along with competitive compensation and terrific benefits to include medical, dental, vision, life and disability insurance, tuition reimbursement, 401K and training opportunities. \n Agiliko is proud to be an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. \n Job Type: Full-time \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Flexible schedule \n Flexible spending account \n Health insurance \n Health savings account \n Life insurance \n Paid time off \n Professional development assistance \n Tuition reimbursement \n Vision insurance \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Application Question(s): \n \n Do you currently reside in the U.S.? Please respond YES or NO \n \n Education: \n \n Bachelor's (Required) \n \n Experience: \n \n IT Business Analysis and Requirements: 8 years (Required) \n IT BA & Requirements capture on an IT -related project: 8 years (Required) \n IT BA in an Application Development Environment: 8 years (Required) \n leading App. Dev. Projects from beginning to end: 5 years (Required) \n MetricStream: 1 year (Preferred) \n Software Dev. Lifecycle: 8 years (Required) \n \n License/Certification: \n \n US CITIZEN? (No H1 B's, Green Cards or Dual Citizenships) (Required) \n \n Work Location: Remote",
        "cleaned_desc": " \u00b7 Review and revise documents to ensure clarity, consistency, and quality. \n \u00b7 Prioritize and manage multiple deliverables simultaneously while maintaining close attention to detail and meeting tight deadlines. \n \u00b7 Other duties as assigned by client. \n Job Requirements: \n \u00b7 Bachelor\u2019s degree in Computer Science, Information Science, Management Information Systems, Math, Statistics, Operations Research or Engineering \n \u00b7 Proven experience as a BA in the IT industry, preferably  with a focus on COTS applications  with a Federal Agency. \n \u00b7 8 + years of experience as a IT Business Analyst in  an application development environment . \n \u00b7 Experience leading projects from prioritization through concept development and user story writing to supporting development and deployment \n \u00b7 Ability to translate and present complex business processes into clear and actionable user stories with thorough acceptance criteria into clear, concise documentation for a variety of audiences. \n \u00b7 Able to present formal and informal oral and written briefings to government managers \n \u00b7 Strong organizational skills and ability to manage multiple tasks simultaneously. \n \u00b7 Proven ability to maintain high levels of accuracy and precision in fast-paced environments, demonstrating exceptional attention to detail. \n \u00b7 Demonstrated ability to proactively identify opportunities, take initiative, and implement solutions to drive organizational success. \n \u00b7 Strong analytical skills with a proven track record of effectively solving complex problems and implementing innovative solutions. \n \u00b7 Experience in an Agile application development environment is preferred. ",
        "techs": [
            "review and revise documents",
            "prioritization through concept development and user story writing",
            "application development environment",
            "translate complex business processes",
            "oral and written briefings",
            "organizational skills",
            "accuracy and precision",
            "proactive identification of opportunities",
            "analytical skills",
            "agile application development environment"
        ],
        "cleaned_techs": [
            "review and revise documents",
            "prioritization through concept development and user story writing",
            "application development environment",
            "translate complex business processes",
            "oral and written briefings",
            "accuracy and precision",
            "proactive identification of opportunities",
            "agile application development environment"
        ]
    },
    "9aa3a90666dd54bc": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 52100.0,
        "salary_max": 119000.0,
        "title": "Business Analyst, Mid",
        "company": "Booz Allen Hamilton",
        "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Arlington,VA,US \n         \n \n \n \n         Remote Work: \n         \n \n         Hybrid \n         \n \n \n \n         Job Number: \n         \n \n         R0182436\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Business Analyst, Mid\n           The Opportunity: \n  You know that true progress is made at the intersection of business and tech, and as an IT Business Analyst, you can develop your skills in both. Here, you\u2019ll have the chance to work with an Agile team as they develop digital products to support your clients\u2019 most pressing missions. We\u2019re looking for someone like you to help propel business analytics and processes forward, as well as delve into technology trends to deliver user-friendly client experiences. \n \n  As an IT Business Analyst, you\u2019ll develop leading-edge products. Partnering with your team of business analysts, developers, data analysts and user experience specialists you\u2019ll identify clients\u2019 business needs, gather user requirements, and develop user stories. You\u2019ll understand the overall direction and nuanced user needs clearly, and you\u2019ll lead your team as they fulfill these needs by creating deployable features. Together, you\u2019ll deliver high business value products to our client. Ready to make an impact by modernizing a legacy system into a flexible, scalable modern web application that aligns with strategic transformation initiatives? \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  2+ years of experience with requirements analysis \n  Experience with requirements management tools, such as JIRA \n  Experience with distilling complex business processes into clear and actionable user stories with thorough acceptance criteria \n  Ability to gather requirements, analyze data and conduct in-depth analysis of business workflows to identify areas of improvement and determine solutions for issues \n  Ability to facilitate current-state mapping sessions and conduct user or stakeholder interviews \n  Secret clearance \n  Bachelor's degree \n \n \n  Nice If You Have: \n \n  Experience in working with federal and DoD organization \n  Experience with identifying and assessing customer needs \n  Experience with presenting recommendations to product owners based on findings \n  Experience with Microsoft Excel \n  Knowledge of several Agile frameworks, including Kanban, Scrum, XP, Lean, DevOps, or SAFe \n  Possession of excellent verbal and written communication skills \n \n \n  Clearance:   \n Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. \n \n  Create Your Career: \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll build your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $52,100.00 to $119,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",
        "cleaned_desc": "  Ability to gather requirements, analyze data and conduct in-depth analysis of business workflows to identify areas of improvement and determine solutions for issues \n  Ability to facilitate current-state mapping sessions and conduct user or stakeholder interviews \n  Secret clearance \n  Bachelor's degree \n \n \n  Nice If You Have: \n \n  Experience in working with federal and DoD organization \n  Experience with identifying and assessing customer needs \n  Experience with presenting recommendations to product owners based on findings \n  Experience with Microsoft Excel \n  Knowledge of several Agile frameworks, including Kanban, Scrum, XP, Lean, DevOps, or SAFe \n  Possession of excellent verbal and written communication skills \n \n \n  Clearance:   \n Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. \n \n  Create Your Career: \n  Grow With Us ",
        "techs": [
            "gather requirements",
            "analyze data",
            "conduct in-depth analysis",
            "current-state mapping sessions",
            "user interviews",
            "stakeholder interviews",
            "federal organization",
            "dod organization",
            "presenting recommendations",
            "microsoft excel",
            "agile frameworks",
            "kanban",
            "scrum",
            "xp",
            "lean",
            "devops",
            "safe",
            "secret clearance"
        ],
        "cleaned_techs": [
            "gather requirements",
            "analyze data",
            "conduct in-depth analysis",
            "current-state mapping sessions",
            "user interviews",
            "stakeholder interviews",
            "federal organization",
            "dod organization",
            "presenting recommendations",
            "excel",
            "agile frameworks",
            "kanban",
            "scrum",
            "xp",
            "lean",
            "devops",
            "safe",
            "secret clearance"
        ]
    },
    "9cfdb67d4c935e38": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 63926.07,
        "salary_max": 80944.65,
        "title": "CRM Data Analyst Remote",
        "company": "Terminix",
        "desc": "Job Summary:  \n In this role you will work together with CRM strategists and a data manager to help produce, test and report upon complex cross-platform digital customer journeys. Your work will help develop new tests and continually work to optimize customer communications, so we ensure we\u2019re giving our customers what they need, when they want, how they want. You are a highly motivated problem solver with a curious mind and exceptional attention to detail and organization. You have extensive experience collecting large sets of data from multiple sources and cleaning for analysis. You are fluent in Excel, Power BI, Tableau, or a similar platform. You are not afraid to ask questions, provide solutions, and you\u2019re quick to learn from your mistakes. \n \n  Principal Duties and Responsibilities:  \n \n Help construct, perform, and analyze testing for pilots, campaigns, and tactics \n  Report on cross-platform marketing and loyalty initiative performance, pulling results from disparate online platforms \n  Provide insights to colleagues and leadership questions on an ad hoc, rolling basis \n  Proficiency in data analysis and reporting using CRM tools or other data analysis software \n  Effective communication and interpersonal skills to interact with a diverse group of stakeholders \n  Project management experience with the ability to prioritize tasks and manage deadlines effectively \n  Make recommendations to improve marketing performance based on the campaign results \n \n \n  Key Relationships:  \n \n North American managers and colleagues \n  Functional teams: Marketing & Innovation, IT, Finance, Legal, and M&A, etc. \n  Key suppliers, partners, and consultants. \n \n \n  Key Performance Indicators: \n \n  Customer retention rate \n  Customer Lifetime Value \n  Deliverability and email metrics \n  Monthly active users \n  Repeat purchase rate \n \n \n  Required experience: \n \n  3+ years experience in marketing data analysis \n  A/B testing cohort segmentation \n  Experience using enterprise-level ESP, like Salesforce Marketing Cloud \n  Detail-oriented \n  Highly organized \n  Previous customer service experience a plus \n  Power BI or Google Analytics experience a plus \n  Strong collaboration and interpersonal skills to work with teams from Product, IT, Data Architecture, and Finance \n \n \n  Required Leadership Traits and Characteristics:  \n \n Strives towards making a positive impact on society and the environment across the Marketing spectrum, establishing Rentokil Terminix as a leader in this space \n  Able to demonstrate high levels of drive, work ethic and personal accountability with the ability to work under pressure while maintaining sound judgement and a rigorous focus on the details. \n \n \n  Formal Education, Qualifications or Training  \n \n 3 years of hands-on marekting analytics experience \n \n \n  Our companies are proud to be Affirmative Action (AA) and Equal Opportunity Employers (EOE) inclusive of veterans and those with disabilities. \n \n  California residents  click here  to review your privacy rights.  tinyurl.com/CANotice2023",
        "cleaned_desc": "Job Summary:  \n In this role you will work together with CRM strategists and a data manager to help produce, test and report upon complex cross-platform digital customer journeys. Your work will help develop new tests and continually work to optimize customer communications, so we ensure we\u2019re giving our customers what they need, when they want, how they want. You are a highly motivated problem solver with a curious mind and exceptional attention to detail and organization. You have extensive experience collecting large sets of data from multiple sources and cleaning for analysis. You are fluent in Excel, Power BI, Tableau, or a similar platform. You are not afraid to ask questions, provide solutions, and you\u2019re quick to learn from your mistakes. \n \n  Principal Duties and Responsibilities:  \n \n Help construct, perform, and analyze testing for pilots, campaigns, and tactics \n  Report on cross-platform marketing and loyalty initiative performance, pulling results from disparate online platforms \n  Provide insights to colleagues and leadership questions on an ad hoc, rolling basis \n  Proficiency in data analysis and reporting using CRM tools or other data analysis software \n  Effective communication and interpersonal skills to interact with a diverse group of stakeholders \n  Project management experience with the ability to prioritize tasks and manage deadlines effectively    A/B testing cohort segmentation \n  Experience using enterprise-level ESP, like Salesforce Marketing Cloud \n  Detail-oriented \n  Highly organized \n  Previous customer service experience a plus \n  Power BI or Google Analytics experience a plus \n  Strong collaboration and interpersonal skills to work with teams from Product, IT, Data Architecture, and Finance \n \n \n  Required Leadership Traits and Characteristics:  \n ",
        "techs": [
            "excel",
            "power bi",
            "tableau",
            "salesforce marketing cloud",
            "power bi",
            "google analytics"
        ],
        "cleaned_techs": [
            "excel",
            "powerbi",
            "tableau",
            "salesforce marketing cloud",
            "google analytics"
        ]
    },
    "7c6124c6c65a58c2": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 115000.0,
        "salary_max": 150000.0,
        "title": "SCRUM MASTER / SENIOR BUSINESS ANALYST (MICROSOFT)",
        "company": "Procentrix",
        "desc": "Position Description \n \n  The Scrum Master will be a servant leader for Agile teams, ensuring all Scrum processes are used as intended. The Scrum Master will protect the team, remove barriers to successful implementation, guiding the team in the development and delivery of application data-centric solutions, using Microsoft technologies. Responsibilities include: \n \n  Facilitates project planning, daily stand-ups, retrospectives, sprint & release planning, demos, and other meetings. \n Tracks and communicates team velocity and sprint progress. \n Expert in process design & working with clients to flush out requirements. \n Develop & maintain process documentation. \n Ensures development teams practice core agile principles of collaboration, prioritization, team accountability, and visibility. \n Assists with backlog maintenance and prioritization/resolution of defects/bugs. \n Assists with internal/external communication, improving transparency, radiating information, making commitments through story selection & task definition. \n Participates proactively in developing/maintaining team standards, tools, & best practices. \n Facilitates discussion and conflict resolution. \n Empowers the team to self-organize. \n Evaluates performance results and recommends major changes affecting short-term project growth and success. \n \n  The projected compensation range for this position is $115,000 to $150,000 (annualized USD). The final salary offered will generally fall within this range and is determined by various factors, including but not limited to the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as internal pay equity, location, contract-specific affordability and other organizational requirements. \n \n  Required Skills \n At least 8 years of IT experience on system / application development teams \n At least 3 years of experience as a Scrum Master \n Hands-on experience managing the agile process in an industry leading ALM tool (e.g., Azure DevOps, Jira), including producing Agile metrics / reports. \n Experience and willing to support testing functions, including: \n Writing and reviewing test cases \n Assisting others with testing as necessary \n Driving test automation adoption \n Experience performing Business Analyst tasks, including writing user stories \n Excellent verbal and written communication skills \n Experience working closely with executive level customer management \n \n  Desirable Skills \n Certified Scrum Master, or similar industry Agile certifications \n Experience working for federal government customers \n Experience working with Microsoft Cloud technologies, including the Power Platform and/or Dynamics 365, is highly desired \n Experience developing performance metrics and status reports using Azure DevOps data, dashboards and Power BI \n \n  Job ID",
        "cleaned_desc": " Hands-on experience managing the agile process in an industry leading ALM tool (e.g., Azure DevOps, Jira), including producing Agile metrics / reports. \n Experience and willing to support testing functions, including: \n Writing and reviewing test cases \n Assisting others with testing as necessary \n Driving test automation adoption \n Experience performing Business Analyst tasks, including writing user stories \n Excellent verbal and written communication skills   Experience working closely with executive level customer management \n \n  Desirable Skills \n Certified Scrum Master, or similar industry Agile certifications \n Experience working for federal government customers \n Experience working with Microsoft Cloud technologies, including the Power Platform and/or Dynamics 365, is highly desired \n Experience developing performance metrics and status reports using Azure DevOps data, dashboards and Power BI ",
        "techs": [
            "azure devops",
            "jira",
            "agile metrics",
            "agile reports",
            "test cases",
            "test automation adoption",
            "business analyst tasks",
            "user stories",
            "verbal communication skills",
            "written communication skills",
            "executive level customer management",
            "certified scrum master",
            "federal government customers",
            "microsoft cloud technologies",
            "power platform",
            "dynamics 365",
            "performance metrics",
            "status reports",
            "azure devops data",
            "dashboards",
            "power bi"
        ],
        "cleaned_techs": [
            "azure",
            "jira",
            "agile metrics",
            "agile reports",
            "test cases",
            "test automation adoption",
            "user stories",
            "executive level customer management",
            "certified scrum master",
            "federal government customers",
            "microsoft cloud technologies",
            "power platform",
            "dynamics 365",
            "performance metrics",
            "status reports",
            "dashboards",
            "powerbi"
        ]
    },
    "e22ddea154b6b759": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 90615.89,
        "salary_max": 114739.91,
        "title": "Functional Business Analyst",
        "company": "Bay State",
        "desc": "We have an exciting opportunity for a  Functional Business Analyst  to join our team. \n  Key Responsibilities:  \n \n  Under general supervision, has duties of instructing, directing, and checking the work of other project technical staff.  \n \n \n  Responsible for the completion of assigned technical projects within budgetary and scheduling guidelines.  \n \n \n  Leads a technical staff assigned for the duration of a project or may function as ongoing lead for technical staff associated with one or more technical areas.  \n \n \n  Does not have formal supervisory responsibilities, although may provide input for (project) team member performance appraisals.  \n \n \n  Typically performs all functional duties independently. \n \n  Required Experience/Skills: \n \n  A minimum of five (5) years experience in business analysis, software development and/or related field \n \n \n  Proficient in the following qualifications: \n \n  o Knowledge of Warehouse Management and Inventory Management Systems \n  o Familiarity with Agile/Scrum processes and management tools (preferably VersionOne) and IT Service Management Systems (preferably ServiceNow) \n  o Strong facilitation skills to effectively lead discussion across multiple groups \n  o Effective liaison between business and technical teams \n \n  Able to perform all functional duties independently \n \n \n  Experience training/mentoring less experienced personnel \n \n \n  Solid knowledge of and experience in software development and testing, preferably using different methodologies and lifecycles (e.g. Waterfall, Agile, etc) \n \n \n  General familiarity and experience with project management methodologies/disciplines, especially in the areas of scope, cost and schedule management \n \n \n  Moderate experience leading small teams and/or technical projects in the successful completion of assigned goals/objectives \n \n \n  Moderate experience writing and reviewing a broad range of technical documentation, especially technical specifications and design documents \n \n \n  Excellent communication skills. \n \n  Other Requirements: \n \n  Candidates must either be US Citizens or Permanent Residents \n \n \n  Candidates must have resided in the United States for the past 5 years \n \n \n  Candidates must not have traveled outside of the United States for a combined total of 6 months or greater in the past 5 years \n \n \n  This position requires successful completion of a background check, drug screen, and a credit check. \n \n  Education:  A degree from an accredited College/University in Software Engineering, Computer Science, Business or related discipline is preferred \n  Benefits:  Full-time employees are eligible for benefits including time-off benefits, such as vacation time and holiday pay, and insurance and other plan benefits. \n  Location:  Remote \u2013 Candidates must be located within the contiguous United States \n  About Us: \n  Bay State Computers, Inc. is a professional services firm and a leading provider of Information Technology (IT) services and products to the U.S. Federal Government and Industry. Bay State brings together experienced IT professionals and the latest state-of-the-art technology tools, practices, and products to support projects and task order requirements for our customers. For more information about Bay State visit our website and connect with us on LinkedIn. \n  Bay State Computers, Inc. is an Equal Opportunity/Affirmative Action Employer. All qualified candidates will receive consideration for this position   regardless of race, color, creed, religion, national origin, age, sex, citizenship, ethnicity, veteran status, marital status, disability, or any other characteristic protected by applicable law.",
        "cleaned_desc": " \n \n  Typically performs all functional duties independently. \n \n  Required Experience/Skills: \n \n  A minimum of five (5) years experience in business analysis, software development and/or related field \n \n \n  Proficient in the following qualifications: \n \n  o Knowledge of Warehouse Management and Inventory Management Systems \n  o Familiarity with Agile/Scrum processes and management tools (preferably VersionOne) and IT Service Management Systems (preferably ServiceNow)    o Strong facilitation skills to effectively lead discussion across multiple groups \n  o Effective liaison between business and technical teams \n \n  Able to perform all functional duties independently \n \n \n  Experience training/mentoring less experienced personnel \n \n \n  Solid knowledge of and experience in software development and testing, preferably using different methodologies and lifecycles (e.g. Waterfall, Agile, etc) \n \n \n  General familiarity and experience with project management methodologies/disciplines, especially in the areas of scope, cost and schedule management ",
        "techs": [
            "warehouse management and inventory management systems",
            "agile/scrum processes",
            "versionone",
            "it service management systems",
            "servicenow",
            "facilitation skills",
            "liaison between business and technical teams",
            "software development and testing methodologies (e.g. waterfall",
            "agile)",
            "project management methodologies/disciplines (e.g. scope",
            "cost",
            "schedule management)"
        ],
        "cleaned_techs": [
            "warehouse management and inventory management systems",
            "agile/scrum processes",
            "versionone",
            "it service management systems",
            "servicenow",
            "liaison between business and technical teams",
            "software development and testing methodologies (e.g. waterfall",
            "agile)",
            "project management methodologies/disciplines (e.g. scope",
            "cost",
            "schedule management)"
        ]
    },
    "7c21309fe6b75e73": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 117394.305,
        "salary_max": 148647.34,
        "title": "Data Analytics Lead",
        "company": "Cyberjin",
        "desc": "Hybrid/Remote role \n  Locations in multiple States \n  The Data Analytics Lead at Company has/is: \n \n  3 - 8 years experience in a data analytics role , preferably at a high-growth startup, CPG, loyalty, retail, or mobile gaming company \n  Entrepreneurial mindset with a  \u2018self-start\u2019 mentality ; Excels at finding answers. Customer centric. Comfortable with a workday and schedule that isn\u2019t always highly structured or predictable \n  Experience with  BI & data visualization tools  (e.g., Tableau, PowerBI).  Strong experience with SQL  and at  least   one  programming language (e.g., Python, R). Experience with  ETL tools  (Tableau Prep, Alteryx, Knime or similar). Proven experience in the cloud (Snowflake/AWS/GCP/Azure), Experience with  mobile products and analytics tools (Amplitude or similar) \n  A leader and a team player : ability to work and make decisions autonomously with appropriate levels of collaboration and engagement with the team to ensure alignment. \n \n  Additional: \n \n  Ability to handle multiple tasks simultaneously, maintain focus, and adapt to a variety of challenges in a  fast-paced agile environment \n  5 Location / ability to relocate to: Chicago (highly preferred) or San Diego \n \n   \n zbe2F1TdlX",
        "cleaned_desc": "  Experience with  BI & data visualization tools  (e.g., Tableau, PowerBI).  Strong experience with SQL  and at  least   one  programming language (e.g., Python, R). Experience with  ETL tools  (Tableau Prep, Alteryx, Knime or similar). Proven experience in the cloud (Snowflake/AWS/GCP/Azure), Experience with  mobile products and analytics tools (Amplitude or similar) \n  A leader and a team player : ability to work and make decisions autonomously with appropriate levels of collaboration and engagement with the team to ensure alignment. \n ",
        "techs": [
            "tableau",
            "powerbi",
            "sql",
            "python",
            "r",
            "tableau prep",
            "alteryx",
            "knime",
            "snowflake",
            "aws",
            "gcp",
            "azure",
            "amplitude"
        ],
        "cleaned_techs": [
            "tableau",
            "powerbi",
            "sql",
            "python",
            "r",
            "tableau prep",
            "alteryx",
            "knime",
            "snowflake",
            "aws",
            "gcp",
            "azure",
            "amplitude"
        ]
    },
    "2a8415a060fce176": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 74088.47,
        "salary_max": 93812.516,
        "title": "Business Analyst - Salesforce",
        "company": "TreviPay",
        "desc": "At TreviPay, we believe loyalty begins at the payment. Thousands of sellers use our global B2B payments and invoicing network to provide choice and convenience to buyers, open new markets and automate accounts receivables. With integrations to top eCommerce and ERP solutions and flexible trade credit options, TreviPay brings 40 years of experience serving leaders in manufacturing, retail and transportation. \n \n \n  Every day, TreviPay employees are challenged and empowered in a supportive, collaborative, entrepreneurial environment. \n \n  The  Business Analyst I  reports to the Manager of Process Excellence and will work with stakeholders to collect requirements and assist in designing, documenting, and implementing process improvements using procedural, Salesforce, Robotic Process Automation, and other TreviPay tools. The successful candidate will be a self-starter who is comfortable working in a busy and dynamic environment with competing priorities. \n \n  Responsibilities \n \n Partner with internal and external stakeholders to identify automation opportunities by analyzing and documenting processes and assessing the feasibility of automation or improved user experiences. \n Direct meetings, interviews, and workshops designed to gather requirements and design solutions. \n Work closely with documentation specialists to document processes, release notes, and other project materials to support development, security, operations, and maintenance. \n Communicate with colleagues or customers during product development to confirm alignment with the design and expectations. \n Support business teams in testing activities, including integration testing, end-to-end (business process) testing, and UAT. \n \n \n \n  Requirements: \n \n Bachelor\u2019s degree in business or technology-related major or two years of related work experience may be substituted for educational requirements. \n Exposure to Salesforce as Salesforce Business Analyst or Administrator \n Proficient use of MS Office (Word, Excel, PowerPoint, etc.) \n Excellent written and verbal communication skills. \n Strong analytical skills with a demonstrated ability to extensively analyze business processes and workflows. \n Basic understanding of SDLC, Waterfall, and Agile development methodologies including requirements, design, development, testing, documentation, training, deployment, operations, support, and maintenance. \n \n \n \n  Preferred Qualifications: \n \n Exposure to BI software such as Sisense, Power BI, or Tableau. \n Experience using flowcharting software (Lucidchart or Visio). \n Certification in SCRUM or Agile Project Management \n Certification in LEAN Six Sigma \n \n \n \n  Why you will love working at TreviPay \n \n Competitive salary \n Generous paid time off \n Medical, dental, vision, FSA, Life/AD&D, long and short-term disability \n 401K matching \n Casual environment and dress \n Employee referral program \n Professional, Innovative, and highly collaborative team \n Options for in-office, hybrid, or remote work \n \n \n At TreviPay we believe: \n \n in saying yes to unique and challenging requirements \n empowered team members are creative team members \n our products make the customer\u2019s day just a little bit better \n work/life balance makes us all more effective \n \n \n \n  TreviPay is an Equal Opportunity and Affirmative Action Employer. We welcome all veterans and disabled applicants. \n \n  #LI-TG1",
        "cleaned_desc": " Communicate with colleagues or customers during product development to confirm alignment with the design and expectations. \n Support business teams in testing activities, including integration testing, end-to-end (business process) testing, and UAT. \n \n \n \n  Requirements: \n \n Bachelor\u2019s degree in business or technology-related major or two years of related work experience may be substituted for educational requirements. \n Exposure to Salesforce as Salesforce Business Analyst or Administrator \n Proficient use of MS Office (Word, Excel, PowerPoint, etc.) \n Excellent written and verbal communication skills. \n Strong analytical skills with a demonstrated ability to extensively analyze business processes and workflows.   Basic understanding of SDLC, Waterfall, and Agile development methodologies including requirements, design, development, testing, documentation, training, deployment, operations, support, and maintenance. \n \n \n \n  Preferred Qualifications: \n \n Exposure to BI software such as Sisense, Power BI, or Tableau. \n Experience using flowcharting software (Lucidchart or Visio). \n Certification in SCRUM or Agile Project Management \n Certification in LEAN Six Sigma \n \n ",
        "techs": [
            "salesforce",
            "ms office",
            "word",
            "excel",
            "powerpoint",
            "bi software (sisense",
            "power bi",
            "tableau)",
            "flowcharting software (lucidchart",
            "visio)",
            "scrum",
            "agile project management",
            "lean six sigma"
        ],
        "cleaned_techs": [
            "salesforce",
            "microsoft",
            "word",
            "excel",
            "powerpoint",
            "bi software (sisense",
            "powerbi",
            "tableau)",
            "flowcharting software (lucidchart",
            "visio)",
            "scrum",
            "agile project management",
            "lean six sigma"
        ]
    },
    "c688c7697c781374": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 40.0,
        "salary_max": 100.0,
        "title": "ServiceNow IT Service Management (ITSM) Analyst",
        "company": "Synovize",
        "desc": "Synovize is a leading technology consulting firm that specializes in providing innovative solutions to businesses across various industries. With a team of experienced professionals, we aim to deliver exceptional services to our clients and help them achieve their digital transformation goals. As a remote-first company, we offer flexible work opportunities to talented individuals across the United States. \n Overview: \n We are currently seeking a skilled and experienced ServiceNow IT Service Management (ITSM) Analyst to join our team. As a ServiceNow ITSM Analyst, you will be responsible for analyzing, designing, and implementing IT service management solutions using the ServiceNow platform. This is a full-time, permanent or contract position with the flexibility of remote work. \n Responsibilities: \n \n Collaborate with clients and stakeholders to understand their IT service management needs and translate them into ServiceNow configurations. \n Analyze existing IT service management processes and workflows, identifying areas for improvement and optimization. \n Design and configure ServiceNow ITSM modules, including incident management, problem management, change management, and service catalog. \n Customize ServiceNow functionalities using JavaScript, Angular, and other web technologies to meet specific client requirements. \n Integrate ServiceNow with external systems through REST API, SOAP API, and other integration methods. \n Develop and maintain the Configuration Management Database (CMDB) to ensure accurate and up-to-date data. \n Conduct testing and quality assurance activities to ensure the stability and reliability of the implemented ITSM solutions. \n Provide end-user training and support during and after the implementation process. \n Collaborate with cross-functional teams to ensure successful project delivery within agreed timelines and budgets. \n Stay updated with the latest ServiceNow features and enhancements, recommending and implementing improvements to optimize IT service management processes. \n \n Requirements: \n \n Proven experience as a ServiceNow ITSM Analyst, working on IT service management projects and configuring the ServiceNow platform. \n Strong knowledge of IT service management processes and frameworks, such as ITIL. \n Proficiency in JavaScript, Angular, and web technologies for customization and enhancement purposes. \n Experience with integrating ServiceNow with external systems using REST API, SOAP API, and other methods. \n Familiarity with the Configuration Management Database (CMDB) and data management best practices. \n Strong problem-solving and analytical skills, with the ability to translate complex business requirements into technical solutions. \n Effective communication and collaboration skills to work with clients and cross-functional teams. \n \n Preferred Skills: \n \n ServiceNow certifications such as Certified Implementation Specialist or Certified Application Developer. \n Knowledge of ITIL best practices and their application in ServiceNow. \n Experience with other ServiceNow modules such as GRC, HAM, SAM, APM, and SPM. \n Familiarity with NoSQL databases and their usage in ServiceNow. \n Experience with ITOM, SCCM, JAMF, or other related tools and technologies. \n \n To apply for the position of ServiceNow IT Service Management (ITSM) Analyst at Synovize, please submit your resume and any relevant certifications. We are excited to hear from talented individuals who are passionate about leveraging the power of ServiceNow to drive efficient IT service delivery. Join us in shaping the future of technology consulting! \n Job Types: Contract, Permanent, Full-time \n Pay: $40.00 - $100.00 per hour \n Benefits: \n \n 401(k) matching \n Dental insurance \n Disability insurance \n Flexible schedule \n Flexible spending account \n Health insurance \n Health savings account \n Life insurance \n Parental leave \n Vision insurance \n \n Compensation package: \n \n 1099 contract \n \n Experience level: \n \n 10 years \n 11+ years \n 1 year \n 2 years \n 3 years \n 4 years \n 5 years \n 6 years \n 7 years \n 8 years \n 9 years \n No experience needed \n Under 1 year \n \n Schedule: \n \n 10 hour shift \n 8 hour shift \n Day shift \n Monday to Friday \n Night shift \n Overtime \n \n Application Question(s): \n \n Do you have any ServiceNow Certifications? If so, were they paid out of pocket? \n \n Experience: \n \n ServiceNow: 2 years (Preferred) \n \n Security clearance: \n \n Secret (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": " Proven experience as a ServiceNow ITSM Analyst, working on IT service management projects and configuring the ServiceNow platform. \n Strong knowledge of IT service management processes and frameworks, such as ITIL. \n Proficiency in JavaScript, Angular, and web technologies for customization and enhancement purposes. \n Experience with integrating ServiceNow with external systems using REST API, SOAP API, and other methods. \n Familiarity with the Configuration Management Database (CMDB) and data management best practices. \n Strong problem-solving and analytical skills, with the ability to translate complex business requirements into technical solutions. \n Effective communication and collaboration skills to work with clients and cross-functional teams. \n \n Preferred Skills: \n \n ServiceNow certifications such as Certified Implementation Specialist or Certified Application Developer. \n Knowledge of ITIL best practices and their application in ServiceNow. \n Experience with other ServiceNow modules such as GRC, HAM, SAM, APM, and SPM. \n Familiarity with NoSQL databases and their usage in ServiceNow. \n Experience with ITOM, SCCM, JAMF, or other related tools and technologies. \n \n To apply for the position of ServiceNow IT Service Management (ITSM) Analyst at Synovize, please submit your resume and any relevant certifications. We are excited to hear from talented individuals who are passionate about leveraging the power of ServiceNow to drive efficient IT service delivery. Join us in shaping the future of technology consulting! \n Job Types: Contract, Permanent, Full-time ",
        "techs": [
            "servicenow itsm analyst",
            "servicenow platform",
            "itil",
            "javascript",
            "angular",
            "rest api",
            "soap api",
            "configuration management database (cmdb)",
            "servicenow certifications",
            "grc",
            "ham",
            "sam",
            "apm",
            "spm",
            "nosql databases",
            "itom",
            "sccm",
            "jamf"
        ],
        "cleaned_techs": [
            "servicenow platform",
            "itil",
            "javascript",
            "angular",
            "rest api",
            "soap api",
            "configuration management database (cmdb)",
            "servicenow certifications",
            "grc",
            "ham",
            "sam",
            "apm",
            "spm",
            "nosql",
            "itom",
            "sccm",
            "jamf"
        ]
    },
    "ca71c94e9e63f427": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 54922.0,
        "salary_max": 107099.0,
        "title": "Medical Economics Analyst - REMOTE",
        "company": "Molina Healthcare",
        "desc": "JOB DESCRIPTION \n \n  Job Summary \n \n  Responsible for conducting analyses of insured medical populations with the goal of identifying opportunities to improve financial performance. Extracts, analyzes, and synthesizes data from various sources to identify risks and opportunities. \n \n  KNOWLEDGE/SKILLS/ABILITIES \n \n  Analyze claims and other data sources to identify early signs of trends or other issues related to medical care costs \n \n  Draw actionable conclusions based on analyses performed \n \n  Work closely with clinical, provider network and other personnel to design and perform studies related to the quantification of medical interventions \n \n  Work with business owners to track key performance indicators of medical interventions \n \n  Perform pro forma sensitivity analyses in order to estimate the expected financial value of proposed medical cost improvement initiatives \n \n  Extract and compile information from various systems to support executive decision-making \n \n  Ability to mine and manage information from large data sources. \n \n  JOB QUALIFICATIONS \n \n  Required Education \n \n  Bachelor's Degree in Mathematics, Statistics, or Economics \n \n  Required Experience \n \n  2-5 years of experience \n \n  Preferred Experience \n \n  Proficiency with Excel and SQL for retrieving specified information from datalake. \n \n \n Pay Range:  $54,922 - $107,099 \n \n \n \n Actual compensation may vary from posting based on geographic location, work experience, education and/or skill level. \n \n To all current Molina employees:  If you are interested in applying for this position, please apply through the intranet job listing. \n \n  Molina Healthcare offers a competitive benefits and compensation package. Molina Healthcare is an Equal Opportunity Employer (EOE) M/F/D/V.",
        "cleaned_desc": " \n  Required Experience \n \n  2-5 years of experience \n \n  Preferred Experience \n \n  Proficiency with Excel and SQL for retrieving specified information from datalake. \n ",
        "techs": [
            "excel",
            "sql"
        ],
        "cleaned_techs": [
            "excel",
            "sql"
        ]
    },
    "3b809fadc8ef8d61": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 101756.3,
        "salary_max": 128846.14,
        "title": "Senior Business Analyst",
        "company": "Nagarro",
        "desc": "Full-time \n  Service Region: Eastern Europe \n \n \n \n \n \n  Company Description \n \n \n  We're Nagarro.    We are a digital product engineering company that is scaling in a big way! We build products, services, and experiences that inspire, excite, and delight. We work at scale \u2014 across all devices and digital mediums, and our people exist everywhere in the world (19,000+ experts across 33 countries, to be exact). Our work culture is dynamic and non-hierarchical. We're looking for great new colleagues. That's where you come in!    By this point in your career, it is not just about the tech you know or how well you can code. It is about what more you want to do with that knowledge. Can you help your teammates proceed in the right direction? Can you tackle the challenges our clients face while always looking to take our solutions one step further to succeed at an even higher level? Yes? You may be ready to join us. \n \n \n \n \n \n  Job Description \n \n \n \n  Participate in the software design, development, and implementation of hybris applications with integration to various modules of SAP. \n  Design, develop, and maintain scalable and stable eCommerce solutions that meet business needs. \n  Transform business function requirements into technical program specs to code, test and debug programs. \n  Execute unit tests, systems, integration and acceptance tests and testing tools for functions of high complexity. \n  Translate development requirements and specifications into high quality, efficient solutions \n  Complete work in a timely and accurate manner while providing exceptional customer service \n  Work on specific area(s) of website functionality such as search, cart and checkout etc and developing features for those areas of responsibility \n  Ensure alignment of all critical systems with security and data privacy policies. \n  Work closely with internal team and external partners to ensure new developments align with roadmap and integrate seamlessly with other platform components \n  Identify and develop improvements for test coverage of new and existing code bases \n  Collaborate with project stakeholders to ensure all requirements are met. \n \n \n \n \n \n \n  Qualifications \n \n \n \n  Previous extensive experience as a Business Analyst within eCommerce business domain. \n  Good hands-on knowledge of Hybris Commerce Payments and Hybris Commerce Order Management or similar tools that are used in eCommerce projects. \n  Nice-to-have: experience with SAP cloud based eCommerce solutions (B2C, B2B) or good level of understanding of Hybris OOTB functionalities.",
        "cleaned_desc": "  Translate development requirements and specifications into high quality, efficient solutions \n  Complete work in a timely and accurate manner while providing exceptional customer service \n  Work on specific area(s) of website functionality such as search, cart and checkout etc and developing features for those areas of responsibility \n  Ensure alignment of all critical systems with security and data privacy policies. \n  Work closely with internal team and external partners to ensure new developments align with roadmap and integrate seamlessly with other platform components \n  Identify and develop improvements for test coverage of new and existing code bases \n  Collaborate with project stakeholders to ensure all requirements are met. \n ",
        "techs": [
            "translate development requirements and specifications into high quality",
            "efficient solutions",
            "complete work in a timely and accurate manner while providing exceptional customer service",
            "work on specific area(s) of website functionality such as search",
            "cart and checkout etc and developing features for those areas of responsibility",
            "ensure alignment of all critical systems with security and data privacy policies",
            "work closely with internal team and external partners to ensure new developments align with roadmap and integrate seamlessly with other platform components",
            "identify and develop improvements for test coverage of new and existing code bases",
            "collaborate with project stakeholders to ensure all requirements are met."
        ],
        "cleaned_techs": [
            "translate development requirements and specifications into high quality",
            "efficient solutions",
            "complete work in a timely and accurate manner while providing exceptional customer service",
            "work on specific area(s) of website functionality such as search",
            "cart and checkout etc and developing features for those areas of responsibility",
            "work closely with internal team and external partners to ensure new developments align with roadmap and integrate seamlessly with other platform components",
            "identify and develop improvements for test coverage of new and existing code bases"
        ]
    },
    "97024d384657c7f4": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 42930.57,
        "salary_max": 54359.67,
        "title": "Full Time Space Management Support Analyst SAS",
        "company": "Advantage Solutions",
        "desc": "Summary: \n   Full Time Space Management Support Analyst SAS \n \n  SAS Retail Services provides national retail merchandising services to a host of fortune 500 CPG companies, distributors, and wholesalers, within the grocery, mass, home/hardware, and drug channels. \n \n  We are looking to hire a Space Management Support Analyst who will be responsible for assisting in the execution of the Retailer\u2019s Space Management GM process. This is an entry level Space Planning position within SAS. The Support Analyst will work closely with a team to accomplish desired business objectives and goals. This position will entail assisting with the creation of planograms, analyzing the data to determine space allocation impact and proposing ideas that will positively impact the sales margin. \n   \n \n  Our people are what make SAS Retail Services a great place to work. All of us work hard to win for the customer \u2013 some of the nation\u2019s largest retailers \u2014 and that\u2019s what makes it fun, the drive to do whatever it takes to get the job done. APPLY TODAY!\n  \n \n \n  What We Offer \n \n \n  Medical, Dental, Vision after 30 days. \n  Short and Long-Term Disability \n  401(K) Plan \n  Generous paid time off. \n  Paid training and ongoing career development certifications and courses. \n \n \n  Responsibilities: \n \n \n  Support the execution of the Retailer\u2019s space management process using customer insights and market data. \n  Collaborate with category teams to identify specific goals for the merchandise reset. \n  Assist with the creation of planograms and product assortments in a timely manner. \n  Make recommendations regarding assortment and space allocation solutions which positively impact the Retailer\u2019s sales margins and turnover. \n  Communicate issues to various teams and propose ideas for resolution. \n  Assist in compiling and analyzing data for assigned Retailers. \n  Assist with running internal reports to determine product viability and preference. \n  May assist with creating merchandise presentations that enhance the customer shopping experience and contribute to our Customer 1st merchandising strategy. \n  Perform other duties as required. \n \n \n  Qualifications: \n \n \n  High School diploma required. \n  Preferred: prior Space Management experience, college course-work. \n  Must have 1 year of retail/merchandising or related field experience. \n  Preliminary knowledge of Microsoft Office Suite. \n  Excellent written, verbal and analytical skills. \n  Ability to work closely in a multi-functional cross-company team environment. \n  Ability to create and deliver effective persuasive presentations. \n  Able to meet deadlines, manage time effectively \n \n  Responsibilities: \n   The Company is one of North America\u2019s leading sales and marketing agencies specializing in outsourced sales, merchandising, category management and marketing services to manufacturers, suppliers and producers of food products and consumer packaged goods. The company services a variety of trade channels including grocery, mass merchandise, specialty, convenience, drug, dollar, club, hardware, consumer electronics and home centers. We bridge the gap between manufacturers and retailers, providing consumers access to the best products available in the marketplace today. \n \n \n  Position Summary \n \n \n   The Space Planning Associate works directly with Company\u2019s customers by analyzing shelving data and building planograms in a way that best fits client/customer\u2019s objectives. Responsible for the efficient and effective managing of assigned categories. Expected to be tactically sound and strategic in plan development. This position can be located in-house with the customer or work remotely as outlined by customer.\n  \n \n \n  Essential Job Duties and Responsibilities \n \n \n   Planogram Management\n  \n \n  Maintain project schedule by monitoring project progress, coordinating activities, resolving problems, and make adjustments as needed to meet deadlines \n  Support retailers and/or clients POG development throughout defined category review process or client initiatives \n \n \n   Planogram Development\n  \n \n  Communicate business opportunities and recommend action plans by working with clients, customers, and/or Business Development Managers \n  Organize information by studying, analyzing, interpreting, and classifying data \n  Executes test sets in set room \n \n \n \n  Data Analysis/Interpretation/Application\n  \n \n  Determine and quantify primary business opportunities and key drivers as they pertain to shelving \n  Support key business opportunities by recommending merchandising/assortment solutions based on applicable data \n  Prioritize optimal assortment and/or shelving information to support the goals of our clients, customers, and company \n  Evaluate the reliability of source information by weighing raw data and organizing results for analysis \n \n \n   POG Data Collection\n  \n \n  Provide planogram information for clients, customers, and/or Business Development Managers through the use of syndicated or customer-specific data sources \n  Meet specific needs of requesting party by determining appropriate movement/performance data selection such as share of shelf, days of supply, pack out, etc. \n \n \n   Database Management\n  \n \n \n \n     Maintain information inputs in Company\u2019s proprietary POG Analysis tools\n    \n \n \n  Supervisory Responsibilities \n \n \n \n \n \n  Direct Reports\n  \n \n   This position does not have supervisory responsibilities for direct reports\n  \n \n \n  Indirect Reports\n  \n \n   This position does not have guidance or mentoring responsibilities for indirect reports\n  \n \n \n  Travel and/or Driving Requirements  \n \n \n  Travel is an essential duty and function of this job. Driving is not an essential duty or function of this job.\n  \n \n   Tavel up to 25%\n  \n \n \n  Minimum Qualifications \n The following are the minimum job-related qualifications which an individual needs in order to successfully perform the essential duties and responsibilities of the job \n \n \n \n  Education Level: \n   (Required):  High School Diploma or GED or equivalent experience\n  \n \n   \n (Preferred):  Associate's Degree or equivalent experience\n  \n \n \n  Field of Study/Area of Experience:\n  \n \n 2-4 years of experience in merchandising and planogram development skills \n \n \n \n  Skills, Knowledge and Abilities \n \n \n  Analytical and research Skills \n  Working knowledge of syndicated data and applications \n  Strong merchandising and planogram development skills \n  Basic understanding of category management \n  Ability to gather data, to compile information, and prepare reports \n  Well-organized, detail-oriented, and able to handle a fast-paced work environment \n  Strong prioritization skills \n  Flexible and adaptable, able to change and alter according to changes in projects or business environment \n  Team building Skills \n  Excellent customer service orientation \n  Ability to ensure a high level of service and quality is maintained \n  Strong computer skills including proficiency with Microsoft Word, Excel, PowerPoint, Access, Outlook, and web-browsers \n  Experience using planogram software (JDA Space Planning, Apollo, Spaceman, etc.) \n \n \n \n  Environmental & Physical Requirements  \n \n \n Office / Sedentary Requirements \n \n \n   Incumbent must be able to perform the essential functions of the job. Work is performed primarily in an office environment. Typically requires the ability to sit for extended periods of time (66%+ each day), ability to hear the telephone, ability to enter data on a computer and may also require the ability to lift up to 10 pounds.\n  \n \n \n  Additional Information Regarding The Company Job Duties and Job Descriptions \n \n \n   \n \n Job duties include additional responsibilities as assigned by one\u2019s supervisor or other manager related to the position/department. This job description is meant to describe the general nature and level of work being performed; it is not intended to be construed as an exhaustive list of all responsibilities, duties and skills required for the position. The Company reserves the right at any time with or without notice to alter or change job responsibilities, reassign or transfer job position or assign additional job responsibilities, subject to applicable law. The company shall provide reasonable accommodations of known disabilities to enable a qualified applicant or employee to apply for employment, perform the essential functions of the job, or enjoy the benefits and privileges of employment as required by the law. \n \n  Any estimate, schedule, or guideline provided to associates in this job description or elsewhere in connection with their jobs is only intended to help describe job duties and for planning purposes. Regardless of any such estimate, schedule, or guideline, associates must always record all time worked for our company (which includes but is not limited to on-site work time in an assigned store, office, or other work location; required waiting time; administrative time; and work-related travel time).  Important Information: \n   The above statements are intended to describe the general nature and level of work being performed by people assigned to this position. They are not intended to be an exhaustive list of all responsibilities, duties and skills required of associates so classified. \n  The Company is committed to providing equal opportunity in all employment practices without regard to age, race, color, national origin, sex, sexual orientation, religion, physical or mental disability, or any other category protected by law. As part of this commitment, the Company shall provide reasonable accommodations of known disabilities to enable an applicant or employee to apply for employment, perform the essential functions of the job, or enjoy the benefits and privileges of employment as required by the law.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "b9b57628c95617de": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 13000.0,
        "salary_max": 70000.0,
        "title": "Data Analyst II",
        "company": "Ascensus",
        "desc": "At Ascensus, technology is more than just a solution. It powers the business that helps millions of people save for what matters\u2014retirement, education, and healthcare. Our technology experts tackle exciting challenges in collaborative teams, but work in an environment where individual and career development is always valued. Technology associates leverage their talents and passion, building new and innovative platforms, creating programs founded in automation in agile frameworks, and driving existing and new markets\u2014all of which supports the rapid growth of a dynamic industry leader. \n \n  A data analyst\u2019s core job responsibilities include: \n \n  Collecting and interpreting data \n Analyzing results using statistical techniques \n Developing and implementing data analyses, data collection systems, and other strategies that optimize statistical efficiency and quality \n Acquiring data from primary or secondary data sources and partnering with a data warehouse team to maintain databases \n Identifying, analyzing, and interpreting trends or patterns in complex data sets \n Filtering and cleaning data to ensure accuracy \n Creating visualizations and reports for internal and external stakeholders \n Developing dashboards and other tools to help stakeholders understand key metrics \n Documenting requirements for data visualizations \n Partnering with internal and external stakeholders to drive solutions to complex business problems. \n \n  To be a successful data analyst, one needs a mix of technical, analytical, and soft skills. Technical skills include proficiency in programming languages such as Python or R, SQL databases, and data visualization tools such as Tableau or Power BI. Analytical skills include the ability to identify patterns in large datasets, interpret results using statistical techniques, and communicate findings effectively. Soft skills include critical thinking, problem-solving, communication, and collaboration. \n \n  The national average salary range for this role is 70k-13k in base pay, exclusive of any bonuses and benefits. This base salary range represents the low and high end of the salary range for this position. Actual salary offered will vary and may be above or below the range based on various factors including but not limited to location, experience, performance, and internal pay alignment. We do not anticipate that candidates hired will begin at the top of the range however, from time to time, it may occur on a case-by-case basis. Other rewards and benefits may include: 401(k) match, Medical, Dental, Vision, Paid-Time-Off, etc. For more information, please visit careers.ascensus.com/#Benefits .",
        "cleaned_desc": " Developing and implementing data analyses, data collection systems, and other strategies that optimize statistical efficiency and quality \n Acquiring data from primary or secondary data sources and partnering with a data warehouse team to maintain databases \n Identifying, analyzing, and interpreting trends or patterns in complex data sets ",
        "techs": [
            "data analyses",
            "data collection systems",
            "statistical efficiency",
            "data sources",
            "data warehouse",
            "databases",
            "trends",
            "patterns"
        ],
        "cleaned_techs": [
            "data analyses",
            "data collection systems",
            "statistical efficiency",
            "data sources",
            "data warehouse",
            "databases",
            "trends",
            "patterns"
        ]
    },
    "c035383358684871": {
        "terms": [
            "data analyst"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Consulting BI Analyst",
        "company": "Work from Home",
        "desc": "Introduction \n  Are you passionate about the patient experience? At HCA Healthcare, we are committed to caring for patients with purpose and integrity. We care like family! Jump-start your career as a(an) Consulting BI Analyst today with Work from Home. \n  Benefits \n  Work from Home, offers a total rewards package that supports the health, life, career and retirement of our colleagues. The available plans and programs include: \n \n  Comprehensive medical coverage that covers many common services at no cost or for a low copay. Plans include prescription drug and behavioral health coverage as well as free telemedicine services and free AirMed medical transportation. \n  Additional options for dental and vision benefits, life and disability coverage, flexible spending accounts, supplemental health protection plans (accident, critical illness, hospital indemnity), auto and home insurance, identity theft protection, legal counseling, long-term care coverage, moving assistance, pet insurance and more. \n  Free counseling services and resources for emotional, physical and financial wellbeing   \n  401(k) Plan with a 100% match on 3% to 9% of pay (based on years of service)   \n  Employee Stock Purchase Plan with 10% off HCA Healthcare stock   \n  Family support through fertility and family building benefits with Progyny and adoption assistance.   \n  Referral services for child, elder and pet care, home and auto repair, event planning and more   \n  Consumer discounts through Abenity and Consumer Discounts   \n  Retirement readiness, rollover assistance services and preferred banking partnerships   \n  Education assistance (tuition, student loan, certification support, dependent scholarships)   \n  Colleague recognition program   \n  Time Away From Work Program (paid time off, paid family leave, long- and short-term disability coverage and leaves of absence)   \n  Employee Health Assistance Fund that offers free employee-only coverage to full-time and part-time colleagues based on income. \n \n  Learn more about Employee Benefits \n  Note: Eligibility for benefits may vary by location. \n  Come join our team as a(an) Consulting BI Analyst. We care for our community! Just last year, HCA Healthcare and our colleagues donated $13.8 million dollars to charitable organizations. Apply Today! \n  Job Summary and Qualifications \n \n  The Consulting BI Analyst leverages technical expertise to review, analyze, and evaluate revenue cycle reporting solutions supported by the IT&S Data & Analytics team. Conducts analysis to recommend business report creation and modifications to support business strategies. Writes detailed description of business goals, user needs, program functions, and steps required to configure, develop or modify reports and upstream data sources. Requires detailed knowledge of requirements gathering and documentation practices, as well as software and database development methodologies. Communicates requirements to technical resources and assures that the designed solution will meet business and user needs as well as comply with system best practices. Works with business users to resolve conflicting requirements and will act as an intermediary between the business users and IT teams to ensure technology architecture and reporting solutions align to achieve mutual desired outcomes. This position will work with management to develop timelines and manage project risks, assist in the development of quality assurance test plans, and help develop end user documentation. \n  The Consulting BI Analyst must be a highly motivated self-starter and enthusiastic learner with excellent verbal and written communication skills. Must have the ability to coordinate and communicate with leadership of various levels within the organization, and with a project team of ETL developers, MicroStrategy developers and QA test analysts. \n \n  What you will do in this role: \n \n \n  Collaborate with customer, developers, and quality analysts on project requirements \n  Provide accurate and thorough estimates of work effort \n  Participate in large-scale development projects involving multiple areas outside of core team \n  Creates a joint vision for IT solutions by maintaining strong relationships with business unit and solution leaders and assists in preparing and presenting the value proposition or business cases \n  Provide expertise in process design and provides leadership and education/training by communicating requirements to the business, peers, technical resources, testers, etc. \n  Build strong and diverse network of relationships with various stakeholder groups and all levels of staff \n  Identifies impact to other solutions or projects, and works with management, developers and stakeholders to identify options and recommendations \n  Provide operational support and trouble-shooting for production systems \n  Knowledge of Information Systems best practices in the areas of Change Management, Disaster Recovery, Data Retention, Incident Management, SLAs, integration, data warehousing, etc. \n  Lead Junior and Senior analysts \n \n  What qualifications you will need: \n \n  Bachelor's Degree or equivalent work experience \n  Experience in BI Product development across multiple BI tools including Microstrategy, Essbase, Longview, \n  Business Objects, Power BI, and Tableau preferred \n  10+ years\u2019 experience in requirements gathering and business analysis required \n  Teradata and SQL Server database experience preferred \n  Healthcare experience, Project Management, Revenue Cycle Management experience preferred \n  Experience working with cross-functional teams \n  Experience interfacing with internal and external stakeholders \n  Experience in leading junior and senior analysts \n  Certificate/License(s) in various BI tools is a plus \n \n \n  Parallon provides full-service revenue cycle management, or total patient account resolution, for HCA Healthcare. Our services include scheduling, registration, insurance verification, hospital billing, revenue integrity, collections, payment compliance, credentialing, health information management, customer service, payroll and physician billing. We also provide full-service revenue cycle management as well as targeted solutions, such as Medicaid Eligibility, for external clients across the country. Parallon has over 17,000 colleagues, and serves close to 1,000 hospitals and 3,000 physician practices, all making an impact on patients, providers and their communities. \n  HCA Healthcare has been recognized as one of the World\u2019s Most Ethical Companies\u00ae by the Ethisphere Institute more than ten times. In recent years, HCA Healthcare spent an estimated $3.7 billion in cost for the delivery of charitable care, uninsured discounts, and other uncompensated expenses. \n \"The great hospitals will always put the patient and the patient's family first, and the really great institutions will provide care with warmth, compassion, and dignity for the individual.\"- Dr. Thomas Frist, Sr.  HCA Healthcare Co-Founder \n If you are looking for an opportunity that provides satisfaction and personal growth, we encourage you to apply for our Consulting BI Analyst opening. We promptly review all applications. Highly qualified candidates will be contacted for interviews.  Unlock the possibilities and apply today! \n  We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",
        "cleaned_desc": "  Job Summary and Qualifications \n \n  The Consulting BI Analyst leverages technical expertise to review, analyze, and evaluate revenue cycle reporting solutions supported by the IT&S Data & Analytics team. Conducts analysis to recommend business report creation and modifications to support business strategies. Writes detailed description of business goals, user needs, program functions, and steps required to configure, develop or modify reports and upstream data sources. Requires detailed knowledge of requirements gathering and documentation practices, as well as software and database development methodologies. Communicates requirements to technical resources and assures that the designed solution will meet business and user needs as well as comply with system best practices. Works with business users to resolve conflicting requirements and will act as an intermediary between the business users and IT teams to ensure technology architecture and reporting solutions align to achieve mutual desired outcomes. This position will work with management to develop timelines and manage project risks, assist in the development of quality assurance test plans, and help develop end user documentation. \n  The Consulting BI Analyst must be a highly motivated self-starter and enthusiastic learner with excellent verbal and written communication skills. Must have the ability to coordinate and communicate with leadership of various levels within the organization, and with a project team of ETL developers, MicroStrategy developers and QA test analysts. \n \n  What you will do in this role: \n \n \n  Collaborate with customer, developers, and quality analysts on project requirements \n  Provide accurate and thorough estimates of work effort \n  Participate in large-scale development projects involving multiple areas outside of core team    Experience in BI Product development across multiple BI tools including Microstrategy, Essbase, Longview, \n  Business Objects, Power BI, and Tableau preferred \n  10+ years\u2019 experience in requirements gathering and business analysis required \n  Teradata and SQL Server database experience preferred \n  Healthcare experience, Project Management, Revenue Cycle Management experience preferred \n  Experience working with cross-functional teams \n  Experience interfacing with internal and external stakeholders \n  Experience in leading junior and senior analysts \n  Certificate/License(s) in various BI tools is a plus \n \n ",
        "techs": [
            "microstrategy",
            "essbase",
            "longview",
            "business objects",
            "power bi",
            "tableau",
            "teradata",
            "sql server"
        ],
        "cleaned_techs": [
            "microstrategy",
            "essbase",
            "longview",
            "business objects",
            "powerbi",
            "tableau",
            "teradata",
            "sql"
        ]
    },
    "54804d8334b20f7c": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 54922.0,
        "salary_max": 107098.0,
        "title": "Sr Analyst - HEDIS Analytics (Remote in NE)",
        "company": "Molina Healthcare",
        "desc": "JOB DESCRIPTION \n \n  Job Summary \n \n  Molina's Quality Improvement function oversees, plans, and implements new and existing healthcare quality improvement initiatives and education programs; ensures maintenance of programs for members in accordance with prescribed quality standards; conducts data collection, reporting and monitoring for key performance measurement activities; and provides direction and implementation of NCQA accreditation surveys and federal/state QI compliance activities. \n \n  KNOWLEDGE/SKILLS/ABILITIES \n \n  In collaboration with Quality Improvement (QI) management, the Senior Analyst, HEDIS/Quality Reporting develops and provides reports and cost-benefit analysis tools to meet QI requirements and uses automated software tools and processes to help streamline activities and improve data/analytics for the quality team. \n \n  Acts as a lead analyst to provide project-, program-, and / or initiative-related direction and guidance for other analysts within the department and/or collaboratively with other departments. \n \n  Develops, codes, runs, and/or prepares formatted reports to support critical Quality Improvement functions (e.g., reporting for key performance measurement activities, including HEDIS, state-based measure reporting and medical record review). \n \n  Collaborates and / or assists in performing quality assurance checks on reports prior to completion \n \n  Works with Director and / or Manager to establish and / or document quality assurance process checks to be utilized by all staff to ensure the integrity, completeness and validity of external and internal reports \n \n  Understands how to prioritize reports according to business need, regulatory requirements, urgency and / or other key business factors \n \n  Collaborates with department leads and other partnering departments to understand and / or document business requirements and / or implement required reporting. \n \n  Writes and / or produces accurate reports and conducts analyses according to set timelines and project plans. \n \n  Collaborates with other department staff to convert HEDIS data sources for use in HEDIS reporting as needed. \n \n  Coordinates data and analyses from MHI and / or Health Plans as needed. \n \n  Assists with generation of State-specific performance measurement requirements. \n \n  Assists program managers with research regarding performance measurement outliers when asked. \n \n  Uses industry standard techniques determined by the department to reduce report writing errors. \n \n  Modifies reports in response to error identification and / or approved change requests; understand the balance between responsiveness to business requests for enhancements versus department needs to complete work efficiently and timely. \n \n  JOB QUALIFICATIONS \n \n  Required Education \n \n  Bachelor's Degree or equivalent combination of education and work experience. \n \n  Required Experience \n \n  3 years of experience in healthcare, or equivalent experience in a non-financial regulated industry. \n \n  1 year experience in managed healthcare, or equivalent \n \n  Technical experience in reporting and/or programming. \n \n  Proficiency with Excel and Visio (flow chart equivalent) and demonstrated ability to learn new information systems and software programs. \n \n  Proficiency with data manipulation and interpretation. \n \n  Knowledge of basic statistics. \n \n  Preferred Education \n \n  Master's Degree or higher in a clinical field, IT, Public Health or Healthcare. \n \n  Preferred Experience \n \n  HEDIS reporting or collection experience. \n \n  CAHPS improvement experience. \n \n  1+ years in managed healthcare non-financial reporting. \n \n  1+ years health care information systems experience or in a role as an IS liaison/contact for QI projects. \n \n  State QI experience. \n \n  Supervisory experience. \n \n  Project management and team building experience. \n \n  Experience developing performance measures that support business objectives. \n \n  Experience using multiple programming languages, including but not limited to, SQL / SSRS. \n \n  Preferred License, Certification, Association \n \n  Microsoft Certification(s) \n \n \n Pay Range:  $54,922 - $107,098 \n \n \n \n Actual compensation may vary from posting based on geographic location, work experience, education and/or skill level. \n \n To all current Molina employees:  If you are interested in applying for this position, please apply through the intranet job listing. \n \n  Molina Healthcare offers a competitive benefits and compensation package. Molina Healthcare is an Equal Opportunity Employer (EOE) M/F/D/V.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "c4c2b75342a0bbe4": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 75794.38,
        "salary_max": 95972.57,
        "title": "Technical Business Analyst",
        "company": "Applied Systems Canada",
        "desc": "Job Overview: \n   Ivans, a division of Applied Systems, is currently searching for a  Technical Business Analyst  to join the Ivans Engineering Team. Engineering is the intersection between business, product, and user experience. The Engineering Team is responsible for designing and building services with a focus on security, stability, and automation. \n  Under the general direction of the Engineering Leadership Team, the Technical Business Analyst ensures a product\u2019s core features and functionality meet the needs of our partners, giving them the ability to integrate their unique workflows and data models quickly and efficiently into IVANS. With a focus on integrating and connecting the industry, the Technical Business Analyst leads the analysis of partner API capabilities to build software that assists with configuring, transmitting, and reporting of data between our platform and partner systems. \n  Success in this role requires a technical background and a willingness to dive into the details. The Technical Business Analyst should be motivated to change the way the industry defines, collects, and moves data between systems. \n \n   What You\u2019ll Do \n \n  Analyzes partner API capabilities for translating and moving data to backend systems from the platform \n  With an understanding of XML and JSON data standards, builds mappings between the support formats \n  Creates technical specifications, functional requirements, and acceptance criteria \n  Develops test cases and data that ensure the requirements and acceptance criteria are met and verified to support a successful release \n  Creates and maintains workflow diagrams to assist the design team when building partner-facing UIs \n  Communicates with internal stakeholders regarding the building, maintaining, and supporting of the platform \n \n \n  What You\u2019ll Need to Succeed \n \n  We\u2019re looking for someone who: \n \n  Can work remotely or from an Ivans office \n \n  Your experience should include some or all of the following: \n \n  Extensive experience  in Technical Business Analysis  in a related industry \n  Advanced knowledge of XML and JSON  data standards \n  Ability to collaborate on programming and analytical problems \n  Strong quantitative, research, and data analytic skills \n  Strong interpersonal and communication skills \n  Ability to work as a member of cross-functional teams to help design solutions \n  Highly motivated self-starter with the ability to work efficiently with minimal supervision \n  Bachelor\u2019s Degree in Computer Science or Information Technology, or similar background gained through professional work experience \n \n  We proudly support and encourage people with military experience, as well as military spouses, to apply \n \n \n  Additionally, you may have: \n \n \n \n  Experience with Agency Management Systems preferred \n  Experience with Policy Administration Systems preferred \n \n \n  Being a part of Ivans \n \n  Benefits from Day One \n \n  Health insurance plans, dental, and vision \n  Wellness incentives \n  401(k) and/or RRSP retirement savings plans with employer match \n \n  Work-Life Balance \n \n  Competitive paid vacation time and a free day for your birthday \n  Personal/sick time \n  Paid holidays \n  Flex Time \n  Volunteer time off \n \n  Empowering Career Growth and Success \u2013 We invest in talent, care about our people and are empowered by the results of our work. We grow our teams from within and give our employees opportunities to advance. \n \n  Moving the Insurance Industry Forward \n  Digital connectivity is the lifeblood of innovation, and at Ivans, we are literally at the heart of what is driving innovation across the entire insurance ecosystem. This is just one of the things that makes Ivans such a cool place to work. Making a difference \u2013 for the industry and within our team \u2013 is what pushes us to do better each day. \n  Our culture is about more than developing the best technology. It\u2019s about being innovative, investing in our team, creating a customer-centric environment, and setting the industry up for the future. A big part of that is attracting, developing, and retaining the best talent for our business and our future. That\u2019s where you come in. You\u2019ll get to work with amazing people on cool innovation that brings the industry forward. \n  Visit ivans.com to learn how you can join us. \n \n  EEO Statement \n  Ivans is proud to be an Equal Employment Opportunity and Affirmative Action Employer. Diversity and Inclusion is a business imperative and is a part of building our brand and reputation. At Ivans, we are committed to recruit, develop, retain, and promote regardless of race, religion, color, national origin, sexual orientation, gender identity, disability, age, veteran status, and other protected status as required by applicable law. \n \n  #LI-Remote",
        "cleaned_desc": "Job Overview: \n   Ivans, a division of Applied Systems, is currently searching for a  Technical Business Analyst  to join the Ivans Engineering Team. Engineering is the intersection between business, product, and user experience. The Engineering Team is responsible for designing and building services with a focus on security, stability, and automation. \n  Under the general direction of the Engineering Leadership Team, the Technical Business Analyst ensures a product\u2019s core features and functionality meet the needs of our partners, giving them the ability to integrate their unique workflows and data models quickly and efficiently into IVANS. With a focus on integrating and connecting the industry, the Technical Business Analyst leads the analysis of partner API capabilities to build software that assists with configuring, transmitting, and reporting of data between our platform and partner systems. \n  Success in this role requires a technical background and a willingness to dive into the details. The Technical Business Analyst should be motivated to change the way the industry defines, collects, and moves data between systems. \n \n   What You\u2019ll Do \n \n  Analyzes partner API capabilities for translating and moving data to backend systems from the platform \n  With an understanding of XML and JSON data standards, builds mappings between the support formats \n  Creates technical specifications, functional requirements, and acceptance criteria \n  Develops test cases and data that ensure the requirements and acceptance criteria are met and verified to support a successful release \n  Creates and maintains workflow diagrams to assist the design team when building partner-facing UIs \n  Communicates with internal stakeholders regarding the building, maintaining, and supporting of the platform    Strong quantitative, research, and data analytic skills \n  Strong interpersonal and communication skills \n  Ability to work as a member of cross-functional teams to help design solutions \n  Highly motivated self-starter with the ability to work efficiently with minimal supervision \n  Bachelor\u2019s Degree in Computer Science or Information Technology, or similar background gained through professional work experience \n \n  We proudly support and encourage people with military experience, as well as military spouses, to apply \n \n \n  Additionally, you may have: \n \n \n ",
        "techs": [
            "xml",
            "json",
            "api",
            "backend systems",
            "platform",
            "technical specifications",
            "functional requirements",
            "acceptance criteria",
            "test cases",
            "data",
            "workflow diagrams",
            "quantitative skills",
            "research skills",
            "data analytic skills",
            "interpersonal skills",
            "communication skills",
            "cross-functional teams",
            "computer science",
            "information technology"
        ],
        "cleaned_techs": [
            "xml",
            "json",
            "api",
            "backend systems",
            "platform",
            "technical specifications",
            "functional requirements",
            "acceptance criteria",
            "test cases",
            "data",
            "workflow diagrams",
            "cross-functional teams",
            "computer science",
            "information technology"
        ]
    },
    "ba58f09380489de9": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 78897.63,
        "salary_max": 99901.99,
        "title": "HRIS Business Analyst II",
        "company": "Yale New Haven Health",
        "desc": "Provide client support services on Manager Self Service and Employee Self Service applications. Develops training materials, user documentation and conduct training sessions for functional users. Develops training materials in conjunction with systems analysts for Employee Self Service users. Assists in the testing maintenance of code table changes. Assists in testing changes and maintaining Infor/Lawson HR code tables. Assists in reviewing and processing security requests for HR system applications. Tests and validates all HR Infor security set up. Maintains and updates HR codes and tables in the HR system, ensuring data integrity. In collaboration with the Manager, sets up new leave plans, modifying existing plans and documenting methodology for exceptions. Coordinates all Position Budget Manager activities such as, but not limited to, troubleshooting FTE conversions, budget restrict error messages. \n EEO/AA/Disability/Veteran \n Qualifications \n EDUCATION:  Bachelor's degree in Human Resources or related discipline or training and work related experience or equivalent. \n EXPERIENCE:  Five (5) to seven (7) years of experience with analysis activities in Human Resources, with at least three (3) years of experience coding HR systems required. \n SPECIAL SKILLS:  In-depth knowledge of Infor/Lawson or comparable HR/Payroll system set up. Understanding of impact of shared systems. Ability to develop training materials and conduct training sessions. Working knowledge in MS Access, SQL or TOAD to build queries for research and issue resolution. Excellent interpersonal and communications skills required. \n Responsibilities: \n \n 1. Provides client support services on Manager Self Service and Employee Self Service applications. Researches and solves issues with Managers experiencing Manager Self Services problems or HR applications issues on Employee Self Service. Responds to Helpdesk tickets and HRConnect cases. \n 2. In collaboration with the Manager, sets up new leave plans, modifying existing plans and documenting methodology for exceptions. Ensures thorough testing and implementation of new and revised plans. Works closely with the HRIS technical team, Benefits, ITS and Payroll teams to ensure plans are set up correctly \n 3. Maintains and updates HR codes and tables in the HR System, ensuring data integrity. \n 4. Responsible for coordinating the testing of HR systems upgrades, patches and issues with all HR users. Coordinates the documentation of test results. Develops test scripts for all HR system users. Maintains Infor/Lawson HR code table changes, as needed. \n 5. Reviews, coordinates and processes end user security access requests for all HR Systems related features in Infor GHR, BI Reports, Position Control reports and Crystal Reports. Assists in processing security access requests for HR/Payroll applications. \n 6. Completes transactions that cannot be processed through Manager Space such as executive new hires, organizational transfers and transactions with appropriate documentation. Provides back-up to other HRIS staff as need arises, including running critical jobs. Assists functional users in researching HR system issues, as they arise. Validates automated jobs for completeness and corrects errors, as needed. \n 7. Researches HR system issues with Manager Space, Employee Space and ESS-HRIS applications, and other HR systems, as they arise. Works with the local functional users to test solutions and documents changes, as needed. \n 8. Works in conjunction with HR functional areas and the Infor Core team to define system change requests and report requests. \n 9. Provides support to all levels of management on Position Budget Manager issues. Works in collaboration with Talent Acquisition and the Budget departments to ensure all facets of Position Budget are considered when resolving an issue. \n 10. Develops training materials and conducts training sessions on enhancements to the HR system for Infor HR clients and HR functional areas. \n 11. Assists in training of HRIS business staff. Assesses current business processes to identify improvement opportunities, makes recommendations for improvements and implements approved enhancements. \n 12. In conjunction with Corporate HRIS systems analysts, develops training materials and user documentation for HRIS web applications. Tests new HR applications as they are developed. \n 13. Assists departments with quick HRDB report requests as needed. \n 14. Provides consultation to clients on procedures and processes affecting HR network and applications. \n 15. Keeps abreast of recent developments in the Information Systems field as related to HR products. Participates in professional development programs. Participates in the evaluation and recommendation of HR software products. \n 16. Performs other job related duties as required. \n \n Job Type: Full-time \n Benefits: \n \n 401(k) matching \n Dental insurance \n Disability insurance \n Family leave \n Health insurance \n Paid time off \n Parental leave \n Retirement plan \n Tuition reimbursement \n Vision insurance \n \n Experience level: \n \n 5 years \n \n Schedule: \n \n Day shift \n Monday to Friday \n \n Work Location: Remote",
        "cleaned_desc": "Provide client support services on Manager Self Service and Employee Self Service applications. Develops training materials, user documentation and conduct training sessions for functional users. Develops training materials in conjunction with systems analysts for Employee Self Service users. Assists in the testing maintenance of code table changes. Assists in testing changes and maintaining Infor/Lawson HR code tables. Assists in reviewing and processing security requests for HR system applications. Tests and validates all HR Infor security set up. Maintains and updates HR codes and tables in the HR system, ensuring data integrity. In collaboration with the Manager, sets up new leave plans, modifying existing plans and documenting methodology for exceptions. Coordinates all Position Budget Manager activities such as, but not limited to, troubleshooting FTE conversions, budget restrict error messages. \n EEO/AA/Disability/Veteran \n Qualifications \n EDUCATION:  Bachelor's degree in Human Resources or related discipline or training and work related experience or equivalent. \n EXPERIENCE:  Five (5) to seven (7) years of experience with analysis activities in Human Resources, with at least three (3) years of experience coding HR systems required. \n SPECIAL SKILLS:  In-depth knowledge of Infor/Lawson or comparable HR/Payroll system set up. Understanding of impact of shared systems. Ability to develop training materials and conduct training sessions. Working knowledge in MS Access, SQL or TOAD to build queries for research and issue resolution. Excellent interpersonal and communications skills required. \n Responsibilities: \n \n 1. Provides client support services on Manager Self Service and Employee Self Service applications. Researches and solves issues with Managers experiencing Manager Self Services problems or HR applications issues on Employee Self Service. Responds to Helpdesk tickets and HRConnect cases. ",
        "techs": [
            "manager self service",
            "employee self service",
            "infor/lawson hr",
            "ms access",
            "sql",
            "toad",
            "helpdesk"
        ],
        "cleaned_techs": [
            "manager self service",
            "employee self service",
            "infor/lawson hr",
            "ms access",
            "sql",
            "toad",
            "helpdesk"
        ]
    },
    "5c1d14f7d08fd821": {
        "terms": [
            "data analyst"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "IT Business Analyst/Scrum Master",
        "company": "Acuity INC",
        "desc": "Overview: \n  \n   As a Business Analyst, you will serve as a dedicated team member who has primary responsibility to support their self-organizing, self-managing team successfully achieve their daily, iteration, and release goals and delivery objectives. They do so by effectively applying, implementing and enforcing Scrum principles and practices. The Business Analyst will also help protect the team from outside influences, which could otherwise interfere with the team's ability to deliver value in a short time-box (iteration). The Business Analyst will help to mentor the empowerment teams and assist the team in its transition to the new method, continuously facilitate a team dynamic intended to maximize performance of the team, and by continuously improving agile practices.\n   Responsibilities: \n  \n   Skills: \n  \n \n SCM \n  General understanding of RPA, AI and ML \n  UiPath customer engagement and follow-up \n  Minor SharePoint site content updates \n  Ability to maintain and track MOU/MOA and other process documents. \n \n \n   DevSecOps\n  \n \n  Support multiple service and support.\n    \n  Application Security understanding \n  Manage Application Engineering, patching and vulnerability mitigation  \n \n Schedule and orchestrate daily stand-up meetings. \n  Schedule and guide sprint planning and reviews. \n  Prepare and publish sprint reports. \n  Follow through with team members on task and board updates. \n  Facilitate technical discussions with team members and external stakeholders. \n  Qualifications: \n  \n Bachelor's Degree or equivalent with experience in a related Information Technology field \n  Communicate and collaborate with project manages and cross-national teams. \n  Maintain documentation regarding various projects, processes and operations. \n  Make recommendations for improvements. \n  Ability to liaise between groups and numerous organization units. \n  Ability to communicate effectively. \n  Review and analyze key business metrics and compliance. \n  Ability to operate independently and accommodate an international audience. \n  Schedule, plan and lead requirements gathering and review meetings. \n  Serve as BA in support of AI/ML projects. \n  Excellent knowledge of agile methodology, techniques and frameworks \n  Ability to lead daily stand-up scrum meetings. \n  Knowledge of kanban, back logs and project tracking \n \n \n  Clearance Requirement \n \n \n  Must have active Top Secret government clearance \n \n \n \n \n \n About Acuity Inc: \n \n \n   Acuity is a leading management and technology consulting firm that specializes in serving the federal government. Our innovative, collaborative and rewarding work environment has earned repeat honors from the Washington Business Journal\u2019s Best Places to Work and SmartCEO Corporate Culture awards.\n  \n \n \n  We are an equal employment opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, national origin, disability status, protected veteran status or any other characteristic protected by law.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "91846ec8d1bbefb9": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 78556.05,
        "salary_max": 99469.45,
        "title": "Salesforce Business Analyst",
        "company": "Keller Postman",
        "desc": "Keller Postman LLC is a national law firm that represents a broad array of clients as plaintiffs in complex litigation at the trial and appellate levels. We act for plaintiffs in federal and state court across a variety of claims and practice areas. We take on complicated cases\u2014frequently class and mass actions, arbitrations or matters in multiple jurisdictions\u2014where our legal and strategic counsel can add significant value. \n \n \n  We are looking for a proactive individual that can join our Salesforce team as our Salesforce Business Analyst. In this role, you will be the driving force behind our data visualization and insights strategy, ensuring that our legal professionals have access to meaningful and actionable information within Salesforce. As our Salesforce Business Analyst with a focus on reports and dashboards, you will play a pivotal role in optimizing our Salesforce system to support decision-making and enhance our legal services. The ideal candidate will possess a strong understanding of the Salesforce platform, enabling a swift understanding of our current setup to ensure effective reporting. \n \n \n  Essential Functions: \n \n \n Collaborate closely with legal professionals and stakeholders to understand their reporting needs. \n Design, create, and maintain a variety of reports and dashboards using Salesforce's reporting tools. \n Run an inventory on existing reports and dashboards to consolidate where applicable. \n Perform in-depth data analysis to uncover trends, opportunities, and areas for improvement for both the legal team and case staff. \n Provide user training and support for report and dashboard usage. \n Create training materials and documentation to ensure user adoption and proficiency with reports and dashboards. \n Work with development teams to build custom report solutions or integrations when standard Salesforce reporting tools cannot meet specific requirements. \n Utilize data visualization best practices to present data in a clear, meaningful, and visually appealing manner, enabling stakeholders to make informed decisions. \n Ensure data accuracy and consistency within reports and dashboards. \n Ensure that reports and dashboards comply with industry regulations and legal requirements. \n Maintain detailed documentation of report and dashboard configurations, data sources, and best practices. \n Stay current with Salesforce updates and enhancements, proactively identifying opportunities to leverage new features for the benefit of the firm. \n Proactively identify opportunities to enhance data visualization and reporting capabilities. \n Other duties as assigned. \n \n \n \n \n  Knowledge, Skills, Abilities: \n \n \n Exceptional analytical and problem-solving skills, with a meticulous eye for detail \n Good understanding of Salesforce data models, object relationships, and architecture \n Proficiency in creating complex reports, dashboards, and data visualizations within Salesforce \n Available and responsive to questions \n Active in the Salesforce community \n Strong computer proficiency; adept at learning new software \n Excellent written and verbal communication skills with the ability to communicate in both technical and non-technical language \n Ability to work independently or as part of a team \n Keen attention to detail and excellent organizational skills \n Ability to multi-task and adapt to changes quickly \n Ability to collaborate across functional teams \n Maintain a strong understanding of technology and its application to achieve business objectives \n \n \n \n \n  Education/Experience: \n \n \n Bachelor's degree preferred \n Minimum 2 years of analytical experience \n Minimum 1 years of Salesforce experience \n \n \n \n \n  Certificates/Licenses Required: \n \n \n Certified Salesforce Administrator \n Certified Salesforce Business Analyst or the ability to obtain in the first 6 months \n Certified Salesforce Advanced Administrator is a plus \n Ability to earn additional Salesforce certifications based on Keller Postman's business needs \n \n \n \n  Keller Postman is an Equal Opportunity Employer.",
        "cleaned_desc": " \n  Knowledge, Skills, Abilities: \n \n \n Exceptional analytical and problem-solving skills, with a meticulous eye for detail \n Good understanding of Salesforce data models, object relationships, and architecture \n Proficiency in creating complex reports, dashboards, and data visualizations within Salesforce \n Available and responsive to questions \n Active in the Salesforce community \n Strong computer proficiency; adept at learning new software \n Excellent written and verbal communication skills with the ability to communicate in both technical and non-technical language \n Ability to work independently or as part of a team \n Keen attention to detail and excellent organizational skills ",
        "techs": [
            "analytical skills",
            "problem-solving skills",
            "salesforce data models",
            "object relationships",
            "salesforce architecture",
            "complex reports",
            "dashboards",
            "data visualizations",
            "salesforce community",
            "computer proficiency",
            "software proficiency",
            "written communication skills",
            "verbal communication skills",
            "technical communication skills",
            "non-technical communication skills",
            "ability to work independently",
            "ability to work as part of a team",
            "attention to detail",
            "organizational skills"
        ],
        "cleaned_techs": [
            "salesforce data models",
            "object relationships",
            "salesforce architecture",
            "complex reports",
            "dashboards",
            "data visualizations",
            "salesforce community",
            "computer proficiency",
            "software proficiency",
            "attention to detail"
        ]
    },
    "1bd9488a8aca2051": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 0.0,
        "salary_max": 125000.0,
        "title": "Sr. BigQuery BI Analyst",
        "company": "Source Select Group, LLC",
        "desc": "PLEASE NOTE: VENDORS OR CANDIDATES THAT REQUIRE SPONSORSHIP NOW OR IN THE FUTURE WILL NOT BE CONSIDERED (NO 3rd Party Vendor applicants) \n Responsibilities: - Collect, analyze, and interpret complex data sets to identify trends, patterns, and insights by using tools such as Google Big Query, Domo, AWS Redshift, Looker. - Develop and maintain business intelligence reports and dashboards - Collaborate with cross-functional teams to gather requirements and define key performance indicators (KPIs) \n REQUIRED: Must have Strong expertise with Google Big Query, seeking experience with Google Cloud, Segment, Google Analytics(4) and Big Query. \n The Senior Business Intelligence Analyst should have a minimum of five years experience in Marketing Analytics. Preferring this exp. in a digital marketing environment. This individual will lead marketing analytics efforts and will provide customer insights and proposals by analyzing data and monitoring relevant market conditions. This role will report on a wide range of metrics and KPI\u2019s relevant to the business, using a deep understanding of digital marketing data to translate complex data into actionable insights for our marketing teams. \n Experience : - Bachelor's degree in a relevant field such as Business Analytics, Marketing, Computer Science or Statistics - Proven experience in business intelligence analysis, data visualization, and reporting - Proficiency in using tools such as Analytics and Visio for data analysis and visualization - Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy - Excellent communication skills with the ability to effectively present complex information to both technical and non-technical stakeholders - Strong problem-solving skills with the ability to think critically and provide innovative solutions - Experience working in a fast-paced environment with the ability to prioritize multiple tasks and meet deadlines \n Note: Experience with vaticinate is a plus but not required.If you are a highly analytical individual with a passion for data-driven decision making, we would love to hear from you. Apply now to join our team as a Business Intelligence Analyst. \n Do you meet the following criteria? \n We are unable to work with candidates that work thru a Vendor or 3rd Party. All Candidates MUST work on our W2 as Employees, and my not require sponsorship now or in the future. \n Job Type: Full-time \n Pay: Up to $125,000.00 per year \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n \n Experience level: \n \n 4 years \n 5 years \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n Google Cloud Platform: 3 years (Required) \n Business intelligence: 5 years (Required) \n Google BigQuery: 3 years (Required) \n Google Analytics: 3 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": "PLEASE NOTE: VENDORS OR CANDIDATES THAT REQUIRE SPONSORSHIP NOW OR IN THE FUTURE WILL NOT BE CONSIDERED (NO 3rd Party Vendor applicants) \n Responsibilities: - Collect, analyze, and interpret complex data sets to identify trends, patterns, and insights by using tools such as Google Big Query, Domo, AWS Redshift, Looker. - Develop and maintain business intelligence reports and dashboards - Collaborate with cross-functional teams to gather requirements and define key performance indicators (KPIs) \n REQUIRED: Must have Strong expertise with Google Big Query, seeking experience with Google Cloud, Segment, Google Analytics(4) and Big Query. \n The Senior Business Intelligence Analyst should have a minimum of five years experience in Marketing Analytics. Preferring this exp. in a digital marketing environment. This individual will lead marketing analytics efforts and will provide customer insights and proposals by analyzing data and monitoring relevant market conditions. This role will report on a wide range of metrics and KPI\u2019s relevant to the business, using a deep understanding of digital marketing data to translate complex data into actionable insights for our marketing teams. \n Experience : - Bachelor's degree in a relevant field such as Business Analytics, Marketing, Computer Science or Statistics - Proven experience in business intelligence analysis, data visualization, and reporting - Proficiency in using tools such as Analytics and Visio for data analysis and visualization - Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy - Excellent communication skills with the ability to effectively present complex information to both technical and non-technical stakeholders - Strong problem-solving skills with the ability to think critically and provide innovative solutions - Experience working in a fast-paced environment with the ability to prioritize multiple tasks and meet deadlines \n Note: Experience with vaticinate is a plus but not required.If you are a highly analytical individual with a passion for data-driven decision making, we would love to hear from you. Apply now to join our team as a Business Intelligence Analyst. ",
        "techs": [
            "google big query",
            "domo",
            "aws redshift",
            "looker",
            "google cloud",
            "segment",
            "google analytics(4)",
            "analytics",
            "visio"
        ],
        "cleaned_techs": [
            "google big query",
            "domo",
            "aws",
            "looker",
            "gcp",
            "segment",
            "google analytics(4)",
            "visio"
        ]
    },
    "e476c4690182a5a3": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 56000.0,
        "salary_max": 73000.0,
        "title": "Int Enhanced Underwriting Analyst",
        "company": "Transamerica",
        "desc": "Job Family\n   Underwriting\n  \n \n \n    Who We Are\n   \n \n \n \n \n  Transamerica has been helping people feel better about the future for more than 100 years. We provide investment, retirement, and life insurance solutions to more than 11 million customers throughout the U.S. But the way we see it, our responsibility goes beyond our clients\u2019 accounts. We\u2019re in the business of helping people live well and empowering them to create a better tomorrow through the financial and health-related habits they form today. We help people prepare by providing solutions that consider the whole picture.\n   \n \n \n    What We Do\n   \n \n \n    Transamerica is organized by lines of business (Life Insurance, Annuities, Mutual Funds, Retirement Plans, Employee Benefits, and Financial Assets), which are supported by Transamerica Corporate (Corporate Development; Finance; Internal Audit; Legislative, Regulatory & Policy; Office of the CEO; People, Places & Brand; Risk; and Technology).\n   \n \n \n \n   Job Description Summary\n   Assist product implementation team to deliver forms and communication that meet the needs of our customers and our internal risk teams.\n  \n   Job Description\n  \n \n   Responsibilities\n  \n \n  Forms, communication, and documentation management. \n  Analyze data to ensure accuracy and alignment with the desired customer and risk expectations. \n  Testing of forms and communication, including writing, and preparing test cases. \n  Collaborate with the enhanced underwriting project team and related stakeholders in New Business, Project Management, Data Analytics, Medical, Actuarial, Sales & Marketing, vendors, etc. \n  Keep abreast of relevant events in the insurance sector including new legislation. \n  Navigate SERFF and Interstate compacts. \n  Help develop cost effective and customer friendly processes for assessing risk. \n \n \n \n   Qualifications\n  \n \n  Bachelor\u2019s degree in a business field or equivalent experience \n  Two years of life or health underwriting experience \n  One year of underwriting experience within Transamerica or one year of experience working on an enhanced underwriting project \n  Basic understanding of enhanced underwriting user interface \n  Knowledge of industry products \n  Communication and interpersonal skills to interact with multiple business groups, including New Business, Project Management, Data Analytics, Medical, Actuaries, Sales & Marketing, etc. \n  Decision-making and problem-solving skills \n  Ability to work in a team environment to deliver a high functioning decision engine \n  Time-management skills to work on multiple priorities simultaneously \n  Willingness to continue education to stay current in the insurance sector \n  Proficiency in MS Office \n \n \n \n   Preferred Qualifications\n  \n \n  Completion of FALU or completion of coursework toward designation \n  FLMI designation or completion of coursework toward designation \n  Expertise building applications and life insurance forms \n \n \n \n   Working Conditions\n  \n \n  Office environment of remote from home \n  Occasional travel \n \n \n \n   Compensation\n  \n \n  **Please note that the compensation information that follows is a good faith estimate for this position only and is provided pursuant to applicable pay transparency and compensation posting laws. It is estimated based on what a successful candidate might be paid in certain Company locations.** \n \n \n \n  The Salary for this position generally ranges between $56-73K. This range is an estimate, based on potential qualifications and operational needs. Salary may vary above and below the stated amounts, as permitted by applicable law.\n  \n \n \n  Additionally, this position is typically eligible for an Annual Bonus of 7.5% based on the Company Bonus Plan/Individual Performance and is at Company discretion.\n  \n \n \n   What We Offer\n  \n \n \n \n  For eligible employees, we offer a comprehensive benefits package designed to support both the personal and financial well-being of our employees.\n   \n \n \n \n \n  Compensation Benefits\n   \n \n \n \n \n \n \n       Competitive Pay\n      \n \n \n       Bonus for Eligible Employees\n      \n \n \n \n \n \n  Benefits Package\n    \n \n \n \n \n \n       Pension Plan\n      \n \n \n       401k Match\n      \n \n \n       Employee Stock Purchase Plan\n      \n \n \n       Tuition Reimbursement\n      \n \n \n       Disability Insurance\n      \n \n \n       Medical Insurance\n      \n \n \n       Dental Insurance\n      \n \n \n       Vision Insurance\n      \n \n \n       Employee Discounts\n      \n \n \n       Career Training & Development Opportunities\n      \n \n \n \n \n \n \n \n  Health and Work/Life Balance Benefits\n    \n \n \n \n \n \n       Paid Time Off starting at 160 hours annually for employees in their first year of service.\n      \n \n \n       Ten (10) paid holidays per year (typically mirroring the New York Stock Exchange (NYSE) holidays).\n      \n \n \n       Be Well Company holistic wellness program, which includes Wellness Coaching and Reward Dollars\n      \n \n \n       Parental Leave \u2013 fifteen (15) days of paid parental leave per calendar year to eligible employees with at least one year of service at the time of birth, placement of an adopted child, or placement of a foster care child.\n      \n \n \n       Adoption Assistance\n      \n \n \n       Employee Assistance Program\n      \n \n \n       College Coach Program\n      \n \n \n       Back-Up Care Program\n      \n \n \n       PTO for Volunteer Hours\n      \n \n \n       Employee Matching Gifts Program\n      \n \n \n       Employee Resource Groups\n      \n \n \n       Inclusion and Diversity Programs\n      \n \n \n       Employee Recognition Program\n      \n \n \n       Referral Bonus Programs\n      \n \n \n       Peer Recognition Program (BRAVO)\n      \n \n \n \n \n \n \n  Inclusion & Diversity\n   \n \n \n \n \n  Transamerica has made a strong commitment to inclusion and diversity, and we are proud to be an organization where all perspectives are valued. Transamerica has earned recognition for its strong efforts year-over-year, including from the Human Rights Campaign\u2019s Foundation Corporate Equality Index, the Diversity Best Practices Inclusion Index, and Seramount\u2019s \u201c100 Best Companies\u201d list.\n   \n \n \n \n \n  In addition, as part of Transamerica\u2019s commitment to maintaining an inclusive workplace, the company sponsors employee-driven Employee Resource Groups (ERGs), which are formed around a shared interest or a common characteristic of diversity. ERGs are open to all employees and provide a supportive environment for raising diversity awareness and promoting inclusive behavior.\n   \n \n \n \n \n  Giving Back\n   \n \n \n \n \n  Transamerica believes our responsibilities extend beyond our corporate walls. That's why we created the Aegon Transamerica Foundation in 1994. Through a combination of financial grants and the volunteer commitment of our employees, this foundation supports nonprofit organizations focused on the education, health, and well-being of the communities where we live and work.\n   \n \n \n \n \n \n  https://www.transamerica.com/why-transamerica/aegon-transamerica-foundation\n    \n \n \n \n \n \n  Transamerica\u2019s Parent Company\n   \n \n \n \n \n \n     Aegon\n     acquired the Transamerica business in 1999. Aegon\u2019s roots go back more than 175 years to the first half of the nineteenth century. Since then, Aegon has grown into an international company, with businesses in the Americas, Europe, and Asia. Today, Aegon is one of the world\u2019s leading financial services organizations, providing life insurance, pensions, and asset management. As a leading global investor and employer, the company seeks to have a positive impact by addressing critical environmental and societal issues, with a focus on climate change and inclusion and diversity.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "55a991f26dcca0a9": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 5521.58,
        "salary_max": 9055.5,
        "title": "IT Business Analyst III \u2013 FULLY REMOTE in TX",
        "company": "Dept of Family & Protectve Svc",
        "desc": "About Texas Department of Family and Protective Services (DFPS) \n      The mission of DFPS is to protect children, the elderly, and people with disabilities from abuse, neglect, and exploitation by involving clients, families, and communities. We are looking to grow our teams with people who share our energy and enthusiasm to get behind our mission of protecting those among us who are most in need. \n     \n  The Texas Department of Family and Protective Services (DFPS) is currently seeking a Business Analyst for a full-time position within the Application Development team in the IT Department. This position is a Business Analyst Lead role and will report directly to the Business Analyst Manager. \n     \n  As a Business Analyst Lead in the Systems Development Resources team, this position will perform advanced (senior-level) business and systems analysis work that involves gathering, developing, and documenting user requirements, and reviewing and assessing business processes and tools. The BA lead\u2019s primary responsibilities will be to support the BA and BA manager to ensure the team is providing quality work consistently by ensuring a repeatable framework, process and tools are in place. The position would work with appropriate stakeholders on IT solutions and business decisions to support the organization\u2019s short- and long-term business goals/strategy to ensure they align with IT strategies and project requirements. Good written and verbal communication and presentation skills are required for developing reports and presentations. \n     \n  This position is classified as a full-time position (40 hours a week). Work outside of regular hours may be required. Travel to other Austin offices(s) may be required. Works under minimal supervision, with considerable latitude for the use of initiative and independent judgment. \n     \n  This position is a full-time position that includes other State of Texas benefits as described in this SAO site: http://www.sao.texas.gov/SAOReports/ReportNumber?id=18-704\n     \n \n \n \n \n \n \n \n Essential Job Functions: \n  Leading, Mentoring & Evaluating \n     \n Oversees Business Analyst work to ensure quality standards and stakeholder needs are being met.  \n \n Mentor Business Analysts to ensure DFPS IT processes for delivering project and production support work are clearly communicated and expectations defined.  \n \n Coaches Business Analysts to address standards and expectations that are not being met.  \n \n Review and comment on complex project deliverables such as project charters, quality management and risk assessment plans, workflow diagrams, and business rules.  \n \n  Administration \n     \n Assist with screening, interview and selection process for potential BA team new hires and contractors.  \n \n Assist with resource allocation and time management for team.  \n \n Understand and assist with on-boarding of new staff.  \n \n Tracks project deadlines for deliverables that are assigned to Business Analysts.  \n \n Tracks production maintenance deadlines and deliverables assigned to Business Analysts.  \n \n Organize, edit and communicate release notes for distribution to the agency at large.  \n \n Assists with scheduling go-live activities.  \n \n  Business Analysis & Process Improvement \n     \n Works with stakeholders to understand their technology needs and issues in performing their day-to-day work.  \n \n Conducts work sessions with users and project team members to document requirements, develop use cases, and/or technology solutions.  \n \n Assists project team members with analysis and interpretation of user requirements.  \n \n Participates in systems analysis as needed.  \n \n Analyzes program policies and business practices to provide recommendations and ideas for addressing technology requests, needs, and solutions.  \n \n Develops presentations for Business Analyst Manager and SDR Director to report on metrics gathered.  \n \n Creates, edits, and maintains technical documentation for current and future applications e.g., technical reference manuals and production control manuals.  \n \n Assists, and may train, users within programs with user acceptance testing activities.  \n \n Develops Use Case documentation.  \n \n Works with developers to interpret and provide clarification on Use Cases as needed.  \n \n Participates in release activities and application development implementation activities.  \n \n Develops and coordinates other special projects.  \n \n  Adheres to all Texas Department of Family and Protective Services HR policies and performs related work as assigned.\n     \n \n \n \n \n \n \n \n \n Knowledge Skills Abilities: \n \n At least five (5) years\u2019 experience in a role demonstrating business systems analysis expertise.  \n \n Knowledge of the Business Analysis Body of Knowledge (BABOK).  \n \n Knowledge of Project Management Body of Knowlede (PMBOK) and Project Management Life Cycle (PMLC) methodologies.  \n \n Knowledge of Software Development Life Cycle (SDLC) and high-level system design methodologies and techniques (entity/relationship models, data/process flow diagrams); object-oriented programming and of programming client/server applications.  \n \n Exceptional interpersonal, presentation building, meeting faciliatation, public-speaking, writing, editing, and proofreading skills.  \n \n Experience researching, understanding and summarizing key and/or abstract ideas and when applicable, suggest recommendations from those findings.  \n \n Consistently demonstrates strong analytical and critical thinking skills.  \n \n Ability to identify and address existing and potential obstacles, issues and opportunities; and identify and mitigate key issues affecting the progress of organization and process solutions.  \n \n Working knowledge of productivity software including Microsoft Office Suite to include MS Word, Excel, PowerPoint, MS Project, SharePoint, Visio and/or SQL.  \n \n Demonstrates excellent organization skills, e.g., defines and organizes tasks, responsibilities and priorities.  \n \n Ability to develop documentation that maps and illustrates processes and develop framework for process improvement.  \n \n Demonstrated experience in expressing technical and business concepts and conclusions orally and in writing.  \n \n Experience leading teams.  \n \n Effective mentor to junior level staff including providing feedback on peer-reviewed documents and feedback on meeting facilitation.  \n \n Experience analyzing business processes and developing business cases for new or modified customer-related products and services.  \n \n Skilled in problem root cause analysis and negotiating problem resolution.  \n \n Ability to analyze and interpret program and technical information including regulations, policies, and business rules to aid in DFPS IT program goal and priority setting.  \n \n Experience in estimating project effort and timelines.  \n \n \n \n \n \n \n Registration or Licensure Requirements: \n \n ITIL Certification a plus but not required.  \n \n CBAP or similar Business Analyst certification is a plus but not required. \n \n \n \n \n \n \n \n Initial Selection Criteria: \n \n Graduation from an accredited four-year college or university; experience may be substituted for education on a year for year basis.  \n \n At least five (5) years\u2019 experience performing in the role of a Business Analyst.  \n \n At least (1) one-year experience in leading Business Analyst either as a lead BA on a project or as a team lead..  \n \n Documented experience in analysis, mapping, and/or developing findings and recommendations for business processes. \n \n \n \n \n \n \n \n \n Additional Information: \n  Interview Requirements: Any candidate who is called to an agency for an interview must notify the interviewing agency in writing of any reasonable accommodation needed prior to the date of the interview.\n     \n \n \n  Texas Administrative Code (TAC 206 and 213) requires state agencies to ensure all Electronic Information Resources (EIR) follow accessibility standards. Staff may be required to create accessible content including but not limited to; Microsoft Office documents, Adobe PDFs, webpages, software, training guides, video, and audio files. \n    \n \n \n \n \n MOS Code: \n  Note: Military occupation(s) that relate to the initial selection criteria and registration or licensure requirements for this position may include 25B, 255A, IT, 182X, 682X, 26, C4|10, C4|11, ISM, 8848, 8846, 8858, 3D0X1 . All active duty military, reservists, guardsmen, and veterans are encouraged to apply if qualified to fill this position. For more information see the Texas State Auditor\u2019s Military Crosswalk at http://www.hr.sao.state.tx.us/Compensation/JobDescriptions.aspx.\n     \n \n \n \n \n \n As a state agency, DFPS is required Texas Administrative Code (TAC 206 and 213) to ensure all Electronic Information Resources (EIR) follow accessibility standards. The staff must be familiar with the WCAG 2.1 AA and Section 508 to create accessible content including but not limited to; Microsoft Office documents, Adobe PDFs, webpages, software, training guides, video, and audio files. \n \n \n \n \n \n \n HHS agencies use E-Verify. You must bring your I-9 documentation with you on your first day of work. \n \n \n In compliance with the Americans with Disabilities Act (ADA), HHS agencies will provide reasonable accommodation during the hiring and selection process for qualified individuals with a disability. If you need assistance completing the on-line application, contact the HHS Employee Service Center at 1-888-894-4747. If you are contacted for an interview and need accommodation to participate in the interview process, please notify the person scheduling the interview.",
        "cleaned_desc": "     \n \n \n \n \n \n \n \n \n Knowledge Skills Abilities: \n \n At least five (5) years\u2019 experience in a role demonstrating business systems analysis expertise.  \n \n Knowledge of the Business Analysis Body of Knowledge (BABOK).  \n \n Knowledge of Project Management Body of Knowlede (PMBOK) and Project Management Life Cycle (PMLC) methodologies.  \n \n Knowledge of Software Development Life Cycle (SDLC) and high-level system design methodologies and techniques (entity/relationship models, data/process flow diagrams); object-oriented programming and of programming client/server applications.  \n \n Exceptional interpersonal, presentation building, meeting faciliatation, public-speaking, writing, editing, and proofreading skills.  \n \n Experience researching, understanding and summarizing key and/or abstract ideas and when applicable, suggest recommendations from those findings.  \n \n Consistently demonstrates strong analytical and critical thinking skills.  \n \n Ability to identify and address existing and potential obstacles, issues and opportunities; and identify and mitigate key issues affecting the progress of organization and process solutions.  \n \n Working knowledge of productivity software including Microsoft Office Suite to include MS Word, Excel, PowerPoint, MS Project, SharePoint, Visio and/or SQL.  \n \n Demonstrates excellent organization skills, e.g., defines and organizes tasks, responsibilities and priorities.  \n \n Ability to develop documentation that maps and illustrates processes and develop framework for process improvement.  \n \n Demonstrated experience in expressing technical and business concepts and conclusions orally and in writing.  \n \n Experience leading teams.  ",
        "techs": [
            "knowledge skills abilities: \n- business analysis body of knowledge (babok)\n- project management body of knowledge (pmbok)\n- project management life cycle (pmlc)\n- software development life cycle (sdlc)\n- entity/relationship models\n- data/process flow diagrams\n- object-oriented programming\n- client/server applications\n- microsoft office suite\n- ms word\n- ms excel\n- ms powerpoint\n- ms project\n- sharepoint\n- visio\n- sql"
        ],
        "cleaned_techs": []
    },
    "87c981842932da43": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 83720.0,
        "salary_max": 136240.0,
        "title": "Business Analysis Specialist (Remote)",
        "company": "TD Bank",
        "desc": "Business Analysis Specialist (Remote) \n \n \n \n    422349BR\n    \n \n \n Job Category - Primary \n \n    Business Analysis / Reporting \n    \n \n \n Work Location \n \n    Remote Mount Laurel (NJ) \n    \n \n \n Employment Type \n \n    Regular \n    \n \n \n City \n \n    Mount Laurel \n    \n \n \n Time Type \n \n    Full Time \n    \n \n \n State \n \n    Nationwide\n    \n \n \n Hours \n \n    40\n    \n \n \n Pay Range \n \n    $83,720 - $136,240 annually \n    \n \n \n Benefits \n \n    For an overview of TD's Benefits program, please visit TD's Total Rewards site \n    \n \n \n Job Searches Match \n \n    Nationwide\n    \n \n \n Department Overview \n \n    Plan, manage, lead and oversee the end-to-end delivery of requirements throughout the lifecycle of the project in alignment with the business and/or enterprise needs and strategies. Provide leadership and work collaboratively with stakeholders including business, technology and finance partners to support project benefits and changes to business processes, policies and systems across single or multiple Lines of Business (LoB).\n    \n \n \n Job Details \n \n Depth & Scope: \n \n  Leads Requirements Management / work packages for Tier 2, high risk, strategic and regulatory projects or programs and may lead requirements may lead Requirements Management for Tier 1 projects/programs \n  Expert knowledge of business analysis, project delivery practices and standards across the project life-cycle \n  Gain/acquire advanced understanding of business and user interaction with technology throughout project delivery \n  Works autonomously as the lead business analyst and coaches and guides members within area of expertise \n  Identifies and leads problem resolution for complex requirements related issues at all levels \n  Contributes to the communication and change Management activities across multiple stakeholders \n \n \n \n \n Job Requirements \n \n \n     Must be eligible for employment under regulatory standards applicable to the position.\n     \n \n \n \n Qualifications \n \n    Digital platforms experience preferred\n    \n \n \n Company Overview \n \n About TD Bank, America's Most Convenient Bank\u00ae  \n TD Bank, America's Most Convenient Bank, is one of the 10 largest banks in the U.S., providing over 9.8 million customers with a full range of retail, small business and commercial banking products and services at more than 1,100 convenient locations throughout the Northeast, Mid-Atlantic, Metro D.C., the Carolinas and Florida. In addition, TD Auto Finance, a division of TD Bank, N.A., offers vehicle financing and dealer commercial services. TD Bank and its subsidiaries also offer customized private banking and wealth management services through TD Wealth\u00ae. TD Bank is headquartered in Cherry Hill, N.J. \n \n We offer a competitive salary and benefit program, including: comprehensive, affordable health care through medical, dental, and vision coverage; financial security with life and disability insurance; opportunities to save using health savings and flexible spending accounts; retirement benefits to help prepare for the future; paid time off and work/life benefits to maintain a good balance. \n \n \n \n Inclusiveness \n \n At TD, we are committed to fostering an inclusive, accessible environment, where all employees and customers feel valued, respected and supported. We are dedicated to building a workforce that reflects the diversity of our customers and communities in which we live in and serve, and creating an environment where every employee has the opportunity to reach their potential. \n  If you are a candidate with a disability and need an accommodation to complete the application process, email the TD Bank US Workplace Accommodations Program at USWAPTDO@td.com . Include your full name, best way to reach you, and the accommodation needed to assist you with the application process. \n  EOE/Minorities/Females/Veterans/Individuals with Disabilities/Sexual Orientation/Gender Identity. \n \n \n \n Business Line \n \n    TD Bank AMCB\n    \n \n \n Job Category(s) \n \n    Business Analysis / Reporting \n    \n \n \n Country \n \n    United States \n    \n \n \n State (Primary) \n \n    New Jersey \n    \n \n \n City (Primary) \n \n    Mount Laurel \n    \n \n \n Job Expires \n \n    20-Oct-2023",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "b9d0b596eadb1bae": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 75240.75,
        "salary_max": 95271.56,
        "title": "Technical Business Analyst",
        "company": "IVANS Insurance Solutions",
        "desc": "Job Overview: \n   Ivans, a division of Applied Systems, is currently searching for a  Technical Business Analyst  to join the Ivans Engineering Team. Engineering is the intersection between business, product, and user experience. The Engineering Team is responsible for designing and building services with a focus on security, stability, and automation. \n  Under the general direction of the Engineering Leadership Team, the Technical Business Analyst ensures a product\u2019s core features and functionality meet the needs of our partners, giving them the ability to integrate their unique workflows and data models quickly and efficiently into IVANS. With a focus on integrating and connecting the industry, the Technical Business Analyst leads the analysis of partner API capabilities to build software that assists with configuring, transmitting, and reporting of data between our platform and partner systems. \n  Success in this role requires a technical background and a willingness to dive into the details. The Technical Business Analyst should be motivated to change the way the industry defines, collects, and moves data between systems. \n \n   What You\u2019ll Do \n \n  Analyzes partner API capabilities for translating and moving data to backend systems from the platform \n  With an understanding of XML and JSON data standards, builds mappings between the support formats \n  Creates technical specifications, functional requirements, and acceptance criteria \n  Develops test cases and data that ensure the requirements and acceptance criteria are met and verified to support a successful release \n  Creates and maintains workflow diagrams to assist the design team when building partner-facing UIs \n  Communicates with internal stakeholders regarding the building, maintaining, and supporting of the platform \n \n \n  What You\u2019ll Need to Succeed \n \n  We\u2019re looking for someone who: \n \n  Can work remotely or from an Ivans office \n \n  Your experience should include some or all of the following: \n \n  Extensive experience  in Technical Business Analysis  in a related industry \n  Advanced knowledge of XML and JSON  data standards \n  Ability to collaborate on programming and analytical problems \n  Strong quantitative, research, and data analytic skills \n  Strong interpersonal and communication skills \n  Ability to work as a member of cross-functional teams to help design solutions \n  Highly motivated self-starter with the ability to work efficiently with minimal supervision \n  Bachelor\u2019s Degree in Computer Science or Information Technology, or similar background gained through professional work experience \n \n  We proudly support and encourage people with military experience, as well as military spouses, to apply \n \n \n  Additionally, you may have: \n \n \n \n  Experience with Agency Management Systems preferred \n  Experience with Policy Administration Systems preferred \n \n \n  Being a part of Ivans \n \n  Benefits from Day One \n \n  Health insurance plans, dental, and vision \n  Wellness incentives \n  401(k) and/or RRSP retirement savings plans with employer match \n \n  Work-Life Balance \n \n  Competitive paid vacation time and a free day for your birthday \n  Personal/sick time \n  Paid holidays \n  Flex Time \n  Volunteer time off \n \n  Empowering Career Growth and Success \u2013 We invest in talent, care about our people and are empowered by the results of our work. We grow our teams from within and give our employees opportunities to advance. \n \n  Moving the Insurance Industry Forward \n  Digital connectivity is the lifeblood of innovation, and at Ivans, we are literally at the heart of what is driving innovation across the entire insurance ecosystem. This is just one of the things that makes Ivans such a cool place to work. Making a difference \u2013 for the industry and within our team \u2013 is what pushes us to do better each day. \n  Our culture is about more than developing the best technology. It\u2019s about being innovative, investing in our team, creating a customer-centric environment, and setting the industry up for the future. A big part of that is attracting, developing, and retaining the best talent for our business and our future. That\u2019s where you come in. You\u2019ll get to work with amazing people on cool innovation that brings the industry forward. \n  Visit ivans.com to learn how you can join us. \n \n  EEO Statement \n  Ivans is proud to be an Equal Employment Opportunity and Affirmative Action Employer. Diversity and Inclusion is a business imperative and is a part of building our brand and reputation. At Ivans, we are committed to recruit, develop, retain, and promote regardless of race, religion, color, national origin, sexual orientation, gender identity, disability, age, veteran status, and other protected status as required by applicable law. \n \n  #LI-Remote",
        "cleaned_desc": "Job Overview: \n   Ivans, a division of Applied Systems, is currently searching for a  Technical Business Analyst  to join the Ivans Engineering Team. Engineering is the intersection between business, product, and user experience. The Engineering Team is responsible for designing and building services with a focus on security, stability, and automation. \n  Under the general direction of the Engineering Leadership Team, the Technical Business Analyst ensures a product\u2019s core features and functionality meet the needs of our partners, giving them the ability to integrate their unique workflows and data models quickly and efficiently into IVANS. With a focus on integrating and connecting the industry, the Technical Business Analyst leads the analysis of partner API capabilities to build software that assists with configuring, transmitting, and reporting of data between our platform and partner systems. \n  Success in this role requires a technical background and a willingness to dive into the details. The Technical Business Analyst should be motivated to change the way the industry defines, collects, and moves data between systems. \n \n   What You\u2019ll Do \n \n  Analyzes partner API capabilities for translating and moving data to backend systems from the platform \n  With an understanding of XML and JSON data standards, builds mappings between the support formats \n  Creates technical specifications, functional requirements, and acceptance criteria \n  Develops test cases and data that ensure the requirements and acceptance criteria are met and verified to support a successful release \n  Creates and maintains workflow diagrams to assist the design team when building partner-facing UIs \n  Communicates with internal stakeholders regarding the building, maintaining, and supporting of the platform    Strong quantitative, research, and data analytic skills \n  Strong interpersonal and communication skills \n  Ability to work as a member of cross-functional teams to help design solutions \n  Highly motivated self-starter with the ability to work efficiently with minimal supervision \n  Bachelor\u2019s Degree in Computer Science or Information Technology, or similar background gained through professional work experience \n \n  We proudly support and encourage people with military experience, as well as military spouses, to apply \n \n \n  Additionally, you may have: \n \n \n ",
        "techs": [
            "webservices",
            "xml",
            "json"
        ],
        "cleaned_techs": [
            "webservices",
            "xml",
            "json"
        ]
    },
    "490a43bc427e7c0c": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 34.0,
        "salary_max": 36.0,
        "title": "Clinical Systems Analyst",
        "company": "RevereIT",
        "desc": "Role: Clinical Informatics Systems Analyst \n Location: Abbott Park, IL - 60064 (Remote- 75% travel, with occasional weekend work, dependent on business need) \n Duration: 12 Months \n Shift Timings: 8:00am to 5:00pm \n Key Skills:  LIS, Middleware, Server and Networking, auto verification. Sound understanding of diagnostics laboratory workflows and related technologies \n Experience: \n \u00b7 2-3 years of experience Lim experience (good) but need LIS experience / Hospital setting/research background/ Middleware work experience, Instrumentation, auto verification/ lab workflow/ Hospital setting with Networking experiencing. \n \u00b7 Hands on experience implementing, configuring, training, and supporting one or more laboratory information systems mentioned above is highly desirable. \n Qualification: \n \u00b7 Education in Computer Science, Information Systems, Medical or Hospital Informatics or related disciplines \n \u00b7 1-3 years of experience preferred installing, configuring and/ or maintaining diagnostics laboratory informatics applications or relevant comparable experience. \n Special Skills & Knowledge: \n \u00b7 Sound understanding of diagnostics laboratory workflows and related technologies \n \u00b7 Demonstrated understanding of one or more products such as laboratory information systems, middleware and/or analyzer management systems, or inventory management systems used in diagnostics laboratories \n \u00b7 Hands on experience implementing, configuring, training and supporting one or more laboratory information systems mentioned above is highly desirable \n \u00b7 Able to execute assigned tasks satisfactorily with a high degree of commitment and quality, independently \n \u00b7 Technical proficiency with general business applications such as MS Office, MS Project/ SmartSheet.Responsibilities: - Collect and analyze data from various sources using data mining techniques - Design and develop systems to support data analysis and reporting - Collaborate with cross-functional teams to understand business requirements and translate them into technical solutions - Perform data analysis to identify trends, patterns, and insights - Develop and maintain SQL queries and scripts for data extraction and manipulation - Conduct system design and testing activities to ensure data integrity and accuracy - Provide technical support and troubleshooting for system-related issues - Stay up-to-date with industry trends and advancements in data analysis techniques \n Qualifications: - Bachelor's degree in Computer Science, Information Systems, or a related field - Proven experience in data analysis, preferably in the healthcare or managed care industry - Strong knowledge of data mining techniques, SQL, and database management systems - Familiarity with Epic or other electronic health record systems is a plus - Experience in clinical trials or bioinformatics is highly desirable - Excellent analytical skills with the ability to interpret complex data sets - Strong problem-solving abilities and attention to detail - Effective communication skills to collaborate with stakeholders at all levels \n Note: This position requires strong technical skills in data analysis and system design. The ideal candidate should have a solid understanding of healthcare industry processes and terminology. \n Job Type: Contract \n Salary: $34.00 - $36.00 per hour \n Expected hours: 40 per week \n Schedule: \n \n Day shift \n Monday to Friday \n \n Experience: \n \n Server: 1 year (Required) \n Laboratory: 1 year (Required) \n Networking: 1 year (Required) \n Middleware: 1 year (Required) \n LIS: 1 year (Required) \n \n Work Location: Remote",
        "cleaned_desc": " \u00b7 Hands on experience implementing, configuring, training and supporting one or more laboratory information systems mentioned above is highly desirable \n \u00b7 Able to execute assigned tasks satisfactorily with a high degree of commitment and quality, independently \n \u00b7 Technical proficiency with general business applications such as MS Office, MS Project/ SmartSheet.Responsibilities: - Collect and analyze data from various sources using data mining techniques - Design and develop systems to support data analysis and reporting - Collaborate with cross-functional teams to understand business requirements and translate them into technical solutions - Perform data analysis to identify trends, patterns, and insights - Develop and maintain SQL queries and scripts for data extraction and manipulation - Conduct system design and testing activities to ensure data integrity and accuracy - Provide technical support and troubleshooting for system-related issues - Stay up-to-date with industry trends and advancements in data analysis techniques \n Qualifications: - Bachelor's degree in Computer Science, Information Systems, or a related field - Proven experience in data analysis, preferably in the healthcare or managed care industry - Strong knowledge of data mining techniques, SQL, and database management systems - Familiarity with Epic or other electronic health record systems is a plus - Experience in clinical trials or bioinformatics is highly desirable - Excellent analytical skills with the ability to interpret complex data sets - Strong problem-solving abilities and attention to detail - Effective communication skills to collaborate with stakeholders at all levels \n Note: This position requires strong technical skills in data analysis and system design. The ideal candidate should have a solid understanding of healthcare industry processes and terminology. \n Job Type: Contract \n Salary: $34.00 - $36.00 per hour ",
        "techs": [
            "ms office",
            "ms project/ smartsheet",
            "data mining techniques",
            "sql",
            "database management systems",
            "epic",
            "electronic health record systems"
        ],
        "cleaned_techs": [
            "microsoft",
            "ms project/ smartsheet",
            "data mining techniques",
            "sql",
            "database management systems",
            "epic",
            "electronic health record systems"
        ]
    },
    "692bb7a59e568704": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 95000.0,
        "salary_max": 141000.0,
        "title": "Business Intelligence Lead",
        "company": "Nationwide IT Services, Inc",
        "desc": "Business Intelligence Lead   DMV (Remote)     Position Overview:  Nationwide IT Services (NIS) has a potential opportunity for an experienced Business Intelligence Lead in support of a Federal Agency focused on the overall assessment of Agency analyses and products to inform Agency leadership. This lead shall also provide recommendations, designs, and dashboard products that can be used to create, modify, and implement business intelligence products for multiple audiences of Component management.     Qualifications:   Five (5) years of experience in business Intelligence developing analyses, dashboards and business intelligence products.  The business intelligence lead shall demonstrate knowledge of and proficiency in analysis software published by SAS as well as visualization software published by Oracle and Tableau.     Required Education/Certification:  The business intelligence lead shall have a Bachelor of Science in Engineering, Mathematics, Business Administration, or related subject       About Nationwide IT Services  NIS is an IT and Management consulting company, designated 8(a) by the SBA, and a CVE-verified Service Disabled Veteran Owned Small Business. Our mission is to deliver value-added services to our customers, leveraging technology, people, and industry best practices to implement innovative solutions through our trusted employees and team members.    Our benefits package includes medical, dental, and vision insurance, life and disability insurance, 401(k) plan with employer match, paid holidays, PTO (sick/vacation), commuter benefits, employee assistance program (EAP) and educational reimbursement along with Pet Insurance.     Nationwide IT Services, Inc. provides equal employment opportunities (EEO) to all qualified applicants for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, genetics, disability or protected veteran status.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "c272ad02282fc96c": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 56000.0,
        "salary_max": 73000.0,
        "title": "Int Enhanced Underwriting Analyst",
        "company": "Transamerica",
        "desc": "Job Family\n   Underwriting\n  \n \n \n    Who We Are\n   \n \n \n \n \n  Transamerica has been helping people feel better about the future for more than 100 years. We provide investment, retirement, and life insurance solutions to more than 11 million customers throughout the U.S. But the way we see it, our responsibility goes beyond our clients\u2019 accounts. We\u2019re in the business of helping people live well and empowering them to create a better tomorrow through the financial and health-related habits they form today. We help people prepare by providing solutions that consider the whole picture.\n   \n \n \n    What We Do\n   \n \n \n    Transamerica is organized by lines of business (Life Insurance, Annuities, Mutual Funds, Retirement Plans, Employee Benefits, and Financial Assets), which are supported by Transamerica Corporate (Corporate Development; Finance; Internal Audit; Legislative, Regulatory & Policy; Office of the CEO; People, Places & Brand; Risk; and Technology).\n   \n \n \n \n   Job Description Summary\n   Responsible for the development, operation, and refinement of digitizing the life insurance experience and products. Primary focus will be creating test matrices and execution.\n   Staff at this level maintain approval authority of $250K to $500K.\n  \n   Job Description\n  \n \n   Responsibilities\n  \n \n  Prepare cases for test beds and conduct tests to determine if the decision engine and/or underwriting system is functioning correctly. \n  Conduct full and risk-based testing, identifying areas for improvement. \n  Analyze data to ensure accuracy and alignment with the traditional underwriting experience; identify gaps for resolution. \n  Provide underwriting expertise in building the evolving decision engine and workflow. \n  Collaborate with the enhanced underwriting project team and related stakeholders in New Business, Project Management, Data Analytics, Medical, Actuarial, Sales & Marketing, vendors, etc. \n  Keep abreast of relevant events in the insurance sector. \n  Help develop cost effective and customer friendly processes for assessing risk. \n \n \n \n   Qualifications\n  \n \n  Bachelor\u2019s degree in a business field or equivalent experience \n  Two years of life or health underwriting experience \n  One year of underwriting experience within Transamerica or one year of experience working on an enhanced underwriting project \n  Basic understanding of enhanced underwriting user interface \n  Knowledge of industry products \n  Communication and interpersonal skills to interact with multiple business groups, including New Business, Project Management, Data Analytics, Medical, Actuaries, Sales & Marketing, etc. \n  Decision-making and problem-solving skills \n  Ability to work in a team environment to deliver a high functioning decision engine \n  Time-management skills to work on multiple priorities simultaneously \n  Willingness to continue education to stay current in the insurance sector \n  Proficiency in MS Office \n \n \n \n   Preferred Qualifications\n  \n \n  Completion of FALU or completion of coursework toward designation \n  FLMI designation or completion of coursework toward designation \n  Previously worked with MRAS \n  Significant experience in an Agile project environment \n \n \n \n   Working Conditions\n  \n \n  Office environment of remote from home \n  Occasional travel \n \n \n \n   Compensation\n  \n \n  **Please note that the compensation information that follows is a good faith estimate for this position only and is provided pursuant to applicable pay transparency and compensation posting laws. It is estimated based on what a successful candidate might be paid in certain Company locations.** \n \n \n \n  The Salary for this position generally ranges between $56-73K. This range is an estimate, based on potential qualifications and operational needs. Salary may vary above and below the stated amounts, as permitted by applicable law.\n  \n \n \n  Additionally, this position is typically eligible for an Annual Bonus of 7.5% based on the Company Bonus Plan/Individual Performance and is at Company discretion.\n  \n \n \n  This job description is not a contract of employment nor for any specific job responsibilities. The Company may change, add to, remove, or revoke the terms of this job description at its discretion. Managers may assign other duties and responsibilities as needed. In the event an employee or applicant requests or requires an accommodation to perform job functions, the applicable HR Business Partner should be contacted to evaluate the accommodation request. \n \n \n \n   What We Offer\n  \n \n \n \n  For eligible employees, we offer a comprehensive benefits package designed to support both the personal and financial well-being of our employees.\n   \n \n \n \n \n  Compensation Benefits\n   \n \n \n \n \n \n \n       Competitive Pay\n      \n \n \n       Bonus for Eligible Employees\n      \n \n \n \n \n \n  Benefits Package\n    \n \n \n \n \n \n       Pension Plan\n      \n \n \n       401k Match\n      \n \n \n       Employee Stock Purchase Plan\n      \n \n \n       Tuition Reimbursement\n      \n \n \n       Disability Insurance\n      \n \n \n       Medical Insurance\n      \n \n \n       Dental Insurance\n      \n \n \n       Vision Insurance\n      \n \n \n       Employee Discounts\n      \n \n \n       Career Training & Development Opportunities\n      \n \n \n \n \n \n \n \n  Health and Work/Life Balance Benefits\n    \n \n \n \n \n \n       Paid Time Off starting at 160 hours annually for employees in their first year of service.\n      \n \n \n       Ten (10) paid holidays per year (typically mirroring the New York Stock Exchange (NYSE) holidays).\n      \n \n \n       Be Well Company holistic wellness program, which includes Wellness Coaching and Reward Dollars\n      \n \n \n       Parental Leave \u2013 fifteen (15) days of paid parental leave per calendar year to eligible employees with at least one year of service at the time of birth, placement of an adopted child, or placement of a foster care child.\n      \n \n \n       Adoption Assistance\n      \n \n \n       Employee Assistance Program\n      \n \n \n       College Coach Program\n      \n \n \n       Back-Up Care Program\n      \n \n \n       PTO for Volunteer Hours\n      \n \n \n       Employee Matching Gifts Program\n      \n \n \n       Employee Resource Groups\n      \n \n \n       Inclusion and Diversity Programs\n      \n \n \n       Employee Recognition Program\n      \n \n \n       Referral Bonus Programs\n      \n \n \n       Peer Recognition Program (BRAVO)\n      \n \n \n \n \n \n \n  Inclusion & Diversity\n   \n \n \n \n \n  Transamerica has made a strong commitment to inclusion and diversity, and we are proud to be an organization where all perspectives are valued. Transamerica has earned recognition for its strong efforts year-over-year, including from the Human Rights Campaign\u2019s Foundation Corporate Equality Index, the Diversity Best Practices Inclusion Index, and Seramount\u2019s \u201c100 Best Companies\u201d list.\n   \n \n \n \n \n  In addition, as part of Transamerica\u2019s commitment to maintaining an inclusive workplace, the company sponsors employee-driven Employee Resource Groups (ERGs), which are formed around a shared interest or a common characteristic of diversity. ERGs are open to all employees and provide a supportive environment for raising diversity awareness and promoting inclusive behavior.\n   \n \n \n \n \n  Giving Back\n   \n \n \n \n \n  Transamerica believes our responsibilities extend beyond our corporate walls. That's why we created the Aegon Transamerica Foundation in 1994. Through a combination of financial grants and the volunteer commitment of our employees, this foundation supports nonprofit organizations focused on the education, health, and well-being of the communities where we live and work.\n   \n \n \n \n \n \n  https://www.transamerica.com/why-transamerica/aegon-transamerica-foundation\n    \n \n \n \n \n \n  Transamerica\u2019s Parent Company\n   \n \n \n \n \n \n     Aegon\n     acquired the Transamerica business in 1999. Aegon\u2019s roots go back more than 175 years to the first half of the nineteenth century. Since then, Aegon has grown into an international company, with businesses in the Americas, Europe, and Asia. Today, Aegon is one of the world\u2019s leading financial services organizations, providing life insurance, pensions, and asset management. As a leading global investor and employer, the company seeks to have a positive impact by addressing critical environmental and societal issues, with a focus on climate change and inclusion and diversity.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "bdbbc9f02e51f0f4": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 73500.0,
        "salary_max": 150000.0,
        "title": "Sr. IAM Controls Testing Analyst",
        "company": "CVS Health",
        "desc": "Bring your heart to CVS Health. Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand \u2014 with heart at its center \u2014 our purpose sends a personal message that how we deliver our services is just as important as what we deliver.    Our Heart At Work Behaviors\u2122 support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable. \n \n  Position Summary \n \n   Key focus on testing the Identity Access Management (IAM) control standards. This will include helping to build out the testing program and execute to that program.\n   \n \n may include participation in all Controls & Governance activities including: \n  o Development and Interpretation of Control Standards, Procedures\n    o Development and measurement of Key Risk Indicators\n    o Conducting Risk Control Self Assessments\n    o Execution of IAM controls including Periodic Access Review\n    o Issue identification and management\n    o Liaison with other oversight organizations such as audit teams\n   \n \n Advisory on process changes impacting IAM workflows to ensure compliance with firm standards \n Participate in developing IAM solutions \u2013 representing the GRC needs \n Communicate and educate business and IT colleagues on IAM GRC topics \n \n \n  Required Qualifications \n \n \n Experience conducting audit/assessment type control testing \n knowledge and experience with legal, privacy, and regulatory compliance \n Familiarity with standards such NIST 800, ISO 27000 \n Familiarity with SOX, SOC, PCI Audits \n 3+ years of experience working in IT Audit (preferred), Controls & Governance, Risk, and/or compliance function \n \n  Preferred Qualifications \n \n Ability to handle multiple competing priorities. \n Self-starter, ability to work across organizations, drive projects to closure \u2013 result and relationship focused. \n Ability to identify problems, analyze data, and present conclusions convincingly \n Strong verbal, written, and presentations skills \n Experience with compliance or regulatory issues preferred \n Strong verbal, written, and presentations skills \n Exposure to IAM technology, solutions and concepts \u2013 Authentication, Authorization etc. \n \n  Education \n  Bachelors degree or eq \n \n  Pay Range \n  The typical pay range for this role is: \n  $73,500.00 - $150,000.00\n  \n  This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above.    In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company\u2019s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (\u201cPTO\u201d) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies.    For more detailed information on available benefits, please visit jobs.CVSHealth.com/benefits \n \n  CVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated. \n \n  You are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work. \n \n  CVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health can provide a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services through ColleagueRelations@CVSHealth.com If you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.",
        "cleaned_desc": "  Preferred Qualifications \n \n Ability to handle multiple competing priorities. \n Self-starter, ability to work across organizations, drive projects to closure \u2013 result and relationship focused. \n Ability to identify problems, analyze data, and present conclusions convincingly \n Strong verbal, written, and presentations skills \n Experience with compliance or regulatory issues preferred \n Strong verbal, written, and presentations skills \n Exposure to IAM technology, solutions and concepts \u2013 Authentication, Authorization etc. \n ",
        "techs": [
            "iam technology"
        ],
        "cleaned_techs": [
            "iam technology"
        ]
    },
    "0eec8b04f245bf0d": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 80913.664,
        "salary_max": 102454.73,
        "title": "Senior Business Analyst",
        "company": "Ameren",
        "desc": "If end date is listed, the posting will come down at 12:00 am on that date:\n  \n \n  Acts as a liaison between development groups and business units for the development and implementation of new systems and enhancement of existing systems. \n  Evaluates new digital developments and evolving business requirements and recommends appropriate systems alternatives and/or enhancements to current systems. \n  Prepares communications and makes presentations on system enhancements and/or alternatives. \n \n \n \n  Key responsibilities include: \n \n \n  Works with stakeholders to identify and clarify moderate to complex business requirements. \n  Facilitates meetings with business stakeholders and Digital to understand business requirements; demonstrates understanding of business needs and recommends design changes for moderately complex challenges. \n  Translates business and design requirements into technical requirements. \n  Directs and owns process/system changes and reviews process changes to ensure design changes meet business requirements. \n  Draws process maps and uses business process modeling techniques. \n  Manages overall catalogue of process flows for medium complexity projects. \n  Analyzes complex source system data in support of improving data quality and translates raw data into information for consumable reports. \n  Performs QA against specifications and solves issues. \n  Assists with conducting tests and inspections of products, services, solutions or processes to evaluate quality or performance. \n  Supports medium complexity projects with little or no degree of supervision, including tracking issues and managing action items. \n  Appropriately documents knowledge and integrates cross-project knowledge, experience and value to make more accurate decisions. \n  Interfaces with agile scrum teams to deliver digital solutions; acts as BA Point of Contact (POC) on scrum team. \n  Provides innovative ideas and insights to redesign business processes that will optimize business results. \n  Acts as a liaison between business stakeholders and vendors to ensure successful implementation and support of project efforts. \n  Communicates with the business and software engineers to develop tools that will solve for client/business requirements. \n  Reviews the Digital organization\u2019s technology enablement and integration plans; demonstrates technical expertise within own technology through determining best course of action for own project. \n  Demonstrates strong working knowledge of agile software development processes and the development lifecycle; liaises with scrum masters and coaches to move project forward. \n  Coaches less experienced co-workers and provides feedback to enhance skills and knowledge. \n \n \n \n   Qualifications:\n  \n \n \n \n     Bachelor\u2019s degree required, preferably in mathematics, computer science, or business.\n    \n \n \n     5 or more years of experience working with IT, related systems/projects required. Business Analyst experience is required.\n    \n \n \n     Three or more years of experience in a customer service oriented and/or IT related field required.\n    \n \n \n     Hands on experience in Oracle EPM suite is necessary. Experience with Oracle Cloud is preferred.\n    \n \n \n     Strong hands on development and administration experience with Consolidations, Planning, Essbase, ODI, FDMEE, DRM, SmartView and Financial Reporting Studio.\n    \n \n \n     Extensive experience in modelling and building financial cubes and data models for reporting financial data using best practices.\n    \n \n \n     Working knowledge of ERP system and strong SQL skills.\n    \n \n \n     Strong Understanding of FP& A principles and best practices.\n    \n \n \n     Experience in utility/energy Corporation a plus.\n    \n \n \n \n   Additional Information\n  \n \n   Ameren\u2019s selection process includes a series of interviews and may include a leadership assessment process. Specific details will be provided to qualified candidates.\n  \n \n \n   #LI-Remote\n  \n \n \n   All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, ethnicity, age, disability, genetic information, military service or status, pregnancy, marital status, sexual orientation, gender identity or expression, or any other class, trait, or status protected by law.",
        "cleaned_desc": "  Manages overall catalogue of process flows for medium complexity projects. \n  Analyzes complex source system data in support of improving data quality and translates raw data into information for consumable reports. \n  Performs QA against specifications and solves issues. \n  Assists with conducting tests and inspections of products, services, solutions or processes to evaluate quality or performance. \n  Supports medium complexity projects with little or no degree of supervision, including tracking issues and managing action items. \n  Appropriately documents knowledge and integrates cross-project knowledge, experience and value to make more accurate decisions. \n  Interfaces with agile scrum teams to deliver digital solutions; acts as BA Point of Contact (POC) on scrum team. \n  Provides innovative ideas and insights to redesign business processes that will optimize business results. \n  Acts as a liaison between business stakeholders and vendors to ensure successful implementation and support of project efforts. \n  Communicates with the business and software engineers to develop tools that will solve for client/business requirements. \n  Reviews the Digital organization\u2019s technology enablement and integration plans; demonstrates technical expertise within own technology through determining best course of action for own project. \n  Demonstrates strong working knowledge of agile software development processes and the development lifecycle; liaises with scrum masters and coaches to move project forward. \n  Coaches less experienced co-workers and provides feedback to enhance skills and knowledge. \n \n \n \n   Qualifications:     \n \n \n     Strong hands on development and administration experience with Consolidations, Planning, Essbase, ODI, FDMEE, DRM, SmartView and Financial Reporting Studio.\n    \n \n \n     Extensive experience in modelling and building financial cubes and data models for reporting financial data using best practices.\n    \n \n \n     Working knowledge of ERP system and strong SQL skills.\n    \n \n \n     Strong Understanding of FP& A principles and best practices.\n    ",
        "techs": [
            "consolidations",
            "planning",
            "essbase",
            "odi",
            "fdmee",
            "drm",
            "smartview",
            "financial reporting studio",
            "erp system",
            "sql"
        ],
        "cleaned_techs": [
            "consolidations",
            "planning",
            "essbase",
            "odi",
            "fdmee",
            "drm",
            "smartview",
            "financial reporting studio",
            "erp system",
            "sql"
        ]
    },
    "204e8adfc1a25f1e": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 75794.38,
        "salary_max": 95972.57,
        "title": "Technical Business Analyst",
        "company": "Applied Systems, Inc.",
        "desc": "Job Description: \n   Ivans, a division of Applied Systems, is currently searching for a  Technical Business Analyst  to join the Ivans Engineering Team. Engineering is the intersection between business, product, and user experience. The Engineering Team is responsible for designing and building services with a focus on security, stability, and automation. \n  Under the general direction of the Engineering Leadership Team, the Technical Business Analyst ensures a product\u2019s core features and functionality meet the needs of our partners, giving them the ability to integrate their unique workflows and data models quickly and efficiently into IVANS. With a focus on integrating and connecting the industry, the Technical Business Analyst leads the analysis of partner API capabilities to build software that assists with configuring, transmitting, and reporting of data between our platform and partner systems. \n  Success in this role requires a technical background and a willingness to dive into the details. The Technical Business Analyst should be motivated to change the way the industry defines, collects, and moves data between systems. \n \n   What You\u2019ll Do \n \n  Analyzes partner API capabilities for translating and moving data to backend systems from the platform \n  With an understanding of XML and JSON data standards, builds mappings between the support formats \n  Creates technical specifications, functional requirements, and acceptance criteria \n  Develops test cases and data that ensure the requirements and acceptance criteria are met and verified to support a successful release \n  Creates and maintains workflow diagrams to assist the design team when building partner-facing UIs \n  Communicates with internal stakeholders regarding the building, maintaining, and supporting of the platform \n \n \n  What You\u2019ll Need to Succeed \n \n  We\u2019re looking for someone who: \n \n  Can work remotely or from an Ivans office \n \n  Your experience should include some or all of the following: \n \n  Extensive experience  in Technical Business Analysis  in a related industry \n  Advanced knowledge of XML and JSON  data standards \n  Ability to collaborate on programming and analytical problems \n  Strong quantitative, research, and data analytic skills \n  Strong interpersonal and communication skills \n  Ability to work as a member of cross-functional teams to help design solutions \n  Highly motivated self-starter with the ability to work efficiently with minimal supervision \n  Bachelor\u2019s Degree in Computer Science or Information Technology, or similar background gained through professional work experience \n \n  We proudly support and encourage people with military experience, as well as military spouses, to apply \n \n \n  Additionally, you may have: \n \n \n \n  Experience with Agency Management Systems preferred \n  Experience with Policy Administration Systems preferred \n \n \n  Being a part of Ivans \n \n  Benefits from Day One \n \n  Health insurance plans, dental, and vision \n  Wellness incentives \n  401(k) and/or RRSP retirement savings plans with employer match \n \n  Work-Life Balance \n \n  Competitive paid vacation time and a free day for your birthday \n  Personal/sick time \n  Paid holidays \n  Flex Time \n  Volunteer time off \n \n  Empowering Career Growth and Success \u2013 We invest in talent, care about our people and are empowered by the results of our work. We grow our teams from within and give our employees opportunities to advance. \n \n  Moving the Insurance Industry Forward \n  Digital connectivity is the lifeblood of innovation, and at Ivans, we are literally at the heart of what is driving innovation across the entire insurance ecosystem. This is just one of the things that makes Ivans such a cool place to work. Making a difference \u2013 for the industry and within our team \u2013 is what pushes us to do better each day. \n  Our culture is about more than developing the best technology. It\u2019s about being innovative, investing in our team, creating a customer-centric environment, and setting the industry up for the future. A big part of that is attracting, developing, and retaining the best talent for our business and our future. That\u2019s where you come in. You\u2019ll get to work with amazing people on cool innovation that brings the industry forward. \n  Visit ivans.com to learn how you can join us. \n \n  EEO Statement \n  Ivans is proud to be an Equal Employment Opportunity and Affirmative Action Employer. Diversity and Inclusion is a business imperative and is a part of building our brand and reputation. At Ivans, we are committed to recruit, develop, retain, and promote regardless of race, religion, color, national origin, sexual orientation, gender identity, disability, age, veteran status, and other protected status as required by applicable law. \n \n  #LI-Remote",
        "cleaned_desc": "Job Description: \n   Ivans, a division of Applied Systems, is currently searching for a  Technical Business Analyst  to join the Ivans Engineering Team. Engineering is the intersection between business, product, and user experience. The Engineering Team is responsible for designing and building services with a focus on security, stability, and automation. \n  Under the general direction of the Engineering Leadership Team, the Technical Business Analyst ensures a product\u2019s core features and functionality meet the needs of our partners, giving them the ability to integrate their unique workflows and data models quickly and efficiently into IVANS. With a focus on integrating and connecting the industry, the Technical Business Analyst leads the analysis of partner API capabilities to build software that assists with configuring, transmitting, and reporting of data between our platform and partner systems. \n  Success in this role requires a technical background and a willingness to dive into the details. The Technical Business Analyst should be motivated to change the way the industry defines, collects, and moves data between systems. \n \n   What You\u2019ll Do \n \n  Analyzes partner API capabilities for translating and moving data to backend systems from the platform \n  With an understanding of XML and JSON data standards, builds mappings between the support formats \n  Creates technical specifications, functional requirements, and acceptance criteria \n  Develops test cases and data that ensure the requirements and acceptance criteria are met and verified to support a successful release \n  Creates and maintains workflow diagrams to assist the design team when building partner-facing UIs \n  Communicates with internal stakeholders regarding the building, maintaining, and supporting of the platform    Strong quantitative, research, and data analytic skills \n  Strong interpersonal and communication skills \n  Ability to work as a member of cross-functional teams to help design solutions \n  Highly motivated self-starter with the ability to work efficiently with minimal supervision \n  Bachelor\u2019s Degree in Computer Science or Information Technology, or similar background gained through professional work experience \n \n  We proudly support and encourage people with military experience, as well as military spouses, to apply \n \n \n  Additionally, you may have: \n \n \n ",
        "techs": [
            "api capabilities",
            "xml",
            "json",
            "technical specifications",
            "functional requirements",
            "acceptance criteria",
            "test cases",
            "workflow diagrams",
            "quantitative skills",
            "research skills",
            "data analytic skills"
        ],
        "cleaned_techs": [
            "api capabilities",
            "xml",
            "json",
            "technical specifications",
            "functional requirements",
            "acceptance criteria",
            "test cases",
            "workflow diagrams"
        ]
    },
    "268637288575e632": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 42.0,
        "salary_max": 45.0,
        "title": "IT Tester/QA Analyst- Senior (NC716555)",
        "company": "Resource Management Associates, LLC",
        "desc": "Tester/QA Analyst- Senior (NC716555) \n The ITQA Analyst III\u2019s role is to develop and establish quality assurance standards and measures for the information technology services within the organization. This individual will also gather and analyze data in support of business cases, proposed projects, and systems requirements. This will include writing test plans and scripts for tracking defects and fixes in product development, software application development, information systems, and operations systems. The ITQA Analyst III will apply proven analytical and problem-solving skills to help validate IT processes through careful testing to maximize the benefit of business investments in IT initiatives. \n Responsibilities: \n \n Serves as a test lead on large complex project involving multiple applications and multiple analysts. \n Actively participates in requirement development meetings to gather/document software testing objectives from business units; and participate in functional and technical meetings, from the beginning of the project through the entire life cycle. \n Review Business Requirements, Functional Specifications, and Technical Specifications to understand the functional and technical requirements to determine the range and scope of testing scenarios needed to fully exercise new or changed code. \n Create test plans/strategies for application releases; and facilitate test strategy and test plan walkthrough. \n Write test scenarios, test plans and test sets/test cases in compliance with Quality Services and industry standards for complex business functions and/or multi-system/integrated environments. \n Participate in test environment planning and identify, create test data following data compliance standards and requirements. \n Execute end-to-end manual and/or automated tests, documents results, and work with developers to remediate issues/retest defects; collaborate with other teams to achieve end-to-end process quality. \n Use testing tools to record testing statuses, defects management and generate reports. \n Host defect triage meetings to track all defects and ensure the correct resolution in timely manner. \n Test any new software to ensure integration into company systems meets functional requirements, system compliance, and technical specifications. \n Design and maintain regression test suite in a manner to support Automation. \n Supervise the tactical work of other analysts, track, and report test results for the application's compliance to the functional specifications. \n Communicate test progress, test results, and other relevant information to project stakeholders and management. \n Serves as the point of contact for specific business or technical partners. \n Support change management/release management activities with detailed information regarding dependencies or risks identified during testing. \n Track project progress through associated KPI\u2019s and review with Quality Services leadership team. \n Coordinate with end-users to test when additional business/functional subject matter expertise is needed. \n Participate in developing, distributing, and coordinating in-depth end-user reviews for modified and new systems or applications. \n \n Knowledge, Skills & Abilities \n \n Bachelor's degree in computer science, Information Technology, Business Administration, or related field. \n 4 to 6 years of direct experience in define, design, and deliver all testing work, including Functional Testing, System Integration Testing, Regression, and support User Acceptance Testing. \n 2 to 3 years of direct experience as a lead tester for major application integration and/or major application product release. \n Experience working in SDLC models Waterfall and Agile. \n Experience with core software applications, including Microsoft web and Client/server applications. \n Experience in using Test Management tools like Azure Devops, Jira, ALM or any other Test Management tool. \n Strong knowledge of system testing best practices and methodologies. \n Excellent written and oral communication skills. \n Ability to communicate ideas in both technical and user-friendly language. \n Able to prioritize and execute tasks in a high-pressure environment. \n Experience working in a team-oriented, collaborative environment. \n \n Domain Specific Skills: \n \n Experience with core software applications including CRM is required. \n Direct hands-on experience in writing medium to complex SQL queries for data analysis & data verification using Microsoft SQL Server required. \n Direct hands-on experience with Mobile App [Native & Hybrid, iOS & Android]. \n Direct hands-on experience of testing HRMS applications like Peoplesoft is a plus. \n \n Work Conditions: \n \n Occasional evening and weekend work to meet deadlines. \n Physically able to participate in meetings, training sessions and presentations. \n \n Job Types: Temporary, Contract, Full-time \n Pay: $42.00 - $45.00 per hour \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Application Question(s): \n \n Can you work off a W-2 or 1099? \n \n Experience: \n \n define, design, and deliver testing work: 4 years (Preferred) \n lead tester for major application integration: 2 years (Preferred) \n working in SDLC models Waterfall and Agile: 2 years (Preferred) \n Microsoft web and Client/server applications: 2 years (Preferred) \n Azure Devops, Jira, ALM or any other Test Management tool: 2 years (Preferred) \n CRM: 2 years (Preferred) \n Mobile App [Native & Hybrid, iOS & Android]: 2 years (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": "Tester/QA Analyst- Senior (NC716555) \n The ITQA Analyst III\u2019s role is to develop and establish quality assurance standards and measures for the information technology services within the organization. This individual will also gather and analyze data in support of business cases, proposed projects, and systems requirements. This will include writing test plans and scripts for tracking defects and fixes in product development, software application development, information systems, and operations systems. The ITQA Analyst III will apply proven analytical and problem-solving skills to help validate IT processes through careful testing to maximize the benefit of business investments in IT initiatives. \n Responsibilities: \n \n Serves as a test lead on large complex project involving multiple applications and multiple analysts. \n Actively participates in requirement development meetings to gather/document software testing objectives from business units; and participate in functional and technical meetings, from the beginning of the project through the entire life cycle. \n Review Business Requirements, Functional Specifications, and Technical Specifications to understand the functional and technical requirements to determine the range and scope of testing scenarios needed to fully exercise new or changed code. \n Create test plans/strategies for application releases; and facilitate test strategy and test plan walkthrough. \n Write test scenarios, test plans and test sets/test cases in compliance with Quality Services and industry standards for complex business functions and/or multi-system/integrated environments. \n Participate in test environment planning and identify, create test data following data compliance standards and requirements. \n Execute end-to-end manual and/or automated tests, documents results, and work with developers to remediate issues/retest defects; collaborate with other teams to achieve end-to-end process quality. \n Use testing tools to record testing statuses, defects management and generate reports. \n Host defect triage meetings to track all defects and ensure the correct resolution in timely manner. \n Test any new software to ensure integration into company systems meets functional requirements, system compliance, and technical specifications.   Design and maintain regression test suite in a manner to support Automation. \n Supervise the tactical work of other analysts, track, and report test results for the application's compliance to the functional specifications. \n Communicate test progress, test results, and other relevant information to project stakeholders and management. \n Serves as the point of contact for specific business or technical partners. \n Support change management/release management activities with detailed information regarding dependencies or risks identified during testing. \n Track project progress through associated KPI\u2019s and review with Quality Services leadership team. \n Coordinate with end-users to test when additional business/functional subject matter expertise is needed. \n Participate in developing, distributing, and coordinating in-depth end-user reviews for modified and new systems or applications. \n \n Knowledge, Skills & Abilities \n \n Bachelor's degree in computer science, Information Technology, Business Administration, or related field. \n 4 to 6 years of direct experience in define, design, and deliver all testing work, including Functional Testing, System Integration Testing, Regression, and support User Acceptance Testing. \n 2 to 3 years of direct experience as a lead tester for major application integration and/or major application product release.   Experience working in SDLC models Waterfall and Agile. \n Experience with core software applications, including Microsoft web and Client/server applications. \n Experience in using Test Management tools like Azure Devops, Jira, ALM or any other Test Management tool. \n Strong knowledge of system testing best practices and methodologies. \n Excellent written and oral communication skills. \n Ability to communicate ideas in both technical and user-friendly language. \n Able to prioritize and execute tasks in a high-pressure environment. \n Experience working in a team-oriented, collaborative environment. \n \n Domain Specific Skills: \n \n Experience with core software applications including CRM is required. \n Direct hands-on experience in writing medium to complex SQL queries for data analysis & data verification using Microsoft SQL Server required. \n Direct hands-on experience with Mobile App [Native & Hybrid, iOS & Android]. ",
        "techs": [
            "azure devops",
            "jira",
            "alm",
            "microsoft sql server",
            "crm",
            "mobile app (native & hybrid",
            "ios & android)"
        ],
        "cleaned_techs": [
            "azure",
            "jira",
            "alm",
            "microsoft sql server",
            "crm",
            "mobile app (native & hybrid",
            "ios & android)"
        ]
    },
    "016f15efafef55f0": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 89399.25,
        "salary_max": 113199.375,
        "title": "Senior Business Analyst - Health (HYBRID)",
        "company": "Inclusively",
        "desc": "Inclusively is partnering with a multinational financial services company to hire a Senior Business Analyst - Health (HYBRID). \n ABOUT INCLUSIVELY: \n Inclusively is a digital tech platform that connects candidates with disabilities, who may benefit from workplace accommodations, to inclusive employers. This includes all disabilities under the ADA, including mental health conditions (e.g. anxiety, depression, PTSD), chronic illnesses (e.g. diabetes, Long COVID), and neurodivergence (e.g. autism, ADHD).  Applicants with one or more of these conditions are encouraged to apply; Inclusively does not require applicants to disclose their specific disability. \n The Expertise and Skills You Bring \n \n Bachelor\u2019s degree or equivalent years of experience required \n 5+ years software Development Business Analyst experience, ideally working in an Agile Scrum environment, with demonstrable ability to work across multiple multi-functional teams or Master\u2019s degree in related filed with solid software product development skills. \n Solid understanding industry experience in health care and/or benefits administration and/or product development preferred. \n Shown expertise in various business analysis methodologies and techniques, including data analysis, use case development, story writing, user acceptance testing, and product documentation. \n Solid grasp of the architecture and deployment needed to support web development \n Interact closely with Subject Matter Experts and stakeholders across Health Benefits domain to elicit Product requirements \n Work with UXD teams to support prototyping \n Skilled in MS Word, Excel, PowerPoint, Visio; Experience with JIRA or similar agile backlog management and testing tool \n Certified Business Analysis Professional\u00ae (CBAP\u00ae) certification or Certified Scrum Product Owner certification is a plus \n Skilled at translating business vision into defined and prioritized user stories for team\u2019s backlog \n Ability to understand complex customer needs, translate them into user stories with concrete acceptance criteria, and drive solution formulation with a multi-functional team \n Customer-obsessed and have demonstrated a commitment to delivering frequent, high business value features \n Look for opportunities to innovate and take thoughtful risks to get work done better and faster \n Excellent listening, communication (verbal and written), and presentation skills \n You effectively and regularly lead, facilitate, and drive individuals and group meetings to common goals \n You are highly organized and have a strong ability to prioritize and work under tight deadlines \n Skilled at building relationships, fostering strong teams, and influencing others \n You are a self-motivated, great teammate with the ability to plan and complete work independently, and partner effectively to handle dependencies \n Strong desire to learn and develop additional skills and expertise over time, as well as drive process improvement \n You have excellent business judgement and maintain confidentiality of all data \n Providing consulting, support, and guidance to leadership, squad members, and other relevant partners to influence culture and behaviors \n \n The Value You Deliver \n \n Working in a Scrum Agile environment to deliver software products \n Leading and conducting business analyses to formulate and make recommendations \n Identifying and defining solutions to business problems, through creation and documentation of systems and process specifications \n Creating, documenting, and leading scrum team backlog (writing user stories / acceptance criteria, supporting prioritization, running refinement sessions, etc.) \n Collaborate closely with business partners, development teams, external vendors, and QA on plans, project management, requirements, design, testing, and implementation of solutions throughout the development lifecycle \n Supporting deployment, business readiness, and solution enablement, e.g., defining and documenting enablement tasks, supporting user procedure documentation, creation and delivery of solution training to internal teams, and communication \n Prioritize multiple initiatives and business analysis tasks at the same time \n \n Job Type: Full-time \n Schedule: \n \n Monday to Friday \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "20453719b65f0639": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 65000.0,
        "salary_max": 75000.0,
        "title": "Board Certified Behavior Analyst",
        "company": "Autism Center of Sauk Valley",
        "desc": "About us \n We are data-driven, supportive, collaborative and our goal is to empower children to reach new heights. \n Our work environment includes: \n \n Work-from-home days \n Growth opportunities \n Flexible working hours \n Relaxed atmosphere \n \n Company Description \n The Autism Center of Sauk Valley provides comprehensive Applied Behavior Analysis (ABA) therapy across Sterling, Rock Falls, Dixon, and surrounding areas including direct, one-to-one therapy services, in-depth caregiver training, and consultation services. ABA therapy is a data-driven, evidence-based treatment that is effective in improving social, communication, and adaptive skills while reducing problem behaviors. We are dedicated to providing support and empowering families in helping their children reach new heights. \n Role Description \n This is a full-time hybrid role for a Board Certified Behavior Analyst. The BCBA will be responsible for providing in-person and telehealth services to clients in addition to collaborating with the interdisciplinary team members, family members, and caregivers. The BCBA will also provide ongoing training for the Registered Behavior Technicians, and gather and analyze data to create and adjust the Individualized Treatment Plan. The BCBA will be based in Dixon, IL, but will also have some flexibility for remote work. \n Qualifications \n \n Expertise in parent education and support \n Master's degree in Psychology, Behavior Analysis, or related field \n Board Certification in Behavior Analysis (BCBA) \n Experience in developing and monitoring Behavioral Intervention Plans \n Excellent written and verbal communication skills \n Collaborative approach and ability to work effectively in a team environment \n Experience in ABA-based autism treatment preferred \n Ability to supervise Registered Behavior Technicians \n \n Note: This job description is not intended to be all-inclusive. The employee may be required to perform other duties as assigned. \n Job Type: Full-time \n Pay: $65,000.00 - $75,000.00 per year \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Employee assistance program \n Flexible schedule \n Flexible spending account \n Health insurance \n Paid time off \n Parental leave \n Professional development assistance \n Relocation assistance \n Retirement plan \n Tuition reimbursement \n Vision insurance \n \n Compensation package: \n \n Bonus opportunities \n \n Schedule: \n \n Choose your own hours \n \n Experience: \n \n ABA: 1 year (Preferred) \n \n License/Certification: \n \n BCBA (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "37530a97220b3500": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 80000.0,
        "salary_max": 95000.0,
        "title": "Board Certified Behavior Analyst (BCBA)",
        "company": "Above and Beyond Therapy",
        "desc": "Duties: - Conduct behavioral assessments and develop individualized treatment plans for clients with developmental disabilities, specifically autism. - Implement evidence-based behavioral therapy techniques to address challenging behaviors and promote skill development. - Provide direct one-on-one therapy sessions with clients, focusing on behavior management and skill acquisition. - Collaborate with a multidisciplinary team including parents, teachers, and other professionals to ensure consistency in treatment goals and strategies. - Collect and analyze data to track progress and make necessary adjustments to treatment plans. - Provide training and support to parents and caregivers on implementing behavior management strategies at home. \n Experience: - Board Certified Behavior Analyst (BCBA) certification required. - Experience working with children or individuals with developmental disabilities, particularly autism. - Knowledge of applied behavior analysis (ABA) principles and techniques. - Familiarity with special education laws and regulations. - Strong communication skills to effectively collaborate with clients, families, and other professionals. - Ability to collect and analyze data to inform treatment decisions. - Excellent problem-solving skills and ability to adapt strategies based on individual client needs. \n Note: This job description is not intended to be all-inclusive. The employee may perform other related duties as assigned by their supervisor. \n Job Types: Full-time, Part-time \n Pay: $80,000.00 - $95,000.00 per year \n Expected hours: No more than 40 per week \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Flexible schedule \n Health insurance \n Life insurance \n Paid time off \n Professional development assistance \n Referral program \n Vision insurance \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "90330fd001b84ce2": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 122147.62,
        "salary_max": 154666.1,
        "title": "Business Intelligence Lead",
        "company": "Pacific Life",
        "desc": "Job Description: \n  Pacific Life is investing in bright, agile and diverse talent to contribute to our mission of innovating our business and creating a superior customer experience. \n \n  We\u2019re actively seeking a talented Business Intelligence Lead to join our new Workforce Benefits division. This role can be fully remote or hybrid and based in Newport Beach, CA. \n \n  As a Business Intelligence Lead , you\u2019ll play a key role within the Workforce Benefits division to advance our reporting and visualization efforts. You will ensure that we remain agile and will be responsible for leveraging Tableau to develop robust reporting mechanisms to present data in a clear, actionable format to stakeholders across departments. You will report to the Head of Analytics, Workforce Benefits and contribute to driving the Business Intelligence aspects of the overall Analytics strategy. \n \n \n How you will make an impact: \n  Data Visualization & Reporting \n Craft and refine Tableau dashboards that display complex data streams in comprehensible visual formats. Regularly update and adapt reports in line with changing business needs and objectives. \n Stakeholder Collaboration \n Engage regularly with department leads to ascertain their data requirements. Conduct workshops and feedback sessions to refine BI offerings. \n Data Integrity Assurance \n Establish protocols to ensure report accuracy and consistency. Identify and rectify any discrepancies or anomalies in datasets. Collaborate closely with the Data Engineering team \n Training & Capability Building \n Roll out Tableau training sessions for internal stakeholders, ensuring optimal utilization. Develop BI best practices and guidelines for the broader team. \n Performance & Scalability \n Ensure rapid dashboard responsiveness and efficient report generation. Strategize on BI infrastructure scalability to support growing datasets. \n Ad hoc reporting needs \n Generates ad hoc reports and regular datasets or report information for end-users using system tools and database or data warehouse queries and scripts. \n \n \n The experience you will bring: \n  Passion for fostering a data-driven culture. \n Bachelor's degree in Technology , Computer Science, or a related field. \n 6+ years of experience in business intelligence, data analysis, or a similar role. \n Proven expertise in Tableau (certification preferred). \n Proficiency in SQL and understanding of relational databases. \n Strong analytical and problem-solving skills. \n Excellent communication skills, with the ability to present complex information in a clear and concise manner. \n \n \n What will make you stand out: \n  MS and/or MBA degree \n Workforce Benefits, Insurance or Financial Services \n Familiarity with other BI tools is a plus \n Knowledge of Salesforce objects and data structures \n \n  #LI-JA1 \n \n  You belong at Pacific Life \n At Pacific Life we are committed to a culture of belonging, a space where all employees are empowered to be authentic. One way we cultivate an inclusive culture is through our employee connection groups. The purpose of these employee-led groups is to offer a place to build community, connection, camaraderie, and a sense of belonging. Each group can be active in education, advocacy, recruitment, and community building throughout our organization. Learn more about our employee connection groups at www.pacificlife.com. \n \n  Want to learn more about life at Pacific Life? Take an inside look at our company culture: Instagram.com/lifeatpacificlife. \n \n \n Base Pay Range: \n  The base pay range noted provides a basis to determine the appropriate offer dependent upon several factors including but not limited to geographic location, experience, skills, education and pay equity. Also, most employees are eligible for additional incentive pay. \n \n  Your Benefits Start Day 1 \n \n  Your wellbeing is important to Pacific Life, and we\u2019re committed to providing you with flexible benefits that you can tailor to meet your needs. Whether you are focusing on your physical, financial, emotional, or social wellbeing, we\u2019ve got you covered. \n \n  Prioritization of your health and well-being including Medical, Dental, Vision, and Wellbeing Reimbursement Account that can be used on yourself or your eligible dependents \n \n \n Generous paid time off options including:  Paid Time Off, Holiday Schedules, and Financial Planning Time Off \n \n  Paid Parental Leave as well as an Adoption Assistance Program \n \n  Competitive 401k savings plan with company match and an additional contribution regardless of participation \n \n \n EEO Statement: \n  Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.",
        "cleaned_desc": " Data Integrity Assurance \n Establish protocols to ensure report accuracy and consistency. Identify and rectify any discrepancies or anomalies in datasets. Collaborate closely with the Data Engineering team \n Training & Capability Building \n Roll out Tableau training sessions for internal stakeholders, ensuring optimal utilization. Develop BI best practices and guidelines for the broader team. \n Performance & Scalability \n Ensure rapid dashboard responsiveness and efficient report generation. Strategize on BI infrastructure scalability to support growing datasets. \n Ad hoc reporting needs \n Generates ad hoc reports and regular datasets or report information for end-users using system tools and database or data warehouse queries and scripts. \n \n \n The experience you will bring: \n  Passion for fostering a data-driven culture. \n Bachelor's degree in Technology , Computer Science, or a related field.   6+ years of experience in business intelligence, data analysis, or a similar role. \n Proven expertise in Tableau (certification preferred). \n Proficiency in SQL and understanding of relational databases. \n Strong analytical and problem-solving skills. \n Excellent communication skills, with the ability to present complex information in a clear and concise manner. \n \n \n What will make you stand out: \n  MS and/or MBA degree \n Workforce Benefits, Insurance or Financial Services \n Familiarity with other BI tools is a plus \n Knowledge of Salesforce objects and data structures \n ",
        "techs": [
            "tableau",
            "sql",
            "salesforce"
        ],
        "cleaned_techs": [
            "tableau",
            "sql",
            "salesforce"
        ]
    },
    "91a7e2d813ca9797": {
        "terms": [
            "data analyst"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Operation Research System Analyst (ORSA)",
        "company": "Iron EagleX",
        "desc": "Overview: \n  \n  Iron EagleX is a veteran owned defense contracting company based in Tampa, FL. \n \n \n   It is our mission to provide solutions to the most challenging technical problems facing the Department of Defense while simultaneously making a positive impact on our employees and community.\n   Responsibilities: \n  \n  Job Description: \n \n \n \n \n \n Iron EagleX  is looking for an Operation Research System Analyst (ORSA) to join us, supporting a USSOCOM customer located at MacDill AFB. The J52 has responsibility for developing USSOCOM strategy, policy, and plans that providing key and critical insights through structured and analytic studies of SOF strategies, plans, and posture to inform USSOCOM senior leaders\u2019 strategic understanding and articulation of risk that drive decisions on forces, footprints, and agreements; planning guidance and implementation; and force development; developing the Global SOF Posture Plan (GSPP); serving as the link for USSOCOM on the Joint Force Posture Planning process and events; and providing key and critical insights through structured and analytic studies of SOF strategies, plans, and posture to inform USSOCOM senior leaders\u2019 strategic understanding and articulation of risk that drive decisions on forces, footprints, and agreements; planning guidance and implementation; and force development.\n  \n \n \n  Job Duties Include (but are not limited to): \n \n \n   Formulate and apply mathematical modeling and other optimizing methods to develop and interpret information that assists management with decision making, policy formulation, or other managerial functions. May collect and analyze data and develop decision support software, service, or products. May develop and supply optimal time, cost, or logistics networks for program evaluation, review, or implementation. Provide structured analysis and strategic assessment during the development of strategic planning, command strategy, posture, readiness, risk assessments, and operational return on investments that support evidence-based recommendations to and decisions by USSOCOM senior leaders. The Contractor shall perform tasks such as:\n  \n \n  Support assigned Operational Planning Teams (OPTs), Crisis Action Teams (CATs), and other boards, bureaus, centers, cells and working groups (B2C2WG) as needed. \n  Support the development of USSOCOM strategic documents by providing ORSA expertise, document preparation and coordination, data collection and analysis, and seminar/symposium, conference, and wargame support. \n  Provide technical expertise and capability for conducting ORSA projects, which are studies and analyses efforts using ORSA methods and tools in support of joint planning and contingency operations (refer to Joint Publications 3-0 and 5-0). \n  Execute high-visibility, urgent, and critical ORSA projects, requiring a variety of ORSA methods and tools. Such projects may be very large, extremely complex and of major importance to national security. \n  Apply operation research methods to identify and solve real-world problems for USSOCOM. Exercise sound military and analytic judgment in applying standard professional ORSA practices. Be creative and innovative in selecting and applying methods and tools to solve problems, enhance performance, or increase efficiency and effectiveness. \n  Use statistical analysis, simulations, stochastic and deterministic modeling, or other methods to analyze information and develop practical solutions to fit specific situations. \n  Perform analysis of program/project performance and design of experiments. \n  Understand and explain underlying, unique, and very difficult to define relationships that may require unconventional approaches or the application and adaptation of sophisticated analytical techniques producing original results. \n  Develop analytical approaches and supporting processes to address a wide variety of ambiguous, complex, compounding problems given only a skeletal framework or foundation for departure characterized by either their expansive breadth or depth where analytic precedents and guidelines often do not exist. \n  Design, develop and advocate for new analytic capabilities and technical improvements consistent with evolving requirements within the command (e.g., data mining and analysis, systems analysis, social analysis, wargaming, survey design and analysis). \n  Communicate with, prepare correspondence and presentations for, and advise senior leaders. \n  Analyze USSOCOM strategic documents alignment with the national-level strategic guidance and direction, including the Unified Command Plan, National Military Strategy, Defense Planning Scenarios, Contingency Planning Guidance, and other relevant national strategic documents. \n  Research and analyze various Department of Defense (DOD), Interagency, Service, and Combatant Command policies, strategies, and concepts associated with USSOCOM strategy and missions. \n  Develop an assessment plan and provide analysis for USSOCOM plans, to include the campaign plans, the Special Operations Forces Enterprise Plan, global campaign plans, and posture plans. \n  Provide analysis for strategic planning meetings, briefings, seminars, and strategy war games. \n  Conduct and prepare executive-level, research-based strategic level studies, assessments, and papers to analyze, assess, and synchronize command strategic documents and processes. \n  Develop and maintain a methodology and structure for implementing DOD and USSOCOM advancing analytics (ADVANA) and/or other data management systems (DMS); develop and maintain the processes and structure for incorporating ADVANA and/or other DMS to support USSOCOM J5 analysis and assessment efforts. \n  Prepare assessment products for 1- and 2-star Joint Planning Board, 3-star JCS led OPSDEPs and 4-star TANK. \n  Brief senior leaders on assessment and strategic questions. \n  Collaborate across USSOCOM enterprise on studies and research conducted for this PWS. \n  Assist on measuring performance, effectiveness, and overall objective ratings. \n  Conduct studies, research, assessments, and wargames that support USSOCOM decision making with evidence-based and data-driven analyses. \n  Qualifications: \n  \n  Required Skills & Experience: \n \n \n   Optional Specializations (One or More Areas Preferred): 5+ years in SOF; PSYOP; MILDEC; CWMD; CYBER; AT/FP; SNA; Special Programs; Interagency Experience, Intelligence, CCMD.\n  \n \n \n  Education & Certifications: \n \n \n  Civilian Education: MA/MS Preferred Disciplines: Social Sciences, Public Policy, Applied Statistics, Operations Research, Systems Analysis; OR Military Education: CGSC Equivalent or Higher (SAMS or equivalent; War College or equivalent; JPME II). \n \n \n  MS degree or higher in Operations Research and 10-15+ years operations research systems analyst (ORSA) experience. \n \n \n \n  Security Clearance: \n \n \n  An active Top Secret SCI security clearance is required. \n \n \n \n  Benefits: \n \n \n  National health, vision, and dental plans \n  20 days of PTO and 11 paid holidays \n  Life Insurance \n  Short and long term disability plans \n  401(K) retirement plan \n  Incentive and recognition programs \n  Relocation opportunities \n \n \n \n  Iron EagleX is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, religion, color, national origin, sex, sexual orientation, gender identity, age, status as a protected veteran, among other things, or status as a qualified individual with disability.",
        "cleaned_desc": " \n  Job Duties Include (but are not limited to): \n \n \n   Formulate and apply mathematical modeling and other optimizing methods to develop and interpret information that assists management with decision making, policy formulation, or other managerial functions. May collect and analyze data and develop decision support software, service, or products. May develop and supply optimal time, cost, or logistics networks for program evaluation, review, or implementation. Provide structured analysis and strategic assessment during the development of strategic planning, command strategy, posture, readiness, risk assessments, and operational return on investments that support evidence-based recommendations to and decisions by USSOCOM senior leaders. The Contractor shall perform tasks such as:\n  \n \n  Support assigned Operational Planning Teams (OPTs), Crisis Action Teams (CATs), and other boards, bureaus, centers, cells and working groups (B2C2WG) as needed. \n  Support the development of USSOCOM strategic documents by providing ORSA expertise, document preparation and coordination, data collection and analysis, and seminar/symposium, conference, and wargame support. \n  Provide technical expertise and capability for conducting ORSA projects, which are studies and analyses efforts using ORSA methods and tools in support of joint planning and contingency operations (refer to Joint Publications 3-0 and 5-0). \n  Execute high-visibility, urgent, and critical ORSA projects, requiring a variety of ORSA methods and tools. Such projects may be very large, extremely complex and of major importance to national security. \n  Apply operation research methods to identify and solve real-world problems for USSOCOM. Exercise sound military and analytic judgment in applying standard professional ORSA practices. Be creative and innovative in selecting and applying methods and tools to solve problems, enhance performance, or increase efficiency and effectiveness. \n  Use statistical analysis, simulations, stochastic and deterministic modeling, or other methods to analyze information and develop practical solutions to fit specific situations. \n  Perform analysis of program/project performance and design of experiments. \n  Understand and explain underlying, unique, and very difficult to define relationships that may require unconventional approaches or the application and adaptation of sophisticated analytical techniques producing original results. \n  Develop analytical approaches and supporting processes to address a wide variety of ambiguous, complex, compounding problems given only a skeletal framework or foundation for departure characterized by either their expansive breadth or depth where analytic precedents and guidelines often do not exist. \n  Design, develop and advocate for new analytic capabilities and technical improvements consistent with evolving requirements within the command (e.g., data mining and analysis, systems analysis, social analysis, wargaming, survey design and analysis). ",
        "techs": [
            "orsa methods and tools",
            "joint publications 3-0 and 5-0",
            "statistical analysis",
            "simulations",
            "stochastic modeling",
            "deterministic modeling",
            "experiments design",
            "data mining and analysis",
            "systems analysis",
            "social analysis",
            "wargaming",
            "survey design and analysis"
        ],
        "cleaned_techs": [
            "orsa methods and tools",
            "joint publications 3-0 and 5-0",
            "statistical analysis",
            "simulations",
            "stochastic modeling",
            "deterministic modeling",
            "experiments design",
            "data mining and analysis",
            "systems analysis",
            "social analysis",
            "wargaming",
            "survey design and analysis"
        ]
    },
    "e712d518d1018cc9": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 81000.0,
        "salary_max": 94000.0,
        "title": "BCBA Behavior Analyst - ABA Therapist (FT)",
        "company": "Delta-T Grp.",
        "desc": "Job Details: \n \n \n  BCBA - Center/Hybrid - Competitive Pay \n  Full Job Description: BCBA ABA Therapy Clinic \n  Total First Year Compensation $81,000 to $94,000 \n  Job Type: Full-Time Center, Hybrid \n  Pay: $81,000 to $94,000 (First Year) \n \n \n   Kaleidoscope ABA is a private agency looking to hire a center-based BCBA position to work part of your week remotely\n  \n \n \n  Position Overview: \n \n \n  The Hybrid BCBA will deliver direct services to clients as well as manage and supervise a small caseload of 4-6 clients. \n  The Clinical Manager and Operations Manager at Kaleidoscope ABA will provide you with administrative support, scheduling help, and general assistance with the Hybrid BCBA's caseload. \n \n \n  What do we offer Full-Time Clinicians: \n \n \n  HYBRID Remote Work Schedule. \n  Full-Time Mon-Friday schedule - NO weekends or late nights. \n  Attractive Benefits Plan! \n  Guaranteed salary regardless of client cancellations. \n  Up to $6000 annual incentive bonus (paid monthly). \n  Small caseload. \n  Laptop provided. \n  Medical, Dental, and Vision Insurance. \n  8 Paid Holidays + 16 PTO Days Yr 2, 11 Yr 1. \n  CEU stipend. \n  Voluntary Benefits - STD, LTD, etc. \n  401K, 401K match. \n \n \n  Responsibilities: \n \n \n  Conduct assessments and reassessments for clients. \n  Develop individual goals and objectives to be included in client Treatment Plans. \n  Develop written guidelines for behavioral interventions, teaching plans, and programs. \n  Collect data for each goal/objective during each direct session. \n  Record data into company software and the individual's confidential file. \n  Provide training in behavioral interventions and applied behavior analysis to families and staff. \n  Analyze data collected to determine program effectiveness. \n  Supervise and coach Behavior Therapists. \n \n \n  Supplemental Pay: \n \n \n  Monthly incentive. \n  Sign-on bonus $3000. \n \n \n  Benefits: \n \n \n  Medical Insurance \n  Dental Insurance \n  Vision Insurance \n  Life Insurance \n  Paid Holidays (8 days) \n  PTO 16 days -Yr 2, (11 - Yr 1) \n  Voluntary STD, LTD, Accident, Cancer \n  401K \n  401K Match 6% \n  CEU Stipend \n \n \n  EXPERIENCE & EDUCATION REQUIRED: \n \n \n  Possess a minimum of a master's degree or national equivalent with a major in psychology, or special education. \n  Applied Behavior Analysis or a related field of study is preferred. \n  Obtained certification as a Board-Certified BCBA as verified through the Certification Board. \n  Active Arizona License. \n  A minimum of 1 year of experience in working with children, adolescents, and/or adults with various special needs. \n  Knowledge of appropriate behavioral intervention strategies, earning theories and instructional methods, ethics, laws, and regulations of acceptable behavior interventions. \n  Proficient in technology, such as Office 365, Microsoft Word, Excel, PowerPoint, and ABA software platforms. \n  Use a computer and behavioral software to prepare documents and maintain client records. \n  Work independently and make decisions within the framework of established guidelines. \n  Supervise clients during treatment sessions. \n  Ability to bend, kneel, crouch, and spend time on their feet. \n  Ability to lift items to 50 lbs. on occasion. \n \n \n  ABOUT US: \n \n \n   Kaleidoscope ABA provides center-based, community, and home-based Applied Behavioral Analysis (ABA) Therapy services to children and young adults. We use evidence-based, best-practice models to support and provide effective treatment to individuals with Autism Spectrum Disorder (ASD) as well as other behavioral and developmental disabilities. Our team partners with family members to create individualized ABA treatment plans designed to meet the individual needs of each person we serve.\n   \n \n \n  Call, email, or apply: \n \n \n   Kandace Robinson, 215-278-8372, krobinson@kfamilysolutions.org\n    https://www.kfsaba.org\n    https://www.kfsaba.org/eeo-statement/ (Kaleidoscope Family Solutions ABA, Inc. is an EEO employer.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "06df32253e80065e": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 35.0,
        "salary_max": 45.0,
        "title": "Jr level Functional Business Analyst With Infrastructure and real estate",
        "company": "Formac Inc",
        "desc": "Business Systems Analyst (2-5 years of Exp only) \n REMOTE \n LONG TERM \n 45/hr on C2C \n working in our Corporate Real Estate space of Optum Technology dealing with occupancy space, room technology, project management, reservation, building reservations, etc. Candidate will be able to handle project managing and coordinating duties, along with delivering successful project outcomes in a fast pace environment. \n Other requirements below: \n 1. Talk to stakeholders and develop a functional requirements specification \n 2. Analyze and map all relevant business processes and IT infrastructure \n 3. Research any rules that might impact solution delivery, such as compliance, data governance, or organizational mandates \n 4. Make recommendations for solutions that deliver organizational goals \n 5. Assist in the design, development, and testing of solutions \n 6. Oversee QA and deployment \n 7. Report to stakeholders and senior IT leaders throughout the project lifecycle \n 8. Write sql queries ; create data analytics reports to provide to company stakeholders ad-hoc or on regular cadences \n 9. General knowledge of PC support, server management, and network operations \n 10. General troubleshooting and triage experiences with technical issues \n Thanks \n Jay \n 628-215-2224 \n Job Types: Full-time, Contract \n Pay: $35.00 - $45.00 per hour \n Benefits: \n \n Dental insurance \n Health insurance \n Paid time off \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Application Question(s): \n \n best time and number to connect \n \n Education: \n \n Bachelor's (Preferred) \n \n Experience: \n \n Cloud infrastructure: 1 year (Required) \n Network infrastructure: 1 year (Required) \n Business analysis: 4 years (Required) \n real estate industry: 1 year (Required) \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "b35f5ffb6fb35f13": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 91945.195,
        "salary_max": 116423.1,
        "title": "Senior Business Analyst - Health (HYBRID)",
        "company": "Inclusively",
        "desc": "Inclusively is partnering with a multinational financial services company to hire a Senior Business Analyst - Health (HYBRID). \n ABOUT INCLUSIVELY: \n Inclusively is a digital tech platform that connects candidates with disabilities, who may benefit from workplace accommodations, to inclusive employers. This includes all disabilities under the ADA, including mental health conditions (e.g. anxiety, depression, PTSD), chronic illnesses (e.g. diabetes, Long COVID), and neurodivergence (e.g. autism, ADHD).  Applicants with one or more of these conditions are encouraged to apply; Inclusively does not require applicants to disclose their specific disability. \n The Expertise and Skills You Bring \n \n Bachelor\u2019s degree or equivalent years of experience required \n 5+ years software Development Business Analyst experience, ideally working in an Agile Scrum environment, with demonstrable ability to work across multiple multi-functional teams or Master\u2019s degree in related filed with solid software product development skills. \n Solid understanding industry experience in health care and/or benefits administration and/or product development preferred. \n Shown expertise in various business analysis methodologies and techniques, including data analysis, use case development, story writing, user acceptance testing, and product documentation. \n Solid grasp of the architecture and deployment needed to support web development \n Interact closely with Subject Matter Experts and stakeholders across Health Benefits domain to elicit Product requirements \n Work with UXD teams to support prototyping \n Skilled in MS Word, Excel, PowerPoint, Visio; Experience with JIRA or similar agile backlog management and testing tool \n Certified Business Analysis Professional\u00ae (CBAP\u00ae) certification or Certified Scrum Product Owner certification is a plus \n Skilled at translating business vision into defined and prioritized user stories for team\u2019s backlog \n Ability to understand complex customer needs, translate them into user stories with concrete acceptance criteria, and drive solution formulation with a multi-functional team \n Customer-obsessed and have demonstrated a commitment to delivering frequent, high business value features \n Look for opportunities to innovate and take thoughtful risks to get work done better and faster \n Excellent listening, communication (verbal and written), and presentation skills \n You effectively and regularly lead, facilitate, and drive individuals and group meetings to common goals \n You are highly organized and have a strong ability to prioritize and work under tight deadlines \n Skilled at building relationships, fostering strong teams, and influencing others \n You are a self-motivated, great teammate with the ability to plan and complete work independently, and partner effectively to handle dependencies \n Strong desire to learn and develop additional skills and expertise over time, as well as drive process improvement \n You have excellent business judgement and maintain confidentiality of all data \n Providing consulting, support, and guidance to leadership, squad members, and other relevant partners to influence culture and behaviors \n \n The Value You Deliver \n \n Working in a Scrum Agile environment to deliver software products \n Leading and conducting business analyses to formulate and make recommendations \n Identifying and defining solutions to business problems, through creation and documentation of systems and process specifications \n Creating, documenting, and leading scrum team backlog (writing user stories / acceptance criteria, supporting prioritization, running refinement sessions, etc.) \n Collaborate closely with business partners, development teams, external vendors, and QA on plans, project management, requirements, design, testing, and implementation of solutions throughout the development lifecycle \n Supporting deployment, business readiness, and solution enablement, e.g., defining and documenting enablement tasks, supporting user procedure documentation, creation and delivery of solution training to internal teams, and communication \n Prioritize multiple initiatives and business analysis tasks at the same time \n \n Job Type: Full-time \n Schedule: \n \n Monday to Friday \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "6dbad63639bfc49f": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 75157.0,
        "salary_max": 127767.0,
        "title": "Senior ServiceNow Business Analyst - Remote",
        "company": "ICF",
        "desc": "*We are open to supporting 100% remote work anywhere within the U.S.*\n  \n \n \n   ICF\u2019s Digital Modernization Division is a rapidly growing, entrepreneurial, technology department, seeking a Senior ServiceNow Business Analyst to support upcoming needs with our federal customers.\n  \n \n \n   Our Digital Modernization Division is an information technology and management consulting department that offers integrated, strategic solutions to its public and private-sector clients. ICF has the expertise, agility, and commitment to design, build, and operate high-performance IT engines to support all aspects of our client\u2019s business.\n  \n \n \n   Job Responsibilities\n  \n \n   We are seeking a Senior ServiceNow Business Analyst - HRSD to assist our customer\u2019s business needs with HR system integration to the ServiceNow platform. This role will be a key member of the development Team, implementing and supporting the ServiceNow HRSD platform, associated processes and external system integration. You will be responsible for developing a strong understanding of the business needs of the stakeholders and how the ServiceNow application will support those needs. This analyst role will partner with development and IT partners to build, document, and test ServiceNow HRSD. You will also provide support to end-users in UAT by training users on new functionality and presenting updates to end-users.\n  \n \n \n   The Senior ServiceNow Business Analyst serves as a translator between technical teams and the client\u2019s business community to collect, clarify, analyze and translate business requirements into documentation and conceptual design from which applications and solutions are developed. This position is within the context of an Agile team employing a Scrum development framework. The Business Analyst defines detailed stories and epics, with applicable acceptance criteria in collaboration with product owners and ICF\u2019s technology team,and facilitates meetings with client and internal technical and operational teams.\n  \n \n   This position will be working directly with stakeholders, serving in both Business Analyst and Project Manager roles, and must be able to communicate effectively via phone and web conferencing as many of the stakeholders work remotely.\n  \n \n \n   In addition to supporting all phases of the project, this position will also be responsible for authoring content and peer-reviewing a wide array of documents, including functional, technical, training as well as marketing, and proposals.\n  \n \n \n   Minimum Job Requirements:\n  \n \n  Bachelor\u2019s Degree \n  1 year and 6 months (or more) experience as a Business Analyst in a fast-paced application development environment, at least 1 full implementation of HRSD \n  1 year and 6 months (or more) recent experience working in an Agile development environment as a business analyst (i.e., Scrum, Kanban, etc.) \n  1 year and 6 months (or more)of experience with the ServiceNow Platform \n  1 year and 6 months (or more) of experience facilitating requirements gathering, Joint Application Design (JAD) sessions, capturing client requirements and feedback \n  US Citizenship required due to federal contract requirements \n  Must be able to obtain Public Trust clearance. \n \n \n \n   Desired Skills:\n  \n \n  Solid understanding of various software development cycles (e.g., Agile, Waterfall, etc.); knowledge of requirements management, configuration management methodologies, along with corresponding support tools, i.e., JIRA, etc. \n  Conceptual understanding of Object-Oriented enterprise software system development processes, methodologies, as well as major technologies (such as Java and .Net) and approaches (such as modularity and SOA) \n  Skilled at analyzing existing system documentation to summarize existing system functionality as it relates to the project at hand \n  Good understanding of basic system technologies as they relate to the project deliverables \n  Ability to maintain project plans, resourcing schedules, and forecasted activities \n  Experience with business process mapping and the use of project management software \n  Ability to provide technical assistance and troubleshooting by effectively responding to inquiries \n  Experience thriving in ambiguous software development environments \n  Ability to work well under constantly changing deadlines and priorities \n  Experience with ServiceNow, Appian, or similar BPM software \n  Excellent oral and written communication skills \n \n \n \n   #dmd\n  \n \n \n   Working at ICF\n  \n  ICF is a global advisory and technology services provider, but we\u2019re not your typical consultants. We combine unmatched expertise with cutting-edge technology to help clients solve their most complex challenges, navigate change, and shape the future.\n  \n \n   We can only solve the world's toughest challenges by building an inclusive workplace that allows everyone to thrive. We are an equal opportunity employer, committed to hiring regardless of any protected characteristic, such as race, ethnicity, national origin, color, sex, gender identity/expression, sexual orientation, religion, age, disability status, or military/veteran status. Together, our employees are empowered to share their expertise and collaborate with others to achieve personal and professional goals. For more information, please read our \n   \n   EEO & AA policy\n   .\n  \n \n \n   Reasonable Accommodations are available, including, but not limited to, for disabled veterans, individuals with disabilities, and individuals with sincerely held religious beliefs, in all phases of the application and employment process. To request an accommodation please email \n   \n   icfcareercenter@icf.com\n    and we will be happy to assist. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. Read more about non-discrimination: \n   \n   Know Your Rights\n    and \n   \n   Pay Transparency Statement.\n   \n \n \n \n  Pay Range - There are multiple factors that are considered in determining final pay for a position, including, but not limited to, relevant work experience, skills, certifications and competencies that align to the specified role, geographic location, education and certifications as well as contract provisions regarding labor categories that are specific to the position. The pay range for this position is:\n   $75,157.00 - $127,767.00\n   Nationwide Remote Office (US99)",
        "cleaned_desc": "  1 year and 6 months (or more)of experience with the ServiceNow Platform \n  1 year and 6 months (or more) of experience facilitating requirements gathering, Joint Application Design (JAD) sessions, capturing client requirements and feedback \n  US Citizenship required due to federal contract requirements \n  Must be able to obtain Public Trust clearance. \n \n \n \n   Desired Skills:\n  \n \n  Solid understanding of various software development cycles (e.g., Agile, Waterfall, etc.); knowledge of requirements management, configuration management methodologies, along with corresponding support tools, i.e., JIRA, etc. \n  Conceptual understanding of Object-Oriented enterprise software system development processes, methodologies, as well as major technologies (such as Java and .Net) and approaches (such as modularity and SOA) \n  Skilled at analyzing existing system documentation to summarize existing system functionality as it relates to the project at hand \n  Good understanding of basic system technologies as they relate to the project deliverables \n  Ability to maintain project plans, resourcing schedules, and forecasted activities \n  Experience with business process mapping and the use of project management software \n  Ability to provide technical assistance and troubleshooting by effectively responding to inquiries \n  Experience thriving in ambiguous software development environments ",
        "techs": [
            "servicenow platform",
            "jad sessions",
            "us citizenship",
            "public trust clearance",
            "software development cycles",
            "agile",
            "waterfall",
            "requirements management",
            "configuration management methodologies",
            "jira",
            "object-oriented",
            "java",
            ".net",
            "modularity",
            "soa",
            "system documentation",
            "project plans",
            "resourcing schedules",
            "business process mapping",
            "project management software",
            "technical assistance"
        ],
        "cleaned_techs": [
            "servicenow platform",
            "jad sessions",
            "us citizenship",
            "public trust clearance",
            "software development cycles",
            "agile",
            "waterfall",
            "requirements management",
            "configuration management methodologies",
            "jira",
            "object-oriented",
            "java",
            ".net",
            "modularity",
            "soa",
            "project plans",
            "resourcing schedules",
            "business process mapping",
            "project management software",
            "technical assistance"
        ]
    },
    "55bd7f9da1b0556a": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 95664.92,
        "salary_max": 121133.11,
        "title": "Senior Business Analyst - Health (HYBRID)",
        "company": "Inclusively",
        "desc": "Inclusively is partnering with a multinational financial services company to hire a Senior Business Analyst - Health (HYBRID). \n ABOUT INCLUSIVELY: \n Inclusively is a digital tech platform that connects candidates with disabilities, who may benefit from workplace accommodations, to inclusive employers. This includes all disabilities under the ADA, including mental health conditions (e.g. anxiety, depression, PTSD), chronic illnesses (e.g. diabetes, Long COVID), and neurodivergence (e.g. autism, ADHD).  Applicants with one or more of these conditions are encouraged to apply; Inclusively does not require applicants to disclose their specific disability. \n The Expertise and Skills You Bring \n \n Bachelor\u2019s degree or equivalent years of experience required \n 5+ years software Development Business Analyst experience, ideally working in an Agile Scrum environment, with demonstrable ability to work across multiple multi-functional teams or Master\u2019s degree in related filed with solid software product development skills. \n Solid understanding industry experience in health care and/or benefits administration and/or product development preferred. \n Shown expertise in various business analysis methodologies and techniques, including data analysis, use case development, story writing, user acceptance testing, and product documentation. \n Solid grasp of the architecture and deployment needed to support web development \n Interact closely with Subject Matter Experts and stakeholders across Health Benefits domain to elicit Product requirements \n Work with UXD teams to support prototyping \n Skilled in MS Word, Excel, PowerPoint, Visio; Experience with JIRA or similar agile backlog management and testing tool \n Certified Business Analysis Professional\u00ae (CBAP\u00ae) certification or Certified Scrum Product Owner certification is a plus \n Skilled at translating business vision into defined and prioritized user stories for team\u2019s backlog \n Ability to understand complex customer needs, translate them into user stories with concrete acceptance criteria, and drive solution formulation with a multi-functional team \n Customer-obsessed and have demonstrated a commitment to delivering frequent, high business value features \n Look for opportunities to innovate and take thoughtful risks to get work done better and faster \n Excellent listening, communication (verbal and written), and presentation skills \n You effectively and regularly lead, facilitate, and drive individuals and group meetings to common goals \n You are highly organized and have a strong ability to prioritize and work under tight deadlines \n Skilled at building relationships, fostering strong teams, and influencing others \n You are a self-motivated, great teammate with the ability to plan and complete work independently, and partner effectively to handle dependencies \n Strong desire to learn and develop additional skills and expertise over time, as well as drive process improvement \n You have excellent business judgement and maintain confidentiality of all data \n Providing consulting, support, and guidance to leadership, squad members, and other relevant partners to influence culture and behaviors \n \n The Value You Deliver \n \n Working in a Scrum Agile environment to deliver software products \n Leading and conducting business analyses to formulate and make recommendations \n Identifying and defining solutions to business problems, through creation and documentation of systems and process specifications \n Creating, documenting, and leading scrum team backlog (writing user stories / acceptance criteria, supporting prioritization, running refinement sessions, etc.) \n Collaborate closely with business partners, development teams, external vendors, and QA on plans, project management, requirements, design, testing, and implementation of solutions throughout the development lifecycle \n Supporting deployment, business readiness, and solution enablement, e.g., defining and documenting enablement tasks, supporting user procedure documentation, creation and delivery of solution training to internal teams, and communication \n Prioritize multiple initiatives and business analysis tasks at the same time \n \n Job Type: Full-time \n Schedule: \n \n Monday to Friday \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "fc106361fd08aa16": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 83720.0,
        "salary_max": 136240.0,
        "title": "Business Analysis Specialist (Remote)",
        "company": "TD Bank",
        "desc": "Business Analysis Specialist (Remote) \n \n \n \n    422352BR\n    \n \n \n Job Category - Primary \n \n    Business Analysis / Reporting \n    \n \n \n Work Location \n \n    Remote Mount Laurel (NJ) \n    \n \n \n Employment Type \n \n    Regular \n    \n \n \n City \n \n    Mount Laurel \n    \n \n \n Time Type \n \n    Full Time \n    \n \n \n State \n \n    Nationwide\n    \n \n \n Hours \n \n    40\n    \n \n \n Pay Range \n \n    $83,720 - $136,240 annually \n    \n \n \n Benefits \n \n    For an overview of TD's Benefits program, please visit TD's Total Rewards site \n    \n \n \n Job Searches Match \n \n    Nationwide\n    \n \n \n Department Overview \n \n    Plan, manage, lead and oversee the end-to-end delivery of requirements throughout the lifecycle of the project in alignment with the business and/or enterprise needs and strategies. Provide leadership and work collaboratively with stakeholders including business, technology and finance partners to support project benefits and changes to business processes, policies and systems across single or multiple Lines of Business (LoB).\n    \n \n \n Job Details \n \n Depth & Scope: \n \n  Leads Requirements Management / work packages for Tier 2, high risk, strategic and regulatory projects or programs and may lead requirements may lead Requirements Management for Tier 1 projects/programs \n  Expert knowledge of business analysis, project delivery practices and standards across the project life-cycle \n  Gain/acquire advanced understanding of business and user interaction with technology throughout project delivery \n  Works autonomously as the lead business analyst and coaches and guides members within area of expertise \n  Identifies and leads problem resolution for complex requirements related issues at all levels \n  Contributes to the communication and change Management activities across multiple stakeholders \n \n \n \n \n Job Requirements \n \n \n Must be eligible for employment under regulatory standards applicable to the position. \n \n  Education & Experience:  \n \n Undergraduate degree required \n  Business Analysis Accreditation \n  7+ year related business analysis experience required \n \n \n \n \n Qualifications \n \n \n Supporting projects within CP&S or Commercial Lending, strong preference for experience in these lines of business \n  Relevant accreditation is  Certified Business Analysis Professional (CBAP) \n \n \n \n \n Company Overview \n \n About TD Bank, America's Most Convenient Bank\u00ae  \n TD Bank, America's Most Convenient Bank, is one of the 10 largest banks in the U.S., providing over 9.8 million customers with a full range of retail, small business and commercial banking products and services at more than 1,100 convenient locations throughout the Northeast, Mid-Atlantic, Metro D.C., the Carolinas and Florida. In addition, TD Auto Finance, a division of TD Bank, N.A., offers vehicle financing and dealer commercial services. TD Bank and its subsidiaries also offer customized private banking and wealth management services through TD Wealth\u00ae. TD Bank is headquartered in Cherry Hill, N.J. \n \n We offer a competitive salary and benefit program, including: comprehensive, affordable health care through medical, dental, and vision coverage; financial security with life and disability insurance; opportunities to save using health savings and flexible spending accounts; retirement benefits to help prepare for the future; paid time off and work/life benefits to maintain a good balance. \n \n \n \n Inclusiveness \n \n At TD, we are committed to fostering an inclusive, accessible environment, where all employees and customers feel valued, respected and supported. We are dedicated to building a workforce that reflects the diversity of our customers and communities in which we live in and serve, and creating an environment where every employee has the opportunity to reach their potential. \n  If you are a candidate with a disability and need an accommodation to complete the application process, email the TD Bank US Workplace Accommodations Program at USWAPTDO@td.com . Include your full name, best way to reach you, and the accommodation needed to assist you with the application process. \n  EOE/Minorities/Females/Veterans/Individuals with Disabilities/Sexual Orientation/Gender Identity. \n \n \n \n Business Line \n \n    TD Bank AMCB\n    \n \n \n Job Category(s) \n \n    Business Analysis / Reporting \n    \n \n \n Country \n \n    US Nationwide \n    \n \n \n State (Primary) \n \n    New Jersey \n    \n \n \n City (Primary) \n \n    Mount Laurel \n    \n \n \n Job Expires \n \n    16-Nov-2023",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "6670051cfa6a42e1": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 101080.0,
        "salary_max": 150000.0,
        "title": "Data Consultant",
        "company": "AllStar Staffing Group",
        "desc": "We have an immediate need for a Data Analyst/Data Migration consultant. This is a contract position estimated to last 9-12 months or so. This position is fully remote. \n Job Duties Include: \n \n act as technical migration lead \n migrate data from legacy system into Saleforce \n data mapping \n Provide recommendations for process improvements based on data analysis \n Collaborate with cross-functional teams to identify data needs and requirements. \n \n Job Requirements Include: \n \n Bachelor's degree in a related field (e.g., Data Analytics, Statistics, Computer Science) \n Solid background in data migration and conversion \n Previous experience with data mapping \n Excellent communication skills \n Detail oriented and well organized \n \n Job Type: Contract \n Pay: $101,080.00 - $150,000.00 per year \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n \n Compensation package: \n \n 1099 contract \n \n Experience level: \n \n 5 years \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Education: \n \n Bachelor's (Preferred) \n \n Experience: \n \n data mapping: 5 years (Preferred) \n data migration: 5 years (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "32e4f79073bb0cb5": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 81000.0,
        "salary_max": 94000.0,
        "title": "BCBA - Behavior Analyst - ABA Therapist (FT)",
        "company": "Delta-T Grp.",
        "desc": "Job Details: \n \n \n  Position: BCBA - Center/Hybrid - Competitive Pay. \n  Full Job Description: BCBA ABA Therapy \n  Total First Year Compensation $81,000 to $94,000. \n  Job Type:  Full-Time Center, Hybrid. \n  Pay:  $81,000 to $94,000 (First Year). \n \n \n   Kaleidoscope ABA is a private agency looking to hire a center-based BCBA position to work part of your week remotely.\n   \n \n Position Overview: \n \n \n  The Hybrid BCBA will deliver direct services to clients as well as manage and supervise a small caseload of 4-6 clients. \n  The Clinical Manager and Operations Manager at Kaleidoscope ABA will provide you with administrative support, scheduling help, and general assistance with the Hybrid BCBA's caseload. \n \n \n  What do we offer Full-Time Clinicians: \n \n \n  HYBRID Remote Work Schedule. \n  Full-Time Mon-Friday schedule - NO weekends or late nights. \n  Attractive Benefits Plan! \n  Guaranteed salary regardless of client cancellations. \n  Up to $6000 annual incentive bonus (paid monthly). \n  Small caseload. \n  Laptop provided. \n  Medical, Dental, and Vision Insurance. \n  8 Paid Holidays + 16 PTO Days Yr 2, 11 Yr 1. \n  CEU stipend. \n  Voluntary Benefits - STD, LTD, etc. \n  401K, 401K match. \n \n \n  Responsibilities: \n \n \n  Conduct assessments and reassessments for clients. \n  Develop individual goals and objectives to be included in client Treatment Plans. \n  Develop written guidelines for behavioral interventions, teaching plans, and programs. \n  Collect data for each goal/objective during each direct session. \n  Record data into company software and the individual's confidential file. \n  Provide training in behavioral interventions and applied behavior analysis to families and staff. \n  Analyze data collected to determine program effectiveness. \n  Supervise and coach Behavior Therapists. \n \n \n  Supplemental Pay: \n \n \n  Monthly incentive. \n  Sign-on bonus of $3000. \n \n \n  Benefits: \n \n \n  Medical Insurance \n  Dental Insurance \n  Vision Insurance \n  Life Insurance \n  Paid Holidays (8 days) \n  PTO 16 days -Yr 2, (11 - Yr 1) \n  Voluntary STD, LTD, Accident, Cancer \n  401K \n  401K Match 6% \n  CEU Stipend \n \n \n  EXPERIENCE & EDUCATION REQUIRED: \n \n \n  Possess a minimum of a master's degree or national equivalent with a major in psychology, or special education. \n  Applied Behavior Analysis or a related field of study is preferred. \n  Obtained certification as a Board-Certified BCBA as verified through the Certification Board. \n  Active Arizona License. \n  A minimum of 1 year of experience in working with children, adolescents, and/or adults with various special needs. \n  Knowledge of appropriate behavioral intervention strategies, earning theories and instructional methods, ethics, laws, and regulations of acceptable behavior interventions. \n  Proficient in technology, such as Office 365, Microsoft Word, Excel, PowerPoint, and ABA software platforms. \n  Use a computer and behavioral software to prepare documents and maintain client records. \n  Work independently and make decisions within the framework of established guidelines. \n  Supervise clients during treatment sessions. \n  Ability to bend, kneel, crouch, and spend time on their feet. \n  Ability to lift items to 50 lbs. on occasion. \n \n \n  ABOUT US: \n \n \n   Kaleidoscope ABA provides center-based, community, and home-based Applied Behavioral Analysis (ABA) Therapy services to children and young adults. We use evidence-based, best-practice models to support and provide effective treatment to individuals with Autism Spectrum Disorder (ASD) as well as other behavioral and developmental disabilities. Our team partners with family members to create individualized ABA treatment plans designed to meet the individual needs of each person we serve.\n   \n \n \n  Call, email, or apply: \n \n \n   Kandace Robinson, 215-278-8372, krobinson@kfamilysolutions.org\n    https://www.kfsaba.org\n    https://www.kfsaba.org/eeo-statement/ (Kaleidoscope Family Solutions ABA, Inc. is an EEO employer.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "c6a81af01879925f": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 90940.0,
        "salary_max": 154598.0,
        "title": "Lead ServiceNow Business Analyst - Remote",
        "company": "ICF",
        "desc": "*We are open to supporting 100% remote work anywhere within the U.S.*\n  \n \n \n   ICF\u2019s Digital Modernization Division is a rapidly growing, entrepreneurial, technology department, seeking a Senior ServiceNow Business Analyst to support upcoming needs with our federal customers. Our Digital Modernization Division is an information technology and management consulting department that offers integrated, strategic solutions to its public and private-sector clients. ICF has the expertise, agility, and commitment to design, build, and operate high-performance IT engines to support all aspects of our client\u2019s business.\n  \n \n \n   Job Responsibilities\n  \n \n   We are seeking a Lead ServiceNow Business Analyst - HRSD to assist our customer\u2019s business needs with HR system integration to the ServiceNow platform. This role will be a key member of the development Team, implementing and supporting the ServiceNow HRSD platform, associated processes and external system integration. You will be responsible for developing a strong understanding of the business needs of the stakeholders and how the ServiceNow application will support those needs. This analyst role will partner with development and IT partners to build, document, and test ServiceNow HRSD. You will also provide support to end-users in UAT by training users on new functionality and presenting updates to end-users.\n  \n \n \n   The Lead ServiceNow Business Analyst serves as a translator between technical teams and the client\u2019s business community to collect, clarify, analyze and translate business requirements into documentation and conceptual design from which applications and solutions are developed. This position is within the context of an Agile team employing a Scrum development framework. The Business Analyst defines detailed stories and epics, with applicable acceptance criteria in collaboration with product owners and ICF\u2019s technology team, and facilitates meetings with client and internal technical and operational teams.\n  \n \n   This position will be working directly with stakeholders, serving in both Business Analyst and Project Manager roles, and must be able to communicate effectively via phone and web conferencing as many of the stakeholders work remotely.\n  \n \n \n   In addition to supporting all phases of the project, this position will also be responsible for authoring content and peer-reviewing a wide array of documents, including functional, technical, training as well as marketing, and proposals.\n  \n \n \n   Minimum Job Requirements:\n  \n \n  Bachelor\u2019s Degree \n  5+ years of experience as a Business Analyst in a fast-paced application development environment \n  5+ years recent experience working in an Agile development environment as a business analyst (i.e., Scrum, Kanban, etc.) \n  2+ years of experience with the ServiceNow Platform \n  5+ years of experience facilitating requirements gathering, Joint Application Design (JAD) sessions, capturing client requirements and feedback \n  US Citizenship required due to federal contract requirements \n  Must be able to obtain Public Trust clearance. \n \n \n \n   Desired Skills:\n  \n \n  Solid understanding of various software development cycles (e.g., Agile, Waterfall, etc.); knowledge of requirements management, configuration management methodologies, along with corresponding support tools, i.e., JIRA, etc. \n  Conceptual understanding of Object-Oriented enterprise software system development processes, methodologies, as well as major technologies (such as Java and .Net) and approaches (such as modularity and SOA) \n  Skilled at analyzing existing system documentation to summarize existing system functionality as it relates to the project at hand \n  Good understanding of basic system technologies as they relate to the project deliverables \n  Ability to maintain project plans, resourcing schedules, and forecasted activities \n  Experience with business process mapping and the use of project management software \n  Ability to provide technical assistance and troubleshooting by effectively responding to inquiries \n  Experience thriving in ambiguous software development environments \n  Ability to work well under constantly changing deadlines and priorities \n  Experience with ServiceNow, Appian, or similar BPM software \n  Excellent oral and written communication skills \n \n \n \n   Working at ICF\n  \n  ICF is a global advisory and technology services provider, but we\u2019re not your typical consultants. We combine unmatched expertise with cutting-edge technology to help clients solve their most complex challenges, navigate change, and shape the future.\n  \n \n   We can only solve the world's toughest challenges by building an inclusive workplace that allows everyone to thrive. We are an equal opportunity employer, committed to hiring regardless of any protected characteristic, such as race, ethnicity, national origin, color, sex, gender identity/expression, sexual orientation, religion, age, disability status, or military/veteran status. Together, our employees are empowered to share their expertise and collaborate with others to achieve personal and professional goals. For more information, please read our \n   \n   EEO & AA policy\n   .\n  \n \n \n   Reasonable Accommodations are available, including, but not limited to, for disabled veterans, individuals with disabilities, and individuals with sincerely held religious beliefs, in all phases of the application and employment process. To request an accommodation please email \n   \n   icfcareercenter@icf.com\n    and we will be happy to assist. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. Read more about non-discrimination: \n   \n   Know Your Rights\n    and \n   \n   Pay Transparency Statement.\n   \n \n \n \n  Pay Range - There are multiple factors that are considered in determining final pay for a position, including, but not limited to, relevant work experience, skills, certifications and competencies that align to the specified role, geographic location, education and certifications as well as contract provisions regarding labor categories that are specific to the position. The pay range for this position is:\n   $90,940.00 - $154,598.00\n   Nationwide Remote Office (US99)",
        "cleaned_desc": "  2+ years of experience with the ServiceNow Platform \n  5+ years of experience facilitating requirements gathering, Joint Application Design (JAD) sessions, capturing client requirements and feedback \n  US Citizenship required due to federal contract requirements \n  Must be able to obtain Public Trust clearance. \n \n \n \n   Desired Skills:\n  \n \n  Solid understanding of various software development cycles (e.g., Agile, Waterfall, etc.); knowledge of requirements management, configuration management methodologies, along with corresponding support tools, i.e., JIRA, etc. \n  Conceptual understanding of Object-Oriented enterprise software system development processes, methodologies, as well as major technologies (such as Java and .Net) and approaches (such as modularity and SOA) \n  Skilled at analyzing existing system documentation to summarize existing system functionality as it relates to the project at hand \n  Good understanding of basic system technologies as they relate to the project deliverables \n  Ability to maintain project plans, resourcing schedules, and forecasted activities \n  Experience with business process mapping and the use of project management software ",
        "techs": [
            "servicenow platform",
            "jad sessions",
            "requirements gathering",
            "us citizenship",
            "public trust clearance",
            "agile",
            "waterfall",
            "requirements management",
            "configuration management methodologies",
            "jira",
            "object-oriented enterprise software system development",
            "java",
            ".net",
            "modularity",
            "soa",
            "project plans",
            "resourcing schedules",
            "business process mapping",
            "project management software"
        ],
        "cleaned_techs": [
            "servicenow platform",
            "jad sessions",
            "requirements gathering",
            "us citizenship",
            "public trust clearance",
            "agile",
            "waterfall",
            "requirements management",
            "configuration management methodologies",
            "jira",
            "object-oriented enterprise software system development",
            "java",
            ".net",
            "modularity",
            "soa",
            "project plans",
            "resourcing schedules",
            "business process mapping",
            "project management software"
        ]
    },
    "8ab53a8f53f0de4f": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 75000.0,
        "salary_max": 82000.0,
        "title": "Business Technical Analyst",
        "company": "Ascendion",
        "desc": "Description \n About Ascendion \n  Ascendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next. \n \n \n  Ascendion | Engineering to elevate life \n  We have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us: \n \n Build the coolest tech for world\u2019s leading brands \n Solve complex problems \u2013 and learn new skill \n Experience the power of transforming digital engineering for Fortune 500 clients \n Master your craft with leading training programs and hands-on experience \n \n \n \n  Experience a community of change makers! \n  Join a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion. \n \n \n  About the Role: \n \n \n  Job Title: Business Technical Analyst \n \n \n  Day-to-Day: \n \n Ascendion is looking for a BTA Developer to support a large healthcare organization. \n This group will be working with risk adjustment team to help reconcile healthcare data sets. \n They are building out dashboards and reports and visualition in powerBI related to medicare and medicaid data sets. \n \n \n \n  Must Haves: \n \n 4 + years of experience with SAS and SQL \n 4 + years of experience of with Power BI for building out complex dashboards \n Strong experience working with large database sets and dealing with the database management \n Healthcare experience with Medicaid and Medicare specifically \n \n \n \n  Location: Remote \n \n \n  Salary Range:  The salary for this position is between $ 75,000 \u2013 $82,000 annually. Factors which may affect pay within this range may include geography/market, skill, education, experience, and other qualifications of the successful candidate. \n \n \n  Benefits:  The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [5 personal day accrued each calendar year. The \n  Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [10-15 day of paid vacation time] [6 paid holiday and 1 floating holiday per calendar year] [Ascendion Learning Management System] \n \n \n  Want to change the world? Let us know. \n  Tell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let\u2019s talk! \n Preferred Skills: \n \n SAS \n  SQL \n  power bi \n  database management \n  medicaid \n  medicare \n \n Job details \n \n \n Job ID \n \n \n   328874\n   \n \n \n \n Job Requirements \n \n \n   Business Technical Analyst\n   \n \n \n \n \n Location \n \n \n   Tampa, Florida, US\n   \n \n \n \n \n Recruiter \n \n \n   Poorvi\n   \n \n \n \n Email \n \n \n   poorvi.ratre@ascendion.com",
        "cleaned_desc": " \n \n  Job Title: Business Technical Analyst \n \n \n  Day-to-Day: \n \n Ascendion is looking for a BTA Developer to support a large healthcare organization. \n This group will be working with risk adjustment team to help reconcile healthcare data sets. \n They are building out dashboards and reports and visualition in powerBI related to medicare and medicaid data sets. \n \n \n \n  Must Haves: \n \n 4 + years of experience with SAS and SQL \n 4 + years of experience of with Power BI for building out complex dashboards \n Strong experience working with large database sets and dealing with the database management \n Healthcare experience with Medicaid and Medicare specifically \n ",
        "techs": [
            "sas",
            "sql",
            "power bi"
        ],
        "cleaned_techs": [
            "sas",
            "sql",
            "powerbi"
        ]
    },
    "9c1fe131ecbccec2": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 122147.62,
        "salary_max": 154666.1,
        "title": "Business Intelligence Lead",
        "company": "Pacific Life",
        "desc": "Job Description: \n  Pacific Life is investing in bright, agile and diverse talent to contribute to our mission of innovating our business and creating a superior customer experience. \n \n  We\u2019re actively seeking a talented Business Intelligence Lead to join our new Workforce Benefits division. This role can be fully remote or hybrid and based in Newport Beach, CA. \n \n  As a Business Intelligence Lead , you\u2019ll play a key role within the Workforce Benefits division to advance our reporting and visualization efforts. You will ensure that we remain agile and will be responsible for leveraging Tableau to develop robust reporting mechanisms to present data in a clear, actionable format to stakeholders across departments. You will report to the Head of Analytics, Workforce Benefits and contribute to driving the Business Intelligence aspects of the overall Analytics strategy. \n \n \n How you will make an impact: \n  Data Visualization & Reporting \n Craft and refine Tableau dashboards that display complex data streams in comprehensible visual formats. Regularly update and adapt reports in line with changing business needs and objectives. \n Stakeholder Collaboration \n Engage regularly with department leads to ascertain their data requirements. Conduct workshops and feedback sessions to refine BI offerings. \n Data Integrity Assurance \n Establish protocols to ensure report accuracy and consistency. Identify and rectify any discrepancies or anomalies in datasets. Collaborate closely with the Data Engineering team \n Training & Capability Building \n Roll out Tableau training sessions for internal stakeholders, ensuring optimal utilization. Develop BI best practices and guidelines for the broader team. \n Performance & Scalability \n Ensure rapid dashboard responsiveness and efficient report generation. Strategize on BI infrastructure scalability to support growing datasets. \n Ad hoc reporting needs \n Generates ad hoc reports and regular datasets or report information for end-users using system tools and database or data warehouse queries and scripts. \n \n \n The experience you will bring: \n  Passion for fostering a data-driven culture. \n Bachelor's degree in Technology , Computer Science, or a related field. \n 6+ years of experience in business intelligence, data analysis, or a similar role. \n Proven expertise in Tableau (certification preferred). \n Proficiency in SQL and understanding of relational databases. \n Strong analytical and problem-solving skills. \n Excellent communication skills, with the ability to present complex information in a clear and concise manner. \n \n \n What will make you stand out: \n  MS and/or MBA degree \n Workforce Benefits, Insurance or Financial Services \n Familiarity with other BI tools is a plus \n Knowledge of Salesforce objects and data structures \n \n  #LI-JA1 \n \n  You belong at Pacific Life \n At Pacific Life we are committed to a culture of belonging, a space where all employees are empowered to be authentic. One way we cultivate an inclusive culture is through our employee connection groups. The purpose of these employee-led groups is to offer a place to build community, connection, camaraderie, and a sense of belonging. Each group can be active in education, advocacy, recruitment, and community building throughout our organization. Learn more about our employee connection groups at www.pacificlife.com. \n \n  Want to learn more about life at Pacific Life? Take an inside look at our company culture: Instagram.com/lifeatpacificlife. \n \n \n Base Pay Range: \n  The base pay range noted provides a basis to determine the appropriate offer dependent upon several factors including but not limited to geographic location, experience, skills, education and pay equity. Also, most employees are eligible for additional incentive pay. \n \n  Your Benefits Start Day 1 \n \n  Your wellbeing is important to Pacific Life, and we\u2019re committed to providing you with flexible benefits that you can tailor to meet your needs. Whether you are focusing on your physical, financial, emotional, or social wellbeing, we\u2019ve got you covered. \n \n  Prioritization of your health and well-being including Medical, Dental, Vision, and Wellbeing Reimbursement Account that can be used on yourself or your eligible dependents \n \n \n Generous paid time off options including:  Paid Time Off, Holiday Schedules, and Financial Planning Time Off \n \n  Paid Parental Leave as well as an Adoption Assistance Program \n \n  Competitive 401k savings plan with company match and an additional contribution regardless of participation \n \n \n EEO Statement: \n  Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.",
        "cleaned_desc": " Data Integrity Assurance \n Establish protocols to ensure report accuracy and consistency. Identify and rectify any discrepancies or anomalies in datasets. Collaborate closely with the Data Engineering team \n Training & Capability Building \n Roll out Tableau training sessions for internal stakeholders, ensuring optimal utilization. Develop BI best practices and guidelines for the broader team. \n Performance & Scalability \n Ensure rapid dashboard responsiveness and efficient report generation. Strategize on BI infrastructure scalability to support growing datasets. \n Ad hoc reporting needs \n Generates ad hoc reports and regular datasets or report information for end-users using system tools and database or data warehouse queries and scripts. \n \n \n The experience you will bring: \n  Passion for fostering a data-driven culture. \n Bachelor's degree in Technology , Computer Science, or a related field.   6+ years of experience in business intelligence, data analysis, or a similar role. \n Proven expertise in Tableau (certification preferred). \n Proficiency in SQL and understanding of relational databases. \n Strong analytical and problem-solving skills. \n Excellent communication skills, with the ability to present complex information in a clear and concise manner. \n \n \n What will make you stand out: \n  MS and/or MBA degree \n Workforce Benefits, Insurance or Financial Services \n Familiarity with other BI tools is a plus \n Knowledge of Salesforce objects and data structures \n ",
        "techs": [
            "data integrity assurance",
            "tableau",
            "sql",
            "relational databases",
            "salesforce objects",
            "data structures"
        ],
        "cleaned_techs": [
            "data integrity assurance",
            "tableau",
            "sql",
            "relational databases",
            "salesforce objects",
            "data structures"
        ]
    },
    "e1d98e1e8a92c976": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 83200.0,
        "salary_max": 93600.0,
        "title": "Business Technical Analyst",
        "company": "Ascendion",
        "desc": "Description \n About Ascendion \n  Ascendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next. \n  Ascendion | Engineering to elevate life \n  We have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us: \n \n Build the coolest tech for world\u2019s leading brands \n Solve complex problems \u2013 and learn new skills \n Experience the power of transforming digital engineering for Fortune 500 clients \n Master your craft with leading training programs and hands-on experience \n \n Experience a community of change makers! \n  Join a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion. \n  About the Role: \n \n Ascendion  is looking for a BTA Developer to support a large healthcare organization in. \n This group will be working with risk adjustment team to help reconcile healthcare data sets. \n They are building out dashboards and reports and visualition in powerBI related to medicare and medicaid data sets. \n \n \n \n  Job Title: Business Technical Analyst/Data Analyst \n \n \n  Key Responsibilities: \n \n Developing with SAS and SQL.   \n \n \n    Building out complex dashboards with Power BI.\n      \n \n \n    Working with large database sets and dealing with database management.\n      \n \n \n    Having healthcare experience with Medicaid and Medicare.\n      \n \n \n    Communicating effectively and working hard.\n      \n \n \n    Having a great go-getter, up-beat personality.\n    \n \n \n   \n Must Haves: \n \n 4+ years of experience with SAS and SQL   \n \n \n    4+ years of experience with Power BI for building out complex dashboards\n      \n \n \n    Strong experience working with large database sets and dealing with the database management\n      \n Healthcare experience with Medicaid and Medicare specifically \n \n \n    Strong communicator/hard worker\n      \n \n \n    MUST have a GREAT go-getter, up-beat personality\n    \n \n \n   \n Location: Remote \n \n \n  Salary Range:  The salary for this position is between $83,200 \u2013 $93,600 annually. Factors which may affect pay within this range may include geography/market, skills, education, experience and other qualifications of the successful candidate. \n \n \n  This position is eligible for commissions in accordance with the terms of the Company\u2019s plan. Commissions for this position are estimated to be based on individual performance. Additionally, this role is also eligible for bonus based on achievement of mutually agreed KRAs. \n \n \n  Benefits : The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [personal days accrued each calendar year. The Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [12-15 days of paid vacation time] [6-8 weeks of paid parental leave after a year of service] [9 paid holidays and 2 floating holidays per calendar year] [Ascendion Learning Management System] [Tuition Reimbursement Program] \n \n \n   Want to change the world? Let us know. \n  Tell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let\u2019s talk! \n Preferred Skills: \n \n Business Technical Analyst \n  Risk Adjustment \n  Data Sets \n  SAS \n  SQL \n  Power BI \n  DBMS \n  Dashboards \n  Medicaid \n  Medicare \n \n Job details \n \n \n Job ID \n \n \n   328888\n   \n \n \n \n Job Requirements \n \n \n   Business Technical Analyst\n   \n \n \n \n \n Location \n \n \n   Tampa, Florida, US\n   \n \n \n \n \n Recruiter \n \n \n   Adarsh\n   \n \n \n \n Email \n \n \n   adarsh.singh@ascendion.com",
        "cleaned_desc": " \n    Building out complex dashboards with Power BI.\n      \n \n \n    Working with large database sets and dealing with database management.\n      \n \n \n    Having healthcare experience with Medicaid and Medicare.\n      \n \n \n    Communicating effectively and working hard.\n      \n \n \n    Having a great go-getter, up-beat personality.\n    \n \n \n   \n Must Haves: \n \n 4+ years of experience with SAS and SQL   \n \n \n    4+ years of experience with Power BI for building out complex dashboards",
        "techs": [
            "power bi",
            "sas",
            "sql"
        ],
        "cleaned_techs": [
            "powerbi",
            "sas",
            "sql"
        ]
    },
    "3307340bc4922426": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 65.0,
        "salary_max": 70.0,
        "title": "8664 \u2013 Retirement Conversion Business Analyst",
        "company": "Interactive Resources LLC",
        "desc": "Implementation-Conversion Analyst/Client Conversion Analyst/Implementation Analyst/Business Analyst/Retirement Business Analyst/OMNI Conversion Analyst \n Join our team today on this EXCITING contract-to-hire opportunity with a FANTASTIC Fortune 500 Banking/Finance industry client company! \n SUMMARY : Client Data Mapping and information collection in order to arrange for a smooth client conversion from one system to the other and may train on use of systems/support client during conversion. \n **FULL DETAILS will be provided over a phone call to discuss!** \n DETAILS: \n \n This position is FULLY remote, but MUST sit in the U.S. (Need work certain time zone work hours \u2013 prefer ET, but CT and MT would be ok) \n A completed Bachelor\u2019s Degree is required at minimum or a completed High School Diploma/GED equivalent with the equivalent in training, work experience, etc. \n This is a contract-to-hire job opportunity! \n Starting pay ranges from $65.00/hour- $70.00/hour based on experience level! \n \n REQUIREMENTS: \n \n A completed Bachelor\u2019s Degree is highly preferred. A completed High School Diploma/GED equivalent with the equivalent in training, work experience, etc. is required at MINIMUM. \n MUST have intermediate to advanced Excel skills, retirement and OMNI recordkeeping systems experience, reconciliations experience, and experience with AdminWeb! \n MUST have at least 1-2 years of Banking or Financial Services industry experience. \n MUST have self-starting abilities & a high level of resourcefulness. \n Previous experience in a client-facing position is required. (Professional relationship building, negotiations, etc. experience is needed) \n 1-2 years of Project Management/Coordination/Assistance experience is a big plus! \n MUST be able to translate client requirements into more technical verbiage in order to communicate to technical team. \n MUST be able to maintain professional working relationships both internally and externally. \n Microsoft Suite programs skills and full computer literacy are required. \n BIG PLUS if you have Project Assistance/Coordinating, Business Analysis, Technical Implementations work experience. \n MUST interview with a hiring manager in order to receive a job offer and MUST be willing/able to submit to background screening and drug screening if job offer is accepted! \n \n Interactive Resources (iR) was built to provide a personalized approach to solving client and candidate needs while building sustaining relationships. In a world where technology advances by the minute, relationships are the variable that cannot be substituted with software. \n Founded in 2006 in Jacksonville, Florida, iR has grown year over year expanding across the United States. iR was founded on the principles of Honesty, Trust, and Dedication. We take pride in the relationships we have built and continue to build, and we are dedicated to delivering the superior results that our clients and candidates come to expect and deserve. We love what we do! \n Relationships \u2013 Talent \u2013 Results \n Job Types: Contract, Full-time \n Pay: $65.00 - $70.00 per hour \n Schedule: \n \n Day shift \n Monday to Friday \n \n Education: \n \n Bachelor's (Required) \n \n Experience: \n \n Retirement Plan: 1 year (Required) \n Data Conversion: 1 year (Required) \n Banking or Finance industry: 1 year (Required) \n OMNI: 1 year (Required) \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "28162dd96d9b7a0d": {
        "terms": [
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 70000.0,
        "salary_max": 125000.0,
        "title": "Jr./Mid-Level Data Engineer",
        "company": "Dama Technology Inc",
        "desc": "About Dama Financial \n  At Dama Financial, we use technology to solve problems that critically impact the growth and reputation of the cannabis industry. We offer innovative, compliant, sustainable financial and traceability products, removing the barriers that exclude cannabis businesses from accessing the fundamental solutions required to support a rapidly growing industry. We have a diverse team of professionals with deep expertise in financial services, payments technology, cannabis regulations, and successfully building and growing companies. Throughout the organization, you\u2019ll find people who solve problems, deliver solutions, and deal with uncertainties while building best in class products for the industry.\n  \n \n \n \n  The Role \n  The Data & Analytics team within Dama is growing to help clients scale their retail operations with a world-class point-of-sale system and flexible payment options. The team is also responsible for helping internal teams become more data-driven by helping them to understand, utilize and extract value from the data generated by our systems and available in our warehouse.\n  \n \n \n  Although we\u2019re a growth-stage company, our environment is typical of a start-up \n \n  We work in small, high-performing teams, are fast-paced, and we all get a lot done by everyone wearing many hats. \n \n \n  We are serious about optimizing our time and staying focused on the most important goals and outcomes. \n \n \n  We are a 100% remote team meaning we focus on communication to ensure we can stay in sync despite our physical distance. \n \n \n \n \n  What you'll do \n \n \n  Report to Director of Data & Analytics \n \n \n  Build and maintain pipelines to move data from source systems into our cloud data warehouse \n \n \n  Transform and model data using SQL & Python \n \n \n  Monitor data pipelines for errors/data quality issues and work with Dev Ops Engineering to improve observability and alerting \n \n \n  Improve data quality, reliability, efficiency, and performance while optimizing cost \n \n \n  Document data models, schemas, business logic, pipelines, and other metadata \n \n \n  Collaborate with engineers and product managers to understand data requirements \n \n \n \n \n  What we\u2019re looking for \n \n \n  You\u2019re a great creative problem solver with an analytical mind who loves to dig in and solve hard problems \n \n \n  You see data flowing and you can\u2019t stop yourself from classifying, categorizing, organizing and directing those flows to create efficient/performant, useful and usable datasets for both operations and decision support \n \n \n  You\u2019re not just a \u201cdata person\u201d, you\u2019re an Engineer who specializes in data and metadata. \n \n \n  You love learning new things and have a passion for building, monitoring and improving a well-oiled \u201cdata machine\u201d \n \n \n  You have the ability to work both independently and collaboratively as part of a remote team \n \n \n \n  Required Experience \n \n  1-3 years of experience in a Data Engineer role working with the \u201cModern Data Stack\u201d \n \n \n  SQL. You know SQL. SQL is a friend of yours. You two probably share a secret handshake \n \n \n  Ideal candidate will have experience with both BigQuery & dbt (including Python) \n \n \n \n  Nice-to-have Experience \n \n  Integration tools (Airbyte, Stitch, Fivetran) \n \n \n  Orchestration tools (Dagster, Airflow, dbt Cloud) \n \n \n  Metadata tools (DataHub, OpenMetadata) \n \n \n  BI/Dashboard tools (Looker, Superset, PowerBI) \n \n \n \n \n  Benefits \n \n \n  Healthcare \n \n \n  401K \n \n \n  Generous PTO \n \n \n  Collaborative Environment \n \n \n \n \n  What we offer \n \n \n  A low ego environment where you can give and receive direct feedback. \n \n \n  Managers who care about your career development. \n \n \n \n \n  Due to the nature of financial systems, you will be required to pass a background check. \n \n \n \n \n  Send resumes to  \n jobs@damafinancial.com \n \n \n \n   CHR: Jr./Mid-Level Data Engineer \n \n \n \n  LI: Jr./Mid Level Data Engineer \n \n \n \n  Salary commensurate upon experience \n \n \n  Bonus goals based on company goals",
        "cleaned_desc": " \n  Build and maintain pipelines to move data from source systems into our cloud data warehouse \n \n \n  Transform and model data using SQL & Python \n \n \n  Monitor data pipelines for errors/data quality issues and work with Dev Ops Engineering to improve observability and alerting \n \n \n  Improve data quality, reliability, efficiency, and performance while optimizing cost \n \n \n  Document data models, schemas, business logic, pipelines, and other metadata \n \n \n  Collaborate with engineers and product managers to understand data requirements \n \n \n \n \n  What we\u2019re looking for \n \n \n  You\u2019re a great creative problem solver with an analytical mind who loves to dig in and solve hard problems \n \n \n  You see data flowing and you can\u2019t stop yourself from classifying, categorizing, organizing and directing those flows to create efficient/performant, useful and usable datasets for both operations and decision support \n   \n  You\u2019re not just a \u201cdata person\u201d, you\u2019re an Engineer who specializes in data and metadata. \n \n \n  You love learning new things and have a passion for building, monitoring and improving a well-oiled \u201cdata machine\u201d \n \n \n  You have the ability to work both independently and collaboratively as part of a remote team \n \n \n \n  Required Experience \n \n  1-3 years of experience in a Data Engineer role working with the \u201cModern Data Stack\u201d \n \n \n  SQL. You know SQL. SQL is a friend of yours. You two probably share a secret handshake \n \n \n  Ideal candidate will have experience with both BigQuery & dbt (including Python) \n \n \n \n  Nice-to-have Experience \n \n  Integration tools (Airbyte, Stitch, Fivetran) \n \n \n  Orchestration tools (Dagster, Airflow, dbt Cloud) ",
        "techs": [
            "sql",
            "python",
            "bigquery",
            "dbt",
            "airbyte",
            "stitch",
            "fivetran",
            "dagster",
            "airflow",
            "dbt cloud."
        ],
        "cleaned_techs": [
            "sql",
            "python",
            "bigquery",
            "dbt",
            "airbyte",
            "stitch",
            "fivetran",
            "dagster",
            "airflow",
            "dbt cloud."
        ]
    },
    "b3bf485f8a0f7808": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 147000.42,
        "salary_max": 186135.3,
        "title": "Data Engineer",
        "company": "Atlassian",
        "desc": "Overview: \n   Atlassian is looking for a Data Engineer to join our Data Engineering Team. You will build top-notch data solutions and applications that inspire important decisions across the organization. You will be reporting to the Senior Data Engineering Manager. \n  You'll have flexibility in where you work \u2013 whether in an office, from home (remote), or a combination of the two. \n Compensation \n  At Atlassian, we strive to design equitable, explainable, and competitive compensation programs. To support this goal, the baseline of our range is higher than that of the typical market range, but in turn we expect to hire most candidates near this baseline. Base pay within the range is ultimately determined by a candidate's skills, expertise, or experience. In the United States, we have three geographic pay zones. For this role, our current base pay ranges for new hires in each zone are: \n Zone A: $147,500 - $196,600 \n  Zone B: $132,700 - $177,000 \n  Zone C: $122,400 - $163,200 \n  This role may also be eligible for benefits, bonuses, commissions, and equity. \n Please visit go.atlassian.com/payzones for more information on which locations are included in each of our geographic pay zones. However, please confirm the zone for your specific location with your recruiter.  Responsibilities: \n   A typical day may involve collaborating with partners, you will design data models, acquisition processes, and applications to address needs. With experience in large-scale data processing systems (batch and streaming), you will lead business growth and enhance product experiences. And will collaborate with Technology Teams, Global Analytical Teams, and Data Scientists across programs. \n  You'll take ownership of problems from end-to-end: extracting/cleaning data, and understanding generating systems. Improving the quality of data by adding sources, coding rules, and producing metrics is crucial as requirements evolve. Agility and smart risk-taking are important qualities in this industry where digital innovation meets partner/customer needs over time.  Qualifications: \n   On your first day, we'll expect you to have: \n \n  BS in Computer Science or equivalent experience with 3+ years as a Data Engineer or a similar role \n  Programming skills in Python & Java (good to have) \n  Design data models for storage and retrieval to meet product and requirements \n  Build scalable data pipelines using Spark, Airflow, AWS data services (Redshift, Athena, EMR), Apache projects (Spark, Flink, Hive, and Kafka) \n  Familiar with modern software development practices (Agile, TDD, CICD) applied to data engineering \n  Enhance data quality through internal tools/frameworks detecting DQ issues. Working knowledge of relational databases and SQL query authoring \n \n  We\u2019d be super excited if you have: \n \n  Followed a Kappa architecture with any of your previous deployments and domain knowledge of Financial and People System",
        "cleaned_desc": "  Design data models for storage and retrieval to meet product and requirements \n  Build scalable data pipelines using Spark, Airflow, AWS data services (Redshift, Athena, EMR), Apache projects (Spark, Flink, Hive, and Kafka) \n  Familiar with modern software development practices (Agile, TDD, CICD) applied to data engineering \n  Enhance data quality through internal tools/frameworks detecting DQ issues. Working knowledge of relational databases and SQL query authoring ",
        "techs": [
            "spark",
            "airflow",
            "redshift",
            "athena",
            "emr",
            "flink",
            "hive",
            "kafka",
            "agile",
            "tdd",
            "cicd",
            "sql"
        ],
        "cleaned_techs": [
            "spark",
            "airflow",
            "redshift",
            "athena",
            "emr",
            "flink",
            "hive",
            "kafka",
            "agile",
            "tdd",
            "cicd",
            "sql"
        ]
    },
    "e1d633e960423d61": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 115000.0,
        "salary_max": 125000.0,
        "title": "Data Engineer",
        "company": "Gen4 Dental",
        "desc": "Company Description \n At Gen4, we pride ourselves on our commitment to providing an incredible patient experience. We are passionate about our craft and the impact we can have on our patients. We aim to foster a doctor-centric organization that allows our doctors to do more of what they love. Culture, high performance, growth, and development are deeply embedded in our business and we have our sights set on finding individuals who are excited to be a part of a growing, flourishing company like ours.  We offer competitive pay and a comprehensive benefits package available on the 1st of the month after 30 days of employment for full-time employees . \n To learn more about us, check out our website here: https://gen4dental.com/ \n Job Description \n The Data Engineer is a detail-oriented and innovative engineer with a deep understanding of Microsoft data platforms and proficiency in Python. In this role, you will spearhead the development and maintenance of our data infrastructure to facilitate efficient data processing and analytics, enhancing our dental services through informed, data-driven strategies. \n Duties & Responsibilities \n \n Develop, construct, test, and maintain robust ETL processes primarily using Microsoft SQL Server Integration Services (SSIS) and\\or Python. \n Design and implement relational and non-relational database systems utilizing Microsoft SQL Server, ensuring data integrity, availability, and confidentiality. \n Leverage Microsoft Azure data services (Azure Data Factory, Azure SQL Data Warehouse, Azure Data Lake, etc.) for scalable and cost-effective solutions. \n Develop analytical tools and solutions using Microsoft Power BI to empower teams with actionable insights for strategic planning and operational efficiency. \n Optimize and automate data delivery processes and establish routines for database tasks to improve system performance and stability. \n Uphold high standards for data quality by devising and implementing effective data cleaning and validation procedures. \n Collaborate closely with cross-functional teams to align data management and analytics solutions with business objectives. \n \n Qualifications \n Required: \n \n Minimum of 5+ years\u2019 experience as a Data Engineer, ETL Developer, or similar role with a focus on Microsoft data platforms. \n Proficient in SQL with a solid understanding of Microsoft SQL Server and SSIS. \n Experience with Azure data services and Microsoft Power BI is essential. \n Knowledge of data modeling principles, including experience with data warehousing and big data technologies. \n Python programming experience. \n Strong problem-solving skills with an analytical mindset. \n Excellent communication skills, capable of explaining complex technical concepts to non-technical stakeholders. \n Multi-site healthcare experience. \n \n Preferred: \n \n Bachelor's degree in a technology or engineering field, or equivalent combination of experience \n Dental industry experience \n Google Bigquery experience \n Postgresql experience. \n \n Physical Requirements: \n \n Prolonged periods of sitting at a desk and working on a computer. \n Ability to lift up to 15 pounds. \n Excellent written, speaking and listening skills, requiring the perception of speech. \n Must have high finger dexterity to perform duties involving work on the computer. \n Able to travel as needed. \n \n Equipment Used: \n General office equipment (e.g. computer). \n Additional information \n Working conditions include those typically seen in an office environment. Prolonged periods of sitting at a desk and working on a computer. \n Equal Opportunity Employer \n Gen4 Dental Partners provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. \n Job Type: Full-time \n Pay: $115,000.00 - $125,000.00 per year \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Health insurance \n Paid time off \n Vision insurance \n \n Schedule: \n \n Monday to Friday \n \n Application Question(s): \n \n Are you at least 18 years of age? \n \n Work Location: Remote",
        "cleaned_desc": "Company Description \n At Gen4, we pride ourselves on our commitment to providing an incredible patient experience. We are passionate about our craft and the impact we can have on our patients. We aim to foster a doctor-centric organization that allows our doctors to do more of what they love. Culture, high performance, growth, and development are deeply embedded in our business and we have our sights set on finding individuals who are excited to be a part of a growing, flourishing company like ours.  We offer competitive pay and a comprehensive benefits package available on the 1st of the month after 30 days of employment for full-time employees . \n To learn more about us, check out our website here: https://gen4dental.com/ \n Job Description \n The Data Engineer is a detail-oriented and innovative engineer with a deep understanding of Microsoft data platforms and proficiency in Python. In this role, you will spearhead the development and maintenance of our data infrastructure to facilitate efficient data processing and analytics, enhancing our dental services through informed, data-driven strategies. \n Duties & Responsibilities \n \n Develop, construct, test, and maintain robust ETL processes primarily using Microsoft SQL Server Integration Services (SSIS) and\\or Python. \n Design and implement relational and non-relational database systems utilizing Microsoft SQL Server, ensuring data integrity, availability, and confidentiality. \n Leverage Microsoft Azure data services (Azure Data Factory, Azure SQL Data Warehouse, Azure Data Lake, etc.) for scalable and cost-effective solutions. \n Develop analytical tools and solutions using Microsoft Power BI to empower teams with actionable insights for strategic planning and operational efficiency. \n Optimize and automate data delivery processes and establish routines for database tasks to improve system performance and stability. \n Uphold high standards for data quality by devising and implementing effective data cleaning and validation procedures.   Collaborate closely with cross-functional teams to align data management and analytics solutions with business objectives. \n \n Qualifications \n Required: \n \n Minimum of 5+ years\u2019 experience as a Data Engineer, ETL Developer, or similar role with a focus on Microsoft data platforms. \n Proficient in SQL with a solid understanding of Microsoft SQL Server and SSIS. \n Experience with Azure data services and Microsoft Power BI is essential. \n Knowledge of data modeling principles, including experience with data warehousing and big data technologies. \n Python programming experience. \n Strong problem-solving skills with an analytical mindset. \n Excellent communication skills, capable of explaining complex technical concepts to non-technical stakeholders. \n Multi-site healthcare experience.   \n Preferred: \n \n Bachelor's degree in a technology or engineering field, or equivalent combination of experience \n Dental industry experience \n Google Bigquery experience \n Postgresql experience. \n \n Physical Requirements: \n \n Prolonged periods of sitting at a desk and working on a computer. \n Ability to lift up to 15 pounds. \n Excellent written, speaking and listening skills, requiring the perception of speech. ",
        "techs": [
            "microsoft sql server integration services (ssis)",
            "python",
            "microsoft sql server",
            "microsoft azure data factory",
            "azure sql data warehouse",
            "azure data lake",
            "microsoft power bi",
            "google bigquery",
            "postgresql."
        ],
        "cleaned_techs": [
            "microsoft sql server integration services (ssis)",
            "python",
            "microsoft sql server",
            "microsoft azure data factory",
            "azure",
            "powerbi",
            "google bigquery",
            "postgresql"
        ]
    },
    "f848260d4e85d0e1": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 105000.0,
        "salary_max": 129000.0,
        "title": "Data Engineer",
        "company": "Jellyvision",
        "desc": "Data Engineer \n  Who we are \n  Jellyvision ALEX\u00ae, is on a mission to improve lives by helping people choose and use their benefits. We are raising the bar\u2014for benefits and the employee experience (for our employees and those of the customers we serve) \u2013 by scaling personalization, compassion and an earnest intent to be helpful in all that we do. \n  Jellyvision people are a group of creative problem solvers who use good judgment, give each other honest feedback, engage in real debate, and snack frequently. We are curious, hungry, and humble\u2014because we know this is how we'll continue to make an impact. We're kind, biased towards action, and sweat the details to create great experiences for those we serve. \n  We are an inclusive, human-first workplace. Respect and trust for each other are foundational, and our equitable total rewards offerings support the lives and holistic well-being of our unique people. At Jellyvision, expect career experiences that challenge you, empower you to have a direct impact on our mission, and enable you to learn, try, and do while having fun along the way. \n  What  you'll  do \n  As a company, Jellyvision is growing fast and so is the data associated with the growth! A Data Engineer will bring in industry expertise in Data Engineering to help bridge the needs of Data Scientists, Data Analysts, Business Intelligence, and the User Research teams. Successful candidates will collaborate with our business partners to understand the data needs and to achieve operational excellence. \n  How you'll do it \n  1.) Design, Build, and Integrate Data ETL/ELT Pipelines \n \n Use Cloud technologies (AWS, Google Cloud Platform [GCP]) and data-centric programming language (Python preferred) \n Be able to use, track, and monitor third party ETL/ELT tools, such as Fivetran, Stitch and Rudderstack \n Write test-friendly application code using either TDD or BDD methodologies \n Create, document, and execute all test plans (unit, integration, end-to-end) \n Write the complex SQL (NoSQL a plus) queries needed to make data easily accessible \n  Create, maintain, and optimize Data ecosystem \n \n 2.) Serve as a Consultative Partner \n \n Collaborate with architecture and lead engineers to ensure consistent development practices are followed \n Provide mentoring to Junior Engineers \n Participate in estimation process for new work and releases \n Participate in peer reviews \n \n 3.) Drive Continuous Improvement \n \n Participate in retrospective reviews once the project and/or sprint is completed \n Provide constructive feedback where and when necessary to improve process and delivery \n Drive improvements in people, practices, and procedures \n Ability to learn and embrace new technologies in an ever-changing environment \n Support live systems to ensure business continuity \n \n Experience & skills you'll need \n \n 5+ years of experience in the Data Engineering domain \n Strong SQL skills and experience writing large volumes of data and various database technologies \n Experience in Python, Ruby, Scala, C++, or any other data-centric programming languages \n Well versed in ETL/ELT process and implementation \n Strong analytic skills related to working with big structured and unstructured datasets \n Experience with big data tools such as Hadoop, Spark, Kafka, etc \n Experience with relational SQL and NoSQL databases \n Experience with AWS cloud services such as EC2, EMR, RDS, Redshift \n Excellent communication skills and ability to work using Agile methodologies \n Ability to work quickly and collaboratively in a fast-paced, entrepreneurial environment \n Outstanding problem-solving skills \n Experience in on-call support rotation schedule \n Good to have: \n    \n Experience with AWS and AWS ML services like SageMaker \n Experience with AWS Data Engineering tools like AWS Glue, AWS Data Pipeline, Airflow \n Experience working with PII, PHI, HIPAA, CCPA, and Healthcare sensitive data \n Experience and knowledge working with data warehouses such as Snowflake \n Full-stack experience, having both frontend and backend development experience \n Entrepreneurial and innovative approach to problem solving \n   \n \n Skills \n \n Action Oriented \n Collaborates \n Drives Results \n Manages Complexity \n Optimizes Work Processes \n Tech Savvy - High Complexity Tasks \n Resourcefulness \n \n The Details \n \n Location : Remote \n Starting Salary:  $105,000-$129,000 \n \n What Jellyvision will give  you \n \n Check out our benefits  here ! \n \n Jellyvision is committed to continuous evolution and to fostering a more diverse and inclusive workplace where everyone is welcomed, valued, and respected. It doesn't matter your race, ethnicity, religion, sexual orientation, age, marital status, disability, gender identity, sex, or country of origin...we just want amazing people who are willing to grow along with us.",
        "cleaned_desc": " Support live systems to ensure business continuity \n \n Experience & skills you'll need \n \n 5+ years of experience in the Data Engineering domain \n Strong SQL skills and experience writing large volumes of data and various database technologies \n Experience in Python, Ruby, Scala, C++, or any other data-centric programming languages \n Well versed in ETL/ELT process and implementation \n Strong analytic skills related to working with big structured and unstructured datasets \n Experience with big data tools such as Hadoop, Spark, Kafka, etc \n Experience with relational SQL and NoSQL databases \n Experience with AWS cloud services such as EC2, EMR, RDS, Redshift \n Excellent communication skills and ability to work using Agile methodologies \n Ability to work quickly and collaboratively in a fast-paced, entrepreneurial environment \n Outstanding problem-solving skills   Experience in on-call support rotation schedule \n Good to have: \n    \n Experience with AWS and AWS ML services like SageMaker \n Experience with AWS Data Engineering tools like AWS Glue, AWS Data Pipeline, Airflow \n Experience working with PII, PHI, HIPAA, CCPA, and Healthcare sensitive data \n Experience and knowledge working with data warehouses such as Snowflake \n Full-stack experience, having both frontend and backend development experience \n Entrepreneurial and innovative approach to problem solving \n   \n \n Skills \n \n Action Oriented \n Collaborates ",
        "techs": [
            "sql",
            "python",
            "ruby",
            "scala",
            "c++",
            "etl/elt",
            "hadoop",
            "spark",
            "kafka",
            "relational sql",
            "nosql",
            "aws ec2",
            "aws emr",
            "aws rds",
            "aws redshift",
            "agile methodologies",
            "aws sagemaker",
            "aws glue",
            "aws data pipeline",
            "airflow",
            "pii",
            "phi",
            "hipaa",
            "ccpa",
            "snowflake"
        ],
        "cleaned_techs": [
            "sql",
            "python",
            "ruby",
            "scala",
            "c++",
            "etl/elt",
            "hadoop",
            "spark",
            "kafka",
            "relational sql",
            "nosql",
            "aws",
            "agile methodologies",
            "airflow",
            "pii",
            "phi",
            "hipaa",
            "ccpa",
            "snowflake"
        ]
    },
    "445662e46d0fc401": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 67800.0,
        "salary_max": 133100.0,
        "title": "Data Engineer, Business Insights - Remote",
        "company": "UnitedHealthcare",
        "desc": "At UnitedHealthcare, we\u2019re simplifying the health care experience, creating healthier communities and removing barriers to quality care. The work you do here impacts the lives of millions of people for the better. Come build the health care system of tomorrow, making it more responsive, affordable and equitable. Ready to make a difference? Join us to start  Caring. Connecting. Growing together. \n \n   \n Positions in this function are responsible for the management and manipulation of mostly structured data, with a focus on building business intelligence tools, conducting analysis, performing normalization operations, and assuring data quality. Depending on the specific role and business line, example responsibilities in this function could include creating specifications to bring data into a common structure, creating product specifications and models, developing data solutions to support analyses, performing analysis, interpreting results, developing actionable insights and presenting recommendations for use across the company. Roles in this function could partner with stakeholders to understand data requirements and develop tools and models such as segmentation, dashboards, data visualizations, decision aids and business case analysis to support the organization. Other roles involved could include producing and managing the delivery of activity and value analytics to external stakeholders and clients. Team members will typically use business intelligence, data visualization, query, analytic and statistical software to build solutions, perform analysis and interpret data. \n \n \n  You\u2019ll enjoy the flexibility to work remotely * from anywhere within the U.S. as you take on some tough challenges. \n \n   \n Primary Responsibilities: \n  General Job Profile \n \n This position will work directly with stakeholders within our UHC Core Operations and more broadly within UHG as appropriate to deliver quality data solutions. This position provides visibility, analytical, ad hoc and development capabilities leveraging data from different functional areas across the UHG landscape \n \n   Job Scope and Guidelines \n \n Works in an Agile framework within a matrix environment working in sprints and utilizing agile tools (e.g., RallyDev) \n Instills an Agile framework within the team and across the matrix environment to operate as applicable and fully utilizing RallyDev tools \n Build, maintain and/or adhere to a structured data governance process to be used across all datasets with a focus on quality and accuracy \n Works closely within Quality Management & Insights (QMI) and across UnitedHealthcare \n Identify and participate in the resolution of data integrity issues and organizational problems \n \n \n Functional Competencies \n \n Demonstrate and apply understanding of UnitedHealth Group's business (e.g., specific business capabilities, functions, processes, and business cycles) and knowledge of operations, goals, and policies and procedures of internal business partners (e.g., information contacts) to provide effective support to internal and/or external customers \n Manage and protect data, adhering to applicable legal/regulatory requirements (e.g., HIPAA, PHI, PII, DOI, state and federal regulations) \n Propose and/or define long-term strategies for implementing process and/or data and reporting improvements \n Identify and/or provide opportunities for additional training and learning to support process and report improvements \n Review and/or identify appropriate data infrastructure to use based on customers' needs in alignment with QMI priorities \n Develop business context diagrams (e.g., business data flows, process flows) to analyze/confirm the definition of project requirements \n Demonstrate understanding of the difference between business requirements and technical solutions and define approach for storing and updating business requirements \n Collaborate with business and technical stakeholders (e.g., business owners, process owners, domain experts) to identify specific business requirements. Perform reviews with all stakeholders to obtain approval/signoff of project requirements documents \n Update progress to project schedule to track/measure progress one\u2019s progress fulfilling aligned tasks. In addition to supporting ongoing monitoring by keeping project documentation or applications updated (e.g., RallyDev) \n \n \n \n   \n You\u2019ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in. \n  Required Qualifications: \n \n 3+ years of SQL/TSQL development experience \n 3+ years of SSIS package development experience \n 3+ years of experience with Data Modeling, ETL construction with advanced job scheduling \n 3+ years of experience performing data analysis and report development \n 3+ years of experience working in relational databases, database structures and design, systems design, data management, data warehouse \n \n \n \n   \n Preferred Qualifications: \n \n Bachelor\u2019s Degree \n Experience with MS Access \n \n \n \n \n All employees working remotely will be required to adhere to UnitedHealth Group\u2019s Telecommuter Policy \n \n \n   \n California, Colorado, Connecticut, Nevada, New Jersey, New York, Rhode Island, or Washington Residents Only:  The salary range for California/Colorado/Connecticut/Nevada/New Jersey/New York/Rhode Island/Washington residents is $67,800 to $133,100 annually. Pay is based on several factors including but not limited to education, work experience, certifications, etc. In addition to your salary, UnitedHealth Group offers benefits such as, a comprehensive benefits package, incentive and recognition programs, equity stock purchase and 401k contribution (all benefits are subject to eligibility requirements). No matter where or when you begin a career with UnitedHealth Group, you\u2019ll find a far-reaching choice of benefits and incentives. \n \n \n  At UnitedHealth Group, our mission is to help people live healthier lives and make the health system work better for everyone. We believe everyone\u2013of every race, gender, sexuality, age, location and income\u2013deserves the opportunity to live their healthiest life. Today, however, there are still far too many barriers to good health which are disproportionately experienced by people of color, historically marginalized groups and those with lower incomes. We are committed to mitigating our impact on the environment and enabling and delivering equitable care that addresses health disparities and improves health outcomes \u2014 an enterprise priority reflected in our mission. \n \n \n   \n Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law. \n \n \n  UnitedHealth Group is a drug - free workplace. Candidates are required to pass a drug test before beginning employment.",
        "cleaned_desc": "   Job Scope and Guidelines \n \n Works in an Agile framework within a matrix environment working in sprints and utilizing agile tools (e.g., RallyDev) \n Instills an Agile framework within the team and across the matrix environment to operate as applicable and fully utilizing RallyDev tools \n Build, maintain and/or adhere to a structured data governance process to be used across all datasets with a focus on quality and accuracy \n Works closely within Quality Management & Insights (QMI) and across UnitedHealthcare \n Identify and participate in the resolution of data integrity issues and organizational problems \n \n \n Functional Competencies \n \n Demonstrate and apply understanding of UnitedHealth Group's business (e.g., specific business capabilities, functions, processes, and business cycles) and knowledge of operations, goals, and policies and procedures of internal business partners (e.g., information contacts) to provide effective support to internal and/or external customers \n Manage and protect data, adhering to applicable legal/regulatory requirements (e.g., HIPAA, PHI, PII, DOI, state and federal regulations) \n Propose and/or define long-term strategies for implementing process and/or data and reporting improvements   3+ years of SSIS package development experience \n 3+ years of experience with Data Modeling, ETL construction with advanced job scheduling \n 3+ years of experience performing data analysis and report development \n 3+ years of experience working in relational databases, database structures and design, systems design, data management, data warehouse \n \n \n \n   \n Preferred Qualifications: \n \n Bachelor\u2019s Degree \n Experience with MS Access \n \n ",
        "techs": [
            "agile framework",
            "matrix environment",
            "rallydev",
            "structured data governance process",
            "quality management & insights (qmi)",
            "data integrity issues",
            "unitedhealth group's business",
            "hipaa",
            "phi",
            "pii",
            "doi",
            "ssis package development",
            "data modeling",
            "etl construction",
            "data analysis",
            "report development",
            "relational databases",
            "database structures and design",
            "systems design",
            "data management",
            "data warehouse",
            "ms access"
        ],
        "cleaned_techs": [
            "agile framework",
            "matrix environment",
            "rallydev",
            "structured data governance process",
            "quality management & insights (qmi)",
            "data integrity issues",
            "unitedhealth group's business",
            "hipaa",
            "phi",
            "pii",
            "doi",
            "ssis package development",
            "etl construction",
            "report development",
            "relational databases",
            "database structures and design",
            "systems design",
            "data management",
            "data warehouse",
            "ms access"
        ]
    },
    "e3a2b78dd10fb62c": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 140000.0,
        "salary_max": 175000.0,
        "title": "Lead Data Engineer",
        "company": "Canyon Associates",
        "desc": "Role and Responsibilities \n Must be a hands on Data Engineer with lead/management experience. Oversee 3 and design, create, test, deploy and support SQL code. Monitor database systems and daily ETL processes. Looking for 5+ years prior experience (hands-on) \n AWS, AZURE Cloud, Azure Databricks, Azure SQL Database, Data Structure, Power BI, Snowflake, Relational databases \n Job Type: Full-time \n Pay: $140,000.00 - $175,000.00 per year \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Employee discount \n Flexible spending account \n Health insurance \n Health savings account \n Paid time off \n Parental leave \n Vision insurance \n \n Schedule: \n \n Monday to Friday \n \n People with a criminal record are encouraged to apply \n Education: \n \n Bachelor's (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "a1ec6d7ad1511944": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 142603.89,
        "salary_max": 180568.3,
        "title": "Senior Data Engineer",
        "company": "SmithRx",
        "desc": "Who We Are: \n  SmithRx is a rapidly growing, venture-backed Health-Tech company. Our mission is to disrupt the expensive and inefficient Pharmacy Benefit Management (PBM) sector by building a next-generation drug acquisition platform driven by cutting edge technology, innovative cost saving tools, and best-in-class customer service. With hundreds of thousands of members onboarded since 2016, SmithRx has a solution that is resonating with clients all across the country. \n  We pride ourselves for our mission-driven and collaborative culture that inspires our employees to do their best work. We believe that the U.S healthcare system is in need of transformation, and we come to work each day dedicated to making that change a reality. At our core, we are guided by our company values: \n \n Integrity:  Do the right thing. Especially when it's hard. \n Courage:  Embrace the challenge. \n Together:  Build bridges and lift up your colleagues. \n \n Job Summary: \n  SmithRx is developing the next-generation pharmacy benefits management (PBM) platform, revolutionizing how businesses administer and oversee pharmacy benefits. Our cutting-edge technology platform provides real-time actionable insights that drive cost efficiencies, enhance clinical services, and elevate the customer experience. Operating within SmithRx's production and engineering division, the data engineering team is dedicated to establishing a scalable and dependable single source of truth data ecosystem. This ecosystem plays a critical role in enabling our organization to provide unparalleled service excellence and operational superiority to our valued customers. \n  We are currently seeking a highly motivated Senior Data Engineer to join our fast-paced data team. The primary focus of this role will be delivering high data availability and quality throughout the entire data life cycle from ingestion to end products: data pipelines, and data warehouse production datasets. This role will gather data quality requirements from stakeholders, these data consumers could include business users, product owners, data analysts, software developers, or even other data developers. \n  This role is critical because data quality is a continuous process as data environments are complex, interdependent, and constantly changing. He/She will advocate and bring best practices/methodologies, coding standards, and large-scale data warehouse design perspectives to our team. \n  What will you do: \n \n Design, build, and implement bug prevention strategies, and maintain highly scalable and reliable data platforms, including data pipelines, data warehouses, and data lakes. \n Develop and execute manual and automated test cases for data warehouse solutions to ensure the reliability of data pipelines, ETL processes, and data transformations. \n Collaborate with business users, product owners, data analytics, data engineering, and development teams to implement data quality best practices and optimize data workflows. \n Implement and optimize data governance and security policies to ensure data quality and compliance. \n Drive engineering excellence and lead craftsmanship in building, testing, and optimizing ETL/feature/metric pipelines \n Document data quality issues, testing procedures, and resolutions for future reference and knowledge sharing. Ability to perform root cause analysis on defects. \n \n What will you bring to SmithRx: \n \n BS or Master's degree preferred in Computer Science, Information Technology or Systems Engineering. Bachelor's degree required. \n A minimum of 6+ years of related experience in data engineering, software engineering, DevOps, and technical leadership. With a Bachelor's degree, 8+ years of experience are required. \n Start-up experience is highly desirable \n Prior experience in cloud services (AWS preferred), and columnar databases (Redshift, Snowflake). \n Proficiency in SQL, Python, Spark (Batch/Streaming), SparkSQL, PySpark, AWS Glue, Airflow, Terraform, Kubernetes, CI/CD, and automated testing capabilities \n Build end-to-end integration testing between multiple independent systems and interfaces (flat files, APIs, ETL), etc. \n \n What SmithRx Offers You: \n \n Highly competitive wellness benefits including Medical, Pharmacy, Dental, Vision, and Life Insurance \n Flexible Spending Benefits \n 401(k) Retirement Savings Program \n Short-term and long-term disability \n Discretionary Time Off \n 13 Paid Holidays \n Wellness benefits- Spring Health, Gympass, and Headspace \n Commuter Benefits \n Paid Parental Leave benefits \n Employee Assistance Program (EAP) \n Well stocked kitchen in office locations \n Professional development and training opportunities",
        "cleaned_desc": " Job Summary: \n  SmithRx is developing the next-generation pharmacy benefits management (PBM) platform, revolutionizing how businesses administer and oversee pharmacy benefits. Our cutting-edge technology platform provides real-time actionable insights that drive cost efficiencies, enhance clinical services, and elevate the customer experience. Operating within SmithRx's production and engineering division, the data engineering team is dedicated to establishing a scalable and dependable single source of truth data ecosystem. This ecosystem plays a critical role in enabling our organization to provide unparalleled service excellence and operational superiority to our valued customers. \n  We are currently seeking a highly motivated Senior Data Engineer to join our fast-paced data team. The primary focus of this role will be delivering high data availability and quality throughout the entire data life cycle from ingestion to end products: data pipelines, and data warehouse production datasets. This role will gather data quality requirements from stakeholders, these data consumers could include business users, product owners, data analysts, software developers, or even other data developers. \n  This role is critical because data quality is a continuous process as data environments are complex, interdependent, and constantly changing. He/She will advocate and bring best practices/methodologies, coding standards, and large-scale data warehouse design perspectives to our team. \n  What will you do: \n \n Design, build, and implement bug prevention strategies, and maintain highly scalable and reliable data platforms, including data pipelines, data warehouses, and data lakes. \n Develop and execute manual and automated test cases for data warehouse solutions to ensure the reliability of data pipelines, ETL processes, and data transformations.   Collaborate with business users, product owners, data analytics, data engineering, and development teams to implement data quality best practices and optimize data workflows. \n Implement and optimize data governance and security policies to ensure data quality and compliance. \n Drive engineering excellence and lead craftsmanship in building, testing, and optimizing ETL/feature/metric pipelines \n Document data quality issues, testing procedures, and resolutions for future reference and knowledge sharing. Ability to perform root cause analysis on defects. \n \n What will you bring to SmithRx: \n \n BS or Master's degree preferred in Computer Science, Information Technology or Systems Engineering. Bachelor's degree required.   A minimum of 6+ years of related experience in data engineering, software engineering, DevOps, and technical leadership. With a Bachelor's degree, 8+ years of experience are required. \n Start-up experience is highly desirable \n Prior experience in cloud services (AWS preferred), and columnar databases (Redshift, Snowflake). \n Proficiency in SQL, Python, Spark (Batch/Streaming), SparkSQL, PySpark, AWS Glue, Airflow, Terraform, Kubernetes, CI/CD, and automated testing capabilities \n Build end-to-end integration testing between multiple independent systems and interfaces (flat files, APIs, ETL), etc. \n \n What SmithRx Offers You: \n ",
        "techs": [
            "smithrx,\npharmacy benefits management (pbm) platform,\nreal-time actionable insights,\ndata engineering team,\nscalable and dependable single source of truth data ecosystem,\nsenior data engineer,\nhigh data availability,\ndata life cycle,\ndata pipelines,\ndata warehouse production datasets,\ndata quality requirements,\nbug prevention strategies,\nhighly scalable and reliable data platforms,\ndata pipelines,\ndata warehouses,\ndata lakes,\nmanual and automated test cases,\ndata transformations,\ndata quality best practices,\ndata workflows,\ndata governance,\ndata security policies,\nengineering excellence,\ncraftsmanship,\netl/feature/metric pipelines,\nroot cause analysis,\ncomputer science,\ninformation technology,\nsystems engineering,\ncloud services,\naws,\ncolumnar databases,\nredshift,\nsnowflake,\nsql,\npython,\nspark,\nsparksql,\npyspark,\naws glue,\nairflow,\nterraform,\nkubernetes,\nci/cd,\nautomated testing capabilities,\nend-to-end integration testing,\nindependent systems,\ninterfaces,\nflat files,\napis,\netl"
        ],
        "cleaned_techs": []
    },
    "0b0dbb24f9a073a7": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 97707.95,
        "salary_max": 123720.05,
        "title": "Data Integration Engineer",
        "company": "Buyers Edge Platform, LLC",
        "desc": "Who are we? \n  Buyers Edge Platform (\"BEP\") was born out of the 20-year growth and success of its founding companies Dining Alliance, Buyers Edge and Consolidated Concepts. BEP is a technology enabled group purchasing network, which provides group purchasing services, SaaS based technology solutions, and supply chain consulting and procurement related services to foodservice operators across many verticals, including restaurants (independents as well as multiunit, chains and franchise concepts), hospitality (hotels, casinos, resorts), healthcare (LTC based operators), colleges & universities and array of other foodservice based operators (food trucks, caterers, amusement parks and other leisure based operators). BEP represents over $35 Billion in Network Transactions. We are committed and passionate about our mission to keep foodservice operators thriving by saving them money and increasing the quality of their products. \n  This position is remote and based around East Coast working hours. We are unable to offer work sponsorship for this role. \n  As a Data Integration Engineer, you will help us bring in data from external sources to support the various development teams. You will also support those teams in various ways including as a development resource. \n  Your impact: \n \n Collaborate with stakeholders to understand data needs. Learn about various internal software products to support development teams with data integration projects. \n Work to align various new or existing data systems to meet business goals. Combine multiple data sources for business use. \n Source and evaluate the quality, reliability, and security of various data sources relevant to assigned projects. \n Develop code to work with internal data or retrieve data from external sources including APIs, databases, and/or other third-party applications as needed. This may include cleaning, processing, or transforming raw data to make it suitable for use in our systems. \n Coordinate projects with multiple cross-functional teams including developers, data scientists, analysts, and business stakeholders. \n \n About you: \n \n Proficient in programming languages such as Python, Java, or Node. \n Strong understanding of database technologies such as MySQL, Aurora, and Redshift. \n Experience performing research/discovery for new data from external sources. \n Experience leading projects and strong understanding of project management principles. \n Experience integrating with REST APIs to pull data and convert/save for business use. \n Experience with API tools such as Postman. \n Experience developing software in an agile environment and strong understanding of agile development methodologies/practices. \n Ability to work independently on complex systems and algorithms. Strong teamwork and collaboration skills with the ability to work effectively with cross-functional teams and stakeholders. \n Strong communication and interpersonal skills. \n Strong analytical and problem-solving skills. \n Strong Microsoft Office skills including Word & Excel. \n BA/BS in a technical discipline, or equivalent professional experience. \n 5-7+ years experience in programming & the key abilities outlined above. \n \n What's in this for you?  \n Amazing coverages to start.  Medical, dental, and vision coverages are just the beginning! We also offer ancillary plans, such as flexible spending accounts for both health and dependent care, critical illness, accident, and voluntary life as well as company paid life and long-term-disability plans! On top of this, we also offer a 401(k) plan with company match. \n  Invest in your success.  We will provide you with a thorough training and development program; and offer competitive compensation. \n  Live well = Work well.  Relax with our Personal Responsibility Paid Time Off policy where you don't have to accrue time off in order to take it! We also offer half-day Summer Fridays! \n \n  We welcome all. \n  We are committed to creating a diverse environment and are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to actual or perceived race, color, creed, religion, national origin, ancestry, citizenship status, age, sex or gender (including pregnancy, childbirth and pregnancy-related conditions), gender identity or expression (including transgender status), sexual orientation, marital status, military service and veteran status, physical or mental disability, genetic information, or any other characteristic protected by applicable federal, state or local laws and ordinances.",
        "cleaned_desc": " Collaborate with stakeholders to understand data needs. Learn about various internal software products to support development teams with data integration projects. \n Work to align various new or existing data systems to meet business goals. Combine multiple data sources for business use. \n Source and evaluate the quality, reliability, and security of various data sources relevant to assigned projects. \n Develop code to work with internal data or retrieve data from external sources including APIs, databases, and/or other third-party applications as needed. This may include cleaning, processing, or transforming raw data to make it suitable for use in our systems. \n Coordinate projects with multiple cross-functional teams including developers, data scientists, analysts, and business stakeholders. \n   About you: \n \n Proficient in programming languages such as Python, Java, or Node. \n Strong understanding of database technologies such as MySQL, Aurora, and Redshift. \n Experience performing research/discovery for new data from external sources. \n Experience leading projects and strong understanding of project management principles.   Experience integrating with REST APIs to pull data and convert/save for business use. \n Experience with API tools such as Postman. \n Experience developing software in an agile environment and strong understanding of agile development methodologies/practices. \n Ability to work independently on complex systems and algorithms. Strong teamwork and collaboration skills with the ability to work effectively with cross-functional teams and stakeholders. \n Strong communication and interpersonal skills. \n Strong analytical and problem-solving skills. ",
        "techs": [
            "python",
            "java",
            "node",
            "mysql",
            "aurora",
            "redshift",
            "postman"
        ],
        "cleaned_techs": [
            "python",
            "java",
            "node",
            "mysql",
            "aurora",
            "redshift",
            "postman"
        ]
    },
    "e2317b3154109084": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 97500.0,
        "salary_max": 176250.0,
        "title": "Data Lakehouse Engineer",
        "company": "Leidos",
        "desc": "Description   \n Leidos has an immediate opening for a Senior Systems Engineer supporting development of a data Lakehouse at HHS in Washington DC. This position is an excellent opportunity to interface directly with government personnel to help design and guide technical solutions and business processes for critical public health research and response mission spaces. \n \n  Primary Responsibilities \n \n  Work directly with the customer to capture and formalize \u2018Baseline\u2019 and \u2018To Be\u2019 business user stories, use cases, requirements, system architectures, and data schema. \n  Track and communicate solution and system development, production and maintenance activities. \n  Design and execute test plans for solution and system testing. \n  Help support the identification and considerations for alternative application solutions to meet business customer needs. \n  Work with the broader development, including SQL developers and Azure engineers. \n  Consider security and infrastructure implications of requested changes. \n \n \n  Basic Qualifications \n \n  Bachelor\u2019s Degree in Systems Engineering, Computer Science, Information Technology, Business Science, or related field required \n  8+ years\u2019 of combined experience in system engineering, software development or business analysis required. \n  Candidate must demonstrate a willing initiative to solicit customer requirements and translate them into formalized structured technical products. Candidate must have strong verbal and written communication skills. Concise writing and ability to communicate technical content to broad audiences are critical candidate abilities. \n  Candidate must be a US Citizen and be able to obtain and maintain a high-risk public trust clearance. \n  Must have experience or familiarity with: executing Agile, Scrum, and Kanban methodologies. Soliciting and documenting use cases and designs for system requirements (User Stories, Use Cases, Requirements, Specifications, Data Schema, Business Process Workflows). Use of system management tools such as Azure DevOps, Jira, Redmine, or similar system. Developing and executing testing and acceptance plans. Tracking bugs, issues and resolutions. Performing data analysis and reporting. Knowledge of government system security policies (ATO process) Ability to flexibly pivot to varying needs of the project while maintaining situational awareness \n \n \n  Preferred Qualifications \n \n  The preferred candidate will possess broader Systems Engineering knowledge and can readily execute low-level engineering tasks as well as high-level technical project management tasks. \n  The preferred candidate will have a MS in Systems Engineering or a related discipline. \n  Preferred candidates will have experience or familiarity with: \n  Knowledge of the Microsoft Azure ecosystem \n  Experience with Data Lakes and preferably Data Lakehouses \n  Experience working with federal IT systems \n  Experience working with SQL developers (or knowledge of SQL) \n  Prioritizing and communicating requirements and system development activities. \n  Communicating impact of requirement changes on active development activities. \n  Executing and presenting trade space of alternatives with cost benefit analysis. \n  Supporting Authority to Operate (ATO) activities and other production system processes. \n  Experience in developing advanced data visualizations. \n \n \n  Pay Range:  Pay Range $97,500.00 - $176,250.00\n  \n  The Leidos pay range for this job level is a general guideline only and not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other law. \n  #Remote",
        "cleaned_desc": "  8+ years\u2019 of combined experience in system engineering, software development or business analysis required. \n  Candidate must demonstrate a willing initiative to solicit customer requirements and translate them into formalized structured technical products. Candidate must have strong verbal and written communication skills. Concise writing and ability to communicate technical content to broad audiences are critical candidate abilities. \n  Candidate must be a US Citizen and be able to obtain and maintain a high-risk public trust clearance. \n  Must have experience or familiarity with: executing Agile, Scrum, and Kanban methodologies. Soliciting and documenting use cases and designs for system requirements (User Stories, Use Cases, Requirements, Specifications, Data Schema, Business Process Workflows). Use of system management tools such as Azure DevOps, Jira, Redmine, or similar system. Developing and executing testing and acceptance plans. Tracking bugs, issues and resolutions. Performing data analysis and reporting. Knowledge of government system security policies (ATO process) Ability to flexibly pivot to varying needs of the project while maintaining situational awareness \n \n \n  Preferred Qualifications \n    The preferred candidate will possess broader Systems Engineering knowledge and can readily execute low-level engineering tasks as well as high-level technical project management tasks. \n  The preferred candidate will have a MS in Systems Engineering or a related discipline. \n  Preferred candidates will have experience or familiarity with: \n  Knowledge of the Microsoft Azure ecosystem \n  Experience with Data Lakes and preferably Data Lakehouses \n  Experience working with federal IT systems \n  Experience working with SQL developers (or knowledge of SQL) \n  Prioritizing and communicating requirements and system development activities. ",
        "techs": [
            "system engineering",
            "software development",
            "business analysis",
            "agile",
            "scrum",
            "kanban methodologies",
            "azure devops",
            "jira",
            "redmine",
            "executing testing and acceptance plans",
            "tracking bugs",
            "issues and resolutions",
            "data analysis and reporting",
            "government system security policies",
            "ato process",
            "systems engineering",
            "ms in systems engineering",
            "microsoft azure ecosystem",
            "data lakes",
            "data lakehouses",
            "federal it systems",
            "sql developers",
            "sql"
        ],
        "cleaned_techs": [
            "system engineering",
            "software development",
            "business analysis",
            "agile",
            "scrum",
            "kanban methodologies",
            "azure",
            "jira",
            "redmine",
            "executing testing and acceptance plans",
            "tracking bugs",
            "issues and resolutions",
            "data analysis and reporting",
            "ato process",
            "systems engineering",
            "ms in systems engineering",
            "microsoft azure ecosystem",
            "data lakes",
            "data lakehouses",
            "federal it systems",
            "sql"
        ]
    },
    "a4278b8168a9614a": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 90.0,
        "salary_max": 100.0,
        "title": "Sr. Data Platform Engineer",
        "company": "Primary Talent Partners",
        "desc": "***********W2 Requirement - USC or GC required - NO C2C AT ALL************       Primary Talent Partners has 1 opening for a Lead Data Platform Engineer to join our client. This is a 6-month W2 contract opening, contract extensions are based on performance, budget, and business needs. \n \n Pay: $90-100/hr \n Duration: 6-month W2 contract, no sponsorship & no c2c \n Location: St. Louis, MO or Remote \n The Data Platform Engineering Lead will be responsible for managing a cross-functional Data Warehouse platform hosted in Google Cloud Platform.\n  \n  The platform itself is still experiencing a rapid growth of end-users / demand, so there will be a need to balance both operational/support needs in additional to delivery of new capital deliverables.\n  \n  The selected candidate should have significant experience in GCP, with specific focus around BigQuery, Logging, IAM, GKE, Cloud Functions, DataFlow, Cloud Composer Cross-Cloud architecture, and Shared VPC Networking. Outside of GCP, the Data Platform Engineering Lead must also have experience with standard DevOps practices, CICD pipelines, and operating in an Agile environment.\n  \n  In addition to the technical responsibilities, the ideal candidate must be able to operate as a Product Owner for the platform \u2013 managing Azure Dev Ops boards, Aha Roadmaps, backlogs and priorities.\n   Due to the high visibility of this platform, the selected candidate must have very strong communication skills and capable of presenting to large audiences varying from developers to senior leaders.\n  \n  The Data Platform Engineering Lead should embrace the challenge of dealing with new and complex problems, understanding how to apply technologies to solve those problems via innovative solutions.\n  \n \n Key Responsibilities include: \n \n Leading a team of senior data engineers to deliver new capabilities for the platform \n Managing product backlog & priorities \n Defining Acceptance criteria \n Collaborating with Delivery teams to provide re-usable pipelines \n Hands-on technical responsibilities to ensure the platform is stable and capable to deep-dive into complex, unexpected errors \n Defining & implementing cross-cloud architecture ( GCP, AWS, Azure ) \n \n What you\u2019ll need to be successful: \n \n Expertise in GCP services and evaluating technology for specific use-cases \n Experience building / managing CICD pipelines \n DevOps experience \n Expertise in Data Warehousing \n Experience with Infrastructure as Code, preferably Terraform \n Strong organizational skills, interpersonal skills, written and oral communication \n Ability to solve complex issues with re-usable frameworks \n Ability to quickly learn technologies such as Terraform, Kubernetes, Apache Beam, and Kafka \n \n Primary Talent Partners is an Equal Opportunity / Affirmative Action employer committed to diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, age, national origin, disability, protected veteran status, gender identity, or any other factor protected by applicable federal, state, or local laws. \n \n  #PTPJobs",
        "cleaned_desc": "  The platform itself is still experiencing a rapid growth of end-users / demand, so there will be a need to balance both operational/support needs in additional to delivery of new capital deliverables.\n  \n  The selected candidate should have significant experience in GCP, with specific focus around BigQuery, Logging, IAM, GKE, Cloud Functions, DataFlow, Cloud Composer Cross-Cloud architecture, and Shared VPC Networking. Outside of GCP, the Data Platform Engineering Lead must also have experience with standard DevOps practices, CICD pipelines, and operating in an Agile environment.\n  \n  In addition to the technical responsibilities, the ideal candidate must be able to operate as a Product Owner for the platform \u2013 managing Azure Dev Ops boards, Aha Roadmaps, backlogs and priorities.\n   Due to the high visibility of this platform, the selected candidate must have very strong communication skills and capable of presenting to large audiences varying from developers to senior leaders.\n    Expertise in GCP services and evaluating technology for specific use-cases \n Experience building / managing CICD pipelines \n DevOps experience \n Expertise in Data Warehousing \n Experience with Infrastructure as Code, preferably Terraform \n Strong organizational skills, interpersonal skills, written and oral communication \n Ability to solve complex issues with re-usable frameworks ",
        "techs": [
            "gcp",
            "bigquery",
            "logging",
            "iam",
            "gke",
            "cloud functions",
            "dataflow",
            "cloud composer",
            "cross-cloud architecture",
            "shared vpc networking",
            "devops practices",
            "cicd pipelines",
            "agile environment",
            "azure dev ops",
            "aha roadmaps",
            "data warehousing",
            "infrastructure as code",
            "terraform"
        ],
        "cleaned_techs": [
            "gcp",
            "bigquery",
            "logging",
            "iam",
            "gke",
            "cloud functions",
            "dataflow",
            "cloud composer",
            "cross-cloud architecture",
            "shared vpc networking",
            "devops practices",
            "cicd pipelines",
            "agile environment",
            "azure",
            "aha roadmaps",
            "data warehousing",
            "infrastructure as code",
            "terraform"
        ]
    },
    "530643730d36388a": {
        "terms": [
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 105363.79,
        "salary_max": 133414.03,
        "title": "Data Engineer - Contract Role",
        "company": "WorldWinner",
        "desc": "WorldWinner  is the most recognized and trusted skill games technology platform and brand for players who want to Play to Win. We bring games to the world that inspire people to play for more. With a content library spanning classic card games to casual favorites to retro arcade games, WorldWinner has something for every gamer. Backed by Platinum Equity and strategic investors, WorldWinner is headed into an exciting growth phase! \n \n \n  We are seeking a highly skilled and experienced Data Engineering contractor to join our dynamic team for a three (3) month contract period, with the opportunity to convert to a full-time role. The ideal candidate will have an extensive background in data integration, ETL processes, and database management, specifically with tools and platforms as mentioned below. This role will support our data analysts and in creating aggregate tables to enhance our reporting capabilities. \n \n \n  Key Projects: \n \n \n \n Create aggregate tables to enhance reporting capabilities \n Design and develop ETL processes \n Optimize existing databases \n Implement analytics dashboards  \n Support machine learning model deployment and integration project \n \n \n \n  Key Qualifications : \n \n \n \n Proven experience with ETL tools, preferably Airflow \n In-depth knowledge of Redshift and Postgres \n Hands-on experience with AWS QuickSight and AWS SageMaker \n Strong SQL skills and familiarity with other querying languages \n Experience in supporting Data Analysts or similar roles \n Understanding of data warehousing, data modeling, and data architecture principles \n Strong problem-solving skills and attention to detail \n \n \n \n  EQUAL EMPLOYMENT OPPORTUNITY \n  WorldWinner is an equal opportunity employer and does not discriminate against employees or applicants on the basis of race, color, national origin, gender, sex, sexual orientation, pregnancy, gender identity or expression, disability, religion, age, genetic information, veteran status or any other characteristic protected by federal, state or local law. We will make a reasonable accommodation to known physical or mental limitations of a qualified applicant or employee with a disability unless the accommodation would impose an undue hardship on our operation or direct threat safety to the individual or others in the work environment. We also participate in the E-Verify program, a service of DHS and SSA.",
        "cleaned_desc": " Hands-on experience with AWS QuickSight and AWS SageMaker \n Strong SQL skills and familiarity with other querying languages \n Experience in supporting Data Analysts or similar roles \n Understanding of data warehousing, data modeling, and data architecture principles \n Strong problem-solving skills and attention to detail \n ",
        "techs": [
            "aws quicksight",
            "aws sagemaker",
            "sql",
            "data warehousing",
            "data modeling",
            "data architecture"
        ],
        "cleaned_techs": [
            "aws",
            "sql",
            "data warehousing",
            "data architecture"
        ]
    },
    "296c9156e04898d3": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 109402.43,
        "salary_max": 138527.86,
        "title": "Software Engineer II, Data",
        "company": "RevaComm",
        "desc": "About Us \n  RVCM (RevaComm) is a leader in Agile Software Development, User-Centered Design, and DevSecOps. As an enterprise digital transformation company, we transform organizational challenges into powerful digital capabilities through fresh experiences and innovative technology. You'll bring unique user experiences to life through your knowledge and perspective here. The problems you will solve are as dynamic as our customers, ranging from the Department of Defense to financial institutions, healthcare, and even state and local agencies. \n  We are embracing the future of work. Make an impact  wherever you are . Home is where you connect with 'ohana (family), friends, and what makes you feel good. Working from home allows you to make a real impact and help bring out the best in one another. \n  We seek a Junior Data Engineer with data pipeline experience to join a team rapidly developing a data lake within a federal agency. The federal agency is looking at building a scalable and dynamic data lake to make data available from various parts of the enterprise for data-driven decisions. \n  What You'll Do Here \n \n  Partner with multiple teams and departments to develop tools and frameworks to extract, transform, and load data from a wide variety of sources into the data lake \n  Implement and enhance support tools for monitoring and acting on data pipeline issues \n  Design review and code review with peer engineers \n  Work closely with different application and system teams to identify valuable data and business use cases \n  Contribute to the overall strategy of maintaining and growing the data lake to help various constituents and stakeholders \n  Provide analysis and feedback on governance and value of data within the data lake platform \n  Build CI/CD pipelines \n  Work during Eastern Standard Time \n \n  What You'll Bring to the Team \n \n  BS in Computer Science/Engineering \n  ~2 years of experience as a Data Engineer or MS in Computer Science/Engineering \n  Strong Python and SQL skills \n  Development experience performing ETL/data pipeline implementations \n  Experience across modern cloud-based data ecosystems\n    \n  AWS and Snowflake experience are strongly preferred but not required \n \n  Strong understanding of distributed systems and Restful APIs \n  Experience working with Apache Druid, ElasticSearch, and Neo4j is a plus \n  Experience working with Cybersecurity log data is a plus \n  AWS and Snowflake certifications are a plus but not required \n \n  Join Our  ' Ohana \n  The 'ohana-oriented mindset is a significant pillar of RVCM's foundation. We wouldn't be here without each remarkable individual that has passed through our doors. No matter where we go in the world, it's essential that everyone under the RVCM roof, first and foremost, feel like they are ohana. \n  We believe in providing a safe space for all RVCM's 'ohana members to grow and thrive. Diversity, Equity, and Inclusion are at the heart of who we are, and everyone should feel valued and free to bring their most authentic self to work - without fear, without judgment, and in consideration of all backgrounds. Creating this environment is essential, not only for our organization but also for our customers and our communities. \n  In addition to an incredible culture, you will find several  benefits  to being part of the RevaComm's ohana, including: \n \n  Fully remote work within the U.S. \n  Company Provided Laptop & Charger Plus A Home Office Bonus: $1,000 upon hire; $500 per year thereafter to purchase any additional equipment to improve productivity at home \n  Comprehensive medical, dental, and vision insurance \n  401(k) with company match \n  Health Care and Dependent Care Savings Accounts \n  15 days of PTO \n  11 Paid Holidays \n  Full Paid Holiday Break (Last Week of the Year) \n  Continuous Education & Training \n  Mentor Programs \n \n  Relocation expenses are not covered.",
        "cleaned_desc": "  Work closely with different application and system teams to identify valuable data and business use cases \n  Contribute to the overall strategy of maintaining and growing the data lake to help various constituents and stakeholders \n  Provide analysis and feedback on governance and value of data within the data lake platform \n  Build CI/CD pipelines \n  Work during Eastern Standard Time \n \n  What You'll Bring to the Team \n \n  BS in Computer Science/Engineering    ~2 years of experience as a Data Engineer or MS in Computer Science/Engineering \n  Strong Python and SQL skills \n  Development experience performing ETL/data pipeline implementations \n  Experience across modern cloud-based data ecosystems\n    \n  AWS and Snowflake experience are strongly preferred but not required \n \n  Strong understanding of distributed systems and Restful APIs \n  Experience working with Apache Druid, ElasticSearch, and Neo4j is a plus ",
        "techs": [
            "ci/cd pipelines",
            "python",
            "sql",
            "etl",
            "aws",
            "snowflake",
            "distributed systems",
            "restful apis",
            "apache druid",
            "elasticsearch",
            "neo4j."
        ],
        "cleaned_techs": [
            "ci/cd pipelines",
            "python",
            "sql",
            "etl",
            "aws",
            "snowflake",
            "distributed systems",
            "restful apis",
            "apache druid",
            "elasticsearch",
            "neo4j."
        ]
    },
    "bda7b582763cd775": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 65.0,
        "salary_max": 95.0,
        "title": "Senior Developer - Data Engineer (AWS/Python/Node)",
        "company": "Intevity",
        "desc": "We are seeking a Senior Full Stack Developer with 7+ years of experience for our team. We need the candidate to have extensive experience inside the AWS stack with experience working with Node and Typescript. \n In this position, you will play a critical role in the success of our clients. We are an agile team of experienced developers and technologists defining the architecture, process, and implementation of critical operational systems for our clients. \n Because each client and their needs are different, you are comfortable wearing multiple hats and rolling up your sleeves when needed. You\u2019re a thinker AND a doer. When compared to others, you stand out as a star player who will do whatever it takes to get the job done\u2014no matter how big or small the job is. You lead by example as well as mentor/help others. \n Here\u2019s what you need: \n \n Minimum of 7 years of hands on experience in utilizing AWS services to design, develop, secure, and maintain data platforms \n Minimum of 5 years experience in enterprise level SDLC \n Minimum of 3 years of experience in Python (Node.js and Typescript is a plus) \n \n Assessment Criteria: \n \n Experience setting up AWS Data Platforms \u2013 CloudFormation/Terraform, AWS Glue, AWS Lambda, Amazon EMR, AWS RDS, QuickSight and Redshift, S3, and EC2. \n Track record of successfully building scalable Data Lake solutions that connects to distributed data storage using multiple data connectors. \n Track record of data engineering, ETL, data transmission and data security \n Proven skills in Python, SQL and the AWS ecosystem of tools. Typescript experience is a plus. \n Ability to lead proofs-of-concepts and then effectively transition and scale those concepts into production at scale through, engineering, deployment and commercialization. \n Serve as an expert; envision and integrate emerging data technologies, anticipate new trends to solve complex business and technical problems. \n Ability to communicate clearly in written and verbal forms with clients and other team members. \n \n Job Types: Full-time, Contract \n Pay: $65.00 - $95.00 per hour \n Expected hours: 40 per week \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n Vision insurance \n \n Compensation package: \n \n 1099 contract \n \n Experience level: \n \n 7 years \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Work Location: Remote",
        "cleaned_desc": " \n Assessment Criteria: \n \n Experience setting up AWS Data Platforms \u2013 CloudFormation/Terraform, AWS Glue, AWS Lambda, Amazon EMR, AWS RDS, QuickSight and Redshift, S3, and EC2. \n Track record of successfully building scalable Data Lake solutions that connects to distributed data storage using multiple data connectors. \n Track record of data engineering, ETL, data transmission and data security \n Proven skills in Python, SQL and the AWS ecosystem of tools. Typescript experience is a plus. \n Ability to lead proofs-of-concepts and then effectively transition and scale those concepts into production at scale through, engineering, deployment and commercialization. ",
        "techs": [
            "aws cloudformation",
            "terraform",
            "aws glue",
            "aws lambda",
            "amazon emr",
            "aws rds",
            "quicksight",
            "redshift",
            "s3",
            "ec2",
            "python",
            "sql",
            "typescript"
        ],
        "cleaned_techs": [
            "aws",
            "terraform",
            "quicksight",
            "redshift",
            "s3",
            "ec2",
            "python",
            "sql",
            "typescript"
        ]
    },
    "d204b938f054b0b9": {
        "terms": [
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 161761.98,
        "salary_max": 204826.73,
        "title": "Staff Software Engineer - Data Products",
        "company": "Discord",
        "desc": "The central Data Platform seeks to build a self-service tooling platform to make the petabytes of data at Discord easily accessible for everyone at the company. We build full-stack applications, tooling, and frameworks to improve the productivity of teams at Discord, in particular our product, analytics, and machine learning teams. Our tooling covers the end-to-end lifecycle of data from acquisition to consumption. Reporting to the Engineering Manager of Data Products, you will work on strategy that is foundational to the company and product. To learn more about Discord Engineering, read our  engineering blog here  \u2014 including  \"How We Create Insights From Trillion Data Points\"  that this team is behind! \n What you'll be doing \n \n Lead end-to-end development of data tooling and frameworks, using modern technologies such as BigQuery, Apache Beam, Airflow, Dagster, dbt, Kubernetes, and Rust. \n Ensure tight-knit collaboration with leadership, cross-functional stake-holders and senior engineers across the organizationCollaborate with leadership and senior engineers across the team to define the technical vision and build on the technical roadmap for Data Platform. \n Work with Data Platform to ensure we have a platform with strong governance that respects our users' privacy throughout. \n Care deeply about business outcomes and constraints and keep them in mind as you solve hard, unbounded problems. \n Work with other Staff Engineers to make decisions for the organization and engineering function as a whole. \n Coach and mentor the next generation of technical leaders at Discord. \n \n \n \n What you should have \n \n 7+ years of experience as a Software Engineer. \n Empathy for both your internal and external users and seek feedback on your work. \n Ability to approach problems with first principles thinking, embrace ambiguity, and enjoy collaborative work on complex solutions. \n Experience defining architecture, tooling, and strategy for a large-scale data processing system. \n Proactive in staying up-to-date with industry trends and assessing new technologies to enhanse problem solving capabilities. \n \n \n \n \n Bonus Points \n \n \n \n     Experience working with very high-scale data infrastructure and tooling\n       \n \n \n     Experience with data products on Google Cloud Platform, Kubernetes, or Airflow\n       \n \n \n     Full-stack development or product engineering experience\n       \n \n \n The US base salary range for this full-time position is $214,000 to $233,000 + equity + benefits. Our salary ranges are determined by role and level. Within the range, individual pay is determined by additional factors, including job-related skills, experience, and relevant education or training. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include equity, or benefits.    #buildbelonging #LI-Remote #LI-Hybrid #LI-HY1 \n \n \n  Benefits and Perks \n \n Comprehensive medical insurance including Health, Dental and Vision (plus up to $20,000 for gender affirmation procedures) \n Mental health resources and quarterly wellness stipends \n 14+ paid holidays, 4 weeks of PTO + use-what-you-need sick days \n Paid parental leave (plus fertility, adoption and other family planning benefits) \n Flexible long-term work options (remote and hybrid) \n Volunteer time off \n A diverse slate of Employee Resource Groups \n Plus commuter contributions and other perks for office-based employees \n \n About Us \n  Discord is a voice, video and text app that helps friends and communities come together to hang out and explore their interests \u2014 from artists and activists, to study groups, sneakerheads, plant parents, and more. With 150 million monthly users across 19 million active communities, called servers, Discord has grown to become one of the most popular communications services in the world. Discord was built without selling ads or user data and instead, offers a premium subscription called Nitro that gives users special perks like higher quality streams and fun customizations. \n  We're working toward an inclusive world where no one feels like an outsider, where genuine human connection is a click, text chat, or voice call away. A place where everyone can find belonging. Challenging? Heck yes. Rewarding? Double heck yes. It's a mission that gives us the chance to positively impact millions of people all over the world.  So if this strikes a chord with you, come build belonging with us!",
        "cleaned_desc": " \n Bonus Points \n \n \n \n     Experience working with very high-scale data infrastructure and tooling\n       \n \n \n     Experience with data products on Google Cloud Platform, Kubernetes, or Airflow\n       ",
        "techs": [
            "google cloud platform",
            "kubernetes",
            "airflow"
        ],
        "cleaned_techs": [
            "gcp",
            "kubernetes",
            "airflow"
        ]
    },
    "0a1b5ba4666e2bed": {
        "terms": [
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 106095.0,
        "salary_max": 134339.9,
        "title": "Data Conversion Engineer",
        "company": "InvoiceCloud",
        "desc": "About InvoiceCloud : \n  InvoiceCloud, an EngageSmart solution, is a leading provider of online bill payment services. Founded in 2009, the company has grown to be one of the leading disruptors in the cloud-based electronic bill presentment and payment (EBPP) space, helping institutions put customer experience first. By switching to InvoiceCloud, clients can improve customer engagement, loyalty, and efficiency while reducing churn and missed payments in the process. With over 50 million payments processed annually, InvoiceCloud is one of the most secure, innovative, and inclusive fintech solutions in the market. To learn more, visit www.InvoiceCloud.com. \n \n  As a Data Conversion Engineer on our integrations team, you will work to convert data for InvoiceCloud clients as they transition or upgrade their core processing system, ensuring their customers' online bill paying experience remains consistent and uninterrupted. You will be responsible for analyzing the source data, designing the target data format, extracting existing data, and performing the transform & load. You will be encouraged to develop automated scripts and tools to facilitate repeatable conversions where possible. \n  As a Data Conversion Engineer You Will: \n \n Understand how to write and troubleshoot complex SQL queries \n Understand ETL (Extract, Transform, and Load) processes and tools \n Create wikis for data conversion processes and tools \n Able to handle a fast-paced environment \n Able to multitask efficiently \n \n What We Seek: \n \n Bachelor's Degree preferred or equivalent combination of education and experience required \n 5 years of Experience using Microsoft Technologies including VB.NET, ASP.NET, C#, Visual Studio \n Proficiency with SQL Server and Microsoft ETL tools \n Machine learning and automation experience a plus \n Self-led, capable of working with little direction \n Skilled communicator with a collaborative spirit \n \n \n \n Benefits \n  We offer a competitive benefits program including: \n \n Medical, dental, vision, life & disability insurance \n 401(k) plan with company match & employee stock purchase plan (ESPP) \n Flexible Time Off (FTO), wellbeing days, paid holidays, and summer Fridays \n Mental health resources \n Paid parental leave & Backup Care \n Tuition reimbursement \n Employee Resource Groups (ERGs) \n \n Invoice Cloud is an Equal Opportunity Employer. \n  Invoice Cloud provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. \n  This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training. \n  If you have a disability under the Americans with Disabilities Act or similar law, or you require a religious accommodation, and you wish to discuss potential accommodations related to applying for employment at our company, please contact jobs@engagesmart.com. \n  Click here to review EngageSmart's Job Applicant Privacy Policy. \n  To all recruitment agencies:  Invoice Cloud does not accept agency resumes. Please do not forward resumes to our job's alias, employees, or any other organization location. Invoice Cloud is not responsible for any fees related to unsolicited resumes.",
        "cleaned_desc": " Bachelor's Degree preferred or equivalent combination of education and experience required \n 5 years of Experience using Microsoft Technologies including VB.NET, ASP.NET, C#, Visual Studio \n Proficiency with SQL Server and Microsoft ETL tools \n Machine learning and automation experience a plus \n Self-led, capable of working with little direction \n Skilled communicator with a collaborative spirit \n ",
        "techs": [
            "vb.net",
            "asp.net",
            "c#",
            "visual studio",
            "sql server",
            "microsoft etl tools"
        ],
        "cleaned_techs": [
            "vb.net",
            "asp.net",
            "c#",
            "visual studio",
            "sql",
            "microsoft etl tools"
        ]
    },
    "85714d51c7a8c220": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 126324.84,
        "salary_max": 159955.4,
        "title": "Senior Data Engineer",
        "company": "Hero Digital, LLC",
        "desc": "US, Remote \n     Location \n \n \n    Full Time \n     Type \n \n \n \n \n \n \n The Data Engineer role at Avionos, a Hero Digital Company is an integral member of our analytics team responsible for working with our clients to extract, integrate and transform their data to make it accessible and ready to be developed into visualizations using business intelligence tools. This role manages our cutting edge data stack, including FiveTran, Snowflake and Tableau to prepare fully integrated data sets that our visualization team can use to develop dashboards for internal and external clients. As a B2B demand generation agency, we have extensive marketing and sales performance data from many different platforms that must be joined together and normalized in order to develop always on, fresh data for our clients. This role also serves as a consultant to our clients to help enable their analytics team to leverage the data that our system provides to incorporate in their internal reporting. The Data Engineer works closely with our closed-loop system product team to design systems to get the data our clients need to fuel their business, and it works with the BI visual design team to build interactive dashboards for the internal and external execution teams. \n  The right candidate will be able to use our ETL tool and data warehouse (FiveTran and Snowflake) to aggregate all relevant data, and will possess advanced SQL skills to integrate data from multiple sources including Salesforce, Marketo, Pardot, Google Adwords, Bing, Facebook, LinkedIn and other media sources. Familiarity with the Salesforce data model is a major plus for this role, as are experience with media and web analytics platforms (especially Google products). Superior problem solving skills, impeccable attention to detail, and a passion for data are required traits for success in this role. \n  What you'll do \n \n Managing the data tech stack, including the ETL and data warehouse \n Setup and maintenance of data extraction and data collection processes \n Joining, blending and cleansing data using SQL (and related languages) \n Troubleshooting data. Finding points of failure in the data collection or sales process and working with the revenue operations team to implement solutions \n Analyzing client data to identify opportunities for improvement within the sales and marketing programs \n Developing innovative solutions to enable self-serve data cleansing, categorization and maintenance for our internal team and clients \n Consulting with clients to enable them to use our data sets and data models to support their internal BI teams \n \n Who you are \n \n Minimum of 2 years of data integration and data engineering experience \n Advanced SQL experience (R and Python are a plus) \n Familiarity with the Salesforce and marketing automation platform data models \n Deep experience working with relational databases \n BI platform experience, with working knowledge of Tableau Desktop and Tableau Online is a big plus \n Advanced analytics, critical thinking and problem solving skills \n Excellent interpersonal and communication skills \n Strong project management experience \n Keen interest in using data to drive business and marketing decisions for clients \n Acute attention to detail and rigor around your work \n Wants to be part of building an agency from the ground up with people who challenge you \n Enjoys working directly with clients, consulting them on opportunities to embrace a data driven culture \n \n \n \n  All qualified applicants will receive consideration for employment without regard to race, color, age, marital status, religion, sex, gender, gender identity, gender expression, sexual orientation, national origin, ancestry, medical condition, physical or mental disability, genetic information or military and veteran status \n  Who we are \n  We are a leading independent customer experience agency in North America that was born in California, at the intersection of business, design and technology. Our purpose is to bring moments of Truth & Beauty into people\u2019s lives by creating customer experiences that are good for people and good for business. We drive growth and loyalty through a relentless focus of placing our client\u2019s customers at the center of their business. Led by the experts in strategy, marketing, data, design, and technology, we work in blended teams, solving client problems and delivering results at market speed. These teams help Fortune 500 companies like Comcast, Oracle, Twitter, U.S. Bank, Salesforce, Sephora, UnitedHealthcare, and TD Ameritrade Institutional invent, transform, and perform to deliver new brand and business value. \n  Do you share the values that set our company apart?    We are expanding our team of humble and hardworking people who share the qualities we believe in. We seek those who are Wholehearted, Craft-driven, and Bright. \n  We are grounded in the values of who we are that ultimately lead to moments of Truth & Beauty. We celebrate leaders at all levels who take risks and create magic. We bring our complete, genuine, and whole-hearted selves forward each day. We are craft-driven in nature, with strong curiosities, but with a diligent and meticulous approach. And we bring an unexpected brightness through imagination, inspiration and an optimistic mindset. The commitment we make to our work is the source of our pride and the basis of our reputation. \n  Above all, Hero Digital is committed to creating an inclusive employee experience. One that reflects the world we live in today. We are an equal opportunity employer that welcomes people regardless of backgrounds, experiences, abilities, and perspectives.",
        "cleaned_desc": " \n \n \n The Data Engineer role at Avionos, a Hero Digital Company is an integral member of our analytics team responsible for working with our clients to extract, integrate and transform their data to make it accessible and ready to be developed into visualizations using business intelligence tools. This role manages our cutting edge data stack, including FiveTran, Snowflake and Tableau to prepare fully integrated data sets that our visualization team can use to develop dashboards for internal and external clients. As a B2B demand generation agency, we have extensive marketing and sales performance data from many different platforms that must be joined together and normalized in order to develop always on, fresh data for our clients. This role also serves as a consultant to our clients to help enable their analytics team to leverage the data that our system provides to incorporate in their internal reporting. The Data Engineer works closely with our closed-loop system product team to design systems to get the data our clients need to fuel their business, and it works with the BI visual design team to build interactive dashboards for the internal and external execution teams. \n  The right candidate will be able to use our ETL tool and data warehouse (FiveTran and Snowflake) to aggregate all relevant data, and will possess advanced SQL skills to integrate data from multiple sources including Salesforce, Marketo, Pardot, Google Adwords, Bing, Facebook, LinkedIn and other media sources. Familiarity with the Salesforce data model is a major plus for this role, as are experience with media and web analytics platforms (especially Google products). Superior problem solving skills, impeccable attention to detail, and a passion for data are required traits for success in this role. \n  What you'll do \n \n Managing the data tech stack, including the ETL and data warehouse \n Setup and maintenance of data extraction and data collection processes   Joining, blending and cleansing data using SQL (and related languages) \n Troubleshooting data. Finding points of failure in the data collection or sales process and working with the revenue operations team to implement solutions \n Analyzing client data to identify opportunities for improvement within the sales and marketing programs \n Developing innovative solutions to enable self-serve data cleansing, categorization and maintenance for our internal team and clients \n Consulting with clients to enable them to use our data sets and data models to support their internal BI teams \n \n Who you are \n \n Minimum of 2 years of data integration and data engineering experience   Advanced SQL experience (R and Python are a plus) \n Familiarity with the Salesforce and marketing automation platform data models \n Deep experience working with relational databases \n BI platform experience, with working knowledge of Tableau Desktop and Tableau Online is a big plus \n Advanced analytics, critical thinking and problem solving skills \n Excellent interpersonal and communication skills \n Strong project management experience \n Keen interest in using data to drive business and marketing decisions for clients \n Acute attention to detail and rigor around your work ",
        "techs": [
            "avionos",
            "hero digital",
            "fivetran",
            "snowflake",
            "tableau",
            "etl",
            "data warehouse",
            "salesforce",
            "marketo",
            "pardot",
            "google adwords",
            "bing",
            "facebook",
            "linkedin",
            "google products",
            "sql",
            "r",
            "python",
            "relational databases",
            "tableau desktop",
            "tableau online"
        ],
        "cleaned_techs": [
            "avionos",
            "hero digital",
            "fivetran",
            "snowflake",
            "tableau",
            "etl",
            "data warehouse",
            "salesforce",
            "marketo",
            "pardot",
            "google adwords",
            "bing",
            "facebook",
            "linkedin",
            "google products",
            "sql",
            "r",
            "python",
            "relational databases",
            "tableau desktop",
            "tableau online"
        ]
    },
    "438a072845b56b63": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 90000.0,
        "salary_max": 115000.0,
        "title": "Software Engineer - Archiving and Data Services",
        "company": "Internet Archive",
        "desc": "Interested in a mission-driven job ensuring perpetual open access to information for a global audience? Enjoy helping scale the use of services and products critical to hundreds of national and international non-profits, libraries, universities, cultural heritage institutions, and mission-driven organizations? If so, the Internet Archive is seeking a Software Engineer for our Archiving & Data Services team. \n  Internet Archive (IA) is a non-profit digital library, top 200 website at archive.org, and an archive of over 99 petabytes of digital information running in many self-owned and operated data centers. Internet Archive also provides mission-aligned services to thousands of organizations working collaboratively to advance our shared goal of \u201cUniversal Access to All Knowledge.\u201d The Archiving & Data Services group provides a suite of paid, SaaS, and free products, as well as community programs, focused on the archiving, management, analysis, and accessibility of digital information. Its services are used by over 1,500 organizations around the world. \n  We are looking for a motivated, detail-oriented Software Engineer to join our team. The role will focus on Archive-It (archive-it.org), our platform for building, sharing, and preserving web archive collections. This position offers the opportunity to work with a range of technologies and gain deep knowledge about web crawling, archival replay, and large-scale distributed systems. Our services work with petabytes of archived data and facilitate the discovery and use of large-scale digital collections. The Software Engineer will have the unique opportunity to build things that further open access to information and advance the public good. \n  Key Responsibilities: \n \n  Collaborate with team members to understand user needs, design new features, support web crawling and preservation, and improve the performance and reliability of Archive-It and other department products. \n \n \n     Implement, test, and maintain software across our stack (Python, Elasticsearch, Postgres, Temporal, HTML/CSS/JS/TS).\n    \n \n \n     Develop, monitor, and maintain the Archive-It partner application, where web crawls are configured, scheduled, and reported.\n    \n \n \n     Improve a distributed system orchestrating web crawls and post-processing them for long term preservation, indexing for retrieval, deduplication, and reporting.\n    \n \n \n     Participate in code reviews to ensure the quality and stability of our software and diffusion of knowledge across the team.\n    \n  Document architecture, software, and features for internal and external users. \n \n  Qualification and Skills: \n \n  Degree in Computer Science or a related field, or equivalent experience, strongly preferred. \n \n \n     Proficiency in Python, with familiarity in Postgres, Elasticsearch, and HTML/CSS/JS preferred.\n    \n \n \n     A strong understanding of web services and distributed systems.\n    \n \n \n     Excellent problem-solving skills, attention to detail, and ability to work both independently and collaboratively.\n    \n \n \n     Experience with web crawling, Django, workflow systems (e.g. Temporal, Airflow), distributed databases (e.g. Cassandra, Scylla), Hadoop, and Ansible are a plus\n    \n \n \n     GitLab, GitHub, Sentry, Grafana, JIRA, are other tools we use.\n    \n \n \n     Our independently operated data centers run Ubuntu Linux VMs and our department runs everything from the VM up, so Linux experience is preferred.\n    \n  An interest in the Internet Archive\u2019s mission to provide Universal Access to All Knowledge is expected. \n \n  Job Details: \n  Remote applicants preferred. We have headquarters in San Francisco and Vancouver and candidates in those locations will have the option for hybrid remote/in-office arrangements. Candidates will need to have some time overlap with primarily North America (and largely Pacific Time) based colleagues. Compensation and title will be commensurate with experience and the role is open to candidates of varying seniority with a general, but negotiable, salary range of $90,000 to $115,000 based on living in the San Francisco, CA region. Compensation may be adjusted based on the geographic location of the finalist. \n  Benefits & Perks: \n  The Internet Archive is a remote first workplace and provides a comprehensive benefits package including; PTO, paid holidays, and medical benefits. Depending on where you live, we also provide these additional benefits; dental, vision, health savings accounts, flex spending accounts, commuter benefits, short term disability, long term disability and retirement programs. \n  At the Internet Archive, we believe we do our best work when our employees bring together diverse ideas. Members of all groups under represented in the tech industry and library world are strongly encouraged to apply. We are proud to be an equal opportunity workplace and are committed to equal employment opportunity regardless of race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, genetic information, veteran status, gender identity or expression, sexual orientation, or any other characteristic protected by applicable federal, state or local law.",
        "cleaned_desc": "  Document architecture, software, and features for internal and external users. \n \n  Qualification and Skills: \n \n  Degree in Computer Science or a related field, or equivalent experience, strongly preferred. \n \n \n     Proficiency in Python, with familiarity in Postgres, Elasticsearch, and HTML/CSS/JS preferred.\n    \n \n       A strong understanding of web services and distributed systems.\n    \n \n \n     Excellent problem-solving skills, attention to detail, and ability to work both independently and collaboratively.\n    \n \n \n     Experience with web crawling, Django, workflow systems (e.g. Temporal, Airflow), distributed databases (e.g. Cassandra, Scylla), Hadoop, and Ansible are a plus\n    \n ",
        "techs": [
            "postgres",
            "elasticsearch",
            "html/css/js",
            "python",
            "web services",
            "distributed systems",
            "web crawling",
            "django",
            "workflow systems (e.g. temporal",
            "airflow)",
            "distributed databases (e.g. cassandra",
            "scylla)",
            "hadoop",
            "ansible"
        ],
        "cleaned_techs": [
            "postgres",
            "elasticsearch",
            "html/css/js",
            "python",
            "web services",
            "distributed systems",
            "web crawling",
            "django",
            "workflow systems (e.g. temporal",
            "airflow)",
            "distributed databases (e.g. cassandra",
            "scylla)",
            "hadoop",
            "ansible"
        ]
    },
    "227119efc149cadc": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 105408.0,
        "salary_max": 209352.0,
        "title": "Lead Data Engineer (Remote)",
        "company": "CareFirst BlueCross BlueShield",
        "desc": "Resp & Qualifications   \n PURPOSE:   The Lead Data Engineer is responsible for orchestrating, deploying, maintaining and scaling cloud OR on-premise infrastructure targeting big data and platform data management (Relational and NoSQL, distributed and converged) with emphasis on reliability, automation and performance. This role will focus on leading the development of solutions and helping transform the company's platforms deliver data-driven, meaningful insights and value to company.     ESSENTIAL FUNCTIONS: \n \n  Lead the team to design, configure, implement, monitor, and manage all aspects of Data Integration Framework. Defines and develop the Data Integration best practices for the data management environment of optimal performance and reliability. \n  Develops and maintains infrastructure systems (e.g., data warehouses, data lakes) including data access APIs. Prepares and manipulates data using Informatica, Snowflake, and Azure SQL. \n  Provides detailed guidance and performs work related to Modeling Data Warehouse solutions in the cloud OR on-premise. Understands Dimensional Modeling, De-normalized Data Structures, OLAP, and Data Warehousing concepts. \n  Oversees the delivery of engineering data initiatives and projects. Supports long term data initiatives as well as Ad-Hoc analysis and ELT/ETL activities. Creates data collection frameworks for structured and unstructured data. Applies data extraction, transformation and loading techniques in order to connect large data sets from a variety of sources. \n  Enforces the implementation of best practices for data auditing, scalability, reliability and application performance. Develop and apply data extraction, transformation and loading techniques in order to connect large data sets from a variety of sources. \n  Interprets data, analyzes results using statistical techniques, and provides ongoing reports. Executes quantitative analyses that translate data into actionable insights. Provides analytical and data-driven decision-making support for key projects. Designs, manages, and conducts quality control procedures for data sets using data from multiple systems. \n  Improves data delivery engineering job knowledge by attending educational workshops; reviewing professional publications; establishing personal networks; benchmarking state-of-the-art practices; participating in professional societies. \n \n  SUPERVISORY RESPONSIBILITY:  Position does not have direct reports but is expected to assist in guiding and mentoring less experienced staff. May lead a team of matrixed resources.     QUALIFICATIONS:     Education Level:  Bachelor's Degree in Computer Science, Information Technology or Engineering or related field OR in lieu of a Bachelor's degree, an additional 4 years of relevant work experience is required in addition to the required work experience.     Experience:  8 years Experience in leading data engineering and cross functional team to implement scalable and fine tuned ETL/ELT solutions for optimal performance. Experience developing and updating ETL/ELT scripts. Hands-on experience with application development, relational database layout, development, data modeling.     Knowledge, Skills and Abilities (KSAs) \n \n  Knowledge and understanding of Informatica including Cloud version (IICS). \n  Knowledge and understanding of Cloud Platforms (ie. Azure). \n  Knowledge and understanding of Cloud Databases (ie. Snowflake, Azure SQL). \n  Knowledge and understanding of at least one programming language (i.e., SQL, NoSQL, Python). \n  Knowledge and understanding of database design and implementation concepts. \n  Knowledge and understanding of data exchange formats. \n  Knowledge and understanding of data movement concepts. \n  Strong technical and analytical and problem solving skills to troubleshoot to solve a variety of problems. \n  Requires strong organizational and communication skills, written and verbal, with the ability to handle multiple priorities. \n  Able to effectively provide direction to and lead technical teams.  Must be able to meet established deadlines and handle multiple customer service demands from internal and external customers, within set expectations for service excellence. Must be able to effectively communicate and provide positive customer service to every internal and external customer, including customers who may be demanding or otherwise challenging. \n  \n   Salary Range:  $105,408 - $209,352   \n Salary Range Disclaimer   \n The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the work is being performed. This compensation range is specific and considers factors such as (but not limited to) the scope and responsibilites of the position, the candidate's work experience, education/training, internal peer equity, and market and business consideration. It is not typical for an individual to be hired at the top of the range, as compensation decisions depend on each case's facts and circumstances, including but not limited to experience, internal equity, and location. In addition to your compensation, CareFirst offers a comprehensive benefits package, various incentive programs/plans, and 401k contribution programs/plans (all benefits/incentives are subject to eligibility requirements). \n  Department   \n Department:  ODS/ETL Members \n  Equal Employment Opportunity   \n CareFirst BlueCross BlueShield is an Equal Opportunity (EEO) employer. It is the policy of the Company to provide equal employment opportunities to all qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, protected veteran or disabled status, or genetic information. \n  Where To Apply   \n Please visit our website to apply: www.carefirst.com/careers \n  Federal Disc/Physical Demand   \n Note: The incumbent is required to immediately disclose any debarment, exclusion, or other event that makes him/her ineligible to perform work directly or indirectly on Federal health care programs. \n  PHYSICAL DEMANDS: \n  The associate is primarily seated while performing the duties of the position. Occasional walking or standing is required. The hands are regularly used to write, type, key and handle or feel small controls and objects. The associate must frequently talk and hear. Weights up to 25 pounds are occasionally lifted. \n  Sponsorship in US   \n Must be eligible to work in the U.S. without Sponsorship \n  #LI-LD1",
        "cleaned_desc": "Resp & Qualifications   \n PURPOSE:   The Lead Data Engineer is responsible for orchestrating, deploying, maintaining and scaling cloud OR on-premise infrastructure targeting big data and platform data management (Relational and NoSQL, distributed and converged) with emphasis on reliability, automation and performance. This role will focus on leading the development of solutions and helping transform the company's platforms deliver data-driven, meaningful insights and value to company.     ESSENTIAL FUNCTIONS: \n \n  Lead the team to design, configure, implement, monitor, and manage all aspects of Data Integration Framework. Defines and develop the Data Integration best practices for the data management environment of optimal performance and reliability. \n  Develops and maintains infrastructure systems (e.g., data warehouses, data lakes) including data access APIs. Prepares and manipulates data using Informatica, Snowflake, and Azure SQL. \n  Provides detailed guidance and performs work related to Modeling Data Warehouse solutions in the cloud OR on-premise. Understands Dimensional Modeling, De-normalized Data Structures, OLAP, and Data Warehousing concepts. \n  Oversees the delivery of engineering data initiatives and projects. Supports long term data initiatives as well as Ad-Hoc analysis and ELT/ETL activities. Creates data collection frameworks for structured and unstructured data. Applies data extraction, transformation and loading techniques in order to connect large data sets from a variety of sources.    Enforces the implementation of best practices for data auditing, scalability, reliability and application performance. Develop and apply data extraction, transformation and loading techniques in order to connect large data sets from a variety of sources. \n  Interprets data, analyzes results using statistical techniques, and provides ongoing reports. Executes quantitative analyses that translate data into actionable insights. Provides analytical and data-driven decision-making support for key projects. Designs, manages, and conducts quality control procedures for data sets using data from multiple systems. \n  Improves data delivery engineering job knowledge by attending educational workshops; reviewing professional publications; establishing personal networks; benchmarking state-of-the-art practices; participating in professional societies. \n \n  SUPERVISORY RESPONSIBILITY:  Position does not have direct reports but is expected to assist in guiding and mentoring less experienced staff. May lead a team of matrixed resources.     QUALIFICATIONS:     Education Level:  Bachelor's Degree in Computer Science, Information Technology or Engineering or related field OR in lieu of a Bachelor's degree, an additional 4 years of relevant work experience is required in addition to the required work experience.     Experience:  8 years Experience in leading data engineering and cross functional team to implement scalable and fine tuned ETL/ELT solutions for optimal performance. Experience developing and updating ETL/ELT scripts. Hands-on experience with application development, relational database layout, development, data modeling.     Knowledge, Skills and Abilities (KSAs) \n \n  Knowledge and understanding of Informatica including Cloud version (IICS).    Knowledge and understanding of Cloud Platforms (ie. Azure). \n  Knowledge and understanding of Cloud Databases (ie. Snowflake, Azure SQL). \n  Knowledge and understanding of at least one programming language (i.e., SQL, NoSQL, Python). \n  Knowledge and understanding of database design and implementation concepts. \n  Knowledge and understanding of data exchange formats. \n  Knowledge and understanding of data movement concepts. \n  Strong technical and analytical and problem solving skills to troubleshoot to solve a variety of problems. ",
        "techs": [
            "informatica",
            "snowflake",
            "azure sql",
            "sql",
            "nosql",
            "python"
        ],
        "cleaned_techs": [
            "informatica",
            "snowflake",
            "azure",
            "sql",
            "nosql",
            "python"
        ]
    },
    "37b5edb36e885430": {
        "terms": [
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 105000.0,
        "title": "Lead Data Engineer",
        "company": "OpenEarth Foundation",
        "desc": "Lead Data Engineer: \n Building Climate Solutions for Cities \n Link to application: https://noteforms.com/forms/openearth-job-application-ctwllg \n Have you created a successful career in tech and are ready to do something good with your skills and experience? If yes, then join us in our Earthshot mission to build open source digital systems and solutions to battle environmental threats. \n Open Earth Foundation is a California-based research and deployment non-profit developing open innovative technology to increase planetary resilience and avoid a catastrophic climate crisis. \n We are building open infrastructure in support of the UNFCCC Paris Agreement, solutions in climate finance, biodiversity tracking, community empowerment and other critical problems and solutions. \n We are a diverse international team, working remotely with a network of collaborators and partners globally, from the United Nations to climate tech startups. \n We have funding and a team of experts focused on Earth systems and digital innovation. \n Your mission, should you choose to accept it: \n As a  lead data engineer , you will leverage your data and engineering expertise and analytical skills to build open digital infrastructure, with a particular focus on our newly launched CityCatalyst project. \n As a Lead Data Engineer you will provide leadership and hands-on data management in our climate accounting technology programs. Your work will cover climate data pipelines, infrastructure design and implementation, working on greenhouse gas data inventories from satellite imagery and diverse data sources, being part of a software production team and even interfacing with new AI and LLM tools for data harmonization. \n You will be part of the technical team and work directly with the Director of Open Technology. You will also work with a variety of team members in the organization from the Product Team and Community Manager. \n The position is remote and international candidates are welcome, but prefer those willing to work with time zones compatible with PST. We're working on the planet's problems and we need the planet's best people to fix them. \n The following requirements describe our ideal candidate. If you don't meet some of the requirements, you're encouraged to apply anyway. Let us know if there is something missing and how we can work together to make it up. \n Essential Functions and Specific Duties: \n \n Design, architect, build and maintain data pipeline systems \n Write code for importing and updating large datasets to relational database and search indexes \n Define and maintain database schemas and data file formats \n Collaborate with web developers on optimizing database schemas for APIs and Web applications \n Collaborate with a team of software engineering peers \n Mentor and guide more junior data engineering staff \n Define and maintain data management processes for the organization \n Work with product managers to develop schedules, estimate tasks, and define success criteria \n Collaborate with team members from other disciplines such as web development, design, product management, and devops \n Coordinate with Open Source contributors \n Coordinate with open standards community to define interoperability standards \n Actively participate in team building and culture development activities at Open Earth Foundation \n Other duties as assigned \n \n Required skills: \n \n Python programming focused on big data management \n PostgreSQL or other relational database \n Docker \n Kubernetes \n Git \n \n Optional skills that will make a candidate stand out: \n \n Generative AI and large language model (LLM) APIs and data applications \n GIS tools such as ESRI \n Amazon Web Services \n ElasticSearch \n Data pipeline tools, e.g. Pachyderm \n Experience with 100Gb or larger data sets \n Climate action data such as emissions, targets, and action plans \n Physical (lat, lon, alt) and political (city, state, country) geographical data \n Remote-sensing and satellite data \n RESTful Web APIs \n Engineering leadership \n Open Source project maintainership \n Machine learning, especially for anomaly detection, pattern recognition, clustering, time series analysis \n \n Qualifications: \n \n Bachelor\u2019s degree in computer science, electrical engineering, or equivalent technical or scientific degree, or equivalent on-the-job experience \n 5 years of experience in software development for data systems \n 3 shipped projects \n \n Interpersonal skills: \n \n Clear communicator with good verbal and written skills in English (additional languages a plus) \n Creative, flexible and efficient with a focus on details \n Capacity to work with team members and partners at all levels and across time zones in a highly collaborative and often remote environment. \n Ability to embrace new challenges, take ownership and initiative as a key team player. \n \n Compensation and benefits \n \n This position is full-time with compensation of $60,000-$105,000 /year, dependent on experience and location \n Open Earth offers unlimited paid time off, paid holidays and paid sick leave \n You will work remotely within a dynamic and international environment \n We celebrate our achievements during our annual team retreat \n \n OEF is an Equal Employment Opportunity Employer. We support diversity, equity and inclusion in teams, and believe people should align their work with their purpose. Join us if you love Earth. \n Please apply by submitting your resume AND a cover letter, it is your opportunity to highlight why you feel you would be a great addition to the team. \n We look forward to hearing from you! \n Open Earth Foundation seeks diverse applicants from underrepresented communities. If you would like to pursue this job opportunity but don\u2019t believe you meet all the requirements, please apply and note what\u2019s missing in your cover letter. Lead Data Engineer: \n Building Climate Solutions for Cities \n Link to application: https://noteforms.com/forms/openearth-job-application-ctwllg \n Have you created a successful career in tech and are ready to do something good with your skills and experience? If yes, then join us in our Earthshot mission to build open source digital systems and solutions to battle environmental threats. \n Open Earth Foundation is a California-based research and deployment non-profit developing open innovative technology to increase planetary resilience and avoid a catastrophic climate crisis. \n We are building open infrastructure in support of the UNFCCC Paris Agreement, solutions in climate finance, biodiversity tracking, community empowerment and other critical problems and solutions. \n We are a diverse international team, working remotely with a network of collaborators and partners globally, from the United Nations to climate tech startups. \n We have funding and a team of experts focused on Earth systems and digital innovation. \n Your mission, should you choose to accept it: \n As a  lead data engineer , you will leverage your data and engineering expertise and analytical skills to build open digital infrastructure, with a particular focus on our newly launched CityCatalyst project. \n As a Lead Data Engineer you will provide leadership and hands-on data management in our climate accounting technology programs. Your work will cover climate data pipelines, infrastructure design and implementation, working on greenhouse gas data inventories from satellite imagery and diverse data sources, being part of a software production team and even interfacing with new AI and LLM tools for data harmonization. \n You will be part of the technical team and work directly with the Director of Open Technology. You will also work with a variety of team members in the organization from the Product Team and Community Manager. \n The position is remote and international candidates are welcome, but prefer those willing to work with time zones compatible with PST. We're working on the planet's problems and we need the planet's best people to fix them. \n The following requirements describe our ideal candidate. If you don't meet some of the requirements, you're encouraged to apply anyway. Let us know if there is something missing and how we can work together to make it up. \n Essential Functions and Specific Duties: \n \n Design, architect, build and maintain data pipeline systems \n Write code for importing and updating large datasets to relational database and search indexes \n Define and maintain database schemas and data file formats \n Collaborate with web developers on optimizing database schemas for APIs and Web applications \n Collaborate with a team of software engineering peers \n Mentor and guide more junior data engineering staff \n Define and maintain data management processes for the organization \n Work with product managers to develop schedules, estimate tasks, and define success criteria \n Collaborate with team members from other disciplines such as web development, design, product management, and devops \n Coordinate with Open Source contributors \n Coordinate with open standards community to define interoperability standards \n Actively participate in team building and culture development activities at Open Earth Foundation \n Other duties as assigned \n \n Required skills: \n \n Python programming focused on big data management \n PostgreSQL or other relational database \n Docker \n Kubernetes \n Git \n \n Optional skills that will make a candidate stand out: \n \n Generative AI and large language model (LLM) APIs and data applications \n GIS tools such as ESRI \n Amazon Web Services \n ElasticSearch \n Data pipeline tools, e.g. Pachyderm \n Experience with 100Gb or larger data sets \n Climate action data such as emissions, targets, and action plans \n Physical (lat, lon, alt) and political (city, state, country) geographical data \n Remote-sensing and satellite data \n RESTful Web APIs \n Engineering leadership \n Open Source project maintainership \n Machine learning, especially for anomaly detection, pattern recognition, clustering, time series analysis \n \n Qualifications: \n \n Bachelor\u2019s degree in computer science, electrical engineering, or equivalent technical or scientific degree, or equivalent on-the-job experience \n 5 years of experience in software development for data systems \n 3 shipped projects \n \n Interpersonal skills: \n \n Clear communicator with good verbal and written skills in English (additional languages a plus) \n Creative, flexible and efficient with a focus on details \n Capacity to work with team members and partners at all levels and across time zones in a highly collaborative and often remote environment. \n Ability to embrace new challenges, take ownership and initiative as a key team player. \n \n Compensation and benefits \n \n This position is full-time with compensation of $60,000-$105,000 /year, dependent on experience and location \n Open Earth offers unlimited paid time off, paid holidays and paid sick leave \n You will work remotely within a dynamic and international environment \n We celebrate our achievements during our annual team retreat \n \n OEF is an Equal Employment Opportunity Employer. We support diversity, equity and inclusion in teams, and believe people should align their work with their purpose. Join us if you love Earth. \n Please apply by submitting your resume AND a cover letter, it is your opportunity to highlight why you feel you would be a great addition to the team. \n We look forward to hearing from you! \n Open Earth Foundation seeks diverse applicants from underrepresented communities. If you would like to pursue this job opportunity but don\u2019t believe you meet all the requirements, please apply and note what\u2019s missing in your cover letter. \n Job Type: Full-time \n Pay: $60,000.00 - $105,000.00 per year \n Benefits: \n \n 401(k) \n Dental insurance \n Flexible schedule \n Health insurance \n Paid time off \n Vision insurance \n \n Compensation package: \n \n Bonus opportunities \n Yearly pay \n \n Experience level: \n \n 3 years \n 4 years \n 5 years \n 6 years \n 7 years \n 8 years \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Experience: \n \n Informatica: 1 year (Preferred) \n SQL: 1 year (Preferred) \n Data warehouse: 1 year (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": "Lead Data Engineer: \n Building Climate Solutions for Cities \n Link to application: https://noteforms.com/forms/openearth-job-application-ctwllg \n Have you created a successful career in tech and are ready to do something good with your skills and experience? If yes, then join us in our Earthshot mission to build open source digital systems and solutions to battle environmental threats. \n Open Earth Foundation is a California-based research and deployment non-profit developing open innovative technology to increase planetary resilience and avoid a catastrophic climate crisis. \n We are building open infrastructure in support of the UNFCCC Paris Agreement, solutions in climate finance, biodiversity tracking, community empowerment and other critical problems and solutions. \n We are a diverse international team, working remotely with a network of collaborators and partners globally, from the United Nations to climate tech startups. \n We have funding and a team of experts focused on Earth systems and digital innovation. \n Your mission, should you choose to accept it: \n As a  lead data engineer , you will leverage your data and engineering expertise and analytical skills to build open digital infrastructure, with a particular focus on our newly launched CityCatalyst project. \n As a Lead Data Engineer you will provide leadership and hands-on data management in our climate accounting technology programs. Your work will cover climate data pipelines, infrastructure design and implementation, working on greenhouse gas data inventories from satellite imagery and diverse data sources, being part of a software production team and even interfacing with new AI and LLM tools for data harmonization. \n You will be part of the technical team and work directly with the Director of Open Technology. You will also work with a variety of team members in the organization from the Product Team and Community Manager. \n The position is remote and international candidates are welcome, but prefer those willing to work with time zones compatible with PST. We're working on the planet's problems and we need the planet's best people to fix them. \n The following requirements describe our ideal candidate. If you don't meet some of the requirements, you're encouraged to apply anyway. Let us know if there is something missing and how we can work together to make it up. \n Essential Functions and Specific Duties: \n \n Design, architect, build and maintain data pipeline systems \n Write code for importing and updating large datasets to relational database and search indexes \n Define and maintain database schemas and data file formats \n Collaborate with web developers on optimizing database schemas for APIs and Web applications \n Collaborate with a team of software engineering peers \n Mentor and guide more junior data engineering staff \n Define and maintain data management processes for the organization \n Work with product managers to develop schedules, estimate tasks, and define success criteria \n Collaborate with team members from other disciplines such as web development, design, product management, and devops \n Coordinate with Open Source contributors \n Coordinate with open standards community to define interoperability standards \n Actively participate in team building and culture development activities at Open Earth Foundation \n Other duties as assigned \n \n Required skills: \n \n Python programming focused on big data management \n PostgreSQL or other relational database \n Docker \n Kubernetes \n Git \n   We look forward to hearing from you! \n Open Earth Foundation seeks diverse applicants from underrepresented communities. If you would like to pursue this job opportunity but don\u2019t believe you meet all the requirements, please apply and note what\u2019s missing in your cover letter. Lead Data Engineer: \n Building Climate Solutions for Cities \n Link to application: https://noteforms.com/forms/openearth-job-application-ctwllg \n Have you created a successful career in tech and are ready to do something good with your skills and experience? If yes, then join us in our Earthshot mission to build open source digital systems and solutions to battle environmental threats. \n Open Earth Foundation is a California-based research and deployment non-profit developing open innovative technology to increase planetary resilience and avoid a catastrophic climate crisis. \n We are building open infrastructure in support of the UNFCCC Paris Agreement, solutions in climate finance, biodiversity tracking, community empowerment and other critical problems and solutions. \n We are a diverse international team, working remotely with a network of collaborators and partners globally, from the United Nations to climate tech startups. \n We have funding and a team of experts focused on Earth systems and digital innovation. \n Your mission, should you choose to accept it: \n As a  lead data engineer , you will leverage your data and engineering expertise and analytical skills to build open digital infrastructure, with a particular focus on our newly launched CityCatalyst project. \n As a Lead Data Engineer you will provide leadership and hands-on data management in our climate accounting technology programs. Your work will cover climate data pipelines, infrastructure design and implementation, working on greenhouse gas data inventories from satellite imagery and diverse data sources, being part of a software production team and even interfacing with new AI and LLM tools for data harmonization. \n You will be part of the technical team and work directly with the Director of Open Technology. You will also work with a variety of team members in the organization from the Product Team and Community Manager. \n The position is remote and international candidates are welcome, but prefer those willing to work with time zones compatible with PST. We're working on the planet's problems and we need the planet's best people to fix them. \n The following requirements describe our ideal candidate. If you don't meet some of the requirements, you're encouraged to apply anyway. Let us know if there is something missing and how we can work together to make it up. \n Essential Functions and Specific Duties: \n \n Design, architect, build and maintain data pipeline systems \n Write code for importing and updating large datasets to relational database and search indexes \n Define and maintain database schemas and data file formats \n Collaborate with web developers on optimizing database schemas for APIs and Web applications \n Collaborate with a team of software engineering peers \n Mentor and guide more junior data engineering staff \n Define and maintain data management processes for the organization \n Work with product managers to develop schedules, estimate tasks, and define success criteria \n Collaborate with team members from other disciplines such as web development, design, product management, and devops \n Coordinate with Open Source contributors \n Coordinate with open standards community to define interoperability standards \n Actively participate in team building and culture development activities at Open Earth Foundation \n Other duties as assigned \n \n Required skills: \n \n Python programming focused on big data management \n PostgreSQL or other relational database \n Docker \n Kubernetes \n Git   \n Optional skills that will make a candidate stand out: \n \n Generative AI and large language model (LLM) APIs and data applications \n GIS tools such as ESRI \n Amazon Web Services \n ElasticSearch \n Data pipeline tools, e.g. Pachyderm \n Experience with 100Gb or larger data sets \n Climate action data such as emissions, targets, and action plans \n Physical (lat, lon, alt) and political (city, state, country) geographical data \n Remote-sensing and satellite data \n RESTful Web APIs \n Engineering leadership \n Open Source project maintainership \n Machine learning, especially for anomaly detection, pattern recognition, clustering, time series analysis \n \n Qualifications: \n \n Bachelor\u2019s degree in computer science, electrical engineering, or equivalent technical or scientific degree, or equivalent on-the-job experience \n 5 years of experience in software development for data systems \n 3 shipped projects \n \n Interpersonal skills: \n \n Clear communicator with good verbal and written skills in English (additional languages a plus) \n Creative, flexible and efficient with a focus on details \n Capacity to work with team members and partners at all levels and across time zones in a highly collaborative and often remote environment. \n Ability to embrace new challenges, take ownership and initiative as a key team player. \n \n Compensation and benefits \n \n This position is full-time with compensation of $60,000-$105,000 /year, dependent on experience and location \n Open Earth offers unlimited paid time off, paid holidays and paid sick leave \n You will work remotely within a dynamic and international environment \n We celebrate our achievements during our annual team retreat \n \n OEF is an Equal Employment Opportunity Employer. We support diversity, equity and inclusion in teams, and believe people should align their work with their purpose. Join us if you love Earth. ",
        "techs": [
            "postgresql",
            "docker",
            "kubernetes",
            "git",
            "esri",
            "amazon web services",
            "elasticsearch",
            "pachyderm",
            "restful web apis"
        ],
        "cleaned_techs": [
            "postgresql",
            "docker",
            "kubernetes",
            "git",
            "esri",
            "aws",
            "elasticsearch",
            "pachyderm",
            "restful web apis"
        ]
    },
    "a4031cd344d4043a": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 145000.0,
        "salary_max": 185000.0,
        "title": "Data Engineer",
        "company": "CyberCoders",
        "desc": "Data Engineer \n  \n Job Title:  Senior Data Engineer\n   \n Remote:  Yes, 100% Remote\n   \n Job Type:  Direct Hire\n   \n Hours:  Full-Time\n   \n Base Salary Range:  $140-185k (base) / year\n   \n \n Given the clients work with government contracts, you must be an active US Citizen to apply. You will need to obtain a security clearance after hire, but do not need to have one currently. US CITIZENSHIP REQUIRED is for all Government Clearance. Thank you. \n \n  Our team is looking for an experienced Senior Data Engineer to join us in working on top secret DOD cleared projects. Ideally someone with experience in time series and sensor data collecting with the ability to program in Python or R. We are building out a new data engineering team and this role would support our existing 4 data scientists in their efforts by building data pipelines, shaping data, etl, etc.\n  \n  What You Need for this Position \n \n Data Engineering / Cloud Engineering / Database Management Experience \n Incredible SQL Skills (MySQL / SQLite / Oracle) \n Programming experience (Python or R) \n \n \n  Bonus Point For: \n \n \n Sensor Data / Imaging Data / Time Series Data \n IOT  \n Azure Gov / AWS \n Government Clearance \n \n  What's In It for You \n \n Generous Base Salary \n 401k (+match) \n Flexible Remote Schedule \n Health / Dental / Vision \n Vacation / PTO \n 14 Paid holidays + Holiday break around new year / end of year \n \n \n   So, if you are a Data Engineer with experience, please apply today!\n  \n \n   Colorado employees will receive paid sick leave. For additional information about available benefits, please contact Hanna Frauen\n  \n \n Applicants must be authorized to work in the U.S. \n  CyberCoders is proud to be an Equal Opportunity Employer \n \n  All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.\n  \n \n Your Right to Work  \u2013 In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.",
        "cleaned_desc": " Incredible SQL Skills (MySQL / SQLite / Oracle) \n Programming experience (Python or R) \n \n \n  Bonus Point For: \n \n \n Sensor Data / Imaging Data / Time Series Data \n IOT  \n Azure Gov / AWS ",
        "techs": [
            "sql skills (mysql",
            "sqlite",
            "oracle)",
            "python",
            "r",
            "sensor data",
            "imaging data",
            "time series data",
            "iot",
            "azure gov",
            "aws"
        ],
        "cleaned_techs": [
            "sqlite",
            "oracle",
            "python",
            "r",
            "sensor data",
            "imaging data",
            "time series data",
            "iot",
            "azure",
            "aws"
        ]
    },
    "c94f3dc0dad47001": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 114575.45,
        "salary_max": 145078.05,
        "title": "Data Engineer",
        "company": "ALTA IT Services",
        "desc": "Data Engineer Work Location: Fully remote \u2013 East Coast candidates preferred. Clearance: Must be able to obtain a Public Trust clearance. As a Data Engineer, you\u2019ll work with AI team members to operationalize data pipelines and ML tasks, with the goal to make an impact across the federal government. What you\u2019ll do: Provide day-to-day support for deploying Python-native ML pipelines and perform data engineering tasks to enable AI/ML capabilities. Present results to a diverse audience in presentation or report form. Support architectural leadership, technical support, and advisement services to ensure identity management system technologies are integrated and meeting the appropriate security requirements Support leadership who engage with senior-level executives at a public-facing Federal agency and provide subject matter expertise in security architecture and other key domain areas. What you\u2019ll need to succeed: More than eight (8) years of experience in Data/ML engineering. If school experience is used, at most that would contribute to 2 years of actual experience. Experience with ETL, Data Labeling, and Data Prep. Experience designing, implementing, and maintaining data architecture and services to be used for AI/ML. Additionally, operationalizing and maintaining AI/ML models in production. The ability to perform data analytics on program-related or system-related activities. This will include assessing performance and manual processes and implementing methods/algorithms to automate/optimize. A bachelor\u2019s degree in Computer Science, Information Technology Management or Engineering, or other comparable degree or experience. The ability to obtain and maintain DHS Suitability. For immediate consideration, please apply directly or contact Crystal Dinnocenti @ Cdinnocenti@altaits.com \n \n \n Data Engineer \n   \n \n Work Location : Fully remote \u2013 East Coast candidates preferred.\n    \n \n Clearance:  Must be able to obtain a Public Trust clearance. \n  \n  As a \n  Data Engineer , you\u2019ll work with AI team members to operationalize data pipelines and ML tasks, with the goal to make an impact across the federal government. \n  \n What you\u2019ll do: \n \n Provide day-to-day support for deploying Python-native ML pipelines and perform data engineering tasks to enable AI/ML capabilities. \n Present results to a diverse audience in presentation or report form. \n Support architectural leadership, technical support, and advisement services to ensure identity management system technologies are integrated and meeting the appropriate security requirements \n Support leadership who engage with senior-level executives at a public-facing Federal agency and provide subject matter expertise in security architecture and other key domain areas. \n \n What you\u2019ll need to succeed: \n \n More than eight (8) years of experience in Data/ML engineering. If school experience is used, at most that would contribute to 2 years of actual experience. \n Experience with ETL, Data Labeling, and Data Prep. \n Experience designing, implementing, and maintaining data architecture and services to be used for AI/ML. Additionally, operationalizing and maintaining AI/ML models in production. \n The ability to perform data analytics on program-related or system-related activities. This will include assessing performance and manual processes and implementing methods/algorithms to automate/optimize. \n A bachelor\u2019s degree in Computer Science, Information Technology Management or Engineering, or other comparable degree or experience. \n The ability to obtain and maintain DHS Suitability. \n \n \n For immediate consideration, please apply directly or contact Crystal Dinnocenti @ Cdinnocenti@altaits.com \n \n \n  BA",
        "cleaned_desc": "Data Engineer Work Location: Fully remote \u2013 East Coast candidates preferred. Clearance: Must be able to obtain a Public Trust clearance. As a Data Engineer, you\u2019ll work with AI team members to operationalize data pipelines and ML tasks, with the goal to make an impact across the federal government. What you\u2019ll do: Provide day-to-day support for deploying Python-native ML pipelines and perform data engineering tasks to enable AI/ML capabilities. Present results to a diverse audience in presentation or report form. Support architectural leadership, technical support, and advisement services to ensure identity management system technologies are integrated and meeting the appropriate security requirements Support leadership who engage with senior-level executives at a public-facing Federal agency and provide subject matter expertise in security architecture and other key domain areas. What you\u2019ll need to succeed: More than eight (8) years of experience in Data/ML engineering. If school experience is used, at most that would contribute to 2 years of actual experience. Experience with ETL, Data Labeling, and Data Prep. Experience designing, implementing, and maintaining data architecture and services to be used for AI/ML. Additionally, operationalizing and maintaining AI/ML models in production. The ability to perform data analytics on program-related or system-related activities. This will include assessing performance and manual processes and implementing methods/algorithms to automate/optimize. A bachelor\u2019s degree in Computer Science, Information Technology Management or Engineering, or other comparable degree or experience. The ability to obtain and maintain DHS Suitability. For immediate consideration, please apply directly or contact Crystal Dinnocenti @ Cdinnocenti@altaits.com \n \n \n Data Engineer \n   \n   Experience with ETL, Data Labeling, and Data Prep. \n Experience designing, implementing, and maintaining data architecture and services to be used for AI/ML. Additionally, operationalizing and maintaining AI/ML models in production. \n The ability to perform data analytics on program-related or system-related activities. This will include assessing performance and manual processes and implementing methods/algorithms to automate/optimize. \n A bachelor\u2019s degree in Computer Science, Information Technology Management or Engineering, or other comparable degree or experience. \n The ability to obtain and maintain DHS Suitability. \n ",
        "techs": [
            "etl",
            "data labeling",
            "data prep",
            "data architecture",
            "ai/ml models",
            "data analytics"
        ],
        "cleaned_techs": [
            "etl",
            "data labeling",
            "data prep",
            "data architecture",
            "ai",
            "data analytics"
        ]
    },
    "8449b6591142bd4e": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 163554.11,
        "salary_max": 207095.95,
        "title": "Senior Data Engineer",
        "company": "Atlassian",
        "desc": "Overview: \n   Atlassian is looking for a Senior Data Engineer to join our Data Engineering Team. You will build top-notch data solutions and applications that inspire important decisions across the organization. You will be reporting to the Senior Data Engineering Manager. \n  You'll have flexibility in where you work \u2013 whether in an office, from home (remote), or a combination of the two. \n Compensation \n  At Atlassian, we strive to design equitable, explainable, and competitive compensation programs. To support this goal, the baseline of our range is higher than that of the typical market range, but in turn we expect to hire most candidates near this baseline. Base pay within the range is ultimately determined by a candidate's skills, expertise, or experience. In the United States, we have three geographic pay zones. For this role, our current base pay ranges for new hires in each zone are: \n Zone A: $176,200 - $234,900 \n  Zone B: $158,600 - $211,500 \n  Zone C: $146,300 - $195,000 \n  This role may also be eligible for benefits, bonuses, commissions, and equity. \n Please visit go.atlassian.com/payzones for more information on which locations are included in each of our geographic pay zones. However, please confirm the zone for your specific location with your recruiter.  Responsibilities: \n   A typical day may involve collaborating with partners, you will design data models, acquisition processes, and applications to address needs. With experience in large-scale data processing systems (batch and streaming), you will lead business growth and enhance product experiences. And will collaborate with Technology Teams, Global Analytical Teams, and Data Scientists across programs. \n  You'll take ownership of problems from end-to-end: extracting/cleaning data, and understanding generating systems. Improving the quality of data by adding sources, coding rules, and producing metrics is crucial as requirements evolve. Agility and smart risk-taking are important qualities in this industry where digital innovation meets partner/customer needs over time. \n  Qualifications: \n   On your first day, we'll expect you to have: \n \n  BS in Computer Science or equivalent experience with 5+ years as Data Engineer or similar role \n  Programming skills in Python & Java (good to have) \n  Design data models for storage and retrieval to meet product and requirements \n  Build scalable data pipelines using Spark, Airflow, AWS data services (Redshift, Athena, EMR), Apache projects (Spark, Flink, Hive, and Kafka) \n  Familiar with modern software development practices (Agile, TDD, CICD) applied to data engineering \n  Enhance data quality through internal tools/frameworks detecting DQ issues. Working knowledge of relational databases and SQL query authoring \n \n  We\u2019d be super excited if you have: \n \n  Followed a Kappa architecture with any of your previous deployments and domain knowledge of Financial and People System",
        "cleaned_desc": "  Programming skills in Python & Java (good to have) \n  Design data models for storage and retrieval to meet product and requirements \n  Build scalable data pipelines using Spark, Airflow, AWS data services (Redshift, Athena, EMR), Apache projects (Spark, Flink, Hive, and Kafka) \n  Familiar with modern software development practices (Agile, TDD, CICD) applied to data engineering ",
        "techs": [
            "python",
            "java",
            "spark",
            "airflow",
            "redshift",
            "athena",
            "emr",
            "hive",
            "kafka",
            "agile",
            "tdd",
            "cicd"
        ],
        "cleaned_techs": [
            "python",
            "java",
            "spark",
            "airflow",
            "redshift",
            "athena",
            "emr",
            "hive",
            "kafka",
            "agile",
            "tdd",
            "cicd"
        ]
    },
    "0164b1c4c3fd1aed": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 147500.0,
        "salary_max": 195000.0,
        "title": "Senior Data Engineer",
        "company": "Circle",
        "desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  As a member of the Data Engineering - Business ETL team, you own the ETL/ELT pipelines and data warehouse that is used for financial and regulatory reporting. Your work powers Circle business functions, including the Compliance, Finance, Accounting, and Analytics teams for experimentation, operational excellence, and actionable insights, so as to fuel and accelerate business growth. High integrity to data accuracy and quality is crucial. Your work will directly impact Circle's transparency, trust, and accountability needs. \n  What you'll work on: \n \n Collaborating with business teams on the design, deployment and continuous improvement of the scalable data platform that ingests, stores, and aggregates various datasets, including data pipelines, platforms, and warehouses, and surfacing data to both internal and customer-facing applications. \n Being a domain expert on data modeling, data pipelines, data quality and data warehousing. \n Designing, building and maintaining data ETL/ELT pipelines to source and aggregate the required data for various data analyses and reporting needs, as well as to continually improve the operations, monitoring and performance of the data warehouse. \n Developing integrations with third party systems to source, qualify and ingest various datasets. \n Providing data analytics and visualization tools to extract valuable insights from the data to enable data-driven decisions. \n Working closely with across groups, such as the product, engineering, data science, compliance, and security teams, for data modeling, general management of data life cycle, data governance and processes for meeting regulatory and legal requirements. \n \n You will aspire to our four core values: \n \n Multistakeholder - you have dedication and commitment to our customers, shareholders, employees and families and local communities. \n Mindful - you seek to be respectful, an active listener and to pay attention to detail. \n Driven by Excellence - you are driven by our mission and our passion for customer success which means you relentlessly pursue excellence, that you do not tolerate mediocrity and you work intensely to achieve your goals. \n High Integrity - you seek open and honest communication, and you hold yourself to very high moral and ethical standards. You reject manipulation, dishonesty and intolerance. \n \n What you'll bring to Circle: \n  For Senior Data Engineer (III) \n \n 4+ years of professional data engineering experience. \n Proficient in one or more programming languages (Java, Scala, Python). \n Advanced experience in SQL in big data warehouse systems such as Snowflake, BigQuery, Databricks, etc. \n Experience in SQL and NoSQL, such as MySQL, PostgreSQL, Cassandra, HBase, Redis, DynamoDB, Neo4j, etc. \n Experience with workflow orchestration management engines such as Airflow, Dagster, DBT, etc \n Experience with Cloud Services (AWS, Google Cloud, Microsoft Azure, etc). \n Experience in building scalable infrastructure to support batch, micro-batch or stream data processing for large volumes of data. \n Experience with financial or compliance data, bonus if in similar business domains, such as payment systems, credit cards, bank transfers, blockchains, etc. \n Experience in data provenance and governance. \n Internal knowledge of open source or related big data technologies. \n Ability to tackle complex and ambiguous problems. \n Self-starter who takes ownership, gets results, and enjoys moving at a fast pace. \n Excellent communication skills, able to collaborate with across remote teams, share ideas and present concepts effectively. \n \n For Staff Data Engineer (IV) \n  All the requirements of above and: \n \n 7+ years of professional data engineering experience. \n Led teams (>5) technically on architecture and system design. \n Expert in one of the domains of ETL/ELT pipelines, feature engineering, data modeling and architecture, or data ingestion. \n Experience working autonomously and able to identify large impactful projects to pursue with minimal guidance. \n Deep understanding/experience with: \n \n Data warehouse architecture and design \n Integration of the data stack to other tools/services \n Extensive knowledge with implementing data quality checks \n \n \n Additional Information: \n \n This position is eligible for day-one PERM sponsorship for qualified candidates. \n \n Circle is on a mission to create an inclusive financial future, with transparency at our core. We consider a wide variety of elements when crafting our compensation ranges and total compensation packages. \n  Starting pay is determined by various factors, including but not limited to: relevant experience, skill set, qualifications, and other business and organizational needs. Please note that compensation ranges may differ for candidates in other locations. \n  Senior Data Engineer (III) \n  Base Pay Range: $147,500 - $195,000 \n  Annual Bonus Target: 12.5% \n  Staff Data Engineer (IV) \n  Base Pay Range: $172,500 - $227,500 \n  Annual Bonus Target: 15% \n  Also Included: Equity & Benefits (including medical, dental, vision and 401(k)). Circle has a discretionary vacation policy. We also provide 10 days of paid sick leave per year and 11 paid holidays per year in the U.S. \n \n  We are an  equal opportunity employer  and value diversity at Circle. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Additionally, Circle participates in the  E-Verify Program  in certain locations, as required by law. \n  #LI-Remote",
        "cleaned_desc": "Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data \u2014 globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure \u2013 including USDC, a blockchain-based dollar \u2013 helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. \n  What you'll be part of: \n  Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: Multistakeholder, Mindfulness, Driven by Excellence and High Integrity. Circlers are consistently evolving in a remote world where strength in numbers fuels team success. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. \n \n  What you'll be responsible for: \n  As a member of the Data Engineering - Business ETL team, you own the ETL/ELT pipelines and data warehouse that is used for financial and regulatory reporting. Your work powers Circle business functions, including the Compliance, Finance, Accounting, and Analytics teams for experimentation, operational excellence, and actionable insights, so as to fuel and accelerate business growth. High integrity to data accuracy and quality is crucial. Your work will directly impact Circle's transparency, trust, and accountability needs. \n  What you'll work on: \n \n Collaborating with business teams on the design, deployment and continuous improvement of the scalable data platform that ingests, stores, and aggregates various datasets, including data pipelines, platforms, and warehouses, and surfacing data to both internal and customer-facing applications. \n Being a domain expert on data modeling, data pipelines, data quality and data warehousing. \n Designing, building and maintaining data ETL/ELT pipelines to source and aggregate the required data for various data analyses and reporting needs, as well as to continually improve the operations, monitoring and performance of the data warehouse. \n Developing integrations with third party systems to source, qualify and ingest various datasets. \n Providing data analytics and visualization tools to extract valuable insights from the data to enable data-driven decisions.   Proficient in one or more programming languages (Java, Scala, Python). \n Advanced experience in SQL in big data warehouse systems such as Snowflake, BigQuery, Databricks, etc. \n Experience in SQL and NoSQL, such as MySQL, PostgreSQL, Cassandra, HBase, Redis, DynamoDB, Neo4j, etc. \n Experience with workflow orchestration management engines such as Airflow, Dagster, DBT, etc \n Experience with Cloud Services (AWS, Google Cloud, Microsoft Azure, etc). \n Experience in building scalable infrastructure to support batch, micro-batch or stream data processing for large volumes of data. \n Experience with financial or compliance data, bonus if in similar business domains, such as payment systems, credit cards, bank transfers, blockchains, etc. \n Experience in data provenance and governance. \n Internal knowledge of open source or related big data technologies. \n Ability to tackle complex and ambiguous problems. \n Self-starter who takes ownership, gets results, and enjoys moving at a fast pace. \n Excellent communication skills, able to collaborate with across remote teams, share ideas and present concepts effectively. \n   For Staff Data Engineer (IV) \n  All the requirements of above and: \n \n 7+ years of professional data engineering experience. \n Led teams (>5) technically on architecture and system design. \n Expert in one of the domains of ETL/ELT pipelines, feature engineering, data modeling and architecture, or data ingestion. \n Experience working autonomously and able to identify large impactful projects to pursue with minimal guidance. \n Deep understanding/experience with: \n \n Data warehouse architecture and design \n Integration of the data stack to other tools/services \n Extensive knowledge with implementing data quality checks \n ",
        "techs": [
            "circle",
            "usdc",
            "blockchain-based dollar",
            "etl/elt pipelines",
            "data warehouse",
            "compliance",
            "finance",
            "accounting",
            "analytics",
            "data platform",
            "data pipelines",
            "data quality",
            "data warehousing",
            "data etl/elt",
            "third party systems",
            "data analytics",
            "visualization tools",
            "programming languages (java",
            "scala",
            "python)",
            "sql",
            "big data warehouse systems (snowflake",
            "bigquery",
            "databricks)",
            "sql and nosql databases (mysql",
            "postgresql",
            "cassandra",
            "hbase",
            "redis",
            "dynamodb",
            "neo4j)",
            "workflow orchestration management engines (airflow",
            "dagster",
            "dbt)",
            "cloud services (aws",
            "google cloud",
            "microsoft azure)",
            "batch processing",
            "micro-batch processing",
            "stream data processing",
            "financial data",
            "compliance data",
            "data provenance",
            "governance",
            "open source",
            "big data technologies",
            "complex problem-solving",
            "communication skills",
            "staff data engineer",
            "architecture and system design",
            "etl/elt pipelines",
            "feature engineering",
            "data modeling and architecture",
            "data ingestion",
            "data warehouse architecture and design",
            "integration of the data stack",
            "data quality checks."
        ],
        "cleaned_techs": [
            "circle",
            "usdc",
            "blockchain-based dollar",
            "etl/elt pipelines",
            "data warehouse",
            "compliance",
            "finance",
            "accounting",
            "data platform",
            "data pipelines",
            "data quality",
            "data warehousing",
            "data etl/elt",
            "third party systems",
            "data analytics",
            "visualization tools",
            "programming languages (java",
            "scala",
            "python",
            "sql",
            "big data warehouse systems (snowflake",
            "bigquery",
            "databricks)",
            "postgresql",
            "cassandra",
            "hbase",
            "redis",
            "dynamodb",
            "neo4j)",
            "workflow orchestration management engines (airflow",
            "dagster",
            "dbt)",
            "cloud services (aws",
            "gcp",
            "microsoft azure)",
            "batch processing",
            "micro-batch processing",
            "stream data processing",
            "financial data",
            "compliance data",
            "data provenance",
            "governance",
            "open source",
            "big data technologies",
            "complex problem-solving",
            "staff data engineer",
            "architecture and system design",
            "feature engineering",
            "data modeling and architecture",
            "data ingestion",
            "data warehouse architecture and design",
            "integration of the data stack",
            "data quality checks."
        ]
    },
    "d1cebe139c961a73": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 50.0,
        "salary_max": 60.0,
        "title": "Senior Data Integration Engineer",
        "company": "The Judge Group",
        "desc": "Contract Length:   6+ months (potential to convert) \n \n  Location:  Fully Remote \n \n  Pay Rate:   Negotiable \n  Passionate about energy efficiency? Join us as an Implementation Engineer! Work with utility partners, integrating data into our company's platform, and customizing applications for their needs. Collaborate with cross-functional teams, utilize MySQL and Unix tools, and automate tasks using Ruby or Python. Ideal for those with database knowledge, UNIX command proficiency, and a desire to learn. Fully Remote Opportunity. Report to Director of Implementation Engineering. Enjoy 401k, unlimited PTO, and career development opportunities. \n  Responsibilities:  \n \n Work with utility project teams on data integrations and energy efficiency product implementations \n  Explain technical specifications of company data integration and products - including highlighting risks with customer experience when requirements are not met \n  Analyze, transform, and load utility-provided data to meet company data requirements for a successful delivery of downstream end-user communications and web experiences \n  Develop new or maintain tooling (in ruby or python) to make our data integration and product implementations more cost & time effective \n  Configure and customize the company's energy efficiency SaaS platform to meet the specific needs of each client \n  Develop a deep understanding of our products with the ability to explain them to others with non-technical backgrounds \n  Improve our ability to customize and deliver energy efficiency products to our customers by optimizing delivery processes and writing useful documentation \n \n \n  Must Haves:  \n \n 5+ years experience with SQL, Unix (file search and manipulation, ETL, Git, and some coding \n  Experience writing effective SQL or Hive queries to analyze large relational datasets \n  Experience performing advanced file searches and text manipulation using the Unix/Linux command-line \n  Comfortable working directly with client teams \n  Experience writing software tools using object-oriented programming \n  You understand code versioning concepts and have experience with tools like git \n  Can connect dots among different pieces of information gained from multiple sources \n  Experience troubleshooting software applications that involve APIs, databases, and frontend \n  Can effectively prioritize multiple tasks at one time \n  Enjoy being part of a team, helping and learning from others. \n  Have 5+ years of professional experience. We are open to hiring at different levels too if there?s a better fit.",
        "cleaned_desc": "  Passionate about energy efficiency? Join us as an Implementation Engineer! Work with utility partners, integrating data into our company's platform, and customizing applications for their needs. Collaborate with cross-functional teams, utilize MySQL and Unix tools, and automate tasks using Ruby or Python. Ideal for those with database knowledge, UNIX command proficiency, and a desire to learn. Fully Remote Opportunity. Report to Director of Implementation Engineering. Enjoy 401k, unlimited PTO, and career development opportunities. \n  Responsibilities:  \n \n Work with utility project teams on data integrations and energy efficiency product implementations \n  Explain technical specifications of company data integration and products - including highlighting risks with customer experience when requirements are not met    Experience writing effective SQL or Hive queries to analyze large relational datasets \n  Experience performing advanced file searches and text manipulation using the Unix/Linux command-line \n  Comfortable working directly with client teams \n  Experience writing software tools using object-oriented programming \n  You understand code versioning concepts and have experience with tools like git ",
        "techs": [
            "mysql",
            "unix",
            "ruby",
            "python",
            "sql",
            "hive",
            "unix/linux",
            "git"
        ],
        "cleaned_techs": [
            "mysql",
            "unix",
            "ruby",
            "python",
            "sql",
            "hive",
            "unix/linux",
            "git"
        ]
    },
    "2faf0871a03fa628": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 144351.11,
        "salary_max": 182780.67,
        "title": "Machine Learning Engineer - Search Relevance",
        "company": "Objective, Inc.",
        "desc": "About Kailua Labs \n  Kailua Labs is a seed stage startup building a search platform that unlocks next-generation search and enrichment on your images, text and video through one simple SaaS API. Our mission is to make content in every application accessible the way people already think and talk about it. \n  We are backed by Matrix Partners, Two Sigma Ventures, Firsthand Ventures, StartX and former execs in top tech companies like Apple, AirBnB, Oracle, LinkedIn, and more, as well as researchers from MIT and Google X. Our founders are ex-Apple engineers with deep experience shipping ML and search systems to hundreds of millions of users across the globe and we have an incredibly talented founding team of ex-Apple, Google and Amazon engineers. We are moving quickly and are passionate about providing a magical experience for our growing customer base. \n  The Role \n  We are hiring a Machine Learning Engineer for Search Relevance. You will be responsible for ensuring that our system provides the highest quality search results in the industry for all our customers, demos and application areas. You will devise evaluation strategies, build evaluation sets, run benchmarks, ensure quality monitoring is in place, and set the agenda / prioritization for where to focus our quality iterations. You will be empowered to model & prototype solutions and will either get them implemented in production or work with one of our other ML engineers and Applied Scientists to make sure it gets implemented at the highest standard of quality. You have exceptional attention to detail, love finding the root cause problems for things. You understand the arguments for Data Centric ML and are excited by the latest developments in LLMs, pre-training, fine-tuning, instruction-tuning and in-context learning. \n  Who you are \n \n You love to learn and look for ways to learn at an accelerated pace \n You are compassionate and help others around you \n You can quickly hit the ground running, map out challenges and opportunities and develop a plan to improve things in the short and long term \n You have strong ownership of any task that you take on, driving it to success whether or not you've done it before \n You can cut through ambiguity and deliver amazing results even when there isn't a lot of guidance \n You are always looking for better ways of doing things, trying out new tools and processes \n You form meaningful relationships wherever you go: people respect and like you because you value them \n You seek continuous feedback from those around you and are willing to share feedback across all levels of the company \n \n Requirements & Skills \n \n Experience with deep learning, LLMs, and Transformers \n Tech stack: PyTorch, Python, and Pandas \n Experience in search and recommendations is welcome but not required \n Preferred Masters in Computer Science, Data Science, Machine Learning, or related field \n \n Benefits \n \n Competitive salary and equity. \n Platinum-level health, dental, and vision insurance for you and your family. We cover 99% of employee premiums and 95% of dependent premiums. \n Flexible Work - remote or in-person. We have a flexible work environment - work remotely from any U.S. timezone, or join us in-person at our San Francisco office. \n Unlimited PTO - take time when you need it to rest, relax, and recharge with unlimited PTO (minimum 4 weeks encouraged). \n Team events. Distributed work is awesome, but so is getting together in-person. Hang out with your colleagues at planned team events around the country. \n Brand new MacBook Pro (or PC if you prefer) \n \n Don't meet every single requirement? Studies have shown that women and people of color are less likely to apply to jobs unless they meet every single qualification. At Kailua Labs we are dedicated to building a diverse, inclusive and authentic workplace, so if you're excited about this role but your past experience doesn't align perfectly with every qualification in the job description, we encourage you to apply anyways. You may be just the right candidate for this or other roles. \n  Kailua Labs  provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.",
        "cleaned_desc": " Experience with deep learning, LLMs, and Transformers \n Tech stack: PyTorch, Python, and Pandas \n Experience in search and recommendations is welcome but not required \n Preferred Masters in Computer Science, Data Science, Machine Learning, or related field \n \n Benefits ",
        "techs": [
            "deep learning",
            "llms",
            "transformers",
            "pytorch",
            "python",
            "pandas"
        ],
        "cleaned_techs": [
            "llm",
            "transformers",
            "pytorch",
            "python",
            "pandas"
        ]
    },
    "69fdad765f9de0ce": {
        "terms": [
            "machine learning engineer",
            "mlops"
        ],
        "salary_min": 120808.62,
        "salary_max": 152970.62,
        "title": "Senior Machine Learning Ops Engineer \u2013 Customer Growth Marketing",
        "company": "Dell Technologies",
        "desc": "Senior Machine Learning Ops Engineer \u2013 Customer Growth Marketing \n  The B2B Customer Growth Marketing team within Dell Field & Partner Marketing is on a mission to transform marketing through the adoption of customer-centric solutions driven by Generative AI, machine-learning, Big Data, and world-class engineering. Working very tightly with Field Marketing and Sales stakeholders, we enable for the right message to get to the right customer at the right time through their omni-channel journey at massive scale. \n  What you'll achieve \n  As a Senior MLOps Engineer on a growing team, you will bring in your industry experience to manage the machine-learning lifecycle at scale using DevOps best practices as a foundation. You will collaborate with our ML Engineering, Data Engineering, and IT teams to support the technical roadmap and world-class engineering practices. \n  Take the first step toward your dream career  \n Every Dell Technologies team member brings something unique to the table. Here\u2019s what we are looking for with this role: \n  Essential Requirements \n \n  Solid industry experience in software-engineering or infrastructure engineering in enterprise-scale environments \n  Solid industry experience supporting CI/CD systems for continuous testing and deployment of machine learning models or scalable software/services \n  Experience with automation, monitoring, logging, and troubleshooting in production \n  Experience with containerization, such as Docker or Kubernetes \n \n  Desired Requirements  \n \n Bachelor\u2019s Degree in Computer Science, Engineering, Information Technology, or equivalent professional experience \n  Experience with the Python programming language \n \n  Who we are \n  We believe that each of us has the power to make an impact. That\u2019s why we put our team members at the center of everything we do. If you\u2019re looking for an opportunity to grow your career with some of the best minds and most advanced tech in the industry, we\u2019re looking for you. \n  Dell Technologies is a unique family of businesses that helps individuals and organizations transform how they work, live and play. Join us to build a future that works for everyone because Progress Takes All of Us. \n  Application closing date: September 30th \n  Dell Technologies is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment.",
        "cleaned_desc": "  Solid industry experience in software-engineering or infrastructure engineering in enterprise-scale environments \n  Solid industry experience supporting CI/CD systems for continuous testing and deployment of machine learning models or scalable software/services \n  Experience with automation, monitoring, logging, and troubleshooting in production \n  Experience with containerization, such as Docker or Kubernetes ",
        "techs": [
            "docker",
            "kubernetes"
        ],
        "cleaned_techs": [
            "docker",
            "kubernetes"
        ]
    },
    "d8f24508b2e7c1b0": {
        "terms": [
            "machine learning engineer",
            "mlops"
        ],
        "salary_min": 100000.0,
        "salary_max": 180000.0,
        "title": "Senior Computer Vision Engineer",
        "company": "Kibsi",
        "desc": "We\u2019re Kibsi and we\u2019re unleashing the future of vision-enabled applications. Our cloud-native, low-code platform democratizes computer vision, allowing customers to focus on their business needs, not the complexity. \n  We're currently looking for a Senior Computer Vision Engineer to help us design and build Kibsi. You\u2019ll be working with a team of designers, engineers, and CV experts responsible for creating our fully integrated environment designed for building computer vision applications.     \n What you bring to the table: \n \n Expertise with Python development and relevant machine learning and analytical libraries \n Experience with popular deep machine learning frameworks, such as TensorFlow, PyTorch, or ONNX Runtime \n Industry experience working with and deploying computer vision models for object detection, tracking, key point detection, segmentation, and classification \n Experience with video streaming technologies, including at the edge and in the cloud \n Experience with real-time video processing and model execution \n Experience with MLOps tools and workflows \n Experience designing and implementing traditional machine learning and neural network classifiers \n Experience setting up and managing (non-production) Linux systems for CV use cases \n 2-3 years of professional work experience creating and deploying computer vision models \n Great written and verbal communication skills \n Motivated and a self-starter with the ability to work autonomously and collaboratively within a team \n An analytical and thoughtful mind with the desire to help shape the requirements of a quickly evolving product \n Passionate to learn new things, whether it's a language, framework or brand-new concept \n \n What you'll get: \n \n Competitive pay:  We provide a highly competitive salary and bonus, and generous equity packages. \n Awesome benefits:  We offer top-notch health, dental, and vision coverage with market-leading employer contributions for you and your dependents, an FSA, a 401k with a match, and a generous parental leave policy to help take care of you and the ones you love. \n Unlimited vacation:  We provide unlimited time off, so you can take that much-needed vacation or random day whenever you need it. \n Flexible environment:  We give you the freedom to work wherever you want and are flexible about when you work. We even pay a phone and home office stipend. \n Fun atmosphere:  We like to bond and have fun outside of the office too, that\u2019s why we throw regular happy hours, team buildings and outings, & more! \n Tools for the job:  We let you choose your own equipment and get access to the materials, training, and the certifications you need to help us build the future. \n Random perks:  We want you to feel loved. That\u2019s why we offer random free lunches, goodies, lots of surprise swag delivered to your door & more!",
        "cleaned_desc": " Experience with popular deep machine learning frameworks, such as TensorFlow, PyTorch, or ONNX Runtime \n Industry experience working with and deploying computer vision models for object detection, tracking, key point detection, segmentation, and classification \n Experience with video streaming technologies, including at the edge and in the cloud \n Experience with real-time video processing and model execution \n Experience with MLOps tools and workflows   Experience designing and implementing traditional machine learning and neural network classifiers \n Experience setting up and managing (non-production) Linux systems for CV use cases \n 2-3 years of professional work experience creating and deploying computer vision models \n Great written and verbal communication skills \n Motivated and a self-starter with the ability to work autonomously and collaboratively within a team ",
        "techs": [
            "tensorflow",
            "pytorch",
            "onnx runtime",
            "computer vision models",
            "object detection",
            "tracking",
            "key point detection",
            "segmentation",
            "classification",
            "video streaming technologies",
            "real-time video processing",
            "mlops tools",
            "traditional machine learning",
            "neural network classifiers",
            "linux systems for cv use cases",
            "2-3 years of professional work experience",
            "written and verbal communication skills."
        ],
        "cleaned_techs": [
            "tensorflow",
            "pytorch",
            "onnx runtime",
            "computer vision models",
            "object detection",
            "tracking",
            "key point detection",
            "segmentation",
            "classification",
            "video streaming technologies",
            "real-time video processing",
            "mlops tools",
            "traditional machine learning",
            "neural network classifiers",
            "linux systems for cv use cases",
            "2-3 years of professional work experience"
        ]
    },
    "eccaeecb08ac448d": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Full Stack Engineer",
        "company": "Thrivent",
        "desc": "At Thrivent, we are focused on a digital transformation that will deliver modern, innovative experiences for our clients, financial advisors, and employees. We are investing in data and technology, using DevOps practices, and building an engineering culture of empowered technical experts. Our technologists are involved in work that includes cloud native development, digital architecture and integration, automation, cloud data platforms, artificial intelligence, and machine learning as well as maximizing platforms such as Salesforce, AWS and Microsoft. \n  \n  As a Full Stack Engineer on the Purchase Experience team, you will work on full-stack engineering with technologies including TypeScript, ReactJS, CSS, Java, Spring Boot, MongoDB/DynamoDB/SQL, Kafka, OpenShift, Azure, AWS and Git. You must have experience in building delightful user interfaces using ReactJS. You must also have experience in building scalable RESTful APIs in Java using Spring Boot. You must have knowledge about application security patterns ( OAuth 2.0/SAML), mobile-responsive web design and accessibility standards. You should be able to contribute to different aspects of the test strategy adopted for our applications. Your experience with continuous integration and continuous deployment pipelines, using infrastructure-as-a-code tooling, observability and monitoring tools will enable you in this role. \n  \n  As an Engineer you will create and/or modify solutions to complex software problems. This includes coding, testing, debugging, documenting, and maintaining those solutions. You will participate in leading smaller engineering efforts as well as contributing to larger, enterprise-wide initiatives. The Engineering teams are challenged to partner across departments and divisions to achieve the best outcomes for our customers. \n  DUTIES & RESPONSIBILITIES:  \n Designing Solutions  \n \n Apply technical knowledge to drive outcomes for customers  \n Ability to work and problem solve independently on initiatives that align to the broader software engineering strategy  \n Proficient at designing solutions within core framework of software products within this team  \n Participate in low level design for the product area / within the team.  \n \n Designing Software  \n \n Use independent, critical thinking to solve complex problems which are significant to the customer.  \n Work with a variety of technologies including TypeScript, ReactJS, CSS, Java, Spring Boot, MongoDB/DynamoDB/SQL, Kafka, OpenShift, Azure, AWS  \n Develop front-end user interfaces using ReactJS.  \n Develop scalable Java REST APIs using Spring Boot  \n Writing effective unit tests  \n Manage source code with Git.  \n Create and Use Continuous Integration/Continuous Deployment pipelines.  \n Use observability and monitoring tools.  \n Provision resources using infrastructure-as-code tooling, such as Terraform.  \n Member of team that can work independently, as well as collaboratively with team, in developing core software for the product that delivers outcomes.  \n Consistent and dependable in delivering core software that delivers outcomes and meets/exceeds the teams expectations for stability, scalability, resilience, etc.  \n \n Learning and Applying New Techniques  \n \n Seek out opportunities to learn new technologies that improve the product and its lifecycle.  \n \n Collaborating within the Team  \n \n Participate in team\u2019s collaboration sessions to provide technical expertise to solve a problem/remove technical roadblocks for the team  \n Participate in product planning and implementation. Helps team to understand and decompose work \"  \n \n DevOps  \n \n Participates in the team support rotation and builds knowledge on focus subsystems.\"  \n \n Coaching Engineers  \n \n Provide technical expertise and help the team to solve technical/software issues  \n Provide trainings to the junior developers and groom them\"  \n \n Recruiting/Building Talent  \n \n Participate in the interview process or be part of the panel to recruit the right talent to the team  \n Models Thrivent\u2019s leadership competencies \u2013 courage, collaboration, and commitment by demonstrating resiliency, working together to make the best decisions, and holding yourself and others accountable.  \n Supports and/or develops an environment in which Thrivent employees and colleagues are focused on continuous improvement, exceptional employee engagement, and an unwavering commitment to our clients. Shapes and/or supports a culture that represents the Thrivent purpose, promise and values, ensuring that Thrivent\u2019s trust and reputation remain strong with its clients.  \n Perform other related duties as required.  \n \n QUALIFICATIONS & SKILLS:  \n Required:  \n \n Bachelor's degree in Computer Science or other technical field or equivalent work experience  \n 3 to 5 years of Engineering experience  \n Sound knowledge of Software Development Life Cycle (SDLC)  \n Knowledge of industry standard Software Development Life Cycle (SDLC) practices  \n Knowledge of systems design concepts that provide security and stability  \n Deep knowledge of Operating Systems and/or Application Development Platforms  \n Ability to debug code and/or complex log files for troubleshooting and analysis of product defects  \n Sound understanding of application engineering concepts  \n Knowledge/experience with querying databases for data lookup/update  \n \n Preferred:  \n \n Financial Services industry experience  \n Coach / mentor other team members as appropriate  \n \n Thrivent provides Equal Employment Opportunity (EEO) without regard to race, religion, color,  sex, gender identity, sexual orientation, pregnancy, national origin, age, disability, marital status, citizenship status, military or veteran status, genetic information, or any other status protected by applicable local, state, or federal law. This policy applies to all employees and job applicants.  \n Thrivent is committed to providing reasonable accommodation to individuals with disabilities. If you need a reasonable accommodation, please let us know by sending an email to  human.resources@thrivent.com  or call 800-847-4836 and request Human Resources.",
        "cleaned_desc": "At Thrivent, we are focused on a digital transformation that will deliver modern, innovative experiences for our clients, financial advisors, and employees. We are investing in data and technology, using DevOps practices, and building an engineering culture of empowered technical experts. Our technologists are involved in work that includes cloud native development, digital architecture and integration, automation, cloud data platforms, artificial intelligence, and machine learning as well as maximizing platforms such as Salesforce, AWS and Microsoft. \n  \n  As a Full Stack Engineer on the Purchase Experience team, you will work on full-stack engineering with technologies including TypeScript, ReactJS, CSS, Java, Spring Boot, MongoDB/DynamoDB/SQL, Kafka, OpenShift, Azure, AWS and Git. You must have experience in building delightful user interfaces using ReactJS. You must also have experience in building scalable RESTful APIs in Java using Spring Boot. You must have knowledge about application security patterns ( OAuth 2.0/SAML), mobile-responsive web design and accessibility standards. You should be able to contribute to different aspects of the test strategy adopted for our applications. Your experience with continuous integration and continuous deployment pipelines, using infrastructure-as-a-code tooling, observability and monitoring tools will enable you in this role. \n  \n  As an Engineer you will create and/or modify solutions to complex software problems. This includes coding, testing, debugging, documenting, and maintaining those solutions. You will participate in leading smaller engineering efforts as well as contributing to larger, enterprise-wide initiatives. The Engineering teams are challenged to partner across departments and divisions to achieve the best outcomes for our customers. \n  DUTIES & RESPONSIBILITIES:  \n Designing Solutions  \n \n Apply technical knowledge to drive outcomes for customers  \n Ability to work and problem solve independently on initiatives that align to the broader software engineering strategy  \n Proficient at designing solutions within core framework of software products within this team  \n Participate in low level design for the product area / within the team.  \n \n Designing Software    \n Use independent, critical thinking to solve complex problems which are significant to the customer.  \n Work with a variety of technologies including TypeScript, ReactJS, CSS, Java, Spring Boot, MongoDB/DynamoDB/SQL, Kafka, OpenShift, Azure, AWS  \n Develop front-end user interfaces using ReactJS.  \n Develop scalable Java REST APIs using Spring Boot  \n Writing effective unit tests  \n Manage source code with Git.  \n Create and Use Continuous Integration/Continuous Deployment pipelines.  \n Use observability and monitoring tools.  \n Provision resources using infrastructure-as-code tooling, such as Terraform.  \n Member of team that can work independently, as well as collaboratively with team, in developing core software for the product that delivers outcomes.  \n Consistent and dependable in delivering core software that delivers outcomes and meets/exceeds the teams expectations for stability, scalability, resilience, etc.  \n \n Learning and Applying New Techniques    3 to 5 years of Engineering experience  \n Sound knowledge of Software Development Life Cycle (SDLC)  \n Knowledge of industry standard Software Development Life Cycle (SDLC) practices  \n Knowledge of systems design concepts that provide security and stability  \n Deep knowledge of Operating Systems and/or Application Development Platforms  \n Ability to debug code and/or complex log files for troubleshooting and analysis of product defects  \n Sound understanding of application engineering concepts  \n Knowledge/experience with querying databases for data lookup/update  \n \n Preferred:  \n \n Financial Services industry experience  \n Coach / mentor other team members as appropriate  \n ",
        "techs": [
            "typescript",
            "reactjs",
            "css",
            "java",
            "spring boot",
            "mongodb",
            "dynamodb",
            "sql",
            "kafka",
            "openshift",
            "azure",
            "aws",
            "git",
            "oauth 2.0/saml",
            "terraform"
        ],
        "cleaned_techs": [
            "typescript",
            "reactjs",
            "css",
            "java",
            "spring boot",
            "mongodb",
            "dynamodb",
            "sql",
            "kafka",
            "openshift",
            "azure",
            "aws",
            "git",
            "oauth 2.0/saml",
            "terraform"
        ]
    },
    "f54aef3fd7cddb23": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 173000.0,
        "salary_max": 197000.0,
        "title": "Lead Product Manager, Technology",
        "company": "Zappos.com",
        "desc": "Welcome! You made it to the job description page!\n  \n \n \n   At Zappos, we look for people who will show up as their whole self because we value diversity and inclusion, as well as people who enjoy fun and maybe even a little weirdness. So be sure to check on whether you\u2019re aligned with our company values and culture. If you think you can see yourself delivering WOW as a member of the Zappos family, then check out the job description below!\n  \n \n   Company Culture is at Our Core\n  \n \n \n   Our \n   \n   10 Core Values\n    are more than just words, they're a way of life. We know that companies with a strong culture & a higher purpose perform better in the long run.\n    Do our values speak to you?\n  \n \n   1. Deliver WOW Through Service\n    2. Embrace and Drive Change\n    3. Create Fun and A Little Weirdness\n    4. Be Adventurous, Creative, and Open-Minded\n    5. Pursue Growth and Learning\n    6. Build Open and Honest Relationships With Communication\n    7. Build a Positive Team and Family Spirit\n    8. Do More With Less\n    9. Be Passionate and Determined\n    10. Be Humble\n  \n \n \n   Company Perks: Quick Reference\n  \n \n \n \n     Zappos pays 100% of every employee\u2019s medical, dental, and vision benefits.\n    \n \n \n     Zappos pays 100% of 12 therapy, mental health, or coaching session annually.\n    \n \n \n     A multitude of benefits and incentives to stay mentally and physically healthy and fit.\n    \n \n \n     Meaningful assistance programs like professional development, mentoring, and 401k with employer contribution.\n    \n \n \n     Paid time off for life, vacations, staycations, and rest.\n    \n \n \n     A generous Zapponian discount program.\n    \n \n \n     Make an impact through volunteer adventures and other community programs.\n    \n \n \n     Want to have some fun, too? Yes, please! Enjoy team building, family spirit, and plenty of room to recharge!\n    \n \n \n   Zapponian [noun| employee of Zappos]. You are self-motivated. You think like an entrepreneur, constantly innovating and driving positive change, but more importantly, you consistently deliver mind-boggling results.\n  \n \n \n   Bold [adjective| not afraid of anything]. A role at Zappos is an opportunity to be a part of something different. To go bold. We\u2019re a company that isn\u2019t afraid to take risks and question the status quo. Oh yeah, we like to have fun too.\n  \n \n \n   Perks [noun| the good stuff you get for working hard]. Zappos pays 100% of your medical, dental and vision premiums. Primary care visits, dental exams, eye exams and generic prescriptions are all free. Plus matching 401k, life coaches, orthodontic benefits, and more. And don\u2019t forget, an unlimited 40% Zappos.com discount.\n  \n \n \n   1990s [noun| a decade we love, but no longer live in]. Old school cover letters are so 1990. Want to show us who you really are? Create a video cover letter. A flash mob, a comedic monologue\u2026 whatever showcases your passion for Zappos and the work you\u2019d be doing! Videos are not required, but if you create it, we\u2019ll watch it.\n  \n \n \n   Scout [noun| you're a recruiter, too]. As a Zapponian, we\u2019ll ask that you always keep your eye out for great talent to join our family. Consider yourself an extension of the recruiting team, scouting for the best people to grow our company.\n  \n \n \n \n    SUMMARY\n   \n \n    Zappos Tech is looking for a technical, analytical, and design-focused Lead Product Manager to craft and lead the product vision and roadmap to improve the search experience for customers shopping across Zappos. This person will work closely with Applied Scientists, Software Engineers, UX Designers, Business teams, and Marketing to identify and unlock new opportunities that delight customers and brands to help make Zappos the preferred shopping destination for customers seeking clothing and shoes.\n   \n \n \n    If you are a product leader who is excited by leveraging design, machine learning, and patented and big data technologies to solve challenging customer problems, we want to talk to you!\n   \n \n \n    WHAT YOU WILL BE DOING\n   \n \n \n \n \n     Effectively influence up and across the organization.\n    \n \n \n     Partner with Design, Machine Learning Scientists, and Software Engineers to invent new customer experiences.\n    \n \n \n     Dive deep on customer behavioral data once we have made a change to understand short and long-term implications.\n    \n \n \n     Collaborate with stakeholders across departments to prioritize customer and business needs.\n    \n \n \n     Write monthly and quarterly updates and present to executive leadership.\n    \n \n \n \n \n    WHAT YOU BRING TO THE TABLE\n   \n \n \n \n \n     Bachelor\u2019s degree in Computer Science, Information Systems, or related field.\n    \n \n \n     At least five (5) years of Product management experience, ideally working in a software development organization that builds large-scale distributed systems.\n    \n \n \n     At least two (2) years of recent domain experience in and/or direct exposure to any of the following: Machine Learning, Information Retrieval, Data Mining, Search, and e-Commerce.\n    \n \n \n     Data-driven decision making and quantitative analysis skills, including decent knowledge of statistical analysis, Excel, SQL, and/or other analytical techniques.\n    \n \n \n     Demonstrated experience as a strong leader who can prioritize well, communicate clearly, and effectively influence across cross-functional teams.\n    \n \n \n     Excellent interpersonal skills; proven ability to guide cross-functional teams through influence versus direct management.\n    \n \n \n     Ability to think strategically while staying on top of tactical execution.\n    \n \n \n \n \n    WHAT REALLY WOWS US\n   \n \n \n \n \n     MBA or graduate degree.\n    \n \n \n     Experience authoring documents relating to product life cycle, including product roadmap, business requirements, and functional specifications.\n    \n \n \n     Ability to earn trust across different levels and multiple groups of a large organization.\n    \n \n \n     A deep understanding of software development in a team, and a proven track record of shipping software quickly then iterating on the experience.\n    \n \n \n     Experience communicating with customers, technical teams, and management to collect requirements, describe software product features, and technical designs on high level.\n    \n \n \n     Excellent analytical and quantitative skills; experience using data and metrics to test theories, confirm assumptions, and measure success.\n    \n \n \n     Demonstrated ability to dive deep in understanding the product, our business, and the competitive landscape.\n    \n \n \n \n  The base pay range for this position is $173,000 to $197,000 per year; however, base pay offered may vary depending on job-related knowledge, skills, and experience. In addition, a full range of medical and other benefits is offered. \n \n \n \n   The Fine Print\n  \n \n  The Zappos Family of Companies is committed to Equal Employment Opportunity regardless of race, color, national origin, gender, sexual orientation, age, religion, veteran status, disability, history of disability or perceived disability. If you need assistance or an accommodation due to a disability, you may email us at recruiting@zappos.com or call us at 1.702.943.7777.\n  \n \n \n   To all recruitment agencies: We do not accept unsolicited agency resumes and are not responsible for any fees related to unsolicited resumes.",
        "cleaned_desc": " \n \n    WHAT YOU BRING TO THE TABLE\n   \n \n \n \n \n     Bachelor\u2019s degree in Computer Science, Information Systems, or related field.\n    \n \n \n     At least five (5) years of Product management experience, ideally working in a software development organization that builds large-scale distributed systems.\n    \n \n \n     At least two (2) years of recent domain experience in and/or direct exposure to any of the following: Machine Learning, Information Retrieval, Data Mining, Search, and e-Commerce.\n    \n \n \n     Data-driven decision making and quantitative analysis skills, including decent knowledge of statistical analysis, Excel, SQL, and/or other analytical techniques.\n    \n \n \n     Demonstrated experience as a strong leader who can prioritize well, communicate clearly, and effectively influence across cross-functional teams.\n    \n \n \n     Excellent interpersonal skills; proven ability to guide cross-functional teams through influence versus direct management.\n    \n \n \n     Ability to think strategically while staying on top of tactical execution.\n    \n \n \n \n \n    WHAT REALLY WOWS US\n   \n \n ",
        "techs": [
            "machine learning",
            "information retrieval",
            "data mining",
            "search",
            "e-commerce",
            "statistical analysis",
            "excel",
            "sql"
        ],
        "cleaned_techs": [
            "information retrieval",
            "data mining",
            "search",
            "e-commerce",
            "statistical analysis",
            "excel",
            "sql"
        ]
    },
    "158db9e45276283f": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 172994.0,
        "salary_max": 241000.0,
        "title": "Graphics Software Engineer, Rendering - Reality Labs",
        "company": "Meta",
        "desc": "Reality Labs at Meta is building products that make it easier for people to connect with the ones they love most, enjoy top-notch, wire-free VR, and push the future of computing platforms. We are a team of world-class experts developing and shipping products at the intersection of hardware, software and content.As a Graphics Software Engineer on the Reality Labs team at Meta, you can help build new, innovative hardware and software that radically redefine the way people work, play and connect. What we build today could one day be the norm. So to be here today is to truly be at the heart of change and the frontier of what's to come. We're the people helping to define the metaverse. We may not have all the answers. But together, we're getting closer.\n  \n \n \n Graphics Software Engineer, Rendering - Reality Labs Responsibilities:    \n \n Develop innovative graphics frameworks, algorithms, and tools to maximize graphics quality and performance \n  Partner closely with various infra and product teams across Meta, on camera, graphics, upcoming hardware, media enhancements, and more to create real-time rendering architecture \n  Building tools and pipelines for generating very realistic synthetic images \n  Enable high fidelity experiences through remote compute solutions on smaller devices with limited battery \n  Building rendering subsystems for platforms such as Spark AR and Horizon \n  Build a platform for cloud streamed games \n  Document and support graphics features \n  Write high-quality, performant, and maintainable code \n  Collaborate with cross-functional engineering teams to deliver innovation into AR/VR products \n \n \n \n \n Minimum Qualifications:   \n \n  Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience. \n  6+ years of graphics software engineering experience or 2+ years of graphics software engineering experience with PhD \n  6+ years of experience with C/C++ programming \n  6+ years of object-oriented and component-based design experience \n  Problem-solving and communication skills \n \n \n \n \n Preferred Qualifications:   \n \n  Experience delivering AAA Games, working on Graphics subsystems or the Game Engine AR/VR experience \n  Knowledge of ray tracing, rasterization and linear algebra \n  Experience with low level performance profiling and optimization \n  Experience implementing 3D graphics features such as lighting, effects, shaders and other low-level systems \n  Experience with tools such as Maya, Houdini, Blender, 3Ds Max, Arnold, RenderMan, or Cycles \n  Experience with either DirectX/Vulkan/OpenGL/Metal \n \n \n \n \n About Meta:    Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today\u2014beyond the constraints of screens, the limits of distance, and even the rules of physics.\n  \n \n \n \n  Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment. \n   \n  Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",
        "cleaned_desc": "  Enable high fidelity experiences through remote compute solutions on smaller devices with limited battery \n  Building rendering subsystems for platforms such as Spark AR and Horizon \n  Build a platform for cloud streamed games \n  Document and support graphics features \n  Write high-quality, performant, and maintainable code \n  Collaborate with cross-functional engineering teams to deliver innovation into AR/VR products \n \n \n   \n Minimum Qualifications:   \n \n  Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience. \n  6+ years of graphics software engineering experience or 2+ years of graphics software engineering experience with PhD \n  6+ years of experience with C/C++ programming \n  6+ years of object-oriented and component-based design experience \n  Problem-solving and communication skills \n   \n \n \n Preferred Qualifications:   \n \n  Experience delivering AAA Games, working on Graphics subsystems or the Game Engine AR/VR experience \n  Knowledge of ray tracing, rasterization and linear algebra \n  Experience with low level performance profiling and optimization \n  Experience implementing 3D graphics features such as lighting, effects, shaders and other low-level systems ",
        "techs": [
            "spark ar",
            "horizon",
            "cloud streamed games",
            "graphics features",
            "c/c++ programming",
            "aaa games",
            "graphics subsystems",
            "game engine ar/vr experience",
            "ray tracing",
            "rasterization",
            "linear algebra",
            "low level performance profiling",
            "low-level systems"
        ],
        "cleaned_techs": [
            "spark ar",
            "horizon",
            "cloud streamed games",
            "graphics features",
            "c/c++ programming",
            "aaa games",
            "graphics subsystems",
            "game engine ar/vr experience",
            "ray tracing",
            "rasterization",
            "linear algebra",
            "low level performance profiling",
            "low-level systems"
        ]
    },
    "7e6c7c3fba186e7b": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 196000.0,
        "salary_max": 269000.0,
        "title": "Display Imaging Pipeline Engineer",
        "company": "Meta",
        "desc": "At Meta Reality Labs, we\u2019re developing the future of virtual reality (VR) and augmented reality (AR). The APIX team is looking for an Imaging Pipeline Engineer who can bring together the disparate simulation models of the component parts of our image chain, and employ this end-to-end pipeline in a continuous feedback loop to optimize product requirements against Display system constraints.\n  \n \n \n Display Imaging Pipeline Engineer Responsibilities:    \n \n Work cross-functionally with silicon, graphics, perception and display teams to implement pipeline models and simulate end-to-end performance of our image pipeline using those models \n  Implement system simulations of pipeline components and algorithms using a mixture of MATLAB and Python \n  Use simulation results to propose and verify improvements to aspects of the pipeline via modeling and human factors testing \n  Perform tradeoff analyses against visual quality metrics \n  Bring up novel display subsystems \n \n \n \n \n Minimum Qualifications:   \n \n  Bachelors in image processing or equivalent experience \n  8+ years of experience in research, advanced optics development, or equivalent experience \n  Experience in taking image-based (e.g. camera, printer, display) products to market \n  Experience with MATLAB \n  Understanding of Color spaces (HDR workflows, LED constraints, Display Calibration & Characterization) \n  Understanding of Imaging Standards such as SMPTE, MPEG & compressions schemes \n  Understanding of frame rates perception and hardware-software interactions \n  image processing algorithms and SW/HW implementation through the entire pipeline \n  Experience in managing production-level tradeoffs in typical image pipelines \n  Experience in working as part of a cross-functional team and familiarity with typical software/hardware design processes \n  Hands on working experience with displays and camera pipelines \n \n \n \n \n Preferred Qualifications:   \n \n  15+ years of experience in research, advanced optics development, or equivalent experience \n  PhD in Image Processing or related field \n  Knowledge of the human visual system, color science and imaging architectures \n  Experience in human factors testing and psychometric testing paradigms \n  Experience in bringing up real-world display technologies or optical systems, especially AR/VR \n  Experience with C/C++, C#, and/or Python and/or Matlab \n \n \n \n \n About Meta:    Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today\u2014beyond the constraints of screens, the limits of distance, and even the rules of physics.\n  \n \n \n \n  Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment. \n   \n  Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",
        "cleaned_desc": "  Experience with MATLAB \n  Understanding of Color spaces (HDR workflows, LED constraints, Display Calibration & Characterization) \n  Understanding of Imaging Standards such as SMPTE, MPEG & compressions schemes \n  Understanding of frame rates perception and hardware-software interactions \n  image processing algorithms and SW/HW implementation through the entire pipeline \n  Experience in managing production-level tradeoffs in typical image pipelines \n  Experience in working as part of a cross-functional team and familiarity with typical software/hardware design processes \n  Hands on working experience with displays and camera pipelines \n \n   \n \n Preferred Qualifications:   \n \n  15+ years of experience in research, advanced optics development, or equivalent experience \n  PhD in Image Processing or related field \n  Knowledge of the human visual system, color science and imaging architectures \n  Experience in human factors testing and psychometric testing paradigms \n  Experience in bringing up real-world display technologies or optical systems, especially AR/VR \n  Experience with C/C++, C#, and/or Python and/or Matlab ",
        "techs": [
            "matlab",
            "color spaces",
            "hdr workflows",
            "led constraints",
            "display calibration & characterization",
            "imaging standards",
            "smpte",
            "mpeg",
            "compression schemes",
            "frame rates perception",
            "image processing algorithms",
            "sw/hw implementation",
            "image pipelines",
            "cross-functional team",
            "software/hardware design processes",
            "displays",
            "camera pipelines",
            "research",
            "advanced optics development",
            "phd in image processing",
            "human visual system",
            "color science",
            "imaging architectures",
            "human factors testing",
            "psychometric testing paradigms",
            "real-world display technologies",
            "optical systems",
            "ar/vr",
            "c/c++",
            "c#",
            "python"
        ],
        "cleaned_techs": [
            "matlab",
            "color spaces",
            "hdr workflows",
            "led constraints",
            "display calibration & characterization",
            "imaging standards",
            "smpte",
            "mpeg",
            "compression schemes",
            "frame rates perception",
            "image processing algorithms",
            "sw/hw implementation",
            "image pipelines",
            "cross-functional team",
            "software/hardware design processes",
            "displays",
            "camera pipelines",
            "research",
            "advanced optics development",
            "human visual system",
            "color science",
            "imaging architectures",
            "human factors testing",
            "psychometric testing paradigms",
            "real-world display technologies",
            "optical systems",
            "ar/vr",
            "c/c++",
            "c#",
            "python"
        ]
    },
    "f03987704c6b6cc2": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 184300.0,
        "salary_max": 255000.0,
        "title": "Principal Software Engineer",
        "company": "Upstart Network, Inc.",
        "desc": "About Upstart \n  Upstart is a leading AI lending marketplace partnering with banks and credit unions to expand access to affordable credit. By leveraging Upstart's AI marketplace, Upstart-powered banks and credit unions can have higher approval rates and lower loss rates across races, ages, and genders, while simultaneously delivering the exceptional digital-first lending experience their customers demand. More than two-thirds of Upstart loans are approved instantly and are fully automated. \n  Upstart is a digital-first company, which means that most Upstarters can live and work anywhere in the U.S. We also have offices in San Mateo, California; Columbus, Ohio; and Austin, Texas. \n  Most Upstarters join us because they connect with our mission of enabling access to effortless credit based on true risk. If you are energized by the impact you can make at Upstart, we\u2019d love to hear from you! \n \n The Team \n  Upstart\u2019s Machine Learning team has a direct impact on our company's success. The team consists of full-stack applied science generalists as well as specialists in research, data science, statistical modeling and machine learning. The fundamental goal of the Machine Learning team is to explore new models and new data sets that can improve the accuracy of our models. With this goal comes near-limitless challenges to tackle, and that is one of the reasons why Upstart is such a unique opportunity. \n  As  Principal Software Engineer  at Upstart, you will be at the forefront of a team of top-notch specialists, using your C++ skills to optimize cutting-edge machine learning frameworks, employing GPU-accelerated computing, and mastering cloud and Linux infrastructure. \n  Position location  This role is available in the following locations: Remote \n  Time zone requirements  The team operates on the East/West coast time zones. \n  Travel requirements  As a digital first company, the majority of your work can be accomplished remotely. The majority of our employees can live and work anywhere in the U.S but are encouraged to to still spend high quality time in-person collaborating via regular onsites. The in-person sessions\u2019 cadence varies depending on the team and role; most teams meet once or twice per quarter for 2-4 consecutive days at a time. \n \n  How you\u2019ll make an impact: \n \n Deep Optimization : Dive into the C++ code which powers these ML models. You will use your expertise to push the boundaries of these models and extract their maximum potential. \n GPU and CUDA : Harness the raw power of GPUs using CUDA to supercharge your machine learning models, creating solutions that are not just efficient, but also blazing fast. \n Cloud and Linux : Leverage your solid understanding of cloud infrastructures and Linux to build robust, scalable, and highly available machine learning solutions \n Data Formats : Look into the finer details of data formats. Your work will ensure the accuracy, efficiency, and quality of the data that feeds into our machine learning models. \n \n Minimum Qualifications \n \n Strong software skills in C++, and multiple languages such as Java, Kotlin, Python. \n Profound knowledge of the entire tech stack, inclusive of computer science fundamentals and in-depth understanding of various operating systems and hardware configurations. \n High degree of cross-functional expertise, with the ability to navigate between various roles within the tech stack. \n Bachelor's or Master's degree in Computer Science or a related field, or equivalent practical experience. \n \n Preferred Qualifications \n \n Deep systems C++ expertise. \n Experience with machine learning frameworks such as TensorFlow, PyTorch, etc. \n Deep knowledge in using GPUs for computation, including a strong understanding of CUDA. \n Extensive experience with cloud and Linux infrastructures \n \n What you'll love: \n \n Competitive Compensation (base + bonus & equity) \n Comprehensive medical, dental, and vision coverage with Health Savings Account contributions from Upstart \n 401(k) with 100% company match up to $4,500 and immediate vesting and after-tax savings \n Employee Stock Purchase Plan (ESPP) \n Life and disability insurance \n Generous holiday, vacation, sick and safety leave \n Supportive parental, family care, and military leave programs \n Annual wellness, technology & ergonomic reimbursement programs \n Social activities including team events and onsites, all-company updates, employee resource groups (ERGs), and other interest groups such as book clubs, fitness, investing, and volunteering \n Catered lunches + snacks & drinks when working in offices \n \n #LI-REMOTE  \n #LI-MidSenior \n \n \n \n At Upstart, your base pay is one part of your total compensation package. The anticipated base salary for this position is expected to be within the below range. Your actual base pay will depend on your geographic location\u2013with our \u201cdigital first\u201d philosophy, Upstart uses compensation regions that vary depending on location. Individual pay is also determined by job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process. \n  In addition, Upstart provides employees with target bonuses, equity compensation, and generous benefits packages (including medical, dental, vision, and 401k). \n \n \n     United States | Remote - Anticipated Base Salary Range\n    \n \n     $184,300\u2014$255,000 USD\n    \n \n \n \n Upstart is a proud Equal Opportunity Employer. We are dedicated to ensuring that underrepresented classes receive better access to affordable credit, and are just as committed to embracing diversity and inclusion in our hiring practices. We celebrate all cultures, backgrounds, perspectives, and experiences, and know that we can only become better together. \n  If you require reasonable accommodation in completing an application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please email  candidate_accommodations@upstart.com \n  https://www.upstart.com/candidate_privacy_policy",
        "cleaned_desc": " \n Deep Optimization : Dive into the C++ code which powers these ML models. You will use your expertise to push the boundaries of these models and extract their maximum potential. \n GPU and CUDA : Harness the raw power of GPUs using CUDA to supercharge your machine learning models, creating solutions that are not just efficient, but also blazing fast. \n Cloud and Linux : Leverage your solid understanding of cloud infrastructures and Linux to build robust, scalable, and highly available machine learning solutions \n Data Formats : Look into the finer details of data formats. Your work will ensure the accuracy, efficiency, and quality of the data that feeds into our machine learning models. \n \n Minimum Qualifications \n \n Strong software skills in C++, and multiple languages such as Java, Kotlin, Python. \n Profound knowledge of the entire tech stack, inclusive of computer science fundamentals and in-depth understanding of various operating systems and hardware configurations. \n High degree of cross-functional expertise, with the ability to navigate between various roles within the tech stack. \n Bachelor's or Master's degree in Computer Science or a related field, or equivalent practical experience. \n ",
        "techs": [
            "deep optimization",
            "gpu",
            "cuda",
            "cloud",
            "linux",
            "data formats",
            "c++",
            "java",
            "kotlin",
            "python"
        ],
        "cleaned_techs": [
            "deep optimization",
            "gpu",
            "cuda",
            "cloud",
            "linux",
            "data formats",
            "c++",
            "java",
            "kotlin",
            "python"
        ]
    },
    "ed9b009b5fdce804": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 155000.0,
        "salary_max": 222000.0,
        "title": "Product Designer",
        "company": "Meta",
        "desc": "At Meta, we\u2019re shaping innovative experiences in service of giving people the power to build community and bring the world closer together. Our multidisciplinary design teams are creating new ways to help people connect, find communities and grow businesses. Together, we are committed to building innovative technologies \u2014 Facebook, Instagram, Messenger, WhatsApp, Workplace, Meta Quest and more \u2014 to serve billions of people around the globe. As a product designer at Meta, you\u2019ll have the opportunity to play a central role in the way we build technologies \u2014 ensuring they are valuable, easy to use and of the highest level of craft and execution. You\u2019ll be involved in every aspect of the product development process, from brainstorming the next great product innovation to tweaking pixels right before launch. We\u2019ll expect you to utilize your full range of product design, interaction design and visual design skills, while contributing to high-level strategic decisions with product and executive partners. Join a diverse group of thinkers and do some of the most meaningful work of your career. This posting represents different full-time roles across the Meta company.\n  \n \n \n Product Designer Responsibilities:    \n \n Leads and delivers design projects of large and (or) ambiguous scope \n  Take broad, conceptual ideas and turn them into something useful and valuable for our 2 billion plus users \n  Design flows and experiences that simplify and distill down complex actions into usable interfaces \n  Design new experiences or layouts that evolve and define visual systems \n  Contribute to strategic decisions around the future direction of Facebook products \n  Give and solicit feedback from designers and a broader product team in order to continually raise our bar for quality, while also taking on mentorship \n  Lead a partnership with product managers, engineers, researchers and content strategists to oversee the user experience of a product from conception until launch \n \n \n \n \n Minimum Qualifications:   \n \n  6+ years of experience building, shipping and leading applications or software that are large and/or ambiguous in scope that encompass an end-to-end experience across a variety of platforms. \n  6+ years of interaction design experience with knowledge of defining how an experience should behave based on understanding people's needs, plus consideration of how this innovation will scale. Use appropriate prototyping tools to demonstrate how a particular flow or interaction will work. \n  6+ years of visual design experience with proficiency in typography, desktop/mobile UI, color, layout, iconography and aesthetic sense and how these elements impact product function. \n  6+ years of experience driving the vision of a successful product playing a critical role in setting goals and direction while making decisions that reach a common goal based on the impact to people and the company. \n  Experience representing work to a broader product team and other leaders, clearly and succinctly articulating the goals and concepts. \n \n \n \n \n Preferred Qualifications:   \n \n  Experience showcasing your end-to-end design process across multiple projects, that include interaction and visual design artifacts, multiple iterations, and high-fidelity prototypes \n  Experience connecting your work with other related initiatives across the company while driving collaboration \n  Proven leadership in non-product dimensions that have made a team stronger and positively impacted the work environment \n \n \n \n \n About Meta:    Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today\u2014beyond the constraints of screens, the limits of distance, and even the rules of physics.\n  \n \n \n \n  Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment. \n   \n  Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",
        "cleaned_desc": " \n Minimum Qualifications:   \n \n  6+ years of experience building, shipping and leading applications or software that are large and/or ambiguous in scope that encompass an end-to-end experience across a variety of platforms. \n  6+ years of interaction design experience with knowledge of defining how an experience should behave based on understanding people's needs, plus consideration of how this innovation will scale. Use appropriate prototyping tools to demonstrate how a particular flow or interaction will work. \n  6+ years of visual design experience with proficiency in typography, desktop/mobile UI, color, layout, iconography and aesthetic sense and how these elements impact product function. \n  6+ years of experience driving the vision of a successful product playing a critical role in setting goals and direction while making decisions that reach a common goal based on the impact to people and the company. \n  Experience representing work to a broader product team and other leaders, clearly and succinctly articulating the goals and concepts. ",
        "techs": [
            "prototyping tools",
            "typography",
            "desktop/mobile ui",
            "color",
            "layout",
            "iconography"
        ],
        "cleaned_techs": [
            "typography",
            "desktop/mobile ui",
            "color",
            "layout",
            "iconography"
        ]
    },
    "32fbf00b595b849d": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 135710.5,
        "salary_max": 171839.72,
        "title": "Software Development Manager",
        "company": "Vibrent Health",
        "desc": "Vibrent Health , a rapidly growing health-tech company, is seeking a \n   Software Development Team Lead.  Our ideal candidate is a self-motivated, self-directed technical leader with a proven track record of building out high performing teams in a complex technical environment.\n   \n \n \n \n \n  A successful \n   Software Development Team Lead  will have a combination of technical skills, project management and team management in software engineering and development. You will work with both engineering and product teams to manage local and remote development teams as we scale the business.\n   \n \n \n \n \n  To be selected for this opportunity, you will need to demonstrate an overall aptitude in software delivery, risk/problem diagnosis, keeping up with industry trends, and the ability to build and grow a reliable team that includes local, remote, and off-shore resources. Our ideal candidate is a self-motivated, self-directed technical leader with a proven track record of building out high performing teams in a complex technical environment.\n  \n \n \n  This is a remote position. Vibrent Health is a \"remote first\" team. You will be equipped to work remote on a team that is fully remote. We do strongly prefer that the candidate be based in the DC metro area. \n \n \n \n  #LI-Remote \n \n \n \n  Please note that we are not seeking off-shore or contingent staffing resources at this time and unsolicited third party resumes will not be accepted.\n  \n Role & Responsibilities: \n \n  Manage delivery of web and mobile applications using local/remote and offshore development teams \n  Manage team productivity \u2013 tracking/measuring as well as enhancing it using tools/processes. \n  Mentoring, coaching, and performance management of a team of engineers. Lead annual reviews and corrective action plans as needed. \n  Help team with difficult goals, challenging situations, production issues, designing for scalability and managing technical debt. \n  Maintain familiarity with tools, Java and Spring development, and Kubernetes sufficient to coach and lead the team and coordinate resources. \n \n  Qualifications: \n \n  Bachelor's degree in a technical discipline (engineering, computer science, etc.) or equivalent specialized training and experience \n  Minimum 8 years\u2019 experience in software development utilizing JAVA and Kubernetes. \n  At least 2 years of team lead or management experience \n  Experience delivering mobile as well as web applications is highly desired. \n  Experience with understanding application and database infrastructure is highly desired. \n  Demonstrate leadership, project management and communication skills \n  Exceptionally self-motivated and directed \n  Superior analytical, evaluative, and problem-solving abilities \n \n \n  When you work at Vibrent, you are surrounded by a diverse group of people who share a passion for achieving excellence and making a lasting impact.  Passion, excellence and impact should be rewarded, and we do that- offering a competitive compensation package that includes over-average 401k match, the benefits you need to prioritize self and family care, and support for your further education and career development. \n   One of the greatest benefits Vibrent offers is opportunity.  At Vibrent, we work with the latest tools and technologies including enterprise mobile apps, fitness sensors, medical devices, cloud computing, machine learning, big data and analytics. We partner with national leaders in healthcare, technology, and research. We create tools that will change and improve healthcare for ourselves and future generations. \n  \n \n \n \n Vibrent is an equal opportunity employer.  All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, national origin, age, sexual orientation, gender identity, disability, or veteran status.\n  \n \n \n  #LI-LJ1",
        "cleaned_desc": "  Help team with difficult goals, challenging situations, production issues, designing for scalability and managing technical debt. \n  Maintain familiarity with tools, Java and Spring development, and Kubernetes sufficient to coach and lead the team and coordinate resources. \n \n  Qualifications: \n \n  Bachelor's degree in a technical discipline (engineering, computer science, etc.) or equivalent specialized training and experience \n  Minimum 8 years\u2019 experience in software development utilizing JAVA and Kubernetes. \n  At least 2 years of team lead or management experience \n  Experience delivering mobile as well as web applications is highly desired. \n  Experience with understanding application and database infrastructure is highly desired. \n  Demonstrate leadership, project management and communication skills ",
        "techs": [
            "java",
            "spring development",
            "kubernetes"
        ],
        "cleaned_techs": [
            "java",
            "spring development",
            "kubernetes"
        ]
    },
    "c7cd8d496fcb1f74": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 21000.0,
        "salary_max": 21000.0,
        "title": "Senior Systems Engineer",
        "company": "G2 Ops, Inc.",
        "desc": "Number of Roles Open:  3 Full Time \n  Location:  San Diego, CA (in office  and   at customer site location) \n  Salary Range:  $120,000 - $180,000 + benefits \n  Start Date:  ASAP \n  Clearance Requirements:  Active DoD Secret required, Top Secret preferred. \n  Experience Requirements Role #1:  Qualified candidates must have clear NAVWAR C4I   systems   experience   and familiarity on  VLF or general RF/radio  knowledge. \n  Experience Requirements Role #2:  Qualified candidates must have clear  NAVWAR C4I  systems experience. \n  Experience Requirements Role #3:  Qualified candidates must have clear NAVWAR C4I   network hosting  experience. \n  What makes someone choose one company over another?  Pay, Benefits, Training, Work Satisfaction, Culture? What if you can have it all! At G2 Ops we have extremely competitive pay and benefits and that is not even the best part. Our culture is what sets us apart from other companies. Here, you will not be another payroll number or a cog in the machine. We provide great value to our customers by working as a team and ensuring every member is set up for success. Our team approach allows for each member to not only provide value with their expertise but also gives them the opportunity to cross train in other areas they have interest in. \n  Let's talk salary.  The salary range for these positions is  $120,000 - $180,000  based on what we are asking you to do, and your qualifications. We also offer a competitive benefits package and have fringe benefits offered throughout the year. The benefits have an estimated value of  $21,000  annually. With company standard annual performance reviews in place, plus on the spot awards for recognition, your performance will be rewarded and recognized, we promise! \n  So, you want to work from home?  Let's be honest, remote work is not always all it's cut out to be. At G2 Ops, we offer a flexible schedule to meet the needs of our employees and customers.  Due to the classification level of the projects we support, we are not able to offer fully remote opportunities at this time.  As a Defense Contractor, we are frequently working with sensitive material, and therefore, we need to ensure where you access your work is secure. You will have a shiny desk at the G2 Ops office, and certain positions  will be required to work   at a military site  directly with our customers (this is a good thing!). We do allow teleworking with prior approvals, but here's the thing, we have worked very hard to create an awesome culture where our employees get to come to a collaborative, exciting office environment. We want you to join the fun! \n  Still not convinced?  Allow us to elaborate. For these opportunities, we are seeking highly motivated, technology-focused, team-oriented  Systems Engineers  to join our team. These are critical roles for our company and the candidate would be required to interface with multiple services and stakeholders up to Flag level. This subject matter expert would be responsible for brief development, process development, technical/organizational problem solving, scheduling test and integration events, and implementing system engineering principles, as required.  \n What does this mean to you?  This is an exciting time to be part of a team that\u2019s impacting how engineering is being performed on a day-to-day basis. We\u2019re looking for  engineering experts  to lead our teams as we take on tough problems and build complex, highly sophisticated systems. Our ideal candidate will have a  Bachelor of Science Degree in engineering, computer science, or related  plus demonstrable  years of industry experience  (DoD military systems, C4I, Surface-, Undersea-, Air-, and Mine-warfare on military programs, etc.) Our desired candidate will be skilled in operational analysis and use case definition, plus requirements management and analysis. \n  We require a  bachelor\u2019s degree  from an accredited college or university (a technical degree in Computer Science, System Engineering, Information Systems is preferred) or additional applicable years of experience to be considered.  \n To be successful in this role,  you must be able to communicate clearly with stakeholders and engineering leadership teams to ensure requirements are clearly defined and Customer expectations are being met. The ability to analyze new and complex program-related problems and create innovative solutions that integrate schedule, technology, methodology, tools, and financial aspects are also critical components to this position.  \n Lastly, as we are working for the DoD, we are beholden to some requirements. These positions  require an  active DoD Secret Clearance , or higher, to be considered. \n  Congratulations , you made it all the way to the end of this job posting! We look forward to learning more about you! \n  Quick Note:  We are seeking full-time employees; the continuation of outside employment shall not constitute a conflict with the Company\u2019s interest, including performing work for a customer or competitor. \n  Benefits \n \n 100% company-paid insurance for medical, dental, and vision for eligible employees and family members \n 100% company-paid insurance for life, short-term (STD) and long-term disability (LTD) for eligible employees  \n 401(K) Plan with discretionary employer matching \n 10 paid holidays \n Paid time off (PTO) \n Educational assistance \n Work/life balance \n Family-oriented culture \n Competitive salaries \n \n About G2 Ops, Inc. \n G2 Ops, Inc. is a small business with big capabilities in cyber security architectural analysis, model-based systems engineering (MBSE), and strategic consulting in support of both government and commercial clients across the globe. As a trusted and reliable government contractor, we deliver cyber security & systems engineering support for integrated DoD weapons, communications, intelligence, and other mission-critical systems. In the commercial space, we provide business solutions analysis, strategic planning, and training and development services to a variety of public and private sector businesses and organizations. Through innovative solutions, exceptional employees, top-tier analytical capabilities, and a customer-centered focus, G2 Ops has established a reputation for service excellence and innovation. \n G2 Ops, Inc. is an Equal Opportunity Employer \n   \n KPJxQegc2J",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "c14c089eba0f276d": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 58400.0,
        "salary_max": 133000.0,
        "title": "Full Stack Software Engineer",
        "company": "Booz Allen Hamilton",
        "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Bethesda,MD,US \n         \n \n \n \n         Remote Work: \n         \n \n         Hybrid \n         \n \n \n \n         Job Number: \n         \n \n         R0182566\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Full Stack Software Engineer\n           The Opportunity: \n  Are you looking for an opportunity to combine your technical skills with big picture thinking to make an impact in healthcare? You understand your customer\u2019s environment and how to develop the right systems for their mission. Your ability to translate real-world needs into technical specifications makes you an integral part of delivering a customer focused engineering solution. \n \n  As a software engineer on our team, you have the chance to design systems in support of a federal client's healthcare initiatives. Your technical expertise will be vital as you evaluate and modernize legacy systems. You\u2019ll develop your skills in cloud technologies while gaining experience in healthcare. Join our team and help turn requirements into accomplishments that drive change. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  3+ years of experience with architecting, integrating, and developing software systems in Java, J2EE, Scala, or Python \n  Experience with ElasticSearch or Hibernate \n  Experience in interacting with Cloud infrastructure providers, including AWS \n  Experience with DevOps methods and tools, including Jenkins, Git, SVN, Jira, Cucumber, Docker, or Kubernetes \n  Experience with all phases of the software development life cycle (SDLC) using Agile methods \n  Knowledge of Microservices development and designing and implementing RESTful Web services \n  Knowledge of JavaScript frameworks, including Angular or React \n  Knowledge of object-oriented programming (OOP) and designing, developing, and communicating complex software solutions \n  Ability to obtain and maintain a Public Trust or Suitability/Fitness determination based on client requirements \n  Bachelor's degree \n \n \n  Nice If You Have: \n \n  Experience with MongoDB, MySQL, Airflow, Apache Spark, or PySpark \n  Experience with large-scale, distributed systems design and development \n  Experience with machine and deep learning concepts and algorithms \n  Knowledge of scripting languages, including Python, Node, or Bash \n  Knowledge of scaling, performance, and scheduling \n  Knowledge of system architecture, including process, memory, storage, and networking management \n  Possession of excellent analytical and problem-solving skills \n  Master's degree in Computer Science or a related field \n \n \n  Vetting: \n  Applicants selected will be subject to a government investigation and may need to meet eligibility requirements of the U.S. government client. \n \n  Create Your Career: \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll build your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $58,400.00 to $133,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",
        "cleaned_desc": " \n \n \n \n \n \n         Full Stack Software Engineer\n           The Opportunity: \n  Are you looking for an opportunity to combine your technical skills with big picture thinking to make an impact in healthcare? You understand your customer\u2019s environment and how to develop the right systems for their mission. Your ability to translate real-world needs into technical specifications makes you an integral part of delivering a customer focused engineering solution. \n \n  As a software engineer on our team, you have the chance to design systems in support of a federal client's healthcare initiatives. Your technical expertise will be vital as you evaluate and modernize legacy systems. You\u2019ll develop your skills in cloud technologies while gaining experience in healthcare. Join our team and help turn requirements into accomplishments that drive change. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  3+ years of experience with architecting, integrating, and developing software systems in Java, J2EE, Scala, or Python \n  Experience with ElasticSearch or Hibernate \n  Experience in interacting with Cloud infrastructure providers, including AWS \n  Experience with DevOps methods and tools, including Jenkins, Git, SVN, Jira, Cucumber, Docker, or Kubernetes \n  Experience with all phases of the software development life cycle (SDLC) using Agile methods \n  Knowledge of Microservices development and designing and implementing RESTful Web services    Knowledge of JavaScript frameworks, including Angular or React \n  Knowledge of object-oriented programming (OOP) and designing, developing, and communicating complex software solutions \n  Ability to obtain and maintain a Public Trust or Suitability/Fitness determination based on client requirements \n  Bachelor's degree \n \n \n  Nice If You Have: \n \n  Experience with MongoDB, MySQL, Airflow, Apache Spark, or PySpark \n  Experience with large-scale, distributed systems design and development \n  Experience with machine and deep learning concepts and algorithms \n  Knowledge of scripting languages, including Python, Node, or Bash \n  Knowledge of scaling, performance, and scheduling \n  Knowledge of system architecture, including process, memory, storage, and networking management \n  Possession of excellent analytical and problem-solving skills \n  Master's degree in Computer Science or a related field \n \n \n  Vetting: \n  Applicants selected will be subject to a government investigation and may need to meet eligibility requirements of the U.S. government client. \n \n  Create Your Career: ",
        "techs": [
            "java",
            "j2ee",
            "scala",
            "python",
            "elasticsearch",
            "hibernate",
            "aws",
            "jenkins",
            "git",
            "svn",
            "jira",
            "cucumber",
            "docker",
            "kubernetes",
            "microservices development",
            "restful web services",
            "angular",
            "react",
            "object-oriented programming (oop)",
            "mongodb",
            "mysql",
            "airflow",
            "apache spark",
            "pyspark",
            "machine learning",
            "deep learning",
            "python",
            "node",
            "bash",
            "scaling",
            "performance",
            "scheduling",
            "system architecture"
        ],
        "cleaned_techs": [
            "java",
            "j2ee",
            "scala",
            "python",
            "elasticsearch",
            "hibernate",
            "aws",
            "jenkins",
            "git",
            "svn",
            "jira",
            "cucumber",
            "docker",
            "kubernetes",
            "microservices development",
            "restful web services",
            "angular",
            "react",
            "object-oriented programming (oop)",
            "mongodb",
            "mysql",
            "airflow",
            "apache spark",
            "pyspark",
            "node",
            "bash",
            "scaling",
            "performance",
            "scheduling",
            "system architecture"
        ]
    },
    "3a848ec52efd987b": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 62874.0,
        "salary_max": 80000.0,
        "title": "Remote IT Support Engineer (Systems Administrator 2)",
        "company": "HII",
        "desc": "Date:  Oct 17, 2023  \n Location:  Adelphi, MD, Remote, United States  \n Company:  HII's Mission Technologies division  \n \n Requisition Number: 16635 \n Required Travel: 0 - 10% \n Employment Type: Full Time/Salaried/Exempt \n Hours Per Week: 40 \n Anticipated Salary Range: $62,874.00 - $80,000.00 \n Security Clearance: Ability to Obtain \n Level of Experience: Entry Level \n \n \n \n  Come Join HII! Where Hard Stuff is Done Right! \n \n \n \n \n HII Mission Technologies currently has an opening for a Remote IT Support Engineer to join the team. In this role the ideal candidate will own and drive crisis situations that may involve technically challenging issues and diverse audiences. If you have the ability to obtain a security clearance and would like to work with a team that makes an organization impact this may be the role for you! \n Who is HII Mission Technologies?  HII Mission Technologies develops integrated solutions that enable today\u2019s connected, all-domain force. Capabilities include C5ISR systems and operations; the application of AI and machine learning to battlefield decisions; defensive and offensive cyberspace strategies and EW; unmanned autonomous systems; LVC solutions; fleet modernization; and critical nuclear operations.   \n \n \n \n \n Responsibilities: I want to and can do that! \n \n \n \n Own and drive crisis situations that may involve technically challenging issues and diverse audiences. \n Identify knowledge opportunities and create documentation or training to resolve the gaps. \n Respond to informal/formal escalation requests for assistance and follow through to resolution. \n Advanced Support and Troubleshooting: Service Delivery escalation tasks and troubleshooting as required \n Administer and maintain existing network and systems infrastructure as well as evaluating and designing new systems and network equipment \n Perform after hours on call rotation as required \n \n \n \n \n \n \n  Requirements: I have already done that or have it! \n \n \n \n 3 years relevant experience with Bachelors in related field; 1 year relevant experience with Masters in related field; or High School Diploma or equivalent and 7 years relevant experience. \n 2+ years of supporting infrastructure in medium to large enterprises \n Experience with Network equipment and monitoring. Able to test network performance and security. \n Must be willing to work in a growing, fast paced and global environment where travel may be required. \n Knowledge of Administration in core IT systems including Windows OS, OSX, iOS, Active Directory, Azure AD and Endpoint Manager, Exchange, SharePoint, Office 365, Microsoft Defender \n Ability to obtain a DoD security clearance \n \n \n \n \n \n \n  Preferred: Bonus Points For\u2026  \n \n \n \n Commercial cloud experience \n Industry certifications \n \n \n \n \n \n \n  Physical Requirements \n \n \n     Adequate visual acuity and manual dexterity for meeting the requirements of the Systems Analyst discipline.\n     \n \n \n  HII\u2019s Mission Technologies division develops integrated solutions that enable today\u2019s connected, all-domain force. Capabilities include C5ISR systems and operations; the application of AI and machine learning to battlefield decisions; defensive and offensive cyberspace strategies and EW; unmanned, autonomous systems; LVC solutions; platform modernization; and critical nuclear operations. Together, HII's domain expertise and advanced technologies support mission partners anywhere around the globe. For more information, visit tsd.huntingtoningalls.com. \n HII is a global engineering and defense technologies provider. With a 135-year history of trusted partnerships in advancing U.S. national security, HII delivers critical capabilities ranging from the most powerful and survivable naval ships ever built, to unmanned systems, ISR and AI/ML analytics. HII leads the industry in mission-driven solutions that support and enable a networked, all-domain force. Headquartered in Virginia, HII\u2019s skilled workforce is 44,000 strong. \n Working at HII is more than a job - it\u2019s an opportunity to build a new future. We offer competitive benefits such as best-in-class medical, dental and vision plan choices; onsite health, vision and dental at some locations; wellness resources; employee assistance programs; Savings Plan Options (401(k)); financial planning tools, life insurance; employee discounts; paid holidays and paid time off; tuition reimbursement; as well as early childhood and post-secondary education scholarships. \n HII Is committed to cultivating an inclusive company culture to promote collaboration and enhance creativity by hiring a diverse work force. HII is an Equal Opportunity/Vets and Disabled Employer. U.S. Citizenship may be required for certain positions.",
        "cleaned_desc": " 3 years relevant experience with Bachelors in related field; 1 year relevant experience with Masters in related field; or High School Diploma or equivalent and 7 years relevant experience. \n 2+ years of supporting infrastructure in medium to large enterprises \n Experience with Network equipment and monitoring. Able to test network performance and security. \n Must be willing to work in a growing, fast paced and global environment where travel may be required. \n Knowledge of Administration in core IT systems including Windows OS, OSX, iOS, Active Directory, Azure AD and Endpoint Manager, Exchange, SharePoint, Office 365, Microsoft Defender \n Ability to obtain a DoD security clearance \n \n \n \n \n \n \n  Preferred: Bonus Points For\u2026  \n \n ",
        "techs": [
            "bachelors in related field",
            "masters in related field",
            "high school diploma",
            "network equipment and monitoring",
            "windows os",
            "osx",
            "ios",
            "active directory",
            "azure ad",
            "endpoint manager",
            "exchange",
            "sharepoint",
            "office 365",
            "microsoft defender",
            "dod security clearance."
        ],
        "cleaned_techs": [
            "masters in related field",
            "high school diploma",
            "network equipment and monitoring",
            "windows os",
            "osx",
            "ios",
            "active directory",
            "azure",
            "endpoint manager",
            "exchange",
            "sharepoint",
            "office 365",
            "microsoft defender"
        ]
    },
    "a0c976c4d01a5860": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 106200.0,
        "salary_max": 242000.0,
        "title": "Software Engineer, Lead",
        "company": "Booz Allen Hamilton",
        "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Washington,DC,US \n         \n \n \n \n         Remote Work: \n         \n \n         Hybrid \n         \n \n \n \n         Job Number: \n         \n \n         R0182407\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Software Engineer, Lead\n           Key Role:  \n Shift the way the world works in a Software Engineering role. Serve as a seasoned member of an Agile team to design and deliver modern technology products in a secure, reliable, and scalable manner. Carry out critical technology solutions across multiple technical areas in support of the firm\u2019s business objectives. \n \n  Basic Qualifications: \n \n  8+ years of experience developing large and complex systems \n  Experience working with Centers for Medicare and Medicaid Services and Government Improper Payment programs \n  Experience with State Medicaid Error Rate Finding (SMERF) system \n  Experience delivering technical assistance to a wide range of stakeholders, using a variety of delivery techniques, and presenting technical approaches in large meetings with both internal and external audiences \n  Experience with hands-on system design, application development, testing, and operational stability using agile development methodologies \n  Experience designing and implementing database schema and data models with Relational Database Management Systems (RDBMS), including MS SQL Server \n  Knowledge of core business functions such as medical reviews, data processing reviews, and related policies \n  Knowledge of Payment Error Rate Measurement (PERM) program and improper payments rates in Medicaid and CHIP \n  Ability to obtain and maintain a Public Trust or Suitability/Fitness determination based on client requirements  \n Bachelor\u2019s degree \n \n \n  Additional Qualifications: \n \n  Experience with the federal procurement and proposal process \n  Experience with SAML standard and JSON Web Token (JWT) for exchanging authentication and authorization data between Identity Provider and Service Provider \n  Knowledge of different resolution and appeals processes in the SMERF system \n  Knowledge of AWS Cloud services and cloud native application architecture \n  Knowledge of Open Authentication (OAuth) standard for token-based authentication and Single Sign On (SSO) \n  Knowledge of core tenants of DevSecOps such as containerization and orchestration, CI/CD pipelines, automated testing, Infrastructure as Code (IaC), security compliance, and application monitoring \n  Ability to apply Artificial Intelligence (AI), Machine Learning (ML), and automation techniques to drive insights and efficiencies \n  Ability to demonstrate relationships in the Centers for Medicare and Medicare Services (CMS) federal agency \n \n \n  Vetting: \n  Applicants selected will be subject to a government investigation and may need to meet eligibility requirements of the U.S. government client. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $106,200.00 to $242,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",
        "cleaned_desc": "  Basic Qualifications: \n \n  8+ years of experience developing large and complex systems \n  Experience working with Centers for Medicare and Medicaid Services and Government Improper Payment programs \n  Experience with State Medicaid Error Rate Finding (SMERF) system \n  Experience delivering technical assistance to a wide range of stakeholders, using a variety of delivery techniques, and presenting technical approaches in large meetings with both internal and external audiences \n  Experience with hands-on system design, application development, testing, and operational stability using agile development methodologies \n  Experience designing and implementing database schema and data models with Relational Database Management Systems (RDBMS), including MS SQL Server \n  Knowledge of core business functions such as medical reviews, data processing reviews, and related policies \n  Knowledge of Payment Error Rate Measurement (PERM) program and improper payments rates in Medicaid and CHIP \n  Ability to obtain and maintain a Public Trust or Suitability/Fitness determination based on client requirements  \n Bachelor\u2019s degree \n \n \n  Additional Qualifications: \n \n  Experience with the federal procurement and proposal process \n  Experience with SAML standard and JSON Web Token (JWT) for exchanging authentication and authorization data between Identity Provider and Service Provider ",
        "techs": [
            "centers for medicare and medicaid services",
            "government improper payment programs",
            "state medicaid error rate finding (smerf) system",
            "agile development methodologies",
            "relational database management systems (rdbms)",
            "ms sql server",
            "payment error rate measurement (perm) program",
            "medicaid",
            "chip",
            "public trust",
            "suitability/fitness determination",
            "federal procurement",
            "saml standard",
            "json web token (jwt)"
        ],
        "cleaned_techs": [
            "centers for medicare and medicaid services",
            "government improper payment programs",
            "state medicaid error rate finding (smerf) system",
            "agile development methodologies",
            "relational database management systems (rdbms)",
            "ms sql server",
            "payment error rate measurement (perm) program",
            "medicaid",
            "chip",
            "public trust",
            "suitability/fitness determination",
            "federal procurement",
            "saml standard",
            "json web token (jwt)"
        ]
    },
    "91841150b9b5499e": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 100000.0,
        "salary_max": 220000.0,
        "title": "Senior Full Stack Software Engineer - Remote",
        "company": "Reality Defender",
        "desc": "About Reality Defender \n \n \n \n  Reality Defender is a groundbreaking security platform offering comprehensive deepfake detection. A Y Combinator graduate, Comcast NBCUniversal LIFT Labs alumni, and winner of SXSW Pitch 2023, Reality Defender's proactive deepfake and AI-generated content detection technology is developed by a leadership team with over 20 years of experience in applied research at the intersection of machine learning, data science, and cybersecurity.\n  \n \n \n  With models defending against present and future fabrication techniques, Reality Defender is the best way to detect and deter fraudulent text, audio, and visual content, partnering with government agencies and enterprise clients to enhance security and detect fraud.\n  \n \n \n  About the Role \n \n \n \n  Are you passionate about leveraging cutting-edge technology to defend against emerging threats in the digital landscape? Do you thrive in a dynamic, collaborative environment where your skills can make a significant impact? If so, we invite you to join Reality Defender, a leading innovator in the field of deep fake detection and misinformation prevention.\n  \n \n \n  Key Responsibilities \n \n \n \n  As a full stack engineer, you will tackle a wide array of intriguing and challenging problems. Key responsibilities include, but are not limited to:\n  \n \n \n  Backend API Design:  Develop robust and secure backend APIs to provide both public interfaces for external applications and internal APIs for our own dashboards. Your role will involve designing APIs that facilitate seamless communication between our deep fake detection algorithms and external applications, ensuring data integrity and security. Internally, you will create APIs that power our own user interfaces, ensuring a smooth user experience for our clients and team.\n  \n \n \n  Backend Testing and Code Coverage:  Write comprehensive tests for the backend infrastructure, ensuring the reliability and stability of our systems. Your responsibility will also include measuring and improving code coverage, ensuring that our tests are thorough and effective in catching potential issues.\n  \n \n \n  Architect Scalable Inference Pipelines:  Your expertise will be pivotal in architecting and optimizing scalable inference pipelines, harnessing the power of multiple GPUs on AWS, Google Cloud, Azure and On-Premises. This involves crafting efficient algorithms, implementing parallel processing techniques, and ensuring seamless integration with our deep fake detection models. Your focus will be on enhancing the speed and accuracy of our detection mechanisms, enabling real-time analysis of vast data sets.\n  \n \n \n  Scalable Preprocessing Pipeline Design and Implementation:  Delve into the intricacies of crafting preprocessing pipelines essential to our deep fake detection systems. You will handle substantial data loads, ensuring seamless flow from diverse sources to our models even under high concurrent request volumes. Building fault-tolerant, high-throughput pipelines is pivotal, enhancing the adaptability of our machine learning algorithms to diverse data sources and emerging misinformation patterns.\n  \n \n \n  Hybrid Cloud Optimization:  Leverage your hybrid cloud expertise to optimize our infrastructure for reliability, scalability, and cost efficiency. You will be responsible for crafting strategies that seamlessly integrate on-premises and cloud-based resources, ensuring our systems operate efficiently across diverse environments. Your role will involve continuous evaluation of cloud services, selecting the best tools for specific tasks, and orchestrating their seamless collaboration.\n  \n \n \n  Frontend Updates:  Contribute to the development of intuitive and visually appealing user interfaces. Collaborate with UI/UX designers to implement frontend updates that enhance user experience, ensuring our clients and internal users have a seamless experience while interacting with our deep fake detection platform.\n  \n \n \n  Collaborative Problem-Solving:  Engage in collaborative problem-solving with cross-functional teams. You will actively participate in brainstorming sessions, contribute innovative ideas, and work closely with machine learning engineers, data scientists and other developers to address complex challenges. Your ability to collaborate effectively will be instrumental in devising comprehensive solutions that encompass both frontend user experiences and backend computational efficiency.\n  \n \n \n  Continuous Learning and Innovation:  Stay at the forefront of technology trends, exploring emerging tools, frameworks, and methodologies. Your curiosity and enthusiasm for learning will drive the innovation engine within our team, ensuring that Reality Defender remains a leader in the field of deep fake detection and misinformation prevention.\n  \n \n \n  Qualifications and Skills \n \n \n \n  If you are a forward-thinking engineer who thrives on challenges and is excited about revolutionizing the landscape of digital security, we invite you to apply. Join us at Reality Defender, where your skills will be honed, your ideas will be valued, and your contributions will shape the future of deep fake detection technologies. Together, we will defend against digital fraud and uphold the integrity of information in the digital age.\n  \n \n \n  We encourage candidates who may not meet all the specified requirements to still apply.  We value diverse perspectives and skills, and believe that unique experiences can contribute significantly to our team. If you are passionate about the role and confident in your ability to make a meaningful impact, we welcome your application. Your enthusiasm, adaptability, and potential for growth are equally important to us.\n  \n \n \n  Basic Requirements: \n \n \n \n  5+ years of professional experience in software development with a bachelor's or master's degree in computer science, engineering, math, or STEM discipline \n \n \n \n  We are unable to engage with firms due to regulatory constraints \n \n \n \n  Preferred Skills and Experience : \n \n \n \n  Proficiency in NodeJs, Typescript, Go and/or Rust with a strong emphasis on scalable software design and efficient data processing \n \n \n \n  Experience in designing and building scalable inference pipelines, preferably in GPU-accelerated environments on cloud platforms \n \n \n \n  Experience working with Docker and Kubernetes \n \n \n \n  Experience with AWS services, especially Lambda, SQS, DynamoDB, RDS, EKS, and ECS. Preferably also multi cloud and on-premises experience \n \n \n \n  Database experience with PostgreSQL, SQL Server, or similar database technologies \n \n \n \n  Writing and consuming REST and GraphQL \n \n \n \n  Experience in frontend technologies, including TypeScript, Remix, Next.js, Remix, Tailwind CSS \n \n \n \n  Strong expertise in implementing intuitive user interfaces and interactive experiences, ensuring seamless user interactions \n \n \n \n  Experience with version control, continuous integration, and continuous delivery concepts \n \n \n \n  Deep understanding of testing, continuous integration, build, deployment & monitoring \n \n \n \n  Expertise in profiling and improving application performance \n \n \n \n  Established skills in strategic and critical thinking, decision-making, and relationship-building \n \n \n \n  Highly organized, detail-oriented, and possess a proven ability to thrive under deadline pressure \n \n \n \n  Successful experience working in a fast-paced, dynamic, results-oriented team environment \n \n \n \n  Additional Requirements :\n  \n \n \n  Willing to work extended hours when needed \n \n \n \n  #LI-Remote",
        "cleaned_desc": " \n \n  Backend Testing and Code Coverage:  Write comprehensive tests for the backend infrastructure, ensuring the reliability and stability of our systems. Your responsibility will also include measuring and improving code coverage, ensuring that our tests are thorough and effective in catching potential issues.\n  \n \n \n  Architect Scalable Inference Pipelines:  Your expertise will be pivotal in architecting and optimizing scalable inference pipelines, harnessing the power of multiple GPUs on AWS, Google Cloud, Azure and On-Premises. This involves crafting efficient algorithms, implementing parallel processing techniques, and ensuring seamless integration with our deep fake detection models. Your focus will be on enhancing the speed and accuracy of our detection mechanisms, enabling real-time analysis of vast data sets.\n  \n \n \n  Scalable Preprocessing Pipeline Design and Implementation:  Delve into the intricacies of crafting preprocessing pipelines essential to our deep fake detection systems. You will handle substantial data loads, ensuring seamless flow from diverse sources to our models even under high concurrent request volumes. Building fault-tolerant, high-throughput pipelines is pivotal, enhancing the adaptability of our machine learning algorithms to diverse data sources and emerging misinformation patterns.\n  \n \n \n  Hybrid Cloud Optimization:  Leverage your hybrid cloud expertise to optimize our infrastructure for reliability, scalability, and cost efficiency. You will be responsible for crafting strategies that seamlessly integrate on-premises and cloud-based resources, ensuring our systems operate efficiently across diverse environments. Your role will involve continuous evaluation of cloud services, selecting the best tools for specific tasks, and orchestrating their seamless collaboration.\n  \n \n \n  Frontend Updates:  Contribute to the development of intuitive and visually appealing user interfaces. Collaborate with UI/UX designers to implement frontend updates that enhance user experience, ensuring our clients and internal users have a seamless experience while interacting with our deep fake detection platform.\n  \n \n \n  Collaborative Problem-Solving:  Engage in collaborative problem-solving with cross-functional teams. You will actively participate in brainstorming sessions, contribute innovative ideas, and work closely with machine learning engineers, data scientists and other developers to address complex challenges. Your ability to collaborate effectively will be instrumental in devising comprehensive solutions that encompass both frontend user experiences and backend computational efficiency.\n  \n \n \n  Continuous Learning and Innovation:  Stay at the forefront of technology trends, exploring emerging tools, frameworks, and methodologies. Your curiosity and enthusiasm for learning will drive the innovation engine within our team, ensuring that Reality Defender remains a leader in the field of deep fake detection and misinformation prevention.\n  \n \n   \n \n  Experience in designing and building scalable inference pipelines, preferably in GPU-accelerated environments on cloud platforms \n \n \n \n  Experience working with Docker and Kubernetes \n \n \n \n  Experience with AWS services, especially Lambda, SQS, DynamoDB, RDS, EKS, and ECS. Preferably also multi cloud and on-premises experience \n \n \n \n  Database experience with PostgreSQL, SQL Server, or similar database technologies \n \n \n \n  Writing and consuming REST and GraphQL \n \n \n \n  Experience in frontend technologies, including TypeScript, Remix, Next.js, Remix, Tailwind CSS \n \n \n \n  Strong expertise in implementing intuitive user interfaces and interactive experiences, ensuring seamless user interactions \n \n \n ",
        "techs": [
            "backend testing and code coverage",
            "architect scalable inference pipelines",
            "scalable preprocessing pipeline design and implementation",
            "hybrid cloud optimization",
            "frontend updates",
            "collaborative problem-solving",
            "continuous learning and innovation",
            "designing and building scalable inference pipelines",
            "docker",
            "kubernetes",
            "aws services (lambda",
            "sqs",
            "dynamodb",
            "rds",
            "eks",
            "ecs)",
            "multi-cloud and on-premises experience",
            "postgresql",
            "sql server",
            "rest",
            "graphql",
            "frontend technologies (typescript",
            "remix",
            "next.js",
            "tailwind css)",
            "expertise in implementing intuitive user interfaces and interactive experiences."
        ],
        "cleaned_techs": [
            "backend testing and code coverage",
            "architect scalable inference pipelines",
            "scalable preprocessing pipeline design and implementation",
            "hybrid cloud optimization",
            "frontend updates",
            "collaborative problem-solving",
            "continuous learning and innovation",
            "designing and building scalable inference pipelines",
            "docker",
            "kubernetes",
            "aws",
            "sqs",
            "dynamodb",
            "rds",
            "eks",
            "ecs)",
            "multi-cloud and on-premises experience",
            "postgresql",
            "sql",
            "rest",
            "graphql",
            "frontend technologies (typescript",
            "remix",
            "next.js",
            "tailwind css)",
            "expertise in implementing intuitive user interfaces and interactive experiences."
        ]
    },
    "182aad49dc53af0d": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Senior Director - ML Engineering",
        "company": "Cisco Systems",
        "desc": "Who We Are \n  \n \n  We are part of the Outshift Group passionate about identifying breakthrough emerging solutions that create new markets and businesses for Cisco. We incubate these new opportunities in partnership with our business groups, partners and other startups. The team also continues to progress Cisco\u2019s important work with Standards bodies and manage research partnerships with leading-edge Universities.\n   \n \n \n \n \n  Our organization is anticipating high growth. We are seeking talent with agility and creativity to explore opportunities and fill in needs as they arise. Applicants should be seeking a flexible role, in which they not only provide leadership in their primary function, but also contribute in meaningful ways to other projects. We are looking for individuals who are excited about adjusting quickly to different domains that may be outside of their normal scope of responsibilities.\n   \n \n \n \n \n  Learn more about us at https://eti.cisco.com.\n   \n \n \n \n \n Who You'll Work With   \n \n \n \n \n  The Outshift team is a highly visible team within Cisco. Outshift focuses on the next wave of innovation by anticipating, investing in, and incubating new technologies and business ventures. As part of the incubation team, you will be responsible for developing new products and bring them to market in a startup-like environment.\n   \n \n \n \n \n What You'll Do   \n \n \n \n \n  In this role you will build and establish AI/ML engineering team. You will be responsible for delivery of new AI/ML products at scale for new markets to drive business growth. As a founding senior leader, you will work across various Cisco teams to create new AI/ML products that make tangible business impacts and contribute to shaping Cisco\u2019s AI strategy for the next decade. Your team will be responsible for evaluation and standardization of AI platform for all AI application development at Cisco.\n   \n \n \n \n \n The Impact You\u2019ll Make   \n \n \n \n \n  If you want the challenge of fast-paced growth, the satisfaction of seeing your thoughtful ideas come to life, and the pride in building a best-in-class data team, this is the place for you. You can help build pioneering full-stack technologies that will create new products by monetizing data.\n   \n \n \n \n \n Your Responsibilities Will Include   \n \n \n \n \n  Build and lead AI/ML engineering team. \n  \n \n  Own end to end delivery of new AI/ML products at scale for new persona and markets to drive business growth. \n  \n \n  Evaluate, perform due diligence, and standardize AI platform for application development. \n  \n \n  Stay updated on emerging technologies and trends in data science and architecture, making informed decisions on technology adoption and investment. \n  \n \n  Collaborate with cross-functional teams, including strategy, marketing, product management, engineering, and sales, to align data initiatives with business objectives.\n   \n \n \n \n \n Minimum Requirements   \n \n \n \n \n  7+ years\u2019 experience in AI, Machines Learning, Automation, Technology Modernization, Generative AI and Cloud development. \n  \n \n  7+ years in a management role leading a team of software engineers, ML engineers, and architects. \n  \n \n  Bachelors degree and 17+ years of Engineering exp OR \n  \n \n  Masters degree and 14+ years of Engineering exp OR \n  \n \n  PhD and 10+ years of Engineering experience\n   \n \n \n \n \n Preferred Requirements   \n \n \n \n \n  Strong leadership skills and the ability to build and lead hard-working teams. \n  \n \n  Extraordinarily resourceful & thorough, you can operate successfully among forward-thinking people. \n  \n \n  Equally comfortable and capable interacting with technologists as with business executives. \n  \n \n  Excellent verbal and written communication skills.\n   \n \n \n \n \n Why Cisco?   \n \n \n \n \n  #WeAreCisco. We are all unique, but collectively we bring our talents to work as a team, to develop innovative technology and power a more inclusive, digital future for everyone. How do we do it? Well, for starters \u2013 with people like you!\n   \n \n \n \n \n  Nearly every internet connection around the world touches Cisco. We\u2019re the Internet\u2019s optimists. Our technology makes sure the data traveling at light speed across connections does so securely, yet it\u2019s not what we make but what we make happen which marks us out. We\u2019re helping those who work in the health service to connect with patients and each other; schools, colleges, and universities to teach in even the most challenging of times. We\u2019re helping businesses of all shapes and sizes to connect with their employees and customers in new ways, providing people with access to the digital skills they need and connecting the most remote parts of the world \u2013 whether through 5G, or otherwise.\n   \n \n \n \n \n  We tackle whatever challenges come our way. We have each other\u2019s backs, we recognize our accomplishments, and we grow together. We celebrate and support one another \u2013 from big and small things in life to big career moments. And giving back is in our DNA (we get 10 days off each year to do just that).\n   \n \n \n \n \n  We know that powering an inclusive future starts with us. Because without diversity and a dedication to equality, there is no moving forward. Our 30 Inclusive Communities, that bring people together around commonalities or passions, are leading the way. Together we\u2019re committed to learning, listening, caring for our communities, whilst supporting the most vulnerable with a collective effort to make this world a better place either with technology, or through our actions.\n   \n \n \n \n \n  So, you have colorful hair? Don\u2019t care. Tattoos? Show off your ink. Like polka dots? That\u2019s cool. Pop culture geek? Many of us are. Passion for technology and world changing? Be you, with us! #WeAreCisco\n   \n \n \n \n \n  #LI-TA2 \n  \n \n  #LI-Remote\n  \n \n \n \n \n Message to applicants applying to work in the U.S.: \n \n \n \n  When available, the salary range posted for this position reflects the projected hiring range for new hire, full-time salaries in U.S. locations, not including equity or benefits. For non-sales roles the hiring ranges reflect base salary only; employees are also eligible to receive annual bonuses. Hiring ranges for sales positions include base and incentive compensation target. Individual pay is determined by the candidate's hiring location and additional factors, including but not limited to skillset, experience, and relevant education, certifications, or training. Applicants may not be eligible for the full salary range based on their U.S. hiring location. The recruiter can share more details about compensation for the role in your location during the hiring process.\n  \n \n  U.S. employees have \n   access  to quality medical, dental and vision insurance, a 401(k) plan with a Cisco matching contribution, short and long-term disability coverage, basic life insurance and numerous wellbeing offerings. Employees receive up to twelve paid holidays per calendar year, which includes one floating holiday, plus a day off for their birthday. Employees accrue up to 20 days of Paid Time Off (PTO) each year and have access to paid time away to deal with critical or emergency issues without tapping into their PTO. We offer additional paid time to volunteer and give back to the community. Employees are also able to purchase company stock through our Employee Stock Purchase Program.\n  \n \n  Employees on sales plans earn performance-based incentive pay on top of their base salary, which is split between quota and non-quota components. For quota-based incentive pay, Cisco pays at the standard rate of 1% of incentive target for each 1% revenue attainment against the quota up to 100%. Once performance exceeds 100% quota attainment, incentive rates may increase up to five times the standard rate with no cap on incentive compensation. For non-quota-based sales performance elements such as strategic sales objectives, Cisco may pay up to 125% of target. Cisco sales plans do not have a minimum threshold of performance for sales incentive compensation to be paid.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "6c693c35654e3237": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 100000.0,
        "salary_max": 200000.0,
        "title": "Senior Forward Deployed Software Engineer - Remote",
        "company": "Reality Defender",
        "desc": "About Reality Defender \n \n \n \n  Reality Defender is a groundbreaking security platform offering comprehensive deepfake detection. A Y Combinator graduate, Comcast NBCUniversal LIFT Labs alumni, and winner of SXSW Pitch 2023, Reality Defender's proactive deepfake and AI-generated content detection technology is developed by a leadership team with over 20 years of experience in applied research at the intersection of machine learning, data science, and cybersecurity.\n  \n \n \n  With models defending against present and future fabrication techniques, Reality Defender is the best way to detect and deter fraudulent text, audio, and visual content, partnering with government agencies and enterprise clients to enhance security and detect fraud.\n  \n \n \n  About the Role \n \n \n \n  Are you motivated by the opportunity to address real-world challenges directly, applying your technical expertise to create a significant impact? Join our innovative team at Reality Defender as a Forward Deployed Software Engineer (FDSE). In this role, you will directly collaborate with our diverse range of clients, understanding their most pressing challenges and crafting tailored detection solutions.\n  \n \n \n  Key Responsibilities \n \n \n \n  As a Forward Deployed Software Engineer, you will play a pivotal role in high-stakes projects, owning end-to-end execution and working in small, dynamic teams. Your responsibilities will include:\n  \n \n \n  Client Collaboration:  Engage directly with clients, understanding their core issues, and collaborating on innovative data and detection solutions. You will communicate complex technical concepts effectively to client executives, ensuring alignment between technical implementations and organizational objectives.\n  \n \n \n  Architectural Design:  Discuss and design robust architectures with fellow engineers. Your role will involve crafting scalable and efficient solutions, leveraging your deep understanding of software engineering principles and data processing techniques while keeping the clients' environment in mind.\n  \n \n \n  Custom Web App Development:  Develop custom web applications tailored to meet specific client requirements. Adapt internally developed solutions to meet clients' needs and continuously contribute to make internal solutions reusable. This role will manage and execute the entire end to end software life cycle. From planning, development to deployment.\n  \n \n \n  Backend API Design:  Help the team to continuously develop robust and secure backend APIs to provide both public interfaces for external applications and internal APIs for our own dashboards. Your role will involve designing APIs that facilitate seamless communication between our deep fake detection algorithms and external applications, ensuring data integrity and security. Internally, you will create APIs that power our own user interfaces, ensuring a smooth user experience for our clients and team.\n  \n \n \n  Strategic Planning:  Collaborate with your team to establish strategic plans, ensuring the successful execution of projects and integrations. Your ability to think critically and strategically will contribute to the formulation of effective project and integration strategies and successful delivery.\n  \n \n \n  Architect Scalable Inference Pipelines:  Your expertise will be pivotal in architecting and optimizing scalable inference pipelines, harnessing the power of multiple GPUs on AWS, Google Cloud, Azure and On-Premises. This involves crafting efficient algorithms, implementing parallel processing techniques, and ensuring seamless integration with our deep fake detection models. Your focus will be on enhancing the speed and accuracy of our detection mechanisms, enabling real-time analysis of vast data sets.\n  \n \n \n  Error Handling:  Develop effective error handling and logging mechanisms to ensure graceful degradation of services during unexpected scenarios. Monitor and analyze logs to proactively identify and address potential issues.\n  \n \n \n  Documentation:  Create and maintain comprehensive technical documentation, including APIs, algorithms, and system architecture. Document code functionalities, usage guidelines, and troubleshooting procedures for reference and knowledge sharing.\n  \n \n \n  Technical Support:  Provide technical support to resolve complex issues escalated from customer support teams. Collaborate with cross-functional teams to diagnose and troubleshoot production incidents.\n  \n \n \n  Collaborative Problem-Solving:  Engage in collaborative problem-solving with cross-functional teams. You will actively participate in brainstorming sessions, contribute innovative ideas, and work closely with machine learning engineers, data scientists and other developers to address complex challenges. Your ability to collaborate effectively will be instrumental in devising comprehensive solutions that encompass both frontend user experiences and backend computational efficiency.\n  \n \n \n  Continuous Learning and Innovation:  Stay at the forefront of technology trends, exploring emerging tools, frameworks, and methodologies. Your curiosity and enthusiasm for learning will drive the innovation engine within our team, ensuring that Reality Defender remains a leader in the field of deep fake detection and misinformation prevention.\n  \n \n \n  Qualifications and Skills \n \n \n \n  If you are a forward-thinking engineer who thrives on challenges and is excited about revolutionizing the landscape of digital security, we invite you to apply. Join us at Reality Defender, where your skills will be honed, your ideas will be valued, and your contributions will shape the future of deep fake detection technologies. Together, we will defend against digital fraud and uphold the integrity of information in the digital age.\n  \n \n \n  We encourage candidates who may not meet all the specified requirements to still apply.  We value diverse perspectives and skills, and believe that unique experiences can contribute significantly to our team. If you are passionate about the role and confident in your ability to make a meaningful impact, we welcome your application. Your enthusiasm, adaptability, and potential for growth are equally important to us.\n  \n \n \n  Basic Requirements \n \n \n \n  5+ years of professional experience in software development with a bachelor's or master's degree in computer science, engineering, math, or STEM discipline \n \n \n \n  We are unable to engage with firms due to regulatory constraints \n \n \n \n  Preferred Skills and Experience \n \n \n \n  Strong communication skills \n \n \n \n  Proficiency in Python, Java, NodeJs, Typescript, Go with a strong emphasis on adapting scalable software solutions to customer needs \n \n \n \n  Experience working with Docker and Kubernetes \n \n \n \n  Experience with AWS, Google Cloud, Azure and On-Premises \n \n \n \n  Database experience with PostgreSQL, SQL Server, NoSQL, or similar database technologies \n \n \n \n  Experience in frontend technologies, like TypeScript, Remix, Next.js, Remix, Tailwind CSS \n \n \n \n  Experience in implementing intuitive user interfaces and interactive experiences, ensuring seamless user interactions \n \n \n \n  Experience with version control, continuous integration, and continuous delivery concepts \n \n \n \n  Deep understanding of testing, continuous integration, build, deployment & monitoring \n \n \n \n  Expertise in profiling and improving application performance \n \n \n \n  Established skills in strategic and critical thinking, decision-making, and relationship-building \n \n \n \n  Highly organized, detail-oriented, and possess a proven ability to thrive under deadline pressure \n \n \n \n  Successful experience working in a fast-paced, dynamic, results-oriented team environment \n \n \n \n  Additional Requirements \n \n \n \n  Willing to work extended hours when needed \n \n \n \n  Willing to occasionally work from or travel to client\u2019s location \n \n \n \n  #LI-Remote",
        "cleaned_desc": "  Architectural Design:  Discuss and design robust architectures with fellow engineers. Your role will involve crafting scalable and efficient solutions, leveraging your deep understanding of software engineering principles and data processing techniques while keeping the clients' environment in mind.\n  \n \n \n  Custom Web App Development:  Develop custom web applications tailored to meet specific client requirements. Adapt internally developed solutions to meet clients' needs and continuously contribute to make internal solutions reusable. This role will manage and execute the entire end to end software life cycle. From planning, development to deployment.\n  \n \n \n  Backend API Design:  Help the team to continuously develop robust and secure backend APIs to provide both public interfaces for external applications and internal APIs for our own dashboards. Your role will involve designing APIs that facilitate seamless communication between our deep fake detection algorithms and external applications, ensuring data integrity and security. Internally, you will create APIs that power our own user interfaces, ensuring a smooth user experience for our clients and team.\n  \n \n \n  Strategic Planning:  Collaborate with your team to establish strategic plans, ensuring the successful execution of projects and integrations. Your ability to think critically and strategically will contribute to the formulation of effective project and integration strategies and successful delivery.\n  \n \n \n  Architect Scalable Inference Pipelines:  Your expertise will be pivotal in architecting and optimizing scalable inference pipelines, harnessing the power of multiple GPUs on AWS, Google Cloud, Azure and On-Premises. This involves crafting efficient algorithms, implementing parallel processing techniques, and ensuring seamless integration with our deep fake detection models. Your focus will be on enhancing the speed and accuracy of our detection mechanisms, enabling real-time analysis of vast data sets.\n  \n \n \n  Error Handling:  Develop effective error handling and logging mechanisms to ensure graceful degradation of services during unexpected scenarios. Monitor and analyze logs to proactively identify and address potential issues.\n  \n \n \n  Documentation:  Create and maintain comprehensive technical documentation, including APIs, algorithms, and system architecture. Document code functionalities, usage guidelines, and troubleshooting procedures for reference and knowledge sharing.\n  \n \n \n  Technical Support:  Provide technical support to resolve complex issues escalated from customer support teams. Collaborate with cross-functional teams to diagnose and troubleshoot production incidents.\n  \n \n    Preferred Skills and Experience \n \n \n \n  Strong communication skills \n \n \n \n  Proficiency in Python, Java, NodeJs, Typescript, Go with a strong emphasis on adapting scalable software solutions to customer needs \n \n \n \n  Experience working with Docker and Kubernetes \n \n \n \n  Experience with AWS, Google Cloud, Azure and On-Premises \n \n \n \n  Database experience with PostgreSQL, SQL Server, NoSQL, or similar database technologies \n \n \n \n  Experience in frontend technologies, like TypeScript, Remix, Next.js, Remix, Tailwind CSS \n \n \n \n  Experience in implementing intuitive user interfaces and interactive experiences, ensuring seamless user interactions \n \n \n ",
        "techs": [
            "architectural design",
            "custom web app development",
            "backend api design",
            "strategic planning",
            "architect scalable inference pipelines",
            "error handling",
            "documentation",
            "technical support",
            "python",
            "java",
            "nodejs",
            "typescript",
            "go",
            "docker",
            "kubernetes",
            "aws",
            "google cloud",
            "azure",
            "on-premises",
            "postgresql",
            "sql server",
            "nosql",
            "typescript",
            "remix",
            "next.js",
            "tailwind css",
            "intuitive user interfaces",
            "interactive experiences"
        ],
        "cleaned_techs": [
            "architectural design",
            "custom web app development",
            "backend api design",
            "strategic planning",
            "architect scalable inference pipelines",
            "error handling",
            "technical support",
            "python",
            "java",
            "nodejs",
            "typescript",
            "go",
            "docker",
            "kubernetes",
            "aws",
            "gcp",
            "azure",
            "on-premises",
            "postgresql",
            "sql",
            "nosql",
            "remix",
            "next.js",
            "tailwind css",
            "intuitive user interfaces",
            "interactive experiences"
        ]
    },
    "f777a182b0aea781": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Insider Threat Analyst (Intelligence Analyst 3)- 16613",
        "company": "HII",
        "desc": "Date:  Oct 18, 2023  \n Location:  Arlington, VA, Virginia, United States  \n Company:  HII's Mission Technologies division  \n \n Requisition Number: 16613 \n Required Travel: 0 - 10% \n Employment Type: Full Time/Salaried/Exempt \n Security Clearance: TS/SCI \n Level of Experience: Mid HI \n \n \n This opportunity resides with  Command, Control, Communications, Computers, Cyber, Intelligence, Surveillance and Reconnaissance (C5ISR) , a business group within HII\u2019s Mission Technologies division. From towers to processors, we design, develop, integrate and manage the sensors, systems and other assets necessary to support integrated intelligence, surveillance and reconnaissance (ISR) operations, exploitation and analysis for the Intelligence Community, the military services, geographic and functional combatant commands and DoD agencies. \n \n \n Meet HII\u2019s Mission Technologies Division  Our team of more than 7,000 professionals worldwide delivers all-domain expertise and advanced technologies in service of mission partners across the globe. Mission Technologies is leading the next evolution of national defense \u2013 the data evolution - by accelerating a breadth of national security solutions for government and commercial customers. Our capabilities range from C5ISR, AI and Big Data, cyber operations and synthetic training environments to fleet sustainment, environmental remediation and the largest family of unmanned underwater vehicles in every class. Find the role that\u2019s right for you. Apply today. We look forward to meeting you. \n \n \n \n  Summary \n \n \n  HII- Mission Technologies is seeking an Insider Threat Analyst to support the DCSA DoD Insider Threat Management Analysis Center (DITMAC)! DITMAC focuses on detecting and responding to behaviors indicative of a potential insider threat. DITMAC informs DoD leaders and the Components to oversee threat mitigation, prepare risk assessments and recommendations, synchronize responses to potential threats, and enable sharing of relevant information. To this end, DITMAC supports the 43 DoD Components by analyzing threats and issues as they occur, promoting best practices, strengthening collaboration and information sharing among Departmental elements, and identifying and helping address systemic insider threat issues. \n \n \n Work performance location is 90% at DCSA\u2019s Crystal City, VA location, and 10% opportunity for remote work. Come join our growing team today! \n \n \n \n \n  What you will do \n \n \n \n Prepare assessments through research and analysis of classified and open-source information \n Collect data using a combination of doctrinal methods and business processes \n Assist with conducting operational readiness exercises as it pertains to receiving and reviewing Insider Threat data and determine if there are additional potential risk indicators (PRI) based on access to Insider Threat databases and Systems \n Analyze information to produce assessments, reports, articles, threat analyses, special studies etc., responsive to user needs, and complying with suspense dates for draft and final products \n Support executing activities to test Insider Threat technologies on a variety of systems. \n Assist in definition of verification methods and procedures for sufficient testing to ensure operational effectiveness, to include data integrity, usability of Insider Threat Systems, trainability, interface conformance, and supportability of current and future Insider Threat capabilities \n Perform Mission Engineering (ME) analyses to guide development, prototyping, and testing to achieve Insider Threat mission and DITMAC needs \n Organize and manage reviews and feedback of system performance, measures of effectiveness, and design characteristics of the data management program \n Organize statistical data for quantitative and qualitative metrics reports, summaries, case studies and trend reports as required \n Analyze requirements concepts, integration, and interoperability of multiple DCSA systems, to identify potential design changes to legacy and emerging systems that may provide operational effectiveness and efficiency benefits \n Other duties as assigned \n \n \n \n \n \n What we are looking for \n \n \n \n 5 years relevant experience with Bachelors in related field; 3 years relevant experience with Masters in related field; 0 years experience with PhD or Juris Doctorate in related field; or High School Diploma or equivalent and 9 years relevant experience \n Familiarity with Intelligence Community Directives 203 (Analytic Standards), 205 (Outreach), 206 (Sourcing), and 208 (Writing for Maximum Utility), template, and SOP standards as appropriate \n Ability to effectively communicate orally and in writing \n Ability to analyze and evaluate, on a quantitative or qualitative basis, the effectiveness of component level reporting in meeting established goals and objectives \n Ability to gather, identify, receive, ingest, examine, integrating data on potential insider threat incidents from various sources following established guidelines, policies, and procedures \n Ability to review and evaluate program progress status, trends in any functions, and goals and objectives \n Ability to prepare responses to queries, reports, justifications, and background papers on insider threat issues \n Ability to plan, organize, develop, coordinate, and represent the DITMAC in briefings with internal and external senior stakeholders to inform them of the progress of initiatives \n Clearance: Must possess and maintain a TS/SCI clearance \n \n \n \n \n \n Bonus points for... \n \n \n \n Records/data management experience \n DCSA/DITMAC experience \n \n \n \n \n \n Physical Requirements \n \n \n     May require working in an office, industrial, shipboard, or laboratory environment. Capable of climbing ladders and tolerating confined spaces and extreme temperature variances.\n     \n \n \n  Why HII  We build the world\u2019s most powerful, survivable naval ships and defense technology solutions that safeguard our seas, sky, land, space and cyber. Our diverse workforce includes skilled tradespeople; artificial intelligence, machine learning (AI/ML) experts; engineers; technologists; scientists; logistics experts; and business administration professionals. \n \n \n Recognized as one of America\u2019s top large company employers, we are a values and ethics driven organization that puts people\u2019s safety and well-being first. Regardless of your role or where you serve, at HII, you\u2019ll find a supportive and welcoming environment, competitive benefits, and valuable educational and training programs for continual career growth at every stage of your career. \n \n \n Together we are working to ensure a future where everyone can be free and thrive.  Today\u2019s challenges are bigger than ever, and the nation needs the best of us. It\u2019s why we\u2019re focused on hiring, developing and nurturing our diversity. We believe that diversity among our workforce strengthens the organization, stimulates creativity, promotes the exchange of ideas and enriches the work lives of all our employees. \n \n \n All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, physical or mental disability, age, or veteran status or any other basis protected by federal, state, or local law. \n \n \n Do You Need Assistance?  If you need a reasonable accommodation for any part of the employment process, please send an e-mail to  buildyourcareer@hii-co.com  and let us know the nature of your request and your contact information. Reasonable accommodations are considered on a case-by-case basis. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this email address. Additionally, you may also call  1-844-849-8463  for assistance. Press #3 for HII Technical Solutions.",
        "cleaned_desc": " Assist in definition of verification methods and procedures for sufficient testing to ensure operational effectiveness, to include data integrity, usability of Insider Threat Systems, trainability, interface conformance, and supportability of current and future Insider Threat capabilities \n Perform Mission Engineering (ME) analyses to guide development, prototyping, and testing to achieve Insider Threat mission and DITMAC needs \n Organize and manage reviews and feedback of system performance, measures of effectiveness, and design characteristics of the data management program \n Organize statistical data for quantitative and qualitative metrics reports, summaries, case studies and trend reports as required \n Analyze requirements concepts, integration, and interoperability of multiple DCSA systems, to identify potential design changes to legacy and emerging systems that may provide operational effectiveness and efficiency benefits \n Other duties as assigned \n \n \n \n \n \n What we are looking for \n \n \n \n 5 years relevant experience with Bachelors in related field; 3 years relevant experience with Masters in related field; 0 years experience with PhD or Juris Doctorate in related field; or High School Diploma or equivalent and 9 years relevant experience \n Familiarity with Intelligence Community Directives 203 (Analytic Standards), 205 (Outreach), 206 (Sourcing), and 208 (Writing for Maximum Utility), template, and SOP standards as appropriate \n Ability to effectively communicate orally and in writing \n Ability to analyze and evaluate, on a quantitative or qualitative basis, the effectiveness of component level reporting in meeting established goals and objectives ",
        "techs": [
            "verification methods and procedures",
            "data integrity",
            "usability of insider threat systems",
            "trainability",
            "interface conformance",
            "supportability",
            "mission engineering (me) analyses",
            "development",
            "prototyping",
            "testing",
            "insider threat mission",
            "ditmac needs",
            "system performance",
            "measures of effectiveness",
            "design characteristics",
            "data management program",
            "statistical data",
            "quantitative metrics reports",
            "qualitative metrics reports",
            "case studies",
            "trend reports",
            "requirements concepts",
            "integration",
            "interoperability",
            "dcsa systems",
            "design changes",
            "legacy systems",
            "emerging systems",
            "operational effectiveness",
            "efficiency benefits",
            "intelligence community directives 203",
            "intelligence community directives 205",
            "intelligence community directives 206",
            "intelligence community directives 208",
            "template",
            "sop standards",
            "communicate orally",
            "communicate in writing",
            "analyze and evaluate",
            "component level reporting",
            "established goals",
            "established objectives"
        ],
        "cleaned_techs": [
            "verification methods and procedures",
            "data integrity",
            "usability of insider threat systems",
            "trainability",
            "interface conformance",
            "supportability",
            "mission engineering (me) analyses",
            "development",
            "prototyping",
            "testing",
            "insider threat mission",
            "ditmac needs",
            "system performance",
            "measures of effectiveness",
            "design characteristics",
            "data management program",
            "statistical data",
            "quantitative metrics reports",
            "qualitative metrics reports",
            "case studies",
            "trend reports",
            "requirements concepts",
            "integration",
            "interoperability",
            "dcsa systems",
            "design changes",
            "legacy systems",
            "emerging systems",
            "operational effectiveness",
            "efficiency benefits",
            "intelligence community directives 203",
            "intelligence community directives 205",
            "intelligence community directives 206",
            "intelligence community directives 208",
            "template",
            "sop standards",
            "communicate orally",
            "communicate in writing",
            "analyze and evaluate",
            "component level reporting",
            "established goals",
            "established objectives"
        ]
    },
    "7dde7bda367a1e02": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 83100.67,
        "salary_max": 105223.97,
        "title": "Engineer Systems 3 (ITSIS)",
        "company": "HII",
        "desc": "Date:  Oct 17, 2023  \n Location:  San Diego, CA, Remote, United States  \n Company:  HII's Mission Technologies division  \n \n \n Requisition Number: 16638 \n Required Travel: 0 - 10% \n Employment Type: Full Time/Salaried/Exempt \n Security Clearance: Secret \n Level of Experience: Mid \n \n \n \n Meet HII\u2019s Mission Technologies Division  Our team of more than 7,000 professionals worldwide delivers all-domain expertise and advanced technologies in service of mission partners across the globe. Mission Technologies is leading the next evolution of national defense \u2013 the data evolution - by accelerating a breadth of national security solutions for government and commercial customers. Our capabilities range from C5ISR, AI and Big Data, cyber operations and synthetic training environments to fleet sustainment, environmental remediation and the largest family of unmanned underwater vehicles in every class. Find the role that\u2019s right for you. Apply today. We look forward to meeting you. \n \n \n \n  Who We Are \n \n \n  HII's System Integration group is seeking a BFTT Systems Engineer to join our Fleet Sustainment group! This is a full-time position location in the Virginia Beach, VA area. As a Systems Engineer you will play a critical role as part of the Integrated Training Systems Installation and Sustainment (ITSIS) support contract for the U.S. Navy. \n \n \n As the top ranked defense contractor on Forbes list of America's Best Large Employers, HII is committed to serving our employees, our communities, our service members, and our nation! We offer competitive bene\ufb01ts, education reimbursement, and professional development opportunities. \n \n \n \n \n  What You Will Do \n \n \n \n Performs technical planning, system integration, verification and validation, cost and risk, and supportability and effectiveness analyses for total systems.   \n Analyses are performed at all levels of total system product to include concept, design, fabrication, test, installation, operation, maintenance and disposal.   \n Ensures the logical and systematic conversion of customer or product requirements into total systems solutions that acknowledge technical, schedule, and cost constraints.   \n Performs functional analysis, timeline analysis, detail trade studies, requirements allocation and interface definition studies to translate customer requirements into hardware and software specifications.   \n \n \n \n \n \n \n What You Must Have \n \n \n \n Must have experience working on Battle Force Tactical Trainer (BFTT) Systems.   \n Knowledge of all phases of systems engineering for the specific purpose of organizing, directing and leading technical efforts in the concept formulation, project planning and project engineering.   \n Have experience in networking standards, architectures, protocols and systems as it applies to training/testing devices, simulation, simulators and instrumentation.   \n Have professional engineering experience in analysis, design, development, integration and test of military systems and knowledgeable in system architecture and domain engineering.   \n Have experience supervising or leading multi-disciplined or matrix teams, with specialized experience in engineering disciplines or technical areas (such as visual, C4I, software, firmware, maintenance management, logistics engineering).   \n Bachelor\u2019s Degree in Engineering, Operations Research, Computer Science, or equivalent.   \n 5 years relevant experience with Bachelors in related field; 3 years relevant experience with Masters in related field; 0 years experience with PhD or Juris Doctorate in related field; or High School Diploma or equivalent and 9 years relevant experience.   \n Must have an Active Secret Clearance   \n \n \n \n \n \n Physical Requirements \n \n \n     Office, industrial, or shipboard environment. Capable of climbing ladders and tolerating confined spaces and extreme temperature variances. Lifting and moving materials may be required.\n     \n \n \n  Why HII  We build the world\u2019s most powerful, survivable naval ships and defense technology solutions that safeguard our seas, sky, land, space and cyber. Our diverse workforce includes skilled tradespeople; artificial intelligence, machine learning (AI/ML) experts; engineers; technologists; scientists; logistics experts; and business administration professionals. \n \n \n Recognized as one of America\u2019s top large company employers, we are a values and ethics driven organization that puts people\u2019s safety and well-being first. Regardless of your role or where you serve, at HII, you\u2019ll find a supportive and welcoming environment, competitive benefits, and valuable educational and training programs for continual career growth at every stage of your career. \n \n \n Together we are working to ensure a future where everyone can be free and thrive.  Today\u2019s challenges are bigger than ever, and the nation needs the best of us. It\u2019s why we\u2019re focused on hiring, developing and nurturing our diversity. We believe that diversity among our workforce strengthens the organization, stimulates creativity, promotes the exchange of ideas and enriches the work lives of all our employees. \n \n \n All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, physical or mental disability, age, or veteran status or any other basis protected by federal, state, or local law. \n \n \n Do You Need Assistance?  If you need a reasonable accommodation for any part of the employment process, please send an e-mail to  buildyourcareer@hii-co.com  and let us know the nature of your request and your contact information. Reasonable accommodations are considered on a case-by-case basis. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this email address. Additionally, you may also call  1-844-849-8463  for assistance. Press #3 for HII Technical Solutions.",
        "cleaned_desc": " \n Must have experience working on Battle Force Tactical Trainer (BFTT) Systems.   \n Knowledge of all phases of systems engineering for the specific purpose of organizing, directing and leading technical efforts in the concept formulation, project planning and project engineering.   \n Have experience in networking standards, architectures, protocols and systems as it applies to training/testing devices, simulation, simulators and instrumentation.   \n Have professional engineering experience in analysis, design, development, integration and test of military systems and knowledgeable in system architecture and domain engineering.   \n Have experience supervising or leading multi-disciplined or matrix teams, with specialized experience in engineering disciplines or technical areas (such as visual, C4I, software, firmware, maintenance management, logistics engineering).   \n Bachelor\u2019s Degree in Engineering, Operations Research, Computer Science, or equivalent.   \n 5 years relevant experience with Bachelors in related field; 3 years relevant experience with Masters in related field; 0 years experience with PhD or Juris Doctorate in related field; or High School Diploma or equivalent and 9 years relevant experience.   \n Must have an Active Secret Clearance   \n \n \n \n \n \n Physical Requirements ",
        "techs": [
            "battle force tactical trainer (bftt) systems",
            "networking standards",
            "architectures",
            "protocols and systems",
            "system architecture and domain engineering."
        ],
        "cleaned_techs": [
            "battle force tactical trainer (bftt) systems",
            "networking standards",
            "architectures",
            "protocols and systems",
            "system architecture and domain engineering."
        ]
    },
    "ee6c27d141d02f1e": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 93300.0,
        "salary_max": 212000.0,
        "title": "Azure Data Architect",
        "company": "Booz Allen Hamilton",
        "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Springfield,VA,US \n         \n \n \n \n         Remote Work: \n         \n \n         Yes \n         \n \n \n \n         Job Number: \n         \n \n         R0182442\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Azure Data Architect\n           Key Role: \n  Lead data architecture design to transform Oracle DB to Azure Synapse, manage SQL and Azure services stack, and move from traditional data warehouse to data mesh architecture. Provide data architectural planning for data management platform and solution modernization and conduct implementation roadmap planning. Design and document Agile User Stories with the technical specifications and architectural design documentation, such as pseudo code needed for the data engineering and ETL team to deploy. Sequence technical architecture task and activities as part of backlog development and Sprint planning and coordinate with the lead data architect, solutions architect, and Booz Allen internal firm technical experts as needed to execute the modernization vision communicated to our clients. \n \n  Basic Qualifications: \n \n  10+ years of experience with requirements analysis and solution architecture design \n  10+ years of experience with ETL, data integration, dimensional modelling, and data warehouse design \n  10+ years of experience conducting data profiling, cataloging, and mapping for technical design and construction of technical data flow \n  8+ years of experience working with clients to identify, document, and translate their business strategy and requirements into solutions and services \n  5+ years of experience architecting and delivering solutions using the Azure Data Analytics platform, including Azure Data Factory, Azure Logic Apps, Azure Functions, Azure Storage, Azure SQL Data Warehouse, Azure Data Lake, Azure Synapse Analytics, Azure Search, or Azure Stream Analytics \n  5+ years of experience designing and implementing machine learning solutions as part of high-volume data ingestion and transformation pipelines \n  Experience implementing data architectures, such as data mesh or data vault 2.0, and exposing data to end-users via Power BI or Azure API Apps \n  Knowledge of concepts, such as Data Lake house and medallion design, integration tools, such as Informatica Power Center or SSIS, and databases, such as Oracle, Postgres, and SQL Server \n  DHS Suitability \n  Bachelor's degree in Computer Science or a technical field \n \n \n  Additional Qualifications: \n \n  Experience working in a DevOps environment \n  Experience with Azure ARM templates, PowerShell, and CI/CD using Azure DevOps or GitHub Actions \n  Experience on an Agile delivery team \n  Experience with Jira or Confluence collaboration tools \n  Experience on Business Intelligence programs \n  Experience working with Federal Government clients \n  Experience working with data types, including workforce, human capital, procurement, acquisitions, real property, personal property, security, logical or physical access \n  Microsoft Certified: Azure Data Engineer Associate Certification \n \n \n  Vetting: \n  Applicants selected will be subject to a government investigation and may need to meet eligibility requirements of the U.S. government client; DHS suitability is required. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $93,300.00 to $212,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",
        "cleaned_desc": " \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Azure Data Architect\n           Key Role: \n  Lead data architecture design to transform Oracle DB to Azure Synapse, manage SQL and Azure services stack, and move from traditional data warehouse to data mesh architecture. Provide data architectural planning for data management platform and solution modernization and conduct implementation roadmap planning. Design and document Agile User Stories with the technical specifications and architectural design documentation, such as pseudo code needed for the data engineering and ETL team to deploy. Sequence technical architecture task and activities as part of backlog development and Sprint planning and coordinate with the lead data architect, solutions architect, and Booz Allen internal firm technical experts as needed to execute the modernization vision communicated to our clients. \n    Basic Qualifications: \n \n  10+ years of experience with requirements analysis and solution architecture design \n  10+ years of experience with ETL, data integration, dimensional modelling, and data warehouse design \n  10+ years of experience conducting data profiling, cataloging, and mapping for technical design and construction of technical data flow \n  8+ years of experience working with clients to identify, document, and translate their business strategy and requirements into solutions and services \n  5+ years of experience architecting and delivering solutions using the Azure Data Analytics platform, including Azure Data Factory, Azure Logic Apps, Azure Functions, Azure Storage, Azure SQL Data Warehouse, Azure Data Lake, Azure Synapse Analytics, Azure Search, or Azure Stream Analytics \n  5+ years of experience designing and implementing machine learning solutions as part of high-volume data ingestion and transformation pipelines \n  Experience implementing data architectures, such as data mesh or data vault 2.0, and exposing data to end-users via Power BI or Azure API Apps \n  Knowledge of concepts, such as Data Lake house and medallion design, integration tools, such as Informatica Power Center or SSIS, and databases, such as Oracle, Postgres, and SQL Server \n  DHS Suitability \n  Bachelor's degree in Computer Science or a technical field \n \n \n  Additional Qualifications: \n \n  Experience working in a DevOps environment \n  Experience with Azure ARM templates, PowerShell, and CI/CD using Azure DevOps or GitHub Actions ",
        "techs": [
            "azure synapse",
            "sql",
            "azure data factory",
            "azure logic apps",
            "azure functions",
            "azure storage",
            "azure sql data warehouse",
            "azure data lake",
            "azure synapse analytics",
            "azure search",
            "azure stream analytics",
            "power bi",
            "azure api apps",
            "informatica power center",
            "ssis",
            "oracle",
            "postgres",
            "sql server",
            "azure arm templates",
            "powershell",
            "azure devops",
            "github actions."
        ],
        "cleaned_techs": [
            "azure",
            "sql",
            "powerbi",
            "informatica power center",
            "ssis",
            "oracle",
            "postgres",
            "powershell",
            "github actions."
        ]
    },
    "f65257542c684c2b": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Chief Technology Officer (CTO) \u2013 Equity Based",
        "company": "Inteliparent LLC",
        "desc": "Chief Technology Officer (CTO) \u2013 Equity Based Compensation \n InteliParent is looking for a passionate, innovative and seasoned technology leader to join our mission to improve the mental health of parents and children everywhere. This role will be crucial to building products that are technologically advanced, intuitive to use, valuable and delights the consumer. As the CTO you will play a pivotal role in laying the very foundation of our company, helping to sculpt its identity and chart its course to success. This role is not compensated; however, equity will be provided upon the achievement of set objectives. \n About Us: \n InteliParent is a company with a heartfelt dedication to leverage today\u2019s technology to gift the ability to parent with confidence and raise thriving children by focusing on the parent\u2019s and child\u2019s mental health needs. We are more than just a company; we are a partner in the extraordinary journey of parenthood. \n Our approach is to do so by designing and deploying impactful digital products that are: \n \n parent and child centered \n hyper-personalized \n science-backed, by leveraging research available to-date and a network of specialized clinicians \n AI-powered \n \n Given that we are building solutions to some of the most critical challenges faced by society today (declining mental health of parents and children), we believe that it is paramount to approach our work with: honesty, love, empowerment, fairness, respect, a learning mindset, teamwork and gratitude. \n About the  Chief Technology Officer at InteliParent  Role: \n \n Recruit and manage the technical team, including engineers (in-house or contractor) \n Effectively partner with the CEO/Founder to set the company\u2019s technology vision and strategy \n Lead the development and launch of new products and features \n Stay up-to-date on the latest advancements in AI and machine learning \n Effectively manage relationships with partners and vendors, as needed \n \n MUST-HAVE EXPERIENCE & SKILLS:  \n \n Excellent leadership and interpersonal skills, with a record of effectively leading and partnering with technical teams, including developers, data scientists, and engineers. \n Exceptional communication skills, including communicating clearly and effectively, and able to simplify complex tech concepts for diverse stakeholders (non-technical). \n Proven record of strategic and innovative thinking, with the ability to align technical decisions with the company's short and long-term goals. \n A proven record as CTO or similar leadership role, developing and launching successful AI-powered mobile apps at scale (large datasets, training machine learning models). \n Strong technical background in app development, AI technologies (generative AI, NLP, LLMs, and machine learning); and familiarity with popular AI frameworks and libraries. \n Ability to lead the design of scalable and robust technical architectures. \n Understanding of cybersecurity best practices to anticipate and identify potential tech vulnerabilities and strengthen our infrastructure with robust security measures. \n Familiarity with data privacy regulations (e.g., GDPR, CCPA). \n Knowledge of cloud computing platforms (e.g., AWS, Azure, GCP). \n \n ADDITIONAL DESIRED EXPERIENCE \n \n Prior experience in a startup environment, including the ability to tackle complex, uncertain problems and make informed decisions in ambiguous situations; take calculated risks. \n Prior experience with: \n Programming languages: Python, R, C++, Java, and Scala \n Machine learning frameworks: TensorFlow, PyTorch, and scikit-learn \n Big data processing tools: Hadoop, Spark, and Hive \n Data visualization tools: Tableau, Power BI, and Matplotlib \n \n \n A deep understanding of the R&D process. \n Experience with creating patentable technologies and a track record of innovating and developing unique products or features. \n Experience in fundraising, securing venture capital, or managing investor relationships. \n Prior experience in the health and wellness industry. \n Connections or partnerships within the health and wellness industry. \n \n Our Commitment to You and Why You Should Join Us \n \n An opportunity to make a major impact to a critical issue today: the increased need for a solution to support the mental health of parents and their children. \n Freedom and accountability to develop life-changing consumer products in an industry with tremendous opportunities and demand. \n A pivotal role in laying the very foundation of our company, helping to sculpt its identity and chart its course to success. \n Work with supportive, passionate and dedicated people, and build a company with an amazing culture and vision. \n Flexible schedule. \n Equity as part of the founding team. \n \n Job Types: Part-time, Contract. Likely will change to Full-time as the company grows. \n Work Location: Remote; however, InteliParent is based out of the Washington D.C. area. \n To Apply : \n We are looking to build the best team and a 200 years old company! If this sounds like an amazing opportunity for you (and it is!), send us your resume and cover letter to  info@ InteliParent.com . \n Job Type: Contract \n Benefits: \n \n Flexible schedule \n \n Experience: \n \n IT management: 1 year (Preferred) \n Technology management: 1 year (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": " Recruit and manage the technical team, including engineers (in-house or contractor) \n Effectively partner with the CEO/Founder to set the company\u2019s technology vision and strategy \n Lead the development and launch of new products and features \n Stay up-to-date on the latest advancements in AI and machine learning \n Effectively manage relationships with partners and vendors, as needed \n \n MUST-HAVE EXPERIENCE & SKILLS:  \n \n Excellent leadership and interpersonal skills, with a record of effectively leading and partnering with technical teams, including developers, data scientists, and engineers. \n Exceptional communication skills, including communicating clearly and effectively, and able to simplify complex tech concepts for diverse stakeholders (non-technical). \n Proven record of strategic and innovative thinking, with the ability to align technical decisions with the company's short and long-term goals. \n A proven record as CTO or similar leadership role, developing and launching successful AI-powered mobile apps at scale (large datasets, training machine learning models). \n Strong technical background in app development, AI technologies (generative AI, NLP, LLMs, and machine learning); and familiarity with popular AI frameworks and libraries. \n Ability to lead the design of scalable and robust technical architectures.   Understanding of cybersecurity best practices to anticipate and identify potential tech vulnerabilities and strengthen our infrastructure with robust security measures. \n Familiarity with data privacy regulations (e.g., GDPR, CCPA). \n Knowledge of cloud computing platforms (e.g., AWS, Azure, GCP). \n \n ADDITIONAL DESIRED EXPERIENCE \n \n Prior experience in a startup environment, including the ability to tackle complex, uncertain problems and make informed decisions in ambiguous situations; take calculated risks. \n Prior experience with: \n Programming languages: Python, R, C++, Java, and Scala \n Machine learning frameworks: TensorFlow, PyTorch, and scikit-learn \n Big data processing tools: Hadoop, Spark, and Hive \n Data visualization tools: Tableau, Power BI, and Matplotlib \n \n ",
        "techs": [
            "recruit and manage the technical team",
            "ceo/founder",
            "development and launch of new products and features",
            "ai",
            "machine learning",
            "relationships with partners and vendors",
            "leadership",
            "interpersonal skills",
            "developers",
            "data scientists",
            "engineers",
            "strategic and innovative thinking",
            "cto",
            "ai-powered mobile apps",
            "large datasets",
            "training machine learning models",
            "app development",
            "generative ai",
            "nlp",
            "llms",
            "machine learning",
            "ai frameworks",
            "technical architectures",
            "cybersecurity",
            "data privacy regulations",
            "cloud computing platforms",
            "startup environment",
            "programming languages",
            "tensorflow",
            "pytorch",
            "scikit-learn",
            "hadoop",
            "spark",
            "hive",
            "data visualization tools",
            "tableau",
            "power bi",
            "matplotlib"
        ],
        "cleaned_techs": [
            "recruit and manage the technical team",
            "ceo/founder",
            "development and launch of new products and features",
            "ai",
            "relationships with partners and vendors",
            "leadership",
            "developers",
            "data scientists",
            "engineers",
            "strategic and innovative thinking",
            "cto",
            "large datasets",
            "training machine learning models",
            "app development",
            "generative ai",
            "nlp",
            "llm",
            "technical architectures",
            "cybersecurity",
            "data privacy regulations",
            "cloud computing platforms",
            "startup environment",
            "programming languages",
            "tensorflow",
            "pytorch",
            "scikit-learn",
            "hadoop",
            "spark",
            "hive",
            "data visualization tools",
            "tableau",
            "powerbi",
            "matplotlib"
        ]
    },
    "4f2c6352b6618929": {
        "terms": [
            "machine learning engineer",
            "mlops"
        ],
        "salary_min": 180250.0,
        "salary_max": 208300.0,
        "title": "Staff Engineer, DevOps",
        "company": "Valo Health",
        "desc": "About Us \n  Valo Health is a technology company that is integrating human-centric data and AI-powered technology to accelerate the creation of life-changing drugs for more patients faster. Valo was created with the belief that the drug discovery and development process can and should be faster and less expensive, with a much higher probability of success. We are using models early to fail less often, executing clinical trials to add valuation to the company, and generating fit-for-purpose data to feed back into Valo's Opal Computational Platform\u2122 as we reinvent drug discovery and development from the ground up. Disease doesn't wait, so neither can we. \n  We are a multi-disciplinary team of experts in science, technology, and pharmaceuticals united in our mission to achieve better drugs for patients faster. Valo is committed to hiring diverse talent, prioritizing growth and development, fostering an inclusive environment, and creating opportunities to bring together a group of different experiences, backgrounds, and voices to work together. We achieve the widest-ranging impact when we leverage our broad backgrounds and perspectives to accelerate a new frontier in health. Valo seeks to become the catalyst for the pharmaceutical industry and drive the digital transformation of the industry. Are you ready to join us? \n  About the Role \n  We are looking for DevOps engineers to help manage the AWS Cloud infrastructure for our Data Science and Machine Learning environments. A successful candidate should be equally adept in handling day-to-day problems encountered by our users, as well as able to see the larger picture and change our infrastructure to lower our overall operational costs and improve user experience. \n  What You'll Do\u2026 \n \n Handle a ticket duty to resolve user problems in an AWS Cloud Environment. \n Able to extract the general shapes of problems based on ad hoc tasks and find a technical path to automate away repetitive tasks and/or create tools and processes to allow self-service by users to decrease user burden. \n \n What You Bring... \n \n Proficient in Python, and shell scripting \n Proficient in administering AWS environments: Linux EC2 instances, EKS clusters, and general networking and security best practices. \n Comfortable with Software Engineering best practices such as the use of source control systems (specifically Git), code review, automated testing, and CI/CD pipelines \n Experience with GitLab, including the deployment and administration of a self-managed GitLab server (with GitLab CI) \n Familiar with automation of cloud deployment and blueprints (e.g. Terraform, Pulumi) \n \n Salary \n  Base Salary: $180,250 to $208,300   This range represents the low and high end of the anticipated annual base salary range for the San Francisco based position. The actual annual base salary will depend on numerous factors such as: experience, knowledge, skills, and if the location of the job changes. \n  More on Valo \n  Valo Health, Inc (\"Valo\") is a technology company built to transform the drug discovery and development process using human-centric data and artificial intelligence-driven computation. As a digitally native company, Valo aims to fully integrate human-centric data across the entire drug development life cycle into a single unified architecture, thereby accelerating the discovery and development of life-changing drugs while simultaneously reducing costs, time, and failure rates. The company's Opal Computational Platform\u2122 is an integrated set of capabilities designed to transform data into valuable insights that may accelerate discoveries and enable Valo to advance a robust pipeline of programs across cardiovascular metabolic renal, oncology, and neurodegenerative disease. Founded by Flagship Pioneering and headquartered in Boston, MA, Valo also has offices in Lexington, MA, and New York. To learn more, visit www.valohealth.com.",
        "cleaned_desc": " Proficient in Python, and shell scripting \n Proficient in administering AWS environments: Linux EC2 instances, EKS clusters, and general networking and security best practices. \n Comfortable with Software Engineering best practices such as the use of source control systems (specifically Git), code review, automated testing, and CI/CD pipelines \n Experience with GitLab, including the deployment and administration of a self-managed GitLab server (with GitLab CI) ",
        "techs": [
            "python",
            "shell scripting",
            "linux ec2 instances",
            "eks clusters",
            "git",
            "gitlab",
            "ci/cd pipelines"
        ],
        "cleaned_techs": [
            "python",
            "shell scripting",
            "linux ec2 instances",
            "eks clusters",
            "git",
            "gitlab",
            "ci/cd pipelines"
        ]
    },
    "ad7e48ef07263f75": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 134044.98,
        "salary_max": 169730.83,
        "title": "Cloud Architect",
        "company": "GAMA-1 Technologies",
        "desc": "GAMA-1 Technologies, LLC seeks a highly experienced Remote Cloud Computing Specialist to support our growing Cloud Services practice. In particular, the successful candidate will help drive GAMA-1\u2019s efforts to support Office of Water Prediction develop, implement and maintain solutions in the AWS public cloud to manage Hydrologic Visualizations and Inundation Services, simply known as HydroVIS. The HydroVIS framework allows synthesis of a large quantity of National Water Model (NWM) output and provision of decision support tools in the form of Map Services that allow users to quickly identify areas of potential flooding. Along with a spatial display of the model output, HydroVIS provides important details about the timing, magnitude, and probability of potential flood events. The many off-the-shelf services provided by AWS, such as S3 buckets, SNS Topics, Lambda functions, Postgres Databases and EC2 machines, enable OWP to create a framework that organizes the flow of the NWM data and provides hourly updates to the dynamic Map Services. \n  The candidate must have extensive experience architecting and provisioning enterprise-level Cloud services, including Infrastructure as a Service (IaaS), Platform as a Service (PaaS), and Software as a Service (SaaS). \n  Supervisory Responsibilities: \n \n  This position is directly responsible for leading, directing, and managing all HydroVIS Infrastructure and Architecture personnel and consultants. \n \n  Duties/Responsibilities: \n  The Cloud Solutions Architect will support NWS/OWP/HydroVIS services which generate and provide data to a global stakeholder community. These systems and services are deemed mission-critical technologies that receive, process, disseminate, store, and archive petabytes of environmental data and information collected from OWP\u2019s Geo-Intelligence Division (GID) which is responsible for providing centralized and consistent data services, geospatial analyses, and cartographic expertise to support science and engineering development, systems implementation, and water resources operations at local, regional, national and global scales. \n  The Cloud Solutions Architect will provide guidance and subject matter expertise in all aspects of network solutions within HydroVIS AWS cloud environment. These services will support the assessment of network cloud applications. \n \n  Evaluate and recommend best-fit, commercially available, and FEDRAMP-compliant cloud services utilizing various cloud models (i.e., public, private, hybrid) to support NOAA\u2019s mission and specific business, technical, and security requirements. \n  Support cloud optimization activities; performance and cost \n  Develops architecture solutions and evaluates alternatives for private, public, and hybrid cloud models, including IaaS, PaaS, and other cloud services. \n  Researches and recommends cloud architecture to enhance internal and external platforms, tools, and systems. \n  Develop architectural strategies/solutions to ensure application high availability in both hybrid (on-premise / cloud) and fully cloud-hosted applications to provide an \u2018always on\u2019 experience \n  Acts as a subject matter expert for end-to-end cloud architecture, including current and future providers, networking, provisioning, and management. \n  Defines optimal design patterns and solutions for high availability and disaster recovery for applications. \n  Ensures delivered solutions are realized in the time frame committed; works with project owners to size, scope, and identify risk. \n  Provides technical expertise in diagnosing and resolving an issue, including determining and providing workaround solutions or escalation to owners. \n  Ensures delivered solutions meet technical and functional/non-functional performance requirements within. \n  Evaluate, design, and implement solutions for migrating on-premise applications to cloud hosting solutions \n  Design, architect, and integrate cloud capabilities using FEDRAMP-certified leading cloud providers that include Azure, AWS, and GCP. \n  Apply technical knowledge and customer insights to create a modernization roadmap and architect solutions to meet business and IT needs, ensuring technical viability of new projects and successful deployments, orchestrating essential resources, and infusing key infrastructure technologies (e.g. Windows and Linux IaaS, Security, Management, Storage, Networking) \n  Provide high-level cost and resource estimates for Infrastructure as a Service (IaaS), Platform as a Service (PaaS), and Software as Service (SaaS) offerings \n  Use a standardized process for mapping business needs to available cloud technology options, including assessment of risks and possible mitigations \n  Architect, engineer, and deploy/provision secure and robust cloud services that include IaaS, PaaS, and SaaS and support service quality, outage management, subscription management, correlation of usage and charges, and cost-efficient solution architecture. \n  Use architectural design principles to develop robust, efficient, and secure cloud solutions based on customer requirements. \n  Provide implementation guidance/support to the customer throughout the project life cycle. \n  Develop tools and documentation to enable support organizations to resolve customer issues, including complex technical scenarios dealing with the cloud architecture. \n \n  Required Skills/Abilities: \n  The successful candidate must be self-driven and possess the analytical skills to resolve challenging technical issues, often through collaboration with other technical subject matter experts. The candidate will serve as a technical resource to the team regarding cloud engineering, security, performance, deployment, and troubleshooting. The candidate must demonstrate the ability to think strategically about the customer\u2019s business needs and requirements, propose and architect appropriate solutions, and solve technical challenges. \n \n  In-depth understanding of cloud computing technologies, IT business drivers, and emerging computing trends and technologies. \n  Experience and understanding of large-scale infrastructure deployments in enterprise-wide environments required \n  Proven track record of building deep technical relationships with senior IT executives and growing data services in mission-critical/significant or highly strategic accounts \n  Extensive experience gathering business and technical requirements for Cloud Services-based services and applications \n  Extensive experience analyzing the customer\u2019s current infrastructure and applications, developing alternatives analysis for migrating to the cloud, and making recommendations on best-fit cloud solutions and service providers \n  In-depth working knowledge of FEDRAMP and extensive experience applying best practices for building/deploying secure and reliable services and applications on FEDRAMP-compliant Cloud platforms \n  Must possess an in-depth understanding of networking principles and technologies and cloud security practices. \n  Experience using coding languages such as Perl, Java, PowerShell, PHP, Ruby, Python, etc. \n  Experience architecting and building scalable, automated infrastructure \n  Experience with Amazon Web Services, code-defined infrastructure, configuration management tools, and CI/CD \n  Experience with AWS Lambda and \u201cServerless\u201d systems \n  Experience in large-scale enterprise IT environments \n  Experience in a consultative, client-facing consulting role \n  Understanding of load balancing, geo-redundancy, CDN, and VPN technologies. \n  Knowledge of Cloud Architecture patterns and strategies (including IaaS, PaaS, Security, Compute, Storage and networking) \n  Functional knowledge of Infrastructure as Code \u2013 Automation using Ansible, Chef, Puppet Powershell, Terraform, etc. \n  Experience in high-performance computing (HPC) and clusters, machine learning, artificial intelligence (ai) applications, and frameworks in a cloud environment \n  Excellent written, verbal, and analytical skills \n  Ability to obtain a Public Trust Clearance \n \n  Education and Experience: \n \n  BS/BA in Computer Science or related discipline \n  Preferred Certifications:  AWS Certified Solutions Architect \u2013 Associate; Microsoft Azure Architect Technologies; Architect with Google Cloud Platform: Infrastructure \n  8+ years of experience architecting and engineering enterprise Cloud Services (Iaas, PaaS, SaaS) using leading cloud providers such as AWS, GCP, and Azure. It must include networking, computing, storage, database, identity management/access control, monitoring, etc. \n  8+ years of experience migrating on-premise workloads to the public or hybrid cloud environments and deploying cloud-ready applications. \n \n  ABOUT GAMA-1 \n  GAMA-1 is a rapidly growing technology business that is based in Greenbelt, Maryland. GAMA-1 Technologies provides strategic information assurance, information security, and business enterprise and networking solutions to the Federal Government. Our success is based on the utilization of industry and agency standards, establishment of standardized processes, and IT Services expertise. At GAMA-1, we believe employees should grow, achieve, and develop just as the company grows, achieves, and develops. GAMA-1 is committed to providing our employees with opportunities for career advancement throughout their employment. For more information, visit www.gama1tech.com \n  GAMA-1 is an Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. \n   \n ASKOUkiGyl",
        "cleaned_desc": "GAMA-1 Technologies, LLC seeks a highly experienced Remote Cloud Computing Specialist to support our growing Cloud Services practice. In particular, the successful candidate will help drive GAMA-1\u2019s efforts to support Office of Water Prediction develop, implement and maintain solutions in the AWS public cloud to manage Hydrologic Visualizations and Inundation Services, simply known as HydroVIS. The HydroVIS framework allows synthesis of a large quantity of National Water Model (NWM) output and provision of decision support tools in the form of Map Services that allow users to quickly identify areas of potential flooding. Along with a spatial display of the model output, HydroVIS provides important details about the timing, magnitude, and probability of potential flood events. The many off-the-shelf services provided by AWS, such as S3 buckets, SNS Topics, Lambda functions, Postgres Databases and EC2 machines, enable OWP to create a framework that organizes the flow of the NWM data and provides hourly updates to the dynamic Map Services. \n  The candidate must have extensive experience architecting and provisioning enterprise-level Cloud services, including Infrastructure as a Service (IaaS), Platform as a Service (PaaS), and Software as a Service (SaaS). \n  Supervisory Responsibilities: \n \n  This position is directly responsible for leading, directing, and managing all HydroVIS Infrastructure and Architecture personnel and consultants. \n \n  Duties/Responsibilities: \n  The Cloud Solutions Architect will support NWS/OWP/HydroVIS services which generate and provide data to a global stakeholder community. These systems and services are deemed mission-critical technologies that receive, process, disseminate, store, and archive petabytes of environmental data and information collected from OWP\u2019s Geo-Intelligence Division (GID) which is responsible for providing centralized and consistent data services, geospatial analyses, and cartographic expertise to support science and engineering development, systems implementation, and water resources operations at local, regional, national and global scales. \n  The Cloud Solutions Architect will provide guidance and subject matter expertise in all aspects of network solutions within HydroVIS AWS cloud environment. These services will support the assessment of network cloud applications. \n \n  Evaluate and recommend best-fit, commercially available, and FEDRAMP-compliant cloud services utilizing various cloud models (i.e., public, private, hybrid) to support NOAA\u2019s mission and specific business, technical, and security requirements. \n  Support cloud optimization activities; performance and cost    Develops architecture solutions and evaluates alternatives for private, public, and hybrid cloud models, including IaaS, PaaS, and other cloud services. \n  Researches and recommends cloud architecture to enhance internal and external platforms, tools, and systems. \n  Develop architectural strategies/solutions to ensure application high availability in both hybrid (on-premise / cloud) and fully cloud-hosted applications to provide an \u2018always on\u2019 experience \n  Acts as a subject matter expert for end-to-end cloud architecture, including current and future providers, networking, provisioning, and management. \n  Defines optimal design patterns and solutions for high availability and disaster recovery for applications. \n  Ensures delivered solutions are realized in the time frame committed; works with project owners to size, scope, and identify risk. \n  Provides technical expertise in diagnosing and resolving an issue, including determining and providing workaround solutions or escalation to owners. \n  Ensures delivered solutions meet technical and functional/non-functional performance requirements within. \n  Evaluate, design, and implement solutions for migrating on-premise applications to cloud hosting solutions \n  Design, architect, and integrate cloud capabilities using FEDRAMP-certified leading cloud providers that include Azure, AWS, and GCP. \n  Apply technical knowledge and customer insights to create a modernization roadmap and architect solutions to meet business and IT needs, ensuring technical viability of new projects and successful deployments, orchestrating essential resources, and infusing key infrastructure technologies (e.g. Windows and Linux IaaS, Security, Management, Storage, Networking) \n  Provide high-level cost and resource estimates for Infrastructure as a Service (IaaS), Platform as a Service (PaaS), and Software as Service (SaaS) offerings    Use a standardized process for mapping business needs to available cloud technology options, including assessment of risks and possible mitigations \n  Architect, engineer, and deploy/provision secure and robust cloud services that include IaaS, PaaS, and SaaS and support service quality, outage management, subscription management, correlation of usage and charges, and cost-efficient solution architecture. \n  Use architectural design principles to develop robust, efficient, and secure cloud solutions based on customer requirements. \n  Provide implementation guidance/support to the customer throughout the project life cycle. \n  Develop tools and documentation to enable support organizations to resolve customer issues, including complex technical scenarios dealing with the cloud architecture. \n \n  Required Skills/Abilities: \n  The successful candidate must be self-driven and possess the analytical skills to resolve challenging technical issues, often through collaboration with other technical subject matter experts. The candidate will serve as a technical resource to the team regarding cloud engineering, security, performance, deployment, and troubleshooting. The candidate must demonstrate the ability to think strategically about the customer\u2019s business needs and requirements, propose and architect appropriate solutions, and solve technical challenges. \n \n  In-depth understanding of cloud computing technologies, IT business drivers, and emerging computing trends and technologies. \n  Experience and understanding of large-scale infrastructure deployments in enterprise-wide environments required \n  Proven track record of building deep technical relationships with senior IT executives and growing data services in mission-critical/significant or highly strategic accounts    Extensive experience gathering business and technical requirements for Cloud Services-based services and applications \n  Extensive experience analyzing the customer\u2019s current infrastructure and applications, developing alternatives analysis for migrating to the cloud, and making recommendations on best-fit cloud solutions and service providers \n  In-depth working knowledge of FEDRAMP and extensive experience applying best practices for building/deploying secure and reliable services and applications on FEDRAMP-compliant Cloud platforms \n  Must possess an in-depth understanding of networking principles and technologies and cloud security practices. \n  Experience using coding languages such as Perl, Java, PowerShell, PHP, Ruby, Python, etc. \n  Experience architecting and building scalable, automated infrastructure \n  Experience with Amazon Web Services, code-defined infrastructure, configuration management tools, and CI/CD \n  Experience with AWS Lambda and \u201cServerless\u201d systems \n  Experience in large-scale enterprise IT environments \n  Experience in a consultative, client-facing consulting role \n  Understanding of load balancing, geo-redundancy, CDN, and VPN technologies. \n  Knowledge of Cloud Architecture patterns and strategies (including IaaS, PaaS, Security, Compute, Storage and networking)    Functional knowledge of Infrastructure as Code \u2013 Automation using Ansible, Chef, Puppet Powershell, Terraform, etc. \n  Experience in high-performance computing (HPC) and clusters, machine learning, artificial intelligence (ai) applications, and frameworks in a cloud environment \n  Excellent written, verbal, and analytical skills \n  Ability to obtain a Public Trust Clearance \n \n  Education and Experience: \n \n  BS/BA in Computer Science or related discipline \n  Preferred Certifications:  AWS Certified Solutions Architect \u2013 Associate; Microsoft Azure Architect Technologies; Architect with Google Cloud Platform: Infrastructure \n  8+ years of experience architecting and engineering enterprise Cloud Services (Iaas, PaaS, SaaS) using leading cloud providers such as AWS, GCP, and Azure. It must include networking, computing, storage, database, identity management/access control, monitoring, etc. \n  8+ years of experience migrating on-premise workloads to the public or hybrid cloud environments and deploying cloud-ready applications. \n ",
        "techs": [
            "gama-1 technologies",
            "llc",
            "aws",
            "hydrovis",
            "s3 buckets",
            "sns topics",
            "lambda functions",
            "postgres databases",
            "ec2 machines",
            "iaas",
            "paas",
            "saas",
            "fedramp",
            "azure",
            "gcp",
            "windows and linux iaas",
            "security",
            "management",
            "storage",
            "networking",
            "perl",
            "java",
            "powershell",
            "php",
            "ruby",
            "python",
            "amazon web services",
            "code-defined infrastructure",
            "configuration management tools",
            "ci/cd",
            "aws lambda",
            "\u201cserverless\u201d systems",
            "ansible",
            "chef",
            "puppet",
            "terraform",
            "high-performance computing (hpc)",
            "machine learning",
            "artificial intelligence (ai) applications",
            "aws certified solutions architect \u2013 associate",
            "microsoft azure architect technologies",
            "architect with google cloud platform: infrastructure"
        ],
        "cleaned_techs": [
            "gama-1 technologies",
            "llc",
            "aws",
            "hydrovis",
            "s3 buckets",
            "sns topics",
            "lambda functions",
            "postgres databases",
            "ec2 machines",
            "iaas",
            "paas",
            "saas",
            "fedramp",
            "azure",
            "gcp",
            "windows and linux iaas",
            "management",
            "storage",
            "networking",
            "perl",
            "java",
            "powershell",
            "php",
            "ruby",
            "python",
            "code-defined infrastructure",
            "configuration management tools",
            "ci/cd",
            "\u201cserverless\u201d systems",
            "ansible",
            "chef",
            "puppet",
            "terraform",
            "high-performance computing (hpc)",
            "microsoft azure architect technologies",
            "architect with google cloud platform: infrastructure"
        ]
    },
    "13150438799d78b4": {
        "terms": [
            "mlops"
        ],
        "salary_min": 110000.0,
        "salary_max": 120000.0,
        "title": "DevOps Lead",
        "company": "Sagitec",
        "desc": "Job Description: \n \n \n   Sagitec Solutions is a growing global software and IT company that designs and delivers tailor-made pension, provident fund, unemployment insurance and health and life sciences software solutions to clients of all sizes. Understanding that a dynamic world requires dynamic technology, Sagitec offers solutions that are highly configurable and extensible by nature. With deep industry experience in software implementation and systems integration, project management, consulting, hosting and software support, Sagitec is a partner clients can trust to deliver mission-critical IT projects. They have multiple office locations and are headquartered in Saint Paul, Minnesota.\n  \n \n   Sagitec is seeking DevOps Lead with an IT consulting background and has experience in large scale projects and system implementations across the entire Software Development Life Cycle (SDLC).\n  \n \n  Responsibilities:  \n \n \n \n \n    Analyze current build and release process and provide recommendations based on Sagitec recommended best practices.\n      \n \n \n    Interact with Client and Internal stakeholders and present the strategies to get alignment.\n      \n \n \n    Define roadmap and plan for build and release activities to align with project goals.\n      \n \n \n    Convert existing build and release pipelines to Azure DevOps Server/Services.\n      \n \n \n    Accountable and responsible for defining and execution of Build and Release Pipelines to various environments.\n      \n \n \n    Mentor DevOps Engineers for daily operations.\n      \n \n \n    Need to work with Leads of Infrastructure, IT Security, Database, Development and Quality Assurance to ensure alignment with the projects Software Development Life Cycle Methodology.\n      \n \n \n    Meet with project leadership to provide periodic updates.\n      \n \n \n Qualifications: \n \n \n \n \n    Five years or more experience in supporting production quality Azure DevOps installation.\n      \n \n \n    Two or more years of leadership experience.\n      \n \n \n    Proficient in Powershell Scripting, Internet Information Services 8.5+, Azure DevOps Extensions, Azure Artifacts.\n      \n \n \n    Excellent analytical, strategic conceptual thinking, strategic planning, and execution skills.\n      \n \n \n    Excellent communication and organizational skills, and the ability to stay focused on completing tasks and meeting goals within a busy workspace.\n      \n \n \n    Experience with Team Foundation Server 2015, Azure DevOps Server/Services.\n      \n \n \n    Experience with Windows Server 2008+.\n      \n \n \n    Experience with migration from on premise to Amazon Web Service is a plus.\n      \n \n \n Education: \n \n \n \n \n    Bachelor\u2019s degree, preferably in Computer Science, IT, or related field.\n      \n \n \n    Master\u2019s degree a plus.\n      \n \n \n Compensation and Benefits: \n \n \n \n \n    Fulltime/permanent\n      \n \n \n    $110,000 \u2013 $120,000 per year\n      \n \n \n    401(k) plan with company match\n      \n \n \n    Health insurance\n      \n \n \n    Dental insurance\n      \n \n \n    Vision insurance\n      \n \n \n    Company paid group life insurance\n      \n \n \n    Company paid short and long-term disability\n      \n \n \n    Voluntary life insurance\n      \n \n \n    Flexible spending account\n      \n \n \n    Paid time off\n      \n \n \n    Company holidays\n      \n \n \n    Floating holidays\n      \n \n \n    Employee assistance program\n      \n \n \n    Referral program\n      \n \n \n    Tuition assistance\n    \n \n \n   \n \n \n  With the application, we would like you to include a maximum one-page cover letter describing the experiences with processes, documentation, and tools, noted in the job description.\n  \n \n \n \n  About Sagitec Solutions: \n \n \n   Sagitec is a leading low-code/no-code application development platform provider for private and public sector organizations, specializing in serving customers focused on solving complex, business-rule-driven problems. Using Sagitec\u2019s low-code/no-code platform, Xelence, we provides evolutionary enterprise-grade solutions for pension, labor and employment, health insurance, disability insurance, paid family medical leave, managed care providers, and other benefits providers that want to accelerate excellence by placing a platform at the center of their enterprise universe. With deep industry experience in software implementation and systems integration, Sagitec is a partner that clients can trust to drive their vision into action. For more information, visit: www.sagitec.com",
        "cleaned_desc": "      \n \n \n    Need to work with Leads of Infrastructure, IT Security, Database, Development and Quality Assurance to ensure alignment with the projects Software Development Life Cycle Methodology.\n      \n \n \n    Meet with project leadership to provide periodic updates.\n      \n \n \n Qualifications: \n \n \n \n \n    Five years or more experience in supporting production quality Azure DevOps installation.\n      \n \n \n    Two or more years of leadership experience.\n      \n \n \n    Proficient in Powershell Scripting, Internet Information Services 8.5+, Azure DevOps Extensions, Azure Artifacts.\n      \n \n \n    Excellent analytical, strategic conceptual thinking, strategic planning, and execution skills.\n      \n \n \n    Excellent communication and organizational skills, and the ability to stay focused on completing tasks and meeting goals within a busy workspace.\n      \n ",
        "techs": [
            "azure devops",
            "powershell scripting",
            "internet information services 8.5+",
            "azure devops extensions",
            "azure artifacts"
        ],
        "cleaned_techs": [
            "azure",
            "powershell scripting",
            "internet information services 8.5+"
        ]
    },
    "ca992831cd8c2df2": {
        "terms": [
            "mlops"
        ],
        "salary_min": 100001.0,
        "salary_max": 125000.0,
        "title": "Entry Level DevOps Engineer Opportunities",
        "company": "SAIC",
        "desc": "Job ID: 2314363 \n  Location:  REMOTE WORK, MO, US \n  Date Posted:  2023-10-17 \n  Category:  Software \n  Subcategory:  \n Schedule:  Full-time \n  Shift:  Day Job \n  Travel:  No \n  Minimum Clearance Required:  None \n  Clearance Level Must Be Able to Obtain:  Public Trust \n  Potential for Remote Work:   \n \n Description \n \n \n SAIC is seeking incumbent and external talent to support the USDA\u2019s Farm Production & Conservation (FPAC) Mission Area -  Enterprise IT Operations and Cloud Support . These positions will provide Design, Modernization, and Enhancements (DME) as well as Operations and Maintenance (O&M) for Cloud Infrastructure, CI/CD Pipelines, Geospatial (GIS) Infrastructure, and Site Reliability Engineering (SRE) services. \n \n   \n The positions are contingent upon contract award anticipated for August 2023 with an August 2023 start date.   All positions are remote and must be performed in the United States.  \n Positions will be available in the following skill areas: \n \n  Terraform DevOps Engineers \n \n \n  GIS DBAs \n \n \n  GIS Developers \n \n \n  Splunk Developers \n \n \n  Splunk Engineers \n \n  Qualifications   \n QUALIFICATIONS: \n  Must have experience with Terraform and Puppet  \n \n EDUCATION AND EXPERIENCE: \n  Minimum requirements will vary based on role and level \n \n \n  CLEARANCE REQUIREMENT: \n  Must be able to successfully obtain a Public Trust Clearance \n \n  Target salary range: $100,001 - $125,000. The estimate displayed represents the typical salary range for this position based on experience and other factors.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "99795d3463a96b0e": {
        "terms": [
            "mlops"
        ],
        "salary_min": 115076.64,
        "salary_max": 145712.67,
        "title": "AWS DevOps Engineer",
        "company": "Centric Consulting",
        "desc": "AWS DevOps Engineer \n  Job Location: Remote \n  Join our team \n  Centric Consulting is an international management consulting firm with expertise in digital, business and technology. We are looking for an AWS DevOps Engineer to join our growing team. \n  In this role, you will: \n \n Lead the implementation of Cloud tools and Technologies. \n Develop and implement technical efforts to design, build, and deploy AWS applications at the direction of lead architects, including large-scale data processing, computationally intensive statistical modelling, and advanced analytics. The candidate does not have to be an expert it data and analytics but must be willing to learn these areas. \n Participate in all aspects of the software development life cycle for AWS solutions, including planning, requirements, development, testing, and quality assurance. \n Troubleshoot incidents, identify root cause, fix and document problems, and implement preventive measures. \n Educate teams on the implementation of new cloud-based initiatives, providing associated training as required. \n Employ exceptional problem-solving skills, with the ability to see and solve issues before they affect business productivity. \n \n Who you are: \n \n 6+ years of relevant consulting, industry or technology experience with DevOps processes, tools, and technologies \n 6+ years' experience supporting application build and deployment in an AWS Cloud environment. \n Deep understanding of core DevOps practices (Configuration Management, Continuous Integration, Infrastructure as Code, Continuous Delivery, Continuous Deployment, Continuous Monitoring) \n Deep understanding of DevOps integration with automated testing and/or automation deployment verification. \n Demonstrated experience with common configuration management version control, build and deployment tools (Jenkins, Git, Bitbucket, Code Commit, Chef, Ansible) \n Experience with modern cloud build and deployment tools (GitLab, Beanstalk, OpsWorks, Code Commit, Code Build, Code Deploy) \n Experience with application deployment to containers (Docker, Kubernetes, AWS EKS, AWS ECS, Fargate) \n Experience working with cloud deployment languages (CloudFormation, Terraform, Chef, Ansible) \n Solid understanding of cloud services and infrastructure (VPC, EC2, S3, EBS, EFS, ELB, SG, NACL) \n Experience in writing Python Scripts for executing commands on GitLab. \n Experience with OPA policies, AWS Configuration services and AWS Organizational policies.  \n Preferred experience with Spacelift.io \n \n \n What We Offer? \n  We offer benefits to support your physical, emotional, mental and financial health: \n \n Time Off, When You Need It.  A self-managed paid time off (PTO) program. \n Built For Families.  Parental leave and flexible remote working options. \n Care For You and Yours.  Flexible health care options for you, your family and your pets. Plus, long-term disability, 401(k) benefits and more! \n Help With the Little Things.  Stipends to offset home office costs (such as internet, cell service and supplies). \n Our Success Is Your Success.  A   profit-sharing program and annual company-sponsored trip to celebrate our accomplishments together. \n Opportunities to Grow.  Take courses. Attend conferences. Get certified. \n \n Want to know why you should work with us and what we offer employees? Visit our   website  to learn more. \n \n \n  About Centric Consulting: \n  Founded in 1999 with a remote workforce, we combine the benefits of experience, flexibility and cost efficiency to create tailored solutions centered on what\u2019s best for businesses. Now numbering more than 1,400 employees across the country and India, we\u2019re committed to solving clients\u2019 toughest problems and delivering on our mission of providing unmatched experiences. \n \n \n  Our purpose at Centric Consulting is to bring  unmatched experiences   to clients and employees. These aren't just words we use \u2014 it's how we became a company and who we are today. Providing an unmatched experience means we approach each other as human beings and lead with empathy and humility. It means we work diligently to ensure we are a place where everyone can create a sense of belonging and feel respected for who they are. \n  We know that creating and sustaining an authentically welcoming culture requires that we all play a part in promoting  diversity, equity, and inclusion   , from our business practice to how we show up for employees and communities. At Centric, we are looking for and embrace candidates of all backgrounds and identities who have a hunger for learning, collaborating, and generating unmatched experiences. This is how we bring  our mission and core values   to life, working together to provide the highest quality services to our clients while allowing our employees to reach their full potential.",
        "cleaned_desc": "AWS DevOps Engineer \n  Job Location: Remote \n  Join our team \n  Centric Consulting is an international management consulting firm with expertise in digital, business and technology. We are looking for an AWS DevOps Engineer to join our growing team. \n  In this role, you will: \n \n Lead the implementation of Cloud tools and Technologies. \n Develop and implement technical efforts to design, build, and deploy AWS applications at the direction of lead architects, including large-scale data processing, computationally intensive statistical modelling, and advanced analytics. The candidate does not have to be an expert it data and analytics but must be willing to learn these areas. \n Participate in all aspects of the software development life cycle for AWS solutions, including planning, requirements, development, testing, and quality assurance.   Deep understanding of DevOps integration with automated testing and/or automation deployment verification. \n Demonstrated experience with common configuration management version control, build and deployment tools (Jenkins, Git, Bitbucket, Code Commit, Chef, Ansible) \n Experience with modern cloud build and deployment tools (GitLab, Beanstalk, OpsWorks, Code Commit, Code Build, Code Deploy) \n Experience with application deployment to containers (Docker, Kubernetes, AWS EKS, AWS ECS, Fargate) \n Experience working with cloud deployment languages (CloudFormation, Terraform, Chef, Ansible) \n Solid understanding of cloud services and infrastructure (VPC, EC2, S3, EBS, EFS, ELB, SG, NACL) \n Experience in writing Python Scripts for executing commands on GitLab. \n Experience with OPA policies, AWS Configuration services and AWS Organizational policies.  \n Preferred experience with Spacelift.io ",
        "techs": [
            "aws devops engineer",
            "cloudformation",
            "terraform",
            "chef",
            "ansible",
            "docker",
            "kubernetes",
            "aws eks",
            "aws ecs",
            "fargate",
            "vpc",
            "ec2",
            "s3",
            "ebs",
            "efs",
            "elb",
            "sg",
            "nacl",
            "python scripts",
            "gitlab",
            "opa policies",
            "aws configuration services",
            "aws organizational policies",
            "spacelift.io"
        ],
        "cleaned_techs": [
            "aws",
            "cloudformation",
            "terraform",
            "chef",
            "ansible",
            "docker",
            "kubernetes",
            "fargate",
            "vpc",
            "ec2",
            "s3",
            "ebs",
            "efs",
            "elb",
            "sg",
            "nacl",
            "python",
            "gitlab",
            "opa policies",
            "spacelift.io"
        ]
    },
    "6cd8f1e0824761b2": {
        "terms": [
            "mlops"
        ],
        "salary_min": 118000.0,
        "salary_max": 155000.0,
        "title": "DevOps Manager",
        "company": "Cotiviti",
        "desc": "Overview: \n  \n   Working in an agile software development environment, the \n   DevOps Manager  is responsible for the vision and technical integrity of the automation infrastructure and services in our Cloud Environment (AWS and Azure). As manager of the Cloud Platform Engineering Team, you will focus on standardizing the automation platform across multiple software products. This position involves developing roadmaps, reporting and detailed plans for new automation, automation standardization and enhancements of existing automat for distributed, highly available applications. The DevOps Manager is a thought leader who will be collaborating with the DevOps Architect / Technical leads, Business Operations Leadership, Product Leadership, Development Leadership as well as Security and Compliance Leadership.\n   Responsibilities: \n  \n Responsible for developing plans, processes and visions in multiple enterprise systems in a fast-paced, agile, service-oriented environment. \n  Good understanding of the full stack software development (databases, services, REST, client-side, user interface). \n  Understand and effectively communicate the needs of automation, infrastructure and security at scale to meet rapidly increasing demand. \n  Develop and enhance reporting on SLA\u2019s, process, requirements and progress toward a resilient, secure, and efficient SaaS application platform. \n  Collaborate with Development Leadership to bring new features and services into the delivery organization. \n  Collaboration with Business Operations develop, report and enhance monitoring and automation for the application platform. \n  Evangelize automation, implement processes, procedures, and best practice guidelines for code management. \n  Collaborate with Engineering, Product, Services, and other departments to define requirements to meet the platform standards. \n  Work with Architecture to drive technical designs to consensus and approval. \n  Clearly communicate changed both verbally and in writing the benefits, uses, purpose and vision for the DevOps Platform \n  Mange the DevOps team in developing and communicating best practices, including improved scalability, performance, reliability, and speed to market. \n  Interface with leadership, Group Leads, and Lead Architects to convey infrastructure requirements, plan, and schedule deployment of tasks, and resolve any issues that impact deployment of the Application delivery systems. \n  Qualifications: \n  \n Master's or Bachelor\u2019s in engineering in IT/ Electronics / Communication / Computer Science / Information Systems. \n  5+ years of work experience in the field or in a related area with proven enterprise level experience in a software configuration management role, test automation, application stack deployment and support experience, and experience being a member of a software project life cycle team. \n  2+ years of experience managing teams deploying cloud-based applications in Azure or AWS. \n  Experience with collaborative version control systems (Git/ GitHub/ Subversion/ Bitbucket). \n  Experience with configuration management tools, processes and best practices. \n  Experience with cloud computing and container best practices, tools and processes. \n  Experience developing vision and leading teams to implement enterprise level platforms for automated code delivery. \n  5+ years Agile software delivery experience. \n  Professional with ability to properly handle confidential information. \n  Excellent written and verbal communication skills. \n  Ability to develop roadmaps, report progress and clearly communicate risk and reward for technical achievements \n  Strong organizational skills and adaptive capacity for rapidly changing priorities and workloads \n  Comfort in working with team members that are remote and located in the US, India or other geographies \n  Ability to work within a matrix organization \n \n \n   Base compensation ranges from $118,000 to $155,000. Specific offers are determined by various factors, such as experience, education, skills, certifications, and other business needs.\n  \n \n \n  Cotiviti offers team members a competitive benefits package to address a wide range of personal and family needs, including medical, dental, vision, disability, and life insurance coverage, 401(k) savings plans, paid family leave, 9 paid holidays per year, and 17-27 days of Paid Time Off (PTO) per year, depending on specific level and length of service with Cotiviti. For information about our benefits package, please refer to our Careers page.\n  \n \n \n  This role is based remotely and all interviews will be conducted virtually.\n  \n \n   #LI-Remote\n    #LI-RA1\n    #senior\n  \n \n   #Manager",
        "cleaned_desc": "Overview: \n  \n   Working in an agile software development environment, the \n   DevOps Manager  is responsible for the vision and technical integrity of the automation infrastructure and services in our Cloud Environment (AWS and Azure). As manager of the Cloud Platform Engineering Team, you will focus on standardizing the automation platform across multiple software products. This position involves developing roadmaps, reporting and detailed plans for new automation, automation standardization and enhancements of existing automat for distributed, highly available applications. The DevOps Manager is a thought leader who will be collaborating with the DevOps Architect / Technical leads, Business Operations Leadership, Product Leadership, Development Leadership as well as Security and Compliance Leadership.\n   Responsibilities: \n  \n Responsible for developing plans, processes and visions in multiple enterprise systems in a fast-paced, agile, service-oriented environment. \n  Good understanding of the full stack software development (databases, services, REST, client-side, user interface). \n  Understand and effectively communicate the needs of automation, infrastructure and security at scale to meet rapidly increasing demand. \n  Develop and enhance reporting on SLA\u2019s, process, requirements and progress toward a resilient, secure, and efficient SaaS application platform.   Master's or Bachelor\u2019s in engineering in IT/ Electronics / Communication / Computer Science / Information Systems. \n  5+ years of work experience in the field or in a related area with proven enterprise level experience in a software configuration management role, test automation, application stack deployment and support experience, and experience being a member of a software project life cycle team. \n  2+ years of experience managing teams deploying cloud-based applications in Azure or AWS. \n  Experience with collaborative version control systems (Git/ GitHub/ Subversion/ Bitbucket). \n  Experience with configuration management tools, processes and best practices. \n  Experience with cloud computing and container best practices, tools and processes. \n  Experience developing vision and leading teams to implement enterprise level platforms for automated code delivery. \n  5+ years Agile software delivery experience. \n  Professional with ability to properly handle confidential information. \n  Excellent written and verbal communication skills. ",
        "techs": [
            "aws",
            "azure",
            "git",
            "github",
            "subversion",
            "bitbucket"
        ],
        "cleaned_techs": [
            "aws",
            "azure",
            "git",
            "github",
            "subversion",
            "bitbucket"
        ]
    },
    "30918e7a91597420": {
        "terms": [
            "mlops"
        ],
        "salary_min": 58400.0,
        "salary_max": 133000.0,
        "title": "DevOps Engineer, Mid",
        "company": "Booz Allen Hamilton",
        "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         McLean,VA,US \n         \n \n \n \n         Remote Work: \n         \n \n         Hybrid \n         \n \n \n \n         Job Number: \n         \n \n         R0182414\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         DevOps Engineer, Mid\n           The Opportunity: \n  As a DevOps engineer, you know how to set up cloud environments and provision computer networking, storage, and virtual networks\u2014ultimately, how to \u201charness the cloud.\u201d We\u2019re looking for a seasoned DevOps infrastructure engineer like you to support our clients as they modernize their IT infrastructures and meet their most challenging missions. \n \n  As a lead DevOps infrastructure engineer at Booz Allen, you\u2019ll oversee a team of cloud architects and engineers as they manage server configuration for modern cloud solutions. You\u2019ll apply your skills and experience within a DevOps framework to establish or provision virtual machines or networks and use cloud service providers to further your clients\u2019 meaningful missions. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  3+ years of experience working within a technical, cloud-based environment \n  3+ years of experience working in a Linux based environment \n  3+ years of experience with commercial Cloud service providers, including Amazon Web Services or Microsoft Azure, or GCP Cloud providers \n  Ability to troubleshoot development builds or pipelines with service desk tools \n  Secret clearance \n  Bachelor\u2019s degree \n \n \n  Nice If You Have: \n \n  1+ year of experience in a technical support role \n  Experience with managing a support desk and creating documentation or training related to solving user problems \n  Knowledge of Jenkins and Gitlab pipelines, mechanisms, and build workflows \n  Possession of client service skills \n  Ability to obtain a security plus Certification \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. \n \n  Create Your Career: \n \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll develop your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $58,400.00 to $133,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "78db0cbf2a42e02f": {
        "terms": [
            "mlops"
        ],
        "salary_min": 119700.0,
        "salary_max": 191800.0,
        "title": "Sr. Manager, DevOps Team Lead, Access Automation",
        "company": "Biogen",
        "desc": "Job Description\n   About This Role  Biogen is seeking a proven DevOps Team Lead who has expertise pulling together the appropriate analysts, developers, configurators, testing, documentation, and other resources necessary to deliver a defined sprint (or set of sprints) as per an approved project. Often working with a set team focused on a particular subject or application area, the DevOps Team Lead functions as a very hands-on project manager that brings technical skill leadership to the team not just task and deadline management. The DevOps Team Lead will work with IT and business customers to gather requirements and work with the Stakeholder Success Lead or Product Owner in planning sprints and releases mindful of the overall plans for the application. This senior leader will report directly to the Head of Access Automation within our Cybersecurity organization and lead a team of ~3-5 development resources. Access Automation is a cornerstone of Biogen\u2019s application security and GXP/Quality compliance programs. This role will ultimately impact every key application user in the corporation and is a critical customer-facing leadership position within our Cybersecurity organization. \n \n  What You\u2019ll Do \n \n \n Work directly with stakeholders and with Stakeholder Success Leads to ensure that Identity & Access Automation services meet their needs and expectations. \n Lead the hands-on design, development and integration of our next generation Access Automation solution \n Ensure that sprints are of high quality and meet or exceed stakeholder expectations \n Coordinate the efforts of development teams with that of operations teams to streamline the development process and build and evolve an automated, secure, and scalable continuous delivery pipeline with high-quality releases to end users. \n Drive adoption and improvement of the Agile / DevOps approach to system development at Biogen. \n Increase the adoption of continuous build, inspection, testing, automated deployment and performance monitoring approaches to ensure maximum uptime and optimal performance in the Production environment. \n Ensure that Access Automation solutions are delivered in compliance with organizational policies, standards, and regulatory requirements. Align with business governance bodies and procedures to ensure appropriate input across relevant stakeholder functions. \n Ensure that all IT solutions are delivered within the allocated budget targets. \n \n \n \n \n \n Qualifications\n   Who You Are  You are resourceful and driven to deliver a superior customer experience. You have demonstrable experience troubleshooting complex processes, finding the root cause and driving continuous improvement. You are able to adapt to different stakeholders\u2019 technical abilities and communicate effectively with business and IT professionals. \n \n  Required Skills \n \n \n 8+ years of IT experience, including 3-5 years of service delivery, project management, and/or service management across Identity platforms & services \n Knowledge across Identity Governance Administration (IGA) platforms (Sailpoint), Identity Assurance platforms (MS Active Directory, Azure, Okta) and PAM platforms (CyberArk). \n Stakeholder Relationship Management \n Program/Project Management \n Agile Methodology \n Requirements Definition and Management \n Release and Deployment \n Change Control \n Systems Development Management \n Integration and System Testing \n Test Planning and Execution \n User Acceptance Testing (UAT) \n Solution Planning \n Demand Management \n \n \n Preferred Skills \n \n \n MSP Service Delivery Management \n MSP Service Delivery Operations - Application Development and Delivery \n Software Configuration \n Contract Management \n SLA Management \n Vendor Management \n \n \n  Additional Information\n   The base compensation range for this role is $119,700 to $191,800. Base salary is determined by a combination of factors including, but not limited to, job related years of relevant experience, internal equity, and location of the job. Additionally, this role is eligible for participation in Biogen\u2019s LTI grants and other incentive programs. Biogen offers a full range of benefits that include medical, dental, life, long and short-term disability insurances, vacation, end-of-year shutdown, and 401K participation and matching contributions. \n  \u201cDiversity is key for the survival of our ecosystem. I believe it is the single most important factor for a balanced flourishing environment where everyone thrives.\u201d  Guy Hadari \u2013 Chief Information Officer- Biogen \n \n  Why Biogen? \n  Our mission to find therapies for neurological and rare diseases is a unique focus within our industry and this shared purpose is what connects us as a team. We work together to overcome obstacles and to follow the science. We are resilient as we strive to make an impact on our patients\u2019 lives and on changing the course of medicine. Together, we pioneer. Together, we thrive. \n  At Biogen, we are committed to building on our culture of inclusion and belonging that reflects the communities where we operate and the patients we serve. We know that diverse backgrounds, cultures, and perspectives make us a stronger and more innovative company, and we are focused on building teams where every employee feels empowered and inspired. Read on to learn more about our DE&I efforts. \n  All qualified applicants will receive consideration for employment without regard to sex, gender identity or expression, sexual orientation, marital status, race, color, national origin, ancestry, ethnicity, religion, age, veteran status, disability, genetic information or any other basis protected by federal, state or local law. Biogen is an E-Verify Employer in the United States.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "20c4ee39729652df": {
        "terms": [
            "mlops"
        ],
        "salary_min": 91000.0,
        "salary_max": 130000.0,
        "title": "DevOps Engineer",
        "company": "Pinnacle Technical Resources",
        "desc": "DevOps Engineer \n \n Location: 100% Remote \n \n Salary Range: $91,000-$130,000  \n \n Duration: Permanent role \n \n \n The Opportunity \n \n Promote technical solutions that support the business requirements within the area of expertise. \n Ensures IT requirements are met, and service quality is maintained when introducing new services. Considers the cost-effectiveness of proposed solution(s). \n Innovative and technically sound in analyzing projects in-depth \n Define and evaluate standards and best practices for the technology area of expertise. \n Collaborate with architects by helping them in choosing the technology tools for solutions. \n Proactively suggest new technologies for improvements over the existing technology landscape. \n Leads technical consultancy assignments that involve specialists from various disciplines; taking responsibility for quality, timely delivery, and the appropriateness of the teams'; recommendations \n Make recommendations on how to improve the effectiveness, efficiency, and delivery of services using technology and methodologies. \n \n This position description identifies the responsibilities and tasks typically associated with the performance of the position. Other relevant essential functions may be required. \n \n What You Need: \n \n Experience in Programming languages and DBMS \n Proficient in Operating Systems and software platforms \n Integrated development environment (IDE) \n Agile, Scrum, or Kanban Experience \n Knowledge of customer domain and subdomain where the problem is solved \n Knowledge of new technologies (e.g.; Data science AI/ML IoT big data etc. cloud platforms) \n RDBMS and NOSQL \n \n \n   Pay Range: $ 91,000-$130,000   The specific compensation for this position will be determined by a number of factors, including the scope, complexity and location of the role as well as the cost of labor in the market; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. Our full-time consultants have access to benefits including medical, dental, vision as well as 401K contributions. \n  #LI-GN1",
        "cleaned_desc": " Experience in Programming languages and DBMS \n Proficient in Operating Systems and software platforms \n Integrated development environment (IDE) \n Agile, Scrum, or Kanban Experience \n Knowledge of customer domain and subdomain where the problem is solved \n Knowledge of new technologies (e.g.; Data science AI/ML IoT big data etc. cloud platforms) ",
        "techs": [
            "programming languages",
            "dbms",
            "operating systems",
            "software platforms",
            "integrated development environment (ide)",
            "agile",
            "scrum",
            "kanban",
            "data science",
            "ai/ml",
            "iot",
            "big data",
            "cloud platforms"
        ],
        "cleaned_techs": [
            "programming languages",
            "dbms",
            "operating systems",
            "software platforms",
            "integrated development environment (ide)",
            "agile",
            "scrum",
            "kanban",
            "data science",
            "ai",
            "iot",
            "big data",
            "cloud platforms"
        ]
    },
    "2e5ed4dc2eacbdad": {
        "terms": [
            "mlops"
        ],
        "salary_min": 150074.3,
        "salary_max": 190027.48,
        "title": "Staff Engineer, DevOps",
        "company": "Valo Health",
        "desc": "About Us \n  Valo Health is a technology company that is integrating human-centric data and AI-powered technology to accelerate the creation of life-changing drugs for more patients faster. Valo was created with the belief that the drug discovery and development process can and should be faster and less expensive, with a much higher probability of success. We are using models early to fail less often, executing clinical trials to add valuation to the company, and generating fit-for-purpose data to feed back into Valo's Opal Computational Platform\u2122 as we reinvent drug discovery and development from the ground up. Disease doesn't wait, so neither can we. \n  We are a multi-disciplinary team of experts in science, technology, and pharmaceuticals united in our mission to achieve better drugs for patients faster. Valo is committed to hiring diverse talent, prioritizing growth and development, fostering an inclusive environment, and creating opportunities to bring together a group of different experiences, backgrounds, and voices to work together. We achieve the widest-ranging impact when we leverage our broad backgrounds and perspectives to accelerate a new frontier in health. Valo seeks to become the catalyst for the pharmaceutical industry and drive the digital transformation of the industry. Are you ready to join us? \n  About the Role \n  We are looking for DevOps engineers to help manage the AWS Cloud infrastructure for our Data Science and Machine Learning environments. A successful candidate should be equally adept in handling day-to-day problems encountered by our users, as well as able to see the larger picture and change our infrastructure to lower our overall operational costs and improve user experience. \n  What You'll Do\u2026 \n \n Handle a ticket duty to resolve user problems in an AWS Cloud Environment. \n Able to extract the general shapes of problems based on ad hoc tasks and find a technical path to automate away repetitive tasks and/or create tools and processes to allow self-service by users to decrease user burden. \n \n What You Bring... \n \n Proficient in Python, and shell scripting \n Proficient in administering AWS environments: Linux EC2 instances, EKS clusters, and general networking and security best practices. \n Comfortable with Software Engineering best practices such as the use of source control systems (specifically Git), code review, automated testing, and CI/CD pipelines \n Experience with GitLab, including the deployment and administration of a self-managed GitLab server (with GitLab CI) \n Familiar with automation of cloud deployment and blueprints (e.g. Terraform, Pulumi) \n \n More on Valo \n  Valo Health, Inc (\"Valo\") is a technology company built to transform the drug discovery and development process using human-centric data and artificial intelligence-driven computation. As a digitally native company, Valo aims to fully integrate human-centric data across the entire drug development life cycle into a single unified architecture, thereby accelerating the discovery and development of life-changing drugs while simultaneously reducing costs, time, and failure rates. The company's Opal Computational Platform\u2122 is an integrated set of capabilities designed to transform data into valuable insights that may accelerate discoveries and enable Valo to advance a robust pipeline of programs across cardiovascular metabolic renal, oncology, and neurodegenerative disease. Founded by Flagship Pioneering and headquartered in Boston, MA, Valo also has offices in Lexington, MA, and New York. To learn more, visit www.valohealth.com.",
        "cleaned_desc": " Proficient in Python, and shell scripting \n Proficient in administering AWS environments: Linux EC2 instances, EKS clusters, and general networking and security best practices. \n Comfortable with Software Engineering best practices such as the use of source control systems (specifically Git), code review, automated testing, and CI/CD pipelines ",
        "techs": [
            "python",
            "shell scripting",
            "aws",
            "linux ec2 instances",
            "eks clusters",
            "networking",
            "security best practices",
            "source control systems (git)",
            "code review",
            "automated testing",
            "ci/cd pipelines"
        ],
        "cleaned_techs": [
            "python",
            "shell scripting",
            "aws",
            "linux ec2 instances",
            "eks clusters",
            "networking",
            "source control systems (git)",
            "code review",
            "automated testing",
            "ci/cd pipelines"
        ]
    },
    "7cea3e83642de718": {
        "terms": [
            "mlops"
        ],
        "salary_min": 118842.48,
        "salary_max": 150481.06,
        "title": "Senior Devops Engineer (Flywork Talent Network)",
        "company": "Flywork",
        "desc": "Who we are   \n \n Flywork is a members-only network of the best independent software talent around the globe. We build on-demand software teams comprised of software developers, devops, designers, project managers, and product managers for companies large and small doing interesting and challenging work in the world. We believe the best people want to work with the best, that great talent can come from Argentina or the Philippines, deep in the Canadian Rockies or in downtown Manhattan, and that great companies win when they have the ability to build dynamic, on-demand, and highly skilled teams to execute on their most pressing challenges. We are passionate about empowering freelancers to do their best work, and about taking that rocket fuel to make the world a better place one innovative project at a time.   \n \n About the job   \n \n Are you an experienced freelancer or experienced at what you do and interested in becoming one? We build the bridges between the best talent and great projects so that living and working as a freelancer is that much more attainable. Whether it is full-time, half-time, or part-time, once you are a part of the Flywork talent network, you tell us how and when you want to work and how much you want to earn, and we will work to match you to opportunities that are a fit.   \n \n As a Senior Devops Engineer, you will work with a diverse, remote team of highly skilled engineers, designers, project managers, product managers, and others to deliver high quality applications that meet the needs of customers.   \n \n Responsibilities  \n \n Designing, implementing, maintaining, and optimizing the infrastructure that supports applications being developed for customers.  \n Troubleshooting and resolving infrastructure issues as they arise in coordination with the development team.  \n Designing, implementing, and maintaining CI/CD pipelines to ensure smooth and continuous software deployment.  \n Collaborating with the development team to continuously improve various processes and systems around deployment, testing, security, etc.  \n Participating in planning meetings associated with the software development process, including sprint planning, daily standups, reviews and retros.  \n Maintaining and sometimes writing user stories associated with sprint planning and execution.  \n Collaborating with team members and communicating effectively and often around progress, status, needs, issues, concerns, etc.  Communicating with the customer when needed to provide status and address any questions or concerns. \n   \n \n Requirements   \n \n The basics:  \n \n Strong communication skills. Do you understand the importance of providing transparent communication to those you are working with?  \n Dedication and commitment. Do you finish what you start?  \n Passion, drive and curiosity. Do you love what you do and keep an open mind as you work to grow and improve?  \n Independent. Strong ability to work without close supervision and take ownership over your work.  Not a jerk. Kindness, thoughtfulness, grace, and civility always win the day. \n   \n \n For the role:  \n \n 5+ years of experience working as a devops engineer designing, implementing, maintaining, and optimizing cloud infrastructure.  \n Expert in one or more major cloud platforms - AWS, GCP, and Azure.  \n Experience implementing CI/CD pipelines.  \n Experience with configuration management tools.  \n Experience developing and deploying containerized applications.  Experience with the Agile development process. \n   \n \n How we work   \n \n Flywork is a community of talented builders from all corners of the globe who are above all else kind, thoughtful, respectful, and open-minded. We believe in and celebrate diversity of experiences, cultures, beliefs, and ideas. We believe that balance between life and work is important and that finding that balance is key to doing your best work. We celebrate innovation and working together so that we can be greater than we are as individuals.   \n \n Perks  \n \n Being part of a global community of talented, innovative people.  \n \n \n 100% remote work and global work opportunities.  \n Work flexibility.  \n Personal and professional growth on your own terms.",
        "cleaned_desc": " \n For the role:  \n \n 5+ years of experience working as a devops engineer designing, implementing, maintaining, and optimizing cloud infrastructure.  \n Expert in one or more major cloud platforms - AWS, GCP, and Azure.  \n Experience implementing CI/CD pipelines.  \n Experience with configuration management tools.  \n Experience developing and deploying containerized applications.  Experience with the Agile development process. \n   \n ",
        "techs": [
            "aws",
            "gcp",
            "azure",
            "ci/cd pipelines",
            "configuration management tools",
            "containerized applications",
            "agile development process"
        ],
        "cleaned_techs": [
            "aws",
            "gcp",
            "azure",
            "ci/cd pipelines",
            "configuration management tools",
            "agile development process"
        ]
    },
    "5d2cb7e4a0d10cba": {
        "terms": [
            "mlops"
        ],
        "salary_min": 157000.0,
        "salary_max": 167000.0,
        "title": "Principal DevOps Engineer",
        "company": "Pure Property Management",
        "desc": "PURE Property Management   is looking for a Principal DevOps Engineer. Come join our team! \n PURE Property Management offers a comprehensive package of benefits such as: Healthcare coverage, a 401K plan with a 4% instantly vested match, health savings accounts for eligible plans, generous vacation and sick time, dental and vision plans, life, and disability policies, equity compensation and more! \n Pay Range:  $157,000 to $167,000 \n Pay Frequency:  Biweekly \n Position Hours:  40 Hours/Week \n FLSA:  Exempt \n **US-based applicants only** \n PURE Property Management is the fastest growing profitable residential property management and technology company in the U.S. Led by a team of experienced industry professionals and seasoned technology innovators, PURE acquires single-family residential property management companies and invests in their people and processes. By deploying technology and providing operational efficiencies, PURE enhances resident and investor experiences. \n We\u2019re looking for a  Principal DevOps Engineer  for a player-coach role focused on shipping a new, high-scale platform for property managers. \n We genuinely have a fantastic situation here at PURE. This role is part of a distributed team of engineers, designers and product managers who are building a new platform for property managers in collaboration with our users, who are deeply insightful and incredible to work with. Our company mission is crystal clear. Our technology mandate is well-formulated, properly-funded, and 100% supported by our leadership. \n In this role, you will: \n \n Lead the DevOps practice , including working with our Head of Engineering to set the roadmap for our Google-based infrastructure, automation, and production monitoring. \n Contribute in a player-coach role , mentoring engineers on DevOps topics and generally serving as the primary subject-matter-expert for DevOps. This role does not have any direct reports (our team is small), but it is a very important practice-lead within the organization and there is a strong leadership component. \n Drive automation  - we are building a modern stack and are moving to CI/CD. We need a strong focus on automation and modern cloud practices. \n Be our Google Cloud expert  - we are heavily using the Google ecosystem and we need someone who knows it inside and out. \n Manage data at scale  - our platform includes a number of integration and a lot of data moving between domains at small-enterprise scale. We need someone who has done this before \n Focus on performance and production  - we are moving into production and we need someone who really understands managing and monitoring platforms in production. \n \n Your Background \n Minimum qualifications: \n \n 10 years of experience in software development , or 8 years with an advanced degree in Computer Science, Mathematics, Statistics, or Software Engineering. \n 7 years of experience working with GCP and a deep understanding of the Google Cloud Ecosystem . At least 4 years working on native cloud architectures and distributed systems. (AWS/Azure are not acceptable substitutes for experience.) \n Working knowledge of  GitHub, CI/CD pipelines into cloud architectures , token based authentication, postgresql, and serverless computing environments. \n Experience working in a  growth-stage startup or scale-up  (series C-E) building enterprise and/or B2B products. Understanding of enterprise workloads. \n Experience  managing data-intensive products with extensive 3p integrations in production . \n \n Preferred qualifications: \n \n You are an empathetic leader  with a demonstrated ability to motivate teammates by creating a shared sense of purpose, community and collaboration. \n You are a great communicator  with an ability to create a compelling argument for ideas, and work cross-functionally in a collaborative manner. \n You like start-up/scale up environments and new products . We are a pretty organized start-up, but we\u2019re still a start-up building a new platform - that entails a certain amount of ambiguity and change. \n You love data platforms . The scale, the integrations, all the moving parts. \n \n Our Values \n These are critical to everything we do at PURE: \n \n User empathy  - Our users define our business. We listen to them, understand their needs, and act on that understanding. \n Freedom and responsibility  - We\u2019re obsessed with results. You get to choose how to get there. \n Team support  - Growing a business is a team sport. We are kind and supportive of each other. \n \n Equal Employment Opportunity:  At PURE Employment LLC and Subsidiaries, we value diversity and are an equal-opportunity employer. We treat everyone fairly regardless of their race, color, creed, religion, national origin, ancestry, citizenship status, age, sex or gender (including pregnancy), gender identity or expression (including transgender status), sexual orientation, marital status, veteran status, physical or mental disability, genetic information, or any other characteristic protected by applicable laws. We base our hiring, promotion, termination, and other employment decisions on merit, qualifications, and competence. Discrimination in employment opportunities based on actual or perceived protected characteristics goes against our policy. \n Job Type: Full-time \n Pay: $157,000.00 - $167,000.00 per year \n Benefits: \n \n 401(k) \n Dental insurance \n Employee assistance program \n Flexible spending account \n Health insurance \n Health savings account \n Life insurance \n Paid time off \n Referral program \n Retirement plan \n Vision insurance \n \n Experience level: \n \n 10 years \n 6 years \n 7 years \n 8 years \n 9 years \n \n Schedule: \n \n Monday to Friday \n \n Application Question(s): \n \n Are you currently located within the United States? \n \n Experience: \n \n managing or leading DevOps teams: 4 years (Required) \n Software development: 8 years (Required) \n CI/CD pipelines and serverless computing environments: 5 years (Required) \n Google Cloud Platform: 5 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": " Manage data at scale  - our platform includes a number of integration and a lot of data moving between domains at small-enterprise scale. We need someone who has done this before \n Focus on performance and production  - we are moving into production and we need someone who really understands managing and monitoring platforms in production. \n \n Your Background \n Minimum qualifications: \n \n 10 years of experience in software development , or 8 years with an advanced degree in Computer Science, Mathematics, Statistics, or Software Engineering. \n 7 years of experience working with GCP and a deep understanding of the Google Cloud Ecosystem . At least 4 years working on native cloud architectures and distributed systems. (AWS/Azure are not acceptable substitutes for experience.) \n Working knowledge of  GitHub, CI/CD pipelines into cloud architectures , token based authentication, postgresql, and serverless computing environments. \n Experience working in a  growth-stage startup or scale-up  (series C-E) building enterprise and/or B2B products. Understanding of enterprise workloads. \n Experience  managing data-intensive products with extensive 3p integrations in production . \n \n Preferred qualifications: \n \n You are an empathetic leader  with a demonstrated ability to motivate teammates by creating a shared sense of purpose, community and collaboration. \n You are a great communicator  with an ability to create a compelling argument for ideas, and work cross-functionally in a collaborative manner. ",
        "techs": [
            "gcp",
            "google cloud ecosystem",
            "aws",
            "azure",
            "github",
            "ci/cd pipelines",
            "token based authentication",
            "postgresql",
            "serverless computing",
            "growth-stage startup",
            "scale-up",
            "3p integrations"
        ],
        "cleaned_techs": [
            "gcp",
            "aws",
            "azure",
            "github",
            "ci/cd pipelines",
            "token based authentication",
            "postgresql",
            "serverless computing",
            "growth-stage startup",
            "scale-up",
            "3p integrations"
        ]
    },
    "94de7a1209430355": {
        "terms": [
            "mlops"
        ],
        "salary_min": 122808.12,
        "salary_max": 155502.44,
        "title": "Senior DevOps Engineer",
        "company": "Nagarro",
        "desc": "Full-time \n  Service Region: Eastern Europe \n \n \n \n \n \n  Company Description \n \n \n  We're Nagarro. \n  We are a digital product engineering company that is scaling in a big way! We build products, services, and experiences that inspire, excite, and delight. We work at scale \u2014 across all devices and digital mediums, and our people exist everywhere in the world (19,000+ experts across 35 countries, to be exact). Our work culture is dynamic and non-hierarchical. We're looking for great new colleagues. That's where you come in! \n  By this point in your career, it is not just about the tech you know or how well you can code. It is about what more you want to do with that knowledge. Can you help your teammates proceed in the right direction? Can you tackle the challenges our clients face while always looking to take our solutions one step further to succeed at an even higher level? Yes? You may be ready to join us. \n \n \n \n \n \n  Job Description \n \n \n \n  Delivering custom developed products for a top diagnostics company in Switzerland. \n  Managing the CI/CD processes for over 200 medical devices projects. \n  Developing new features for the build solution (C# wrapper over Nuke). \n  Full autonomy when it comes to developing and maintaining the build system. \n  Using the client methodology complemented by the Nagarro software delivery process and best practices. \n  Providing general guidance related to development teams and resolving support tickets around building, testing, and deploying existing and new applications. \n  Implementing solutions which aim for a full automation of manual tasks, delivery processes and monitoring. \n \n \n \n \n \n \n  Qualifications \n \n \n  Must have skills: \n \n  Azure DevOps \n  Gitlab CI/CD \n  Docker \n  PowerShell \n  Bash \n  Windows and Linux Server Administration \n  GitOps \n \n \n \n \n \n \n  Nice to have: \n \n  C# \n  Experience in highly regulated industries (e.g. Life Sciences). \n  AWS Knowledge \n  Experience with Jenkins. \n  Exposure to monitoring tools (Prometheus, Grafana). \n  Familiarity with Docker Compose. \n  Server administration. \n  Client-facing role, directly interacting with Nagarro and customer project stakeholders. \n  Organized, structured. Problem-solving and effective communication skills.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "81851a4e76f04736": {
        "terms": [
            "mlops"
        ],
        "salary_min": 119930.55,
        "salary_max": 151858.8,
        "title": "DevOps Engineer",
        "company": "Baer Group",
        "desc": "**Federal Project - Applicant must be a United States Citizen with Active Secret Clearance** \n \n   \n \n Baer is looking for DevOps Engineer for a 6+ month Federal remote project. \n \n \n Title:  DevOps Engineer\n  \n Location:  Remote (Must be based in US) \u2013 Preference to Consultants Commutable to Kingstowne, VA\n  \n Duration : 6+ months\n  \n Rate:  All-Inclusive\n  \n Alignment:  W2 or C2C\n  \n \n Description: \n \n Deploy infrastructure and platform environments, creates a proof of architecture to test architecture viability security, and performance.  \n Deploy and manage AWS cloud infrastructure and services.  \n Deploy, configure, and operationalize resilient, highly available production grade containers using AWS EKS  \n Develop IaC for cluster orchestration and application deployment using a variety of tools such as Ansible, Terraform  \n Work with a variety of cloud native tools to add capabilities and secure the platform.  \n Troubleshoot complex technical issues across all layers of the technology stack.  \n Design and build features for implementation in the production system and operational employment by our customer.  \n Proactively resolve technical hurdles and continue innovative efforts within SAFe development practices.  \n Collaborate and communicate with other team members to decompose large tasks into small testable tasks.  \n \n \n Requirements: \n \n 5+ years of experience in cloud-based solutions and cloud CLIs  \n Experience troubleshooting DNS, VPN, HTTPS, and networking configurations  \n Knowledge of software development methodologies, security concepts, network, and system design  \n Advanced experience in various technology areas including cloud, identity solutions.  \n Experience developing and deploying Infrastructure as Code solutions in a cloud environment.  \n Experience hardening and testing systems and applications.  \n Experience configuring physical/virtual networks (VLANs, VNIC, Switches, & other networking hardware)  \n Experience with Linux and Windows Server file systems and operations.  \n Certified in one or more of top for CSP (AWS Preferred)  \n DoD 8140 Baseline Certification (Security+, CASP, CISM, CISSP)  \n Preferred experience in DoD Cloud environments  \n Education Requirement: Bachelor\u2019s Degree \n \n \n \n \n Company Overview: \n \n  Baer is an Enterprise Performance Partner providing job opportunities with several 1st Tier Global Systems Integrators and a wide array of Fortune 1000 clients. Baer consultants and employees enjoy access to the highest profile job opportunities across leading Enterprise Technology Solutions ranging from Digital Transformation programs utilizing the latest technologies from SAP and Oracle to a wide range of emerging Cloud based infrastructure, application and AI related solutions.\n  \n  At Baer we aim to provide a best-in-class engagement experience for our consultants. Our job requirements are carefully vetted and are typically associated with pivotal programs offering tremendous opportunities to expand your skills leveraging the latest solutions.\n  \n  Baer is an equal opportunity employer including disability/veteran.",
        "cleaned_desc": " Deploy, configure, and operationalize resilient, highly available production grade containers using AWS EKS  \n Develop IaC for cluster orchestration and application deployment using a variety of tools such as Ansible, Terraform  \n Work with a variety of cloud native tools to add capabilities and secure the platform.  \n Troubleshoot complex technical issues across all layers of the technology stack.  \n Design and build features for implementation in the production system and operational employment by our customer.  \n Proactively resolve technical hurdles and continue innovative efforts within SAFe development practices.  \n Collaborate and communicate with other team members to decompose large tasks into small testable tasks.  \n \n \n Requirements: \n   5+ years of experience in cloud-based solutions and cloud CLIs  \n Experience troubleshooting DNS, VPN, HTTPS, and networking configurations  \n Knowledge of software development methodologies, security concepts, network, and system design  \n Advanced experience in various technology areas including cloud, identity solutions.  \n Experience developing and deploying Infrastructure as Code solutions in a cloud environment.  \n Experience hardening and testing systems and applications.  \n Experience configuring physical/virtual networks (VLANs, VNIC, Switches, & other networking hardware)  \n Experience with Linux and Windows Server file systems and operations.  \n Certified in one or more of top for CSP (AWS Preferred)  \n DoD 8140 Baseline Certification (Security+, CASP, CISM, CISSP)  \n Preferred experience in DoD Cloud environments  ",
        "techs": [
            "aws eks",
            "ansible",
            "terraform",
            "safe",
            "dns",
            "vpn",
            "https",
            "vlans",
            "vnics",
            "linux",
            "windows server",
            "csp",
            "dod 8140 baseline certification"
        ],
        "cleaned_techs": [
            "aws",
            "ansible",
            "terraform",
            "safe",
            "dns",
            "vpn",
            "https",
            "vlans",
            "vnics",
            "linux",
            "windows server",
            "csp",
            "dod 8140 baseline certification"
        ]
    },
    "01046b503d1bc1e6": {
        "terms": [
            "mlops"
        ],
        "salary_min": 100000.0,
        "salary_max": 100000.0,
        "title": "DevOps Engineer",
        "company": "Rapidiant",
        "desc": "We are looking for a new DevOps Engineer to join our United States Internal Revenue Service (IRS) team supporting the CI/CD pipeline. Applicants must be US Citizens capable of obtaining a US Government public trust security clearance. \n \n 5-10 years' experience in Linux Systems Administration or working in a DevOps environment. \n Experience (2 years) with administering and using Nexus Repository Pro. \n Experience administering GitLab a big plus. \n Experience with Ansible a plus \n Experience administering Web Applications -- native or Cloud (AWS, Azure, etc.) \n DevOps Engineer with high level scripting experience (e.g., Unix shell, Perl, Python, Groovy, PowerShell, Ruby, Go, JavaScript). \n \n Job Type: Full-time \n Pay: $100,000.00 per year \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Experience: \n \n Ansible: 2 years (Required) \n Scripting: 3 years (Required) \n Linux: 6 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": " Experience administering GitLab a big plus. \n Experience with Ansible a plus \n Experience administering Web Applications -- native or Cloud (AWS, Azure, etc.) \n DevOps Engineer with high level scripting experience (e.g., Unix shell, Perl, Python, Groovy, PowerShell, Ruby, Go, JavaScript). ",
        "techs": [
            "gitlab",
            "ansible",
            "aws",
            "azure",
            "unix shell",
            "perl",
            "python",
            "groovy",
            "powershell",
            "ruby",
            "go",
            "javascript"
        ],
        "cleaned_techs": [
            "gitlab",
            "ansible",
            "aws",
            "azure",
            "unix shell",
            "perl",
            "python",
            "groovy",
            "powershell",
            "ruby",
            "go",
            "javascript"
        ]
    },
    "c2029cc493f49f26": {
        "terms": [
            "mlops"
        ],
        "salary_min": 125000.0,
        "salary_max": 143000.0,
        "title": "DevOps Engineer",
        "company": "Homebot",
        "desc": "Come join one of the best places to work in Denver (not kidding, check out our 4.5 rating on Glassdoor with 30+ reviews!) At Homebot, we believe that every team member has an important role to play in bringing our mission statement to life. How do we do this? By keeping a clear focus on culture and engagement, and creating an environment where people are valued! We're seeking joyous, Humanity-fueled professionals to join us in revolutionizing how people build wealth with the single largest asset they'll ever own \u2014 their home. \n \n Homebot is a fintech company that helps users save money and build wealth by encouraging smart home finance decisions. We connect people to make informed homeownership decisions together. Our platform empowers consumers with personalized and actionable financial insights, and facilitates engagement with the experts through the full homeownership lifecycle. \n We are scaling rapidly and need an approachable & methodical  DevOps Engineer  to Empower Product R&D squads to scale & iterate efficiently and safely through stewardship of Homebot's deployment pipeline, devops & chatops tooling, infrastructure and applications, to Champion Developer Experience, fostering a culture that embraces continuous improvement, automation, and risk mitigation. \n If this opportunity gets you pumped - perfect! Apply below and we look forward to speaking with you very soon! (We also read cover letters so take a moment to tell us what makes you a great addition to the team!) \n This is a  full-time  position based in  our Denver, CO office.  We will consider full-remote (US Resident) candidates for this position, and for those located near Denver, we also have a hybrid work model in place that encourages employees to split their time between working in-office and from home a few days a week. \n Compensation:  We are committed to providing competitive pay and benefits that are in line with industry standards. We analyze and carefully consider several factors when determining compensation, including skills, qualifications and professional experience, which can cause your compensation to vary. This role has an annual targeted base salary range of  $125,000 \u2014 $143,000 , plus an  annual 10% performance bonus target . \n For additional details on our total benefits package, please review the section \u201cWhy Homebot?\u201d at the end of this job description. \n \n The impact you'll make by joining us: \n \n Within 1 month you will:\n    \n  Integrate as newest member of our hybrid workforce, investing some screen time & face-to-face time working & bonding over a beverage or recipe of choice, a match of ping pong, and excellent technical challenges across the tech stack \n  Develop a high-level understanding of the various products, services, processes and technologies used across R&D \n  Pair with engineers & engineering managers on each of our 5 product squads to develop relationships and start to get familiar with the value that each squad serves & challenges they face \n  Partner with Mobile, ETL & Data squads to understand existing cloud infrastructure workflows and pain points \n  Build and maintain core infrastructure, especially with regards to managing IAM, containers, k8s, RDS and other AWS products, using mostly Terraform \n  Build, support, and maintain features for our Go DevOps & ChatOps tooling to elevate Developer Experience \n  Identify, migrate & prune systems that have reached end-of-life, or are due for some form of migration or upgrade \n  Steward at least 1 On-Call rotation in support of infrastructure, deploy & DevEx issues when they come up \n  Help our esteemed & studious junior colleagues to level up, get plenty of support & challenge \n  Join our AppSec steering committee & biweekly roundtable sessions to continuously iterate on our AppSec Champions Program \n \n  Within 3 months you will:\n    \n  Continuously enhance our CI/CD pipelines \n  Instrument & operationalize DORA metrics \n  Close observability gaps across our tech stack \n  Reduce release-time from commit to production \n  Assist the organization in embracing microservices architecture & \n  Work with engineering leadership to identify & establish key metrics, SLOs \n \n  Within 6-12 months you will:\n    \n  Instrument & operationalize squad-specific + service-specific  change-failure-rate monitoring & alerting \n  Work with engineering management to establish and usher in initial adoption of a formalized SDLC Program to operate alongside R&D's PDLC \n \n \n \n \n \n \n Who You'll Collaborate With: \n \n This role will report to Engineering Manager, DevSecOps + QA \n  You will work closely with R&D Product Squads to support Developer Experience & AppSec Programs \n  You will be part of our foundational & multidisciplinary DevSecOps + QA squad as a shining Individual among 7 other fantastic Humans \n \n \n What You Bring: \n \n \n DevOps & ChatOps Tooling Stewardship \n \n Go or similar programming language experience \n  Documentation & technical writing skills, exceptional partner communicating technical matters & business risks for varying audiences \n  Experience in frequent-deploy Agile release PDLC environments (organization deploying multiple times / day to production) \n  Thoughtful about considering DevOps impacts & opportunities alongside AppSec & Infra competing priorities \n  Experience working in a SaaS Product or tech startup environment \n  Supporting product squad deploy capabilities\n    \n  Patient troubleshooting \n  Bash / Zsh shell scripting \n  CI/CD Pipelines \n \n \n \n Cloud Infrastructure Engineering Expertise \n \n Experience in frequent-deploy Agile release PDLC  organizations, deploying multiple times / day to production \n  Familiarity with AWS & GCP Cloud Services, including CloudWatch, AMI, k8s & Container Management, RDS, EBS, VPCs, IAM, EC2, S3, SNS \n  Infrastructure as code, e.g. terraform or cloudformation \n  Ready to apply scalable & automatable cloud infrastructure solutions that grow alongside the organization's R&D organization and the company's ambitious goal to reach & engage 55M people / month by 2027 \n  Working with Dockerized services \n  Ability to communicate business risks of technical vulnerabilities, impact of security incidents & unexpected infrastructure events \n  Consistent application of Principle of Least Privilege (PoLP) \n  AWS Certified Solutions Architect, or Developer Certification \n  Experience with at least a few of the following:\n    \n  Designing secure networks \n  IAM Management \n  Vulnerability & dependency management \n  Go \n  Git \n  Ruby / Rails \n  TypeScript \n  Python \n  PostgreSQL \n  Redis, Sidekiq \n  ElasticSearch, Kibana \n \n \n \n Complementary Skills / Competencies (nice-to-have) \n \n Experience with cloud infrastructure security and / or AppSec\n    \n  Vulnerability management & compliance assurance \n  Secure access control management \n  Threat modeling \n \n  Experience building out processes, programs & frameworks used by an engineering community \n  Experience working in a SaaS web product and / or tech startup environment \n  Experience in established SRE / DevSecOps environments \n  Skilled with containerization & microservices \n  Experience in FinTech or Real Estate Tech \n  Real Estate Industry Knowledge \n \n \n     Characteristics of a Homebot  DevOps Engineer \n \n Vigilant & Methodical \n  Values different perspectives & backgrounds \n  Seeks first to Understand, then to be Understood \n  Patient, friendly, approachable & coachable!\n    \n  An excellent candidate will put others at-ease and transmit a sense of calm & patience. Our colleagues must feel safe to confide security concerns with you & seek advice trusting that you'll seek to provide expert counsel & support \n \n  Collaborative Force Multiplier \n  A Solutions Creator who takes initiative and proactively seeks to add value \n  A quick learner, eager to grow by helping wherever needed! \n  Confident, adaptable self-starter who thrives in a fast-paced environment \n  Efficiency-focused - always looking for new processes and tools to increase efficiency \n  Collaborative, gritty, and resourceful \n  A positive, \u2018get it done' attitude \n  Action-oriented \u2013 won't sit around and wait for someone else to do it \n  Passionate about the details - nothing slips through the cracks! \n  You are always curious; you maintain a learner's mind in all aspects of the job, identifying and testing assumptions to get to the heart of a situation! \n  You get stoked about joining a scaling team, where you can own initiatives, take on hats outside your role, and evolve this position to deliver maximum value to our teams and your career \n \n \n Who We Strive To Be as Homebotters: \n \n We are Humbly Hungry \n  We are Courageously Authentic \n  We Challenge Limiting Beliefs \n  We Keep our Eye on the Ball, Hand in the Dirt \n  and we do all of this TOGETHER, as a team, and we have fun doing it! \n \n \n Read about  (https://www.builtincolorado.com/2022/06/13/how-homebot-anchors-company-values)  how we rolled out these new values to the organization! \n \n Why Homebot? \n We believe in a collaborative, fun work environment. And when we say we have an awesome culture, we mean it. The team members, aka Homebotters, are not only passionate about our product, but also about how they interact with each other. We push ourselves every day to be better, challenge each other to continuously grow, and to have fun doing it. We are professional when we need to be and goofy when it's time to celebrate a win. We realize we might be a little biased so we encourage you to check out our Glassdoor reviews (https://www.glassdoor.com/Reviews/Homebot-Reviews-E1799514.htm) and visit BuiltinColorado's Best Places to Work (https://builtin.com/awards/colorado/2023/best-places-to-work#homebot) list (#82!) and Best Midsize Places to Work (https://builtin.com/awards/colorado/2023/best-midsize-places-to-work#homebot) (#46) for 2023! \n With the mortgage and tech industries being highly male-dominated, we're proud to be a tech company in the mortgage space with ~40% female employees across the organization. We encourage you to check out two of our awesome BuiltinColorado's articles featuring one of our fantastic engineers (https://www.builtincolorado.com/2022/06/03/9-colorado-tech-companies-hiring-engineers-june-2022?utm_source=linkedin&utm_medium=social_media&utm_campaign=homebot), as well as our Chief Customer Officer (https://www.builtincolorado.com/2023/09/19/mix-tapes-blackhawk-helicopters-and-tampa-bay-buccaneers-how-11-women-discovered-their#Homebot)!! \n We appreciate and value what our team members do every day, so we offer some amazing benefits to reward them: \n \n Perks/Benefits: \n \n Medical (Aetna) / Dental (Sun Life) / Vision (VSP)\n    \n  Homebot covers 99% for the employee and 50% for dependents \n \n  401(k) match\n    \n  Homebot matches 100% on the first 3% and an additional 50% on the next 2% (Homebotter contributes 5% and receives 4% from Homebot!) \n \n  Flexible Vacation Policy - we believe in taking care of yourself & rewarding team members so we offer flexible time off policy! \n  6 days of Sick/Mental Health time \n  Paid Parental Leave - 12 Weeks! \n  Hybrid Working Model - Blend Work From Home and In-Office Days \n  Budget for Home Office Setup \n  Denver EcoPass for light rail and bus system  Office location in downtown Denver (modern, spacious 4-story with top floor deck\n    ) \n  Relocation reimbursement for out-of-state moves to the Denver area \n  Weekly catered lunches in-office on Thursdays \n  Nitro cold brew, french press, smoothie bullet and snacks (vegan, gluten-free and food allergy safe options available) \n  Rotating beer tap + stocked beer/wine fridge, hard kombucha, wine tap \n  Fun quarterly events like Rockies games, holiday parties, etc. \n  Awesome culture! Awesome coworkers! (seriously, have you seen Glassdoor?) \n  We give back to the community (Habitat for Humanity, Giving Tree) \n  Open work environment with sit/stand desks \n  Financial Wellness Program \n  Free Employee Assistance Program & Mental Health Coaches \n  Educational Assistance Program \n  Annual Training Budget for Professional Development \n \n \n \n \n \n Our DEI Mission \n Homebot values and is strengthened by diversity. We believe that everyone comes from a diverse set of backgrounds and each member brings different skills to the group. With that, we're committed to ensuring equity within as many aspects of our organization as we can. \n Homebot is proud to be an equal opportunity employer and we encourage all applicants to apply. All qualified applicants will receive consideration for employment, transfer, or promotion opportunities without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. We also encourage you to apply even if your experience doesn't precisely match the job description :) \n \n More about Homebot \n Problem we're solving: \n The US homeownership market is the largest asset class in the world at $30 trillion but is essentially an \u201cunmanaged\u201d asset that causes people to leave billions of dollars on the table every year. At the same time, loan officers and real estate agents spent $20 billion a year on desperate attempts to maintain mindshare and loyalty with their past clients in hopes of gaining more repeat and referral business. \n Our solution: \n Homebot is a client-for-life portal that maximizes repeat and referral business for lenders by empowering consumers to build wealth through homeownership. The award-winning client portal delivers personalized, actionable intelligence throughout the entire homeownership lifecycle to every client and prospect. With an average 50% monthly engagement rate, Homebot ensures lenders and agents remain the trusted advisors that consumers rely on to make informed decisions about the largest asset they may ever own, their home. \n It's definitely a game-changer and we are truly making an impact. Having launched in 2016, we're over 100 Homebotters strong and expect to continue that growth throughout the year. Join us! \n Check out our website at www.homebot.ai (http://www.homebot.ai/)",
        "cleaned_desc": " \n \n \n \n \n Who You'll Collaborate With: \n \n This role will report to Engineering Manager, DevSecOps + QA \n  You will work closely with R&D Product Squads to support Developer Experience & AppSec Programs \n  You will be part of our foundational & multidisciplinary DevSecOps + QA squad as a shining Individual among 7 other fantastic Humans \n \n \n What You Bring: \n \n \n DevOps & ChatOps Tooling Stewardship \n \n Go or similar programming language experience \n  Documentation & technical writing skills, exceptional partner communicating technical matters & business risks for varying audiences \n  Experience in frequent-deploy Agile release PDLC environments (organization deploying multiple times / day to production) \n  Thoughtful about considering DevOps impacts & opportunities alongside AppSec & Infra competing priorities \n  Experience working in a SaaS Product or tech startup environment \n  Supporting product squad deploy capabilities\n    \n  Patient troubleshooting \n  Bash / Zsh shell scripting \n  CI/CD Pipelines \n \n \n \n Cloud Infrastructure Engineering Expertise \n \n Experience in frequent-deploy Agile release PDLC  organizations, deploying multiple times / day to production \n  Familiarity with AWS & GCP Cloud Services, including CloudWatch, AMI, k8s & Container Management, RDS, EBS, VPCs, IAM, EC2, S3, SNS \n  Infrastructure as code, e.g. terraform or cloudformation \n  Ready to apply scalable & automatable cloud infrastructure solutions that grow alongside the organization's R&D organization and the company's ambitious goal to reach & engage 55M people / month by 2027 \n  Working with Dockerized services \n  Ability to communicate business risks of technical vulnerabilities, impact of security incidents & unexpected infrastructure events    Consistent application of Principle of Least Privilege (PoLP) \n  AWS Certified Solutions Architect, or Developer Certification \n  Experience with at least a few of the following:\n    \n  Designing secure networks \n  IAM Management \n  Vulnerability & dependency management \n  Go \n  Git \n  Ruby / Rails \n  TypeScript \n  Python \n  PostgreSQL \n  Redis, Sidekiq \n  ElasticSearch, Kibana \n \n \n \n Complementary Skills / Competencies (nice-to-have) \n \n Experience with cloud infrastructure security and / or AppSec\n    \n  Vulnerability management & compliance assurance \n  Secure access control management \n  Threat modeling \n \n  Experience building out processes, programs & frameworks used by an engineering community \n  Experience working in a SaaS web product and / or tech startup environment \n  Experience in established SRE / DevSecOps environments \n  Skilled with containerization & microservices \n  Experience in FinTech or Real Estate Tech \n  Real Estate Industry Knowledge \n \n \n     Characteristics of a Homebot  DevOps Engineer \n \n Vigilant & Methodical \n  Values different perspectives & backgrounds ",
        "techs": [
            "devops & chatops tooling stewardship",
            "go",
            "documentation & technical writing skills",
            "frequent-deploy agile release pdlc environments",
            "thoughtful consideration of devops impacts",
            "saas product or tech startup environment",
            "supporting product squad deploy capabilities",
            "patient troubleshooting",
            "bash / zsh shell scripting",
            "ci/cd pipelines",
            "cloud infrastructure engineering expertise",
            "aws & gcp cloud services",
            "infrastructure as code",
            "terraform or cloudformation",
            "dockerized services",
            "communication of business risks",
            "principle of least privilege (polp)",
            "aws certified solutions architect or developer certification",
            "designing secure networks",
            "iam management",
            "vulnerability & dependency management",
            "go",
            "git",
            "ruby / rails",
            "typescript",
            "python",
            "postgresql",
            "redis",
            "sidekiq",
            "elasticsearch",
            "kibana",
            "cloud infrastructure security",
            "appsec",
            "vulnerability management & compliance assurance",
            "secure access control management",
            "threat modeling",
            "building out processes",
            "programs & frameworks",
            "established sre / devsecops environments",
            "containerization & microservices",
            "fintech or real estate tech",
            "real estate industry knowledge"
        ],
        "cleaned_techs": [
            "devops & chatops tooling stewardship",
            "go",
            "frequent-deploy agile release pdlc environments",
            "thoughtful consideration of devops impacts",
            "saas product or tech startup environment",
            "supporting product squad deploy capabilities",
            "patient troubleshooting",
            "bash / zsh shell scripting",
            "ci/cd pipelines",
            "cloud infrastructure engineering expertise",
            "aws",
            "infrastructure as code",
            "terraform or cloudformation",
            "dockerized services",
            "communication of business risks",
            "principle of least privilege (polp)",
            "designing secure networks",
            "iam management",
            "vulnerability & dependency management",
            "git",
            "ruby / rails",
            "typescript",
            "python",
            "postgresql",
            "redis",
            "sidekiq",
            "elasticsearch",
            "kibana",
            "appsec",
            "vulnerability management & compliance assurance",
            "secure access control management",
            "threat modeling",
            "building out processes",
            "programs & frameworks",
            "established sre / devsecops environments",
            "containerization & microservices",
            "fintech or real estate tech",
            "real estate industry knowledge"
        ]
    },
    "bd65ffa74521fd62": {
        "terms": [
            "mlops"
        ],
        "salary_min": 100000.0,
        "salary_max": 130000.0,
        "title": "DevOps Engineer - Remote",
        "company": "CyberCoders",
        "desc": "DevOps Engineer - Remote \n  \n  We are a rapidly growing pharmacy based out of Atlantic County, NJ. We are committed to improving patients outcomes by providing optimal service and an unsurpassed level of care. By integrating clinical pharmacy care with technology and dedication to the patient we offer an unparalleled pharmacy experience enabling a healthier tomorrow.\n   \n  The DevOps Engineer will be responsible for the smooth operation of our IT infrastructure. Work with developers to deploy and manage code changes, and with operations staff to ensure that systems are up and running smoothly. To be successful in this role, a DevOps engineer must have a deep understanding of both development and operations processes, as well as a strong technical background.\n  \n  What You Will Be Doing \n \n Collaborate with development teams to design and implement CI/CD pipelines for PHP and Laravel applications on Azure, Windows, and Linux. \n Manage and automate deployment, scaling, and monitoring of PHP applications in Azure Kubernetes Service (AKS) or Azure App Service. \n Ensure the reliability and performance of our systems \n Implement and maintain security best practices, including identity and access management, encryption, and compliance on Azure. \n Troubleshoot and resolve infrastructure issues in a timely manner. \n Continuously monitor system performance and proactively optimize infrastructure for cost efficiency. \n Collaborate with cross-functional teams to optimize application architecture for cloud scalability. \n Stay updated on industry trends and emerging technologies to drive innovation within the team. \n \n  What You Need for this Position \n \n   BSCS or similar and 3+ years of:\n   \n \n Experience with containerization and orchestration tools such as Docker. \n Experience with software development using LAMP stack. \n Familiarity with CI/CD tools such as GitLab CI/CD, or Azure DevOps Pipelines. \n Strong expertise in Azure services, including Azure DevOps, Azure Kubernetes Service, Azure App Service, and Azure Monitor. \n Strong analytical and problem-solving skills required. \n \n \n  What's In It for You \n \n   Salary: $100,000-$130,000/year\n   \n \n Full benefits: Medical, Dental, Vision \n 401 (K) with generous company match \n Vacation, sick, and paid holidays \n Life Insurance coverage \n \n \n  Benefits \n \n Vacation/PTO \n Medical \n Dental \n Vision \n 401k \n \n \n   So, if this sounds like you, we'd love to hear from you!\n   \n  Either:\n    1. Apply directly to this job opening here!\n   \n  Or\n   \n  2. E-mail directly for more information to patrick.solano@cybercoders.com\n  \n \n   Colorado employees will receive paid sick leave. For additional information about available benefits, please contact Patrick Solano\n  \n \n Applicants must be authorized to work in the U.S. \n  CyberCoders is proud to be an Equal Opportunity Employer \n \n  All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.\n  \n \n Your Right to Work  \u2013 In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.",
        "cleaned_desc": "DevOps Engineer - Remote \n  \n  We are a rapidly growing pharmacy based out of Atlantic County, NJ. We are committed to improving patients outcomes by providing optimal service and an unsurpassed level of care. By integrating clinical pharmacy care with technology and dedication to the patient we offer an unparalleled pharmacy experience enabling a healthier tomorrow.\n   \n  The DevOps Engineer will be responsible for the smooth operation of our IT infrastructure. Work with developers to deploy and manage code changes, and with operations staff to ensure that systems are up and running smoothly. To be successful in this role, a DevOps engineer must have a deep understanding of both development and operations processes, as well as a strong technical background.\n  \n  What You Will Be Doing \n \n Collaborate with development teams to design and implement CI/CD pipelines for PHP and Laravel applications on Azure, Windows, and Linux. \n Manage and automate deployment, scaling, and monitoring of PHP applications in Azure Kubernetes Service (AKS) or Azure App Service. \n Ensure the reliability and performance of our systems \n Implement and maintain security best practices, including identity and access management, encryption, and compliance on Azure. \n Troubleshoot and resolve infrastructure issues in a timely manner.   Continuously monitor system performance and proactively optimize infrastructure for cost efficiency. \n Collaborate with cross-functional teams to optimize application architecture for cloud scalability. \n Stay updated on industry trends and emerging technologies to drive innovation within the team. \n \n  What You Need for this Position \n \n   BSCS or similar and 3+ years of:\n   \n \n Experience with containerization and orchestration tools such as Docker. \n Experience with software development using LAMP stack. \n Familiarity with CI/CD tools such as GitLab CI/CD, or Azure DevOps Pipelines. \n Strong expertise in Azure services, including Azure DevOps, Azure Kubernetes Service, Azure App Service, and Azure Monitor. ",
        "techs": [
            "devops engineer",
            "php",
            "laravel",
            "azure",
            "windows",
            "linux",
            "ci/cd",
            "azure kubernetes service (aks)",
            "azure app service",
            "identity and access management",
            "encryption",
            "compliance",
            "docker",
            "lamp stack",
            "gitlab ci/cd",
            "azure devops pipelines",
            "azure devops",
            "azure monitor"
        ],
        "cleaned_techs": [
            "php",
            "laravel",
            "azure",
            "windows",
            "linux",
            "ci/cd",
            "identity and access management",
            "encryption",
            "compliance",
            "docker",
            "lamp stack",
            "gitlab ci/cd"
        ]
    },
    "metadata": {
        "keywords": [
            "data science",
            "data analyst",
            "data engineer",
            "machine learning engineer",
            "mlops"
        ],
        "locations": [
            "remote"
        ],
        "time_ran": "13:32:59-18-10-23",
        "num_jobs": 274,
        "timings": {
            "start_drivers": 46.37139296531677,
            "find_job_ids": 423.38553619384766,
            "get_job_descs": 121.41661977767944
        },
        "models": {
            "classifier": {
                "clf": "data/classifier_models/job_desc_classifier_v1.0.pkl",
                "tfidf": "data/classifier_models/job_desc_tfidf_vectorizer_v1.0.pkl"
            },
            "NER": "gpt-3.5-turbo"
        }
    }
}