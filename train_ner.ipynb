{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should change the get_tech.py to now save shortened texts as short_desc rather than clean_desc.  Then here we can add clean_desc for when we aren't using openai API.  Change previous .json files as well if we do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "\n",
    "from spacy.training.example import Example\n",
    "from spacy.scorer import Scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Remove bad techs\n",
    "Before we do any training or NER we want to remove the techs that don't belong that the OpenAI API picked up anyways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Collect and annotate data\n",
    "This was done with job_search.py and get_techs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"p-raw_data-17-09-23.json\" # one test json file, will iterate through what I need later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fr\"data/{filename}\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data preprocessing\n",
    "We must clean/format our job descriptions and tech entities, then convert the data into spaCy training data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "for key in data:\n",
    "    if key == 'metadata':\n",
    "        continue\n",
    "    else:\n",
    "        # print(data[key]['cleaned_desc'])\n",
    "        # print(data[key]['techs'])\n",
    "        technologies = data[key]['techs']\n",
    "        \n",
    "        for tech in technologies:\n",
    "            tech = tech.lower()  # Convert the technology to lowercase\n",
    "            for match in re.finditer(r'\\b' + re.escape(tech) + r'\\b', data[key]['cleaned_desc'].lower()):\n",
    "                start, end = match.start(), match.end()\n",
    "                training_data.append((data[key]['cleaned_desc'].lower(), {\"entities\": [(start, end, \"TECH\")]}))\n",
    "\n",
    "    \n",
    "# Below fails as it'll find first match\n",
    "# E.g. for data[\"dd60a69f8f6a7bd7\"]['cleaned_desc'].lower(), 'r' programming language is found at [23:24] in the word 'large'\n",
    "        # for tech in technologies:\n",
    "        #     start = data[key]['cleaned_desc'].lower().find(tech)\n",
    "        #     if start != -1:\n",
    "        #         end = start + len(tech)\n",
    "        #         training_data.append((data[key]['cleaned_desc'].lower(), {\"entities\": [(start, end, \"TECH\")]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\" \\n collect and clean large datasets from various sources \\n analyze data using statistical techniques and machine learning algorithms \\n develop predictive models and perform data visualization \\n collaborate with cross-functional teams to identify business problems and propose data-driven solutions   bachelor's degree in a quantitative field such as computer science, statistics, mathematics, or related fields \\n experience in data analysis, data mining, and data visualization techniques \\n proficiency in programming languages such as python or r \\n strong understanding of statistical modeling and machine learning algorithms \\n ability to work with large datasets and perform data cleaning and preprocessing \",\n",
       "  {'entities': [(536, 542, 'TECH')]}),\n",
       " (\" \\n collect and clean large datasets from various sources \\n analyze data using statistical techniques and machine learning algorithms \\n develop predictive models and perform data visualization \\n collaborate with cross-functional teams to identify business problems and propose data-driven solutions   bachelor's degree in a quantitative field such as computer science, statistics, mathematics, or related fields \\n experience in data analysis, data mining, and data visualization techniques \\n proficiency in programming languages such as python or r \\n strong understanding of statistical modeling and machine learning algorithms \\n ability to work with large datasets and perform data cleaning and preprocessing \",\n",
       "  {'entities': [(546, 547, 'TECH')]})]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(filenames):\n",
    "    \"\"\"Function to get the spaCy training data from our shortened job descriptions and OpenAI API results.\n",
    "    Returns spaCy training data\n",
    "\n",
    "    Args:\n",
    "        filenames (list): List of filenames of parsed .json files to be used to generate training data\n",
    "    \"\"\"\n",
    "    training_data = []\n",
    "    for filename in filenames:\n",
    "        with open(fr\"data/{filename}\") as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        for key in data:\n",
    "            if key == 'metadata':\n",
    "                continue\n",
    "            else:\n",
    "                technologies = data[key]['techs'] \n",
    "                if len(technologies) > 0:  # there's at least 1 tech\n",
    "                    lower_job_desc = data[key]['cleaned_desc'].lower()\n",
    "                    entities = [] # init list to store techs for a given jd\n",
    "                    for tech in technologies:\n",
    "                        tech = tech.lower()  # Convert the technology to lowercase, should already be, but make sure.\n",
    "                        for match in re.finditer(r'\\b' + re.escape(tech) + r'\\b', lower_job_desc):\n",
    "                            start, end = match.start(), match.end()\n",
    "                            entities.append((start, end, \"TECH\"))\n",
    "                    training_data.append((lower_job_desc, {\"entities\": entities}))\n",
    "                else:\n",
    "                    continue\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [filename for filename in os.listdir(\"data\") if filename.startswith(\"p-raw\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = get_training_data(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data into training and validation sets.\n",
    "random.seed(1234)\n",
    "random.shuffle(training_data)\n",
    "validation_split = int(0.2 * len(training_data)) # get the number for a 80-20 train-valid split\n",
    "training_set = training_data[:-validation_split]\n",
    "validation_set = training_data[-validation_split]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Init NER model\n",
    "We can either use a blank spaCy model or a pre-trained one to fine-tune.  Let's start with a blank one and see how it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creates a blank NLP, commented out as we have one now.\n",
    "# blank_nlp = spacy.blank(\"en\")\n",
    "# ner = blank_nlp.create_pipe(\"ner\")\n",
    "# ner.add_label(\"TECH\")\n",
    "# blank_nlp.add_pipe(\"ner\")\n",
    "\n",
    "# blank_nlp.to_disk(\"data/ner_models/nlp_v1.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Training NER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_version = \"data/ner_models/nlp_v1.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below broken, seems to be due to extraneous techs that openai api picked up.  Should clean them up before using them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E103] Trying to set conflicting doc.ents: '(561, 571, 'TECH')' and '(549, 571, 'TECH')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\n",
      "{'entities': [(23, 50, 'TECH'), (72, 87, 'TECH'), (135, 163, 'TECH'), (189, 211, 'TECH'), (216, 233, 'TECH'), (235, 245, 'TECH'), (462, 472, 'TECH'), (561, 571, 'TECH'), (251, 259, 'TECH'), (421, 435, 'TECH'), (448, 457, 'TECH'), (1244, 1253, 'TECH'), (488, 509, 'TECH'), (521, 524, 'TECH'), (1255, 1258, 'TECH'), (529, 544, 'TECH'), (549, 571, 'TECH'), (691, 713, 'TECH'), (797, 820, 'TECH'), (917, 933, 'TECH'), (935, 957, 'TECH'), (1133, 1151, 'TECH'), (1184, 1198, 'TECH'), (1200, 1203, 'TECH'), (1205, 1217, 'TECH'), (1219, 1224, 'TECH'), (448, 457, 'TECH'), (1244, 1253, 'TECH'), (521, 524, 'TECH'), (1255, 1258, 'TECH'), (144, 163, 'TECH'), (1325, 1344, 'TECH'), (1346, 1352, 'TECH'), (1354, 1358, 'TECH'), (1385, 1407, 'TECH'), (23, 42, 'TECH'), (1412, 1431, 'TECH'), (1472, 1480, 'TECH'), (1485, 1492, 'TECH')]}\n",
      "  design and implement continuous delivery systems and methodologies on cloud platforms. \n",
      " automate our operations and processes using advanced scripting languages. \n",
      " develop and implement infrastructure as code for environment setup, management, and teardown, ensuring a smooth transition from development to production. \n",
      " collaborate with development and operations teams to enhance efficiency and effectiveness of the ci/cd pipeline. \n",
      " leverage terraform for management and scaling of cloud-based resources. \n",
      " utilize git for version control and source code management. \n",
      " monitor system performance proactively, troubleshoot issues, and ensure system stability and scalability. \n",
      " conduct system troubleshooting and problem-solving across platform and application domains. \n",
      " implement stringent cloud security measures to safeguard critical system components. \n",
      " \n",
      "    **qualifications:** \n",
      " \n",
      " \n",
      "  bachelor's degree in computer science, information technology, or related field. master's degree preferred. \n",
      " 5-7 years of experience in a devops role or similar, with demonstrated success in software deployment. \n",
      " deep understanding of cloud architecture and substantial experience with cloud services (aws, google cloud, azure). \n",
      " proficiency in terraform, git, and other infrastructure and deployment tools. \n",
      " experience with scripting languages (python, bash). \n",
      " advanced knowledge of continuous integration and continuous delivery (ci/cd) methodologies. \n",
      " proficiency in sap hana and sap sac is a substantial advantage. \n",
      " excellent problem-solving skills and keen attention to detail. \n",
      "Losses: {}\n",
      "[E103] Trying to set conflicting doc.ents: '(561, 571, 'TECH')' and '(549, 571, 'TECH')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\n",
      "{'entities': [(23, 50, 'TECH'), (72, 87, 'TECH'), (135, 163, 'TECH'), (189, 211, 'TECH'), (216, 233, 'TECH'), (235, 245, 'TECH'), (462, 472, 'TECH'), (561, 571, 'TECH'), (251, 259, 'TECH'), (421, 435, 'TECH'), (448, 457, 'TECH'), (1244, 1253, 'TECH'), (488, 509, 'TECH'), (521, 524, 'TECH'), (1255, 1258, 'TECH'), (529, 544, 'TECH'), (549, 571, 'TECH'), (691, 713, 'TECH'), (797, 820, 'TECH'), (917, 933, 'TECH'), (935, 957, 'TECH'), (1133, 1151, 'TECH'), (1184, 1198, 'TECH'), (1200, 1203, 'TECH'), (1205, 1217, 'TECH'), (1219, 1224, 'TECH'), (448, 457, 'TECH'), (1244, 1253, 'TECH'), (521, 524, 'TECH'), (1255, 1258, 'TECH'), (144, 163, 'TECH'), (1325, 1344, 'TECH'), (1346, 1352, 'TECH'), (1354, 1358, 'TECH'), (1385, 1407, 'TECH'), (23, 42, 'TECH'), (1412, 1431, 'TECH'), (1472, 1480, 'TECH'), (1485, 1492, 'TECH')]}\n",
      "  design and implement continuous delivery systems and methodologies on cloud platforms. \n",
      " automate our operations and processes using advanced scripting languages. \n",
      " develop and implement infrastructure as code for environment setup, management, and teardown, ensuring a smooth transition from development to production. \n",
      " collaborate with development and operations teams to enhance efficiency and effectiveness of the ci/cd pipeline. \n",
      " leverage terraform for management and scaling of cloud-based resources. \n",
      " utilize git for version control and source code management. \n",
      " monitor system performance proactively, troubleshoot issues, and ensure system stability and scalability. \n",
      " conduct system troubleshooting and problem-solving across platform and application domains. \n",
      " implement stringent cloud security measures to safeguard critical system components. \n",
      " \n",
      "    **qualifications:** \n",
      " \n",
      " \n",
      "  bachelor's degree in computer science, information technology, or related field. master's degree preferred. \n",
      " 5-7 years of experience in a devops role or similar, with demonstrated success in software deployment. \n",
      " deep understanding of cloud architecture and substantial experience with cloud services (aws, google cloud, azure). \n",
      " proficiency in terraform, git, and other infrastructure and deployment tools. \n",
      " experience with scripting languages (python, bash). \n",
      " advanced knowledge of continuous integration and continuous delivery (ci/cd) methodologies. \n",
      " proficiency in sap hana and sap sac is a substantial advantage. \n",
      " excellent problem-solving skills and keen attention to detail. \n",
      "Losses: {}\n",
      "[E103] Trying to set conflicting doc.ents: '(561, 571, 'TECH')' and '(549, 571, 'TECH')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\n",
      "{'entities': [(23, 50, 'TECH'), (72, 87, 'TECH'), (135, 163, 'TECH'), (189, 211, 'TECH'), (216, 233, 'TECH'), (235, 245, 'TECH'), (462, 472, 'TECH'), (561, 571, 'TECH'), (251, 259, 'TECH'), (421, 435, 'TECH'), (448, 457, 'TECH'), (1244, 1253, 'TECH'), (488, 509, 'TECH'), (521, 524, 'TECH'), (1255, 1258, 'TECH'), (529, 544, 'TECH'), (549, 571, 'TECH'), (691, 713, 'TECH'), (797, 820, 'TECH'), (917, 933, 'TECH'), (935, 957, 'TECH'), (1133, 1151, 'TECH'), (1184, 1198, 'TECH'), (1200, 1203, 'TECH'), (1205, 1217, 'TECH'), (1219, 1224, 'TECH'), (448, 457, 'TECH'), (1244, 1253, 'TECH'), (521, 524, 'TECH'), (1255, 1258, 'TECH'), (144, 163, 'TECH'), (1325, 1344, 'TECH'), (1346, 1352, 'TECH'), (1354, 1358, 'TECH'), (1385, 1407, 'TECH'), (23, 42, 'TECH'), (1412, 1431, 'TECH'), (1472, 1480, 'TECH'), (1485, 1492, 'TECH')]}\n",
      "  design and implement continuous delivery systems and methodologies on cloud platforms. \n",
      " automate our operations and processes using advanced scripting languages. \n",
      " develop and implement infrastructure as code for environment setup, management, and teardown, ensuring a smooth transition from development to production. \n",
      " collaborate with development and operations teams to enhance efficiency and effectiveness of the ci/cd pipeline. \n",
      " leverage terraform for management and scaling of cloud-based resources. \n",
      " utilize git for version control and source code management. \n",
      " monitor system performance proactively, troubleshoot issues, and ensure system stability and scalability. \n",
      " conduct system troubleshooting and problem-solving across platform and application domains. \n",
      " implement stringent cloud security measures to safeguard critical system components. \n",
      " \n",
      "    **qualifications:** \n",
      " \n",
      " \n",
      "  bachelor's degree in computer science, information technology, or related field. master's degree preferred. \n",
      " 5-7 years of experience in a devops role or similar, with demonstrated success in software deployment. \n",
      " deep understanding of cloud architecture and substantial experience with cloud services (aws, google cloud, azure). \n",
      " proficiency in terraform, git, and other infrastructure and deployment tools. \n",
      " experience with scripting languages (python, bash). \n",
      " advanced knowledge of continuous integration and continuous delivery (ci/cd) methodologies. \n",
      " proficiency in sap hana and sap sac is a substantial advantage. \n",
      " excellent problem-solving skills and keen attention to detail. \n",
      "Losses: {}\n",
      "[E103] Trying to set conflicting doc.ents: '(561, 571, 'TECH')' and '(549, 571, 'TECH')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\n",
      "{'entities': [(23, 50, 'TECH'), (72, 87, 'TECH'), (135, 163, 'TECH'), (189, 211, 'TECH'), (216, 233, 'TECH'), (235, 245, 'TECH'), (462, 472, 'TECH'), (561, 571, 'TECH'), (251, 259, 'TECH'), (421, 435, 'TECH'), (448, 457, 'TECH'), (1244, 1253, 'TECH'), (488, 509, 'TECH'), (521, 524, 'TECH'), (1255, 1258, 'TECH'), (529, 544, 'TECH'), (549, 571, 'TECH'), (691, 713, 'TECH'), (797, 820, 'TECH'), (917, 933, 'TECH'), (935, 957, 'TECH'), (1133, 1151, 'TECH'), (1184, 1198, 'TECH'), (1200, 1203, 'TECH'), (1205, 1217, 'TECH'), (1219, 1224, 'TECH'), (448, 457, 'TECH'), (1244, 1253, 'TECH'), (521, 524, 'TECH'), (1255, 1258, 'TECH'), (144, 163, 'TECH'), (1325, 1344, 'TECH'), (1346, 1352, 'TECH'), (1354, 1358, 'TECH'), (1385, 1407, 'TECH'), (23, 42, 'TECH'), (1412, 1431, 'TECH'), (1472, 1480, 'TECH'), (1485, 1492, 'TECH')]}\n",
      "  design and implement continuous delivery systems and methodologies on cloud platforms. \n",
      " automate our operations and processes using advanced scripting languages. \n",
      " develop and implement infrastructure as code for environment setup, management, and teardown, ensuring a smooth transition from development to production. \n",
      " collaborate with development and operations teams to enhance efficiency and effectiveness of the ci/cd pipeline. \n",
      " leverage terraform for management and scaling of cloud-based resources. \n",
      " utilize git for version control and source code management. \n",
      " monitor system performance proactively, troubleshoot issues, and ensure system stability and scalability. \n",
      " conduct system troubleshooting and problem-solving across platform and application domains. \n",
      " implement stringent cloud security measures to safeguard critical system components. \n",
      " \n",
      "    **qualifications:** \n",
      " \n",
      " \n",
      "  bachelor's degree in computer science, information technology, or related field. master's degree preferred. \n",
      " 5-7 years of experience in a devops role or similar, with demonstrated success in software deployment. \n",
      " deep understanding of cloud architecture and substantial experience with cloud services (aws, google cloud, azure). \n",
      " proficiency in terraform, git, and other infrastructure and deployment tools. \n",
      " experience with scripting languages (python, bash). \n",
      " advanced knowledge of continuous integration and continuous delivery (ci/cd) methodologies. \n",
      " proficiency in sap hana and sap sac is a substantial advantage. \n",
      " excellent problem-solving skills and keen attention to detail. \n",
      "Losses: {}\n",
      "[E103] Trying to set conflicting doc.ents: '(561, 571, 'TECH')' and '(549, 571, 'TECH')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\n",
      "{'entities': [(23, 50, 'TECH'), (72, 87, 'TECH'), (135, 163, 'TECH'), (189, 211, 'TECH'), (216, 233, 'TECH'), (235, 245, 'TECH'), (462, 472, 'TECH'), (561, 571, 'TECH'), (251, 259, 'TECH'), (421, 435, 'TECH'), (448, 457, 'TECH'), (1244, 1253, 'TECH'), (488, 509, 'TECH'), (521, 524, 'TECH'), (1255, 1258, 'TECH'), (529, 544, 'TECH'), (549, 571, 'TECH'), (691, 713, 'TECH'), (797, 820, 'TECH'), (917, 933, 'TECH'), (935, 957, 'TECH'), (1133, 1151, 'TECH'), (1184, 1198, 'TECH'), (1200, 1203, 'TECH'), (1205, 1217, 'TECH'), (1219, 1224, 'TECH'), (448, 457, 'TECH'), (1244, 1253, 'TECH'), (521, 524, 'TECH'), (1255, 1258, 'TECH'), (144, 163, 'TECH'), (1325, 1344, 'TECH'), (1346, 1352, 'TECH'), (1354, 1358, 'TECH'), (1385, 1407, 'TECH'), (23, 42, 'TECH'), (1412, 1431, 'TECH'), (1472, 1480, 'TECH'), (1485, 1492, 'TECH')]}\n",
      "  design and implement continuous delivery systems and methodologies on cloud platforms. \n",
      " automate our operations and processes using advanced scripting languages. \n",
      " develop and implement infrastructure as code for environment setup, management, and teardown, ensuring a smooth transition from development to production. \n",
      " collaborate with development and operations teams to enhance efficiency and effectiveness of the ci/cd pipeline. \n",
      " leverage terraform for management and scaling of cloud-based resources. \n",
      " utilize git for version control and source code management. \n",
      " monitor system performance proactively, troubleshoot issues, and ensure system stability and scalability. \n",
      " conduct system troubleshooting and problem-solving across platform and application domains. \n",
      " implement stringent cloud security measures to safeguard critical system components. \n",
      " \n",
      "    **qualifications:** \n",
      " \n",
      " \n",
      "  bachelor's degree in computer science, information technology, or related field. master's degree preferred. \n",
      " 5-7 years of experience in a devops role or similar, with demonstrated success in software deployment. \n",
      " deep understanding of cloud architecture and substantial experience with cloud services (aws, google cloud, azure). \n",
      " proficiency in terraform, git, and other infrastructure and deployment tools. \n",
      " experience with scripting languages (python, bash). \n",
      " advanced knowledge of continuous integration and continuous delivery (ci/cd) methodologies. \n",
      " proficiency in sap hana and sap sac is a substantial advantage. \n",
      " excellent problem-solving skills and keen attention to detail. \n",
      "Losses: {}\n"
     ]
    }
   ],
   "source": [
    "# Load in the saved blank we had\n",
    "nlp = spacy.load(nlp_version)\n",
    "\n",
    "# number of epochs to train\n",
    "num_iters = 5 \n",
    "\n",
    "# Train the NER component\n",
    "for _ in range(num_iters):\n",
    "    losses = {}\n",
    "    examples = []\n",
    "\n",
    "    for text, annotations in training_set:\n",
    "        try:\n",
    "            doc = nlp.make_doc(text)\n",
    "            example = Example.from_dict(doc, annotations)\n",
    "            examples.append(example)\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            print(annotations)\n",
    "            print(text)\n",
    "            break\n",
    "    nlp.update(examples, drop=0.5, losses=losses)\n",
    "    print(\"Losses:\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.to_disk(nlp_version) # save the updated nlp after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
